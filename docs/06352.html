<html>
<head>
<title>Understanding “convolution” operations in CNN</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">理解CNN中的“卷积”运算</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/understanding-convolution-operations-in-cnn-1914045816d4?source=collection_archive---------5-----------------------#2020-05-19">https://medium.com/analytics-vidhya/understanding-convolution-operations-in-cnn-1914045816d4?source=collection_archive---------5-----------------------#2020-05-19</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/></div><div class="ab cl if ig gp ih" role="separator"><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik"/></div><div class="hb hc hd he hf"><figure class="in io ip iq fd ir er es paragraph-image"><div role="button" tabindex="0" class="is it di iu bf iv"><div class="er es im"><img src="../Images/0ac4212e2e66023e66d98188d9ba2a92.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KhUiEJdZy42JfkCfwm7jjg.jpeg"/></div></div><figcaption class="iy iz et er es ja jb bd b be z dx translated">CNN架构</figcaption></figure><p id="f980" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">人工智能的首要目标是将人类的思维能力带入机器，它在一定程度上实现了这一目标。大多数机器学习方法缺乏微调其内部机制的能力，而这正是神经网络通过其众多可训练参数和潜在的永无止境的训练曲线来拯救的地方。</p><p id="4999" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">在人工智能的无数领域中，最突出的领域之一是计算机视觉，其目标是分类、标记、重建和识别图像/视频中的组件。深度学习的进展与计算机视觉的想法相结合，导致我们创建了一个<strong class="je hj">卷积神经网络，也称为Convnets。</strong></p><h1 id="d855" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">什么是卷积神经网络？它是基于什么？</h1><figure class="in io ip iq fd ir er es paragraph-image"><div role="button" tabindex="0" class="is it di iu bf iv"><div class="er es ky"><img src="../Images/c8b0d82cd45ecde277c5e9fa66de88b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SF_7ii2wOi8GtKr0BjMXRA.png"/></div></div><figcaption class="iy iz et er es ja jb bd b be z dx translated">convnet中的分类</figcaption></figure><p id="1fbb" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">卷积网络属于一类神经网络，它将图像作为输入，对其进行权重和偏差的组合，提取特征并输出结果。它们倾向于通过使用核来降低输入图像的维度，与一般的密集神经网络相比，这使得提取特征更容易。卷积网络的基础可以追溯到矩阵上的<strong class="je hj">卷积运算</strong>。</p><p id="a796" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">Convnets受到生物过程的启发，因为神经元之间的连接模式类似于动物视觉皮层的组织。个别的皮质神经元只在视野中称为感受野的有限区域对刺激做出反应。不同神经元的感受野部分重叠，从而覆盖整个视野。</p><h1 id="2603" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">卷积运算</h1><p id="2c2b" class="pw-post-body-paragraph jc jd hi je b jf kz jh ji jj la jl jm jn lb jp jq jr lc jt ju jv ld jx jy jz hb bi translated">“卷积神经网络”这一名称表明该网络采用了一种称为卷积的数学运算。卷积是一种特殊的线性运算。Convnets是简单的神经网络，它至少在一层中使用卷积来代替一般的矩阵乘法。</p><blockquote class="le lf lg"><p id="02ad" class="jc jd lh je b jf jg jh ji jj jk jl jm li jo jp jq lj js jt ju lk jw jx jy jz hb bi translated">数学中两个函数之间的卷积产生第三个函数，表示一个函数的形状如何被另一个函数修改</p></blockquote><h2 id="4db9" class="ll kb hi bd kc lm ln lo kg lp lq lr kk jn ls lt ko jr lu lv ks jv lw lx kw ly bi translated">卷积核</h2><p id="bdb7" class="pw-post-body-paragraph jc jd hi je b jf kz jh ji jj la jl jm jn lb jp jq jr lc jt ju jv ld jx jy jz hb bi translated">内核是一个小的2D矩阵，其内容基于要执行的操作。核通过简单的矩阵乘法和加法映射到输入图像上，所获得的输出具有较低的维数，因此更容易处理。</p><figure class="in io ip iq fd ir er es paragraph-image"><div class="er es lz"><img src="../Images/47d8fed66b979c7ab2b5cb90e6a5ff7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1206/format:webp/1*ZPXWZDIHFbTxs-6KVPS5gg.png"/></div><figcaption class="iy iz et er es ja jb bd b be z dx translated">内核类型</figcaption></figure><p id="a636" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">上面是一个应用高斯模糊(在处理之前平滑图像)、锐化图像(增强边缘深度)和边缘检测的内核的例子。</p><p id="869b" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">核的形状很大程度上取决于图像的输入形状和整个网络的结构，通常核的大小是<strong class="je hj"> (MxM) </strong>，即一个正方形矩阵。内核的运动总是从左到右，从上到下。</p><figure class="in io ip iq fd ir er es paragraph-image"><div class="er es ma"><img src="../Images/acbceb82920e650f6f708ddb21cca6c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:934/format:webp/1*r-pXJS6r3xtFm-QNkoQdyg.png"/></div><figcaption class="iy iz et er es ja jb bd b be z dx translated">内核运动</figcaption></figure><p id="3e9f" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated"><strong class="je hj">步距</strong>定义了内核移动的步距，例如步距1使内核每次滑动一行/列，步距2使内核移动2行/列。</p><figure class="in io ip iq fd ir er es paragraph-image"><div role="button" tabindex="0" class="is it di iu bf iv"><div class="er es mb"><img src="../Images/89b99d89a3eb22ab3f216a76d891f9ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*m4IsBwYv7QEND-y6xWw3Yw.gif"/></div></div><figcaption class="iy iz et er es ja jb bd b be z dx translated">步幅=1的多核滤波器</figcaption></figure><p id="c358" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">对于具有3个或更多通道(如RGB)的输入图像，应用<strong class="je hj">过滤器</strong></p><blockquote class="le lf lg"><p id="4da2" class="jc jd lh je b jf jg jh ji jj jk jl jm li jo jp jq lj js jt ju lk jw jx jy jz hb bi translated">滤波器比内核高一个维度，可以被视为多个内核相互堆叠，其中每个内核用于一个特定的通道。</p></blockquote><p id="0883" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">因此，对于(32×32)的RGB图像，我们有一个形状为(5x5x3)的过滤器</p><p id="2929" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">现在让我们看看一个内核是如何操作样本矩阵的</p><figure class="in io ip iq fd ir er es paragraph-image"><div class="er es mc"><img src="../Images/0b4c19a8268a19ed2dff5239a147073f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1336/format:webp/1*F-S2h9KgZszROEOQffNfEg.png"/></div><figcaption class="iy iz et er es ja jb bd b be z dx translated">卷积运算</figcaption></figure><p id="4d0d" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">这里，输入矩阵具有4x4x1的形状，并且核的大小为3x3。由于输入的形状大于核，所以我们能够实现滑动窗口协议，并且在整个输入上应用核。卷积结果中的第一项计算如下:</p><blockquote class="le lf lg"><p id="589a" class="jc jd lh je b jf jg jh ji jj jk jl jm li jo jp jq lj js jt ju lk jw jx jy jz hb bi">45*0 + 12*(-1) + 5*0 + 22*(-1) + 10*5 + 35*(-1) + 88*0 + 26*(-1) + 51*0 = -45</p></blockquote><p id="48ee" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">滑动窗口协议:</p><ol class=""><li id="b653" class="md me hi je b jf jg jj jk jn mf jr mg jv mh jz mi mj mk ml bi translated">内核位于输入矩阵的左上角。</li><li id="0692" class="md me hi je b jf mm jj mn jn mo jr mp jv mq jz mi mj mk ml bi translated">然后它开始从左向右移动，计算点积并保存到一个新的矩阵中，直到它到达最后一列。</li><li id="26a6" class="md me hi je b jf mm jj mn jn mo jr mp jv mq jz mi mj mk ml bi translated">接下来，内核重置它在第一列的位置，但是现在它滑动一行到底部。从而跟随时尚左右上下。</li><li id="37cf" class="md me hi je b jf mm jj mn jn mo jr mp jv mq jz mi mj mk ml bi translated">重复步骤2和3，直到处理完所有输入。</li></ol><p id="d545" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">对于3D输入矩阵，内核的移动将是从前到后、从左到右和从上到下。到目前为止，您必须对卷积运算有一个基本的了解，卷积运算是卷积神经网络的本质。</p><h1 id="8f22" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">下一步是什么？</h1><p id="b45c" class="pw-post-body-paragraph jc jd hi je b jf kz jh ji jj la jl jm jn lb jp jq jr lc jt ju jv ld jx jy jz hb bi translated">您可以在Keras/tensor flow/the ano/py torch中实现自己的conv net，也可以更深入地了解它们是如何工作的。说说你的选择吧！感谢您的阅读！保持更新，保持安全:)</p><h1 id="f14c" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">推荐读物</h1><p id="edb6" class="pw-post-body-paragraph jc jd hi je b jf kz jh ji jj la jl jm jn lb jp jq jr lc jt ju jv ld jx jy jz hb bi translated"><a class="ae mr" href="https://cs231n.github.io/convolutional-networks/" rel="noopener ugc nofollow" target="_blank">用于视觉识别的CS231n卷积神经网络</a></p><p id="8389" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated"><a class="ae mr" href="https://missinglink.ai/guides/keras/keras-conv2d-working-cnn-2d-convolutions-keras/" rel="noopener ugc nofollow" target="_blank"> Keras Conv2D:在Keras中使用CNN 2D卷积</a></p></div></div>    
</body>
</html>