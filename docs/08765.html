<html>
<head>
<title>Feature Engineering with the help of Data Visualization</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">借助数据可视化的特征工程</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/feature-engineering-with-the-help-of-data-visualization-69c359f5bba5?source=collection_archive---------8-----------------------#2020-08-12">https://medium.com/analytics-vidhya/feature-engineering-with-the-help-of-data-visualization-69c359f5bba5?source=collection_archive---------8-----------------------#2020-08-12</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/0d03ea2c322c690c8c1006a18a3da925.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t8d6pcrhaZ3GZn31Y-U0pA.png"/></div></div></figure><p id="5dbe" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">为什么特性工程很重要？</strong></p><p id="d20c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">您数据中的<strong class="is hj">特征</strong>将直接影响您模型的准确性。更好的特性使你的测试数据更加准确。你选择的<strong class="is hj">功能</strong>越好，你取得的结果就越好。</p><h1 id="81f3" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated"><strong class="ak">ML 中的特征减少</strong></h1><p id="7874" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">一般认为增加更多的特征可以提高模型/分类器的性能。</p><p id="c9c5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">让我们看看为什么不是这样:</strong></p><ul class=""><li id="f746" class="kr ks hi is b it iu ix iy jb kt jf ku jj kv jn kw kx ky kz bi translated">维度的诅咒:</li></ul><p id="8161" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">选择更多的特征通常会降低分类器的性能。</p><figure class="lb lc ld le fd ij er es paragraph-image"><div class="er es la"><img src="../Images/dfca366036edb73285bc4ea8d39d1f62.png" data-original-src="https://miro.medium.com/v2/resize:fit:562/format:webp/1*B3lJYzcdSSaiB9rWItU24Q.png"/></div><figcaption class="lf lg et er es lh li bd b be z dx translated">维度的诅咒</figcaption></figure><ul class=""><li id="387f" class="kr ks hi is b it iu ix iy jb kt jf ku jj kv jn kw kx ky kz bi translated">有限的训练数据</li><li id="bf1f" class="kr ks hi is b it lj ix lk jb ll jf lm jj ln jn kw kx ky kz bi translated">有限的计算资源</li><li id="d841" class="kr ks hi is b it lj ix lk jb ll jf lm jj ln jn kw kx ky kz bi translated">添加不相关/不必要的特征会导致计算成本增加和性能下降。</li></ul><h1 id="2c6f" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated"><strong class="ak">功能选择:</strong></h1><p id="8dc8" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">有 n 个初始特征，就有可能选择 features(2^n 子集的(2^n)组合。</p><p id="fd9e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们只是不能检查所有可能的(2^n)子集。</p><p id="01d5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">特征选择是一个优化问题</p><ul class=""><li id="c7e8" class="kr ks hi is b it iu ix iy jb kt jf ku jj kv jn kw kx ky kz bi translated">搜索可能子集的空间。</li><li id="88da" class="kr ks hi is b it lj ix lk jb ll jf lm jj ln jn kw kx ky kz bi translated">选择最适合的一个<strong class="is hj">。</strong></li></ul><p id="eef3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">评估特征子集</strong></p><ul class=""><li id="6b34" class="kr ks hi is b it iu ix iy jb kt jf ku jj kv jn kw kx ky kz bi translated"><strong class="is hj">监督学习:</strong></li></ul><p id="49d9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">当在选定的子集上训练时，我们使用验证集中的估计误差进行评估。</p><ul class=""><li id="933e" class="kr ks hi is b it iu ix iy jb kt jf ku jj kv jn kw kx ky kz bi translated"><strong class="is hj">无监督学习:</strong></li></ul><p id="c0ee" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">查看输入并选择包含更多信息的子集。</p><h2 id="a77d" class="lo jp hi bd jq lp lq lr ju ls lt lu jy jb lv lw kc jf lx ly kg jj lz ma kk mb bi translated">选择子集</h2><ul class=""><li id="c86f" class="kr ks hi is b it km ix kn jb mc jf md jj me jn kw kx ky kz bi translated">选择所有相关和不相关的特征。</li><li id="79cc" class="kr ks hi is b it lj ix lk jb ll jf lm jj ln jn kw kx ky kz bi translated">通过添加每个特征来估计分类/回归误差，并选择能最大程度改善验证误差的特征。</li><li id="21dd" class="kr ks hi is b it lj ix lk jb ll jf lm jj ln jn kw kx ky kz bi translated">删除所有对错误影响较小的特征。</li></ul><p id="b4e7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">选择特征的单变量方法</strong></p><ul class=""><li id="c51a" class="kr ks hi is b it iu ix iy jb kt jf ku jj kv jn kw kx ky kz bi translated">皮尔逊相关系数</li></ul><p id="8526" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">范围从-1 到+1，如果该值接近+1，则两个要素高度相关，因此可以移除任何一个要素。如果它更接近-1，则两个特征是高度负相关的。</p><p id="31d2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">让我们使用<em class="mf"> seaborn </em>绘制相关矩阵</p><pre class="lb lc ld le fd mg mh mi mj aw mk bi"><span id="93cd" class="lo jp hi mh b fi ml mm l mn mo"><strong class="mh hj">import</strong> <strong class="mh hj">seaborn</strong> <strong class="mh hj">as</strong> <strong class="mh hj">sns<br/></strong>f, ax = plt.subplots(figsize=(10,10))<br/>sns.heatmap(data.corr(), annot=<strong class="mh hj">True</strong> ,linewidth=0.5,     fmt='.1f',ax=ax);</span></pre><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mp"><img src="../Images/8232a38700b2e86bfaa8ed6d9a42c7f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F1e65tB-f7nurJhXPTGqDQ.png"/></div></div></figure><p id="7c94" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果任何两个变量具有超过 0.7 的相关系数，我们可以说两个特征都是高度相关的，并且一个可以被去除。</p><ul class=""><li id="b05c" class="kr ks hi is b it iu ix iy jb kt jf ku jj kv jn kw kx ky kz bi translated">我们可以使用 J <strong class="is hj">点图</strong>来检查任何两个特征之间的相关性</li></ul><p id="42d9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">压力、握杆角度是两个特征</p><pre class="lb lc ld le fd mg mh mi mj aw mk bi"><span id="c0f5" class="lo jp hi mh b fi ml mm l mn mo">sns.jointplot(data.loc[:,'pressure'],<br/>              data.loc[:,'grip_angle'],<br/>              kind ='regg',<br/>              color= 'blue'<br/>             );</span></pre><figure class="lb lc ld le fd ij er es paragraph-image"><div class="er es mq"><img src="../Images/1fbff7900769cbd6968f40a1460e5ea6.png" data-original-src="https://miro.medium.com/v2/resize:fit:868/format:webp/1*hthbQz3WY43yVL1IFp-QOg.png"/></div></figure><p id="3886" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">观察该图，可以说它们没有很好的相关性，如果它们相关，数据点将被很好地分类如下。</p><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mr"><img src="../Images/77a7eac5708cbc0311cc579b38089038.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BJ1JeUvbZUR2zMDAfE6ovA.png"/></div></div></figure><p id="d9ab" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">可以使用更多的图来确定特征是否可以通过标准化来很好地对数据进行分类。</p><ol class=""><li id="0df6" class="kr ks hi is b it iu ix iy jb kt jf ku jj kv jn ms kx ky kz bi translated">箱形图</li></ol><pre class="lb lc ld le fd mg mh mi mj aw mk bi"><span id="0d74" class="lo jp hi mh b fi ml mm l mn mo">data1 = data.drop(['state','timestamp'],axis =1)<br/>data_std = (data1 - data1.mean()) / data1.std()<br/>data1 = pd.melt(data1,id_vars ="status",var_name = "features",value_name="value")<br/>plt.figure(figsize=(5,5))<br/>sns.boxplot(x="features",y="value",hue="status",data = data1)<br/>plt.xticks(rotation=45);</span></pre><figure class="lb lc ld le fd ij er es paragraph-image"><div class="er es mt"><img src="../Images/503ad73b794f4a9928ed35e2d862d1f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:678/format:webp/1*Imne6Gf-WYZ9cHgFyduxpg.png"/></div></figure><p id="fec8" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">2)群体图</p><pre class="lb lc ld le fd mg mh mi mj aw mk bi"><span id="015e" class="lo jp hi mh b fi ml mm l mn mo">sns.set(style='whitegrid',palette='muted')<br/>data = train_data.drop(['Name','Ticket','Embarked','Sex','Cabin'],axis=1)<br/>data_std = (data - data.mean()) / data.std()<br/>data = data_std<br/>data = pd.melt(data,id_vars ="Survived",var_name = "features",value_name="value")<br/>plt.figure(figsize=(10,10))<br/>plt.figure(figsize=(10,10))<br/>sns.swarmplot(x="features",y="value",hue="Survived",data = data)<br/>plt.xticks(rotation=45);</span></pre><figure class="lb lc ld le fd ij er es paragraph-image"><div class="er es mu"><img src="../Images/11075ca1de1e4f2a2f5a4403aa66b6dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1230/format:webp/1*DTTcfkENV7DFrMNlqkUktg.png"/></div></figure><p id="0b25" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">3)小提琴情节</p><pre class="lb lc ld le fd mg mh mi mj aw mk bi"><span id="d540" class="lo jp hi mh b fi ml mm l mn mo">data = train_data.drop(['Name','Ticket','Embarked','Sex','Cabin'],axis=1)<br/>data_std = (data - data.mean()) / data.std()<br/>data = data_std<br/>data = pd.melt(data,id_vars ="Survived",var_name = "features",value_name="value")<br/>plt.figure(figsize=(10,10))<br/>sns.violinplot(x="features",y="value",hue="Survived",data = data)<br/>plt.xticks(rotation=60);</span></pre><figure class="lb lc ld le fd ij er es paragraph-image"><div class="er es mv"><img src="../Images/5ea08a64499739876d22ce5d87149c38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1216/format:webp/1*m9C1KsW435Vv8Z7hqfYRyw.png"/></div></figure></div></div>    
</body>
</html>