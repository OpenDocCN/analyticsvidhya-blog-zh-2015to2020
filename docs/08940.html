<html>
<head>
<title>K-Nearest Neighbor Algorithm with Amazon Food Reviews Analysis</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于亚马逊美食评论分析的 k-最近邻算法</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/k-nearest-neighbor-algorithm-with-amazon-food-reviews-analysis-14d83a4cadea?source=collection_archive---------13-----------------------#2020-08-19">https://medium.com/analytics-vidhya/k-nearest-neighbor-algorithm-with-amazon-food-reviews-analysis-14d83a4cadea?source=collection_archive---------13-----------------------#2020-08-19</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/13cbb5f87680b5d33baefe2af1d78927.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*86cg1NlS84yvagDVHhR4vQ.png"/></div></div></figure><p id="56dc" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">首先我们想知道什么是亚马逊美食点评分析？</strong></p><p id="724e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这个数据集由亚马逊的美食评论组成。这些数据跨越了 10 多年的时间，包括截至 2012 年 10 月的所有约 500，000 篇评论。评论包括产品和用户信息、评级和明文评论。我们也有来自所有其他亚马逊类别的评论。</p><p id="e46f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">亚马逊评论通常是最公开可见的消费品评论。作为一个经常使用亚马逊的用户，我对检查亚马逊评论的大型数据库的结构和可视化这些信息很感兴趣，以便成为一个更聪明的消费者和评论者。</p><p id="1f45" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">【https://www.kaggle.com/snap/amazon-fine-food-reviews】来源:<a class="ae jo" href="https://www.kaggle.com/snap/amazon-fine-food-reviews" rel="noopener ugc nofollow" target="_blank"><strong class="is hj"/></a></p><p id="d1f0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">亚马逊美食点评数据集由来自亚马逊的美食点评组成。</p><p id="9062" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">评论数:568，454 <br/>用户数:256，059 <br/>产品数:74，258 <br/>时间跨度:1999 年 10 月—2012 年 10 月<br/>数据中的属性/列数:10</p><p id="6e4d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">属性信息:</p><ol class=""><li id="49a6" class="jp jq hi is b it iu ix iy jb jr jf js jj jt jn ju jv jw jx bi translated">身份</li><li id="fc84" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated">产品 Id —产品的唯一标识符</li><li id="3cdf" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated">UserId —用户的唯一标识符</li><li id="bf11" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated">ProfileName</li><li id="71e8" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated">帮助度分子—认为评论有帮助的用户数量</li><li id="01c4" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated">帮助度分母——表示他们认为评论是否有帮助的用户数量</li><li id="6edc" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated">分数—介于 1 和 5 之间的等级</li><li id="8ae1" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated">时间—审核的时间戳</li><li id="ee02" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated">摘要—审核的简要摘要</li><li id="ef81" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated">文本—审阅的文本</li></ol><h1 id="4c81" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">目标</h1><p id="5464" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">给出一个评价，确定该评价是正面的(评分为 4 或 5)还是负面的(评分为 1 或 2)。</p><h1 id="d021" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">内容</h1><ol class=""><li id="9f24" class="jp jq hi is b it lb ix lc jb lg jf lh jj li jn ju jv jw jx bi translated">数据预处理</li></ol><p id="ba45" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">2.列车测试分离</p><p id="5bd2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">3.使用单词包特征的 K-NN 简单“蛮”模型</p><p id="1639" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">4.使用 TFIDF 特征的 K-NN 简单“野蛮”模型</p><p id="acca" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">5.使用 Word2Vec 特性的 K-NN 简单“野蛮”模型</p><p id="fcf9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">6.使用平均 Word2Vec 特征的 K-NN 简单“野蛮”模型</p><p id="3152" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">7.使用 TFIDF W2V 功能的 K-NN 简单“野蛮”模型</p><p id="f2f2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">8.使用单词包特征的 k-NN“Kd-tree”模型</p><p id="63cb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">9.结论</p><p id="0cab" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">10.观察</p><h2 id="fb1c" class="lj ke hi bd kf lk ll lm kj ln lo lp kn jb lq lr kr jf ls lt kv jj lu lv kz lw bi translated"><strong class="ak">数据预处理</strong></h2><p id="d43b" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">数据预处理是一种用于将原始数据转换成干净数据集的技术。换句话说，无论何时从不同来源收集数据，都是以原始格式收集的，这对于分析是不可行的。</p><figure class="ly lz ma mb fd ij er es paragraph-image"><div class="er es lx"><img src="../Images/d39b70f0e4ae9ff48ef569ffce8bff1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1398/format:webp/0*pruwDNw2SDg_12gT.png"/></div></figure><p id="f98b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">要了解亚马逊食品评论数据集和特征的完整概述，请访问我以前的博客链接<a class="ae jo" rel="noopener" href="/analytics-vidhya/amazon-fine-food-reviews-featurization-with-natural-language-processing-a386b0317f56"> <strong class="is hj">这里</strong> </a> <strong class="is hj">。</strong></p><p id="1653" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">让我们用 K-NN 建立一个模型如果你不知道 K-NN 是如何工作的，请访问我以前的博客链接<a class="ae jo" rel="noopener" href="/analytics-vidhya/k-nearest-neighbors-algorithm-7952234c69a4"> <strong class="is hj">这里</strong> </a> <strong class="is hj">。</strong></p><p id="d2df" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">将数据分配给从属特征 X，将目标分配给 y。</p><pre class="ly lz ma mb fd mc md me mf aw mg bi"><span id="6daf" class="lj ke hi md b fi mh mi l mj mk"> X=data['preprocessed_reviews'].values<br/> Y=data['Score'].values</span></pre><h2 id="e77e" class="lj ke hi bd kf lk ll lm kj ln lo lp kn jb lq lr kr jf ls lt kv jj lu lv kz lw bi translated">列车测试分离</h2><p id="fb28" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">当机器学习算法用于对不用于训练模型的数据进行预测时，训练-测试分离过程用于估计机器学习算法的性能。</p><p id="af89" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果你有<strong class="is hj">一个数据集</strong>，你需要首先使用 Sklearn <code class="du ml mm mn md b">train_test_split</code>函数分割它。</p><p id="0c13" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">训练测试分割是一种用于评估机器学习算法性能的技术。它可用于分类或回归问题，并可用于任何监督学习算法。</p><p id="8881" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">该过程包括获取一个数据集并将其分成两个子集。第一个子集用于拟合模型，称为训练数据集。第二子集不用于训练模型；相反，数据集的输入元素被提供给模型，然后进行预测并与期望值进行比较。第二个数据集被称为测试数据集。</p><pre class="ly lz ma mb fd mc md me mf aw mg bi"><span id="ee07" class="lj ke hi md b fi mh mi l mj mk"><em class="mo">#Train-Test split</em><br/><strong class="md hj">from</strong> <strong class="md hj">sklearn.model_selection</strong> <strong class="md hj">import</strong> train_test_split<br/>X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.3) <em class="mo">#random splitting</em><br/><br/>X_train,X_cv,Y_train,Y_cv=train_test_split(X_train,Y_train,test_size=0.3) <em class="mo">#random splitting</em><br/>   <br/>print(X_train.shape,Y_train.shape)<br/>print(X_test.shape,Y_test.shape)<br/>print(X_cv.shape,Y_cv.shape)</span></pre><h2 id="afcb" class="lj ke hi bd kf lk ll lm kj ln lo lp kn jb lq lr kr jf ls lt kv jj lu lv kz lw bi translated"><strong class="ak">使用单词包的文本特征化</strong></h2><pre class="ly lz ma mb fd mc md me mf aw mg bi"><span id="e2b8" class="lj ke hi md b fi mh mi l mj mk"><em class="mo">#featurization_using_Bow</em><br/><strong class="md hj">from sklearn.feature_extraction.text import</strong> <strong class="md hj">CountVectorizer</strong><br/>vect=CountVectorizer()<br/>vect.fit(X_train)<br/>X_train_bow=vect.fit_transform(X_train)<br/>X_test_bow=vect.transform(X_test)<br/>X_cv_bow=vect.transform(X_cv)</span></pre><h2 id="3769" class="lj ke hi bd kf lk ll lm kj ln lo lp kn jb lq lr kr jf ls lt kv jj lu lv kz lw bi translated">超参数调谐</h2><p id="27d2" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">我们希望选择最佳的 K 来获得更好的模型性能，通过使用交叉验证或网格搜索交叉验证来选择最佳的 K。</p><figure class="ly lz ma mb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mp"><img src="../Images/3b1ca8f0386226badaffd31587c96e2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bU9E7WYdSAhtvN8nIQAPFw.png"/></div></div></figure><figure class="ly lz ma mb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mq"><img src="../Images/7f6cca21c56ecaf599f837d5eb41fc27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-n5yZ6-6Wyc3Q0p5GG1_gQ.png"/></div></div></figure><p id="ae36" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">使用 K-NN 蛮力建立一个简单的模型，我们已经定义了一个 Grid_search 函数，当我们调用它时，它会给出结果。</p><pre class="ly lz ma mb fd mc md me mf aw mg bi"><span id="ae24" class="lj ke hi md b fi mh mi l mj mk">#Hyper parameter tuning<br/>best_k=Grid_search(X_train,Y_train,'brute')</span></pre><figure class="ly lz ma mb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mr"><img src="../Images/7b1af7d9fde62f8149a626b126ef8f26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GPVUgCcqwfz962_xuARUUg.png"/></div></div></figure><p id="0a6c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">从误差图中，我们选择 K，使得我们将在 cv 数据上具有最大 AUC，并且训练和 cv 之间的差距较小。基于我们使用的方法，我们可能得到不同的超参数值作为最佳值。</p><p id="6e01" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">所以，我们根据我们选择的方法来选择，如果我们有更多的计算能力，你使用网格搜索，注意这将花费更多的时间。如果我们增加网格搜索 cv 中的 CV 值，您将获得更稳健的结果。</p><h2 id="2e0e" class="lj ke hi bd kf lk ll lm kj ln lo lp kn jb lq lr kr jf ls lt kv jj lu lv kz lw bi translated">使用测试数据进行测试</h2><p id="0b2f" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">测试集是一组观察值，用于使用一些性能度量来评估模型的性能。重要的是，测试集中不包括来自训练集的观察值。如果测试集确实包含来自训练集的示例，则很难评估该算法是学会了从训练集进行归纳，还是简单地记住了它。</p><p id="b106" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在我们使用网格搜索 CV 找到最佳 k 之后，我们希望使用测试数据检查性能，在本案例研究中，我们使用 AUC 作为性能度量。</p><p id="0d2b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">定义测试数据的功能。</strong></p><figure class="ly lz ma mb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ms"><img src="../Images/06fdc9d42ba219a2fab0d1b6ab6a542b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1O32_INEmOIbXKb75zJr2A.png"/></div></div></figure><pre class="ly lz ma mb fd mc md me mf aw mg bi"><span id="2529" class="lj ke hi md b fi mh mi l mj mk">#Testing with test data<br/>test_data(X_train,Y_train,X_test,Y_test,'brute')</span></pre><figure class="ly lz ma mb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mt"><img src="../Images/f5aa7a9cc0514b3210b6bfad451c984e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ODhZwNOBxz_lq7M_r4BHtw.png"/></div></div></figure><h2 id="726d" class="lj ke hi bd kf lk ll lm kj ln lo lp kn jb lq lr kr jf ls lt kv jj lu lv kz lw bi translated">性能指标</h2><p id="77c0" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">绩效指标用于衡量企业的行为、活动和绩效。这应该是在一个范围内测量所需数据的数据形式，允许形成支持总体业务目标实现的基础。</p><p id="e54a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">要了解机器学习中使用的性能指标的详细信息，请访问我以前的博客链接<strong class="is hj"> </strong> <a class="ae jo" rel="noopener" href="/@sachin.s1dn/performance-metrics-for-machine-learning-models-80d7666b432e"> <strong class="is hj">这里</strong> </a> <strong class="is hj">。</strong></p><p id="5904" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">定义绩效指标的功能。</strong></p><figure class="ly lz ma mb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mu"><img src="../Images/f1d8f4b65d1fc089eb550c65821b626d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SnSQ3wBrYOMEOXmWUZukeA.png"/></div></div></figure><pre class="ly lz ma mb fd mc md me mf aw mg bi"><span id="adf2" class="lj ke hi md b fi mh mi l mj mk">#performance metric<br/>metric(X_train,Y_train,X_test,Y_test,'brute')</span></pre><figure class="ly lz ma mb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mv"><img src="../Images/6e3a8fc00a8f616e25717c24624bd3df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kCz7WsHFJxfGWfJxCA9Mpw.png"/></div></div></figure><h2 id="a9d5" class="lj ke hi bd kf lk ll lm kj ln lo lp kn jb lq lr kr jf ls lt kv jj lu lv kz lw bi translated">使用 TFIDF 特征的文本特征化</h2><figure class="ly lz ma mb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mw"><img src="../Images/8971df9ad46eb6fcfc613193da93e1f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*reMq2soGMdotmLCJPLXy0A.png"/></div></div></figure><pre class="ly lz ma mb fd mc md me mf aw mg bi"><span id="b71c" class="lj ke hi md b fi mh mi l mj mk"><em class="mo">#generating the tf-idf features</em><br/><strong class="md hj">from</strong> <strong class="md hj">sklearn.feature_extraction.text</strong> <strong class="md hj">import</strong> <strong class="md hj">TfidfVectorizer</strong><br/>vectorizer=TfidfVectorizer(ngram_range=(1, 2))<br/>X_train_tf_idf=vect.fit_transform(X_train)<br/>X_test_tf_idf=vect.transform(X_test)</span><span id="72e0" class="lj ke hi md b fi mx mi l mj mk">X_train=X_train_tf_idf<br/>X_test=X_test_tf_idf</span><span id="a572" class="lj ke hi md b fi mx mi l mj mk">#Hyper Parameter Tuning<br/>best_k=Grid_search(X_train,Y_train,'brute')</span></pre><figure class="ly lz ma mb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lx"><img src="../Images/301623288abfa5134dd30c52be9c77f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1398/format:webp/1*-omNyKIPTNLxIMb1pklgww.png"/></div></div></figure><pre class="ly lz ma mb fd mc md me mf aw mg bi"><span id="9bcf" class="lj ke hi md b fi mh mi l mj mk"><em class="mo">#computing the AUC on the test data</em><br/>test_data(X_train,Y_train,X_test,Y_test,'brute')</span></pre><figure class="ly lz ma mb fd ij er es paragraph-image"><div class="er es my"><img src="../Images/dba232aca8509af0fa765d39f1fb5fa6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1202/format:webp/1*WzaAc1JZ0tbJ0YF9Tu0fPA.png"/></div></figure><pre class="ly lz ma mb fd mc md me mf aw mg bi"><span id="b55e" class="lj ke hi md b fi mh mi l mj mk">#performance metric</span><span id="3aaa" class="lj ke hi md b fi mx mi l mj mk">metric(X_train_tf_idf,Y_train,X_test_tf_idf,Y_test,'brute')</span></pre><figure class="ly lz ma mb fd ij er es paragraph-image"><div class="er es my"><img src="../Images/310833ecbb5b762d2a5a011cdc7a20ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1202/format:webp/1*3xu6U0-eNgbWIliPTTJ0Lw.png"/></div></figure><h2 id="7e05" class="lj ke hi bd kf lk ll lm kj ln lo lp kn jb lq lr kr jf ls lt kv jj lu lv kz lw bi translated">使用 Word2Vec 特性的文本特征</h2><p id="e327" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">Word2vec 创建向量，这些向量是单词特征的分布式数字表示，如单个单词的上下文。</p><p id="cdca" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">它不需要人工干预。给定足够的数据、用法和上下文，Word2vec 可以根据过去的表现对单词的意思做出高度准确的猜测。</p><figure class="ly lz ma mb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mz"><img src="../Images/8dcbeb91008ed86bbd64fb10ccab89ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SC874XBGWmjWE19SpOnkiQ.png"/></div></div></figure><pre class="ly lz ma mb fd mc md me mf aw mg bi"><span id="c407" class="lj ke hi md b fi mh mi l mj mk"><em class="mo"># Train your own Word2Vec model using your own text corpus</em><br/>i=0<br/>train_list_of_sentance=[]<br/><strong class="md hj">for</strong> sentance <strong class="md hj">in</strong> X_train:<br/>    train_list_of_sentance.append(sentance.split())</span><span id="7232" class="lj ke hi md b fi mx mi l mj mk"><em class="mo"># Using Google News Word2Vectors</em><br/><strong class="md hj">from</strong> <strong class="md hj">gensim.models</strong> <strong class="md hj">import</strong> <strong class="md hj">Word2Vec</strong><br/><strong class="md hj">from</strong> <strong class="md hj">gensim.models</strong> <strong class="md hj">import</strong> <strong class="md hj">KeyedVectors</strong><br/><em class="mo"># min_count = 5 considers only words that occured atleast 5 times</em><br/>train_w2v_model=Word2Vec(train_list_of_sentance,min_count=5,size=50, workers=4)</span></pre><figure class="ly lz ma mb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mq"><img src="../Images/26175776dfa29c6905bce37dc152218e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PZ-2VRZ7cY3GoCMz410Dmg.png"/></div></div></figure><p id="6219" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> Word2Vec 为每次审查特征化列车数据</strong></p><figure class="ly lz ma mb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es na"><img src="../Images/157e811bec2b29209f9c8269e5da6dea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*D5I8ELRP2MOZqNSAHIKRXw.png"/></div></div></figure><pre class="ly lz ma mb fd mc md me mf aw mg bi"><span id="7b5f" class="lj ke hi md b fi mh mi l mj mk"><em class="mo"># Train your own Word2Vec model using your own text corpus for test data</em><br/>i=0<br/>test_list_of_sentance=[]<br/><strong class="md hj">for</strong> sentance <strong class="md hj">in</strong> X_test:<br/>    test_list_of_sentance.append(sentance.split())<br/>test_w2v_model=Word2Vec(test_list_of_sentance,min_count=5,size=50, workers=4)</span></pre><figure class="ly lz ma mb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mq"><img src="../Images/92f6be9298e89f7a7f708baf0fa3615e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_3PAc1XTawgwOzJqazuDzA.png"/></div></div></figure><p id="edc9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> Word2Vec 对每次审查的测试数据进行特征化</strong></p><figure class="ly lz ma mb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nb"><img src="../Images/899fee32e714618c585391fe35e23eb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_RZJwgGVRzOXCsXp7iNLQA.png"/></div></div></figure><pre class="ly lz ma mb fd mc md me mf aw mg bi"><span id="4b15" class="lj ke hi md b fi mh mi l mj mk">#Hyper parameter Tuning<br/>best_k=Grid_search(X_train,Y_train,'brute')</span></pre><figure class="ly lz ma mb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nc"><img src="../Images/13c671a2a3529843a6529414832cc63a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qUPTmYqLn-HMzVQlbg6kyQ.png"/></div></div></figure><pre class="ly lz ma mb fd mc md me mf aw mg bi"><span id="bf46" class="lj ke hi md b fi mh mi l mj mk"><em class="mo">#Testing with Test data</em><br/><em class="mo">#computing the AUC on the test data</em><br/>test_data(X_train,Y_train,X_test,Y_test,'brute')</span></pre><figure class="ly lz ma mb fd ij er es paragraph-image"><div class="er es lx"><img src="../Images/50f5ecee40f6ccdff2565af95c4578ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1398/format:webp/1*KZEj6FRr6AZIw0yDL7-9jw.png"/></div></figure><pre class="ly lz ma mb fd mc md me mf aw mg bi"><span id="d966" class="lj ke hi md b fi mh mi l mj mk"><em class="mo">#performance metric</em><br/>metric(X_train,Y_train,X_test,Y_test,'brute')</span></pre><figure class="ly lz ma mb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nd"><img src="../Images/a5267ae48551d4fcbfbfbacdf03c2409.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*06_5FF5HfyeRt2UPRUVNKw.png"/></div></div></figure><h2 id="3037" class="lj ke hi bd kf lk ll lm kj ln lo lp kn jb lq lr kr jf ls lt kv jj lu lv kz lw bi translated">使用平均 Word2Vec 特征的文本特征化</h2><figure class="ly lz ma mb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mu"><img src="../Images/651c0f50c582cde836d98b2fa7f39f50.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GQN_HvfstKJ8y_nK2nTTvw.png"/></div></div></figure><p id="0d78" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">每次审查列车数据的平均 Word2Vec 特征化</strong></p><figure class="ly lz ma mb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es na"><img src="../Images/cb1ba27b5e68b0f93c8b42b7847b1261.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*H9AGpEXJuRYgEqe2m3JGQQ.png"/></div></div></figure><p id="97c2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">每次审查测试数据的平均 Word2Vec 特征</strong></p><figure class="ly lz ma mb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ne"><img src="../Images/9dcc9742b6ec3613be0cab1dd4bb29be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lyT2Af9pyqTPWc5SHPcQnA.png"/></div></div></figure><pre class="ly lz ma mb fd mc md me mf aw mg bi"><span id="f024" class="lj ke hi md b fi mh mi l mj mk">#Hyper parameter tuning<br/>best_k=Grid_search(X_train,Y_train,'brute')</span></pre><figure class="ly lz ma mb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nf"><img src="../Images/2789b7d1152ad43fb9b877a4bcb9dd97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1P1NdtWGQriJ600NRD1bSA.png"/></div></div></figure><pre class="ly lz ma mb fd mc md me mf aw mg bi"><span id="0cc5" class="lj ke hi md b fi mh mi l mj mk"><em class="mo">#Testing with Test data</em><br/><em class="mo">#computing the AUC on the test data</em><br/>test_data(X_train,Y_train,X_test,Y_test,'brute')</span></pre><figure class="ly lz ma mb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ng"><img src="../Images/338d467df7e6d0ea6ff362465f30d760.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*66ymbarEFj1gc1QBhmNxFg.png"/></div></div></figure><pre class="ly lz ma mb fd mc md me mf aw mg bi"><span id="6cbf" class="lj ke hi md b fi mh mi l mj mk"><em class="mo">#performance metric</em><br/>metric(X_train,Y_train,X_test,Y_test,'brute')</span></pre><figure class="ly lz ma mb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nh"><img src="../Images/44706ee3c2b9d5f103a6dc58e1e6dd4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N8xsl5QcojSj1AQYQ36Qzw.png"/></div></div></figure><h2 id="3c5e" class="lj ke hi bd kf lk ll lm kj ln lo lp kn jb lq lr kr jf ls lt kv jj lu lv kz lw bi translated">使用 TFIDF W2V 功能的文本特征</h2><figure class="ly lz ma mb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mz"><img src="../Images/8dcbeb91008ed86bbd64fb10ccab89ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SC874XBGWmjWE19SpOnkiQ.png"/></div></div></figure><figure class="ly lz ma mb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ni"><img src="../Images/8e276f18f8b33ffa518bcb7ea5d3b897.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TGJxelifwiCj4Goaks3WZQ.png"/></div></div></figure><pre class="ly lz ma mb fd mc md me mf aw mg bi"><span id="0744" class="lj ke hi md b fi mh mi l mj mk"><em class="mo">#define tf_idf vectorizer</em><br/><strong class="md hj">from</strong> <strong class="md hj">sklearn.feature_extraction.text</strong> <strong class="md hj">import</strong> <strong class="md hj">TfidfVectorizer</strong><br/>tfidf_vect = TfidfVectorizer(ngram_range=(1, 1))<br/>train_tfidf_w2v = tfidf_vect.fit(X_train)<br/>test_tfidf_w2v = tfidf_vect.transform(X_test)</span></pre><figure class="ly lz ma mb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mq"><img src="../Images/0ebc21fb77a7f91aff56e894845d7098.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eADIGJ8TLwRz6UNdTR9UgA.png"/></div></div></figure><figure class="ly lz ma mb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es na"><img src="../Images/cb77b5f2fe75804333d33964bbf1d971.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mLeW7rR_C7mhBdH6PANTlw.png"/></div></div></figure><pre class="ly lz ma mb fd mc md me mf aw mg bi"><span id="826b" class="lj ke hi md b fi mh mi l mj mk">#Hyper parameter tuning<br/>best_k=Grid_search(X_train,Y_train,'brute')</span></pre><figure class="ly lz ma mb fd ij er es paragraph-image"><div class="er es nj"><img src="../Images/d0e6fd365953c38d741f69a9efb01668.png" data-original-src="https://miro.medium.com/v2/resize:fit:1162/format:webp/1*m12R9J1Gl7-IYHw3VoEUkw.png"/></div></figure><pre class="ly lz ma mb fd mc md me mf aw mg bi"><span id="c4de" class="lj ke hi md b fi mh mi l mj mk"><em class="mo"># Testing with Test data</em><br/><em class="mo">#computing the AUC on the test data</em><br/>test_data(X_train,Y_train,X_test,Y_test,'brute')</span></pre><figure class="ly lz ma mb fd ij er es paragraph-image"><div class="er es nk"><img src="../Images/f872bba3596ab9d42f9457bb766e3b9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1192/format:webp/1*7EXlBkySj7oOGpGHTlKSkQ.png"/></div></figure><pre class="ly lz ma mb fd mc md me mf aw mg bi"><span id="2ff7" class="lj ke hi md b fi mh mi l mj mk"><em class="mo">#performance metric</em><br/>metric(X_train,Y_train,X_test,Y_test,'brute')</span></pre><figure class="ly lz ma mb fd ij er es paragraph-image"><div class="er es nl"><img src="../Images/adf3b84d3fda3648b3628e02e14e69c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1286/format:webp/1*_Lkbnw-Aga9Zd-HJbtVYQw.png"/></div></figure><p id="bf7e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">至此，我们使用一些流行的文本特征化技术构建了一个 K-NN 简单“暴力”模型。</p><p id="68c7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">要用“Kd-tree”建立 K-NN 模型，在函数中，我们只需将算法从“brute”改为“Kd-tree ”,它就会给出结果。</p><p id="41b5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">当我们使用 Kd-tree 算法时，它需要大量的时间来运行，所以要有耐心，如果你有内存错误，只考虑较少的特征和数据点。</p><h1 id="e0d9" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">基于 Bow 特征的 K-NN kd 树</h1><pre class="ly lz ma mb fd mc md me mf aw mg bi"><span id="5ec4" class="lj ke hi md b fi mh mi l mj mk"><em class="mo">#K-D tree takes lots of time so I used 10 K data points only</em><br/><em class="mo">#use preprocessed_reviews and score for building a model </em><br/>X=data['preprocessed_reviews'][:10000].values<br/>Y=data['Score'][:10000].values</span></pre><figure class="ly lz ma mb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mz"><img src="../Images/8dcbeb91008ed86bbd64fb10ccab89ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SC874XBGWmjWE19SpOnkiQ.png"/></div></div></figure><p id="36fd" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们只考虑了 500 个特征，以避免下图所示的内存错误。</p><figure class="ly lz ma mb fd ij er es paragraph-image"><div class="er es nm"><img src="../Images/90fd982fae42058e335c0a14f1b5c022.png" data-original-src="https://miro.medium.com/v2/resize:fit:1176/format:webp/1*2hWtagFwenCYkAylzsvFWw.png"/></div></figure><p id="d594" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Kd-tree 只接受信任点，所以我们想把稀疏矩阵转换成信任矩阵。</p><pre class="ly lz ma mb fd mc md me mf aw mg bi"><span id="c2fc" class="lj ke hi md b fi mh mi l mj mk">X_train=X_train_bow.todense()<br/>X_test=X_test_bow.todense()</span></pre><p id="5969" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们刚刚将函数中的“brute”算法改为“Kd-tree ”,以构建一个包含 Kd-tree 的 K-NN，如下所示。</p><pre class="ly lz ma mb fd mc md me mf aw mg bi"><span id="e96d" class="lj ke hi md b fi mh mi l mj mk">#Hyper parameter tuning<br/>best_k=Grid_search(X_train,Y_train,'kd_tree')</span></pre><figure class="ly lz ma mb fd ij er es paragraph-image"><div class="er es nn"><img src="../Images/7758d5ce39775b360bb0722001082471.png" data-original-src="https://miro.medium.com/v2/resize:fit:1234/format:webp/1*UCkeUMhogKx56qf1eqYipg.png"/></div></figure><pre class="ly lz ma mb fd mc md me mf aw mg bi"><span id="c813" class="lj ke hi md b fi mh mi l mj mk"><em class="mo"># Testing with Test data</em><br/><em class="mo">#computing the AUC on the test data</em><br/>test_data(X_train,Y_train,X_test,Y_test,'kd_tree')</span></pre><figure class="ly lz ma mb fd ij er es paragraph-image"><div class="er es no"><img src="../Images/f1c6a7840e18dd93d8b3399e965140b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1140/format:webp/1*OQ_IUXKVdMIQ2ZDbs8gbfg.png"/></div></figure><pre class="ly lz ma mb fd mc md me mf aw mg bi"><span id="244e" class="lj ke hi md b fi mh mi l mj mk"><em class="mo">#performance metric</em><br/>metric(X_train,Y_train,X_test,Y_test,'kd_tree')</span></pre><figure class="ly lz ma mb fd ij er es paragraph-image"><div class="er es np"><img src="../Images/3331c5eac17a9f853d05638a7b0f25e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*sChkvvp5MwxP2fBjoWYpiw.png"/></div></figure><p id="51c4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">类似地，我们为 TFIDF、Word2Vec、Average word2Vec 和 TFIDF W2V 构建了具有 Kd 树的 K-NN 模型。</p><p id="f37e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">要了解完整代码请访问我的<a class="ae jo" href="https://github.com/Sachin-D-N/Amazon_Food_Reviews/blob/main/02.KNN_Amazon_Food_Reviews/KNN_Amazon_Food_Reviews_Assignment.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="is hj"> GitHub </strong> </a>链接。</p><h1 id="e905" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">结论</h1><p id="12a9" class="pw-post-body-paragraph iq ir hi is b it lb iv iw ix lc iz ja jb ld jd je jf le jh ji jj lf jl jm jn hb bi translated">为了在表格中写入震荡，我们使用了 python 库 PrettyTable。</p><p id="3091" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">pretty table 是一个简单的 Python 库，旨在使在视觉上吸引人的表格中表示表格数据变得快速而简单。</p><pre class="ly lz ma mb fd mc md me mf aw mg bi"><span id="d570" class="lj ke hi md b fi mh mi l mj mk"><strong class="md hj">from</strong> <strong class="md hj">prettytable</strong> <strong class="md hj">import</strong> PrettyTable<br/>    <br/>table = PrettyTable()<br/>table.field_names = ["Vectorizer", "Model", "Hyper Parameter", "AUC"]<br/>table.add_row(["Bow", 'Brute_Forse', 49,80.18 ])<br/>table.add_row(["TFIDF", 'Brute_Forse', 49, 81.34])<br/>table.add_row(["Word2vec", 'Brute_Forse',49 ,84.61 ])<br/>table.add_row(["Avg_Word2vec", 'Brute_Forse', 7, 50.27,])<br/>table.add_row(["TFIDF_Word2vec", 'Brute_Forse',45 ,49.75 ])<br/>table.add_row(["Bow", 'kd_Tree', 49,79.15 ])<br/>table.add_row(["TFIDF", 'kd_Tree', 47,79.84 ])<br/>table.add_row(["Word2vec", 'kd_Tree', 47,50.71 ])<br/>table.add_row(["Avg_Word2vec", 'kd_Tree',27 ,50.12 ])<br/>table.add_row(["TFIDF_Word2vec", 'kd_Tree', 3,49.76 ])<br/>print(table)</span></pre><figure class="ly lz ma mb fd ij er es paragraph-image"><div class="er es nq"><img src="../Images/39fc1eb2bc783111a9e4a4543ce5bc4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1138/format:webp/1*6o-q6t2nK0AiqvwTVWNrWA.png"/></div></figure><h1 id="84b3" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">观察</h1><ol class=""><li id="a892" class="jp jq hi is b it lb ix lc jb lg jf lh jj li jn ju jv jw jx bi translated">从上表中，我们可以得出结论，对于所有的文本特征，通过超参数调整的 best_K 是 49。</li><li id="99fb" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated">从上表中，我们观察到 Word2vec 的 K-NN 简单强力模型在测试数据上具有 84.61%的最高 AUC 分数。</li><li id="467b" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated">TF-IDF 和单词包特征的 K-NN 简单粗暴模型在具有 81.34%和 80.18%的 AUC 分数的测试数据上也工作得相当好。</li><li id="8df5" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated">Avg_Word2Vec 和 TFIDF_Word2vec 在测试数据上的 AUC 得分较低。</li></ol><p id="6798" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">要了解亚马逊美食评论数据集和特征的完整概述，请访问我以前的博客链接<a class="ae jo" rel="noopener" href="/analytics-vidhya/amazon-fine-food-reviews-featurization-with-natural-language-processing-a386b0317f56"> <strong class="is hj">这里</strong> </a> <strong class="is hj">。</strong></p><p id="378e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">想知道 K-NN 是如何工作的，访问我之前的博客链接<a class="ae jo" rel="noopener" href="/analytics-vidhya/k-nearest-neighbors-algorithm-7952234c69a4"> <strong class="is hj">这里</strong> </a> <strong class="is hj">。</strong></p><p id="c7a1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">要了解机器学习中使用的性能指标的详细信息，请访问我以前的博客链接<strong class="is hj"> </strong> <a class="ae jo" rel="noopener" href="/@sachin.s1dn/performance-metrics-for-machine-learning-models-80d7666b432e"> <strong class="is hj">这里</strong> </a> <strong class="is hj">。</strong></p><p id="e74e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">欲了解完整代码，请访问我的<a class="ae jo" href="https://github.com/Sachin-D-N/Amazon_Food_Reviews/blob/main/02.KNN_Amazon_Food_Reviews/KNN_Amazon_Food_Reviews_Assignment.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="is hj"> GitHub </strong> </a>链接。</p><h1 id="52a8" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">参考</h1><ul class=""><li id="4adb" class="jp jq hi is b it lb ix lc jb lg jf lh jj li jn nr jv jw jx bi translated">应用人工智能</li><li id="0e8d" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn nr jv jw jx bi translated">Coursera</li><li id="fc3f" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn nr jv jw jx bi translated">数据营</li></ul><p id="e3f0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">感谢您的阅读和耐心。我希望你喜欢这个帖子，如果我的帖子有错误，请告诉我。如果你发现帖子中有什么错误或者有什么要补充的，就在评论中讨论吧…</p><p id="c325" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">快乐学习！！</p></div></div>    
</body>
</html>