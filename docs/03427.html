<html>
<head>
<title>Auto Encoders: De-Noising Text Documents</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">自动编码器:文本文档去噪</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/auto-encoders-de-noising-text-documents-c58d6950dfad?source=collection_archive---------4-----------------------#2020-01-31">https://medium.com/analytics-vidhya/auto-encoders-de-noising-text-documents-c58d6950dfad?source=collection_archive---------4-----------------------#2020-01-31</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/dddf2583371ec56f1e4654e827ab8b33.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*XeWl7ip-VXp4QXov.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">图:-自动编码器结构(图- <a class="ae iu" href="https://www.researchgate.net/profile/Xifeng_Guo/publication/320658590/figure/fig1/AS:614154637418504@1523437284408/The-structure-of-proposed-Convolutional-AutoEncoders-CAE-for-MNIST-In-the-middle-there.png" rel="noopener ugc nofollow" target="_blank">此处为</a>)</figcaption></figure><p id="7dac" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">什么是自动编码器？</strong></p><p id="d856" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">自动编码器是一种无监督的学习方法。自动编码器背后的思想是压缩潜在空间中的数据，然后再次解压缩潜在空间中的数据以重新创建输入。</p><p id="8c89" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">什么是编码器？</strong></p><p id="0754" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">编码器是神经网络的一部分，它压缩潜在空间表示中的输入。</p><p id="4370" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">什么是解码器？</strong></p><p id="21d6" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">解码器对于从潜在空间表示中重建输入是有用的。</p><figure class="ju jv jw jx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es jt"><img src="../Images/9253a57c69441f192b23524e05aef6e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0uTpozegFTpY0VDNAFgZEg.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">图2-编码器和解码器</figcaption></figure><p id="1bab" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">自动编码器对于PCA这样的降维也很有用。如果自动编码器像PCA一样工作，那么我们为什么需要自动编码器？自动编码器对于学习最无声的特征非常有用。在潜在空间中，表示包含的维度比输入少得多，这就是自动编码器学习有用信息的原因</p><p id="fe88" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">自动编码器的应用:- </strong></p><ol class=""><li id="7594" class="jy jz hi ix b iy iz jc jd jg ka jk kb jo kc js kd ke kf kg bi translated">图像去噪</li><li id="15b4" class="jy jz hi ix b iy kh jc ki jg kj jk kk jo kl js kd ke kf kg bi translated">降维</li><li id="0638" class="jy jz hi ix b iy kh jc ki jg kj jk kk jo kl js kd ke kf kg bi translated">特征变化</li><li id="0e7c" class="jy jz hi ix b iy kh jc ki jg kj jk kk jo kl js kd ke kf kg bi translated">图像着色</li><li id="882f" class="jy jz hi ix b iy kh jc ki jg kj jk kk jo kl js kd ke kf kg bi translated">水印去除</li></ol><h1 id="8e3f" class="km kn hi bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">文本去噪的自动编码器:-</h1><p id="c8cd" class="pw-post-body-paragraph iv iw hi ix b iy lk ja jb jc ll je jf jg lm ji jj jk ln jm jn jo lo jq jr js hb bi translated">在这里，我们实现了自动编码器，用于文本文档去噪。文本文档如下:-</p><figure class="ju jv jw jx fd ij er es paragraph-image"><div class="er es lp"><img src="../Images/6ef124317733b8f09fb6f176886b9f38.png" data-original-src="https://miro.medium.com/v2/resize:fit:750/format:webp/1*qVkBF75k69fUFel50twjRA.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">Fig-嘈杂的文本文档</figcaption></figure><p id="70fc" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">该数据集用于此处的<a class="ae iu" href="https://www.kaggle.com/c/denoising-dirty-documents" rel="noopener ugc nofollow" target="_blank">和</a>。数据集包括脏文档，我们必须从图像中移除脏的部分并清理整个图像。所以在这里，我们使用自动编码器技术去噪的文件</p><h1 id="d514" class="km kn hi bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated"><strong class="ak">自动编码器去噪型号代码:- </strong></h1><figure class="ju jv jw jx fd ij"><div class="bz dy l di"><div class="lq lr l"/></div></figure><p id="8f81" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">模型结构:- </strong></p><figure class="ju jv jw jx fd ij er es paragraph-image"><div class="er es ls"><img src="../Images/6403fc1976d6928fbedfa61abe63b056.png" data-original-src="https://miro.medium.com/v2/resize:fit:1186/format:webp/1*he54FYTH2krfI4nnVUPWqA.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">图=模型结构</figcaption></figure><p id="da30" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">从上图可以看出输入层和最后一层的形状是一样的。这里，中间层用于降维，并压缩潜在空间中的所有数据，然后我们再次对数据进行上采样/解压缩，以重建图像</p><p id="6a06" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">张量板输出:- </strong></p><p id="741d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这里我们运行我们的模型30个时期。</p><figure class="ju jv jw jx fd ij er es paragraph-image"><div class="er es lt"><img src="../Images/d5505efad0cda4552a74bfd68a3add39.png" data-original-src="https://miro.medium.com/v2/resize:fit:978/format:webp/1*3WQ2tjMlnd4KZTuxvqlQZg.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">图-纪元丢失(蓝线=验证，橙线=训练数据</figcaption></figure><p id="fa0b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">评估和预测:- </strong></p><figure class="ju jv jw jx fd ij"><div class="bz dy l di"><div class="lq lr l"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">图1-评估和预测</figcaption></figure><p id="466e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">预测值:- </strong></p><div class="ju jv jw jx fd ab cb"><figure class="lu ij lv lw lx ly lz paragraph-image"><img src="../Images/6ef124317733b8f09fb6f176886b9f38.png" data-original-src="https://miro.medium.com/v2/resize:fit:750/format:webp/1*qVkBF75k69fUFel50twjRA.png"/></figure><figure class="lu ij lv lw lx ly lz paragraph-image"><img src="../Images/1412102dd80b29d82399bf9079d4459d.png" data-original-src="https://miro.medium.com/v2/resize:fit:750/format:webp/1*3pKFuwQl5wWBVGnvN7yygQ.png"/><figcaption class="iq ir et er es is it bd b be z dx ma di mb mc translated">图=实际值和预测值</figcaption></figure></div></div><div class="ab cl md me gp mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="hb hc hd he hf"><p id="0a28" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> <em class="mk">参考文献:- </em> </strong></p><div class="ml mm ez fb mn mo"><a href="https://blog.keras.io/building-autoencoders-in-keras.html" rel="noopener  ugc nofollow" target="_blank"><div class="mp ab dw"><div class="mq ab mr cl cj ms"><h2 class="bd hj fi z dy mt ea eb mu ed ef hh bi translated">在Keras中构建自动编码器</h2><div class="mv l"><h3 class="bd b fi z dy mt ea eb mu ed ef dx translated">在本教程中，我们将回答一些关于自动编码器的常见问题，我们将涵盖代码的例子…</h3></div><div class="mw l"><p class="bd b fp z dy mt ea eb mu ed ef dx translated">blog.keras.io</p></div></div><div class="mx l"><div class="my l mz na nb mx nc io mo"/></div></div></a></div><div class="ml mm ez fb mn mo"><a href="https://www.kaggle.com/c/denoising-dirty-documents" rel="noopener  ugc nofollow" target="_blank"><div class="mp ab dw"><div class="mq ab mr cl cj ms"><h2 class="bd hj fi z dy mt ea eb mu ed ef hh bi translated">去噪脏文档</h2><div class="mv l"><h3 class="bd b fi z dy mt ea eb mu ed ef dx translated">消除打印文本中的噪点</h3></div><div class="mw l"><p class="bd b fp z dy mt ea eb mu ed ef dx translated">www.kaggle.com</p></div></div></div></a></div></div></div>    
</body>
</html>