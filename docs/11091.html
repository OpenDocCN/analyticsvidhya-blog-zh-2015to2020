<html>
<head>
<title>Face Mask Detection</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">面罩检测</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/face-mask-detection-6dca534f7879?source=collection_archive---------8-----------------------#2020-11-17">https://medium.com/analytics-vidhya/face-mask-detection-6dca534f7879?source=collection_archive---------8-----------------------#2020-11-17</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="5cd7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">人脸面具检测是一个基于人工智能的项目。在这种情况下，我们检测戴面具或不戴面具的人。</p><p id="4d8f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这个项目的制作过程中，我们分两个阶段。</p><ul class=""><li id="213a" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated">使用卷积或任何检测图像中人脸遮罩的预训练模型来训练模型。</li><li id="5fab" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">然后，检测视频或图像中的人脸，并从我们训练的模型中获得预测。</li></ul><p id="fea2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这个项目中，我使用迁移学习来训练数据集上的模型，其中我使用了预训练的模型 MobileNetV2，现在的问题是 MobileNetv2 是什么？它的结构是什么？</p><h1 id="0d67" class="jr js hi bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">MobileNetV2</h1><p id="b47d" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated">MobileNets 是小型、低延迟、低功耗的模型，其参数化可以满足各种用例的资源限制。与其他流行的大规模模型类似，MobileNetv2 可用于分类、检测、嵌入和分割，是对 MobileNetV1 的重大改进。MobileNetV1 和 V2 的结构如下。</p><figure class="kv kw kx ky fd kz er es paragraph-image"><div class="er es ku"><img src="../Images/b9fc18e547144e39dcb9f3f25eac345c.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/format:webp/1*pnUlLdaySJgkPmqAwuPWyQ.png"/></div><figcaption class="lc ld et er es le lf bd b be z dx translated">移动网络</figcaption></figure><p id="0e5f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，来看代码和数据解释</p><h1 id="78ae" class="jr js hi bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">资料组</h1><p id="b424" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated">在数据集中，我们有两种类型的图像，一种是戴面具的，另一种是没有面具的。</p><p id="a600" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">训练数据集由 4296 个图像组成，其中 2455 个图像具有带遮罩的标签，1841 个图像没有遮罩面部，验证数据集由 300 个组成。</p><figure class="kv kw kx ky fd kz er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es lg"><img src="../Images/5a3c718e54fac81a90ef13ad35e919bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*l4sp1I2yRPtYfQr-5l5NWw.png"/></div></div></figure><h1 id="2eb9" class="jr js hi bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">导入:</h1><p id="3d4b" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated">首先，我导入所需的模块，如 tensorflow、keras、optimizer、层和预训练模型(MobileNetV2)</p><figure class="kv kw kx ky fd kz"><div class="bz dy l di"><div class="ll lm l"/></div></figure><h1 id="e76f" class="jr js hi bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">加载数据和增强图像:</h1><p id="f500" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated">现在，我使用 MobileNetv2“preprocess _ input”加载所有用于训练和预处理的图像，通过它，图像可以按照 MobileNetv2 的要求准备好。</p><p id="c14a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们也扩大我们的图像，通过它我们可以获得更多的数据和数据的多样性。我们增加了放大技术，如缩放、水平和垂直翻转、旋转。</p><p id="ba7e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这一步之后，我们将训练和验证一批形状，mobilenetv2 需要这些形状作为输入。</p><figure class="kv kw kx ky fd kz"><div class="bz dy l di"><div class="ll lm l"/></div></figure><h1 id="186e" class="jr js hi bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">加载预训练模型:</h1><p id="376f" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated">正如我以前写的，我使用 MobileNetV2。因此，我下载了模型的权重，并在冻结了预训练模型的层之后创建了一个 MobileNetV2 类型的对象，通过该对象，当我们的模型在训练时，层权重不能被修改。</p><figure class="kv kw kx ky fd kz"><div class="bz dy l di"><div class="ll lm l"/></div></figure><h1 id="6ee0" class="jr js hi bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">向模型添加更多的层:</h1><p id="0bae" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated">在模型的末端添加一些层，以获得良好的精度或避免模型过度拟合。</p><p id="9dc6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后添加一个完全连接的层，它包含的神经元数量等于我们拥有的标签数量(在这种情况下，我们有 2 个标签屏蔽或没有屏蔽)。并在定义模型输入和输出层后。</p><figure class="kv kw kx ky fd kz"><div class="bz dy l di"><div class="ll lm l"/></div></figure><p id="5c4e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在我们的模型结构已经准备好了。</p><figure class="kv kw kx ky fd kz er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es ln"><img src="../Images/2d34e3ed1843435b4d9f75e34d77847f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5kimt4VzIzARz4_OK_O07A.png"/></div></div></figure><h1 id="0460" class="jr js hi bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">编译和培训:</h1><p id="a14e" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated">现在是训练模型的时候了，但在训练之前，我们必须定义损失函数和优化器，即编译模型。</p><p id="28ba" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在参数超调之后，我发现学习率为 0.00001 的结果很好。所以，我用了学习率为 0.00001，损失函数为 binary_crossentropy 的 Adam 优化器。然后，在我用 15 个时期训练模型并在验证数据(包含 300 张图像)上验证它之后。</p><figure class="kv kw kx ky fd kz"><div class="bz dy l di"><div class="ll lm l"/></div></figure><figure class="kv kw kx ky fd kz er es paragraph-image"><div class="er es lo"><img src="../Images/314b497cde6b4dde52cdf021624620a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1136/format:webp/1*84gRKbnpc0Rk9JiMcHTmZQ.png"/></div></figure><h1 id="d587" class="jr js hi bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">测试阶段:</h1><p id="3754" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated">现在，我们必须在测试数据上测试模型，通过测试数据，我们可以很好地了解模型是否适用于实时数据。因此，我们有 2 类 74 幅图像作为测试数据集，在测试数据集上进行评估后，我得到了很好的结果。</p><p id="d555" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">损耗:0.058</p><figure class="kv kw kx ky fd kz"><div class="bz dy l di"><div class="ll lm l"/></div></figure><figure class="kv kw kx ky fd kz er es paragraph-image"><div class="er es lp"><img src="../Images/58ee3ce9d8bd46dca96440b238d40cf4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1130/format:webp/1*wg54xFs6oAdiIQ_rTxj85g.png"/></div></figure><h1 id="9b72" class="jr js hi bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">混淆矩阵:</h1><p id="dc5c" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated">混淆矩阵是一个表格，通常用于描述一个分类模型对一组真实值已知的测试数据的性能。</p><p id="4973" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在绘制混淆矩阵后，我看到我的训练模型只预测了一个图像错误，其他所有图像都预测正确。因此，模型将实时工作良好。</p><figure class="kv kw kx ky fd kz"><div class="bz dy l di"><div class="ll lm l"/></div></figure><figure class="kv kw kx ky fd kz er es paragraph-image"><div class="er es lq"><img src="../Images/cc5466a4607e8e920b6651a22f4aa8f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:678/format:webp/1*SkrAAOTsCqyatxkMEVyVHw.png"/></div></figure><p id="f224" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因为我得到了很好的结果，所以现在是时候实现它与相机实时工作。所以，首先我们要保存训练好的模型。</p><figure class="kv kw kx ky fd kz"><div class="bz dy l di"><div class="ll lm l"/></div></figure><p id="3334" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在下一部分，我将讲述如何用 Opencv 实现它。</p></div><div class="ab cl lr ls gp lt" role="separator"><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw lx"/><span class="lu bw bk lv lw"/></div><div class="hb hc hd he hf"><p id="69d0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Github 回购链接:</p><div class="ly lz ez fb ma mb"><a href="https://github.com/chauhanarpit09/Face-Mask-Detection-" rel="noopener  ugc nofollow" target="_blank"><div class="mc ab dw"><div class="md ab me cl cj mf"><h2 class="bd hj fi z dy mg ea eb mh ed ef hh bi translated">chauhanarpit 09/面罩-检测-</h2><div class="mi l"><h3 class="bd b fi z dy mg ea eb mh ed ef dx translated">人脸面具检测是一个基于人工智能的项目。在这种情况下，我们检测戴面具或不戴面具的人。在…</h3></div><div class="mj l"><p class="bd b fp z dy mg ea eb mh ed ef dx translated">github.com</p></div></div><div class="mk l"><div class="ml l mm mn mo mk mp la mb"/></div></div></a></div></div></div>    
</body>
</html>