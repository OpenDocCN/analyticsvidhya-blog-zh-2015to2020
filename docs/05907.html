<html>
<head>
<title>Dog Breed Classifier â€” Power of Neural Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">çŠ¬ç§åˆ†ç±»å™¨â€”â€”ç¥ç»ç½‘ç»œçš„åŠ›é‡</h1>
<blockquote>åŸæ–‡ï¼š<a href="https://medium.com/analytics-vidhya/dog-breed-classifier-power-of-neural-networks-a277f4ad91be?source=collection_archive---------16-----------------------#2020-05-05">https://medium.com/analytics-vidhya/dog-breed-classifier-power-of-neural-networks-a277f4ad91be?source=collection_archive---------16-----------------------#2020-05-05</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="00c9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">ä¸ä»…æŠŠç‹—ï¼Œè€Œä¸”æŠŠäººçš„å½¢è±¡ä¹Ÿå½’ç±»ä¸ºç‹—çš„å“ç§ï¼Œè¿™æ˜¯å¤šä¹ˆæœ‰è¶£å•Šï¼</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/d515effc404b7752392c88f103e7d560.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GQVbkZK-AwzpwACOvAi5rQ.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">äººå·¥ç¥ç»ç½‘ç»œ<a class="ae jt" href="https://commons.wikimedia.org/wiki/File:Single-layer_feedforward_artificial_neural_network.png" rel="noopener ugc nofollow" target="_blank">æ¥æº</a></figcaption></figure><p id="4af8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi ju translated"><span class="l jv jw jx bm jy jz ka kb kc di">ä»¤äººéš¾ä»¥ç½®ä¿¡çš„æ˜¯ï¼Œä¸Šé¢æ˜¾ç¤ºçš„è¾¹å’ŒèŠ‚ç‚¹åˆ›é€ äº†ä¸€å¥—å¼ºå¤§çš„ç®—æ³•ï¼Œèƒ½å¤Ÿæ¼‚äº®åœ°è¯†åˆ«æ¨¡å¼ã€‚è¿™äº›éƒ½æ˜¯åœ¨äººè„‘çš„åŸºç¡€ä¸Šå»ºç«‹çš„ï¼Œäººè„‘å¯ä»¥é€šè¿‡ä¸€ç§æœºå™¨æ„ŸçŸ¥åˆ†ç±»æ¥è§£é‡Šæ„Ÿå®˜æ•°æ®ã€‚å®ƒæ‹æ‘„å›¾åƒã€å£°éŸ³ã€æ–‡æœ¬ã€æ—¶é—´åºåˆ—ç­‰ã€‚æ‰€æœ‰çœŸå®ä¸–ç•Œçš„æ•°æ®ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºæ•°å­—å‘é‡ä»¥è¯†åˆ«æ¨¡å¼ã€‚</span></p><p id="3797" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å°†æ›´å¤šåœ°å…³æ³¨<strong class="ih hj">å·ç§¯ç¥ç»ç½‘ç»œ</strong> (ConvNetsæˆ–CNN)ï¼Œå®ƒæ˜¯<strong class="ih hj">æ·±åº¦ç¥ç»ç½‘ç»œ</strong>çš„ä¸€ä¸ªç±»åˆ«ï¼Œå·²è¢«è¯æ˜åœ¨åˆ†æè§†è§‰å›¾åƒå°¤å…¶æ˜¯å›¾åƒè¯†åˆ«å’Œåˆ†ç±»é¢†åŸŸéå¸¸æœ‰æ•ˆã€‚ä¸ºäº†è¿›ä¸€æ­¥ç†è§£è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬å°†é€šè¿‡ä¸€ä¸ªå·ç§¯ç¥ç»ç½‘ç»œæ¥å¤„ç†ç°å®ä¸–ç•Œä¸­ç”¨æˆ·æä¾›çš„å›¾åƒã€‚</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es kd"><img src="../Images/6e3a6c67ee2ace215fbeaaef7debfba1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kum6fk7tzPjW5Qm41nUGSg.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated"><a class="ae jt" href="https://unsplash.com/photos/yihlaRCCvd4" rel="noopener ugc nofollow" target="_blank">æ¥æº</a></figcaption></figure><p id="f36b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">ç»™å®šä¸€å¼ ç‹—çš„å›¾åƒï¼Œè¯¥ç®—æ³•å°†è¯†åˆ«æ½œåœ¨çš„ç‹—å“ç§ã€‚å¦‚æœæä¾›ä¸€ä¸ªäººçš„å½¢è±¡ï¼Œä»£ç å°†è¯†åˆ«ç›¸ä¼¼çš„ç‹—å“ç§ã€‚</p><p id="b6bb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">å¬èµ·æ¥å¾ˆæœ‰è¶£ä¸æ˜¯å—ï¼Ÿè®©æˆ‘ä»¬æ½œå…¥æ›´æ·±çš„åœ°æ–¹â€¦</p></div><div class="ab cl ke kf gp kg" role="separator"><span class="kh bw bk ki kj kk"/><span class="kh bw bk ki kj kk"/><span class="kh bw bk ki kj"/></div><div class="hb hc hd he hf"><p id="93af" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">è¿™æ˜¯ä¸€ä¸ªéå¸¸ç®€å•çš„7æ­¥æµç¨‹<strong class="ih hj"/>,ä¸åŒäºåœ¨å¹•åè¿è¡Œçš„å¤æ‚çš„ç¥ç»ç½‘ç»œæµç¨‹:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es kl"><img src="../Images/07acbc1d1bbb25a082fa4ef314a43166.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*7o4Ud_KtLZEOsumWTbURtA.gif"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">å·ç§¯ç¥ç»ç½‘ç»œ<a class="ae jt" href="https://commons.wikimedia.org/wiki/File:Convolutional_Neural_Network.gif" rel="noopener ugc nofollow" target="_blank">æ¥æº</a></figcaption></figure><p id="1205" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="km">ç¬¬ä¸€æ­¥:</em> </strong> <em class="km">å¯¼å…¥æ•°æ®é›†<br/> </em> <strong class="ih hj"> <em class="km">ç¬¬äºŒæ­¥</em> </strong> <em class="km">:æ£€æµ‹äººç±»<br/> </em> <strong class="ih hj"> <em class="km">ç¬¬ä¸‰æ­¥:</em> </strong> <em class="km">æ£€æµ‹ç‹—<br/> </em> <strong class="ih hj"> <em class="km">ç¬¬å››æ­¥:</em> </strong> <em class="km">åˆ›å»ºCNNå¯¹ç‹—çš„å“ç§è¿›è¡Œåˆ†ç±»<br/> </em> <strong class="ih hj"> <em class="km">ç¬¬äº”æ­¥:) <br/> </em> <strong class="ih hj"> <em class="km">ç¬¬å…­æ­¥:</em> </strong> <em class="km">å†™ä¸€ä¸ªç®—æ³•ç»‘å®šä¸Šé¢çš„æ­¥éª¤<br/> </em> <strong class="ih hj"> <em class="km">ç¬¬ä¸ƒæ­¥:</em> </strong> <em class="km">æµ‹è¯•ç®—æ³•</em></strong></p></div><div class="ab cl ke kf gp kg" role="separator"><span class="kh bw bk ki kj kk"/><span class="kh bw bk ki kj kk"/><span class="kh bw bk ki kj"/></div><div class="hb hc hd he hf"><h1 id="79b0" class="kn ko hi bd kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk bi translated"><strong class="ak">ç¬¬ä¸€æ­¥:</strong>å¯¼å…¥æ•°æ®é›†</h1><p id="8d02" class="pw-post-body-paragraph if ig hi ih b ii ll ik il im lm io ip iq ln is it iu lo iw ix iy lp ja jb jc hb bi translated">æˆ‘ä»¬ä»ä»<a class="ae jt" href="https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip" rel="noopener ugc nofollow" target="_blank"> Udacity </a>å¯¼å…¥æ‰€éœ€çš„åº“å’Œæ•°æ®é›†å¼€å§‹ã€‚æ•°æ®é›†æœ‰<strong class="ih hj">~ 8500å¼ ç‹—çš„å›¾ç‰‡ï¼Œæ¨ªè·¨133ä¸ªç‹—å“ç§</strong>ã€‚å¯¼å…¥åï¼Œæˆ‘ä»¬å°†æ•°æ®åˆ†ä¸ºè®­ç»ƒã€éªŒè¯å’Œæµ‹è¯•æ•°æ®é›†ï¼Œåˆ†å¸ƒåˆ†åˆ«ä¸º80%ã€10%å’Œ10%ï¼Œå¹¶å­˜å‚¨æ¯ä¸ªæ•°æ®é›†çš„ç‰¹æ€§å’Œç›®æ ‡ã€‚</p><pre class="je jf jg jh fd lq lr ls lt aw lu bi"><span id="737b" class="lv ko hi lr b fi lw lx l ly lz">from sklearn.datasets import load_files       <br/>from keras.utils import np_utils<br/>import numpy as np<br/>from glob import glob</span><span id="5588" class="lv ko hi lr b fi ma lx l ly lz"># define function to load train, test, and validation datasets<br/>def load_dataset(path):<br/>    data = load_files(path)<br/>    dog_files = np.array(data['filenames'])<br/>    dog_targets = np_utils.to_categorical(np.array(data['target']), 133)<br/>    return dog_files, dog_targets</span><span id="1d89" class="lv ko hi lr b fi ma lx l ly lz"># load train, test, and validation datasets<br/>train_files, train_targets = load_dataset('../../../data/dog_images/train')<br/>valid_files, valid_targets = load_dataset('../../../data/dog_images/valid')<br/>test_files, test_targets = load_dataset('../../../data/dog_images/test')</span><span id="576f" class="lv ko hi lr b fi ma lx l ly lz"># load list of dog names<br/>dog_names = [item[20:-1] for item in sorted(glob("../../../data/dog_images/train/*/"))]</span></pre><h1 id="12bf" class="kn ko hi bd kp kq mb ks kt ku mc kw kx ky md la lb lc me le lf lg mf li lj lk bi translated">ç¬¬äºŒæ­¥:æ¢æµ‹äººç±»</h1><p id="86ae" class="pw-post-body-paragraph if ig hi ih b ii ll ik il im lm io ip iq ln is it iu lo iw ix iy lp ja jb jc hb bi translated">åœ¨è¿™ä¸€æ­¥ï¼Œæˆ‘ä»¬å°†ç¼–å†™ä¸€ä¸ªå‡½æ•°æ¥æ£€æµ‹å›¾åƒæ˜¯å¦æœ‰äººè„¸ã€‚ä¸ºäº†èƒ½å¤Ÿè®¾è®¡è¿™ä¸ªå‡½æ•°ï¼Œæˆ‘ä»¬é¦–å…ˆä»<a class="ae jt" href="https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/lfw.zip" rel="noopener ugc nofollow" target="_blank"> Udacity </a>å¯¼å…¥ä¸€ä¸ªäººç±»å›¾åƒæ•°æ®é›†ã€‚</p><pre class="je jf jg jh fd lq lr ls lt aw lu bi"><span id="b6f1" class="lv ko hi lr b fi lw lx l ly lz">import random<br/>random.seed(8675309)</span><span id="ed3f" class="lv ko hi lr b fi ma lx l ly lz"># load filenames in shuffled human dataset<br/>human_files = np.array(glob("../../../data/lfw/*/*"))<br/>random.shuffle(human_files)</span><span id="5633" class="lv ko hi lr b fi ma lx l ly lz"># print statistics about the dataset<br/>print('There are %d total human images.' % len(human_files))</span></pre><p id="847f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">ç°åœ¨ï¼Œä¸ºäº†æ£€æµ‹äººè„¸ï¼Œæˆ‘ä»¬ä½¿ç”¨OpenCVçš„<a class="ae jt" href="https://docs.opencv.org/trunk/db/d28/tutorial_cascade_classifier.html" rel="noopener ugc nofollow" target="_blank"> HaaråŸºäºç‰¹å¾çš„çº§è”åˆ†ç±»å™¨</a>çš„å®ç°ã€‚OpenCVæä¾›äº†è®¸å¤šé¢„å…ˆè®­ç»ƒçš„äººè„¸æ£€æµ‹å™¨ï¼Œä½œä¸ºXMLæ–‡ä»¶å­˜å‚¨åœ¨<a class="ae jt" href="https://github.com/opencv/opencv/tree/master/data/haarcascades" rel="noopener ugc nofollow" target="_blank"> Github </a>ä¸Šï¼Œæˆ‘ä»¬ä¸‹è½½äº†å…¶ä¸­ä¸€ä¸ªæ£€æµ‹å™¨ã€‚æ­£å¦‚æˆ‘ä»¬åœ¨ä¸‹é¢çœ‹åˆ°çš„ï¼Œåœ¨æ£€æµ‹åˆ°äººè„¸ä¹‹å‰ï¼Œç®—æ³•è¿˜éœ€è¦ä¸€äº›é¢å¤–çš„å›¾åƒè½¬æ¢æ­¥éª¤ã€‚ä¸‹é¢çš„<code class="du mg mh mi lr b">face_detector</code>å‡½æ•°å°†å›¾åƒè·¯å¾„ä½œä¸ºå‚æ•°ï¼Œå¦‚æœæ£€æµ‹åˆ°äººè„¸ï¼Œåˆ™è¿”å›<code class="du mg mh mi lr b">True</code>ï¼Œå¦åˆ™è¿”å›<code class="du mg mh mi lr b">False</code>ã€‚</p><pre class="je jf jg jh fd lq lr ls lt aw lu bi"><span id="1312" class="lv ko hi lr b fi lw lx l ly lz">import cv2                <br/>import matplotlib.pyplot as plt                        <br/>%matplotlib inline</span><span id="e624" class="lv ko hi lr b fi ma lx l ly lz"># extract pre-trained face detector<br/>face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_alt.xml')</span><span id="e98b" class="lv ko hi lr b fi ma lx l ly lz"># returns "True" if face is detected in image stored at img_path<br/>def face_detector(img_path):<br/>    img = cv2.imread(img_path)<br/>    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)<br/>    faces = face_cascade.detectMultiScale(gray)<br/>    return len(faces) &gt; 0</span></pre><p id="b955" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ä»ä¹‹å‰ä¸‹è½½çš„äººå’Œç‹—çš„æ•°æ®ä¸­æŠ½å–100ä¸ªå›¾åƒæ ·æœ¬ï¼Œå¹¶é€šè¿‡å‡½æ•°è¿è¡Œå®ƒä»¬ã€‚æˆ‘ä»¬çš„æ¨¡å‹èƒ½å¤Ÿåœ¨<strong class="ih hj"> 100% </strong>çš„äººå›¾åƒå’Œ<strong class="ih hj"> 11% </strong>çš„ç‹—å›¾åƒä¸­æ£€æµ‹å‡ºäººè„¸ã€‚å¾ˆå¥½ï¼Œä½†è¿™è¶³å¤Ÿäº†å—ï¼Ÿ</p><h1 id="163b" class="kn ko hi bd kp kq mb ks kt ku mc kw kx ky md la lb lc me le lf lg mf li lj lk bi translated">ç¬¬ä¸‰æ­¥:æ¢æµ‹ç‹—</h1><p id="f9c3" class="pw-post-body-paragraph if ig hi ih b ii ll ik il im lm io ip iq ln is it iu lo iw ix iy lp ja jb jc hb bi translated">åœ¨è¿™ä¸€æ­¥ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªé¢„å…ˆè®­ç»ƒå¥½çš„<a class="ae jt" href="http://ethereon.github.io/netscope/#/gist/db945b393d40bfa26006" rel="noopener ugc nofollow" target="_blank"> ResNet-50 </a>æ¨¡å‹æ¥æ£€æµ‹å›¾åƒä¸­çš„ç‹—ã€‚æˆ‘ä»¬é¦–å…ˆä¸‹è½½ResNet-50æ¨¡å‹ä»¥åŠå·²ç»åœ¨<a class="ae jt" href="http://www.image-net.org/" rel="noopener ugc nofollow" target="_blank"> ImageNet </a>ä¸Šè®­ç»ƒè¿‡çš„æƒé‡ï¼Œè¿™æ˜¯ä¸€ä¸ªéå¸¸å¤§çš„æµè¡Œæ•°æ®é›†ï¼Œç”¨äºå›¾åƒåˆ†ç±»å’Œå…¶ä»–è§†è§‰ä»»åŠ¡ã€‚</p><pre class="je jf jg jh fd lq lr ls lt aw lu bi"><span id="7c7b" class="lv ko hi lr b fi lw lx l ly lz">from keras.applications.resnet50 import ResNet50</span><span id="b95b" class="lv ko hi lr b fi ma lx l ly lz"># define ResNet50 model<br/>ResNet50_model = ResNet50(weights='imagenet')</span></pre><p id="b407" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">è€ƒè™‘åˆ°çœŸå®ä¸–ç•Œçš„å›¾åƒå¯èƒ½æœ‰å¤šæ··ä¹±ï¼Œé€šå¸¸éœ€è¦åœ¨è¾“å…¥æ¨¡å‹ä¹‹å‰è¿›è¡Œä¸€äº›é¢„å¤„ç†ã€‚ä¸‹é¢çš„<code class="du mg mh mi lr b">path_to_tensor</code>å‡½æ•°é¦–å…ˆå°†æ‰€æœ‰å›¾åƒçš„å¤§å°è°ƒæ•´ä¸º224Ã—224åƒç´ çš„æ­£æ–¹å½¢<em class="km">(å…³é”®æ­¥éª¤ä¹‹ä¸€)</em>ã€‚æ¥ä¸‹æ¥ï¼Œå›¾åƒè¢«è½¬æ¢æˆ4Dæ•°ç»„<em class="km">(åˆå4Då¼ é‡)</em>ï¼Œå› ä¸ºKeras CNNåœ¨è¿™é‡Œä½¿ç”¨TensorFlowä½œä¸ºåç«¯ã€‚<em class="km">å¼ é‡æ˜¯çŸ©é˜µåˆ°Nç»´ç©ºé—´çš„æ¨å¹¿</em>ã€‚<em class="km">æ›´å¤šè¯¦æƒ…è¯·çœ‹è¿™ç¯‡ä¼Ÿå¤§çš„</em> <a class="ae jt" href="https://www.kdnuggets.com/2018/05/wtf-tensor.html" rel="noopener ugc nofollow" target="_blank"> <em class="km">å¸–å­</em> </a> <em class="km"> by </em> <a class="mj mk ge" href="https://medium.com/u/a0bc63d95eb0?source=post_page-----a277f4ad91be--------------------------------" rel="noopener" target="_blank"> <em class="km">é©¬ä¿®æ¢…å¥¥</em> </a> <em class="km">ã€‚</em></p><p id="2050" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">è¾“å…¥å½¢çŠ¶:<strong class="ih hj"> (nb_samplesï¼Œrowsï¼Œcolumnsï¼Œchannels) </strong>å…¶ä¸­ï¼Œ<br/> <code class="du mg mh mi lr b">nb_samples</code>ä¸ºå›¾åƒ(æˆ–æ ·æœ¬)æ€»æ•°ï¼Œ<br/> <code class="du mg mh mi lr b">rows</code>ï¼Œ<code class="du mg mh mi lr b">columns</code>ï¼Œ<code class="du mg mh mi lr b">channels</code>åˆ†åˆ«å¯¹åº”æ¯å¹…å›¾åƒçš„é«˜åº¦ï¼Œé•¿åº¦ï¼Œæ·±åº¦ã€‚æˆ‘ä»¬çš„4Då¼ é‡æ˜¯(1ï¼Œ224ï¼Œ224ï¼Œ3)ã€‚</p><pre class="je jf jg jh fd lq lr ls lt aw lu bi"><span id="f137" class="lv ko hi lr b fi lw lx l ly lz">from keras.preprocessing import image                  <br/>from tqdm import tqdm</span><span id="d624" class="lv ko hi lr b fi ma lx l ly lz">def path_to_tensor(img_path):<br/>    # loads RGB image as PIL.Image.Image type<br/>    img = image.load_img(img_path, target_size=(224, 224))<br/>    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)<br/>    x = image.img_to_array(img)<br/>    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor<br/>    return np.expand_dims(x, axis=0)</span><span id="dab1" class="lv ko hi lr b fi ma lx l ly lz">def paths_to_tensor(img_paths):<br/>    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]<br/>    return np.vstack(list_of_tensors)</span></pre><p id="a8a2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">åœ¨æ¨¡å‹å¯ç”¨äºé¢„æµ‹ä¹‹å‰ï¼Œéœ€è¦ä¸€äº›é¢å¤–çš„é¢„å¤„ç†æ­¥éª¤ï¼Œå¦‚å°†RGBå›¾åƒè½¬æ¢ä¸ºBGRï¼Œé€šè¿‡ä»æ¯ä¸ªå›¾åƒçš„æ¯ä¸ªåƒç´ ä¸­å‡å»å¹³å‡åƒç´ æ¥å½’ä¸€åŒ–æ¨¡å‹ç­‰ã€‚è¿™éƒ½ç”±<code class="du mg mh mi lr b">preprocess_input</code>åŠŸèƒ½è´Ÿè´£ã€‚è¦äº†è§£æ›´å¤šä¿¡æ¯ï¼Œè¯·ç‚¹å‡»æŸ¥çœ‹ä»£ç <a class="ae jt" href="https://github.com/fchollet/keras/blob/master/keras/applications/imagenet_utils.py" rel="noopener ugc nofollow" target="_blank">ã€‚</a></p><p id="e90d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">ç°åœ¨æˆ‘ä»¬çš„å›¾åƒå·²ç»æ ¼å¼åŒ–äº†ï¼Œæˆ‘ä»¬å‡†å¤‡æŠŠå®ƒæä¾›ç»™ResNet-50å¹¶è¿›è¡Œé¢„æµ‹ã€‚ä¸‹é¢çš„<code class="du mg mh mi lr b">predict</code>å‡½æ•°è¿”å›å›¾åƒå±äºç‰¹å®šImageNetç±»åˆ«çš„é¢„æµ‹æ¦‚ç‡ã€‚ä¸ºäº†å°†è¿”å›çš„æ•´æ•°æ˜ å°„åˆ°æ¨¡å‹çš„é¢„æµ‹å¯¹è±¡ç±»ï¼Œè¯·ä½¿ç”¨è¿™ä¸ª<a class="ae jt" href="https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a" rel="noopener ugc nofollow" target="_blank">å­—å…¸</a>ã€‚</p><pre class="je jf jg jh fd lq lr ls lt aw lu bi"><span id="c8a0" class="lv ko hi lr b fi lw lx l ly lz">from keras.applications.resnet50 import preprocess_input, decode_predictions</span><span id="c22f" class="lv ko hi lr b fi ma lx l ly lz">def ResNet50_predict_labels(img_path):<br/>    # returns prediction vector for image located at img_path<br/>    img = preprocess_input(path_to_tensor(img_path))<br/>    return np.argmax(ResNet50_model.predict(img))</span></pre><p id="4144" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">å­—å…¸ä¸­æ‰€æœ‰çš„ç‹—ç±»åˆ«éƒ½å¯¹åº”äº151-268é”®ã€‚å› æ­¤ï¼Œè¦æ£€æµ‹ä¸€å¼ ç‹—è„¸ï¼Œæˆ‘ä»¬éœ€è¦æ£€æŸ¥ä¸‹é¢çš„<code class="du mg mh mi lr b">ResNet50_predict_labels</code>å‡½æ•°æ˜¯å¦è¿”å›ä¸€ä¸ªä»‹äº151å’Œ268(å«)ä¹‹é—´çš„å€¼ã€‚å¦‚æœæ£€æµ‹åˆ°ç‹—è„¸ï¼Œè¯¥å‡½æ•°è¿”å›<code class="du mg mh mi lr b">True</code>ï¼Œå¦åˆ™è¿”å›<code class="du mg mh mi lr b">False</code>ã€‚</p><p id="4432" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">ç±»ä¼¼äºæ­¥éª¤2ï¼Œæˆ‘ä»¬é€šè¿‡è¿™ä¸ªå‡½æ•°è¿è¡Œ100ä¸ªå›¾åƒçš„æ ·æœ¬ã€‚æˆ‘ä»¬çš„æ¨¡å‹èƒ½å¤Ÿåœ¨ç‹—å›¾åƒçš„<strong class="ih hj"> 100% </strong>å’Œäººå›¾åƒçš„<strong class="ih hj"> 0% </strong>ä¸­æ£€æµ‹åˆ°ç‹—è„¸ã€‚</p><h1 id="9b39" class="kn ko hi bd kp kq mb ks kt ku mc kw kx ky md la lb lc me le lf lg mf li lj lk bi translated">ç¬¬å››æ­¥:åˆ›å»ºä¸€ä¸ªCNNæ¥åˆ†ç±»ç‹—çš„å“ç§</h1><p id="d518" class="pw-post-body-paragraph if ig hi ih b ii ll ik il im lm io ip iq ln is it iu lo iw ix iy lp ja jb jc hb bi translated">æ—¢ç„¶æˆ‘ä»¬èƒ½å¤Ÿåœ¨å›¾åƒä¸­æ£€æµ‹å‡ºäººå’Œç‹—çš„è„¸ï¼Œæˆ‘ä»¬çš„ä¸‹ä¸€ä¸ªç›®æ ‡æ˜¯å¯¹ç‹—çš„å“ç§è¿›è¡Œåˆ†ç±»ã€‚æˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªCNNæ¨¡å‹æ¥å¸®åŠ©è¿™äº›åˆ†ç±»é¢„æµ‹ã€‚åœ¨æˆ‘ä»¬å¼€å§‹å»ºç«‹æ¨¡å‹ä¹‹å‰ï¼Œæˆ‘ä»¬é€šè¿‡å°†æ¯ä¸ªå›¾åƒä¸­çš„æ¯ä¸ªåƒç´ é™¤ä»¥255æ¥é‡æ–°ç¼©æ”¾å›¾åƒã€‚</p><pre class="je jf jg jh fd lq lr ls lt aw lu bi"><span id="f949" class="lv ko hi lr b fi lw lx l ly lz"># pre-process the data for Keras<br/>train_tensors = paths_to_tensor(train_files).astype('float32')/255<br/>valid_tensors = paths_to_tensor(valid_files).astype('float32')/255<br/>test_tensors = paths_to_tensor(test_files).astype('float32')/255</span></pre><p id="a9ad" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">ä¸‹é¢æ˜¯æ¥è‡ªæˆ‘ä»¬åˆ†ç±»æ¨¡å‹çš„<strong class="ih hj"> CNNæ¶æ„</strong>ã€‚CNNçš„è®¾è®¡ç›®æ ‡é€šå¸¸æ˜¯ä½¿è¾“å…¥é˜µåˆ—æ¯”å…¶é•¿åº¦æˆ–å®½åº¦æ›´æ·±ã€‚åœ¨ä¸‹é¢ä½¿ç”¨çš„3ä¸ª<strong class="ih hj">å·ç§¯å±‚</strong>ä¸­ï¼Œæˆ‘å¢åŠ äº†è¿‡æ»¤å™¨çš„æ•°é‡ï¼Œä»¥å¢åŠ ç‰¹å¾çš„å †å ï¼Œä»è€Œå¢åŠ å…¶æ·±åº¦ã€‚æ¯ä¸ªå·ç§¯å±‚ä¹‹åæ˜¯ä¸€ä¸ª<strong class="ih hj">æœ€å¤§æ± å±‚</strong>ï¼Œä»¥å‡å°‘å›¾åƒçš„ç©ºé—´ç»´åº¦ã€‚ç„¶åï¼Œæˆ‘ä»¬å°†çŸ©é˜µå±•å¹³æˆä¸€ä¸ªå‘é‡ï¼Œç„¶åå°†å®ƒé€å…¥ä¸€ä¸ªå®Œå…¨è¿æ¥çš„<strong class="ih hj">å¯†é›†å±‚</strong>ï¼Œå› ä¸ºè¿™äº›ä¸æ¥å—å¤šç»´æ•°ç»„ã€‚è¯¥å±‚ä½¿ç”¨softmaxæ¿€æ´»å‡½æ•°æ¥è·å¾—æ¯ä¸ªç±»åˆ«çš„åˆ†ç±»æ¦‚ç‡ï¼Œä»¥åŠ133ä¸ªè¾“å‡ºèŠ‚ç‚¹ï¼Œåœ¨æˆ‘ä»¬çš„è®­ç»ƒæ•°æ®ä¸­ï¼Œæ¯ä¸ªç‹—ç±»åˆ«1ä¸ªã€‚<em class="km">è¦è¯¦ç»†äº†è§£æ¯ä¸ªå‚æ•°ï¼Œä»¥åŠè¿™äº›å‚æ•°æ˜¯å¦‚ä½•è®¡ç®—çš„ï¼Œè¯·å‚è§æœ¬</em> <a class="ae jt" href="https://towardsdatascience.com/understanding-and-calculating-the-number-of-parameters-in-convolution-neural-networks-cnns-fc88790d530d" rel="noopener" target="_blank"> <em class="km">å¸–å­</em></a><em class="km">by</em><a class="mj mk ge" href="https://medium.com/u/4ed456ddae20?source=post_page-----a277f4ad91be--------------------------------" rel="noopener" target="_blank"><em class="km">Rakshith Vasudev</em></a><em class="km">ã€‚</em></p><pre class="je jf jg jh fd lq lr ls lt aw lu bi"><span id="6e0c" class="lv ko hi lr b fi lw lx l ly lz">from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D<br/>from keras.layers import Dropout, Flatten, Dense<br/>from keras.models import Sequential</span><span id="8507" class="lv ko hi lr b fi ma lx l ly lz"># Define your architecture.</span><span id="5ae8" class="lv ko hi lr b fi ma lx l ly lz">model = Sequential()<br/># Convolutional layers and maxpooling layers, note: all images are 224*224 pixel<br/>model.add(Conv2D(filters=16, kernel_size=2, strides=1, padding='same',activation='relu', input_shape=[224,224,3]))<br/>model.add(MaxPooling2D(pool_size=2, strides=1, padding='same'))</span><span id="5ed8" class="lv ko hi lr b fi ma lx l ly lz">model.add(Conv2D(filters=32, kernel_size=2, strides=2, padding='same',activation='relu'))<br/>model.add(MaxPooling2D(pool_size=2, strides=1, padding='same'))</span><span id="696e" class="lv ko hi lr b fi ma lx l ly lz">model.add(Conv2D(filters=64, kernel_size=2, strides=2, padding='same',activation='relu'))<br/>model.add(MaxPooling2D(pool_size=2, strides=1, padding='same'))<br/>#model.add(GlobalAveragePooling2D())</span><span id="c9bf" class="lv ko hi lr b fi ma lx l ly lz"># Flatten the array into a vector and feed to a dense layer<br/>model.add(Flatten())<br/>model.add(Dense(133, activation='softmax'))</span><span id="5179" class="lv ko hi lr b fi ma lx l ly lz">model.summary()</span></pre><p id="ca5b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬<strong class="ih hj">ç¼–è¯‘</strong>ï¼Œè€Œ<strong class="ih hj">è®­ç»ƒ</strong>æˆ‘ä»¬çš„æ¨¡å‹ã€‚ModelCheckpointç”¨äºä¿å­˜è·å¾—æœ€ä½³éªŒè¯æŸå¤±çš„æ¨¡å‹ã€‚</p><pre class="je jf jg jh fd lq lr ls lt aw lu bi"><span id="d160" class="lv ko hi lr b fi lw lx l ly lz">from keras.callbacks import ModelCheckpoint</span><span id="1f28" class="lv ko hi lr b fi ma lx l ly lz">model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])</span><span id="3a4c" class="lv ko hi lr b fi ma lx l ly lz">checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.from_scratch.hdf5', <br/>                               verbose=1, save_best_only=True)</span><span id="a59a" class="lv ko hi lr b fi ma lx l ly lz">model.fit(train_tensors, train_targets, <br/>          validation_data=(valid_tensors, valid_targets),<br/>          epochs=epochs, batch_size=20, callbacks=[checkpointer], verbose=1)</span></pre><p id="2b43" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">ä¸€æ—¦æˆ‘ä»¬çš„æ¨¡å‹è¢«è®­ç»ƒï¼Œæˆ‘ä»¬åŠ è½½ä¹‹å‰ä¿å­˜çš„æƒé‡ï¼Œå¹¶ä½¿ç”¨å®ƒåœ¨æˆ‘ä»¬çš„<strong class="ih hj">æµ‹è¯•</strong>æ•°æ®ä¸Šè¿è¡Œæ¨¡å‹ï¼Œä»¥è¯„ä¼°æˆ‘ä»¬çš„æ¨¡å‹çš„å‡†ç¡®æ€§ã€‚</p><pre class="je jf jg jh fd lq lr ls lt aw lu bi"><span id="52ab" class="lv ko hi lr b fi lw lx l ly lz">model.load_weights('saved_models/weights.best.from_scratch.hdf5')</span><span id="c2ce" class="lv ko hi lr b fi ma lx l ly lz"># get index of predicted dog breed for each image in test set<br/>dog_breed_predictions = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]</span><span id="8bc9" class="lv ko hi lr b fi ma lx l ly lz"># report test accuracy<br/>test_accuracy = 100*np.sum(np.array(dog_breed_predictions)==np.argmax(test_targets, axis=1))/len(dog_breed_predictions)<br/>print('Test accuracy: %.4f%%' % test_accuracy)</span></pre><p id="244c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">è¿™ä¸ªæ¨¡å‹å·¥ä½œæ­£å¸¸ï¼Œå¹¶ä¸”ä¼šç»™å‡º<strong class="ih hj"> ~7% </strong>çš„ç²¾åº¦ã€‚ä½ ä¸€å®šåœ¨æƒ³ï¼Œè¿™ä¹ˆå¤šæ‰èƒ½å¾—åˆ°è¿™ä¹ˆä½çš„ç²¾åº¦ï¼Ÿè¯·è®°ä½ï¼Œè¿™æ˜¯æ²¡æœ‰ä»»ä½•å‚æ•°å¾®è°ƒå’Œæ•°æ®å¢å¼ºã€‚è¿™æ˜¯æ¥ä¸‹æ¥çš„æ­¥éª¤å°†æœ‰åŠ©äºæé«˜å‡†ç¡®æ€§çš„åœ°æ–¹ã€‚</p><h1 id="2457" class="kn ko hi bd kp kq mb ks kt ku mc kw kx ky md la lb lc me le lf lg mf li lj lk bi translated">ç¬¬äº”æ­¥:ä½¿ç”¨é¢„å…ˆæ„å»ºçš„Keras CNNæ¨¡å‹ï¼Œå¹¶ä¿®æ”¹è¿™äº›æ¨¡å‹æ¥å¯¹ç‹—çš„å“ç§è¿›è¡Œåˆ†ç±»(ä½¿ç”¨è¿ç§»å­¦ä¹ )</h1><p id="34cc" class="pw-post-body-paragraph if ig hi ih b ii ll ik il im lm io ip iq ln is it iu lo iw ix iy lp ja jb jc hb bi translated">Kerasä¸­æœ‰ä¸€äº›çªç ´æ€§çš„é¢„å»ºCNNæ¶æ„ï¼Œå¯ä»¥é€šè¿‡è¿ç§»å­¦ä¹ æ¥ä½¿ç”¨ã€‚VGG16ã€VGG19ã€ResNet50ã€Xceptionã€InceptionV3ã€‚è¿™äº›æ¨¡å‹æœ‰åŠ©äºåœ¨ä¸ç‰ºç‰²å‡†ç¡®æ€§çš„æƒ…å†µä¸‹å‡å°‘è®­ç»ƒæ—¶é—´ã€‚è¿™é‡Œä½¿ç”¨äº†é¢„å…ˆè®­ç»ƒçš„VGG-16æ¨¡å‹ï¼Œå¹¶å°†å…¶è¾“å…¥åˆ°æˆ‘ä»¬çš„æ¨¡å‹ä¸­ã€‚æˆ‘ä»¬åªæ·»åŠ äº†ä¸€ä¸ªå…¨å±€å¹³å‡æ± å±‚<em class="km">(å‡å°‘ç»´åº¦)</em>å’Œä¸€ä¸ªå…·æœ‰softmaxæ¿€æ´»å‡½æ•°çš„å…¨è¿æ¥å±‚<em class="km">(ä¸ºæ¯ä¸ªç‹—ç±»åˆ«è·å¾—ä¸€ä¸ªèŠ‚ç‚¹)</em>ã€‚</p><pre class="je jf jg jh fd lq lr ls lt aw lu bi"><span id="619e" class="lv ko hi lr b fi lw lx l ly lz">bottleneck_features = np.load('bottleneck_features/DogVGG16Data.npz')<br/>train_VGG16 = bottleneck_features['train']<br/>valid_VGG16 = bottleneck_features['valid']<br/>test_VGG16 = bottleneck_features['test']</span><span id="fe1e" class="lv ko hi lr b fi ma lx l ly lz"># CNN architecture using Transfer Learning<br/>VGG16_model = Sequential()<br/>VGG16_model.add(GlobalAveragePooling2D(input_shape=train_VGG16.shape[1:]))<br/>VGG16_model.add(Dense(133, activation='softmax'))</span><span id="e276" class="lv ko hi lr b fi ma lx l ly lz">VGG16_model.summary()</span></pre><p id="c04c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">å½“æˆ‘ä»¬é€šè¿‡è¿™ä¸ªæ–°è®­ç»ƒçš„æ¨¡å‹å’Œé¢„å…ˆè®¡ç®—çš„ç‰¹å¾è¿è¡Œæˆ‘ä»¬çš„æµ‹è¯•æ•°æ®æ—¶ï¼Œæˆ‘ä»¬çš„å‡†ç¡®æ€§åœ¨æ›´çŸ­çš„æ—¶é—´å†…å¢åŠ åˆ°äº†<strong class="ih hj"> ~45% </strong>ï¼Œè¿™æ˜¯ä¸€ä¸ªæ˜¾è‘—çš„æ”¹è¿›ã€‚è¿™æ˜¯å› ä¸ºç°åœ¨ç½‘ç»œä¸­åªæœ‰2å±‚æ­£åœ¨å¤„ç†ã€‚ä½¿ç”¨ResNet50æ¨¡å‹ï¼Œå‡†ç¡®ç‡è¿›ä¸€æ­¥è·ƒå‡è‡³<strong class="ih hj"> ~82% </strong>ï¼Œè¿™æ˜¯æˆ‘æœ€ç»ˆåœ¨ä»£ç ä¸­ä½¿ç”¨çš„ã€‚</p><h1 id="9dc2" class="kn ko hi bd kp kq mb ks kt ku mc kw kx ky md la lb lc me le lf lg mf li lj lk bi translated">ç¬¬å…­æ­¥:å†™ä¸€ä¸ªç®—æ³•æ¥ç»‘å®šä¸Šé¢çš„æ­¥éª¤</h1><p id="648d" class="pw-post-body-paragraph if ig hi ih b ii ll ik il im lm io ip iq ln is it iu lo iw ix iy lp ja jb jc hb bi translated">è¿™æ˜¯æˆ‘ä»¬æŠŠæ‰€æœ‰ä¸åŒçš„éƒ¨åˆ†æ”¾åœ¨ä¸€èµ·çš„æ­¥éª¤ã€‚æˆ‘ä»¬ç¼–å†™äº†ä¸€ä¸ªç®€å•çš„ç®—æ³•ï¼Œå®ƒæ¥å—ä¸€ä¸ªå›¾åƒè·¯å¾„ï¼Œå¹¶é¦–å…ˆç¡®å®šå®ƒæ˜¯å¦åŒ…å«äººè„¸ã€ç‹—è„¸ï¼Œæˆ–è€…ä¸¤è€…éƒ½ä¸åŒ…å«ã€‚ç„¶åï¼Œ</p><ul class=""><li id="6ea3" class="ml mm hi ih b ii ij im in iq mn iu mo iy mp jc mq mr ms mt bi translated">å¦‚æœåœ¨å›¾åƒä¸­æ£€æµ‹åˆ°ä¸€åª<strong class="ih hj">ç‹—</strong>ï¼Œè¿”å›é¢„æµ‹çš„å“ç§ã€‚</li><li id="5949" class="ml mm hi ih b ii mu im mv iq mw iu mx iy my jc mq mr ms mt bi translated">å¦‚æœåœ¨å›¾åƒä¸­æ£€æµ‹åˆ°ä¸€ä¸ª<strong class="ih hj">äºº</strong>ï¼Œè¿”å›ç›¸ä¼¼çš„ç‹—å“ç§ã€‚</li><li id="448e" class="ml mm hi ih b ii mu im mv iq mw iu mx iy my jc mq mr ms mt bi translated">å¦‚æœåœ¨å›¾åƒä¸­æ²¡æœ‰æ£€æµ‹åˆ°<strong class="ih hj">æˆ–</strong>ï¼Œåˆ™æä¾›æŒ‡ç¤ºé”™è¯¯çš„è¾“å‡ºã€‚</li></ul><pre class="je jf jg jh fd lq lr ls lt aw lu bi"><span id="d1c1" class="lv ko hi lr b fi lw lx l ly lz">def display_detect_image(img_path):<br/>    detect_breed(img_path)<br/>    # load color (BGR) image<br/>    img = cv2.imread(img_path)<br/>    # convert BGR image to RGB for plotting<br/>    cv_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)<br/>    # display the image<br/>    plt.imshow(cv_rgb)<br/>    return plt.show()</span><span id="91a6" class="lv ko hi lr b fi ma lx l ly lz">def detect_breed(img_path):<br/>    # check if image is human face<br/>    if face_detector(img_path) == True:<br/>        return print("Hello human! Your face resembles a: ",Resnet50_predict_breed(img_path).str.split(".")[-1])<br/>    # check if image is dog face<br/>    elif dog_detector(img_path) == True:<br/>        return print("Hello dog! Your predicted breed is: ",Resnet50_predict_breed(img_path).str.split(".")[-1])<br/>    # else print an error message<br/>    else:<br/>        return print("Oops! This is neither a human nor a dog")</span></pre><h1 id="9894" class="kn ko hi bd kp kq mb ks kt ku mc kw kx ky md la lb lc me le lf lg mf li lj lk bi translated">æ­¥éª¤7:æµ‹è¯•æˆ‘ä»¬çš„ç®—æ³•</h1><p id="866e" class="pw-post-body-paragraph if ig hi ih b ii ll ik il im lm io ip iq ln is it iu lo iw ix iy lp ja jb jc hb bi translated">åœ¨è¿™ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬å°†çœ‹åˆ°æˆ‘ä»¬ç®—æ³•çš„å¼ºå¤§ä¹‹å¤„ï¼Œå¹¶å°è¯•ä¸€ä¸‹ï¼æˆ‘éšæœºæä¾›äº†ä¸€äº›ç‹—å’Œäººçš„å›¾åƒï¼Œç§ï¼ç®—æ³•é¢„æµ‹å“ç§ã€‚ç°åœ¨ï¼Œå¦‚æœä½ å–œæ¬¢è¡—ä¸Šæˆ–å…¬å›­é‡Œçš„ä¸€åªç‹—ï¼Œä½ æƒ³çŸ¥é“å®ƒçš„å“ç§ï¼Œä¸éœ€è¦é—®ä¸»äººï¼Œåªéœ€ç‚¹å‡»ä¸€å¼ å›¾ç‰‡ï¼Œå¹¶é€šè¿‡æ¨¡å‹è¿è¡Œå®ƒğŸ˜„</p><p id="7c6e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="km">è¦è®¿é—®å®Œæ•´çš„ä»£ç ï¼Œè¯·ç‚¹å‡»</em>  <em class="km">æŸ¥çœ‹æˆ‘çš„GitHubçš„é“¾æ¥ã€‚</em></p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mz"><img src="../Images/d1f36ee2c34e4d8def33e91070c650e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Uu65_iBJ7sPczlkiBs5sWg.png"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es na"><img src="../Images/350754a206c14e66e7f449ffb7fe528c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sVoq5OyitvYmtnvFTI21Ng.png"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es nb"><img src="../Images/58b1bec9a259e5be388b3a6abca1d524.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qUCZjX50j-GWM2PeYSbeoQ.png"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es nc"><img src="../Images/db17803e4d71baed59bf7d3d8a939fd8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OWAdy4lSjLQGjp0sB-aZmg.png"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es nd"><img src="../Images/46faeafc5eb40cbc2da5e4cf29c7e1b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Kff4SG9NJ7Pt0mTJ9j_WkA.png"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ne"><img src="../Images/71c2ee7ca01a48b8dac5bd096b6db5df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z_RSKP2l5DZqhwZkufiFCQ.png"/></div></div></figure><blockquote class="nf ng nh"><p id="f06f" class="if ig km ih b ii ij ik il im in io ip ni ir is it nj iv iw ix nk iz ja jb jc hb bi translated"><strong class="ih hj">å‚è€ƒæ–‡çŒ®:</strong></p><p id="581b" class="if ig km ih b ii ij ik il im in io ip ni ir is it nj iv iw ix nk iz ja jb jc hb bi translated"><a class="ae jt" href="https://pathmind.com/wiki/neural-network" rel="noopener ugc nofollow" target="_blank">https://pathmind.com/wiki/neural-network</a></p><p id="07c6" class="if ig km ih b ii ij ik il im in io ip ni ir is it nj iv iw ix nk iz ja jb jc hb bi translated"><a class="ae jt" href="https://analyticsindiamag.com/tensorflow-vs-keras-which-one-should-you-choose/" rel="noopener ugc nofollow" target="_blank">https://analyticsindiamag . com/tensor flow-vs-keras-ä½ åº”è¯¥é€‰æ‹©å“ªä¸€ä¸ª/ </a></p></blockquote></div></div>    
</body>
</html>