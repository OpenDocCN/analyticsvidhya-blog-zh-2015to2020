<html>
<head>
<title>Pytorch with TPUs HACKED!!!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">TPUs 被黑的 Pytorch！！！</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/pytorch-with-tpus-hacked-dc860d2df7e?source=collection_archive---------15-----------------------#2020-09-01">https://medium.com/analytics-vidhya/pytorch-with-tpus-hacked-dc860d2df7e?source=collection_archive---------15-----------------------#2020-09-01</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/aa5808467c2c37654c6f92b55bd4c6a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o6pcNM-eYMnpTn9ybHqA5Q.jpeg"/></div></div></figure><p id="bf3b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们大多数人都用过带 GPU 的<strong class="is hj"> Google Colab，但有多少人用过 Colab 中的<strong class="is hj"> TPU(张量处理单元)？？？</strong></strong></p><figure class="jp jq jr js fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es jo"><img src="../Images/48623caa300d0a00d804075ecd3b1f4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xoZQ9gE63DzSHONk5GoPBQ.jpeg"/></div></div></figure><p id="8d2a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">今天，我将帮助我的读者了解我们如何在使用 Pytorch 的同时，轻松地使用 TPU 来更快地训练我们的深度学习模型。只要坚持遵循给定的步骤，你就能轻松掌握它。</p><ol class=""><li id="09cd" class="jt ju hi is b it iu ix iy jb jv jf jw jj jx jn jy jz ka kb bi translated">首先更改你的笔记本设置 TPU。</li><li id="3281" class="jt ju hi is b it kc ix kd jb ke jf kf jj kg jn jy jz ka kb bi translated">然后运行以下命令安装到<strong class="is hj"> pytorch-xla </strong>(一个集成 pytorch 和 TPU 的框架)夜间版本。</li></ol><pre class="jp jq jr js fd kh ki kj kk aw kl bi"><span id="8425" class="km kn hi ki b fi ko kp l kq kr">!curl <a class="ae ks" href="https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py" rel="noopener ugc nofollow" target="_blank">https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py</a> -o pytorch-xla-env-setup.py</span><span id="11ae" class="km kn hi ki b fi kt kp l kq kr">!python pytorch-xla-env-setup.py — apt-packages libomp5 libopenblas-dev</span></pre><p id="2574" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">3.然后导入以下库</p><pre class="jp jq jr js fd kh ki kj kk aw kl bi"><span id="19db" class="km kn hi ki b fi ko kp l kq kr">import torch_xla<br/>import torch_xla.distributed.parallel_loader as pl<br/>import torch_xla.core.xla_model as xm<br/>import torch_xla.distributed.xla_multiprocessing as xmp</span></pre><p id="876b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">4.然后为训练和验证数据集创建分布式采样器</p><pre class="jp jq jr js fd kh ki kj kk aw kl bi"><span id="cced" class="km kn hi ki b fi ko kp l kq kr">train_sampler = torch.utils.data.distributed.DistributedSampler(<br/>          <strong class="ki hj">your_train_dataset</strong>,<br/>          num_replicas=xm.xrt_world_size(),<br/>          rank=xm.get_ordinal(),<br/>          shuffle=True)<br/><br/>valid_sampler = torch.utils.data.distributed.DistributedSampler(<br/>          <strong class="ki hj">your_val_dataset</strong>,<br/>          num_replicas=xm.xrt_world_size(),<br/>          rank=xm.get_ordinal(),<br/>          shuffle=False)</span></pre><p id="7bf2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">5.在您的数据加载器中，传递上面在 sampler 参数中创建的这些分布式采样器</p><pre class="jp jq jr js fd kh ki kj kk aw kl bi"><span id="81d7" class="km kn hi ki b fi ko kp l kq kr">training_dataloader = torch.utils.data.DataLoader(<br/>                        CutMix_train_dataloader,<br/>                        num_workers=4,<br/>                        batch_size=TRAIN_BATCH_SIZE,<br/>                        <strong class="ki hj">sampler=train_sampler</strong>,<br/>                        drop_last=True<br/>                       )<br/><br/>val_dataloader = torch.utils.data.DataLoader(<br/>                        val_dataset,<br/>                        num_workers=4,<br/>                        batch_size=TRAIN_BATCH_SIZE,<br/>                        <strong class="ki hj">sampler=valid_sampler</strong>,<br/>                        drop_last=False<br/>                       )</span></pre><p id="1976" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">6.然后创建一个 xla_model 类的对象来集成 torch-xla 和 tpu</p><pre class="jp jq jr js fd kh ki kj kk aw kl bi"><span id="ec11" class="km kn hi ki b fi ko kp l kq kr">device = xm.xla_device()</span></pre><p id="ad50" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">7.然后将创建的深度学习模型与 xla_model 的实例集成</p><pre class="jp jq jr js fd kh ki kj kk aw kl bi"><span id="fe0d" class="km kn hi ki b fi ko kp l kq kr">model = model.to(device)</span></pre><p id="e36c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">8.将输入和标签与创建的设备实例集成。</p><pre class="jp jq jr js fd kh ki kj kk aw kl bi"><span id="6814" class="km kn hi ki b fi ko kp l kq kr">for inputs,labels in <strong class="ki hj">your_data_loader</strong>:<br/>    inputs = inputs.to(<strong class="ki hj">device</strong>, dtype=torch.float)<br/>    labels = labels.to(<strong class="ki hj">device</strong>, dtype=torch.float)</span></pre><p id="4e5e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">9.然后在<strong class="is hj"> epoch </strong>循环中使用<strong class="is hj"> ParallelLoader </strong></p><pre class="jp jq jr js fd kh ki kj kk aw kl bi"><span id="95f6" class="km kn hi ki b fi ko kp l kq kr">train_loader = pl.ParallelLoader(<strong class="ki hj">your_train_dataloader</strong>, [device])<br/><strong class="ki hj">train_func_loop</strong>(train_loader.per_device_loader(device), model, optimizer, device, scheduler=scheduler)<br/><br/>val_loader = pl.ParallelLoader(<strong class="ki hj">your_val_dataloader</strong>, [device])<br/><strong class="ki hj">val_func_loop</strong>(para_loader.per_device_loader(device), model, device)</span></pre><p id="25d2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">10.最后初始化模型的训练&amp;应用多重处理，使得图像在卡格尔-tpu 的不同内核中得到并行训练</p><pre class="jp jq jr js fd kh ki kj kk aw kl bi"><span id="fbb9" class="km kn hi ki b fi ko kp l kq kr">def _mp_fn(rank, flags):<br/>    torch.set_default_tensor_type('torch.FloatTensor')<br/>    a = <strong class="ki hj">epochLoop</strong>()<br/>    <br/><em class="ku"># applying multiprocessing so that images get trained different on      # cores of kaggle-tpu</em></span><span id="5162" class="km kn hi ki b fi kt kp l kq kr">FLAGS={}<br/>xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=1, start_method='fork')</span></pre><p id="49b4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">更多信息，请查看这些 Kaggle 笔记本</p><ol class=""><li id="71c9" class="jt ju hi is b it iu ix iy jb jv jf jw jj jx jn jy jz ka kb bi translated"><a class="ae ks" href="https://www.kaggle.com/soumochatterjee/cutmix-flower-classification" rel="noopener ugc nofollow" target="_blank">使用 TPU 增强 Cutmix 数据</a></li><li id="cb1a" class="jt ju hi is b it kc ix kd jb ke jf kf jj kg jn jy jz ka kb bi translated"><a class="ae ks" href="https://www.kaggle.com/soumochatterjee/mixup-tpu" rel="noopener ugc nofollow" target="_blank">用 TPU 增强混合数据</a></li></ol><figure class="jp jq jr js fd ij er es paragraph-image"><div class="er es kv"><img src="../Images/e082232abd00c01bca4f3549fc6ee09d.png" data-original-src="https://miro.medium.com/v2/resize:fit:982/1*AKDyEE0ccBl7XO4B-ED6JA.gif"/></div></figure><p id="7b30" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><a class="ae ks" href="https://cloud.google.com/images/products/tpu/try-the-demo.gif" rel="noopener ugc nofollow" target="_blank">https://cloud . Google . com/images/products/TPU/try-the-demo . gif</a></p><p id="7e64" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">最终你会得到</p><figure class="jp jq jr js fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kw"><img src="../Images/eb539f30660856b643974fe921057e30.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i9VTMi-MQA05HVXA8TWH8w.jpeg"/></div></div></figure><p id="997f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果您有任何问题、意见或担忧，请在下面的评论区告诉我，或者您可以在这里张贴出来<a class="ae ks" href="https://github.com/pytorch/xla/issues" rel="noopener ugc nofollow" target="_blank">，直到享受学习的乐趣。</a></p><p id="9144" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">更多与数据科学相关的博客文章，请查看 medium 上的顶级数据科学博客。</p><ul class=""><li id="18f6" class="jt ju hi is b it iu ix iy jb jv jf jw jj jx jn kx jz ka kb bi translated">拉胡尔·阿加瓦尔</li><li id="4853" class="jt ju hi is b it kc ix kd jb ke jf kf jj kg jn kx jz ka kb bi translated">威尔·科尔森</li><li id="eaf5" class="jt ju hi is b it kc ix kd jb ke jf kf jj kg jn kx jz ka kb bi translated">卡西·科济尔科夫</li><li id="22ce" class="jt ju hi is b it kc ix kd jb ke jf kf jj kg jn kx jz ka kb bi translated">丽贝卡·维克里</li><li id="2086" class="jt ju hi is b it kc ix kd jb ke jf kf jj kg jn kx jz ka kb bi translated"><a class="ky kz ge" href="https://medium.com/u/840a3210fbe7?source=post_page-----dc860d2df7e--------------------------------" rel="noopener" target="_blank">Tony Yiu(T1)</a></li><li id="f01a" class="jt ju hi is b it kc ix kd jb ke jf kf jj kg jn kx jz ka kb bi translated">丹尼尔·伯克(Daniel Bourke)</li><li id="4eef" class="jt ju hi is b it kc ix kd jb ke jf kf jj kg jn kx jz ka kb bi translated">埃里克·莱文森(Eryk Lewinson)</li><li id="3af7" class="jt ju hi is b it kc ix kd jb ke jf kf jj kg jn kx jz ka kb bi translated">本杰明·奥比·塔约(Benjamin Obi Tayo)博士</li><li id="9461" class="jt ju hi is b it kc ix kd jb ke jf kf jj kg jn kx jz ka kb bi translated"><a class="ky kz ge" href="https://medium.com/u/fba05660b60f?source=post_page-----dc860d2df7e--------------------------------" rel="noopener" target="_blank">Moez Ali(T9)</a></li><li id="f67b" class="jt ju hi is b it kc ix kd jb ke jf kf jj kg jn kx jz ka kb bi translated">拉瓦尔(Siraj Raval) (T11)</li></ul></div></div>    
</body>
</html>