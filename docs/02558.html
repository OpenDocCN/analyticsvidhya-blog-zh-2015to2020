<html>
<head>
<title>SPARK optimization and ways to maximize Resource Allocation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">火花优化和最大化资源分配的方法</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/understanding-resource-allocation-configurations-for-a-spark-application-9c1307e6b5e3?source=collection_archive---------2-----------------------#2019-12-23">https://medium.com/analytics-vidhya/understanding-resource-allocation-configurations-for-a-spark-application-9c1307e6b5e3?source=collection_archive---------2-----------------------#2019-12-23</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="065b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">资源分配是任何spark作业执行过程中的一个重要方面。如果配置不正确，spark作业可能会消耗整个集群资源，并使其他应用程序缺乏资源。</p><p id="8c8b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这个博客有助于理解Spark应用程序的基本流程，以及如何配置执行器的数量、每个执行器的内存设置以及Spark作业的内核数量。我们需要考虑几个因素来确定上述三个因素的最佳数量，例如:</p><ul class=""><li id="300c" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated">数据量</li><li id="578f" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">一项工作必须完成的时间</li><li id="13a0" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">资源的静态或动态分配</li></ul><h1 id="5037" class="jr js hi bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated"><strong class="ak">简介</strong></h1><p id="7f4e" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated">让我们从处理Spark应用程序时使用的术语的一些基本定义开始。</p><p id="42e9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">分区</strong>:分区是大型分布式数据集的一小部分。Spark使用分区来管理数据，分区有助于并行化数据处理，并将执行器之间的数据洗牌降至最低。</p><p id="35b2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">任务</strong>:任务是一个工作单元，可以在分布式数据集的一个分区上运行，并在单个执行器上执行。<strong class="ih hj">并行执行的单元在任务级</strong>。单个阶段中的所有任务都可以并行执行。</p><p id="57ce" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">执行器</strong>:执行器是为工作节点上的应用程序启动的单个JVM进程。Executor运行任务，并将数据保存在内存或磁盘存储器中。每个应用程序都有自己的执行者。一个节点可以运行多个执行器，一个应用程序的执行器可以跨越多个工作节点。一个执行器在Spark应用程序的<br/>持续时间内保持运行，并在多个线程中运行任务。spark应用程序的执行器数量可以在SparkConf中指定，或者通过命令行中的标志–num-executors来指定。</p><p id="7eed" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">集群管理器</strong>:获取集群上资源的外部服务(如独立管理器、Mesos、YARN)。Spark对于集群管理器来说是不可知的，只要它可以获取执行器进程，并且这些进程可以相互通信。spark集群可以在纱线集群或纱线客户端模式下运行:</p><p id="ea6d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> yarn-client模式</strong> —驱动程序在客户端进程上运行，应用主机仅用于向yarn请求资源。</p><figure class="kv kw kx ky fd kz er es paragraph-image"><div class="er es ku"><img src="../Images/3ae26b9ec3a81b028005f267924a2163.png" data-original-src="https://miro.medium.com/v2/resize:fit:1250/format:webp/1*k1q0MTIyUFtYH56s3YymHQ.png"/></div><figcaption class="lc ld et er es le lf bd b be z dx translated"><strong class="bd jt">客户端模式</strong></figcaption></figure><p id="2a0a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> yarn-cluster模式</strong> —驱动程序在应用程序主进程内运行，一旦应用程序初始化，客户端就离开</p><figure class="kv kw kx ky fd kz er es paragraph-image"><div class="er es lg"><img src="../Images/17da6e99cf8e46436361b03507ca53ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1186/format:webp/1*oxBbcPVZs0jlEOHPBW1hmQ.png"/></div><figcaption class="lc ld et er es le lf bd b be z dx translated"><strong class="bd jt">集群模式</strong></figcaption></figure><p id="e917" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">核心</strong>:核心是CPU的基本计算单元，一个CPU在给定的时间可以有一个或多个核心来执行任务。内核越多，我们能做的工作就越多。在spark中，这控制了一个执行器可以运行的并行任务的数量。</p><figure class="kv kw kx ky fd kz er es paragraph-image"><div class="er es lh"><img src="../Images/b9c841d27ca4db2b6d814c8192df7e27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1068/format:webp/1*o80WzWJShjCV1RSfWzCiQA.png"/></div><figcaption class="lc ld et er es le lf bd b be z dx translated">集群概述</figcaption></figure><h1 id="0d2c" class="jr js hi bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">Spark作业的集群模式中涉及的步骤</h1><ol class=""><li id="b5b0" class="jd je hi ih b ii kp im kq iq li iu lj iy lk jc ll jj jk jl bi translated">通过驱动程序代码，SparkContext连接到集群管理器(standalone/Mesos/YARN)。</li><li id="c042" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ll jj jk jl bi translated">集群管理器在其他应用程序之间分配资源。任何集群管理器都可以使用，只要执行器进程正在运行并且它们相互通信。</li><li id="819e" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ll jj jk jl bi translated">Spark获取集群中节点上的执行器。在这里，每个应用程序都有自己的执行器进程。</li><li id="9afc" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ll jj jk jl bi translated">应用程序代码(jar/python文件/python egg文件)被发送给每个执行器。</li><li id="5057" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ll jj jk jl bi translated">SparkContext将任务发送给执行者。</li></ol><p id="dbe8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从上面的步骤可以看出，执行人的数量和他们的内存设置在一个spark作业中起着主要作用。运行具有太多内存的执行器通常会导致过多的垃圾收集延迟</p><p id="0574" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们将尝试了解如何配置最佳值集来优化spark作业。</p><p id="3897" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们有两种方式来配置Spark作业的执行器和核心细节。它们是:</p><ol class=""><li id="50ac" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ll jj jk jl bi translated">静态分配—值作为spark-submit的一部分给出</li><li id="efd1" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ll jj jk jl bi translated">动态分配—根据需求(数据大小、所需的计算量)选择值，并在使用后释放。这有助于资源被其他应用程序重用。</li></ol><h1 id="6f87" class="jr js hi bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">静态分配</h1><p id="422b" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated">讨论了不同的情况，根据用户/数据要求改变不同的参数并得到不同的组合。</p><h1 id="df7c" class="jr js hi bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">情形1硬件— 6个节点，每个节点有16个内核，64 GB RAM</h1><p id="60e3" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated">首先，在每个节点上，操作系统和Hadoop守护程序需要1个内核和1 GB内存，因此每个节点有15个内核和63 GB RAM</p><p id="b38c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="lm">我们先从如何选择核数开始</em> : </strong></p><p id="f543" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="lm">内核数量=一个执行者可以运行的并发任务</em></p><p id="4906" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以我们可能会想，每个执行器并发的任务越多，性能越好。但是研究表明，任何超过5个并发任务的应用程序都会导致糟糕的表现。所以最佳值是5。</p><p id="f27f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这个数字来自于执行器运行并行任务的能力，而不是来自于一个系统有多少个内核。因此，即使CPU中有两个(32)内核，数字5也保持不变</p><figure class="kv kw kx ky fd kz er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es ln"><img src="../Images/117cf0495f1d9cc29be18234357a824f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ce468NTOmhd9T3i9wo54lQ.png"/></div></div></figure><p id="62ba" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="lm">执行人数:</em> </strong></p><p id="40cf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下一步，每个执行器有5个内核，一个节点(CPU)中有15个可用内核——我们得出每个节点有3个执行器，即15/5。我们需要计算每个节点上的执行者的数量，然后得到作业的总数。</p><p id="7de4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以有6个节点，每个节点有3个执行器，我们总共有18个执行器。在18个中，我们需要1个执行程序(java进程)用于YARN中的应用程序主程序。所以最后的数字是17个遗嘱执行人</p><p id="49fb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这个17是我们从spark-submit shell命令运行时使用–num-executors给spark的数字</p><p id="4fef" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="lm">每个执行者的内存:</em> </strong></p><p id="61d9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从上面的步骤中，我们每个节点有3个执行者。每个节点上的可用RAM为63 GB</p><p id="e5a9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以每个节点中每个执行器的内存是63/3 = 21GB。</p><p id="0d1a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然而，还需要小的内存开销来确定每个执行器的全部内存请求。</p><p id="09c2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">开销的公式是max(384，. 07 * spark.executor.memory)</p><p id="7f27" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">计算开销:. 07 * 21(此处21是按照上面的63/3计算的)= 1.47</p><p id="fbfd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">由于1.47 GB &gt; 384 MB，开销为1.47</p><p id="c64c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从每张21以上中取上述= &gt; 21–1.47 ~ 19gb</p><p id="d82e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以执行器内存— 19 GB</p><p id="639b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="lm">最终数字—执行器— 17，内核5，执行器内存— 19 GB </em></p><h1 id="0b0c" class="jr js hi bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">情形2硬件— 6个节点，每个节点有32个核心，64 GB</h1><p id="36cd" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated"><strong class="ih hj">内核数量</strong>为5与上面解释的良好并发性相同。</p><p id="39e2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">每个节点的执行者数量</strong>= 32/5 ~ 6</p><p id="d154" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以总执行人= 6 * 6节点= 36。那么最终的数字是36–1(AM)= 35</p><p id="912c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">执行者记忆</strong>:</p><p id="a30e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">每个节点6个执行者。63/6 ~ 10.开销是. 07 * 10 = 700 MB。因此，取1GB作为开销，我们得到10–1 = 9gb</p><p id="bcf4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="lm">最终数字—执行器— 35，内核5，执行器内存— 9 GB </em></p><h1 id="ed16" class="jr js hi bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">情况3 —当执行器不需要更多内存时</h1><p id="2b93" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated">上面的场景从接受固定的内核数量开始，然后转移到执行器和内存的数量。</p><p id="c463" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于第一种情况，如果我们认为我们不需要19 GB，根据数据大小和所涉及的计算，10 GB就足够了，那么数字如下:</p><p id="425a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">核心:5个</p><p id="15af" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">每个节点的执行者数量= 3。尽管如此，15/5如上计算。</p><p id="101c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这个阶段，这将导致21 GB，然后根据我们的第一次计算是19gb。但是既然我们认为10是可以的(假设开销很小)，那么我们不能将每个节点的执行器数量切换到6(比如63/10)。因为如果每个节点有6个执行器和5个内核，那么当我们只有16个内核时，每个节点会有30个内核。所以我们还需要改变每个执行器的内核数量。</p><p id="e5d6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以再计算一下，</p><p id="83fe" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">幻数5等于3(任何小于或等于5的数)。因此，对于3个内核和15个可用内核，我们每个节点有5个执行器，29个执行器(即(5*6 -1))，内存为63/5 ~ 12。</p><p id="8860" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">开销是12 * 07 = . 84。因此执行器内存是12–1gb = 11gb</p><p id="1d8b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="lm">最终数字为29个执行器，3个内核，执行器内存为11 GB </em></p><h1 id="8db1" class="jr js hi bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">一览表</h1><figure class="kv kw kx ky fd kz er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es ls"><img src="../Images/3bb13ddde11ba4a3e3d6f95dff85c7bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VDNzR0sxT1QYJCoERlYCyQ.png"/></div></div><figcaption class="lc ld et er es le lf bd b be z dx translated">汇总统计</figcaption></figure><h1 id="5861" class="jr js hi bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">动态分配</h1><p id="55cd" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated"><em class="lm">注意:启用动态分配时，执行人数量的上限为无穷大。所以这表示，如果需要，spark应用程序可以吃掉所有资源。在运行其他应用程序的集群中，它们也需要内核来运行任务，我们需要确保在集群级别分配内核。</em></p><p id="b1d5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="lm">这意味着我们可以根据用户访问情况为基于纱线的应用分配特定数量的内核。因此，我们可以创建一个spark_user，然后为该用户分配核心(最小/最大)。这些限制用于spark和其他纱线应用程序之间的共享。</em></p><p id="d0fe" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">要理解动态分配，我们需要了解以下属性:</p><p id="5056" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="lm">spark . dynamic allocation . enabled—</em>当设置为true时，我们不需要提及执行者。原因如下:</p><p id="6b25" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们在spark-submit上给出的静态参数数字是针对整个作业持续时间的。但是，如果进行动态分配，将会有如下不同的阶段:</p><p id="c748" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">遗嘱执行人的起始号码是多少:</strong></p><p id="1dc1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">开始时的初始执行器数(<em class="lm">spark . dynamic allocation . initial executors</em>)</p><p id="78c3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">动态控制执行者的数量:</strong></p><p id="fd3b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后根据负载(未决任务)请求多少个执行者。这将最终成为我们在spark-submit上以静态方式给出的数字。因此，一旦设置了初始执行程序编号，我们就进入min(<em class="lm">spark . dynamic allocation . minexecutors</em>)和max(<em class="lm">spark . dynamic allocation . max executors</em>)编号。</p><p id="a515" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">何时询问新遗嘱执行人或放弃当前遗嘱执行人:</strong></p><p id="056a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们什么时候请求新的执行者(<em class="lm">spark . dynamic allocation . schedulerbacklogtimeout</em>)—这意味着已经有这么长时间的未决任务。因此，每一轮请求的执行人数量比前一轮呈指数增长。例如，应用程序将在第一轮中添加1个执行程序，然后在随后的几轮中添加2个、4个、8个等等执行程序。在一个特定的点上，上面的属性max出现了。</p><p id="9037" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们什么时候放弃一个执行者是使用<em class="lm">spark . dynamic allocation . executor idle time out .</em>设置的</p><p id="5ecd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">常见问题清单</strong></p><ul class=""><li id="5c80" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated">足够的并发分区。如果你有20个内核，确保你至少有20个分区或者更多。</li><li id="4b2d" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">通过过滤您需要的数据来最小化内存消耗。</li><li id="00b4" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">最小化混洗的数据量。洗牌很贵。</li><li id="2015" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">了解标准库，在正确的地方使用正确的函数。</li></ul><p id="6b29" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">总之，如果我们需要对作业执行时间进行更多的控制，监控作业中意外的数据量，静态数据会有所帮助。通过迁移到dynamic，资源将在后台使用，涉及意外卷的作业可能会影响其他应用程序。</p><p id="b2a0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">参考资料:</p><p id="62b2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae lt" href="http://spark.apache.org/docs/latest/configuration.html#dynamic-allocation" rel="noopener ugc nofollow" target="_blank">http://spark . Apache . org/docs/latest/configuration . html #动态分配</a></p><p id="611e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae lt" href="http://spark.apache.org/docs/latest/job-scheduling.html#resource-allocation-policy" rel="noopener ugc nofollow" target="_blank">http://spark . Apache . org/docs/latest/job-scheduling . html # resource-allocation-policy</a></p><p id="9c7d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae lt" href="https://blog.cloudera.com/blog/2015/03/how-to-tune-your-apache-spark-jobs-part-2/" rel="noopener ugc nofollow" target="_blank">https://blog . cloud era . com/blog/2015/03/how-to-tune-your-Apache-spark-jobs-part-2/</a></p><div class="lu lv ez fb lw lx"><a href="http://spark.apache.org/docs/latest/cluster-overview.html" rel="noopener  ugc nofollow" target="_blank"><div class="ly ab dw"><div class="lz ab ma cl cj mb"><h2 class="bd hj fi z dy mc ea eb md ed ef hh bi translated">集群模式概述</h2><div class="me l"><h3 class="bd b fi z dy mc ea eb md ed ef dx translated">本文档简要概述了Spark如何在集群上运行，以便更容易理解组件…</h3></div><div class="mf l"><p class="bd b fp z dy mc ea eb md ed ef dx translated">spark.apache.org</p></div></div><div class="mg l"><div class="mh l mi mj mk mg ml la lx"/></div></div></a></div><p id="b5c7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">谢谢塞缪尔·威廉姆帮我做这件事。</p></div></div>    
</body>
</html>