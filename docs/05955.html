<html>
<head>
<title>Vectorized Implementation of Gradient Descent in Linear Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">线性回归中梯度下降的矢量化实现</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/vectorized-implementation-of-gradient-descent-in-linear-regression-12a10ea37210?source=collection_archive---------2-----------------------#2020-05-07">https://medium.com/analytics-vidhya/vectorized-implementation-of-gradient-descent-in-linear-regression-12a10ea37210?source=collection_archive---------2-----------------------#2020-05-07</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="dd6c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">梯度下降算法:</p><p id="1037" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是梯度下降算法，用于确定θ的最佳值，使得成本函数J(θ)最小。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jd"><img src="../Images/941bfafc17be10155cee2eac9203556b.png" data-original-src="https://miro.medium.com/v2/resize:fit:968/format:webp/1*lIthvknHt9Tok5aIj4e__g.png"/></div></figure><p id="6199" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">假设给定了以下X、y和θ值:</p><p id="b553" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">m =训练样本的数量<br/> n =特征的数量+ 1</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jl"><img src="../Images/c0b826a1d2abca5efda2e9b783d8a6de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1306/format:webp/1*n2vxPruMIR9QITp77VL52A.png"/></div></figure><p id="d466" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">m = 5(训练样本总数)<br/> n = 4(特征数+1)<br/>x = m×n矩阵<br/>y = m×1向量<br/>θ= n×1向量<br/> xᶦ是第I个训练样本<br/> xj是给定训练样本中的第j个特征</p><p id="1024" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用矩阵查找错误:</p><p id="5643" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">h(x) = ([X] * [θ])(我们训练集的m x 1个预测值矩阵)<br/> h(x)-y = ([X] * [θ] — [y])(我们预测中的m x 1个误差矩阵)</p><p id="fa33" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">机器学习的全部目标是最小化预测中的错误。</p><p id="e429" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">误差矩阵是m×1向量矩阵，如下所示:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jn jo di jp bf jq"><div class="er es jm"><img src="../Images/1bdc8cb9ebf73721634c5cde91cd4f7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E8PIhhqG0Lsyd7DBxbKVeQ.png"/></div></div></figure><p id="be7f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了计算θj的新值，我们找到所有误差(m行)的总和乘以训练集x的第j个特征值</p><p id="b4b5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">即取E中的所有值，分别乘以对应训练样本的第j个特征，按照梯度下降算法全部相加。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jn jo di jp bf jq"><div class="er es jr"><img src="../Images/ba66fe357c743ba0f578f57a49a52caf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iC9F-nvX_6pc7agid3oYrg.png"/></div></div></figure><p id="5f64" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以进一步简化为:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jn jo di jp bf jq"><div class="er es js"><img src="../Images/6c5c684d87d040cb3676e34a341bec95.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0ntd0b7khnDev3IONEdZyQ.png"/></div></div></figure><p id="d7fe" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">[E]' x [X]会给我们一个行向量矩阵，因为E '是1×m矩阵，X是m×n矩阵。</p><p id="0933" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">但是我们感兴趣的是得到一个列矩阵，因此我们转置得到的矩阵。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jt"><img src="../Images/4de39573a382d519e700ca1ba55660e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1238/format:webp/1*hivTmasjgOhAf9ZTTk-eqg.png"/></div></figure><p id="85c6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最终矢量化方程:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ju"><img src="../Images/22b03595d8a770f0b85b327a291cda2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1190/format:webp/1*pRl_nb8L8WBLQYB463P5fA.png"/></div></figure></div></div>    
</body>
</html>