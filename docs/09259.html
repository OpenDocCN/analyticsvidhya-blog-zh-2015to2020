<html>
<head>
<title>Demystifying Model Variance in Linear Regression-1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">揭开线性回归中模型方差的神秘面纱-1</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/demystifying-model-variance-in-linear-regression-1-4b1a1f3c9a51?source=collection_archive---------16-----------------------#2020-08-30">https://medium.com/analytics-vidhya/demystifying-model-variance-in-linear-regression-1-4b1a1f3c9a51?source=collection_archive---------16-----------------------#2020-08-30</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="ffec" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">在这一系列博客中，我将尝试解构数理统计中的观点，因为我已经直观地理解了它们。这不是回归分析的教程，而是试图将统计学中的概念从复杂的数学语言中带出来，让数据科学家能够理解。</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/2c801fffede3b13c395eac3797a01d14.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*2foz3vM9_b1CeL9t.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated"><strong class="bd jn">代表形象，</strong> <a class="ae jo" href="https://en.wikipedia.org/wiki/Linear_regression#/media/File:Linear_regression.svg" rel="noopener ugc nofollow" target="_blank"> <strong class="bd jn">来源</strong> </a></figcaption></figure><p id="05be" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated"><strong class="jr hj">(向下滚动到 tl 的可视化和代码；博士)</strong></p><h1 id="49ae" class="kl km hi bd jn kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated">设置上下文</h1><p id="68a3" class="pw-post-body-paragraph jp jq hi jr b js lc ij ju jv ld im jx jy le ka kb kc lf ke kf kg lg ki kj kk hb bi translated">考虑线性回归方程</p><blockquote class="lh li lj"><p id="e557" class="jp jq lk jr b js jt ij ju jv jw im jx ll jz ka kb lm kd ke kf ln kh ki kj kk hb bi translated"><strong class="jr hj">y =(β0)+(β1)(x1)+(β2)(x2)+e(~ N(0，σ )) </strong></p></blockquote><p id="8a00" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated"><em class="lk">这里的</em> <strong class="jr hj"> <em class="lk"> y </em> </strong> <em class="lk">是回归变量，</em> <strong class="jr hj"> <em class="lk"> x1 </em> </strong> <em class="lk">是回归变量，</em><em class="lk"/><em class="lk"/><strong class="jr hj"><em class="lk">【β0</em></strong><em class="lk">是截距，</em> <strong class="jr hj"> <em class="lk"> β1 </em> </strong> <em class="lk">是本质上是指 y 对于 x1 的所有值都是固定方差σ正态分布的随机变量，其均值是 x1 → β0+(β1)(x1)的线性函数。参见图 0 </em>和</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="ab fe cl lo"><img src="../Images/bf534ba82e6e038d06e1070888b56b51.png" data-original-src="https://miro.medium.com/v2/0*V4kBB_WzjrFlvhwr"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated"><strong class="bd jn">图 0、</strong> <a class="ae jo" href="http://complx.me/2017-01-22-mle-linear-regression/" rel="noopener ugc nofollow" target="_blank"> <strong class="bd jn">来源</strong> </a></figcaption></figure><p id="1213" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">当使用 OLS 对任何给定数据拟合模型时，<strong class="jr hj">获得的系数本身并不能给出足够的信息。需要评估它们有多可靠。</strong>模型中可能存在估计系数幅度较高的变量，但它们的<strong class="jr hj">“统计显著性”</strong>较低。</p><p id="eb0a" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">问:我们是在谈论拟合模型的准确性吗？</p><blockquote class="lh li lj"><p id="37f6" class="jp jq lk jr b js jt ij ju jv jw im jx ll jz ka kb lm kd ke kf ln kh ki kj kk hb bi translated">答:不，一个模型可以有高的平方误差，或者低的 R 平方，这意味着低的精确度，但是有高度“统计显著性”的变量。</p></blockquote><p id="562c" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">(我们将在后面的部分中更多地讨论变量的<strong class="jr hj">、</strong>统计显著性、平方误差及其与欠拟合/过拟合的关系，现在让我们试着理解模型估计量的<strong class="jr hj">、</strong>。)</p><p id="c30d" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">问:我们是在谈论风险值(X1)还是风险值(X2)？</p><blockquote class="lh li lj"><p id="6ad0" class="jp jq lk jr b js jt ij ju jv jw im jx ll jz ka kb lm kd ke kf ln kh ki kj kk hb bi translated"><strong class="jr hj">答:</strong>不，我们正在讨论估计系数的方差<strong class="jr hj"> β0*和β1* </strong>(我们将使用*符号表示预测值)</p></blockquote><p id="0122" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated"><strong class="jr hj">问:系数怎么会有方差？线性回归不是应该是确定性的吗？每当我用 OLS 模型拟合我的数据时，它每次都给出相同的系数</strong></p><blockquote class="lh li lj"><p id="1c54" class="jp jq lk jr b js jt ij ju jv jw im jx ll jz ka kb lm kd ke kf ln kh ki kj kk hb bi translated"><strong class="jr hj">答:</strong>让我们从了解总体和样本的区别开始。假设样本是从具有固定分布的无限总体中抽取的。我们拥有的数据只是从人群中抽取的样本。样本越大，越接近总体。因此<strong class="jr hj"> 1)具有大量数据点的单个样本的估计参数趋向于实际总体。</strong>对于任何有限的样本量，我们只能不完全地估计总体参数。但是，在 OLS 估计量的情况下，<strong class="jr hj"> 2)大量样本的估计参数的平均值趋向于实际的总体参数。</strong></p><p id="f9be" class="jp jq lk jr b js jt ij ju jv jw im jx ll jz ka kb lm kd ke kf ln kh ki kj kk hb bi translated">对于简单的线性回归，方程<strong class="jr hj"> y=β0+(β1)(x)+e(~N(0，σ )) </strong> <strong class="jr hj">代表假设从中抽取样本的总体</strong>。因此<strong class="jr hj"> β0，β1，σ </strong>是总体的参数。</p><p id="0e4f" class="jp jq lk jr b js jt ij ju jv jw im jx ll jz ka kb lm kd ke kf ln kh ki kj kk hb bi translated">OLS 回归得到的系数<strong class="jr hj"> β0* </strong>和<strong class="jr hj"> β1* </strong>只是基于给定样本的实际总体参数的估计。<strong class="jr hj"> </strong>对于从总体中抽取的每个随机样本，估计参数的不同值。因此在估计的参数中存在<strong class="jr hj">【方差】</strong>。即使实际的总体参数是不同的，对任何给定样本计算的估计值也可以很好地得到。</p></blockquote><h1 id="0d7c" class="kl km hi bd jn kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated"><strong class="ak">估计方差示例</strong></h1><p id="9223" class="pw-post-body-paragraph jp jq hi jr b js lc ij ju jv ld im jx jy le ka kb kc lf ke kf kg lg ki kj kk hb bi translated"><strong class="jr hj">让我们试着想象拟合线的“变化”。</strong>假设总体用<strong class="jr hj"> y=5+x+e(~N(0，9)) </strong>表示。在<strong class="jr hj">图 1 </strong>中，<strong class="jr hj">蓝色</strong>线代表总体的<strong class="jr hj"> y </strong>值的平均值(<strong class="jr hj"> y=5+x </strong>)。我们使用随机数生成器为<strong class="jr hj"> X </strong>和<strong class="jr hj"> e </strong>生成多个大小为<strong class="jr hj"> 50 </strong>的样本，并使用公式<strong class="jr hj"> y=5+x+e </strong>计算<strong class="jr hj"> Y </strong>值。其中一个样本显示为散点图。</p><p id="9c43" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">红色线是通过在这些样本上拟合 OLS 回归得到的。绿色的<strong class="jr hj">线</strong>拟合在散点图显示的特定样本上。向下滚动链接到用于生成图表的 python 代码。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lp"><img src="../Images/8127574f25df2eda472cbebbaabb40d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B1ik3S5QO73OMo5ELmNG3Q.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated"><strong class="bd jn">图一</strong></figcaption></figure><h1 id="a36c" class="kl km hi bd jn kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated"><strong class="ak">深潜</strong></h1><p id="df3b" class="pw-post-body-paragraph jp jq hi jr b js lc ij ju jv ld im jx jy le ka kb kc lf ke kf kg lg ki kj kk hb bi translated">大量样本的<strong class="jr hj">估计参数</strong>的方差本身取决于未知的假设总体的<strong class="jr hj">实际参数</strong>。因此，我们拥有的数据的估计参数和其他统计用于估计方差<strong class="jr hj">、</strong>，假设样本代表总体<strong class="jr hj">、</strong>。</p><p id="697e" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">考虑一下<strong class="jr hj"> Var(β1*)，</strong>的计算公式</p><blockquote class="lh li lj"><p id="c15f" class="jp jq lk jr b js jt ij ju jv jw im jx ll jz ka kb lm kd ke kf ln kh ki kj kk hb bi translated"><strong class="jr hj">Var(β1 *)=(σ)/((n-1)Var(X))</strong></p></blockquote><p id="4e38" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">其中<strong class="jr hj"> σ </strong>估计为均方误差<strong class="jr hj">s =σ(Y-Y *)/(n-2)</strong>，<strong class="jr hj"> n </strong>为样本大小或数据点数，<strong class="jr hj"> Var(X) </strong>为数据在 X 轴上投影的样本方差。<strong class="jr hj"> Var(β1*) </strong>估计为<strong class="jr hj"> (s )/((n-1)Var(X)) </strong></p><p id="a120" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">让我们分析出现在估计<strong class="jr hj"> Var(β1*) </strong>的公式中的比率<strong class="jr hj"> (s )/(Var*(X)) </strong></p><p id="1462" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated"><strong class="jr hj">(s)/(Var(X))比值的极值暗示了什么？</strong></p><h2 id="7fc0" class="lq km hi bd jn lr ls lt kq lu lv lw ku jy lx ly kw kc lz ma ky kg mb mc la md bi translated">在<strong class="ak"> (s )/(Var(X))=0 </strong></h2><blockquote class="lh li lj"><p id="d884" class="jp jq lk jr b js jt ij ju jv jw im jx ll jz ka kb lm kd ke kf ln kh ki kj kk hb bi translated">分子将是 0，这意味着残差将是 0。这意味着拟合线穿过样本中的所有点，如图<strong class="jr hj">图 2 </strong>所示。基于给定的样本，总体位于一条完美的直线上，从总体中抽取的任何样本在回归时都会给出相同的直线，即斜率和截距的方差为<strong class="jr hj"> 0 </strong>。</p></blockquote><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es me"><img src="../Images/d8692246f99a4a5c954a96aab435f487.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Vqmx-YSJn6U-NQUZ5Lk-Ag.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated"><strong class="bd jn">图 2 </strong></figcaption></figure><h2 id="2cc1" class="lq km hi bd jn lr ls lt kq lu lv lw ku jy lx ly kw kc lz ma ky kg mb mc la md bi translated">在<strong class="ak">(s)/(Var(X))→无穷大</strong></h2><blockquote class="lh li lj"><p id="0f3f" class="jp jq lk jr b js jt ij ju jv jw im jx ll jz ka kb lm kd ke kf ln kh ki kj kk hb bi translated">分母变成零。这意味着样本中的 X 值没有变化。所有点都位于一条垂直线上，这条垂直线上表示<strong class="jr hj"> X </strong>的固定值，如图<strong class="jr hj">图 3 </strong>所示。在这种情况下，对于通过这些点的质心的任何线，平方误差<strong class="jr hj"> s </strong>将被最小化到相同的值。由于存在无穷多个解，为了预测的目的，在相关的<strong class="jr hj"> x </strong>值上等价，斜率和截距的方差是无穷的。</p></blockquote><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mf"><img src="../Images/a0e814ec0422c84bc28eb0f6d913d914.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*f76nZjXkdtcmeQLt3aFYkQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated"><strong class="bd jn">图 3 </strong></figcaption></figure><p id="3448" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">在实践中，当<strong class="jr hj"> Var(X) </strong>和残差<strong class="jr hj"> s </strong>之间的反差很大时，从远处看，散点图看起来像<strong class="jr hj">图 2 </strong>或<strong class="jr hj">图 3 </strong>。</p><p id="6c67" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">在这两个极端值之间，存在比率<strong class="jr hj"> (σ )/(Var(X)) </strong>的整个值范围，针对固定样本量<strong class="jr hj"> 50 </strong>和模型方程<strong class="jr hj"> y=5+x+e(~N(0，σ )) </strong>生成以下图表。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mg"><img src="../Images/0b4f2f42dc3c5a6a95ab141fd9d66715.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1fNuDBK17vIcFRgjF_YppA.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated"><strong class="bd jn">图 4 </strong></figcaption></figure><p id="29cc" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">我们只剩下<strong class="jr hj"> Var(β1*) </strong>公式分母中的<strong class="jr hj"> (n-1) </strong>项。</p><blockquote class="lh li lj"><p id="d974" class="jp jq lk jr b js jt ij ju jv jw im jx ll jz ka kb lm kd ke kf ln kh ki kj kk hb bi translated"><strong class="jr hj">Var(β1 *)=(σ)/((n-1)Var(X))</strong></p></blockquote><p id="53de" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">样本量<strong class="jr hj"> n </strong>与方差<strong class="jr hj"> Var(β1*) </strong>成反比关系。可以在<strong class="jr hj">图 5 </strong>中看到，所有的图表都是用同一组总体参数<strong class="jr hj"> β1，β2，σ </strong>生成的，样本量<strong class="jr hj"> n </strong>不同。这与对于大的<strong class="jr hj"> n </strong>样本更接近总体的想法是一致的。所有参数<strong class="jr hj"> β1*、β2*、σ * </strong>的估计值位于其实际值的附近，并且随着<strong class="jr hj"> n、</strong>的增加而更接近于实际值，无论拟合的模型有多差。</p><div class="iy iz ja jb fd ab cb"><figure class="mh jc mi mj mk ml mm paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><img src="../Images/5fbf8b0054f6cfa8ae85b7abdca966f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*3BtxmxhQAxro5g-vJXlSRw.png"/></div></figure><figure class="mh jc mi mj mk ml mm paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><img src="../Images/26c76236933a02d5d9badc5a5e7d83ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*R-sPwvnPOVEfhZ1Nqc4R4Q.png"/></div></figure></div><div class="ab cb"><figure class="mh jc mi mj mk ml mm paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><img src="../Images/16ac83f05c66237d5b71045c53b14999.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*mkf6dFW90K2R5E2Eq6sMcg.png"/></div></figure><figure class="mh jc mi mj mk ml mm paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><img src="../Images/7cfd86eda59914b6579fe2fcf551d764.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*-b2ASUGSl_GtjxuIVt7d9Q.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx mn di mo mp translated"><strong class="bd jn">图 5 </strong></figcaption></figure></div><p id="007e" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">最后，让我们来看看<strong class="jr hj"> Var(β0*)，</strong>它的计算公式为</p><blockquote class="lh li lj"><p id="1054" class="jp jq lk jr b js jt ij ju jv jw im jx ll jz ka kb lm kd ke kf ln kh ki kj kk hb bi translated"><strong class="jr hj">var(β0 *)=(σ){ 1/n+(x̅)/(n-1)var(x)}</strong></p></blockquote><p id="c486" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">这里还有一个额外的因素<strong class="jr hj"> (x̅ ) </strong>，其中<strong class="jr hj">【x̅】</strong>是沿<strong class="jr hj"> X 轴</strong>的样本平均值，其余分量与<strong class="jr hj"> Var(β0*) </strong>的关系类似于<strong class="jr hj"> Var(β1*) </strong>的单调性。<strong class="jr hj">图 6 </strong>显示了沿<strong class="jr hj"> X 轴</strong>移动的两个等效实例。由于拟合线的变化，在<strong class="jr hj"> Y 轴</strong>上截距的<a class="ae jo" href="https://en.wikipedia.org/wiki/Parallax" rel="noopener ugc nofollow" target="_blank"> <strong class="jr hj">视差</strong> </a>对于更大的<strong class="jr hj">|</strong>更大，即沿着<strong class="jr hj"> X 轴</strong>的质心远离原点。换句话说，更高的<strong class="jr hj"> Var(β0*)。</strong></p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mq"><img src="../Images/fbd67b61c6ae71af463c866e32bb1fea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dNI2hTENUTSE30Bn6cQvRg.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated"><strong class="bd jn">图 6 </strong></figcaption></figure><p id="c245" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">(我知道这不是一个令人满意的直觉，拟合线在[x̅ ,y̅ ]并不严格同时。如果有人能帮助我更直观地解释 E[y <strong class="jr hj"> ̅* </strong> |x】的方差依赖于与 x̅的距离，我会很高兴</p><p id="4356" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated"><strong class="jr hj">在下面找到用来生成上图的 python 代码。</strong></p><div class="mr ms ez fb mt mu"><a href="https://github.com/Palash93/VisualizeEstimatorVariance/blob/master/EstimatorVariance.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="mv ab dw"><div class="mw ab mx cl cj my"><h2 class="bd hj fi z dy mz ea eb na ed ef hh bi translated">palash 93/VisualizeEstimatorVariance</h2><div class="nb l"><h3 class="bd b fi z dy mz ea eb na ed ef dx translated">permalink dissolve GitHub 是超过 5000 万开发人员的家园，他们一起工作来托管和审查代码，管理…</h3></div><div class="nc l"><p class="bd b fp z dy mz ea eb na ed ef dx translated">github.com</p></div></div><div class="nd l"><div class="ne l nf ng nh nd ni jh mu"/></div></div></a></div><h1 id="4075" class="kl km hi bd jn kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated">最后</h1><p id="d5a4" class="pw-post-body-paragraph jp jq hi jr b js lc ij ju jv ld im jx jy le ka kb kc lf ke kf kg lg ki kj kk hb bi translated">通过剖析公式和使用可视化，我们看到了估计量的方差与许多因素的关系。在下一部分中，我们将通过引入多个变量使事情变得更加复杂。palash31093@gmail.com 欢迎任何反馈或问题</p><p id="fb32" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated"><strong class="jr hj">(未完待续……)</strong></p></div></div>    
</body>
</html>