<html>
<head>
<title>Wine and Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">葡萄酒和机器学习</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/wine-and-machine-learning-efec11cd4d69?source=collection_archive---------26-----------------------#2020-06-25">https://medium.com/analytics-vidhya/wine-and-machine-learning-efec11cd4d69?source=collection_archive---------26-----------------------#2020-06-25</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/61436fed05320dab3c27b4195b9e861f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/0*i4ldYoCebT2LAWSO"/></div><figcaption class="im in et er es io ip bd b be z dx translated">来源<a class="ae iq" href="https://www.google.com/url?sa=i&amp;url=http%3A%2F%2Fwww.marcelocopello.com%2Fpost%2Fvinho-combate-a-depressao-feminina&amp;psig=AOvVaw0BC_r5w_wNAWpGyDty-CaI&amp;ust=1593180659134000&amp;source=images&amp;cd=vfe&amp;ved=0CAIQjRxqFwoTCJCNsYGWneoCFQAAAAAdAAAAABAJ" rel="noopener ugc nofollow" target="_blank">此处</a></figcaption></figure><p id="745f" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">在这篇文章中，我们将通过一个实际的例子深入研究随机森林分类器。我们将应用随机森林对葡萄酒进行分类！</p><h1 id="7286" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">随机林已恢复</h1><p id="95c4" class="pw-post-body-paragraph ir is hi it b iu kn iw ix iy ko ja jb jc kp je jf jg kq ji jj jk kr jm jn jo hb bi translated"><strong class="it hj"> <em class="ks">随机森林分类器</em> </strong>源自<a class="ae iq" rel="noopener" href="/greyatom/decision-trees-a-simple-way-to-visualize-a-decision-dc506a403aeb"> <strong class="it hj"> <em class="ks">决策树</em> </strong> </a>，基本上，在决策树中我们构建了一棵模拟人类推理的树，如下图所示:</p><figure class="ku kv kw kx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="er es kt"><img src="../Images/7beeb8906ff2a1c1bfecafd6d4132dc0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Xdiw8Gkw8NjV2zuV"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">来源<a class="ae iq" href="https://miro.medium.com/max/1400/0*QwJ2oZssAQ2_cchJ" rel="noopener">此处</a></figcaption></figure><p id="cb95" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">如你所见，我们有节点提出问题，基于这些问题的答案，我们去其他节点。这与人类的推理非常相似，我们提出问题并建立对主题的理解，最终得到答案。</p><p id="8606" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">但是决策树的问题是<a class="ae iq" rel="noopener" href="/@gabriel.mayers/overfitting-explained-in-less-than-5-minutes-441481afe19e"> <strong class="it hj"> <em class="ks">过拟合</em> </strong> </a>，我们的模型只是记忆答案，实际上并没有学习如何产生答案！</p><p id="f4f4" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">基本上，<a class="ae iq" rel="noopener" href="/@gabriel.mayers/overfitting-explained-in-less-than-5-minutes-441481afe19e"> <strong class="it hj"> <em class="ks">过拟合</em> </strong> </a>就是我们的模型在训练集中表现太好，而在测试集中表现太差。</p><p id="da0c" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">更多关于<a class="ae iq" rel="noopener" href="/@gabriel.mayers/overfitting-explained-in-less-than-5-minutes-441481afe19e"> <strong class="it hj"> <em class="ks">过拟合</em> </strong> </a> <a class="ae iq" rel="noopener" href="/@gabriel.mayers/overfitting-explained-in-less-than-5-minutes-441481afe19e">可以在这里</a>阅读。</p><p id="acea" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">虽然决策树是一个强大的算法，但它非常容易受到<a class="ae iq" rel="noopener" href="/@gabriel.mayers/overfitting-explained-in-less-than-5-minutes-441481afe19e"><strong class="it hj"><em class="ks"/></strong></a>的过度拟合。而这也是<strong class="it hj"> <em class="ks">随机森林</em> </strong>存在的原因！</p><p id="5a36" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">在<strong class="it hj"> <em class="ks">随机森林</em> </strong>中，我们构建了一个单独的<a class="ae iq" rel="noopener" href="/greyatom/decision-trees-a-simple-way-to-visualize-a-decision-dc506a403aeb"> <strong class="it hj"> <em class="ks">决策树</em> </strong> </a>来产生一个单独的结果，我们构建了一个森林树来赋予算法在进行预测时进行归纳的能力。</p><p id="f2c9" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">你可以在这里阅读更多关于<strong class="it hj"> <em class="ks">随机森林</em> </strong> <a class="ae iq" href="https://towardsdatascience.com/an-implementation-and-explanation-of-the-random-forest-in-python-77bf308a9b76" rel="noopener" target="_blank">。</a></p><p id="2b96" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">就目前而言，没有什么比通过应用来学习<strong class="it hj"> <em class="ks">随机森林</em> </strong>更好的了</p><h1 id="2eac" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">理解问题</h1><p id="e623" class="pw-post-body-paragraph ir is hi it b iu kn iw ix iy ko ja jb jc kp je jf jg kq ji jj jk kr jm jn jo hb bi translated">我们将使用来自<a class="ae iq" href="https://scikit-learn.org/stable/index.html" rel="noopener ugc nofollow" target="_blank"> sklearn </a>的<a class="ae iq" href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html" rel="noopener ugc nofollow" target="_blank">葡萄酒数据集</a>，我决定使用它，因为加载和理解数据非常简单。</p><p id="0c6b" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">数据集如下所示:</p><figure class="ku kv kw kx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="er es lc"><img src="../Images/3589fd1128d1b89d2f0dd0da2db0d05a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MFzKf6uiLiwlBUuFs1VYNw.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">资料组</figcaption></figure><p id="c114" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">对应于葡萄酒类型的列是“target”，对于这个数据集，我们有3种类型，分别表示为:0、1和2。</p><p id="cbae" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">基本上，我们将应用一个具有所有特征的<strong class="it hj"> <em class="ks">随机森林分类器</em> </strong>，减去目标，基于所有其他特征来预测葡萄酒的目标。</p><p id="f901" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">但是首先，我们需要把我们的数据集分成训练和测试，让我们开始吧！</p><p id="673b" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">我们可以通过使用下面的代码来做到这一点:</p><pre class="ku kv kw kx fd ld le lf lg aw lh bi"><span id="ccf2" class="li jq hi le b fi lj lk l ll lm">from sklearn.model_selection import train_test_split</span><span id="e845" class="li jq hi le b fi ln lk l ll lm">X = data.drop(columns=[‘target’])</span><span id="77bf" class="li jq hi le b fi ln lk l ll lm">y = data[‘target’]</span><span id="6388" class="li jq hi le b fi ln lk l ll lm">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)</span></pre><p id="0121" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">首先，我们从<a class="ae iq" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html" rel="noopener ugc nofollow" target="_blank">sk learn . model _ selection</a>中导入<a class="ae iq" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html" rel="noopener ugc nofollow" target="_blank"> train_test_split </a>，之后，我们将数据集的所有特征设为X，将y设为数据集的目标。我们的数据集中只有178个例子，但这对我们的模型非常有用。之后，我们调用train_test_split传递作为参数，我们的X，y和我们测试的大小，30%。</p><p id="36b0" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">现在，我们已经分割了我们的数据，是时候建立我们的模型了！</p><h1 id="7bf7" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">构建模型</h1><p id="f15a" class="pw-post-body-paragraph ir is hi it b iu kn iw ix iy ko ja jb jc kp je jf jg kq ji jj jk kr jm jn jo hb bi translated">正如您之前看到的，我们将使用随机森林分类器算法。要使用它，我们只需要从s <a class="ae iq" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html" rel="noopener ugc nofollow" target="_blank"> klearn.ensemble </a>中导入，就像下面的代码:</p><pre class="ku kv kw kx fd ld le lf lg aw lh bi"><span id="3d49" class="li jq hi le b fi lj lk l ll lm">from sklearn.ensemble import RandomForestClassifier</span><span id="7bc3" class="li jq hi le b fi ln lk l ll lm">model = RandomForestClassifier()</span></pre><p id="e7c3" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">现在，我们可以使用<em class="ks"> fit() </em>方法passing或<strong class="it hj"> <em class="ks"> X_train </em> </strong>和<strong class="it hj"> <em class="ks"> y_train </em> </strong>来训练我们的模型:</p><pre class="ku kv kw kx fd ld le lf lg aw lh bi"><span id="5600" class="li jq hi le b fi lj lk l ll lm">model.fit(X_train, y_train)</span></pre><p id="7400" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">在训练我们的模型后，我们可以看到使用的参数。我们在实例化RandomForestClassifier()时没有传递任何参数，所以我们的参数将是默认值。</p><figure class="ku kv kw kx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="er es lo"><img src="../Images/d0eda5a8e94994424cce97d1cdc02c78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7istlPpu52IBI4_gTb5L9A.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">模型参数</figcaption></figure><p id="10b9" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">现在，我们已经可以使用我们的模型进行预测了。我们将使用<em class="ks"> predict() </em>方法将X_test作为参数传递，如下面的代码所示:</p><pre class="ku kv kw kx fd ld le lf lg aw lh bi"><span id="c8a9" class="li jq hi le b fi lj lk l ll lm"># Predictions:</span><span id="dded" class="li jq hi le b fi ln lk l ll lm">pred = model.predict(X_test)</span></pre><p id="3f5d" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">现在，我们已经有了模型的预测。我们需要可视化预测的准确性，为了做到这一点，我们可以使用<a class="ae iq" href="https://scikit-learn.org/stable/modules/model_evaluation.html" rel="noopener ugc nofollow" target="_blank"> sklearn.metrics </a>，其中我们有许多工具来测量我们模型的指标。对于这个例子，我将使用<a class="ae iq" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html" rel="noopener ugc nofollow" target="_blank">分类报告</a>和<a class="ae iq" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html" rel="noopener ugc nofollow" target="_blank">混淆矩阵</a>:</p><figure class="ku kv kw kx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="er es lp"><img src="../Images/2677cee9d20ac015843b13d3da813f3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DhRembFEO2cINttsA-dw2A.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">我们模型的度量</figcaption></figure><p id="fdf3" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">我们的预测非常精确！😁</p><p id="3eea" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">现在，我们有了一个表现非常好的模型，可以做预测了！</p><h1 id="8105" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">额外收获:改进模型</h1><p id="b7d0" class="pw-post-body-paragraph ir is hi it b iu kn iw ix iy ko ja jb jc kp je jf jg kq ji jj jk kr jm jn jo hb bi translated">我们有许多方法来改进我们的模型，我将解释最著名和最容易的！</p><blockquote class="lq lr ls"><p id="9a08" class="ir is ks it b iu iv iw ix iy iz ja jb lt jd je jf lu jh ji jj lv jl jm jn jo hb bi translated">注意:我们的模型已经有一个很好的结果，所以很难赶上更好的结果。我个人推荐在准确率低于90%的模型中使用<strong class="it hj"> <em class="hi">网格搜索</em> </strong></p></blockquote><p id="8628" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">为了改进我们的模型，我们可以使用<strong class="it hj"> <em class="ks">网格搜索</em> </strong>。基本上，网格搜索是一种通过反复试验为我们的模型找到最佳参数的技术。好在<a class="ae iq" href="https://scikit-learn.org/stable/index.html" rel="noopener ugc nofollow" target="_blank"> sklearn </a>有支持让网格搜索变得轻松，下面就来看看如何应用吧。</p><p id="c694" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">首先，我们需要导入<a class="ae iq" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html" rel="noopener ugc nofollow" target="_blank"> GridSearchCV </a>并创建一个与我们之前所做的非常相似的过程，但是这一次，我们需要将一个参数列表传递到我们的<strong class="it hj"> <em class="ks">网格搜索</em> </strong>中，如下面的代码所示:</p><pre class="ku kv kw kx fd ld le lf lg aw lh bi"><span id="be9b" class="li jq hi le b fi lj lk l ll lm">from sklearn.model_selection import GridSearchCV</span><span id="61d5" class="li jq hi le b fi ln lk l ll lm"># Parameters for Grid Search:</span><span id="95a1" class="li jq hi le b fi ln lk l ll lm">param_grid = {‘n_estimators’: np.arange(100, 200, 1), ‘criterion’: [‘gini’, ‘entropy’]}</span><span id="4533" class="li jq hi le b fi ln lk l ll lm">model_grid = GridSearchCV(RandomForestClassifier(), param_grid=param_grid, refit=True)</span><span id="a6fd" class="li jq hi le b fi ln lk l ll lm">model_grid.fit(X_train, y_train)</span></pre><p id="52e4" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">现在，我们只需要等待我们的网格模型完成；</p><p id="7e0d" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">完成训练后，我们可以使用<em class="ks">model _ Grid . best _ params _</em>可视化通过<strong class="it hj"> <em class="ks">网格搜索</em> </strong>找到的最佳参数:</p><figure class="ku kv kw kx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="er es lp"><img src="../Images/9690a726194ed0a29c022c5e6e8a6b14.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6w_nJnAzKPpx_xQ6l9wyFQ.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">最佳参数</figcaption></figure><p id="44d3" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">现在，我们可以像以前一样可视化网格模型的指标:</p><figure class="ku kv kw kx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="er es lw"><img src="../Images/d023757924193fa6779d22483432adc6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eM6E9rRZIJx_NkmRdZ_dwA.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">网格模型度量</figcaption></figure><p id="6cfb" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">正如你所看到的，我们的模型没有改进！</p><p id="40e1" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">发生这种情况是因为我们在第一个模型中已经有了很好的精度，在<strong class="it hj"> <em class="ks">网格搜索</em> </strong>之前，很难再提高一个太好的精度。</p><p id="5b23" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">希望你已经设法理解了<strong class="it hj"> <em class="ks">随机森林</em> </strong>的工作原理以及如何应用！</p><p id="6161" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">目前，这就是全部！</p><p id="c3f4" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">下次见！</p></div><div class="ab cl lx ly gp lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="hb hc hd he hf"><div class="ku kv kw kx fd me"><a href="https://mailchi.mp/42ad4556e7c5/sub-medium" rel="noopener  ugc nofollow" target="_blank"><div class="mf ab dw"><div class="mg ab mh cl cj mi"><h2 class="bd hj fi z dy mj ea eb mk ed ef hh bi translated">在我的VIP内容列表订阅！</h2><div class="ml l"><h3 class="bd b fi z dy mj ea eb mk ed ef dx translated">天天独家AI，宝贝！n</h3></div><div class="mm l"><p class="bd b fp z dy mj ea eb mk ed ef dx translated">mailchi.mp</p></div></div></div></a></div><h1 id="762f" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">在社交网络上与我联系</h1><p id="e792" class="pw-post-body-paragraph ir is hi it b iu kn iw ix iy ko ja jb jc kp je jf jg kq ji jj jk kr jm jn jo hb bi translated">https://www.linkedin.com/in/gabriel-mayer-779b5a162/<strong class="it hj"><em class="ks">领英:</em> </strong> <em class="ks"> </em> <a class="ae iq" href="https://www.linkedin.com/in/gabriel-mayer-779b5a162/" rel="noopener ugc nofollow" target="_blank"/></p><p id="3358" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">github:<a class="ae iq" href="https://github.com/gabrielmayers" rel="noopener ugc nofollow" target="_blank">https://github.com/gabrielmayers</a></p><p id="b5aa" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">https://www.instagram.com/gabrielmayerl/<strong class="it hj"><em class="ks">insta gram:</em></strong><a class="ae iq" href="https://www.instagram.com/gabrielmayerl/" rel="noopener ugc nofollow" target="_blank"/></p></div></div>    
</body>
</html>