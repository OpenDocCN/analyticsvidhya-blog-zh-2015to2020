<html>
<head>
<title>How to Calculate Confusion Matrix Manually.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何手动计算混淆矩阵？</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/how-to-calculate-confusion-matrix-manually-14292c802f52?source=collection_archive---------3-----------------------#2020-07-01">https://medium.com/analytics-vidhya/how-to-calculate-confusion-matrix-manually-14292c802f52?source=collection_archive---------3-----------------------#2020-07-01</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/c8135089498d94e272c17b61d6f217d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:968/format:webp/1*r6nB0oqR7xtm_p-ZfBB1yg.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">混淆矩阵图</figcaption></figure><p id="43a9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了正确理解这些术语，我将举一个简单的二元分类问题。比方说，我们的数据集包含一个电子商务网站的产品评论。每个评论都有一个标签，要么是正面的(1)，要么是负面的(0)。我们的任务是分类一个评论是正面的还是负面的。让我们假设，使用不同的NLP技术，我们已经建立了一个好的/坏的模型，可以以某种方式预测标签。例如，下面的CSV文件快照是我们的模型做出预测后，我们的<strong class="is hj">实际</strong>和<strong class="is hj">预测</strong>标签的样本。</p><figure class="jp jq jr js fd ij er es paragraph-image"><div class="er es jo"><img src="../Images/cf8ce8c1c70e56e6c048328fb0055ad7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1038/format:webp/1*AtF9-0GxWKxFjxTdeBY00g.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated"><strong class="bd jt">图1: </strong>我们的样本产品根据实际标签审查预测</figcaption></figure><p id="c204" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这个数据集中，<strong class="is hj"> 0 </strong>表示负面评价，<strong class="is hj"> 1 </strong>表示正面评价。这里，我们使用机器学习模型获得了我们预测的标签。在本文中，我不会解释任何机器学习模型或训练/测试阶段。</p><p id="2d64" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果你计算一下<code class="du ju jv jw jx b">true_label</code>，你会发现有10个正面评价(<strong class="is hj"> 1 </strong>)和10个负面评价(<strong class="is hj"> 0 </strong>)。在下一列(<code class="du ju jv jw jx b">predicted_label</code>)，我们有我们的机器学习模型做出的预测。这些值与实际标签不完全相同(<code class="du ju jv jw jx b">true_label</code>)。</p><p id="3aa8" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">你可能已经在别的地方看到过我们计算混淆矩阵使用:<br/> <strong class="is hj"> TP </strong>(真正)<br/> <strong class="is hj"> TN </strong>(真负)<br/> <strong class="is hj"> FP </strong>(假正)<br/> <strong class="is hj"> FN </strong>(假负)</p><p id="6f37" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这些价值是什么？</p><h2 id="504b" class="jy jz hi bd jt ka kb kc kd ke kf kg kh jb ki kj kk jf kl km kn jj ko kp kq kr bi translated">真阳性(TP)</h2><p id="5706" class="pw-post-body-paragraph iq ir hi is b it ks iv iw ix kt iz ja jb ku jd je jf kv jh ji jj kw jl jm jn hb bi translated">当实际标签(<code class="du ju jv jw jx b">true_label</code>)为正(1)，并且你的机器学习模型也预测该标签为正(1)。<br/>在我们的CSV文件快照中，在<code class="du ju jv jw jx b"><strong class="is hj">sample review 4</strong>,</code>中，我们的实际标签为正(1)，我们的模型也预测审核为正(1)。所以，它是一个<strong class="is hj"> TP </strong>值。</p><h2 id="1298" class="jy jz hi bd jt ka kb kc kd ke kf kg kh jb ki kj kk jf kl km kn jj ko kp kq kr bi translated">真阴性(TN)</h2><p id="5097" class="pw-post-body-paragraph iq ir hi is b it ks iv iw ix kt iz ja jb ku jd je jf kv jh ji jj kw jl jm jn hb bi translated">当实际标签(<code class="du ju jv jw jx b">true_label</code>)为负(0)，而你的机器学习模型也预测该标签为负(0)时。<br/>在我们的CSV文件快照中，在<code class="du ju jv jw jx b"><strong class="is hj">sample review 2</strong>,</code>中，我们的实际标签为负(0)，我们的模型也预测该评论为负(0)。所以，它是一个<strong class="is hj"> TN </strong>值。</p><h2 id="20df" class="jy jz hi bd jt ka kb kc kd ke kf kg kh jb ki kj kk jf kl km kn jj ko kp kq kr bi translated">假阳性</h2><p id="9429" class="pw-post-body-paragraph iq ir hi is b it ks iv iw ix kt iz ja jb ku jd je jf kv jh ji jj kw jl jm jn hb bi translated">当实际标签(<code class="du ju jv jw jx b">true_label</code>)为负(0)，但你的机器学习模型预测该标签为正(1)。<br/>在我们的CSV文件快照中，在<code class="du ju jv jw jx b"><strong class="is hj">sample review 1</strong>,</code>中，我们的实际标签为负(0)，但我们的模型预测该评论为正(1)。所以，它是一个<strong class="is hj"> FP </strong>值。</p><h2 id="6497" class="jy jz hi bd jt ka kb kc kd ke kf kg kh jb ki kj kk jf kl km kn jj ko kp kq kr bi translated">假阴性(FN)</h2><p id="b030" class="pw-post-body-paragraph iq ir hi is b it ks iv iw ix kt iz ja jb ku jd je jf kv jh ji jj kw jl jm jn hb bi translated">当实际标签为正(1)，但您的机器学习模型预测该标签为负(0)时。<br/>在我们的CSV文件快照中，在<code class="du ju jv jw jx b"><strong class="is hj">sample review 3</strong>,</code>中，我们的实际标签(<code class="du ju jv jw jx b">true_label</code>)为正(1)，但我们的模型预测该审查为负(0)。所以，它是一个<strong class="is hj"> FN </strong>值。</p><h1 id="da55" class="kx jz hi bd jt ky kz la kd lb lc ld kh le lf lg kk lh li lj kn lk ll lm kq ln bi translated">计算混淆矩阵</h1><p id="dcb0" class="pw-post-body-paragraph iq ir hi is b it ks iv iw ix kt iz ja jb ku jd je jf kv jh ji jj kw jl jm jn hb bi translated">现在，你知道哪些值是什么了！</p><figure class="jp jq jr js fd ij er es paragraph-image"><div class="er es lo"><img src="../Images/f1191add334759079fe5873117cbe1aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1322/format:webp/1*ffGdT-r9jwZSrPD5_h-rjw.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated"><strong class="bd jt">图2: </strong>我们模型预测的TP、TN、FP、FN值</figcaption></figure><p id="90c2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">当你理解了这一点，剩下的事情就只是简单的数学了。</p><p id="884c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在我们的例子中，(根据图2计算):<br/>TP的总值:7<br/>TN的总值:6<br/>FP的总值:4<br/>FN的总值:3</p><h2 id="117a" class="jy jz hi bd jt ka kb kc kd ke kf kg kh jb ki kj kk jf kl km kn jj ko kp kq kr bi translated">计算准确度</h2><p id="e862" class="pw-post-body-paragraph iq ir hi is b it ks iv iw ix kt iz ja jb ku jd je jf kv jh ji jj kw jl jm jn hb bi translated">计算模型精度的公式:</p><figure class="jp jq jr js fd ij er es paragraph-image"><div class="er es lp"><img src="../Images/3e41484caee79593d2d604bf58ccf101.png" data-original-src="https://miro.medium.com/v2/resize:fit:766/format:webp/1*cYMFZqO2tY_rSPRE7TtD6g.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">计算精度的公式</figcaption></figure><p id="a674" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果您将这些项的值放入上面的公式中，并进行简单的数学计算，您将获得精确度数字。在我们的例子中，它是:<strong class="is hj"> 0.65 <br/> </strong>这意味着准确率是65%。</p></div><div class="ab cl lq lr gp ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="hb hc hd he hf"><h2 id="85e9" class="jy jz hi bd jt ka kb kc kd ke kf kg kh jb ki kj kk jf kl km kn jj ko kp kq kr bi translated">计算精度</h2><p id="829d" class="pw-post-body-paragraph iq ir hi is b it ks iv iw ix kt iz ja jb ku jd je jf kv jh ji jj kw jl jm jn hb bi translated">计算模型精度的公式:</p><figure class="jp jq jr js fd ij er es paragraph-image"><div class="er es lx"><img src="../Images/eca57ec967492ff0bb52218b2accdc0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:330/format:webp/1*jMFfPfJ856vZ_3QqEchmtA.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">计算精度的公式</figcaption></figure><p id="3b82" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">替换这些项的值，并计算简单的数学，它将是<strong class="is hj"> 0.636 </strong></p></div><div class="ab cl lq lr gp ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="hb hc hd he hf"><h2 id="6a0f" class="jy jz hi bd jt ka kb kc kd ke kf kg kh jb ki kj kk jf kl km kn jj ko kp kq kr bi translated">计算召回率|敏感度|真阳性率— TPR</h2><figure class="jp jq jr js fd ij er es paragraph-image"><div class="er es ly"><img src="../Images/0cbc4dd527f05f7da107f06016e2794f.png" data-original-src="https://miro.medium.com/v2/resize:fit:342/format:webp/1*ShhcXtLE3lWZAgjpzWEscw.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">计算召回率或敏感度的公式</figcaption></figure><p id="0c9a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">替换这些项的值，并计算简单的数学，它将是<strong class="is hj"> 0.70 </strong></p></div><div class="ab cl lq lr gp ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="hb hc hd he hf"><h2 id="7f7c" class="jy jz hi bd jt ka kb kc kd ke kf kg kh jb ki kj kk jf kl km kn jj ko kp kq kr bi translated">计算F1分数</h2><figure class="jp jq jr js fd ij er es paragraph-image"><div class="er es lz"><img src="../Images/1b65dbae27b6a36b12a3398277936d80.png" data-original-src="https://miro.medium.com/v2/resize:fit:566/format:webp/1*LPdMAVkbtpZ1bDY9kOoK3Q.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">计算F1分数的公式</figcaption></figure><p id="5136" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">替换这些项的值，并计算简单的数学，它将是<strong class="is hj"> 0.667 </strong></p></div><div class="ab cl lq lr gp ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="hb hc hd he hf"><h2 id="ed0a" class="jy jz hi bd jt ka kb kc kd ke kf kg kh jb ki kj kk jf kl km kn jj ko kp kq kr bi translated">计算误报率-FPR</h2><figure class="jp jq jr js fd ij er es paragraph-image"><div class="er es ma"><img src="../Images/d66edd417b3698df2448edbfacf81719.png" data-original-src="https://miro.medium.com/v2/resize:fit:322/format:webp/1*acsyjUI-gwGHwHAys0MRsw.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">计算FPR的公式</figcaption></figure><p id="21f7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">替换这些项的值，并计算简单的数学，它将是<strong class="is hj"> 0.4 </strong></p></div><div class="ab cl lq lr gp ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="hb hc hd he hf"><h2 id="021f" class="jy jz hi bd jt ka kb kc kd ke kf kg kh jb ki kj kk jf kl km kn jj ko kp kq kr bi translated">受试者工作特征曲线</h2><p id="6953" class="pw-post-body-paragraph iq ir hi is b it ks iv iw ix kt iz ja jb ku jd je jf kv jh ji jj kw jl jm jn hb bi translated">它是通过在X轴绘制假阳性率(FPR ),在y轴绘制真阳性率(TPR)而生成的图。</p></div><div class="ab cl lq lr gp ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="hb hc hd he hf"><p id="89e8" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">作者:萨德曼·卡比尔·苏米克<br/>领英:<a class="ae mb" href="https://www.linkedin.com/in/sksoumik/" rel="noopener ugc nofollow" target="_blank">https://www.linkedin.com/in/sksoumik</a></p></div></div>    
</body>
</html>