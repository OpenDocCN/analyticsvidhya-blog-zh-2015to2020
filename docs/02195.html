<html>
<head>
<title>Predict Retinal Disease With CNN(Retinal OCT Images Dataset)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用CNN(视网膜OCT图像数据集)预测视网膜疾病</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/predict-retinal-disease-with-cnn-retinal-oct-images-dataset-6df09cb50206?source=collection_archive---------8-----------------------#2019-12-05">https://medium.com/analytics-vidhya/predict-retinal-disease-with-cnn-retinal-oct-images-dataset-6df09cb50206?source=collection_archive---------8-----------------------#2019-12-05</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="3ab5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本文中，我们将建立一个分类器来检测不同的视网膜疾病。</p><blockquote class="jd je jf"><p id="eef7" class="if ig jg ih b ii ij ik il im in io ip jh ir is it ji iv iw ix jj iz ja jb jc hb bi translated"><strong class="ih hj">概要:</strong></p><p id="b5d5" class="if ig jg ih b ii ij ik il im in io ip jh ir is it ji iv iw ix jj iz ja jb jc hb bi translated">视网膜光学相干断层扫描(OCT)是一种用于捕捉活着的患者的视网膜的高分辨率横截面的成像技术。可以区分视网膜内的层，并且可以测量视网膜厚度，以帮助视网膜疾病和状况的早期检测和诊断。OCT测试已经成为评估和治疗大多数视网膜疾病的标准护理。OCT使用光线来测量视网膜厚度。在这项测试中没有使用辐射或X射线，OCT扫描不会造成伤害，也不会让人不舒服。每年大约进行3000万次OCT扫描，这些图像的分析和解释占用了大量时间(Swanson和Fujimoto，2017)。</p></blockquote><h2 id="3f4c" class="jk jl hi bd jm jn jo jp jq jr js jt ju iq jv jw jx iu jy jz ka iy kb kc kd ke bi translated">数据集详细信息:</h2><p id="076a" class="pw-post-body-paragraph if ig hi ih b ii kf ik il im kg io ip iq kh is it iu ki iw ix iy kj ja jb jc hb bi translated">数据集包含每个图像类别(正常、CNV、DME、DRUSEN)的子文件夹。有84，495个X射线图像(JPEG)和4个类别(正常，CNV，DME，玻璃疣)。</p><p id="5ff0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">视网膜oct图像分为四类。它们列在下面-</p><figure class="kl km kn ko fd kp er es paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="er es kk"><img src="../Images/e90019d198d52cc90aa49af6b20bbd68.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DJFYw2oBjCyF28lJga-N-Q.png"/></div></div><figcaption class="kw kx et er es ky kz bd b be z dx translated">来源:https://i.imgur.com/fSTeZMd.png<a class="ae la" href="https://i.imgur.com/fSTeZMd.png" rel="noopener ugc nofollow" target="_blank"/></figcaption></figure><p id="73ec" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 1)脉络膜新生血管(CNV) : </strong>脉络膜新生血管(CNV)是在<a class="ae la" href="https://en.wikipedia.org/wiki/Human_eye" rel="noopener ugc nofollow" target="_blank">眼</a>的<a class="ae la" href="https://en.wikipedia.org/wiki/Choroid" rel="noopener ugc nofollow" target="_blank">脉络膜</a>层产生新的血管。脉络膜新生血管化是新生血管变性黄斑病变(即“湿性”黄斑变性)的常见原因，其通常因极度近视、恶性近视变性或年龄相关的发展而加剧。</p><p id="70e3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 2)糖尿病性黄斑水肿(DME) : </strong>糖尿病性黄斑水肿(DME)是由于血管渗漏而在黄斑(视网膜的一部分，控制我们最详细的视觉能力)中积聚的液体。为了发展DME，您必须首先患有糖尿病视网膜病变。糖尿病视网膜病变是一种损害视网膜血管的疾病，导致视力损害。如果不治疗，这些血管开始在眼睛中积聚压力并泄漏液体，导致DME</p><p id="4b07" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 3)玻璃疣(玻璃疣):</strong>玻璃疣是<a class="ae la" href="https://www.aao.org/eye-health/anatomy/retina-list" rel="noopener ugc nofollow" target="_blank">视网膜下的黄色沉积物</a>。玻璃疣是由脂质，一种脂肪蛋白质组成的。玻璃疣可能不会导致<a class="ae la" href="https://www.aao.org/eye-health/diseases/age-related-macular-degeneration" rel="noopener ugc nofollow" target="_blank">老年性黄斑变性</a>。</p><p id="d8c6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">但是患有玻璃疣会增加一个人患AMD的风险。有不同种类的德鲁森。“硬”德鲁斯人很小，与众不同，彼此远离。这种类型的德鲁森可能不会导致长期的视力问题，如果有的话。</p><p id="c8a7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">“软”德鲁斯人很大，聚集在一起。他们的边缘不像坚硬的玻璃疣那样清晰。这种软性玻璃膜疣增加了患AMD的风险。</p><p id="7d0e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 4)正常眼睛视网膜(正常):</strong>具有保留的视网膜中央凹轮廓且没有任何视网膜液体/水肿的正常视网膜。</p><p id="78a1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">项目概述:</strong>在这里，我们将建立一个分类器，它将预测四类(CNV，DME，德鲁森，正常)中的一类。首先，我们将准备数据集。这里我们将使用卷积神经网络(CNN)来预测类别。</p><figure class="kl km kn ko fd kp er es paragraph-image"><div class="er es lb"><img src="../Images/dc9da9f31228b1168881e5ffcd0646c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1074/format:webp/1*ZNU8XGK88j-QwdHjjkP2pg.png"/></div><figcaption class="kw kx et er es ky kz bd b be z dx translated">数据集文件夹结构</figcaption></figure><p id="1ac4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是一个多类分类问题。对于这个医学问题，我们希望错误尽可能低，即高精度和高召回率。所以，我们采取了<a class="ae la" href="https://datascience.stackexchange.com/questions/15989/micro-average-vs-macro-average-performance-in-a-multiclass-classification-settin" rel="noopener ugc nofollow" target="_blank">f1-微avg </a>。作为公制。</p><p id="2c53" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> GitHub Repo: </strong> <a class="ae la" href="https://github.com/subhande/Retinal-OCT-Images" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">视网膜OCT图像</strong> </a></p><p id="8259" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">工作流程:</strong></p><ol class=""><li id="5b3e" class="lc ld hi ih b ii ij im in iq le iu lf iy lg jc lh li lj lk bi translated">数据准备</li><li id="aaa2" class="lc ld hi ih b ii ll im lm iq ln iu lo iy lp jc lh li lj lk bi translated">数据分析</li><li id="3c03" class="lc ld hi ih b ii ll im lm iq ln iu lo iy lp jc lh li lj lk bi translated">数据预处理</li><li id="dde5" class="lc ld hi ih b ii ll im lm iq ln iu lo iy lp jc lh li lj lk bi translated">CNN模型</li><li id="1e97" class="lc ld hi ih b ii ll im lm iq ln iu lo iy lp jc lh li lj lk bi translated">比较各型号的性能</li></ol><h1 id="da24" class="lq jl hi bd jm lr ls lt jq lu lv lw ju lx ly lz jx ma mb mc ka md me mf kd mg bi translated"><strong class="ak">数据准备:</strong></h1><p id="717b" class="pw-post-body-paragraph if ig hi ih b ii kf ik il im kg io ip iq kh is it iu ki iw ix iy kj ja jb jc hb bi translated">这里我们有84，495张图片，每张图片都属于相应的文件夹。我们将创建一个包含filename、filepath和class列的dataframe文件。</p><figure class="kl km kn ko fd kp"><div class="bz dy l di"><div class="mh mi l"/></div></figure><h1 id="c6ef" class="lq jl hi bd jm lr ls lt jq lu lv lw ju lx ly lz jx ma mb mc ka md me mf kd mg bi translated"><strong class="ak">数据分析:</strong></h1><figure class="kl km kn ko fd kp er es paragraph-image"><div class="er es mj"><img src="../Images/79af886838139ddf8ea2047725f00165.png" data-original-src="https://miro.medium.com/v2/resize:fit:822/format:webp/1*cOGpeZMRPzqgX-z9yrEhHg.png"/></div><figcaption class="kw kx et er es ky kz bd b be z dx translated">整个数据集的类别分布</figcaption></figure><p id="8678" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在分析了数据之后，从左侧的图像中，我们可以清楚地看出这是一个不平衡的数据集问题。这里DME和德鲁森类的图像非常少。</p><h1 id="bdf6" class="lq jl hi bd jm lr ls lt jq lu lv lw ju lx ly lz jx ma mb mc ka md me mf kd mg bi translated"><strong class="ak">数据预处理:</strong></h1><p id="30af" class="pw-post-body-paragraph if ig hi ih b ii kf ik il im kg io ip iq kh is it iu ki iw ix iy kj ja jb jc hb bi translated">这里，我们必须在将图像输入CNN模型之前对其进行预处理。</p><figure class="kl km kn ko fd kp"><div class="bz dy l di"><div class="mh mi l"/></div></figure><p id="4441" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里我们创建了一个名为imageToArray的函数，它将图像转换为3D数组。每个图像的高度和宽度都被调整为224像素，并对数组进行了规范化。所以最后每个图像转换成224*224*3的数组。在这个数据集中，我们有84，495个图像，我们无法将所有图像加载到主内存中，因此，我们已经加载了图像，并将其成批转换到数组bactch。在这里，我们创建了imageLoader函数，用于批量加载图像。</p><h1 id="4769" class="lq jl hi bd jm lr ls lt jq lu lv lw ju lx ly lz jx ma mb mc ka md me mf kd mg bi translated"><strong class="ak"> CNN型号:</strong></h1><p id="a80a" class="pw-post-body-paragraph if ig hi ih b ii kf ik il im kg io ip iq kh is it iu ki iw ix iy kj ja jb jc hb bi translated">在<a class="ae la" href="https://en.wikipedia.org/wiki/Deep_learning" rel="noopener ugc nofollow" target="_blank">深度学习</a>中，<strong class="ih hj">卷积神经网络</strong> ( <strong class="ih hj"> CNN </strong>，或<strong class="ih hj"> ConvNet </strong>)是一类深度神经网络，最常用于分析视觉意象。基于它们的共享权重架构和平移不变性特征，它们也被称为<strong class="ih hj">移位不变</strong>或<strong class="ih hj">空间不变人工神经网络</strong> ( <strong class="ih hj"> SIANN </strong>)。它们在图像和视频识别、推荐系统、图像分类、医学图像分析和自然语言处理中有应用。</p><figure class="kl km kn ko fd kp er es paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="er es mk"><img src="../Images/d3fac43fc6926d91875044d625750815.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F2Ik_XFzmu5jZF-byiAKQQ.jpeg"/></div></div><figcaption class="kw kx et er es ky kz bd b be z dx translated">来源:<a class="ae la" href="https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53" rel="noopener" target="_blank">https://towards data science . com/a-comprehensive-guide-to-convolutionary-neural-networks-the-Eli 5-way-3bd 2b 1164 a53</a></figcaption></figure><p id="423d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">迁移学习是一种技术，我们将使用现有的预训练CNN模型。迁移学习技术可分为以下几种类型</p><p id="1022" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">a)获取在ImageNet上预先训练的CNN模型，移除最后一个全连接层，然后将CNN的其余部分视为新数据集的固定特征提取器，并为数据集构建自定义全连接层。</p><p id="27f4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">b)获取在ImageNet上预训练的CNN模型，移除最后一个完全连接的层，然后解冻最后几个层，并在顶部连接自定义完全连接的层，并在新数据集上微调该模型。</p><figure class="kl km kn ko fd kp er es paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="er es ml"><img src="../Images/0a08f2704af5a4bc5e53beff302ad117.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*avpxkiWV6wy-gqreOJGy2A.png"/></div></div><figcaption class="kw kx et er es ky kz bd b be z dx translated">来源:<a class="ae la" href="https://www.researchgate.net/figure/TOP-LEVEL-DIAGRAM-OF-TRANSFER-LEARNING-FROM-A-PRE-TRAINED-CNN-MODEL_fig4_333882146" rel="noopener ugc nofollow" target="_blank">https://www . research gate . net/figure/TOP-LEVEL-DIAGRAM-OF-TRANSFER-LEARNING-FROM-A-PRE-TRAINED-CNN-MODEL _ fig 4 _ 333882146</a></figcaption></figure><p id="1f0b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里我们将使用5个CNN模型，其中最后3个模型将使用迁移学习技术。</p><p id="8fc8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因为我们没有所需的资源和时间来训练84k图像。所以，我们在这里取了60000个图像样本，它们的类别分布与整个数据中的相同。<br/>我们将数据分成三部分，即训练(72.5%) —验证(12.75%) —测试数据(15%)</p><ol class=""><li id="5915" class="lc ld hi ih b ii ij im in iq le iu lf iy lg jc lh li lj lk bi translated"><strong class="ih hj"> 3层定制CNN型号:</strong></li></ol><figure class="kl km kn ko fd kp"><div class="bz dy l di"><div class="mh mi l"/></div></figure><figure class="kl km kn ko fd kp"><div class="bz dy l di"><div class="mh mi l"/></div></figure><p id="38eb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里我们训练了一个3层CNN模型。我们在conv层使用了具有相同填充的3*3内核，还使用了maxpool和avgmeanpool层。我们用Adam optimizer训练了这个模型。</p><p id="b0ec" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们使用了早期停止来防止模型过拟合，使用了ReduceLROnPlateau来降低一个时期内没有改善的验证损失后的学习率，使用了模型检查点来保存模型。</p><figure class="kl km kn ko fd kp er es paragraph-image"><div class="er es mm"><img src="../Images/b92ad9538d799eafe30dd9bdc810aa13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1336/format:webp/1*f1a8nVqjBc0dEQEY0eS4uw.png"/></div></figure><figure class="kl km kn ko fd kp er es paragraph-image"><div class="er es mm"><img src="../Images/aa008b871a7076e82f86eb48ab8cc540.png" data-original-src="https://miro.medium.com/v2/resize:fit:1336/format:webp/1*tmKFFLbgKZ9ggqOHIQQ_sQ.png"/></div></figure><pre class="kl km kn ko fd mn mo mp mq aw mr bi"><span id="a24d" class="jk jl hi mo b fi ms mt l mu mv"><strong class="mo hj">Train F1-micro avg score :  0.9296<br/>Val F1-micro avg score :  0.9199<br/>Test F1-micro avg score :  0.9203</strong></span></pre><figure class="kl km kn ko fd kp er es paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="er es mw"><img src="../Images/6a20a44272278709774e1b96ef119b23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5Q8ChkLfyZJMloHfk6VLXQ.png"/></div></div></figure><h1 id="efe3" class="lq jl hi bd jm lr ls lt jq lu lv lw ju lx ly lz jx ma mb mc ka md me mf kd mg bi translated"><strong class="ak"> 2。7层CNN型号:</strong></h1><figure class="kl km kn ko fd kp"><div class="bz dy l di"><div class="mh mi l"/></div></figure><p id="0d83" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里我们训练了一个7层CNN模型。我们在conv层使用了具有相同填充的3*3内核，还使用了maxpool和avgmeanpool层。我们用Adam optimizer训练了这个模型。</p><figure class="kl km kn ko fd kp er es paragraph-image"><div class="er es mx"><img src="../Images/30d9ddf7ff9a00e7eea64a8a705c1acb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1350/format:webp/1*NFwr8asqe1a__iIuzQ2yQA.png"/></div></figure><figure class="kl km kn ko fd kp er es paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="er es my"><img src="../Images/62c26fa40f1c4e3b0d8ff4c1bb0a4a40.png" data-original-src="https://miro.medium.com/v2/resize:fit:1348/format:webp/1*rbzGA9HyVTHAwU-7QEWCcg.png"/></div></div></figure><pre class="kl km kn ko fd mn mo mp mq aw mr bi"><span id="405c" class="jk jl hi mo b fi ms mt l mu mv"><strong class="mo hj">Train F1-micro avg score :  0.9649<br/>Val F1-micro avg score :  0.9542<br/>Test F1-micro avg score :  0.9582</strong></span></pre><figure class="kl km kn ko fd kp er es paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="er es mw"><img src="../Images/630f99d861a4308c3c8f6257a2c529ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IH852rz3zbM1sAoFLJEK0Q.png"/></div></div></figure><p id="2653" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们从3层CNN到7层CNN模型改进了很多。精确度、召回率和f1-micro评分都比以前的CNN模型有所提高。接下来，我们将尝试迁移学习，即我们将使用预训练作为基础模型。</p><h1 id="b477" class="lq jl hi bd jm lr ls lt jq lu lv lw ju lx ly lz jx ma mb mc ka md me mf kd mg bi translated"><strong class="ak"> 3) VGG16迁移学习:</strong></h1><figure class="kl km kn ko fd kp"><div class="bz dy l di"><div class="mh mi l"/></div></figure><p id="329a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里，我们使用了一个预训练模型，即没有完全连接层的VGG16。我们为4类分类问题添加了自定义的全连接层。我们在训练时冻结了预训练的模型重量。</p><figure class="kl km kn ko fd kp er es paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="er es my"><img src="../Images/33b4e73aef4ae516016f4c77ef8d65d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1348/format:webp/1*XbS4YRnna9lEBhuf2NkP6g.png"/></div></div></figure><figure class="kl km kn ko fd kp er es paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="er es my"><img src="../Images/5a0ec8acd2dbbe601806a8be25a340df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1348/format:webp/1*p76ArV9HfBBPCz3O4ldqKw.png"/></div></div></figure><pre class="kl km kn ko fd mn mo mp mq aw mr bi"><span id="213b" class="jk jl hi mo b fi ms mt l mu mv"><strong class="mo hj">Train F1-micro avg score :  0.9298<br/>Val F1-micro avg score :  0.9071<br/>Test F1-micro avg score :  0.9089</strong></span></pre><figure class="kl km kn ko fd kp er es paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="er es mw"><img src="../Images/9d627634ef0771d7c4b23d075f3819a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bmEXbV_AOlOZluuVpjIxKg.png"/></div></div></figure><p id="c466" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这里我们可以清楚地看到比对于德鲁森类的精度和召回率都低。在下面的模型中，我们将尝试改进它。该模型比以前的7层CNN模型表现更差。接下来，我们将尝试ResNet50和DenseNet121作为最佳学习者，让我们看看指标是否有所改善。</p><h1 id="3ff7" class="lq jl hi bd jm lr ls lt jq lu lv lw ju lx ly lz jx ma mb mc ka md me mf kd mg bi translated"><strong class="ak"> 4) ResNet50迁移学习:</strong></h1><figure class="kl km kn ko fd kp"><div class="bz dy l di"><div class="mh mi l"/></div></figure><p id="fc2a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里，我们使用了一个预训练模型，即没有完全连接层的ResNet50。我们为4类分类问题添加了自定义的全连接层。训练时，除了最后3层，我们冻结了预训练的模型权重。我们微调了最后3层和完全连接的层。</p><figure class="kl km kn ko fd kp er es paragraph-image"><div class="er es mm"><img src="../Images/6f87d582cac81f696212d9e737a26e79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1336/format:webp/1*Zji6Ak2jnwxd9dsDwkfH-A.png"/></div></figure><figure class="kl km kn ko fd kp er es paragraph-image"><div class="er es mm"><img src="../Images/7aae3841ea8936fa1b930ca8a06b2eed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1336/format:webp/1*TebA-3P28Xr1YgO9jUaf3w.png"/></div></figure><pre class="kl km kn ko fd mn mo mp mq aw mr bi"><span id="a88a" class="jk jl hi mo b fi ms mt l mu mv"><strong class="mo hj">Train F1-micro avg score :  0.9459<br/>Val F1-micro avg score :  0.9366<br/>Test F1-micro avg score :  0.9399</strong></span></pre><figure class="kl km kn ko fd kp er es paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="er es mw"><img src="../Images/836081618e6a643d54638c5ff4519fad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sGsPQmi20yKvh3sIHCh7PA.png"/></div></div></figure><p id="6d41" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这里我们可以清楚地看到比得森类的精度和召回率都是从VGG16迁移学习模型改进而来的。</p><h1 id="d2b9" class="lq jl hi bd jm lr ls lt jq lu lv lw ju lx ly lz jx ma mb mc ka md me mf kd mg bi translated"><strong class="ak"> 5) DenseNet121迁移学习:</strong></h1><figure class="kl km kn ko fd kp"><div class="bz dy l di"><div class="mh mi l"/></div></figure><p id="2a86" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里，我们使用了一个预训练模型，即没有完全连接层的DenseNet121。我们为4类分类问题添加了自定义的全连接层。训练时，除了最后3层，我们冻结了预训练的模型权重。我们微调了最后3层和完全连接的层。</p><figure class="kl km kn ko fd kp er es paragraph-image"><div class="er es mz"><img src="../Images/46b93a4ad1a797e3ed2058801763a2f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1368/format:webp/1*U6N8cWSGL2k-nbIeqYOsfg.png"/></div></figure><figure class="kl km kn ko fd kp er es paragraph-image"><div class="er es mm"><img src="../Images/781bacab26bc00bbcf2d24992f6ca2ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1336/format:webp/1*0ilOEHu7rM32SCJEqvtVkA.png"/></div></figure><pre class="kl km kn ko fd mn mo mp mq aw mr bi"><span id="5c0e" class="jk jl hi mo b fi ms mt l mu mv"><strong class="mo hj">Train F1-micro avg score :  0.9857<br/>Val F1-micro avg score :  0.9561<br/>Test F1-micro avg score :  0.9651</strong></span></pre><figure class="kl km kn ko fd kp er es paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="er es mw"><img src="../Images/99889f7d66676203bd7f57d439bbedfd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AiuDrcLYbsd81LoO5XWboQ.png"/></div></div></figure><h1 id="43cf" class="lq jl hi bd jm lr ls lt jq lu lv lw ju lx ly lz jx ma mb mc ka md me mf kd mg bi translated"><strong class="ak">车型性能对比:</strong></h1><figure class="kl km kn ko fd kp er es paragraph-image"><div role="button" tabindex="0" class="kq kr di ks bf kt"><div class="er es na"><img src="../Images/3d956b3236b061423275651e04053a2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_F0qaVcB8pBG_kBtS8yhPA.png"/></div></div></figure><ul class=""><li id="ec58" class="lc ld hi ih b ii ij im in iq le iu lf iy lg jc nb li lj lk bi translated">7层CNN模型和DenseNet121迁移学习模型表现优于其他模型。</li><li id="8e75" class="lc ld hi ih b ii ll im lm iq ln iu lo iy lp jc nb li lj lk bi translated">DenseNet121是上述5种型号中性能最好的型号。DenseNet121 Transfer Learning在测试数据上的f1-micro平均得分最高，即0.965。</li><li id="c8b6" class="lc ld hi ih b ii ll im lm iq ln iu lo iy lp jc nb li lj lk bi translated">如果我们用完整的84K图像训练模型，我们还可以提高f1-micro得分。</li><li id="1075" class="lc ld hi ih b ii ll im lm iq ln iu lo iy lp jc nb li lj lk bi translated">详细代码参见<a class="ae la" href="https://github.com/subhande/Retinal-OCT-Images" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj"> Github Repo </strong> </a>。</li></ul><h1 id="0406" class="lq jl hi bd jm lr ls lt jq lu lv lw ju lx ly lz jx ma mb mc ka md me mf kd mg bi translated"><strong class="ak">参考文献:</strong></h1><ol class=""><li id="5462" class="lc ld hi ih b ii kf im kg iq nc iu nd iy ne jc lh li lj lk bi translated"><a class="ae la" href="http://www.cell.com/cell/fulltext/S0092-8674(18)30154-5" rel="noopener ugc nofollow" target="_blank">http://www . cell . com/cell/full text/s 0092-8674(18)30154-5</a></li><li id="8c2b" class="lc ld hi ih b ii ll im lm iq ln iu lo iy lp jc lh li lj lk bi translated"><a class="ae la" href="https://www.kaggle.com/paultimothymooney/kermany2018" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/paultimothymooney/kermany2018</a></li><li id="401f" class="lc ld hi ih b ii ll im lm iq ln iu lo iy lp jc lh li lj lk bi translated"><a class="ae la" href="https://www.appliedaicourse.com/" rel="noopener ugc nofollow" target="_blank">https://www.appliedaicourse.com/</a></li><li id="c0f2" class="lc ld hi ih b ii ll im lm iq ln iu lo iy lp jc lh li lj lk bi translated"><a class="ae la" href="https://ophthalmology.med.ubc.ca/patient-care/ophthalmic-photography/optical-coherence-tomography/" rel="noopener ugc nofollow" target="_blank">https://ophthalmology . med . UBC . ca/patient-care/ophthalmic-photography/optical-coherence-tomography/</a></li><li id="2310" class="lc ld hi ih b ii ll im lm iq ln iu lo iy lp jc lh li lj lk bi translated"><a class="ae la" href="https://www.vsp.com/eyewear-wellness/eye-health/diabetic-macular-edema" rel="noopener ugc nofollow" target="_blank">https://www . VSP . com/wegger-wellness/eye-health/diabetic-macular-水肿</a></li><li id="e00a" class="lc ld hi ih b ii ll im lm iq ln iu lo iy lp jc lh li lj lk bi translated">https://www.aao.org/eye-health/diseases/what-are-drusen<a class="ae la" href="https://www.aao.org/eye-health/diseases/what-are-drusen" rel="noopener ugc nofollow" target="_blank"/></li><li id="af5a" class="lc ld hi ih b ii ll im lm iq ln iu lo iy lp jc lh li lj lk bi translated"><a class="ae la" href="https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53" rel="noopener" target="_blank">https://towards data science . com/a-comprehensive-guide-to-convolutionary-neural-networks-the-Eli 5-way-3bd2b 1164 a53</a></li><li id="0fe7" class="lc ld hi ih b ii ll im lm iq ln iu lo iy lp jc lh li lj lk bi translated"><a class="ae la" href="https://en.wikipedia.org/wiki/Convolutional_neural_network" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Convolutional_neural_network</a></li></ol></div></div>    
</body>
</html>