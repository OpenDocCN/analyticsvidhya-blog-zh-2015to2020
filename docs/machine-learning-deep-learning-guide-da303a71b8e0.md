# æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ æŒ‡å—

> åŸæ–‡ï¼š<https://medium.com/analytics-vidhya/machine-learning-deep-learning-guide-da303a71b8e0?source=collection_archive---------22----------------------->

W æ¬¢è¿æ¥åˆ°æœºå™¨å­¦ä¹ &æ·±åº¦å­¦ä¹ æŒ‡å—çš„ç¬¬ 4 éƒ¨åˆ†ï¼Œåœ¨è¿™é‡Œæˆ‘ä»¬å­¦ä¹ å’Œå®è·µæœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ ï¼Œè€Œä¸ä¼šè¢«æ¦‚å¿µå’Œæ•°å­¦è§„åˆ™æ‰€æ·¹æ²¡ã€‚

> [*ç¬¬ 1 éƒ¨åˆ†:å…³é”®æœ¯è¯­ã€å®šä¹‰å’Œä»ç›‘ç£å­¦ä¹ (çº¿æ€§å›å½’)å¼€å§‹ã€‚*](/analytics-vidhya/machine-learning-deep-learning-guide-part-1-4ba7ce8cf7eb)
> 
> [*ç¬¬äºŒéƒ¨åˆ†:ç›‘ç£å­¦ä¹ :å›å½’(SGD)å’Œåˆ†ç±»(SVMã€æœ´ç´ è´å¶æ–¯ã€KNN å’Œå†³ç­–æ ‘)ã€‚*](/analytics-vidhya/machine-learning-deep-learning-guide-db520c4797da)
> 
> [*ç¬¬ä¸‰éƒ¨åˆ†:æ— ç›‘ç£å­¦ä¹ (KMeansï¼ŒPCA)ï¼Œæ¬ æ‹Ÿåˆ vs è¿‡æ‹Ÿåˆå’Œäº¤å‰éªŒè¯*](/analytics-vidhya/machine-learning-deep-learning-guide-11ad26e0854c) *ã€‚*
> 
> *ç¬¬ 4 éƒ¨åˆ†:æ·±åº¦å­¦ä¹ :å®šä¹‰ã€å±‚æ¬¡ã€åº¦é‡å’ŒæŸå¤±ã€ä¼˜åŒ–å™¨å’Œæ­£åˆ™åŒ–*

# **å­¦ä¹ ç›®æ ‡**

åœ¨æ•™ç¨‹çš„ç¬¬ 4 éƒ¨åˆ†ï¼Œæˆ‘ä»¬å°†è®¨è®º**æ·±åº¦å­¦ä¹ ã€‚**é¦–å…ˆï¼Œæˆ‘ä»¬ä¼šæœ‰æ·±åº¦å­¦ä¹ å’Œç¥ç»ç½‘ç»œçš„å®šä¹‰ã€‚ç„¶åæˆ‘ä»¬è®¨è®ºä¸¤ç§ä¸»è¦çš„ç¥ç»ç½‘ç»œç»“æ„ã€‚ä¹‹åï¼Œæˆ‘ä»¬å°†åˆ—å‡ºä¸ä¼˜åŒ–å‡½æ•°ä¸€èµ·ä½¿ç”¨çš„ä¸»è¦è¯¯å·®å’Œåº¦é‡å‡½æ•°ã€‚æœ€åï¼Œæˆ‘ä»¬ä¼šå†™ä¸€ä¸ªæ·±åº¦å­¦ä¹ çš„ä¾‹å­ã€‚

# å®šä¹‰

**æ·±åº¦å­¦ä¹ **

åœ¨æœ¬æŒ‡å—çš„[ç¬¬ 1 éƒ¨åˆ†](/analytics-vidhya/machine-learning-deep-learning-guide-part-1-4ba7ce8cf7eb)ä¸­ï¼Œæˆ‘ä»¬å°†[æ·±åº¦å­¦ä¹ ](/datadriveninvestor/difference-between-ml-ai-dl-23db64f7aa2)å®šä¹‰ä¸ºæœºå™¨å­¦ä¹ çš„å­é›†ï¼Œå®ƒä½¿ç”¨ç½‘çŠ¶ç½‘ç»œï¼Œå·¥ä½œæ–¹å¼ç±»ä¼¼äºæˆ‘ä»¬çš„å¤§è„‘ï¼ŒæŠ€æœ¯ä¸Šç§°ä¸º*æ·±åº¦ç¥ç»ç½‘ç»œ*ã€‚
å°±åƒæˆ‘ä»¬çš„å¤§è„‘è¯†åˆ«æ¨¡å¼å¯¹äº‹ç‰©è¿›è¡Œåˆ†ç±»ï¼Œå¹¶ä»é”™è¯¯ä¸­å­¦ä¹ ä¸€æ ·â€”â€”*æ·±åº¦å­¦ä¹ ä¹Ÿæ˜¯å¦‚æ­¤*ã€‚å®ƒå°†æœªçŸ¥æ•°æ®ä¸å·²çŸ¥æ•°æ®è¿›è¡Œæ¯”è¾ƒï¼Œä»è€Œå¯¹å…¶è¿›è¡Œç›¸åº”çš„åˆ†ç±»ã€‚

åœ¨ç¬¬ 3 éƒ¨åˆ†[ä¸­ï¼Œæˆ‘ä»¬çœ‹åˆ°äº†ä¸€ä¸ªæ— ç›‘ç£å­¦ä¹ çš„ä¾‹å­ï¼Œæˆ‘ä»¬åšäº†ä¸€äº›ç‰¹å¾æå–ã€‚æ·±åº¦å­¦ä¹ å…·æœ‰å­¦ä¹ å¤šå±‚è¡¨ç¤ºçš„èƒ½åŠ›ï¼Œæ˜¯å°‘æ•°å‡ ç§å¸®åŠ©æˆ‘ä»¬è‡ªåŠ¨æå–ç‰¹å¾çš„æ–¹æ³•ä¹‹ä¸€ã€‚å¯ä»¥å‡è®¾è¾ƒä½å±‚æ­£åœ¨æ‰§è¡Œè‡ªåŠ¨ç‰¹å¾æå–ï¼Œå¾ˆå°‘æˆ–ä¸éœ€è¦ç¨‹åºå‘˜çš„æŒ‡å¯¼ã€‚](/analytics-vidhya/machine-learning-deep-learning-guide-11ad26e0854c)

![](img/4798ddeed20bb75a7248a9c8a41c88fc.png)

[ç¥ç»ç½‘ç»œç¤ºæ„å›¾](https://www.slideshare.net/TessFerrandez/notes-from-coursera-deep-learning-courses-by-andrew-ng)

**ç¥ç»ç½‘ç»œ**
ç¥ç»ç½‘ç»œæ˜¯ä¸€ç±»ç”¨å±‚æ„å»ºçš„æ¨¡å‹ã€‚å¸¸ç”¨çš„ç¥ç»ç½‘ç»œç±»å‹åŒ…æ‹¬å·ç§¯ç¥ç»ç½‘ç»œå’Œé€’å½’ç¥ç»ç½‘ç»œã€‚

![](img/2fc7327b5a636aafaba78aa2b6b7b5ed.png)

ç¥ç»ç½‘ç»œ

*   **è¾“å…¥å±‚:**ä»£è¡¨æˆ‘ä»¬è¾“å…¥ç¥ç»ç½‘ç»œçš„æ•°æ®ã€‚
*   **è¾“å‡ºå±‚:**å®ƒç”Ÿæˆæˆ‘ä»¬çš„ç¥ç»ç½‘ç»œçš„è¾“å‡ºã€‚å®ƒèƒ½å‡ºå»
*   **éšè—å±‚:**æ˜¯æˆ‘ä»¬ç¥ç»ç½‘ç»œçš„æ ¸å¿ƒã€‚å®ƒå¯ä»¥è¾“å‡ºäºŒè¿›åˆ¶å€¼(äºŒè¿›åˆ¶åˆ†ç±»)ã€å±äºä¸€ç±»çš„æ¦‚ç‡(å¤šç±»åˆ†ç±»)æˆ–è¿ç»­å€¼(å›å½’)ã€‚å¦‚æœæˆ‘ä»¬æœ‰ä¸€å±‚(æˆ–å‡ å±‚)ï¼Œå®ƒè¢«ç§°ä¸ºæµ…ç½‘ç»œã€‚å¦åˆ™å®ƒè¢«ç§°ä¸ºæ·±åº¦ç¥ç»ç½‘ç»œ(DNN)

å•ä¸ªç¥ç»å…ƒå¯èƒ½å¦‚ä¸‹æ‰€ç¤º

![](img/e21a30f99bf9a45c2a587bc22bcc3e43.png)

[å•ä¸ªç¥ç»å…ƒ](https://pythonprogramming.net/introduction-deep-learning-python-tensorflow-keras/)

åœ¨æ¯ä¸€å±‚ä¸­ï¼Œä½ éƒ½æœ‰è¾“å…¥æ•°æ®ï¼Œä½  ***åŠ æƒ*** å®ƒï¼Œå¹¶æŠŠå®ƒé€šè¿‡ç¥ç»å…ƒä¸­è¢«ç§°ä¸ºæ¿€æ´»å‡½æ•°çš„å‡½æ•°ã€‚å®ƒæ˜¯æ‰€æœ‰å€¼ä¸æŸä¸ªå€¼æ¯”è¾ƒåçš„æ€»å’Œã€‚å¦‚æœä½ å‘å°„ä¸€ä¸ªä¿¡å·ï¼Œé‚£ä¹ˆç»“æœæ˜¯(1) outï¼Œæˆ–è€…æ²¡æœ‰å‘å°„ä»»ä½•ä¸œè¥¿ï¼Œé‚£ä¹ˆæ˜¯(0)ã€‚ç„¶ååŠ æƒå¹¶ä¼ é€’ç»™ä¸‹ä¸€ä¸ªç¥ç»å…ƒï¼Œè¿è¡Œç›¸åŒçš„åŠŸèƒ½ã€‚ä¸€æ—¦æˆ‘ä»¬åˆ°è¾¾è¾“å‡ºå±‚ï¼Œæˆ‘ä»¬ç”Ÿæˆæˆ‘ä»¬çš„è¾“å‡ºå’Œ ***æ¯”è¾ƒ*** ä»¥åŒ¹é…æ‚¨æƒ³è¦çš„è¾“å‡ºå¹¶è®¡ç®— ***æŸå¤±/æˆæœ¬*** ã€‚

å°†æ•°æ®ä»ä¸€ä¸ªç¥ç»å…ƒä¼ æ’­åˆ°ä¸‹ä¸€ä¸ªç¥ç»å…ƒ(æŒ‰é¡ºåº)çš„è¿‡ç¨‹ç§°ä¸º**å‰é¦ˆã€‚** åŸºäºæŸå¤±ï¼Œæˆ‘ä»¬å›æº¯å¹¶å¼€å§‹æ›´æ–° ***æƒé‡*** å’Œ ***åå·®*** ä»¥æœ€å°åŒ–æŸå¤±/æˆæœ¬ã€‚è¿™ä¸ªè¿‡ç¨‹å«åš ***åå‘ä¼ æ’­ã€‚***

![](img/674d10eb3415ef27090416ecdb0c9b83.png)

å­¦ä¹ è¿‡ç¨‹

![](img/bb8d05cdc7c6cb42ddce763efffd64b8.png)

æ·±åº¦å­¦ä¹ å¯ä»¥ç”¨äºæœ‰ç›‘ç£çš„ã€æ— ç›‘ç£çš„æˆ– RLã€‚æ¥æº:å¼—é‡Œå¾·æ›¼ç­‰äºº| [éº»çœç†å·¥æ·±åº¦å­¦ä¹ ](https://deeplearning.mit.edu/)

æ—¢ç„¶æˆ‘ä»¬å·²ç»çœ‹åˆ°äº†ç¥ç»ç½‘ç»œçš„ç»“æ„ã€‚è®©æˆ‘ä»¬æ¥çœ‹ä¸€äº›ç¥ç»ç½‘ç»œçš„ä¾‹å­ã€‚

# **å·ç§¯ç¥ç»ç½‘ç»œ**

å·ç§¯ç¥ç»ç½‘ç»œèƒŒåçš„æ€æƒ³æ˜¯é€šè¿‡å›¾åƒçš„ç§»åŠ¨æ»¤æ³¢å™¨(å·ç§¯)çš„æ€æƒ³ã€‚ç„¶åæˆ‘ä»¬åº”ç”¨ä¸‹é‡‡æ ·(æ± åŒ–),é€‰æ‹©ä¸€ä¸ªåŒºåŸŸå¹¶åº”ç”¨è¯¥åŒºåŸŸä¸­å€¼çš„å¹³å‡å€¼æˆ–æœ€å¤§å€¼ã€‚æœ€åä¸€å±‚(è¾“å‡º)æ˜¯ç”Ÿæˆè¾“å‡ºçš„å…¨è¿æ¥å±‚ã€‚

![](img/edd030656c871123676261fe61f4c00d.png)

å·ç§¯ç¥ç»ç½‘ç»œ(CNN)

CNN ä¸»è¦ç”¨äº**æœºå™¨è§†è§‰**é¡¹ç›®ã€‚ä½†æ˜¯ï¼Œå®ƒä»ç„¶å¯ä»¥ç”¨äºå…¶ä»–åº”ç”¨ç¨‹åºã€‚

# é€’å½’ç¥ç»ç½‘ç»œ

> é€’å½’ç½‘ç»œæ˜¯ä¸€ç§äººå·¥ç¥ç»ç½‘ç»œï¼Œæ—¨åœ¨è¯†åˆ«æ•°æ®åºåˆ—ä¸­çš„æ¨¡å¼ï¼Œå¦‚æ–‡æœ¬ã€åŸºå› ç»„ã€æ‰‹å†™ã€å£è¯­æˆ–æ¥è‡ªä¼ æ„Ÿå™¨ã€è‚¡ç¥¨å¸‚åœºå’Œæ”¿åºœæœºæ„çš„æ•°å­—æ—¶é—´åºåˆ—æ•°æ®ã€‚è¿™äº›ç®—æ³•è€ƒè™‘äº†æ—¶é—´å’Œé¡ºåºï¼Œå®ƒä»¬æœ‰ä¸€ä¸ªæ—¶é—´ç»´åº¦ã€‚

![](img/4f85ed9ec951b48beee726d6aab9ab82.png)

**é•¿æœŸä¾èµ–é—®é¢˜ï¼Œæ¯ä¸ªèŠ‚ç‚¹ä»£è¡¨ä¸€ä¸ª rnn å°åŒºã€‚**æ¥æº:Github

# **å›¾å±‚ç±»å‹åŠåŠŸèƒ½:**

è®©æˆ‘ä»¬è€ƒè™‘æœ€é‡è¦å’Œæœ€å¸¸ç”¨çš„å±‚:

*   **è¾“å…¥å±‚**â€”â€”æŒ‰åŸæ ·è·å–åŸå§‹æ•°æ®ã€‚
*   **å·ç§¯å±‚**â€”â€”è¿™ä¸€å±‚æ˜¯å·ç§¯ç¥ç»ç½‘ç»œ( **CNN)** çš„æ ¸å¿ƒæ„å»ºæ¨¡å—ï¼Œå®Œæˆå¤§éƒ¨åˆ†è®¡ç®—ã€‚è¿™ä¸€å±‚è®¡ç®—è¾“å…¥ä¸­ç¥ç»å…ƒå’Œå„ç§å°å—ä¹‹é—´çš„å·ç§¯ã€‚
*   **æ± åŒ–å±‚**â€”æ± åŒ–æœ‰åŠ©äºæˆ‘ä»¬åœ¨ç½‘ç»œä¸­å‰è¿›æ—¶ä»…ä¿ç•™é‡è¦éƒ¨åˆ†ã€‚æ± å±‚åœ¨è¾“å…¥çš„æ¯ä¸ªæ·±åº¦åˆ‡ç‰‡ä¸Šç‹¬ç«‹æ“ä½œï¼Œå¹¶åœ¨ç©ºé—´ä¸Šè°ƒæ•´å…¶å¤§å°ã€‚å®ƒä½¿ç”¨æœ€å¤§å€¼å‡½æ•°ã€‚
*   **å…¨è¿æ¥å±‚(å¯†é›†)**â€”è¯¥å±‚è®¡ç®—æœ€åä¸€å±‚çš„è¾“å‡ºåˆ†æ•°ã€‚ç»“æœè¾“å‡ºçš„å¤§å°ä¸º **ğŸÃ—ğŸÃ—ğ‘³** ï¼Œå…¶ä¸­ l æ˜¯è®­ç»ƒæ•°æ®é›†ç±»çš„æ•°é‡ã€‚
*   **LSTM****é•¿çŸ­æœŸè®°å¿†ç½‘ç»œâ€”â€”é€šå¸¸ç®€ç§°ä¸ºâ€œlstmâ€â€”â€”æ˜¯ä¸€ç§ç‰¹æ®Šçš„ RNNï¼Œèƒ½å¤Ÿå­¦ä¹ é•¿æœŸä¾èµ–å…³ç³»ã€‚**

**å¦‚å‰æ‰€è¿°ï¼Œéšè—å±‚ä¹‹é—´æœ‰ä¸€ä¸ªæ¿€æ´»å‡½æ•°ï¼Œåº”ç”¨äºå‰ä¸€å±‚çš„è¾“å‡ºã€‚å®ƒå¢åŠ äº†ç½‘ç»œçš„éçº¿æ€§ï¼Œå› æ­¤å®ƒå¯ä»¥å¾ˆå¥½åœ°æ¨å¹¿åˆ°ä»»ä½•ç±»å‹çš„å‡½æ•°ã€‚ä»¥ä¸‹æ˜¯æœ€å¸¸è§çš„å‡ ç§:**

**![](img/2c0d5e5b12186f169ad888106b443cb0.png)**

**a.Sigmoid b.Tanh c .æ•´æµçº¿æ€§å•å…ƒ(ReLU) d .æ³„æ¼ ReLU**

# **æŒ‡æ ‡å’ŒæŸå¤±:**

**ä¸**æœºå™¨å­¦ä¹ ä¸€æ ·ï¼Œ**åœ¨æ·±åº¦å­¦ä¹ ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨æŸå¤±å‡½æ•°æ¥è¯„ä¼°æˆ‘ä»¬æ¨¡å‹çš„é”™è¯¯ï¼Œæˆ‘ä»¬ä½¿ç”¨åº¦é‡æ¥è¯„ä¼°æ€§èƒ½ã€‚**

**ä»¥ä¸‹æ˜¯æ·±åº¦å­¦ä¹ ä¸­ä½¿ç”¨çš„ä¸»è¦æŸå¤±å‡½æ•°:**

****ç”¨äºåˆ†ç±»:****

*   **äºŒå…ƒåˆ†ç±»:äºŒå…ƒäº¤å‰ç†µ**
*   **å¤šç±»åˆ†ç±»:ç±»åˆ«äº¤å‰ç†µå’Œç¨€ç–ç±»åˆ«äº¤å‰ç†µ**

****ç”¨äºå›å½’:****

*   **å‡æ–¹è¯¯å·®**
*   **å¹³å‡ç»å¯¹è¯¯å·®**

**ä»¥ä¸‹æ˜¯æ·±åº¦å­¦ä¹ çš„ä¸»è¦æŒ‡æ ‡:**

*   **å‡†ç¡®(æ€§)**
*   **å¹³å‡ç»å¯¹è¯¯å·®**

# **ä¼˜åŒ–å™¨:**

**å®ƒæ˜¯ä½¿ç”¨åå‘ä¼ æ’­æ¥æ›´æ–°æƒé‡çš„å‡½æ•°ã€‚æˆ‘ä»¬ä¸»è¦ä½¿ç”¨ä»¥ä¸‹ä¼˜åŒ–å™¨ã€‚**

*   ****äºšå½“:**è‡ªé€‚åº”åŠ¨é‡**
*   **å‡æ–¹æ ¹ä¼ æ’­**
*   ****SGD** :éšæœºæ¢¯åº¦ä¸‹é™ä¼˜åŒ–å™¨**

# **æ­£è§„åŒ–:**

**å¸®åŠ©ç½‘ç»œå½’çº³å‡ºå®ƒæ²¡æœ‰è§è¿‡çš„æ•°æ®ã€‚å®ƒç”¨äºè§£å†³è¿‡æ‹Ÿåˆé—®é¢˜:**

*   ****ä¸¢å¼ƒ:**éšæœºç§»é™¤ç½‘ç»œä¸­çš„ä¸€äº›èŠ‚ç‚¹(ä»¥åŠè¾“å…¥å’Œè¾“å‡ºè¾¹)**
*   ****æå‰åœæ­¢:**å½“éªŒè¯é›†çš„æ€§èƒ½ä¸‹é™æ—¶ï¼Œåœæ­¢è®­ç»ƒ(æˆ–è€…è‡³å°‘ä¿å­˜ä¸€ä¸ªæ£€æŸ¥ç‚¹)**
*   ****å¯ç”¨æƒ©ç½š:
    L1 æƒ©ç½š:**æƒ©ç½šç»å¯¹é‡é‡ã€‚
    **L2 ç½š:**ç½šå¹³æ–¹é‡é‡**

# ****è¶³å¤Ÿçš„å®šä¹‰â€¦å¼€å§‹ç¼–ç ****

**æˆ‘ä»¬å°†å®ç°**å·ç§¯ç¥ç»ç½‘ç»œ(CNN)** æ¨¡å‹ [**Keras**](https://keras.io/) ã€‚**

> ***ä½ å¯ä»¥ä»* [*è¿™é‡Œ*](https://www.kaggle.com/mohammadhatoum/deep-learning-cnn) ä¸‹è½½å®Œæ•´çš„ Kaggle ç¬”è®°æœ¬**

**1.**æ•°æ®å®šä¹‰**:æˆ‘ä»¬å°†ä½¿ç”¨[**MNIST**](http://yann.lecun.com/exdb/mnist/)**æ•°æ®é›†ã€‚æˆ‘ä»¬å°†å®šä¹‰ä¸€äº›å‚æ•°å¦‚ä¸‹:****

```
**from __future__ import print_function
import keras
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from keras import backend as K# Set few parameters to be used
batch_size = 128
num_classes = 10
epochs = 12
# input image dimensions
img_rows, img_cols = 28, 28#Load MNIST dataset the split it between train and test sets
(x_train, y_train), (x_test, y_test) = mnist.load_data()if K.image_data_format() == 'channels_first':
    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)
    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)
    input_shape = (1, img_rows, img_cols)
else:
    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)
    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)
    input_shape = (img_rows, img_cols, 1)**
```

****2.æ‰§è¡Œé¢„å¤„ç†:****

****a.è§„èŒƒåŸ¹è®­å’Œæµ‹è¯•è¾“å…¥****

```
**x_train = x_train.astype('float32')
x_test = x_test.astype('float32')
x_train /= 255
x_test /= 255
print('x_train shape:', x_train.shape)
print(x_train.shape[0], 'train samples')
print(x_test.shape[0], 'test samples')**
```

> ****ç»“æœ:****
> 
> ****x _ è®­ç»ƒå½¢çŠ¶:(60000ï¼Œ28ï¼Œ28ï¼Œ1)
> 60000 ä¸ªè®­ç»ƒæ ·æœ¬
> 10000 ä¸ªæµ‹è¯•æ ·æœ¬****

****b.å°†ç±»åˆ«å‘é‡è½¬æ¢ä¸ºäºŒè¿›åˆ¶ç±»åˆ«çŸ©é˜µ****

```
**y_train = keras.utils.to_categorical(y_train, num_classes)
y_test = keras.utils.to_categorical(y_test, num_classes)**
```

****3.å»ºç«‹æ¨¡å‹****

```
**model = Sequential()
model.add(Conv2D(32, kernel_size=(3, 3),
                 activation='relu',
                 input_shape=input_shape))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(num_classes, activation='softmax'))**
```

****4.ç»˜åˆ¶æ¨¡å‹****

```
**from keras.utils import plot_model
plot_model(model)**
```

****![](img/82754ca55e19b20f64a9a6cfa4362529.png)****

****CNN æ¨¡å‹****

****5.ä¸ºåŸ¹è®­é…ç½®æ¨¡å‹****

```
**model.compile(loss=keras.losses.categorical_crossentropy,
              optimizer=keras.optimizers.Adam(),
              metrics=['accuracy'])**
```

****6.ä¸ºæ¨¡å‹å®šå‹å›ºå®šæ•°é‡çš„å†å…ƒ(æ•°æ®é›†ä¸Šçš„è¿­ä»£)****

```
**history = model.fit(x_train, y_train,
          batch_size=batch_size,
          epochs=epochs,
          verbose=1,
          validation_data=(x_test, y_test))**
```

****7.é€šè¿‡åœ¨æµ‹è¯•æ¨¡å¼ä¸‹è·å–æŸå¤±å€¼å’Œåº¦é‡å€¼æ¥è¯„ä¼°æ¨¡å‹****

```
**score = model.evaluate(x_test, y_test, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])**
```

> ****ç»“æœ:****
> 
> ****æµ‹è¯•æŸè€—:0.029843983797999968
> æµ‹è¯•ç²¾åº¦:0.99000001****

****ä»¤äººå°è±¡æ·±åˆ»çš„æ˜¯ï¼Œæˆ‘ä»¬å¾—åˆ°äº† 99.19%çš„å‡†ç¡®ç‡****

****8.ç»˜åˆ¶ä¸€ä¸ªå›¾åƒå’Œæˆ‘ä»¬çš„æ¨¡å‹æä¾›çš„æ ‡ç­¾****

```
**import matplotlib.pyplot as plt
image_index = 8855
plt.imshow(x_test[image_index].reshape(28, 28),cmap='Greys')
pred = model.predict(x_test[image_index].reshape(1, img_rows, img_cols, 1))
print(f"Label predicated by model: {pred.argmax()}")**
```

> ****ç»“æœ:****
> 
> ****ç”±æ¨¡å‹é¢„æµ‹çš„æ ‡ç­¾:5****

****![](img/d3626919c1da7872e67e68d5ce28556f.png)****

****é¢„æµ‹ç»“æœ****

****9.ä¸ºè®­ç»ƒå’Œæµ‹è¯•ç»˜åˆ¶å‡†ç¡®åº¦å’ŒæŸå¤±å€¼****

```
**# Plot training & validation accuracy values
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()# Plot training & validation loss values
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()**
```

****![](img/8c1ade3238265e69cfe8dbe80dd8ec8c.png)****

****æ¨¡å‹ç²¾åº¦****

****![](img/96fca655afa852e99cdcf4b25ef59e6e.png)****

****æ¨¡å‹æŸå¤±****

# ****æ¦‚è¿°****

****æˆ‘ä»¬å·²ç»åˆ°äº†æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ æŒ‡å—ç³»åˆ—çš„ç¬¬å››éƒ¨åˆ†ä¹Ÿæ˜¯æœ€åä¸€éƒ¨åˆ†çš„æœ«å°¾ã€‚åœ¨è¿™ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬è®¨è®ºäº†æ·±åº¦å­¦ä¹ :**å®šä¹‰**ï¼Œ**å±‚**ï¼Œ**åº¦é‡**å’Œ**æŸå¤±**ï¼Œ**ä¼˜åŒ–å™¨**å’Œ**æ­£åˆ™åŒ–**ã€‚ç„¶åæˆ‘ä»¬æœ‰äº†ä¸€ä¸ªå®Œæ•´çš„**å·ç§¯ç¥ç»ç½‘ç»œ(CNN)** çš„ä¾‹å­ã€‚****

# ******ä¸‹ä¸€æ­¥è¯¥æ€ä¹ˆåšï¼Œ******

****æˆ‘ä»¬æ•´ä¸ªæŒ‡å—çš„ä¸»è¦ç›®æ ‡æ˜¯å¸®åŠ©ç¨‹åºå‘˜å’Œè½¯ä»¶å·¥ç¨‹å¸ˆå¼€å§‹ä½¿ç”¨ **ML/DLã€‚**è¿™åªæ˜¯ä¸€ä¸ªåˆ‡å…¥ç‚¹ï¼Œå¦‚æœä½ æƒ³æ·±å…¥è¿™ä¸ªé¢†åŸŸï¼Œæˆ‘å»ºè®®ä½ æŸ¥çœ‹ä¸€ä¸‹æ¯ä¸ªæ•™ç¨‹ä¸­æåˆ°çš„å‚è€ƒèµ„æ–™â€”â€”å°¤å…¶æ˜¯ [Scikit-Learn](https://scikit-learn.org/) å’Œ [Keras](https://keras.io/) ã€‚è€Œæœ€é‡è¦çš„æ˜¯è¦é è‡ªå·±**ç»ƒä¹ ã€‚******

****æ„Ÿè°¢é˜…è¯»ï¼****

# ****å‚è€ƒé“¾æ¥:****

1.  ****[https://www . tutorialspoint . com/python _ deep _ learning/python _ deep _ basic _ machine _ learning . htm](https://www.tutorialspoint.com/python_deep_learning/python_deep_basic_machine_learning.htm)****
2.  ****[https://stanford.edu/~shervine/](https://stanford.edu/~shervine/)****
3.  ****[https://python programming . net/introduction-deep-learning-python-tensor flow-keras/](https://pythonprogramming.net/introduction-deep-learning-python-tensorflow-keras/)****
4.  ****[https://www . tutorialspoint . com/python _ deep _ learning/python _ deep _ learning _ artificial _ neural _ networks . htm](https://www.tutorialspoint.com/python_deep_learning/python_deep_learning_artificial_neural_networks.htm)****
5.  ****[https://www . slide share . net/TessFerrandez/notes-from-coursera-deep-learning-courses-by-Andrew-ng](https://www.slideshare.net/TessFerrandez/notes-from-coursera-deep-learning-courses-by-andrew-ng)****
6.  ****[https://skymind.ai/wiki/lstm](https://skymind.ai/wiki/lstm)****
7.  ****[http://colah.github.io/posts/2015-08-Understanding-LSTMs/](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)****
8.  ****[https://deeplearning.mit.edu/](https://deeplearning.mit.edu/)****
9.  ****[https://github . com/keras-team/keras/blob/master/examples/Mn ist _ CNN . py](https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py)****