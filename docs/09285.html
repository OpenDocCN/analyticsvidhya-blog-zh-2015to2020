<html>
<head>
<title>Bayes Theorem and Text Classification using Naive Bayes Classifier</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">贝叶斯定理和使用朴素贝叶斯分类器的文本分类</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/bayes-theorem-and-text-classification-using-naive-bayes-classifier-591ade7d5299?source=collection_archive---------17-----------------------#2020-08-31">https://medium.com/analytics-vidhya/bayes-theorem-and-text-classification-using-naive-bayes-classifier-591ade7d5299?source=collection_archive---------17-----------------------#2020-08-31</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="12ca" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">本文讨论贝叶斯定理以及朴素贝叶斯分类器在文本分类中的应用。</p><p id="b365" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">首先，我们将考虑一个问题，假设我们被给定某些信息<em class="jd">，在给定烟雾的情况下找到火灾的概率。</em>为了得到<em class="jd"> p(火|烟)</em>或<em class="jd"> p(火给烟)</em>，让我们画一个可以看到所有可能性的样本空间，如下:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es je"><img src="../Images/0b8ddcb4a9870d0b1efb6842981c48a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1346/format:webp/1*uS0F9ehJiXLIlQrAqTeuGA.png"/></div></figure><p id="15c4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了找到<em class="jd"> p </em>(火|烟)，我们只关心存在烟(证据)的区域{1}和{3},因为我们受限于给定烟的证据，所以<em class="jd"> p </em>(火|烟)将是</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es jm"><img src="../Images/26f40be015b77370493db6f3de0f3afe.png" data-original-src="https://miro.medium.com/v2/resize:fit:224/format:webp/1*K3W8R3MkAfOS9GwcNuX4MQ.png"/></div></figure><p id="62ed" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">或者我们也可以写它已经</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es jn"><img src="../Images/53ccd6de2e298ecb54659c0c815c7343.png" data-original-src="https://miro.medium.com/v2/resize:fit:1188/format:webp/1*la_D1hH01QKza4g1nsiAxQ.png"/></div></figure><p id="9348" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">将它推广到给定证据的事件:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es jo"><img src="../Images/5127ee15d29d96371e7e71eda7d17999.png" data-original-src="https://miro.medium.com/v2/resize:fit:1246/format:webp/1*prLmwZbdZFElp1HyFA_DOg.png"/></div></figure><p id="460a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如前所述，我们需要考虑两个方面 1。证据真实-事件发生空间{1}。2.证据为真-事件未发生空间{3}。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es jp"><img src="../Images/8ddb4944e61bb4fa3b6d3095c84900df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1044/format:webp/1*mLORIjhiO7ZRIZZtNvQhww.png"/></div></figure><p id="16cf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">(或)</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es jq"><img src="../Images/fc10cd8af46e3b256359bd0ea3e479d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:754/format:webp/1*2vU8f6JSPHx261Q26o1irg.png"/></div></figure><p id="ced8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">同样的公式可以改写如下，基本上在分母中，我们将所有证据为真的区域相加。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es jr"><img src="../Images/d221bd1d4b39f609b9b7fd43d5693a8f.png" data-original-src="https://miro.medium.com/v2/resize:fit:490/format:webp/1*po-rrPHig_p1QpvZ4JdG_Q.png"/></div></figure><p id="25de" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们已经得出了贝叶斯定理公式，基本上贝叶斯规则是根据证据来描述一个事件的概率。更一般地，基于先验知识寻找事件的概率可以写成:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jt ju di jv bf jw"><div class="er es js"><img src="../Images/e850abcf35651a0db7fed43a11773a5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:550/format:webp/1*ha1-ysB7Mmm4L8jkw9ka5g.png"/></div></div></figure><p id="b96e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">朴素贝叶斯多类分类器:</strong></p><p id="139d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">朴素贝叶斯分类器根据贝叶斯原理工作，但它是朴素的，这意味着我们假设观察到事件的概率是相互独立的。让我们逐步解决这个问题，目标是基于贝叶斯规则将文档分类。</p><p id="4978" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">问题描述</strong>:将文档分类，这里他只考虑 2 个类别，但是同样的思路可以扩展到多类分类问题。</p><p id="2348" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">目标</strong>:通过找到每一类的概率，基于给定的单词识别文档类别。</p><p id="415e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jd">遵循的步骤:</em> </strong></p><h2 id="1d0a" class="jx jy hi bd jz ka kb kc kd ke kf kg kh iq ki kj kk iu kl km kn iy ko kp kq kr bi translated">第一步:从标签数据中找出给定类别的单词的概率</h2><h2 id="f771" class="jx jy hi bd jz ka kb kc kd ke kf kg kh iq ki kj kk iu kl km kn iy ko kp kq kr bi translated">第二步:根据贝叶斯定理从测试数据中找出给定单词的类的概率</h2><h2 id="2158" class="jx jy hi bd jz ka kb kc kd ke kf kg kh iq ki kj kk iu kl km kn iy ko kp kq kr bi translated">第三步:得到所有类的最大概率作为我们的预测</h2><p id="fbdc" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">让我们考虑一个基本的非现实的简单数据集来理解朴素贝叶斯分类器。</p><p id="8b6a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们的训练数据中有 4 个带标签的文档(每一行都是下面的一个文档)。</p><p id="2081" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi">{</p><p id="746f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">「正面」:「奇妙惊人的伟大电影」，</p><p id="948a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">“正面”:“很棒很惊艳的电影”，</p><p id="234e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">「负面」:「糟糕沉闷无聊的电影」，</p><p id="f799" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">“消极”:“沉闷无聊的可怕电影”</p><p id="2a9a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi">}</p><p id="f9e3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在下表中显示相同的上述数据:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es kx"><img src="../Images/368e6cf71e2d5d7340f5a1d5386bd0bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1012/format:webp/1*0rGr9PgbDHba-VYD8If0lw.png"/></div><figcaption class="ky kz et er es la lb bd b be z dx translated">数据集</figcaption></figure><p id="49e7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">数据集中的所有单词都作为列(特征),如果该单词出现在文档中，则值设置为 1，如果不出现，则值设置为 0。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jt ju di jv bf jw"><div class="er es lc"><img src="../Images/36b304adc4148a0eeb2d16e5e7204a87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_lc4OcRJ344z607H1jEqSA.png"/></div></div></figure><h2 id="59d4" class="jx jy hi bd jz ka kb kc kd ke kf kg kh iq ki kj kk iu kl km kn iy ko kp kq kr bi translated">第一步:使用训练数据找出给定班级单词的概率</h2><p id="b39f" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">每个单词的概率可以通过计算每个单词的频率来找到，请注意，我们将每个单词的频率加 1，这样我们可以避免概率为 0(例如，正面评论中单词“可怕”的概率将为 0，我们希望在步骤 2 中乘以概率时避免出现这种情况),还要注意，<em class="jd"> p(正面)与 p(负面)相同，p(负面)为 0.5，因为我们有 2 个正面评论的文档和 2 个负面评论的文档</em></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es ld"><img src="../Images/4cdf9385072e5003c71dcd144db786be.png" data-original-src="https://miro.medium.com/v2/resize:fit:460/format:webp/1*ADjgEfbBXdI0bdKAlf6AkQ.png"/></div><figcaption class="ky kz et er es la lb bd b be z dx translated">每一类的先验概率</figcaption></figure><p id="1d45" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">概率的计算方法是将该单词的出现次数除以给定类别中的单词总数:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es le"><img src="../Images/a65fc157f1ecc539f27e25d481394864.png" data-original-src="https://miro.medium.com/v2/resize:fit:1080/format:webp/1*Oy3o9IwdR4G5SudFS6k1Eg.png"/></div><figcaption class="ky kz et er es la lb bd b be z dx translated">给定评论的单词概率为正</figcaption></figure><p id="d40b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">负类相同:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es lf"><img src="../Images/77a3b97a1bd883dffd1aacc372f2990a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1088/format:webp/1*t8jJlC3y0kPdJXtejSk5iA.png"/></div><figcaption class="ky kz et er es la lb bd b be z dx translated">给定评论的单词概率为负</figcaption></figure><h2 id="878a" class="jx jy hi bd jz ka kb kc kd ke kf kg kh iq ki kj kk iu kl km kn iy ko kp kq kr bi translated">第二步:根据贝叶斯定理从测试数据中找出给定单词的类的概率</h2><p id="d485" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">现在我们有了所有需要的信息，我们可以计算给定单词的类的概率。在这里，我们试图将带有单词{“Amazing Movie”}的文档归类到其中一个类中。根据贝叶斯法则，我们可以计算如下概率</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es lg"><img src="../Images/8578b760438b4d4d3478281b34df49ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1108/format:webp/1*-8mgq3ZgVv_rYHFy685jQw.png"/></div><figcaption class="ky kz et er es la lb bd b be z dx translated">给定词语“惊人的，电影”时，评论为正面的概率</figcaption></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es lh"><img src="../Images/9c53506270a90926795145be26e87cf8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1130/format:webp/1*efqjBXXOG1zwfd4aNkKu1g.png"/></div><figcaption class="ky kz et er es la lb bd b be z dx translated">给定单词“惊人的，电影”时，给定评论的单词为负面的概率</figcaption></figure><p id="d8b9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">由于我们将在步骤 3 中比较两个概率以获得最大概率，我们可以忽略上述等式中的分母，因为它们是相同的。同样，基于联合概率重新排列上述两个等式中的分子将得到以下结果:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es li"><img src="../Images/89e9202147ac939f631db5ecfd221a2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1284/format:webp/1*5XysKJytD9I84-Efy2_pTQ.png"/></div></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es lj"><img src="../Images/994d155c98cc928bdff7a96672bec973.png" data-original-src="https://miro.medium.com/v2/resize:fit:1304/format:webp/1*7JlWHTe2VagGL6rXn79YGg.png"/></div></figure><p id="60a5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">基于我们表格中的值:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es lk"><img src="../Images/d5e5743310e0caaf75a793cf2809f69a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1150/format:webp/1*0xBG3gF3nQIx0ZkdqNK6Gg.png"/></div></figure><h2 id="2049" class="jx jy hi bd jz ka kb kc kd ke kf kg kh iq ki kj kk iu kl km kn iy ko kp kq kr bi translated">第三步:得到所有类的最大概率作为我们的预测</h2><p id="ea12" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">从上面每个类别的计算概率来看，最大值是正面类别，因此我们可以得出结论，根据文档中的给定单词{“Amazing Movie”}，我们可以将其分类为具有正面评论的文档。</p><p id="13d2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">概括公式:</p><p id="2184" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">相同的概念可以用于多类分类问题:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es ll"><img src="../Images/2183e50f15c02fd613014b72c633e9bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1278/format:webp/1*LDx9FdvDLAyrO47hgM3R6Q.png"/></div></figure><p id="94a5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">输出预测可归纳如下，也请注意，我们在下面使用了对数函数，以避免我们通过概率相乘得到的小值。Log 函数将概率相乘转化为对数概率的相加:log(<em class="jd">p(A)* p(B))= log(p(A))+log((p(B))</em>。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es lm"><img src="../Images/559ba2d75ddc2555e3ac4bcd26faff55.png" data-original-src="https://miro.medium.com/v2/resize:fit:1070/format:webp/1*jyTn3V6zOOnA4Rz6JZZzYQ.png"/></div><figcaption class="ky kz et er es la lb bd b be z dx translated">所有类别概率值中的最大概率值</figcaption></figure><p id="d311" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">请报告任何错误/建议。感谢阅读。</p></div></div>    
</body>
</html>