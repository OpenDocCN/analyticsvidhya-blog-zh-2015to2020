<html>
<head>
<title>Using Machine Learning to classify Instrument Sounds</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用机器学习对乐器声音进行分类</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/using-machine-learning-to-classify-instrument-sounds-21c48a91c290?source=collection_archive---------11-----------------------#2020-04-01">https://medium.com/analytics-vidhya/using-machine-learning-to-classify-instrument-sounds-21c48a91c290?source=collection_archive---------11-----------------------#2020-04-01</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/087e4c4bf2d704f4c576eec2ee3d0b4a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Z2BsNJhQMn_HRBqo.jpg"/></div></div></figure><p id="74bd" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">今天，我们已经有了识别随机音乐片段和识别声音/专辑/来源的应用程序。在这篇博客中，我们将尝试理解这些应用程序是如何工作的，并创建我们自己的项目。</p><p id="19a5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我已经分享了我的作品和代码。如果你有兴趣做这个工作，我会建议不要盲目复制，因为我已经把代码放在snips中，它们不在我的系统中。此外，这段代码是两年前用python 2x编写，因此要相应地工作。</p><p id="485e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果你渴望学习，这将是一个很好的指导。</p><h2 id="b04a" class="jp jq hi bd jr js jt ju jv jw jx jy jz jb ka kb kc jf kd ke kf jj kg kh ki kj bi translated"><strong class="ak">数据收集</strong></h2><p id="4de1" class="pw-post-body-paragraph iq ir hi is b it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj ko jl jm jn hb bi translated">我可以通过网站-【www.freesound.org】<em class="jo"/>获得我的训练音</p><p id="f7dd" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">下载小提琴、小号、钢琴和长笛的歌曲，然后用audacity剪辑它们。这里下载<a class="ae kp" href="http://www.audacityteam.org/download" rel="noopener ugc nofollow" target="_blank"><em class="jo"/></a><em class="jo">。</em></p><p id="d05b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果你没有时间创建自己的数据，请使用我的<a class="ae kp" href="https://www.kaggle.com/omrastogi/instrument-classification" rel="noopener ugc nofollow" target="_blank"> <em class="jo">作品</em> </a>。</p><figure class="kr ks kt ku fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kq"><img src="../Images/1f53f3bd01654314c4875fa56595b981.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xrRXciZzvUt6DY0fpcTIng.jpeg"/></div></div><figcaption class="kv kw et er es kx ky bd b be z dx translated">剪切音频以创建多个样本</figcaption></figure><p id="28ac" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">要在python中打开音频文件，需要使用以下代码。</p><pre class="kr ks kt ku fd kz la lb lc aw ld bi"><span id="c978" class="jp jq hi la b fi le lf l lg lh">import wave<br/>import struct<br/>import scipy.io.wavfile as wav<br/>import numpy as np</span><span id="b9d0" class="jp jq hi la b fi li lf l lg lh">def get_audio(file):<br/>    audio_file = wave.open(file)<br/>    length = audio_file.getnframes()<br/>    signal = np.zeros(length)<br/>    for i in range (0,length):<br/>        data = audio_file.readframes(1)<br/>        data = struct.unpack("&lt;h", data)<br/>        signal[i] = int(data[0])<br/>    rate = audio_file.getframerate()<br/>    signal = np.divide(signal, float(2**15))<br/>    return signal, rate</span></pre><h2 id="4ca8" class="jp jq hi bd jr js jt ju jv jw jx jy jz jb ka kb kc jf kd ke kf jj kg kh ki kj bi translated">特征抽出</h2><p id="a0a4" class="pw-post-body-paragraph iq ir hi is b it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj ko jl jm jn hb bi translated">声音有数百种频谱和时间特征，如频率、振幅、质心等。然而，我们将在理解的感知层面上使用一些特定的特征。使用的功能有:</p><ol class=""><li id="6377" class="lj lk hi is b it iu ix iy jb ll jf lm jj ln jn lo lp lq lr bi translated"><strong class="is hj">信号的Mel倒谱频率系数(MFCC)</strong>是一小组特征(通常约10-20)，它们简明地描述了频谱包络的整体形状。常用来形容音色。</li><li id="e287" class="lj lk hi is b it ls ix lt jb lu jf lv jj lw jn lo lp lq lr bi translated"><strong class="is hj">对数滤波器组</strong>是一个带通滤波器阵列，将输入信号分成多个分量，每个分量携带原始信号的单个频率子带。</li><li id="ca36" class="lj lk hi is b it ls ix lt jb lu jf lv jj lw jn lo lp lq lr bi translated"><strong class="is hj">频谱子带质心(SSC) </strong>是表征频谱的一种度量，它表示频谱的质心所在的位置。</li></ol><figure class="kr ks kt ku fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lx"><img src="../Images/caf82ddd1e3efcf505167c749448512d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YBCMgXtYLOE0b7Wff6yImg.png"/></div></div></figure><p id="06e4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">对于windows，我使用了库<a class="ae kp" href="https://python-speech-features.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank"><em class="jo">python _ speech _ features</em></a>，它提供了有限但足够的特性。</p><pre class="kr ks kt ku fd kz la lb lc aw ld bi"><span id="0383" class="jp jq hi la b fi le lf l lg lh">from python_speech_features import mfcc<br/>from python_speech_features import logfbank<br/>from python_speech_features import ssc</span><span id="244a" class="jp jq hi la b fi li lf l lg lh">import numpy as np<br/>import matplotlib.pyplot as plt</span></pre><p id="72b5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在实现这些模块时，应该记住，这些模块提供2d阵列，理解这些输出可能是困难的。所以人们应该彻底了解这些特性，否则它们会迷失在数字和数组海洋中。如果你没有太多时间只阅读关于<a class="ae kp" href="http://practicalcryptography.com/miscellaneous/machine-learning/guide-mel-frequency-cepstral-coefficients-mfccs/" rel="noopener ugc nofollow" target="_blank"><em class="jo">【MFCC】</em></a>和会有抽象的想法。</p><p id="1794" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果你有兴趣深入研究，在<strong class="is hj"> Coursera </strong> on <a class="ae kp" href="https://www.coursera.org/learn/audio-signal-processing/lecture/GCK1G/sound-and-music-description" rel="noopener ugc nofollow" target="_blank"> <em class="jo">音频信号处理</em> </a>上有一门很棒的课程。</p><pre class="kr ks kt ku fd kz la lb lc aw ld bi"><span id="883b" class="jp jq hi la b fi le lf l lg lh">def featuresplot(sig,rate,typo):</span><span id="af30" class="jp jq hi la b fi li lf l lg lh">#Extrating the feature<br/>    m = mfcc(sig,rate)<br/>    fbank_feat = logfbank(sig,rate)<br/>    s= ssc(sig,rate)</span><span id="282c" class="jp jq hi la b fi li lf l lg lh">    mlst = []<br/>    slst = []</span><span id="c7bb" class="jp jq hi la b fi li lf l lg lh">    for i in range(0, len(m)):<br/>        l = m[0:4]<br/>        mlst.append(m[i][2])<br/>        slst.append(s[i][4])</span><span id="f794" class="jp jq hi la b fi li lf l lg lh">    m=[]<br/>    s=[]</span><span id="79e6" class="jp jq hi la b fi li lf l lg lh">    m.append(np.mean(mlst))<br/>    s.append(np.mean(slst))</span><span id="6488" class="jp jq hi la b fi li lf l lg lh">    clst=[]<br/>    for i in range(0, len(fbank_feat)):<br/>        l = m[0:4]<br/>        clst.append(np.mean(fbank_feat[i]))</span><span id="a0b0" class="jp jq hi la b fi li lf l lg lh">    c=[]<br/>    c.append(np.mean(clst))<br/>    plt.plot(m,c, typo)<br/>    return  s[0],m[0],c[0]</span></pre><figure class="kr ks kt ku fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ly"><img src="../Images/1a58c66edc7b40ae1d5edc773672a852.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UHfHTWNW5oCu6wc47vrLiQ.png"/></div></div><figcaption class="kv kw et er es kx ky bd b be z dx translated"><strong class="bd jr"> PLOT1:质心</strong></figcaption></figure><figure class="kr ks kt ku fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lz"><img src="../Images/18442647070bb2a554b38c4160be08f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RrkIF8xf7SGvhTEV9cJcHg.png"/></div></div><figcaption class="kv kw et er es kx ky bd b be z dx translated"><strong class="bd jr">图2: Ssc[4] </strong></figcaption></figure><p id="4e8c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这段代码中，我调用了一些方法来给我一些特性。我存储了某一列的平均值。对于mfcc，我使用了第三列，对于ssc，我使用了第五列。</p><p id="edfa" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">你可以看到这些功能是如何为不同的乐器分割声音的。然而没有一个特征能够完全区分所有的仪器。</p><p id="d7d1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">因此，我们使用所有三个特征来训练我们的模型。</p><p id="49dc" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">不同颜色代表不同的仪器:</p><ol class=""><li id="18b2" class="lj lk hi is b it iu ix iy jb ll jf lm jj ln jn lo lp lq lr bi translated">黄色代表小提琴</li><li id="d4e8" class="lj lk hi is b it ls ix lt jb lu jf lv jj lw jn lo lp lq lr bi translated">蓝色代表钢琴</li><li id="1fa8" class="lj lk hi is b it ls ix lt jb lu jf lv jj lw jn lo lp lq lr bi translated">绿色代表小号</li><li id="890d" class="lj lk hi is b it ls ix lt jb lu jf lv jj lw jn lo lp lq lr bi translated">红色代表长笛</li></ol><figure class="kr ks kt ku fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ma"><img src="../Images/5d068efff07aad633658142ced69c389.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*goOAnjozR0sJ2h94v8wFzA.png"/></div></div><figcaption class="kv kw et er es kx ky bd b be z dx translated"><strong class="bd jr">图3:质心</strong></figcaption></figure><p id="2327" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">培训数据</strong></p><p id="7706" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">获得特征后，我们需要创建我们的训练数据。</p><p id="ef01" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这段代码将通过调用<em class="jo"> get_audio() </em>打开每个音频文件，并使用<em class="jo"> featuresplot() </em>提取特征。变量typo用于建议图中点的颜色。</p><p id="3769" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">最后，每个特征存储在<em class="jo"> dataset.pkl </em>中</p><pre class="kr ks kt ku fd kz la lb lc aw ld bi"><span id="77b2" class="jp jq hi la b fi le lf l lg lh">import pickle</span><span id="9676" class="jp jq hi la b fi li lf l lg lh">def create_dataset():<br/>    dataset= []<br/>    print ("Extracting Dataset")<br/>    print ("\nviolin:"),<br/>    for i in range(1,40):<br/>        print (i),<br/>        file ='Violin/sample_'+str(i)+'.wav'<br/>        sig, rate = get_audio(file)<br/>        typo = '.y'<br/>        s,m,c,k = featuresplot(sig, rate, typo)<br/>        dataset.append(['violin',s,m,c,k])</span><span id="c2ce" class="jp jq hi la b fi li lf l lg lh">    print ("\ntrumpet:"),<br/>    for i in range(1,53):<br/>        print (i),<br/>        file = 'Trumpet/sample_'+str(i)+'.wav'<br/>        sig, rate = get_audio(file)<br/>        typo = '.b'<br/>        s,m,c,k = featuresplot(sig, rate, typo)<br/>        dataset.append(['trumpet',s,m,c,k])</span><span id="26cd" class="jp jq hi la b fi li lf l lg lh">    print ("\npiano:"),<br/>    for i in range(1,46):<br/>        print (i),<br/>        file = 'Piano/sample_'+str(i)+'.wav'<br/>        sig, rate = get_audio(file)<br/>        typo = '.g'<br/>        s,m,c,k = featuresplot(sig, rate, typo)<br/>        dataset.append(['piano',s,m,c,k])</span><span id="e18d" class="jp jq hi la b fi li lf l lg lh">    print ("\nflute:"),<br/>    for i in range(1,58):<br/>        print (i),<br/>        file = 'Flute/sample_'+str(i)+'.wav'<br/>        sig, rate = get_audio(file)<br/>        typo = '.r'<br/>        s,m,c,k = featuresplot(sig, rate, typo)<br/>        dataset.append(['flute',s,m,c,k])<br/>    print ("\nTraining Completed")</span><span id="9953" class="jp jq hi la b fi li lf l lg lh">    with open ('sample_data.pkl','wb') as pickle_file:<br/>        pickle.dump(dataset, pickle_file)</span></pre><p id="c0a5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">输出:<em class="jo"> dataset.pkl </em></p><pre class="kr ks kt ku fd kz la lb lc aw ld bi"><span id="9a8b" class="jp jq hi la b fi le lf l lg lh"><em class="jo">Extracting Dataset<br/>violin: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 </em></span><span id="e68d" class="jp jq hi la b fi li lf l lg lh"><em class="jo">trumpet: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 </em></span><span id="3384" class="jp jq hi la b fi li lf l lg lh"><em class="jo">piano: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45<br/> <br/>flute: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57</em></span></pre><h2 id="b27f" class="jp jq hi bd jr js jt ju jv jw jx jy jz jb ka kb kc jf kd ke kf jj kg kh ki kj bi translated"><strong class="ak">型号</strong></h2><figure class="kr ks kt ku fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mb"><img src="../Images/cac0c268e4a8471e15be7ad42236bbbd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*tYTZFV_HY4kWUJlv.png"/></div></div><figcaption class="kv kw et er es kx ky bd b be z dx translated"><strong class="bd jr">支持向量机</strong></figcaption></figure><p id="83d0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">首先我们需要从sklearn导入必要的模块来训练支持向量机模型。</p><pre class="kr ks kt ku fd kz la lb lc aw ld bi"><span id="ac35" class="jp jq hi la b fi le lf l lg lh">import pandas as pd<br/>from sklearn import svm<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.preprocessing import LabelEncoder<br/>from sklearn.metrics import confusion_matrix</span></pre><p id="e8d4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这里我们使用标签编码器将乐器名称编码成数字。然后我们分割数据集来训练和测试数据。</p><p id="1d1b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">对于SVM模型，线性核最适合C = 3.0的情况。以获得大约90%的准确率。</p><pre class="kr ks kt ku fd kz la lb lc aw ld bi"><span id="5b75" class="jp jq hi la b fi le lf l lg lh">def train_model()<br/>    with open ('sample_data.pkl','rb') as pickle_file:<br/>        dataset = pickle._Unpickler(pickle_file)</span><span id="7cca" class="jp jq hi la b fi li lf l lg lh">    dataset = np.array(dataset)<br/>    le = LabelEncoder()<br/>    data = pd.DataFrame(dataset)<br/>    X, Y = data.iloc[:,1:], dataset[:,0]<br/>    Y = le.fit_transform(Y)</span><span id="6019" class="jp jq hi la b fi li lf l lg lh">    X_train, X_test, y_train, y_test = train_test_split(X, Y,      test_size=0.2, random_state = 42)</span><span id="1a52" class="jp jq hi la b fi li lf l lg lh"><br/>    clf = svm.SVC(kernel = 'linear', C = 3.0)<br/>    clf.fit(X_train, y_train)</span><span id="b606" class="jp jq hi la b fi li lf l lg lh">    acc = clf.score(X_test, y_test)<br/>    y_predict = clf.predict(X_test)</span><span id="6931" class="jp jq hi la b fi li lf l lg lh">    print (str(acc*100)+"% accuracy")<br/>    print (confusion_matrix(y_test, y_predict))</span><span id="3454" class="jp jq hi la b fi li lf l lg lh">    return clf</span></pre><p id="cfc1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">输出:</p><pre class="kr ks kt ku fd kz la lb lc aw ld bi"><span id="84cc" class="jp jq hi la b fi le lf l lg lh">Accuracy: 89.74358974358975% </span><span id="8bb7" class="jp jq hi la b fi li lf l lg lh">Confusion Matrix:<br/>[[13  0  0  0]<br/> [ 0  8  0  0]<br/> [ 0  1  7  2]<br/> [ 1  0  0  7]]</span></pre><figure class="kr ks kt ku fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mc"><img src="../Images/d0dda0b02d492c49deed3cde05fe3a40.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XZXZgcPs4mWFA7D2Tx1xsg.png"/></div></div><figcaption class="kv kw et er es kx ky bd b be z dx translated">质心与mfcc的关系</figcaption></figure><h2 id="72c3" class="jp jq hi bd jr js jt ju jv jw jx jy jz jb ka kb kc jf kd ke kf jj kg kh ki kj bi translated">现在该怎么办</h2><p id="1656" class="pw-post-body-paragraph iq ir hi is b it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj ko jl jm jn hb bi translated">如果你这样想，这个模型的准确性就低了。您可以通过增加模型的数据集来处理它。我认为有了足够的数据，它可以达到95%的准确率。</p><p id="eb4e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">另外，如果你是一个linux用户，你可以使用Librosa这样的库来获得更多的特性，这将通过流形来改进这个模型。</p></div></div>    
</body>
</html>