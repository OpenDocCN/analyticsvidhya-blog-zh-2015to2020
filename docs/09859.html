<html>
<head>
<title>How to deploy a Tensorflow model on Heroku with Tensorflow serving</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何在Heroku上部署Tensorflow模型并提供Tensorflow服务</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/how-to-deploy-a-tensorflow-model-on-heroku-with-tensorflow-serving-6e84e1dc96e7?source=collection_archive---------2-----------------------#2020-09-23">https://medium.com/analytics-vidhya/how-to-deploy-a-tensorflow-model-on-heroku-with-tensorflow-serving-6e84e1dc96e7?source=collection_archive---------2-----------------------#2020-09-23</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/b8e94d44e8b749c3118b7ef054e4f4d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IgFcnBhxBLIBn1u0zjHloA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">图片来自<a class="ae iu" href="https://xd.adobe.com/ideas/principles/emerging-technology/what-is-computer-vision-how-does-it-work/" rel="noopener ugc nofollow" target="_blank"> Adobe博客</a></figcaption></figure><p id="0d2b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在花费数分钟或数小时玩转所有可用的精彩示例后，例如在<a class="ae iu" href="https://aihub.cloud.google.com/s?category=notebook" rel="noopener ugc nofollow" target="_blank">谷歌人工智能中心</a>，人们可能想要在线部署一个或另一个模型。</p><p id="2df4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这篇文章介绍了一种用<a class="ae iu" href="https://www.tensorflow.org/tfx/guide/serving" rel="noopener ugc nofollow" target="_blank"> Tensorflow Serving </a>和<a class="ae iu" href="https://www.heroku.com" rel="noopener ugc nofollow" target="_blank"> Heroku </a>实现的<strong class="ix hj">快速、最优和简洁</strong>的方式。</p><h1 id="2df7" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">介绍</h1><p id="6f0e" class="pw-post-body-paragraph iv iw hi ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">在使用例如<a class="ae iu" href="https://colab.research.google.com" rel="noopener ugc nofollow" target="_blank"> Google colab </a>在单个笔记本电脑上训练和测试单个模型与将模型部署到可以处理更新、批处理和异步预测等的生产环境之间存在差距。</p><p id="1cdd" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">幸运的是<strong class="ix hj"> Google已经公开发布了自己的框架来管理一个模型的整个生命周期</strong>从数据存储到服务到日志等等。对于任何数据科学家或软件工程师来说，阅读<a class="ae iu" href="https://www.tensorflow.org/tfx" rel="noopener ugc nofollow" target="_blank"> Tensorflow Extended </a>文档都是有价值的，因为他们正在寻找关于部署模型和实际应用程序的信息。</p><p id="3f51" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这个简单的<a class="ae iu" href="https://www.tensorflow.org/tfx/tutorials/serving/rest_simple" rel="noopener ugc nofollow" target="_blank"> REST API示例</a>举例说明了如何训练一个简单的分类器，并最终使用服务于 Rest API的<a class="ae iu" href="https://www.tensorflow.org/tfx/guide/serving" rel="noopener ugc nofollow" target="_blank"> Tensorflow进行推理。</a></p><p id="5705" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这篇简短的博文进一步展示了如何在Heroku 上部署这个模型，这样它就可以在线使用，并且可以被另一个API使用。</p><h1 id="11e4" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">关于为模特服务</h1><p id="1550" class="pw-post-body-paragraph iv iw hi ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">为模型服务就是使用它来进行某种预测:它应该被请求输入并返回一个有希望相关的答案。从服务的角度来看，模型是一个应该稳定返回输出的黑盒。</p><p id="7734" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">换句话说，当考虑为模型服务时，您不应该必须重新构建它。服务是模型不可知的:如果你服务一个计算机视觉分类器，它的目标是接收<strong class="ix hj">要分类的原始图片</strong>，并返回每个标签的分数。也就是说，裁剪、预处理等。步骤应该在为服务而构建模型时封装到模型中，即在培训结束时封装。</p><p id="39de" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">事实上，在生产思维状态下，每个经过训练的模型都有可能成为你问题的SOTA。来自服务期间要接收的原始数据和最终预测的所有内容都应该存储在同一个对象中，以便任何人(尤其不是训练模型的数据科学家)都可以安全地使用它，而不会出现常见错误，如像素规范化、错误裁剪等。</p><h1 id="20b4" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">使用张量流</h1><p id="baa2" class="pw-post-body-paragraph iv iw hi ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated"><a class="ae iu" href="https://www.tensorflow.org/" rel="noopener ugc nofollow" target="_blank"> Tensorflow </a>库公开了<a class="ae iu" href="https://www.tensorflow.org/api_docs/python/tf/saved_model" rel="noopener ugc nofollow" target="_blank"> saved_model </a> API，这是专门为将模型打包成二进制跨平台格式而设计的，以后可以在任何地方使用而不会出现问题。<code class="du kx ky kz la b">signatures</code>参数允许从相应的REST API定义几个要在模型上执行的路线和操作。</p><p id="5e96" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">来自<a class="ae iu" href="https://github.com/few-shot-learning/Keras-FewShotLearning" rel="noopener ugc nofollow" target="_blank">Keras-FewShotLearning repo</a>的笔记本<a class="ae iu" href="https://github.com/few-shot-learning/Keras-FewShotLearning/blob/master/notebooks/build_siamese_model_for_serving.py" rel="noopener ugc nofollow" target="_blank"> build for serving </a>是一个很好的例子，说明了如何使用<code class="du kx ky kz la b">@tf.function</code>来创建路线(签名),然后可以使用tensorflow serving API轻松调用这些路线。</p><p id="757f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">例如，给定训练期间使用的预处理:</p><figure class="lb lc ld le fd ij"><div class="bz dy l di"><div class="lf lg l"/></div></figure><p id="7bac" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">人们可以加上下面的<code class="du kx ky kz la b">@tf.function</code>:</p><figure class="lb lc ld le fd ij"><div class="bz dy l di"><div class="lf lg l"/></div></figure><p id="2655" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">并导出模型，如下所示:</p><figure class="lb lc ld le fd ij"><div class="bz dy l di"><div class="lf lg l"/></div></figure><p id="bc18" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这样，当接收完整的base64编码图像时，默认签名将返回每个类的格式化分数，而调用“预处理”签名将仅返回预处理图像。</p><p id="44cb" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">来自<a class="ae iu" href="https://github.com/few-shot-learning/Keras-FewShotLearning" rel="noopener ugc nofollow" target="_blank">Keras-FewShotLearning repo</a>的<a class="ae iu" href="https://github.com/few-shot-learning/Keras-FewShotLearning/blob/master/notebooks/request_served_model.py" rel="noopener ugc nofollow" target="_blank"> request_served_model.py笔记本</a>显示了如何使用docker运行tensorflow服务以及如何请求不同的签名，例如:</p><figure class="lb lc ld le fd ij"><div class="bz dy l di"><div class="lf lg l"/></div></figure><h1 id="de83" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">赫罗库</h1><p id="b226" class="pw-post-body-paragraph iv iw hi ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">到目前为止，我们已经在本地运行了该模型。服务是从docker容器内完成的(即从tensor flow/服务图像)。使用任何容器编排系统，如<a class="ae iu" href="https://docs.docker.com/compose/" rel="noopener ugc nofollow" target="_blank"> docker-compose </a>或<a class="ae iu" href="https://en.wikipedia.org/wiki/Kubernetes" rel="noopener ugc nofollow" target="_blank"> Kubernetes </a>将允许您清楚地将tensorflow提供的ml模型与应用程序或任何其他服务分开。你将从谷歌人的所有优秀工作中受益，例如，一旦新版本被推送到目标目录，就热重装模型:将新模型放入<code class="du kx ky kz la b">classifier/2</code>将自动用新模型重装服务API。</p><p id="27a0" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">然而，如果你想在Heroku上部署这个容器，你将面临最后一个小困难，我现在要减轻这个困难。Tensorflow服务通过端口8501提供Rest API，但是Heroku在运行dyno时会分配一个随机端口。</p><p id="a872" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">因此，必须更新tf-serving命令的默认端口。自定义Dockerfile文件如下:</p><figure class="lb lc ld le fd ij"><div class="bz dy l di"><div class="lf lg l"/></div></figure><p id="4dcd" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">考虑到<code class="du kx ky kz la b">$PORT</code> env变量，对入口点稍作修改:</p><figure class="lb lc ld le fd ij"><div class="bz dy l di"><div class="lf lg l"/></div></figure><p id="9edd" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">瞧啊！你的模型现在可以在地球上的任何地方被请求。如果你想从一个静态网站调用它，你可能会面临一个CORS问题，但这是另一回事。</p><h1 id="5872" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">结论</h1><p id="e2c8" class="pw-post-body-paragraph iv iw hi ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">我在本教程中介绍了如何使用Tensorflow扩展框架来构建、部署和服务一个具有高效API的tensorflow模型(我猜是来自Google)。我很想听听你关于使用TFX的其他好处，技巧等等。</p><p id="40ae" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">别忘了关注我的更新和其他tensorflow相关文章！</p></div></div>    
</body>
</html>