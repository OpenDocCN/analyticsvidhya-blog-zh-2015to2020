<html>
<head>
<title>Siamese Neural Network for signature verification</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于签名验证的连体神经网络</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/siamese-neural-network-for-signature-verification-efd2f399d586?source=collection_archive---------0-----------------------#2019-07-01">https://medium.com/analytics-vidhya/siamese-neural-network-for-signature-verification-efd2f399d586?source=collection_archive---------0-----------------------#2019-07-01</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="540e" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">让我们看看Siamese Architecture如何使用CNN来执行签名验证任务！</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/f8ffa54e66c37a6aa8ec9db27b7e6032.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g0HklSUXPIRLt5bb9kJlVg.jpeg"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">来源:<a class="ae jn" href="https://pixabay.com/photos/writing-pen-man-ink-paper-pencils-1149962/" rel="noopener ugc nofollow" target="_blank">https://pix abay . com/photos/writing-pen-man-ink-paper-pencils-1149962/</a></figcaption></figure><p id="3af4" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">简介</strong></p><p id="aefe" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">一个人的签名几乎不会在每次签名时发生变化，我们用于欺诈检测的算法必须考虑笔画的变化。但是检测系统还应该设法捕捉伪造的签名，这些签名可能与熟练的伪造签名非常相似。幸运的是，深度学习可以自己学习相似性，我们所要做的就是简单明了的反向传播。我们将构建一个连体网络，并训练它来逼近相似性函数，该函数输出0到1之间的分数(1表示完全真实，0表示完全不相似)</p><p id="33fd" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">数据准备</strong></p><p id="16e9" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">让我们将此视为监督学习任务，并准备特征和标签。连体网络由成对的图像及其相应的标签(相似或不相似)提供。用于签名验证的数据集可在SigComp的网站上获得，其链接为<a class="ae jn" href="http://www.iapr-tc11.org/mediawiki/index.php/ICDAR_2011_Signature_Verification_Competition_(SigComp2011)" rel="noopener ugc nofollow" target="_blank">此处</a>。通过在数据集上循环并在另一个数组中形成图像对及其标签的数组来准备数据。这最终使它成为一个二元分类问题！</p><p id="289c" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">网络架构</strong></p><p id="8bca" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">暹罗网络有一个卷积层和池层的堆栈，以及一个具有128个神经元的最终全连接层。姐妹网络承担与原始网络相同的权重和偏差(本质上意味着运行相同的网络两次)。它接受输入图像对并产生两个128维向量作为输出。网络学习在向量空间中对相似的输入图像进行编码，对相近的和不相似的输入图像进行编码，对彼此远离的输入图像进行编码。训练它的传统方法是通过使用对比损失函数或一次拍摄三幅图像的三重损失。在这篇文章中，我们将用“交叉熵”损失来训练我们的网络。你怎么问？这是我们建筑的布局。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es kk"><img src="../Images/d859abe3645b3d4f5c7de6c4af2f65ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_HcPUerQPoKTeyaLL4Bb3w.jpeg"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">具有分类的连体网络</figcaption></figure><p id="0f1e" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">然后，这两个向量按元素相减以形成单个128维向量(不要与仅产生单个标量值作为输出的L1距离函数相混淆)。</p><p id="7896" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">嗯，我们快完成了。它的下一部分是一个完全连接的网络，该网络将128-D距离向量作为输入，输出层具有单个输出神经元，用于通过sigmoid激活进行分类。隐藏层的数量是一个超参数，可以通过实验来获得最佳结果。现在，用我们先前收集的图像对和标签来训练网络。损失函数是“二元交叉熵”，最适合的优化器是“Adagrad”。</p><p id="5811" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">结论</strong></p><p id="17b2" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">经过几个时期(5到7)的训练后，我们将在验证集中获得接近93%的准确率。注意:为了使网络在真实世界的签名中表现良好，SigComp数据集可以通过添加噪声和随机模糊来增强，以迫使网络良好地概括，因为数据集是使用几乎没有伪像的数字平板电脑收集的。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es kl"><img src="../Images/247fb7b18df146ec4e37e3181fe9f2bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UqaADGWHcYw_mXYUvPaq5w.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">而且，就是这么做的。</figcaption></figure><p id="f5ff" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">源代码:<a class="ae jn" href="https://he-s3.s3.amazonaws.com/media/sprint/axis-hackathon/team/456719/97f5efaproject.rar" rel="noopener ugc nofollow" target="_blank">https://he-S3 . S3 . Amazon AWS . com/media/sprint/axis-hackathon/team/456719/97 F5 EFA project . rar</a></p><p id="a282" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">Github链接:【https://github.com/Baakchsu T4】</p><div class="km kn ez fb ko kp"><a href="https://www.linkedin.com/in/anirudh-s-37307114b/" rel="noopener  ugc nofollow" target="_blank"><div class="kq ab dw"><div class="kr ab ks cl cj kt"><h2 class="bd hj fi z dy ku ea eb kv ed ef hh bi translated">在Linkedin上找到我</h2></div><div class="kw l"><div class="kx l ky kz la kw lb jh kp"/></div></div></a></div></div></div>    
</body>
</html>