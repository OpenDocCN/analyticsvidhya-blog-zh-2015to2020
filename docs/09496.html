<html>
<head>
<title>Ridge and Lasso: Hyper Parameter Tuning in Linear Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">山脊和套索:线性回归中的超参数调整</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/ridge-and-lasso-hyper-tuning-in-linear-regression-2ff88d5968c?source=collection_archive---------9-----------------------#2020-09-08">https://medium.com/analytics-vidhya/ridge-and-lasso-hyper-tuning-in-linear-regression-2ff88d5968c?source=collection_archive---------9-----------------------#2020-09-08</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="71a7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在线性回归中，如果训练数据集完全符合模型，形成一条直线(如y=mx ),并且形成的回归线覆盖所有点，但在测试时，预测值和实际值有很大差异。这是训练数据在线性回归模型上过度拟合的情况。</p><p id="78b0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">怎么才能解决呢？</p><p id="621a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这可以通过使用岭回归或套索回归来解决。</p></div><div class="ab cl jd je gp jf" role="separator"><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji"/></div><div class="hb hc hd he hf"><p id="dcd7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">1.岭回归:</p><p id="f783" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">线性回归的损失函数如下所示:</p><figure class="jl jm jn jo fd jp er es paragraph-image"><div class="er es jk"><img src="../Images/6ab1b32dd9862107c1bb9579623b0f67.png" data-original-src="https://miro.medium.com/v2/resize:fit:490/format:webp/1*loAYomPaImgSWHUCudLtrg.png"/></div><figcaption class="js jt et er es ju jv bd b be z dx translated">线性回归的成本函数</figcaption></figure><p id="40db" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">其中L是损耗，Y-hat是预测值，Y是实际输出值。</p><p id="81bd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里我们想让损失函数值收敛到0，即斜率最大。</p><p id="4566" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是模型可能面临过度拟合的时候。在岭回归中，损失函数是通过增加一个简单的方程加法来调整的，它可以降低斜率曲线的陡度。该公式如下所示:</p><figure class="jl jm jn jo fd jp er es paragraph-image"><div class="er es jw"><img src="../Images/44e2e6b6bb7facaded01055c53bbf279.png" data-original-src="https://miro.medium.com/v2/resize:fit:1054/format:webp/1*psb6zRncVMIU3og4V2i6dg.png"/></div><figcaption class="js jt et er es ju jv bd b be z dx translated">岭回归的成本函数</figcaption></figure><p id="47d2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在我们将使损失函数/成本函数的这个值收敛到0。</p><p id="e15b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这将降低斜率曲线的陡度，从而避免过度拟合的情况。</p><p id="e3a4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">λ保持为0到任何正整数。让我们将lambda的值设为1，并查看值或线如何变化的示例:</p><p id="e9b4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在线性回归中，L = 0。假设斜率值为1.3，则山脊中的L将变为L= 0 + (1.3) = 1.69。现在在线性回归中，当值收敛到0时，我们停止，但现在在岭中，如果值不收敛，它将继续前进，并选择不同的线，直到它收敛到0。</p><p id="cd25" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于m1、m2和m3等多个特性，方程将变成:</p><figure class="jl jm jn jo fd jp er es paragraph-image"><div class="er es jx"><img src="../Images/18cb1b6903adfb7f25d39657335e1c18.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/1*1pSX9GcgaYh7aANWmYP9XA.png"/></div><figcaption class="js jt et er es ju jv bd b be z dx translated">多特征岭回归的代价函数</figcaption></figure><p id="1d8c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这将惩罚曲线，并选择L的方程最小的最佳拟合线。</p></div><div class="ab cl jd je gp jf" role="separator"><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji"/></div><div class="hb hc hd he hf"><p id="3754" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.套索回归:</p><p id="64a2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Lasso回归的损失函数/成本函数方程如下:</p><figure class="jl jm jn jo fd jp er es paragraph-image"><div class="er es jy"><img src="../Images/3364cd54acbecd6c57b85835c423bf8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:920/format:webp/1*WL4APN5s6QJhNfnAqGloEQ.png"/></div><figcaption class="js jt et er es ju jv bd b be z dx translated">Lasso回归的成本函数</figcaption></figure><p id="1603" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里我们没有使用斜率的平方，而是使用斜率的大小。</p><p id="97c8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">它不仅用于克服线性回归的过拟合值，还用于通过以下方式进行特征选择:</p><p id="b73e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">假设有三个特征m1、m2和m3。等式将是这样的:</p><figure class="jl jm jn jo fd jp er es paragraph-image"><div class="er es jz"><img src="../Images/07b037facab5708822afbdce27b05dc8.png" data-original-src="https://miro.medium.com/v2/resize:fit:872/format:webp/1*hwZoFpBWPwVU_X42DOxcJw.png"/></div><figcaption class="js jt et er es ju jv bd b be z dx translated">多要素Lasso回归的成本函数</figcaption></figure><p id="f2c1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当我们趋向于收敛到0时，一些值变得非常小，这将被忽略，这意味着特征不重要，并且在输出值的预测中不太重要。</p><p id="5b72" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，通过惩罚曲线，它也有助于特征选择。</p><p id="e956" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在交叉验证的帮助下，可以通过多个值来选择λ值。调整该值将有助于选择合适的lambda值来预测最佳拟合线。</p></div></div>    
</body>
</html>