<html>
<head>
<title>Building a dog search engine with FaceNet</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用 FaceNet 构建一个狗搜索引擎</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/building-a-dog-search-engine-with-facenet-65d1ae79dd8a?source=collection_archive---------6-----------------------#2020-10-15">https://medium.com/analytics-vidhya/building-a-dog-search-engine-with-facenet-65d1ae79dd8a?source=collection_archive---------6-----------------------#2020-10-15</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="ef5f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用自定义在线硬三元组挖掘在 dog-face 数据集上实现 Facenet 的论文到代码</p></div><div class="ab cl jd je gp jf" role="separator"><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji"/></div><div class="hb hc hd he hf"><p id="80de" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">FaceNet 是目前最先进的人脸识别技术。它被广泛应用于几种现成的产品中。</p><blockquote class="jk jl jm"><p id="74d4" class="if ig jn ih b ii ij ik il im in io ip jo ir is it jp iv iw ix jq iz ja jb jc hb bi translated">“FaceNet……直接学习从人脸图像到紧致欧几里得空间的<strong class="ih hj">映射</strong>,其中距离直接对应于人脸相似性的度量。一旦产生了这个空间，诸如人脸识别、验证和聚类之类的任务就可以使用标准技术以 FaceNet 嵌入作为特征向量来容易地实现”——FaceNet 论文</p></blockquote><p id="b5a6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">FaceNet 是一种神经网络，它学习在低维“嵌入”空间中表示或编码图像，以使同一张脸的图像彼此更接近。facenet 有效生成这种人脸编码表示(嵌入)的能力使其适用于一次性分类，即，为了构建人脸识别系统，该模型将只需要一张人脸图像来生成嵌入。然后，可以将它与一组图像嵌入的图像进行比较，以查看它是否接近潜在/嵌入空间中的另一个图像。</p><figure class="js jt ju jv fd jw er es paragraph-image"><div class="er es jr"><img src="../Images/6ffe360042013d8e9b230e37b25454d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1312/format:webp/1*fxef4ok_qbZArcLLPikm9g.png"/></div><figcaption class="jz ka et er es kb kc bd b be z dx translated">FaceNet 生成图像的嵌入</figcaption></figure><p id="4287" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当图像具有不同的光照和姿态时，FaceNet 已经被证明是有效的。</p><figure class="js jt ju jv fd jw er es paragraph-image"><div class="er es kd"><img src="../Images/1f093c34a79763a7bf9e10cd4e2ebb6b.png" data-original-src="https://miro.medium.com/v2/resize:fit:728/format:webp/0*L1qcswckWlxfIJyx.jpg"/></div><figcaption class="jz ka et er es kb kc bd b be z dx translated">面网是照明和姿态不可知的</figcaption></figure><blockquote class="jk jl jm"><p id="acc4" class="if ig jn ih b ii ij ik il im in io ip jo ir is it jp iv iw ix jq iz ja jb jc hb bi translated">在这篇文章中，我将演示在狗脸数据集上训练的 FaceNet 的自定义实现。我的方法是阅读论文(FaceNet:人脸识别和聚类的统一嵌入),并尝试根据我对论文的解释实现模型。我使用 pytorch 来实现。</p></blockquote><h1 id="562c" class="ke kf hi bd kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb bi translated">模型架构和培训设计</h1><p id="78ae" class="pw-post-body-paragraph if ig hi ih b ii lc ik il im ld io ip iq le is it iu lf iw ix iy lg ja jb jc hb bi translated">本文描述了一个标准的 inception 风格的 CNN 模型来生成嵌入。</p><figure class="js jt ju jv fd jw er es paragraph-image"><div class="er es lh"><img src="../Images/1b13c5baed9c80546bf8af4b82dbe2b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1064/format:webp/1*iSVq-r1tEL1iROkqj8fpkQ.png"/></div><figcaption class="jz ka et er es kb kc bd b be z dx translated">初始模型图</figcaption></figure><p id="5323" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">建筑很标准，对吧？让这个模型如此强大的秘密武器是它的训练哲学和损失函数——三重损失。</p><p id="5d05" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">该模型的目标是生成满足这两个约束的嵌入:</p><ol class=""><li id="c91a" class="li lj hi ih b ii ij im in iq lk iu ll iy lm jc ln lo lp lq bi translated"><em class="jn">相同的人脸在嵌入空间中彼此接近</em></li><li id="2abd" class="li lj hi ih b ii lr im ls iq lt iu lu iy lv jc ln lo lp lq bi translated"><em class="jn">不同的面孔离得很远</em></li></ol><p id="abd7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">损失函数正是这样做的。</p><blockquote class="jk jl jm"><p id="63d1" class="if ig jn ih b ii ij ik il im in io ip jo ir is it jp iv iw ix jq iz ja jb jc hb bi translated">培训步骤将包括以下内容:</p></blockquote><ol class=""><li id="9ae4" class="li lj hi ih b ii ij im in iq lk iu ll iy lm jc ln lo lp lq bi translated">选择 3 幅图像</li></ol><ul class=""><li id="01f6" class="li lj hi ih b ii ij im in iq lk iu ll iy lm jc lw lo lp lq bi translated">锚点图像(a)—一个人的图像 A</li><li id="e151" class="li lj hi ih b ii lr im ls iq lt iu lu iy lv jc lw lo lp lq bi translated">正样本(p)——人 A 的另一个图像</li><li id="33c4" class="li lj hi ih b ii lr im ls iq lt iu lu iy lv jc lw lo lp lq bi translated">负样本(n) —人 B 的图像</li></ul><p id="fc3f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.训练模型以最小化三重态损失:</p><figure class="js jt ju jv fd jw er es paragraph-image"><div class="er es lx"><img src="../Images/121ce51fd27e7fc18bd3e40d0476a62e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1010/1*AC3le14_FQdrfuLTsXmLFw.gif"/></div></figure><figure class="js jt ju jv fd jw er es paragraph-image"><div class="er es ly"><img src="../Images/4e6761af558659e81799027bd485f11d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1112/1*HYhIx4gwPgpfkv--UIbVlg.gif"/></div><figcaption class="jz ka et er es kb kc bd b be z dx translated">三连音丢失训练:最小化 a-p 距离，最大化 n-p 距离</figcaption></figure><p id="d40d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你不清楚三重损失函数是如何工作的，可以看看 OG 吴恩达本人的这个视频:<a class="ae lz" href="https://www.youtube.com/watch?v=d2XB5-tuCWU&amp;ab_channel=Deeplearning.ai" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=d2XB5-tuCWU&amp;ab _ channel = deep learning . ai</a></p><p id="1b69" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">本文提出的对训练过程的优化之一是三元组选择过程——硬三元组挖掘。为了减少模型收敛所需的时间，需要仔细选择有助于模型改进的三元组。</p><p id="365a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于每个锚图像，我们选择嵌入距离锚最远的正片图像——硬正片。我们选择一个嵌入最接近锚的负片图像——硬负片。</p><figure class="js jt ju jv fd jw er es paragraph-image"><div class="er es ma"><img src="../Images/f8270ad7391e89398f4429963547cfad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1212/format:webp/1*oWTnl3yv-bT65RR4zO9HdA.png"/></div><figcaption class="jz ka et er es kb kc bd b be z dx translated">啊…古老的马克·沃尔伯格 vs 马特达蒙难题。在硬三元组挖掘方法中，我们挑选出硬阳性和硬阴性样本，使模型变得有趣😜</figcaption></figure><p id="dd9b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">训练过程本质上是神经网络学习生成最小化三联体损失的嵌入。这确保了经过训练的模型将同一个人的图像彼此非常接近地嵌入。</p><h1 id="3ce7" class="ke kf hi bd kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb bi translated">建立一个狗搜索引擎</h1><p id="ade8" class="pw-post-body-paragraph if ig hi ih b ii lc ik il im ld io ip iq le is it iu lf iw ix iy lg ja jb jc hb bi translated">我使用实现硬三元组挖掘的自定义数据加载器在 DogFace 数据集上训练了 Facenet。请查看<a class="ae lz" href="https://github.com/kvsnoufal/Pytorch-FaceNet-DogDataset" rel="noopener ugc nofollow" target="_blank">我的 github </a>获取代码。</p><figure class="js jt ju jv fd jw er es paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="er es mb"><img src="../Images/662465dd6ec4d3454ef2d5369e518eef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gWlkGhZ-A8X15AlUEin7iw.png"/></div></div><figcaption class="jz ka et er es kb kc bd b be z dx translated">NVIDIA GTX1080Ti 小时培训</figcaption></figure><figure class="js jt ju jv fd jw er es paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="er es mg"><img src="../Images/478cf2f709184b04e9ffa46ae745fd46.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*SiK4QBvDVsfCJ7uTJpLQJA.gif"/></div></div><figcaption class="jz ka et er es kb kc bd b be z dx translated">嵌入空间可视化— PCA</figcaption></figure><figure class="js jt ju jv fd jw er es paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="er es mh"><img src="../Images/cf557665d8b61d7d8a85e10e054d419f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*MiH6Wz_ClHSMVxerxe4REA.gif"/></div></div><figcaption class="jz ka et er es kb kc bd b be z dx translated">Web 界面-快速查看</figcaption></figure><p id="692d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">查看 YouTube 视频:</p><figure class="js jt ju jv fd jw"><div class="bz dy l di"><div class="mi mj l"/></div><figcaption class="jz ka et er es kb kc bd b be z dx translated">用狗脸测试反向图像搜索</figcaption></figure><blockquote class="jk jl jm"><p id="e5e0" class="if ig jn ih b ii ij ik il im in io ip jo ir is it jp iv iw ix jq iz ja jb jc hb bi translated"><em class="hi">我知道我在这里展示的远非完美。我的目标是从头开始实现一篇论文，并在此过程中了解更多关于 pytorch 的知识。我将更新我的</em> <a class="ae lz" href="https://github.com/kvsnoufal/Pytorch-FaceNet-DogDataset" rel="noopener ugc nofollow" target="_blank"> <em class="hi"> github </em> </a> <em class="hi">关于训练过程、架构和实施的更多细节。</em></p></blockquote><p id="96a8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在我的<a class="ae lz" href="https://github.com/kvsnoufal/Pytorch-FaceNet-DogDataset" rel="noopener ugc nofollow" target="_blank"> github </a>上查看完整实现</p><h2 id="fa3d" class="mk kf hi bd kg ml mm mn kk mo mp mq ko iq mr ms ks iu mt mu kw iy mv mw la mx bi translated">巨人的肩膀:</h2><ol class=""><li id="354b" class="li lj hi ih b ii lc im ld iq my iu mz iy na jc ln lo lp lq bi translated">FaceNet:人脸识别和聚类的统一嵌入</li><li id="4b14" class="li lj hi ih b ii lr im ls iq lt iu lu iy lv jc ln lo lp lq bi translated"><a class="ae lz" href="https://github.com/GuillaumeMougeot/DogFaceNet/releases/" rel="noopener ugc nofollow" target="_blank"> DogFace 数据集</a></li><li id="215b" class="li lj hi ih b ii lr im ls iq lt iu lu iy lv jc ln lo lp lq bi translated">Thiemeyyah</li><li id="23a5" class="li lj hi ih b ii lr im ls iq lt iu lu iy lv jc ln lo lp lq bi translated">如何单元测试一个必读-(<a class="ae lz" rel="noopener" href="/@keeper6928/how-to-unit-test-machine-learning-code-57cf6fd81765">https://medium . com/@ keeper 6928/how-to-unit-test-machine-learning-code-57 cf 6 FD 81765</a>)</li><li id="3201" class="li lj hi ih b ii lr im ls iq lt iu lu iy lv jc ln lo lp lq bi translated">狗脸网(<a class="ae lz" href="https://github.com/GuillaumeMougeot/DogFaceNet" rel="noopener ugc nofollow" target="_blank">https://github.com/GuillaumeMougeot/DogFaceNet</a>)</li></ol></div><div class="ab cl jd je gp jf" role="separator"><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji"/></div><div class="hb hc hd he hf"><blockquote class="jk jl jm"><p id="63fc" class="if ig jn ih b ii ij ik il im in io ip jo ir is it jp iv iw ix jq iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="hi">关于作者</em> </strong></p><p id="aea1" class="if ig jn ih b ii ij ik il im in io ip jo ir is it jp iv iw ix jq iz ja jb jc hb bi translated">我在阿联酋迪拜控股公司工作，是一名数据科学家。你可以在 kvsnoufal@gmail.com 或者<a class="ae lz" href="https://www.linkedin.com/in/kvsnoufal/" rel="noopener ugc nofollow" target="_blank"><em class="hi"/></a>联系我</p></blockquote></div></div>    
</body>
</html>