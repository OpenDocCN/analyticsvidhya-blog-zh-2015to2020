<html>
<head>
<title>How to scrape a news website using Python, BeautyfulSoup, and Selenium to build the Word Cloud</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">å¦‚ä½•ä½¿ç”¨Pythonã€BeautyfulSoupå’ŒSeleniumæ„å»ºå•è¯äº‘æ¥æ„å»ºæ–°é—»ç½‘ç«™</h1>
<blockquote>åŸæ–‡ï¼š<a href="https://medium.com/analytics-vidhya/how-to-scrape-a-news-website-using-python-beautyfulsoup-and-selenium-to-build-the-word-cloud-3355066b72dc?source=collection_archive---------13-----------------------#2020-05-25">https://medium.com/analytics-vidhya/how-to-scrape-a-news-website-using-python-beautyfulsoup-and-selenium-to-build-the-word-cloud-3355066b72dc?source=collection_archive---------13-----------------------#2020-05-25</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="8d5f" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">é€šè¿‡ä½¿ç”¨è¯äº‘å®ç°æ›´å¥½çš„å¯è§†åŒ–</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/cbf0f04ba3d902e324244702922cf234.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oFjaReilo0xBbXt766hKwA.png"/></div></div></figure><p id="a663" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">ä»2020å¹´åˆåˆ°ç°åœ¨ï¼Œé¦™æ¸¯æŠ¥çº¸ä¸Šæœ€å¸¸å‡ºç°çš„æ–°é—»æ˜¯ä»€ä¹ˆï¼Ÿé¦™æ¸¯ç¤¾ä¼šè¿åŠ¨ï¼Œ2019å† çŠ¶ç—…æ¯’è¿˜æ˜¯ä¸­ç¾è´¸æ˜“æˆ˜ï¼Ÿæˆ‘åœ¨é¦™æ¸¯åˆ®äº†ä¸€ä»½çŸ¥åæŠ¥çº¸ï¼Œå¸Œæœ›ç”¨ä¸€ä¸ªå¥½çš„å¯è§†åŒ–æ–¹æ³•~ <strong class="jl hj">å­—äº‘</strong>å¾—åˆ°æˆ‘æƒ³è¦çš„ç­”æ¡ˆã€‚</p><p id="8cf3" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jl hj">ä»€ä¹ˆæ˜¯ç½‘é¡µæŠ“å–ï¼Ÿ</strong></p><p id="ddb6" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">ç½‘ç»œæŠ“å–å·¥å…·ä¸“é—¨ç”¨äºä»ç½‘ç«™ä¸Šæå–ä¿¡æ¯ã€‚å®ƒä»¬ä¹Ÿè¢«ç§°ä¸ºç½‘ç»œæ”¶é›†å·¥å…·æˆ–ç½‘ç»œæ•°æ®æå–å·¥å…·ã€‚</p><p id="1478" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jl hj">ä¸ºä»€ä¹ˆè¦åšç½‘é¡µæŠ“å–ï¼Ÿ</strong></p><p id="c379" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">ç½‘ç»œæŠ“å–å·¥å…·å¯ä»¥åœ¨å„ç§æƒ…å†µä¸‹ç”¨äºå„ç§ç›®çš„ã€‚ä¾‹å¦‚:</p><ol class=""><li id="3dc4" class="kf kg hi jl b jm jn jp jq js kh jw ki ka kj ke kk kl km kn bi translated">æ”¶é›†å¸‚åœºç ”ç©¶æ•°æ®</li><li id="96d1" class="kf kg hi jl b jm ko jp kp js kq jw kr ka ks ke kk kl km kn bi translated">æ”¶é›†è‚¡ç¥¨å¸‚åœºä¿¡æ¯</li><li id="f097" class="kf kg hi jl b jm ko jp kp js kq jw kr ka ks ke kk kl km kn bi translated">æ”¶é›†è”ç³»ä¿¡æ¯</li><li id="9a38" class="kf kg hi jl b jm ko jp kp js kq jw kr ka ks ke kk kl km kn bi translated">æ”¶é›†æ•°æ®ä»¥ä¸‹è½½ä¾›ç¦»çº¿é˜…è¯»æˆ–å­˜å‚¨</li><li id="659c" class="kf kg hi jl b jm ko jp kp js kq jw kr ka ks ke kk kl km kn bi translated">è·Ÿè¸ªå¤šä¸ªå¸‚åœºçš„ä»·æ ¼ç­‰ã€‚</li></ol><p id="7891" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jl hj">å¦‚ä½•åœ¨Pythonä¸­åˆ®ï¼Ÿ</strong></p><p id="b1d9" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">ç”¨PythonæŠ“å–ä¸€ä¸ªç½‘ç«™éå¸¸å®¹æ˜“ï¼Œå°¤å…¶æ˜¯åœ¨BeautifulSoupå’ŒSeleniumåº“çš„å¸®åŠ©ä¸‹ã€‚Beautiful Soupæ˜¯ä¸€ä¸ªPythonåº“æ¨¡å—ï¼Œå…è®¸å¼€å‘äººå‘˜é€šè¿‡ç¼–å†™å°‘é‡ä»£ç ï¼Œå¿«é€Ÿè§£æç½‘é¡µHTMLä»£ç å¹¶ä»ä¸­æå–æœ‰ç”¨çš„æ•°æ®ï¼Œå‡å°‘å¼€å‘æ—¶é—´ï¼ŒåŠ å¿«ç½‘é¡µæŠ“å–çš„ç¼–ç¨‹é€Ÿåº¦ã€‚Seleniumæ˜¯ä¸€ä¸ªè‡ªåŠ¨åŒ–æµ‹è¯•ç½‘é¡µçš„å·¥å…·ï¼Œå¯ä»¥é€šè¿‡å®ƒæä¾›çš„ä¸€äº›æ–¹æ³•è‡ªåŠ¨æ“ä½œæµè§ˆå™¨ï¼Œå¯ä»¥å®Œå…¨æ¨¡æ‹ŸçœŸäººçš„æ“ä½œã€‚</p><p id="9a6f" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">åœ¨æŠ“å–ä¸€ä¸ªç½‘ç«™ä¹‹å‰ï¼Œå¿…é¡»åšä¸€äº›å‡†å¤‡å·¥ä½œï¼Œåœ¨Jupiterç¬”è®°æœ¬ä¸­è¾“å…¥å‘½ä»¤ï¼Œå®ƒå°†å®‰è£…ä»¥ä¸‹åº“ã€‚</p><pre class="iy iz ja jb fd kt ku kv kw aw kx bi"><span id="d687" class="ky kz hi ku b fi la lb l lc ld">!pip install BeautifulSoup4<br/>!pip install selenium</span></pre><p id="1c47" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jl hj">ä»€ä¹ˆæ˜¯è¯äº‘ï¼Œæˆ‘ä»¬ä¸ºä»€ä¹ˆéœ€è¦å®ƒï¼Ÿ</strong></p><p id="99a4" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">Word Cloudæ˜¯Pythonä¸­éå¸¸å¥½çš„ç¬¬ä¸‰æ–¹word cloudå¯è§†åŒ–åº“ã€‚å•è¯äº‘æ˜¯åœ¨æ–‡æœ¬ä¸­æ›´é¢‘ç¹å‡ºç°çš„å…³é”®è¯çš„å¯è§†åŒ–æ˜¾ç¤ºã€‚WordCloudä¼šè¿‡æ»¤æ‰å¤§é‡ä½é¢‘ä½è´¨é‡çš„æ–‡å­—ä¿¡æ¯ï¼Œè®©å—ä¼—ä¸€çœ¼å°±èƒ½æ˜ç™½æ–‡å­—çš„ä¸»æ—¨ã€‚</p><p id="2c4f" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jl hj">ä»€ä¹ˆæ˜¯åˆ†è¯ï¼Ÿ</strong></p><p id="044e" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">åˆ†è¯æ˜¯å°†è¿ç»­çš„è¯åºåˆ—æŒ‰ç…§ä¸€å®šçš„è§„èŒƒé‡æ–°ç»„åˆæˆè¯åºåˆ—çš„è¿‡ç¨‹ã€‚Jiebaæ˜¯ä¸€ä¸ªæ¯”è¾ƒå¥½çš„ä¸­æ–‡åˆ†è¯åº“ï¼Œå› ä¸ºä¸­æ–‡é€šå¸¸åŒ…å«æ•´ä¸ªå¥å­ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦ä½¿ç”¨Jiebaæ¥è¾…åŠ©åˆ†è¯çš„å·¥ä½œã€‚</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es le"><img src="../Images/2218b1e03ecc10a326d8ae50b5cb7f1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*26qQCmYtmhLhPLjmy2kY4g.png"/></div></div></figure><p id="dae2" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">åœ¨ç”Ÿæˆwordäº‘æ˜ åƒä¹‹å‰ï¼Œå¿…é¡»åšä¸€äº›å‡†å¤‡å·¥ä½œï¼Œåœ¨Jupiterç¬”è®°æœ¬ä¸­è¾“å…¥å‘½ä»¤ï¼Œå®ƒå°†å®‰è£…ä»¥ä¸‹åº“ã€‚</p><pre class="iy iz ja jb fd kt ku kv kw aw kx bi"><span id="e100" class="ky kz hi ku b fi la lb l lc ld">!pip install wordcloud<br/>!pip install jieba</span></pre></div><div class="ab cl lf lg gp lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="hb hc hd he hf"><p id="df97" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jl hj"> #åŠ è½½åº“</strong></p><pre class="iy iz ja jb fd kt ku kv kw aw kx bi"><span id="ffb2" class="ky kz hi ku b fi la lb l lc ld">#! /usr/bin/env python<br/># -*- encoding UTF-8 -*-</span><span id="8028" class="ky kz hi ku b fi lm lb l lc ld">import os<br/>import sys<br/>from importlib import reload<br/>reload(sys)</span><span id="1016" class="ky kz hi ku b fi lm lb l lc ld">if sys.version[0] == '2':<br/>    sys.setdefaultencoding("utf-8")<br/>    <br/>    import parse<br/>    import urllib2<br/>else:<br/>    import urllib.parse<br/>    from urllib.request import urlopen</span><span id="0fc4" class="ky kz hi ku b fi lm lb l lc ld">import re<br/>import jieba</span><span id="5e17" class="ky kz hi ku b fi lm lb l lc ld">import pandas as pd<br/>import numpy as np</span><span id="ae3d" class="ky kz hi ku b fi lm lb l lc ld">#from bs4 import BeautifulSoup<br/>from selenium import webdriver<br/>from selenium.webdriver import ChromeOptions</span><span id="0552" class="ky kz hi ku b fi lm lb l lc ld">from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator</span><span id="de24" class="ky kz hi ku b fi lm lb l lc ld">from PIL import Image</span><span id="7c7b" class="ky kz hi ku b fi lm lb l lc ld">import matplotlib.pyplot as plt<br/>%matplotlib inline</span><span id="da5f" class="ky kz hi ku b fi lm lb l lc ld">jieba.enable_paddle()</span></pre><p id="5062" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jl hj"> #æ¸…ç†CSSã€JavaScriptå’ŒHTMLæ ‡ç­¾</strong></p><pre class="iy iz ja jb fd kt ku kv kw aw kx bi"><span id="e46a" class="ky kz hi ku b fi la lb l lc ld">def cleanHTML(html):<br/>    for script in html(["script", "style"]): # remove all javascript and stylesheet code<br/>        script.extract()<br/>    # get text<br/>    text = html.get_text()<br/>    # break into lines and remove leading and trailing space on each<br/>    lines = (line.strip() for line in text.splitlines())<br/>    # break multi-headlines into a line each<br/>    chunks = (phrase.strip() for line in lines for phrase in line.split("  "))<br/>    # drop blank lines<br/>    text = '\n'.join(chunk for chunk in chunks if chunk)<br/>    <br/>    return text</span></pre><p id="11dd" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jl hj"> #æŸ¥æ‰¾å½“æ—¥ä¸»è¦ç„¦ç‚¹æ–°é—»é“¾æ¥</strong></p><pre class="iy iz ja jb fd kt ku kv kw aw kx bi"><span id="5ca6" class="ky kz hi ku b fi la lb l lc ld">def getNewsLink(news_date):<br/>    try:<br/>        options = ChromeOptions()<br/>        options.add_argument('headless')<br/>        driver = webdriver.Chrome(options=options)</span><span id="0fc5" class="ky kz hi ku b fi lm lb l lc ld">        url = '<a class="ae ln" href="https://orientaldaily.on.cc/cnt/news/'" rel="noopener ugc nofollow" target="_blank">https://orientaldaily.on.cc/cnt/news/'</a> + str(news_date) + '/mobile/index.html'</span><span id="62dc" class="ky kz hi ku b fi lm lb l lc ld">        driver.get(url)<br/>        driver.implicitly_wait(30)</span><span id="0585" class="ky kz hi ku b fi lm lb l lc ld">        html_source = (driver.page_source.encode('utf-8'))</span><span id="cd6e" class="ky kz hi ku b fi lm lb l lc ld">        driver.quit()</span><span id="86e4" class="ky kz hi ku b fi lm lb l lc ld">        soup = BeautifulSoup(html_source, 'html.parser')<br/>        news = soup.find('div', attrs={'id':'swipe'})<br/>        main_focus = soup.find('div', attrs={'class':'main-focus-container'})<br/>        main_focus_link = '<a class="ae ln" href="https://orientaldaily.on.cc'" rel="noopener ugc nofollow" target="_blank">https://orientaldaily.on.cc'</a> + main_focus.find('a', href = re.compile(r'[/]([a-z]|[A-Z])\w+')).attrs['href']</span><span id="c5aa" class="ky kz hi ku b fi lm lb l lc ld">        return (main_focus_link)<br/>    except:<br/>        return 0</span></pre><p id="0e5e" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jl hj"> #æ•°æ®æ”¶é›†</strong></p><pre class="iy iz ja jb fd kt ku kv kw aw kx bi"><span id="d81f" class="ky kz hi ku b fi la lb l lc ld">def getNews(news_url):<br/>    options = ChromeOptions()<br/>    options.add_argument('headless')<br/>    driver = webdriver.Chrome(options=options)<br/>    <br/>    driver.get(news_url)<br/>    driver.implicitly_wait(30)<br/>        <br/>    html_source = (driver.page_source.encode('utf-8'))<br/>        <br/>    driver.quit()<br/>    <br/>    soup = BeautifulSoup(html_source, 'html.parser')<br/>    paragraph = soup.find_all('div', attrs={'class':'paragraph'})<br/>    paragraph_list = []<br/>    <br/>    for sub_paragraph in paragraph:<br/>        clean_sub_paragraph = cleanHTML(sub_paragraph)<br/>        paragraph_list.append(clean_sub_paragraph)<br/>        <br/>    full_paragraph_list = [e for e in paragraph_list if e]<br/>    <br/>    if (len(full_paragraph_list) &gt; 0):<br/>        f=open("news.txt", "a+")<br/>        <br/>        for i in range(len(full_paragraph_list)):<br/>            <br/>            <br/>            for line in full_paragraph_list[i].splitlines():<br/>                clean_paragraph = cleanText(line)<br/>                <br/>                f.write(clean_paragraph)<br/>                <br/>        f.write('\n\n')<br/>        f.close()</span></pre><p id="ff79" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jl hj"> #ç”»å­—äº‘</strong></p><pre class="iy iz ja jb fd kt ku kv kw aw kx bi"><span id="4a99" class="ky kz hi ku b fi la lb l lc ld">def draw_word_cloud(text, images_name, plt_title):<br/>    images_path = images_name<br/>    images = Image.open(images_path)<br/>    <br/>    #create a write mask <br/>    images_mask = Image.new("RGB", images.size, (255,255,255))<br/>    images_mask.paste(images, images)<br/>    images_mask = np.array(images_mask)<br/>    <br/>    color = ImageColorGenerator(images_mask)<br/>    <br/>    #Chinese need to use another font, download it from <a class="ae ln" href="https://www.freechinesefont.com/" rel="noopener ugc nofollow" target="_blank">https://www.freechinesefont.com/</a><br/>    font_path = 'HanyiSentyCandy.ttf'<br/>    <br/>    #create wordcloud ~ <br/>    wc = WordCloud(font_path=font_path, max_font_size=250, max_words=1000, mask=images_mask, \<br/>                   margin=5, background_color="black").generate_from_text(text)<br/>    wc.recolor(color_func = color, random_state = 7)<br/>    <br/>    #Save the image<br/>    wc.to_file("news.png")<br/>    <br/>    plt.rcParams["figure.figsize"] = (16, 12)<br/>    <br/>    plt.title(plt_title)<br/>    plt.imshow(wc, interpolation="bilinear")<br/>    plt.axis("off")<br/>    plt.show()</span></pre><p id="4da8" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jl hj"> #ä¸»é€»è¾‘:</strong></p><pre class="iy iz ja jb fd kt ku kv kw aw kx bi"><span id="566e" class="ky kz hi ku b fi la lb l lc ld">if __name__ == "__main__":<br/>    start_date = input("Enter the start date (yyyymmdd): ")<br/>    end_date = input("Enter the end date (yyyymmdd): ")<br/>    <br/>    if ((start_date != "") and (end_date != "")):<br/>        daterange = pd.date_range(start_date, end_date)<br/>        <br/>        #Download the main focus news<br/>        for news_date in daterange:<br/>            print ('Downloading ' + str(news_date) + ' news...')<br/>            single_news_date = dateConvert(news_date)<br/>            getNews(getNewsLink(single_news_date))<br/>            <br/>        source_text = open('news.txt', 'r',encoding= 'UTF-8').read()<br/>        tokens = ' '.join(jieba.cut_for_search(source_text))<br/>        <br/>        title = str(start_date) + ' - ' + str(end_date) + ' Main Focus News on on.cc'<br/>        <br/>        draw_word_cloud(tokens, 'hongkongpng.png', title)</span></pre><p id="e197" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jl hj"> #æœªæ¥æ”¹å–„</strong></p><ol class=""><li id="a0a7" class="kf kg hi jl b jm jn jp jq js kh jw ki ka kj ke kk kl km kn bi translated">æ·»åŠ åœç”¨è¯çš„å¤„ç†</li><li id="4226" class="kf kg hi jl b jm ko jp kp js kq jw kr ka ks ke kk kl km kn bi translated">ä½¿ç”¨ä¸åŒçš„åˆ†è¯åº“ï¼Œå¦‚thulacã€FoolNLTKã€HanLPã€nlpirå’Œltpã€‚</li></ol></div><div class="ab cl lf lg gp lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="hb hc hd he hf"><p id="1311" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">æ„Ÿè°¢é˜…è¯»ï¼å¦‚æœä½ å–œæ¬¢è¿™ç¯‡æ–‡ç« ï¼Œè¯·é€šè¿‡é¼“æŒæ¥æ„Ÿè°¢ä½ çš„æ”¯æŒ(ğŸ‘ğŸ¼)æŒ‰é’®ï¼Œæˆ–è€…é€šè¿‡å…±äº«è¿™ç¯‡æ–‡ç« è®©å…¶ä»–äººå¯ä»¥æ‰¾åˆ°å®ƒã€‚</p><p id="7052" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">æœ€åå¸Œæœ›ä½ èƒ½å­¦ä¼šåˆ®ç—§çš„æŠ€å·§ã€‚ä½ ä¹Ÿå¯ä»¥åœ¨<a class="ae ln" href="https://github.com/kindersham/100DaysDS/tree/master/NewsWordCloud" rel="noopener ugc nofollow" target="_blank"> GitHub </a>åº“ä¸Šæ‰¾åˆ°å®Œæ•´çš„é¡¹ç›®ã€‚</p><p id="687e" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jl hj">å‚è€ƒæ–‡çŒ®</strong></p><div class="lo lp ez fb lq lr"><a rel="noopener follow" target="_blank" href="/the-artificial-impostor/nlp-four-ways-to-tokenize-chinese-documents-f349eb6ba3c3"><div class="ls ab dw"><div class="lt ab lu cl cj lv"><h2 class="bd hj fi z dy lw ea eb lx ed ef hh bi translated">[NLP]ä¸­æ–‡æ–‡æ¡£çš„å››ç§åˆ†è¯æ–¹æ³•</h2><div class="ly l"><h3 class="bd b fi z dy lw ea eb lx ed ef dx translated">æœ‰äº†ä¸€äº›æ”¯æŒå­è¯åˆ†å‰²æŠ€æœ¯çš„ç»éªŒè¯æ®</h3></div><div class="lz l"><p class="bd b fp z dy lw ea eb lx ed ef dx translated">medium.com</p></div></div><div class="ma l"><div class="mb l mc md me ma mf jh lr"/></div></div></a></div><div class="lo lp ez fb lq lr"><a href="https://amueller.github.io/word_cloud/index.html" rel="noopener  ugc nofollow" target="_blank"><div class="ls ab dw"><div class="lt ab lu cl cj lv"><h2 class="bd hj fi z dy lw ea eb lx ed ef hh bi translated">WordCloud for Pythonæ–‡æ¡£-word cloud 1 . 6 . 0 . post 54+GB 870 febæ–‡æ¡£</h2><div class="ly l"><h3 class="bd b fi z dy lw ea eb lx ed ef dx translated">åœ¨è¿™é‡Œä½ å¯ä»¥æ‰¾åˆ°å¦‚ä½•ç”¨æˆ‘çš„Python wordcloudé¡¹ç›®åˆ›å»ºwordcloudçš„è¯´æ˜ã€‚ä¸å…¶ä»–è¯äº‘ç›¸æ¯”â€¦</h3></div><div class="lz l"><p class="bd b fp z dy lw ea eb lx ed ef dx translated">amueller.github.io</p></div></div><div class="ma l"><div class="mg l mc md me ma mf jh lr"/></div></div></a></div></div></div>    
</body>
</html>