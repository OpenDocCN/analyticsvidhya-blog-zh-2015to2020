<html>
<head>
<title>Extracting Structured Data From Invoice</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从发票中提取结构化数据</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/extracting-structured-data-from-invoice-96cf5e548e40?source=collection_archive---------1-----------------------#2020-10-03">https://medium.com/analytics-vidhya/extracting-structured-data-from-invoice-96cf5e548e40?source=collection_archive---------1-----------------------#2020-10-03</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/49ed9d57ef07b61b61236d879830a1dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cHaMLC61Kk3jaDZ0cwBZaQ.png"/></div></div></figure><blockquote class="iq ir is"><p id="04cd" class="it iu iv iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在这篇博客中，我们将了解如何处理SROIE数据集并训练PICK-pytorch从发票中获取关键信息。</p><p id="595d" class="it iu iv iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">这里是colab笔记本<a class="ae js" href="https://colab.research.google.com/drive/1o8-Km-kVHtOcdEd7i9uPY6vXg7MyCN0B?usp=sharing" rel="noopener ugc nofollow" target="_blank">点击这里</a>直接运行教程代码</p></blockquote><h2 id="b974" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">SROIE数据集</h2><blockquote class="iq ir is"><p id="2b70" class="it iu iv iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">对于发票数据集，我们在扫描收据OCR和信息提取竞争数据集上使用ICDAR 2019鲁棒读取挑战。</p><p id="d1fd" class="it iu iv iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">参考:</p></blockquote><ul class=""><li id="5521" class="kr ks hi iw b ix iy jb jc ke kt ki ku km kv jr kw kx ky kz bi translated"><a class="ae js" href="https://rrc.cvc.uab.es/?ch=13&amp;com=introduction" rel="noopener ugc nofollow" target="_blank">https://rrc.cvc.uab.es/?ch=13&amp;com =简介</a></li><li id="87bd" class="kr ks hi iw b ix la jb lb ke lc ki ld km le jr kw kx ky kz bi translated"><a class="ae js" href="https://github.com/zzzDavid/ICDAR-2019-SROIE" rel="noopener ugc nofollow" target="_blank">https://github.com/zzzDavid/ICDAR-2019-SROIE</a></li></ul><p id="2f63" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je ke jg jh ji ki jk jl jm km jo jp jq jr hb bi translated"><strong class="iw hj">文件夹结构</strong></p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="bace" class="jt ju hi lk b fi lo lp l lq lr">data/<br/>  img/<br/>      000.jpg<br/>      001.jpg    <br/>  box/<br/>      000.csv<br/>      001.csv  <br/>  key/<br/>      000.json<br/>      001.json</span></pre><p id="4bd1" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je ke jg jh ji ki jk jl jm km jo jp jq jr hb bi translated"><strong class="iw hj">图像示例</strong></p><figure class="lf lg lh li fd ij er es paragraph-image"><div class="er es ls"><img src="../Images/ead0c1a9ffdfb6c97372404e057b5a82.png" data-original-src="https://miro.medium.com/v2/resize:fit:926/format:webp/0*AIzqENvLlSpXjCrg.jpg"/></div></figure><p id="5a10" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je ke jg jh ji ki jk jl jm km jo jp jq jr hb bi translated"><strong class="iw hj"> Csv数据示例</strong></p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="0652" class="jt ju hi lk b fi lo lp l lq lr">x1_1,y1_1,x2_1,y2_1,x3_1,y3_1,x4_1,y4_1,transcript_1<br/><br/>72,25,326,25,326,64,72,64,TAN WOON YANN<br/>50,82,440,82,440,121,50,121,BOOK TA .K(TAMAN DAYA) SDN BND<br/>205,121,285,121,285,139,205,139,789417-W<br/>110,144,383,144,383,163,110,163,NO.53 55,57 &amp; 59, JALAN SAGU 18,<br/>192,169,299,169,299,187,192,187,TAMAN DAYA,<br/>162,193,334,193,334,211,162,211,81100 JOHOR BAHRU,<br/>....</span></pre><p id="7308" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je ke jg jh ji ki jk jl jm km jo jp jq jr hb bi translated"><strong class="iw hj">关键数据示例</strong></p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="2984" class="jt ju hi lk b fi lo lp l lq lr">{<br/>    "company": "BOOK TA .K (TAMAN DAYA) SDN BHD",<br/>    "date": "25/12/2018",<br/>    "address": "NO.53 55,57 &amp; 59, JALAN SAGU 18, <br/>                TAMAN DAYA, 81100 JOHOR BAHRU, JOHOR.",<br/>    "total": "9.00"<br/>}</span></pre><p id="2ec8" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je ke jg jh ji ki jk jl jm km jo jp jq jr hb bi translated"><strong class="iw hj">下载数据集</strong></p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="f90a" class="jt ju hi lk b fi lo lp l lq lr">#dataset<br/>!git clone <a class="ae js" href="https://github.com/zzzDavid/ICDAR-2019-SROIE.git" rel="noopener ugc nofollow" target="_blank">https://github.com/zzzDavid/ICDAR-2019-SROIE.git</a></span><span id="1625" class="jt ju hi lk b fi lt lp l lq lr">Cloning into 'ICDAR-2019-SROIE'...<br/>remote: Enumerating objects: 94, done.[K<br/>remote: Counting objects: 100% (94/94), done.[K<br/>remote: Compressing objects: 100% (69/69), done.[K<br/>remote: Total 2386 (delta 50), reused 65 (delta 22), pack-reused 2292[K<br/>Receiving objects: 100% (2386/2386), 278.63 MiB | 23.17 MiB/s, done.<br/>Resolving deltas: 100% (213/213), done.<br/>Checking out files: 100% (1980/1980), done.</span></pre><h2 id="c653" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">预处理数据集</h2><p id="476a" class="pw-post-body-paragraph it iu hi iw b ix lu iz ja jb lv jd je ke lw jh ji ki lx jl jm km ly jp jq jr hb bi translated">我们将按照PICK-pytorch预处理数据集。<br/>参考:<a class="ae js" href="https://github.com/wenwenyu/PICK-pytorch/blob/master/data/README.md" rel="noopener ugc nofollow" target="_blank">https://github . com/于文文/PICK-py torch/blob/master/data/readme . MD</a></p><p id="5162" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je ke jg jh ji ki jk jl jm km jo jp jq jr hb bi translated">为预处理数据集创建文件夹</p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="8604" class="jt ju hi lk b fi lo lp l lq lr">!mkdir boxes_and_transcripts images entities</span></pre><p id="58a1" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je ke jg jh ji ki jk jl jm km jo jp jq jr hb bi translated">预处理数据集的脚本</p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="960a" class="jt ju hi lk b fi lo lp l lq lr">import os<br/>import pandas<br/>import json<br/>import csv<br/>import shutil<br/><br/>## Input dataset<br/>data_path = "ICDAR-2019-SROIE/data/"<br/>box_path = data_path + "box/"<br/>img_path = data_path + "img/"<br/>key_path = data_path + "key/"<br/><br/>## Output dataset<br/>out_boxes_and_transcripts = "/content/boxes_and_transcripts/"<br/>out_images = "/content/images/"<br/>out_entities  = "/content/entities/"<br/><br/>train_samples_list =  []<br/>for file in os.listdir(data_path + "box/"):<br/>  <br/>  ## Reading csv<br/>  with open(box_path +file, "r") as fp:<br/>    reader = csv.reader(fp, delimiter=",")<br/>    ## arranging dataframe index ,coordinates x1_1,y1_1,x2_1,y2_1,x3_1,y3_1,x4_1,y4_1, transcript<br/>    rows = [[1] + x[:8] + [','.join(x[8:]).strip(',')] for x in reader] <br/>    df = pandas.DataFrame(rows)<br/>  <br/>  ## including ner label dataframe index ,coordinates x1_1,y1_1,x2_1,y2_1,x3_1,y3_1,x4_1,y4_1, transcript , ner tag<br/>  df[10] = 'other'  <br/>  <br/>  ##saving file into new dataset folder<br/>  jpg = file.replace(".csv",".jpg")<br/>  entities = json.load(open(key_path+file.replace(".csv",".json")))<br/>  for key,value in sorted(entities.items()):<br/>    idx = df[df[9].str.contains('|'.join(map(str.strip, value.split(','))))].index<br/>    df.loc[idx, 10] = key<br/><br/>  shutil.copy(img_path +jpg, out_images)<br/>  with open(out_entities + file.replace(".csv",".txt"),"w") as j:  <br/>    print(json.dumps(entities), file=j)<br/>  <br/>  df.to_csv(out_boxes_and_transcripts+file.replace(".csv",".tsv"),index=False,header=False, quotechar='',escapechar='\\',quoting=csv.QUOTE_NONE, )<br/>  train_samples_list.append(['receipt',file.replace('.csv','')])<br/>train_samples_list = pandas.DataFrame(train_samples_list)<br/>train_samples_list.to_csv("train_samples_list.csv")</span></pre><p id="663f" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je ke jg jh ji ki jk jl jm km jo jp jq jr hb bi translated"><strong class="iw hj">预处理后的文件夹结构</strong></p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="aaf8" class="jt ju hi lk b fi lo lp l lq lr">boxes_and_transcripts/<br/>    000.tsv<br/>    001.tsv<br/>images/<br/>    000.jpg<br/>    001.jpg    <br/>entities/<br/>    000.txt<br/>    001.txt</span></pre><p id="ff6a" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je ke jg jh ji ki jk jl jm km jo jp jq jr hb bi translated"><strong class="iw hj">预处理数据示例</strong> <br/>这里我们只在tsv文件中添加ner标签。</p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="1641" class="jt ju hi lk b fi lo lp l lq lr">index ,x1_1,y1_1,x2_1,y2_1,x3_1,y3_1,x4_1,y4_1, transcript , ner tag<br/>1,72,25,326,25,326,64,72,64,TAN WOON YANN,other<br/>1,50,82,440,82,440,121,50,121,BOOK TA .K(TAMAN DAYA) SDN BND,address<br/>1,205,121,285,121,285,139,205,139,789417-W,other<br/>1,110,144,383,144,383,163,110,163,NO.53 55\,57 &amp; 59\, JALAN SAGU 18,address<br/>1,192,169,299,169,299,187,192,187,TAMAN DAYA,address<br/>1,162,193,334,193,334,211,162,211,81100 JOHOR BAHRU,address<br/>1,217,216,275,216,275,233,217,233,JOHOR.,address<br/>1,50,342,279,342,279,359,50,359,DOCUMENT NO : TD01167104,other<br/>1,50,372,96,372,96,390,50,390,DATE:,other<br/>1,165,372,342,372,342,389,165,389,25/12/2018 8:13:39 PM,date</span><span id="b299" class="jt ju hi lk b fi lt lp l lq lr">## document_type, file_name<br/>train_samples_list.head()</span></pre><figure class="lf lg lh li fd ij er es paragraph-image"><div class="ab fe cl lz"><img src="../Images/ae8900eccc63a67fc5df6f3834d5c0cc.png" data-original-src="https://miro.medium.com/v2/format:webp/1*mtr5q9LnctNGMUEZn-9BsA.png"/></div></figure><p id="9ab9" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je ke jg jh ji ki jk jl jm km jo jp jq jr hb bi translated"><strong class="iw hj">将数据集分割成训练测试集</strong></p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="68a4" class="jt ju hi lk b fi lo lp l lq lr">from sklearn.model_selection import train_test_split<br/>train_test = pandas.read_csv("train_samples_list.csv",dtype=str)<br/>train, test= train_test_split(train_test,test_size=0.2,random_state = 42)</span></pre><h2 id="4e80" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">模型</h2><blockquote class="iq ir is"><p id="5233" class="it iu iv iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">对于深度学习模型，我们将使用PICK-pytorch模型。</p><p id="50e4" class="it iu iv iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">PICK是一个框架，它通过将图形学习与图形卷积运算相结合，在处理用于关键信息提取(KIE)的复杂文档布局方面是有效和健壮的，产生包含文本和视觉特征的更丰富的语义表示以及没有歧义的全局布局。</p></blockquote><figure class="lf lg lh li fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ma"><img src="../Images/2d1a53601b36607d137b9d3c5bd9e146.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*OB-cZCCTf2luDsOg.png"/></div></div></figure><blockquote class="iq ir is"><p id="9e25" class="it iu iv iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">参考:<a class="ae js" href="https://github.com/wenwenyu/PICK-pytorch" rel="noopener ugc nofollow" target="_blank">https://github.com/wenwenyu/PICK-pytorch</a></p><p id="6aab" class="it iu iv iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><code class="du mb mc md lk b">@inproceedings{Yu2020PICKPK,<br/> title={{PICK}: Processing Key Information Extraction from Documents using Improved Graph Learning-Convolutional Networks},<br/> author={Wenwen Yu and Ning Lu and Xianbiao Qi and Ping Gong and Rong Xiao}, booktitle={2020 25th International Conference on Pattern Recognition (ICPR)}, year={2020}<br/>}</code></p></blockquote><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="d5c9" class="jt ju hi lk b fi lo lp l lq lr">!git clone <a class="ae js" href="https://github.com/wenwenyu/PICK-pytorch.git" rel="noopener ugc nofollow" target="_blank">https://github.com/wenwenyu/PICK-pytorch.git</a></span><span id="8ca2" class="jt ju hi lk b fi lt lp l lq lr">Cloning into 'PICK-pytorch'...<br/>remote: Enumerating objects: 4, done.[K<br/>remote: Counting objects: 100% (4/4), done.[K<br/>remote: Compressing objects: 100% (4/4), done.[K<br/>remote: Total 218 (delta 1), reused 0 (delta 0), pack-reused 214[K<br/>Receiving objects: 100% (218/218), 9.97 MiB | 8.62 MiB/s, done.<br/>Resolving deltas: 100% (86/86), done.</span></pre><p id="f598" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je ke jg jh ji ki jk jl jm km jo jp jq jr hb bi translated"><strong class="iw hj">将列车数据复制到PICK-pytorch数据文件夹</strong></p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="f3dd" class="jt ju hi lk b fi lo lp l lq lr">for index, row in train.iterrows():<br/>  shutil.copy(out_boxes_and_transcripts+str(row[2])+".tsv",'/content/PICK-pytorch/data/data_examples_root/boxes_and_transcripts/')<br/>    shutil.copy(out_images+str(row[2])+".jpg",'/content/PICK-pytorch/data/data_examples_root/images/')<br/>    shutil.copy(out_entities +str(row[2])+".txt", '/content/PICK-pytorch/data/data_examples_root/entities/')</span><span id="a61f" class="jt ju hi lk b fi lt lp l lq lr">train.drop(['Unnamed: 0'], axis = 1,inplace = True)<br/>train.reset_index(inplace= True)<br/>train.drop(['index'], axis = 1,inplace = True)<br/>train.to_csv("/content/PICK-pytorch/data/data_examples_root/train_samples_list.csv",header = False)</span></pre><p id="3bd1" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je ke jg jh ji ki jk jl jm km jo jp jq jr hb bi translated"><strong class="iw hj">将测试数据复制到PICK-pytorch数据文件夹</strong></p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="3116" class="jt ju hi lk b fi lo lp l lq lr">!mkdir '/content/PICK-pytorch/data/test_data_example/entities/'</span><span id="3517" class="jt ju hi lk b fi lt lp l lq lr">for index, row in test.iterrows():<br/>  shutil.copy(out_boxes_and_transcripts+str(row[2])+".tsv",'/content/PICK-pytorch/data/test_data_example/boxes_and_transcripts/')<br/>  shutil.copy(out_images+str(row[2])+".jpg",'/content/PICK-pytorch/data/test_data_example/images/')<br/>  shutil.copy(out_entities +str(row[2])+".txt", '/content/PICK-pytorch/data/test_data_example/entities/')<br/><br/>test.drop(['Unnamed: 0'], axis = 1,inplace = True)<br/>test.reset_index(inplace= True)<br/>test.drop(['index'], axis = 1,inplace = True)<br/>test.to_csv("/content/PICK-pytorch/data/test_data_example/test_samples_list.csv",header = False)</span><span id="1dc5" class="jt ju hi lk b fi lt lp l lq lr">## Removing data once it is copied into PICK-pytorch data folder<br/>!rm /content/boxes_and_transcripts/*.tsv<br/>!rm /content/images/*.jpg<br/>!rm /content/entities/*.txt</span><span id="9e04" class="jt ju hi lk b fi lt lp l lq lr">%cd PICK-pytorch/</span></pre><p id="2cd5" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je ke jg jh ji ki jk jl jm km jo jp jq jr hb bi translated">根据PICK-pytorch指南修改配置文件。<br/><a class="ae js" href="https://github.com/wenwenyu/PICK-pytorch#distributed-training-with-config-files" rel="noopener ugc nofollow" target="_blank">https://github . com/于文文/PICK-py torch # distributed-training-with-config-files</a><br/>注:您可以根据自己的文件夹结构修改config.json中的train_dataset和validation_dataset参数。</p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="8b3c" class="jt ju hi lk b fi lo lp l lq lr">%%writefile config.json<br/><br/>{<br/>    "name": "PICK_Default",<br/>    "run_id":"test",<br/><br/>    "local_world_size":4,<br/>    "local_rank":-1,<br/>    "distributed":-1,<br/><br/>    "model_arch": {<br/>        "type": "PICKModel",<br/>        "args": {<br/>            "embedding_kwargs":{<br/>                "num_embeddings": -1,<br/>                "embedding_dim": 512<br/>            },<br/>            "encoder_kwargs":{<br/>                "char_embedding_dim":-1,<br/>                "out_dim": 512,<br/>                "nheaders": 4,<br/>                "nlayers": 3,<br/>                "feedforward_dim": 1024,<br/>                "dropout": 0.1,<br/>                "image_encoder": "resnet50",<br/>                "roi_pooling_mode": "roi_align",<br/>                "roi_pooling_size": [7,7]<br/>            },<br/>            "graph_kwargs":{<br/>                "in_dim":-1,<br/>                "out_dim":-1,<br/>                "eta": 1,<br/>                "gamma": 1,<br/>                "learning_dim": 128,<br/>                "num_layers": 2<br/>            },<br/>            "decoder_kwargs":{<br/>                "bilstm_kwargs":{<br/>                    "input_size": -1,<br/>                     "hidden_size": 512,<br/>                     "num_layers": 2,<br/>                     "dropout": 0.1,<br/>                     "bidirectional": true,<br/>                     "batch_first": true<br/><br/>                },<br/>                "mlp_kwargs":{<br/>                     "in_dim": -1,<br/>                     "out_dim": -1,<br/>                    "dropout": 0.1<br/>                },<br/>                "crf_kwargs":{<br/>                    "num_tags":-1<br/>                }<br/>            }<br/>        }<br/>    },<br/><br/>    "train_dataset": {<br/>        "type": "PICKDataset",<br/>        "args": {<br/>            "files_name":"/content/PICK-pytorch/data/data_examples_root/train_samples_list.csv",<br/>            "boxes_and_transcripts_folder":"/content/PICK-pytorch/data/data_examples_root/boxes_and_transcripts",<br/>            "images_folder":"/content/PICK-pytorch/data/data_examples_root/images",<br/>            "entities_folder":"/content/PICK-pytorch/data/data_examples_root/entities",<br/>            "iob_tagging_type":"box_and_within_box_level",<br/>            "resized_image_size": [480, 960],<br/>            "ignore_error": false<br/>        }<br/>    },<br/>    "validation_dataset": {<br/>        "type": "PICKDataset",<br/>        "args": {<br/>            "files_name":"/content/PICK-pytorch/data/test_data_example/test_samples_list.csv",<br/>            "boxes_and_transcripts_folder":"/content/PICK-pytorch/data/test_data_example/boxes_and_transcripts",<br/>            "images_folder":"/content/PICK-pytorch/data/test_data_example/images",<br/>            "entities_folder":"/content/PICK-pytorch/data/test_data_example/entities",<br/>            "iob_tagging_type":"box_and_within_box_level",<br/>            "resized_image_size": [480, 960],<br/>            "ignore_error": false<br/>        }<br/>    },<br/>    "train_data_loader": {<br/>        "type": "DataLoader",<br/>        "args":{<br/>            "batch_size": 4,<br/>            "shuffle": true,<br/>            "drop_last": true,<br/>            "num_workers": 8,<br/>            "pin_memory":true<br/>        }<br/>    },<br/>    "val_data_loader": {<br/>          "type": "DataLoader",<br/>          "args":{<br/>              "batch_size": 4,<br/>              "shuffle": false,<br/>              "drop_last": false,<br/>              "num_workers": 8,<br/>              "pin_memory":true<br/>          }<br/>      },<br/><br/>    "optimizer": {<br/>          "type": "Adam",<br/>          "args":{<br/>              "lr": 0.0001,<br/>              "weight_decay": 0,<br/>              "amsgrad": true<br/>          }<br/>    },<br/>    "lr_scheduler": {<br/>        "type": "StepLR",<br/>        "args": {<br/>            "step_size": 30,<br/>            "gamma": 0.1<br/>        }<br/>    },<br/><br/>    "trainer": {<br/>        "epochs": 100,<br/>        "gl_loss_lambda": 0.01,<br/>        "log_step_interval": 10,<br/>        "val_step_interval": 50,<br/><br/>        "save_dir": "saved/",<br/>        "save_period": 20,<br/>        "log_verbosity": 2,<br/><br/>        "monitor": "max overall-mEF",<br/>        "monitor_open": true,<br/>        "early_stop": 40,<br/><br/>        "anomaly_detection": false,<br/>        "tensorboard": false,<br/><br/>        "sync_batch_norm":true<br/>    }<br/>}</span><span id="5578" class="jt ju hi lk b fi lt lp l lq lr">Overwriting config.json</span></pre><p id="3007" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je ke jg jh ji ki jk jl jm km jo jp jq jr hb bi translated">entities_list.py包含实体类的名称。这里我们有4个实体</p><ul class=""><li id="58b3" class="kr ks hi iw b ix iy jb jc ke kt ki ku km kv jr kw kx ky kz bi translated">公司</li><li id="ae28" class="kr ks hi iw b ix la jb lb ke lc ki ld km le jr kw kx ky kz bi translated">地址</li><li id="9715" class="kr ks hi iw b ix la jb lb ke lc ki ld km le jr kw kx ky kz bi translated">日期</li><li id="fc74" class="kr ks hi iw b ix la jb lb ke lc ki ld km le jr kw kx ky kz bi translated">总数</li></ul><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="fd68" class="jt ju hi lk b fi lo lp l lq lr">%%writefile utils/entities_list.py<br/><br/>Entities_list = [<br/>    "company",<br/>    "address",<br/>    "date",<br/>    "total"<br/>]</span></pre><p id="0250" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je ke jg jh ji ki jk jl jm km jo jp jq jr hb bi translated"><strong class="iw hj">运行PICK-pytorch的安装要求。</strong></p><p id="3844" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je ke jg jh ji ki jk jl jm km jo jp jq jr hb bi translated"><code class="du mb mc md lk b">!pip install -r requirements.txt<br/>!pip install torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f <a class="ae js" href="https://download.pytorch.org/whl/torch_stable.html" rel="noopener ugc nofollow" target="_blank">https://download.pytorch.org/whl/torch_stable.html</a></code></p><h2 id="2555" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">培养</h2><p id="db4d" class="pw-post-body-paragraph it iu hi iw b ix lu iz ja jb lv jd je ke lw jh ji ki lx jl jm km ly jp jq jr hb bi translated">训练至少100个历元以获得更好结果。如果您有多个gpu，您可以通过<code class="du mb mc md lk b">-d</code>参数更改gpu设备列表。</p><p id="67ae" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je ke jg jh ji ki jk jl jm km jo jp jq jr hb bi translated">参考:<a class="ae js" href="https://github.com/wenwenyu/PICK-pytorch#distributed-training-with-config-files" rel="noopener ugc nofollow" target="_blank">https://github . com/于文文/PICK-py torch #带配置文件的分布式培训</a></p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="243b" class="jt ju hi lk b fi lo lp l lq lr">#!/bin/bash<br/>!python -m torch.distributed.launch --nnode=1 --node_rank=0 --nproc_per_node=1 \<br/>   train.py -c config.json -d 0 --local_world_size 1<br/>  # --resume /content/PICK-pytorch/saved/models/PICK_Default/test_0917_074722/model_best.pth ##uncomment for resume training</span><span id="4423" class="jt ju hi lk b fi lt lp l lq lr"><br/>[2020-10-03 09:55:08,494 - trainer - INFO] - Train Epoch:[22/100] Step:[250/250] Total Loss: 45.489735 GL_Loss: 0.946765 CRF_Loss: 44.542969<br/>[2020-10-03 09:55:41,285 - trainer - INFO] - [Step Validation] Epoch:[22/100] Step:[250/250]  <br/>+---------+----------+----------+----------+----------+<br/>| name    |      mEP |      mER |      mEF |      mEA |<br/>+=========+==========+==========+==========+==========+<br/>| address | 0.742765 | 0.55     | 0.632011 | 0.55     |<br/>+---------+----------+----------+----------+----------+<br/>| company | 0.54717  | 0.623656 | 0.582915 | 0.623656 |<br/>+---------+----------+----------+----------+----------+<br/>| total   | 0.591111 | 0.461806 | 0.518519 | 0.461806 |<br/>+---------+----------+----------+----------+----------+<br/>| date    | 0.820359 | 0.88961  | 0.853583 | 0.88961  |<br/>+---------+----------+----------+----------+----------+<br/>| overall | 0.690977 | 0.58534  | 0.633787 | 0.58534  |<br/>+---------+----------+----------+----------+----------+<br/>[2020-10-03 09:55:45,078 - trainer - INFO] - Saving current best: model_best.pth ...<br/>[2020-10-03 09:56:18,330 - trainer - INFO] - [Epoch Validation] Epoch:[22/100] Total Loss: 73.259899 GL_Loss: 0.011341 CRF_Loss: 72.125789 <br/>+---------+----------+----------+----------+----------+<br/>| name    |      mEP |      mER |      mEF |      mEA |<br/>+=========+==========+==========+==========+==========+<br/>| address | 0.743506 | 0.545238 | 0.629121 | 0.545238 |<br/>+---------+----------+----------+----------+----------+<br/>| company | 0.566038 | 0.645161 | 0.603015 | 0.645161 |<br/>+---------+----------+----------+----------+----------+<br/>| total   | 0.570796 | 0.447917 | 0.501946 | 0.447917 |<br/>+---------+----------+----------+----------+----------+<br/>| date    | 0.788235 | 0.87013  | 0.82716  | 0.87013  |<br/>+---------+----------+----------+----------+----------+<br/>| overall | 0.681481 | 0.57801  | 0.625496 | 0.57801  |<br/>+---------+----------+----------+----------+----------+<br/>[2020-10-03 09:56:42,240 - trainer - INFO] - Train Epoch:[23/100] Step:[10/250] Total Loss: 31.438135 GL_Loss: 0.875147 CRF_Loss: 30.562988<br/></span></pre><h2 id="dbad" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">测试</h2><p id="a36d" class="pw-post-body-paragraph it iu hi iw b ix lu iz ja jb lv jd je ke lw jh ji ki lx jl jm km ly jp jq jr hb bi translated">混凝土试验文件夹</p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="d8df" class="jt ju hi lk b fi lo lp l lq lr">##creating testing folders<br/>!mkdir /content/test_img /content/test_boxes_and_transcripts</span><span id="ea06" class="jt ju hi lk b fi lt lp l lq lr">## copy one file from test sample<br/>import os<br/>import shutil<br/>data_path = "data/test_data_example/boxes_and_transcripts/"<br/>image_path = "data/test_data_example/images/"<br/><br/>out_img_path = "/content/test_img/"<br/>out_box_path = "/content/test_boxes_and_transcripts/"<br/><br/>for file in os.listdir(data_path)[:10]:<br/>  shutil.copy(data_path+file,out_box_path)<br/>  shutil.copy(image_path+file.replace(".tsv",".jpg"),out_img_path)</span></pre><p id="e895" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je ke jg jh ji ki jk jl jm km jo jp jq jr hb bi translated">预言；预测；预告</p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="2fda" class="jt ju hi lk b fi lo lp l lq lr">## change model_best.pth path<br/>!python test.py --checkpoint saved/models/PICK_Default/test_1003_053713/model_best.pth \<br/>                --boxes_transcripts {out_box_path} \<br/>                --images_path {out_img_path} --output_folder /content/output/ \<br/>                --gpu 0 --batch_size 2</span><span id="3363" class="jt ju hi lk b fi lt lp l lq lr">2020-10-03 10:07:50.457224: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1<br/>Loading checkpoint: saved/models/PICK_Default/test_1003_053713/model_best.pth <br/>with saved mEF 0.6338 ...<br/>5it [00:02,  1.83it/s]</span></pre><p id="2bb1" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je ke jg jh ji ki jk jl jm km jo jp jq jr hb bi translated">您可以在输出文件夹中看到预测。</p><p id="1a8c" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je ke jg jh ji ki jk jl jm km jo jp jq jr hb bi translated">它看起来会像这样</p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="5bf9" class="jt ju hi lk b fi lo lp l lq lr">company	ADVANCO COMPANY,co<br/>address	NO 1&amp;3\, JALAN ANGSA DELIMA 12<br/>address	WANGSA LINK\, WANGSA MAJU<br/>address	53300 KUALA LUMPUR<br/>date	23/03/2018</span></pre><p id="2b6a" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je ke jg jh ji ki jk jl jm km jo jp jq jr hb bi translated">在colab笔记本中查找更好的缩进<a class="ae js" href="https://colab.research.google.com/drive/1o8-Km-kVHtOcdEd7i9uPY6vXg7MyCN0B?usp=sharing" rel="noopener ugc nofollow" target="_blank">单击此处</a></p><p id="38d2" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je ke jg jh ji ki jk jl jm km jo jp jq jr hb bi translated">如果你喜欢这篇文章，点击给我买杯咖啡！感谢阅读。</p><figure class="lf lg lh li fd ij er es paragraph-image"><a href="https://www.payumoney.com/paybypayumoney/#/147695053B73CAB82672E715A52F9AA5"><div class="er es me"><img src="../Images/226d333c001f2bdbc8bc791892ea31ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:834/format:webp/1*-aubdwm03fkW39OOplP4ag.png"/></div></a></figure><p id="6f09" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je ke jg jh ji ki jk jl jm km jo jp jq jr hb bi translated">你的每一个小小的贡献都会鼓励我创造更多这样的内容。</p></div></div>    
</body>
</html>