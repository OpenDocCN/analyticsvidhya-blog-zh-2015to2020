<html>
<head>
<title>Hear your model’s training</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">听听你模特的训练</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/hear-your-model-train-30bcde8287c9?source=collection_archive---------32-----------------------#2020-07-01">https://medium.com/analytics-vidhya/hear-your-model-train-30bcde8287c9?source=collection_archive---------32-----------------------#2020-07-01</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="be84" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">听听你的模特想对你说什么..哈哈！</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/6da1351315777a3cf64ba7bd0bef1901.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CcOOGk5m0QXU_x8cSrTwAw.jpeg"/></div></div></figure><p id="804a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这个星球上每个对数据科学感兴趣的人都会用python中的一个图形来可视化模型训练，如下所示</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jp"><img src="../Images/a6da3c3b2f96c1e19c36bd5d9085774b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wR2mOWK2pY2ZAObxVS9WqA.jpeg"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">MNIST模型的训练图</figcaption></figure><p id="d2e8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">但今天早上我有一个荒谬的想法，“为什么不听听你的模型训练，看看它是否过度训练了”。所以这篇文章引导你去理解我的荒谬想法:用很少的步骤就能听到你训练过的模型。它实际上是我计划制作的第一个python库的第一个模块。希望这能引起你的兴趣</p><p id="f8fb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是一个验证损失和准确性与训练损失和准确性的例子</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="ju jv l"/></div><figcaption class="jq jr et er es js jt bd b be z dx translated">验证准确性</figcaption></figure><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="ju jv l"/></div><figcaption class="jq jr et er es js jt bd b be z dx translated">验证损失</figcaption></figure><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="ju jv l"/></div><figcaption class="jq jr et er es js jt bd b be z dx translated">准确(性)</figcaption></figure><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="ju jv l"/></div><figcaption class="jq jr et er es js jt bd b be z dx translated">失败</figcaption></figure><p id="c5b0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">步骤1:训练模型:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jw"><img src="../Images/ae3e44b94ff69b2a56d68c9b0db2b260.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*-Ea0UN25x-8UWapa.gif"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">模特培训</figcaption></figure><p id="0695" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">例如，在这里，我正在为MNIST数据集训练一个简单的模型，并使用Tensorflow中build中的回调函数将数据[损失+准确性数据]记录到CSV文件中</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="jx jv l"/></div></figure><p id="4f74" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第二步:倾听你的模型</p><p id="6ce4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你需要更多关于如何训练模特的细节，请参考我之前的帖子:</p><div class="jy jz ez fb ka kb"><a rel="noopener follow" target="_blank" href="/analytics-vidhya/visualizing-convolution-neural-network-the-hidden-truth-c825d69f1832"><div class="kc ab dw"><div class="kd ab ke cl cj kf"><h2 class="bd hj fi z dy kg ea eb kh ed ef hh bi translated">可视化卷积神经网络[隐藏的真相]</h2><div class="ki l"><h3 class="bd b fi z dy kg ea eb kh ed ef dx translated">对计算机视觉、深度学习感兴趣的人，这可能很有见地</h3></div><div class="kj l"><p class="bd b fp z dy kg ea eb kh ed ef dx translated">medium.com</p></div></div><div class="kk l"><div class="kl l km kn ko kk kp jn kb"/></div></div></a></div><p id="c90e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，您已经准备好将模型历史记录转换成CSV文件，让我们为听力构建代码</p><pre class="je jf jg jh fd kq kr ks kt aw ku bi"><span id="eb97" class="kv kw hi kr b fi kx ky l kz la">import pandas as pd<br/>import numpy as np<br/>from scipy.interpolate import interp1d<br/>import sounddevice as sd<br/>from math import pi<br/>from scipy.io import wavfile</span></pre><ol class=""><li id="841d" class="lb lc hi ih b ii ij im in iq ld iu le iy lf jc lg lh li lj bi translated">熊猫用于读取包含训练信息的日志文件</li><li id="9178" class="lb lc hi ih b ii lk im ll iq lm iu ln iy lo jc lg lh li lj bi translated">用于为音频生成余弦值的数字</li><li id="bbe3" class="lb lc hi ih b ii lk im ll iq lm iu ln iy lo jc lg lh li lj bi translated">Interp1d用于将数据映射到频率范围</li><li id="67f2" class="lb lc hi ih b ii lk im ll iq lm iu ln iy lo jc lg lh li lj bi translated">听余弦值的声音装置</li><li id="261e" class="lb lc hi ih b ii lk im ll iq lm iu ln iy lo jc lg lh li lj bi translated">使用圆周率值的圆周率[3.14……]</li><li id="701e" class="lb lc hi ih b ii lk im ll iq lm iu ln iy lo jc lg lh li lj bi translated">Wavfile用于以wave格式保存音频</li></ol><pre class="je jf jg jh fd kq kr ks kt aw ku bi"><span id="11e7" class="kv kw hi kr b fi kx ky l kz la">MAX_DURATION=0.15<br/>MIN_VAL,MAX_VAL = 1000,3000<br/>SAMPLING_RATE = 22050</span></pre><p id="0b5b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们设置音频文件的采样率，我们想要听到的最小和最大频率范围，以及听到特定频率的最大持续时间</p><pre class="je jf jg jh fd kq kr ks kt aw ku bi"><span id="bf57" class="kv kw hi kr b fi kx ky l kz la">df = pd.read_csv('model_log.csv')<br/>l=df['loss'].values</span></pre><p id="ea67" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们现在读取CSV文件，为了举例，我们读取模型训练的每个时期的损失值</p><pre class="je jf jg jh fd kq kr ks kt aw ku bi"><span id="de4d" class="kv kw hi kr b fi kx ky l kz la">m = interp1d([min(l),max(l)],[MIN_VAL,MAX_VAL])<br/>list_of_f = [m(x) for x in l]<br/>x=[]<br/>t=np.arange(0,MAX_DURATION,1./SAMPLING_RATE)</span></pre><p id="5d45" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">其中m是interp1d类的对象，用于将我们的损耗值映射到前面提到的频率范围。list comprehension用于使用对象m映射所有值。初始化一个空数组以附加音频文件的每个频率的结果。t是时间为0.15秒的每个频率的平均间隔值的nd数组</p><pre class="je jf jg jh fd kq kr ks kt aw ku bi"><span id="c815" class="kv kw hi kr b fi kx ky l kz la">for f in list_of_f:<br/>    cos_wav=10000*np.cos(2*pi*f*t) #generated signals<br/>    x=np.hstack((x,cos_wav))<br/>    <br/>wavfile.write('loss.wav',SAMPLING_RATE,x.astype(np.dtype('i2')))</span></pre><p id="b7ca" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们为特定时间范围内的每个频率生成cos波，并添加或堆叠到列表中，最后保存音频文件。你可能在想什么是np.dtype('i2 ')，它实际上是将int64值转换成波形文件可以理解的i2格式，否则你可能会出错</p><p id="5d26" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">请参考此StackOverflow帖子，了解可能发生的错误:</p><div class="jy jz ez fb ka kb"><a href="https://stackoverflow.com/questions/10558377/wav-file-doesnt-play-any-sounds" rel="noopener  ugc nofollow" target="_blank"><div class="kc ab dw"><div class="kd ab ke cl cj kf"><h2 class="bd hj fi z dy kg ea eb kh ed ef hh bi translated">。wav文件不播放任何声音</h2><div class="ki l"><h3 class="bd b fi z dy kg ea eb kh ed ef dx translated">感谢贡献一个堆栈溢出的答案！请务必回答问题。提供详细信息并分享…</h3></div><div class="kj l"><p class="bd b fp z dy kg ea eb kh ed ef dx translated">stackoverflow.com</p></div></div><div class="kk l"><div class="lp l km kn ko kk kp jn kb"/></div></div></a></div><pre class="je jf jg jh fd kq kr ks kt aw ku bi"><span id="0c40" class="kv kw hi kr b fi kx ky l kz la">import IPython.display as ipd<br/>ipd.Audio('loss.wav')</span></pre><p id="1cbc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是你在Jupyter笔记本上播放文件的方法。</p><p id="c0e9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在对日志文件中的所有参数重复这些步骤</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="jx jv l"/></div></figure><p id="6a82" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我希望你喜欢这篇文章。如果你觉得很有见地，请分享</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lq"><img src="../Images/0ffe0029797685033b368199552a4f3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:980/0*6R30r8L9A6I9xRSc.gif"/></div></figure></div></div>    
</body>
</html>