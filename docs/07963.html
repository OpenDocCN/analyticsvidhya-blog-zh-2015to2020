<html>
<head>
<title>Methods to Handle Missing Data in Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习中缺失数据的处理方法</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/techniques-for-handling-the-missing-data-in-machine-learning-a-walkthrough-in-python-fdc37103a66b?source=collection_archive---------6-----------------------#2020-07-13">https://medium.com/analytics-vidhya/techniques-for-handling-the-missing-data-in-machine-learning-a-walkthrough-in-python-fdc37103a66b?source=collection_archive---------6-----------------------#2020-07-13</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="0a9e" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">机器学习中缺失数据的处理技术:Python中的演练</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/4d0533d2a99cd7060f8f95164a3ec0a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*INNOb7JtIeEZylCo"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">弗兰基·查马基在<a class="ae jn" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><h1 id="1fa2" class="jo jp hi bd jq jr js jt ju jv jw jx jy io jz ip ka ir kb is kc iu kd iv ke kf bi translated">为什么处理缺失数据很重要？</h1><p id="e530" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko kp kq kr ks kt ku kv kw kx ky kz la lb hb bi translated">缺失数据问题在大多数研究领域都很普遍。丢失数据会产生各种问题。</p><ul class=""><li id="c611" class="lc ld hi ki b kj le km lf kp lg kt lh kx li lb lj lk ll lm bi translated">首先，数据的缺失降低了统计方法的效力。</li><li id="79a9" class="lc ld hi ki b kj ln km lo kp lp kt lq kx lr lb lj lk ll lm bi translated">其次，缺失的数据会导致模型出现偏差。</li><li id="7cf6" class="lc ld hi ki b kj ln km lo kp lp kt lq kx lr lb lj lk ll lm bi translated">第三，python中很多机器学习包不接受缺失数据。它需要先处理缺失的数据。</li></ul><p id="86df" class="pw-post-body-paragraph kg kh hi ki b kj le ij kl km lf im ko kp ls kr ks kt lt kv kw kx lu kz la lb hb bi translated">这些问题中的每一个都可能导致虚假的结论，降低模型的可靠性。</p><h1 id="8e0b" class="jo jp hi bd jq jr js jt ju jv jw jx jy io jz ip ka ir kb is kc iu kd iv ke kf bi translated">缺失数据机制</h1><ul class=""><li id="fff3" class="lc ld hi ki b kj kk km kn kp lv kt lw kx lx lb lj lk ll lm bi translated"><strong class="ki hj">完全随机缺失(MCAR): </strong>如果缺失数据与观察到的和缺失的实例都完全不相关，则值完全随机缺失(MCAR)。</li><li id="9409" class="lc ld hi ki b kj ln km lo kp lp kt lq kx lr lb lj lk ll lm bi translated"><strong class="ki hj">随机缺失(MAR): </strong>随机缺失(MAR)是指缺失数据与观测数据有关，但与缺失数据无关。</li><li id="7cc1" class="lc ld hi ki b kj ln km lo kp lp kt lq kx lr lb lj lk ll lm bi translated"><strong class="ki hj">非随机缺失(MNAR): </strong>非随机缺失(MNAR)是既不是MAR也不是MCAR的数据。这意味着丢失的数据与观察到的和丢失的实例都有关。</li></ul><h1 id="f4b5" class="jo jp hi bd jq jr js jt ju jv jw jx jy io jz ip ka ir kb is kc iu kd iv ke kf bi translated">处理缺失数据</h1><ol class=""><li id="f98b" class="lc ld hi ki b kj kk km kn kp lv kt lw kx lx lb ly lk ll lm bi translated">删除变量</li><li id="7a2d" class="lc ld hi ki b kj ln km lo kp lp kt lq kx lr lb ly lk ll lm bi translated">部分删除</li><li id="9dc1" class="lc ld hi ki b kj ln km lo kp lp kt lq kx lr lb ly lk ll lm bi translated">数据插补</li></ol><h1 id="04f2" class="jo jp hi bd jq jr js jt ju jv jw jx jy io jz ip ka ir kb is kc iu kd iv ke kf bi translated">1.删除变量</h1><p id="f745" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko kp kq kr ks kt ku kv kw kx ky kz la lb hb bi translated">如果该列包含超过<strong class="ki hj"> 70%的缺失值</strong>，则删除该列；否则，数据插补是比删除该列更可取的方法。模型的信息量越大，模型结果的可靠性就越高。</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="lz ma l"/></div></figure><h1 id="73e1" class="jo jp hi bd jq jr js jt ju jv jw jx jy io jz ip ka ir kb is kc iu kd iv ke kf bi translated">2.部分删除</h1><h1 id="0b82" class="jo jp hi bd jq jr js jt ju jv jw jx jy io jz ip ka ir kb is kc iu kd iv ke kf bi translated">2.1列表式删除</h1><p id="eaa4" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko kp kq kr ks kt ku kv kw kx ky kz la lb hb bi translated"><strong class="ki hj">列表删除</strong>是一种删除包含缺失值的行的技术。</p><p id="f5bb" class="pw-post-body-paragraph kg kh hi ki b kj le ij kl km lf im ko kp ls kr ks kt lt kv kw kx lu kz la lb hb bi translated"><strong class="ki hj">缺点:</strong>列表式删除降低了所进行的统计检验的强度。更多的数据样本是分析的关键因素。因为列表式删除会删除缺少值的数据，所以它会减小数据的大小。列表式删除可能会导致数据偏差。</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="lz ma l"/></div></figure><h1 id="1192" class="jo jp hi bd jq jr js jt ju jv jw jx jy io jz ip ka ir kb is kc iu kd iv ke kf bi translated">3.数据插补</h1><h1 id="80dd" class="jo jp hi bd jq jr js jt ju jv jw jx jy io jz ip ka ir kb is kc iu kd iv ke kf bi translated">3.1单一插补</h1><p id="fdc0" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko kp kq kr ks kt ku kv kw kx ky kz la lb hb bi translated">单一插补试图用单一值对缺失数据进行插补，而多重插补则用多个值替代缺失数据。</p><blockquote class="mb mc md"><p id="1f35" class="kg kh me ki b kj le ij kl km lf im ko mf ls kr ks mg lt kv kw mh lu kz la lb hb bi translated"><strong class="ki hj"> <em class="hi"> 3.1.1数字列的单一插补</em> </strong></p></blockquote><p id="1ea6" class="pw-post-body-paragraph kg kh hi ki b kj le ij kl km lf im ko kp ls kr ks kt lt kv kw kx lu kz la lb hb bi translated">3.1.1.1平均插补</p><p id="79e5" class="pw-post-body-paragraph kg kh hi ki b kj le ij kl km lf im ko kp ls kr ks kt lt kv kw kx lu kz la lb hb bi translated">3.1.1.2回归插补</p><blockquote class="mb mc md"><p id="4c77" class="kg kh me ki b kj le ij kl km lf im ko mf ls kr ks mg lt kv kw mh lu kz la lb hb bi translated"><strong class="ki hj"> <em class="hi"> 3.1.2分类列的单一插补</em> </strong></p></blockquote><p id="6278" class="pw-post-body-paragraph kg kh hi ki b kj le ij kl km lf im ko kp ls kr ks kt lt kv kw kx lu kz la lb hb bi translated">3.1.2.1模式插补</p><h2 id="3710" class="mi jp hi bd jq mj mk ml ju mm mn mo jy kp mp mq ka kt mr ms kc kx mt mu ke mv bi translated">3.1.1数字列的单一插补</h2><p id="3397" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko kp kq kr ks kt ku kv kw kx ky kz la lb hb bi translated"><strong class="ki hj">3.1.1.1均值插补</strong></p><ul class=""><li id="0cd9" class="lc ld hi ki b kj le km lf kp lg kt lh kx li lb lj lk ll lm bi translated">平均值插补是用变量的平均值来插补缺失数据的过程，只能对数字列进行插补。</li></ul><p id="9669" class="pw-post-body-paragraph kg kh hi ki b kj le ij kl km lf im ko kp ls kr ks kt lt kv kw kx lu kz la lb hb bi translated"><strong class="ki hj">缺点:</strong>均值插补更容易在模型中引入偏倚。</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="lz ma l"/></div></figure><p id="6aab" class="pw-post-body-paragraph kg kh hi ki b kj le ij kl km lf im ko kp ls kr ks kt lt kv kw kx lu kz la lb hb bi translated">【3.1.1.2 T2】回归插补</p><ul class=""><li id="a250" class="lc ld hi ki b kj le km lf kp lg kt lh kx li lb lj lk ll lm bi translated">拟合回归模型，其中预测值是没有缺失值的要素，目标值是有缺失值的要素。</li><li id="e4c2" class="lc ld hi ki b kj ln km lo kp lp kt lq kx lr lb lj lk ll lm bi translated">然后用预测值替换缺失值。回归插补不太可能在模型中引入偏差。</li></ul><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="lz ma l"/></div></figure><h2 id="97ce" class="mi jp hi bd jq mj mk ml ju mm mn mo jy kp mp mq ka kt mr ms kc kx mt mu ke mv bi translated">3.1.2分类栏的单一插补</h2><p id="e411" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko kp kq kr ks kt ku kv kw kx ky kz la lb hb bi translated">【3.1.2.1模式插补】T4</p><ul class=""><li id="712a" class="lc ld hi ki b kj le km lf kp lg kt lh kx li lb lj lk ll lm bi translated">模式插补是通过变量的模式对缺失数据进行插补的过程，只能对分类列进行插补。</li></ul><p id="ffc6" class="pw-post-body-paragraph kg kh hi ki b kj le ij kl km lf im ko kp ls kr ks kt lt kv kw kx lu kz la lb hb bi translated"><strong class="ki hj">缺点:</strong>更容易在模型中引入偏差。</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="lz ma l"/></div></figure><h1 id="6696" class="jo jp hi bd jq jr js jt ju jv jw jx jy io jz ip ka ir kb is kc iu kd iv ke kf bi translated">3.2多重插补</h1><ul class=""><li id="5f20" class="lc ld hi ki b kj kk km kn kp lv kt lw kx lx lb lj lk ll lm bi translated">在多重插补中，缺失数据被多次用多个值进行插补，最终形成大量插补数据集。</li></ul><h2 id="50df" class="mi jp hi bd jq mj mk ml ju mm mn mo jy kp mp mq ka kt mr ms kc kx mt mu ke mv bi translated">3.2.1小鼠(通过链式方程进行多重插补)</h2><h2 id="daf7" class="mi jp hi bd jq mj mk ml ju mm mn mo jy kp mp mq ka kt mr ms kc kx mt mu ke mv bi translated">鼠标算法:</h2><ul class=""><li id="c368" class="lc ld hi ki b kj kk km kn kp lv kt lw kx lx lb lj lk ll lm bi translated"><strong class="ki hj">第一步:</strong>最初，数据集使用平均值进行估算，平均值充当“占位符”。</li><li id="11cc" class="lc ld hi ki b kj ln km lo kp lp kt lq kx lr lb lj lk ll lm bi translated"><strong class="ki hj">第二步:</strong>随机选择一个缺失变量，命名为目标，除此之外的其他特征将作为特征。根据这些特征和目标训练回归模型。</li><li id="03d8" class="lc ld hi ki b kj ln km lo kp lp kt lq kx lr lb lj lk ll lm bi translated"><strong class="ki hj">第3步:</strong>目标的缺失值随后被回归模型的预测值(插补值)替代。</li><li id="4449" class="lc ld hi ki b kj ln km lo kp lp kt lq kx lr lb lj lk ll lm bi translated"><strong class="ki hj">步骤4: </strong>然后对每个有未观察数据的特征重复步骤2-3。在单个周期结束时，所有缺失值都将通过预测进行估算。</li><li id="4827" class="lc ld hi ki b kj ln km lo kp lp kt lq kx lr lb lj lk ll lm bi translated"><strong class="ki hj">步骤5: </strong>重复步骤2-4，重复指定的循环次数。</li></ul><h2 id="4849" class="mi jp hi bd jq mj mk ml ju mm mn mo jy kp mp mq ka kt mr ms kc kx mt mu ke mv bi translated">分类数据的MICE算法:</h2><p id="c8fc" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko kp kq kr ks kt ku kv kw kx ky kz la lb hb bi translated">在执行MICE算法中的步骤1到6之前，必须完成以下步骤以估算分类数据。</p><ul class=""><li id="9e1f" class="lc ld hi ki b kj le km lf kp lg kt lh kx li lb lj lk ll lm bi translated"><strong class="ki hj">第一步:</strong>对非空值进行顺序编码</li><li id="9c15" class="lc ld hi ki b kj ln km lo kp lp kt lq kx lr lb lj lk ll lm bi translated"><strong class="ki hj">步骤2: </strong>使用带有梯度增强分类器的MICE插补来插补有序编码的数据</li><li id="dbd7" class="lc ld hi ki b kj ln km lo kp lp kt lq kx lr lb lj lk ll lm bi translated"><strong class="ki hj">第三步:</strong>从序数值转换回分类值。</li><li id="8e2a" class="lc ld hi ki b kj ln km lo kp lp kt lq kx lr lb lj lk ll lm bi translated"><strong class="ki hj">步骤4: </strong>按照MICE算法中的步骤1至5。使用<strong class="ki hj">模式插补</strong>代替初始策略的均值插补。</li></ul><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="lz ma l"/></div></figure></div><div class="ab cl mw mx gp my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="hb hc hd he hf"><p id="96f2" class="pw-post-body-paragraph kg kh hi ki b kj le ij kl km lf im ko kp ls kr ks kt lt kv kw kx lu kz la lb hb bi translated"><strong class="ki hj"> <em class="me">在我的Kaggle笔记本里找到这个帖子:</em></strong><a class="ae jn" href="https://www.kaggle.com/srivignesh/techniques-for-handling-the-missing-data" rel="noopener ugc nofollow" target="_blank"><em class="me">https://www . ka ggle . com/srivignesh/techniques-for-handling-the-missing-data</em></a></p><p id="8e6a" class="pw-post-body-paragraph kg kh hi ki b kj le ij kl km lf im ko kp ls kr ks kt lt kv kw kx lu kz la lb hb bi translated"><strong class="ki hj">参考文献:</strong></p><p id="187e" class="pw-post-body-paragraph kg kh hi ki b kj le ij kl km lf im ko kp ls kr ks kt lt kv kw kx lu kz la lb hb bi translated">[1]玄康<strong class="ki hj">，</strong>，<a class="ae jn" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3668100/" rel="noopener ugc nofollow" target="_blank">数据缺失的预防与处理</a> (2013)，国家生物技术信息中心。</p><p id="a197" class="pw-post-body-paragraph kg kh hi ki b kj le ij kl km lf im ko kp ls kr ks kt lt kv kw kx lu kz la lb hb bi translated">[2] <strong class="ki hj"> </strong>梅丽莎·j·阿祖尔，伊丽莎白·a·斯图亚特，康斯坦丁·弗兰基斯，菲利普·j·利夫，<a class="ae jn" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3074241/" rel="noopener ugc nofollow" target="_blank">链式方程多重插补:什么是多重插补，如何工作？</a> (2011)，国家生物技术信息中心。</p></div><div class="ab cl mw mx gp my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="hb hc hd he hf"><p id="6ca1" class="pw-post-body-paragraph kg kh hi ki b kj le ij kl km lf im ko kp ls kr ks kt lt kv kw kx lu kz la lb hb bi translated"><em class="me">在</em><a class="ae jn" href="https://www.linkedin.com/in/srivignesh-rajan-123569151/" rel="noopener ugc nofollow" target="_blank"><em class="me">LinkedIn</em></a><em class="me">，</em><a class="ae jn" href="https://twitter.com/RajanSrivignesh" rel="noopener ugc nofollow" target="_blank"><em class="me">Twitter</em></a><em class="me">上联系我！</em></p><p id="14a0" class="pw-post-body-paragraph kg kh hi ki b kj le ij kl km lf im ko kp ls kr ks kt lt kv kw kx lu kz la lb hb bi translated"><strong class="ki hj">快乐的机器学习！</strong></p><h2 id="bf89" class="mi jp hi bd jq mj mk ml ju mm mn mo jy kp mp mq ka kt mr ms kc kx mt mu ke mv bi translated">谢谢你！</h2></div></div>    
</body>
</html>