<html>
<head>
<title>Spotting Defects! — Deep Metric Learning Solution For MVTec Anomaly Detection Dataset</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">发现缺陷！—针对MVTec异常检测数据集的深度度量学习解决方案</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/spotting-defects-deep-metric-learning-solution-for-mvtec-anomaly-detection-dataset-c77691beb1eb?source=collection_archive---------1-----------------------#2019-09-16">https://medium.com/analytics-vidhya/spotting-defects-deep-metric-learning-solution-for-mvtec-anomaly-detection-dataset-c77691beb1eb?source=collection_archive---------1-----------------------#2019-09-16</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/f6f4bf5e171f6171f5dc709940320449.png" data-original-src="https://miro.medium.com/v2/resize:fit:1168/format:webp/1*312rUDKnOfELw3CbyB7VXQ.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">来自MVTec异常检测数据集的螺钉图像中的斑点缺陷。</figcaption></figure><p id="dcd9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">每天我们都在检查视觉上是否有问题，这在我们的生活中很自然地发生了。例如，当你从冰箱里拿出食物时，你会无意识地瞥一眼，看看它是否可以。</p><p id="efa0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在商业中，目视检查广泛应用于生产的最终过程。这将是机器学习异常检测的主要应用。</p><h1 id="91c4" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">MVTec异常检测数据集(MVTec AD)</h1><p id="ee10" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated"><a class="ae kr" href="https://www.mvtec.com/company/research/datasets/mvtec-ad/" rel="noopener ugc nofollow" target="_blank">https://www.mvtec.com/company/research/datasets/mvtec-ad/</a></p><p id="be8e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">一家德国公司<a class="ae kr" href="https://www.mvtec.com" rel="noopener ugc nofollow" target="_blank"> MVTec软件有限公司</a>最近发布了一个新颖的<a class="ae kr" href="https://www.mvtec.com/company/research/datasets/mvtec-ad/" rel="noopener ugc nofollow" target="_blank"> MVTec异常检测数据集</a>【1】，它拥有来自15个类别的真实数据。</p><figure class="kt ku kv kw fd ij er es paragraph-image"><div class="er es ks"><img src="../Images/383ee979855bca2038cb8115da88e21d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1306/format:webp/1*0lRbLkuWqafTXQ9PXCGH4A.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">图来自MVTec广告网站:来自6个类别的好的(绿色)和坏的(红色)例子。</figcaption></figure><p id="b220" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">从工业到农业的各种类别，每个不同领域的缺陷，图像中的各种对齐，甚至注释中的缺陷区域的分段数据——这是一个很棒的数据集。</p><blockquote class="kx ky kz"><p id="b6d1" class="iq ir la is b it iu iv iw ix iy iz ja lb jc jd je lc jg jh ji ld jk jl jm jn hb bi translated">"就我们所知，没有可比较的数据集存在于无监督的异常检测任务中."</p></blockquote><p id="3233" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">引入MVTec AD是为了在无监督异常检测(和分割)研究领域扮演MNIST、CIFAR10或ImageNet的角色。</p><p id="f59d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">该数据集附有一篇论文[1]，其中不仅介绍了数据集，还评估了基线方法，如GAN、autoencoder或其他传统方法。</p><h1 id="d6b1" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">深度度量学习</h1><p id="a224" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">本文利用该数据集进行了一些实验，将深度度量学习应用于异常检测任务。主要的深度度量学习如ArcFace[3]/ CosFace[4]在人脸验证/识别任务中比较流行，这些方法可以度量数据间的<strong class="is hj"> <em class="la">距离</em> </strong>。例如，该距离然后被用于确定两张照片中的人脸是否具有相同的身份。</p><p id="2ac6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这些深度度量学习方法的一大好处是它们的简单性。</p><ul class=""><li id="2ddd" class="le lf hi is b it iu ix iy jb lg jf lh jj li jn lj lk ll lm bi translated">它们非常简单，只需再利用传统的CNN模型，增加一些小的插件层。</li><li id="0904" class="le lf hi is b it ln ix lo jb lp jf lq jj lr jn lj lk ll lm bi translated">修改后的CNN可以照常在分类任务中进行训练，甚至在训练过程中不做任何改变，然后就完成了。</li><li id="93db" class="le lf hi is b it ln ix lo jb lp jf lq jj lr jn lj lk ll lm bi translated">CNN的主体现在准备好输出可用于计算数据之间距离的特征。</li></ul><h1 id="ed38" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">经过测试的深度度量学习方法</h1><figure class="kt ku kv kw fd ij er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es ls"><img src="../Images/3806fac3d7a4b6a394960d30e0f56adb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I0NhhRQFXaX0LeCEtc9uYg.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">图一。来自CosFace[4]:提议的CosFace框架的概述。</figcaption></figure><p id="2026" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在所有实验中，测试了以下方法:</p><ul class=""><li id="cb37" class="le lf hi is b it iu ix iy jb lg jf lh jj li jn lj lk ll lm bi translated">L2约束的软最大损失[2]</li><li id="8d01" class="le lf hi is b it ln ix lo jb lp jf lq jj lr jn lj lk ll lm bi translated">弧面[3]</li><li id="fb7f" class="le lf hi is b it ln ix lo jb lp jf lq jj lr jn lj lk ll lm bi translated">CosFace[4]</li><li id="291d" class="le lf hi is b it ln ix lo jb lp jf lq jj lr jn lj lk ll lm bi translated">球面[5]</li><li id="ddef" class="le lf hi is b it ln ix lo jb lp jf lq jj lr jn lj lk ll lm bi translated">中心丢失[6]</li><li id="d34b" class="le lf hi is b it ln ix lo jb lp jf lq jj lr jn lj lk ll lm bi translated">和传统的CNN一样，它的功能也适用于测量距离</li></ul><h1 id="4f41" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">实验</h1><p id="083a" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">已经测试了3个不同的分类问题设置。一个失败了，下一个失败了，最后一个用新发明的技术成功了。</p><ol class=""><li id="f3a7" class="le lf hi is b it iu ix iy jb lg jf lh jj li jn lx lk ll lm bi translated">实验一:传统的监督多类分类。</li><li id="518b" class="le lf hi is b it ln ix lo jb lp jf lq jj lr jn lx lk ll lm bi translated">实验2:正常和异常(缺陷)类别之一之间的二元分类。</li><li id="60b6" class="le lf hi is b it ln ix lo jb lp jf lq jj lr jn lx lk ll lm bi translated">实验3:自监督从正常样本生成异常样本。</li><li id="54d0" class="le lf hi is b it ln ix lo jb lp jf lq jj lr jn lx lk ll lm bi translated">这里还有一个尝试:所有类别的AUC都超过90%。</li></ol></div><div class="ab cl ly lz gp ma" role="separator"><span class="mb bw bk mc md me"/><span class="mb bw bk mc md me"/><span class="mb bw bk mc md"/></div><div class="hb hc hd he hf"><h1 id="428b" class="jo jp hi bd jq jr mf jt ju jv mg jx jy jz mh kb kc kd mi kf kg kh mj kj kk kl bi translated">实验1:传统的监督多类分类</h1><p id="6efd" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">正如MVTec广告论文所声称的，许多先前的工作使用主要的图像数据集进行评估，例如MNIST、CIFAR10。问题设置是:</p><ul class=""><li id="e53e" class="le lf hi is b it iu ix iy jb lg jf lh jj li jn lj lk ll lm bi translated">在训练之前，为异常检测任务分配一些原始类为正常，而其他类为异常。</li></ul><figure class="kt ku kv kw fd ij er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es mk"><img src="../Images/4af215645e4308fcd95843e9266e2b25.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mrgkwFQUOW9LfzGjoHlL3g.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">显示CIFAR-10分类拆分示例的图。</figcaption></figure><ul class=""><li id="ad90" class="le lf hi is b it iu ix iy jb lg jf lh jj li jn lj lk ll lm bi translated">仅分配给<em class="la">正常</em>的训练类样本。不使用<em class="la">异常</em>样本，然后模型将被训练来区分<em class="la">正常</em>类中的一个。</li><li id="1eb7" class="le lf hi is b it ln ix lo jb lp jf lq jj lr jn lj lk ll lm bi translated">训练后，通过测量距离对所有测试样本进行评估。<br/>(这个后面有描述。)</li></ul><p id="61dc" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">因此，这里应用了类似的设置:</p><ul class=""><li id="da9f" class="le lf hi is b it iu ix iy jb lg jf lh jj li jn lj lk ll lm bi translated">训练集由来自以下4个类别的无缺陷(正常)样本组成:<em class="la">“胶囊”、“地毯”、“皮革”、“电缆”。</em>所以训练是这4个类的多类分类问题。</li><li id="89bb" class="le lf hi is b it ln ix lo jb lp jf lq jj lr jn lj lk ll lm bi translated">测试按类别进行。评估每个类别中的所有测试样品，最后计算AUC以评估性能。</li><li id="1e07" class="le lf hi is b it ln ix lo jb lp jf lq jj lr jn lj lk ll lm bi translated">注意，测试班和培训班不一样。测试样本包括<em class="la">正常</em>‘良好’样本以及各种类型的<em class="la">异常</em>缺陷样本。</li></ul><figure class="kt ku kv kw fd ij er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es ml"><img src="../Images/9e41e1956355c9120c504171a1ad027a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rRv0U3XIzyC9_3CIIeF-6A.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">训练批次的示例图。这是一个4级分类问题。</figcaption></figure><p id="e0ca" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">训练成功完成后，很容易将看起来非常不同的图像分类。</p><p id="3a08" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">但与通常的CNN分类不同，这实际上训练了具有度量学习功能的CNN来学习度量样本之间的距离。</p><h1 id="fd46" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">测量距离和异常识别</h1><p id="9ccb" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">在测试阶段，通过以下步骤测量所有测试样品与正常等级的距离:</p><ol class=""><li id="16ce" class="le lf hi is b it iu ix iy jb lg jf lh jj li jn lx lk ll lm bi translated">从训练好的模型中剪切最后一层，然后模型将输出512-D特征。(此处使用ResNet18，它在最终FC层之前输出512-D特征)</li><li id="166e" class="le lf hi is b it ln ix lo jb lp jf lq jj lr jn lx lk ll lm bi translated">提前获取所有<em class="la"> N </em>训练实例<em class="la"> x_n </em>的特征<em class="la"> e_n </em>。<br/>(将所有<em class="la"> x_n </em>馈入模型，并从其输出中获取特征)</li><li id="cc43" class="le lf hi is b it ln ix lo jb lp jf lq jj lr jn lx lk ll lm bi translated">现在得到第<em class="la"> m </em>个测试样本<em class="la"> x_m </em>的特征<em class="la"> e_m </em>，然后用所有训练样本<em class="la"> e_n </em>计算<a class="ae kr" href="http://cosine distance" rel="noopener ugc nofollow" target="_blank"> <em class="la">余弦距离</em> </a>。现在我们有了从测试样本<em class="la"> x_m </em>到所有训练样本的<em class="la"> N </em>个距离。</li><li id="e4e5" class="le lf hi is b it ln ix lo jb lp jf lq jj lr jn lx lk ll lm bi translated">然后从<em class="la"> N </em>距离中选择最小值。该最小距离是试样<em class="la"> x_m </em>与正常<em class="la">的距离<em class="la"> d_m </em>。</em></li><li id="0198" class="le lf hi is b it ln ix lo jb lp jf lq jj lr jn lx lk ll lm bi translated">重复步骤3和4，直到我们获得所有的<em class="la"> M </em>测试样品距离。</li><li id="1f6a" class="le lf hi is b it ln ix lo jb lp jf lq jj lr jn lx lk ll lm bi translated">然后，我们可以设置任何阈值，将距离分为正常或异常类别。距离较短的样本是正常的，其他距离较长的样本被检测为异常。</li></ol><h1 id="ed86" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">传统监督多类分类的结果</h1><figure class="kt ku kv kw fd ij er es paragraph-image"><div class="er es mm"><img src="../Images/ff8267bc3ad46caaab0556d939a17047.png" data-original-src="https://miro.medium.com/v2/resize:fit:638/format:webp/1*iqb9HbHiJ9a4kiQgKm1AJw.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">在多类分类设置中训练的模型的AUC结果。</figcaption></figure><p id="5d56" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">学习指标的训练模型失败(小于0.5；比随机回答更糟)，测量的距离几乎是不正确的。这很自然:</p><ul class=""><li id="a096" class="le lf hi is b it iu ix iy jb lg jf lh jj li jn lj lk ll lm bi translated">受过训练，能辨别非常不同的物体，如“胶囊”和“电缆”。</li><li id="8eea" class="le lf hi is b it ln ix lo jb lp jf lq jj lr jn lj lk ll lm bi translated">在非常相似的物体之间进行测试；_正常_ '胶囊'对_异常'胶囊'有缺陷，这些看起来比'胶囊'对'电缆'更接近。</li></ul><p id="3354" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">因此，度量学习评价的传统问题设置在现实场景中不起作用…</p><blockquote class="kx ky kz"><p id="cd18" class="iq ir la is b it iu iv iw ix iy iz ja lb jc jd je lc jg jh ji ld jk jl jm jn hb bi translated">我们需要激励模型去<strong class="is hj">学会衡量<em class="hi">小差异</em> </strong>。猫和车没有区别，甚至黑猫和灰猫也没有区别。<br/> <em class="hi">在干净的螺丝和有微小划痕的螺丝之间！</em></p></blockquote><h1 id="9de6" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">实验2:正常和异常(缺陷)类别之一之间的二元分类</h1><p id="c7cf" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">模型应该能发现正常样本的微小差异。为了做到这一点，</p><ul class=""><li id="1cba" class="le lf hi is b it iu ix iy jb lg jf lh jj li jn lj lk ll lm bi translated">从测试集中选出一个缺陷类(只有测试集有缺陷类)，然后将其样本作为异常类放入训练集。</li><li id="a711" class="le lf hi is b it ln ix lo jb lp jf lq jj lr jn lj lk ll lm bi translated">现在训练模型是正常/异常二元分类任务。</li></ul><figure class="kt ku kv kw fd ij er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es mn"><img src="../Images/edad016a3c1a3b235c70c78a3574316f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m_8GmpAEqc7CnOBfu7SV8A.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">既有“好”(正常)又有“坏_大”(异常)的训练批次示例图。</figcaption></figure><p id="6102" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">但也失败了，大概0.5接近随机答。</p><figure class="kt ku kv kw fd ij er es paragraph-image"><div class="er es mm"><img src="../Images/78b8e08f12a67e9f46bc9c4b293af557.png" data-original-src="https://miro.medium.com/v2/resize:fit:638/format:webp/1*WLHNnH0DsufTkmeW82Xcmw.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">二元分类设置中训练的模型的AUC结果。</figcaption></figure><p id="39c1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">基本上，异常样本量太小；正常样本量在200+左右，缺陷异常样本量在10左右，非常不平衡。以下是为了减轻这个问题，虽然这些没有工作。</p><ul class=""><li id="1bb8" class="le lf hi is b it iu ix iy jb lg jf lh jj li jn lj lk ll lm bi translated">过采样缺陷类别，具有增强功能，以及类似于<a class="ae kr" href="https://forums.fast.ai/t/mixup-data-augmentation/22764" rel="noopener ugc nofollow" target="_blank">混合</a>的训练技术。</li></ul><p id="b453" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="la">训练模型以便它们能辨别微小的“错误”的旅程还在继续… </em></p><h1 id="5d60" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">实验3:自监督从正常样本生成异常样本</h1><p id="1055" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">这是基于一个简单的想法。</p><p id="ed23" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="la">现在我们需要的是与正常样本有微小差异的异常样本。然后，我们可以简单地从正常样本中生成异常样本。</em></p><p id="c640" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">一旦异常样本准备就绪，我们就可以训练模型，使它们能够区分与原始正常样本的微小差异。这个训练问题就是二元分类。我们只使用正常样本，这也是自我监督的训练。</p><p id="297b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这个实验发明了一个新的数据集类(实际上是fast.ai库的ImageList类[7]):</p><ul class=""><li id="9c41" class="le lf hi is b it iu ix iy jb lg jf lh jj li jn lj lk ll lm bi translated">双打训练<em class="la">正常</em>样本。</li><li id="c1f9" class="le lf hi is b it ln ix lo jb lp jf lq jj lr jn lj lk ll lm bi translated">为偶数样本分配正常标签，为奇数样本分配异常标签。那么所有的原始样本现在都有了“异常孪生”样本。</li><li id="cb2a" class="le lf hi is b it ln ix lo jb lp jf lq jj lr jn lj lk ll lm bi translated">当使用图像时，所有标记为<em class="la">异常</em>的图像将在其上随机绘制一条线。这是一条与普通样本不同的细线。画线时的随机性也有助于数据扩充。</li></ul><figure class="kt ku kv kw fd ij er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es mo"><img src="../Images/95d53ab5c9aaa53deec8bdca3cf5e7be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IaXiLzmYT46gg3JTf194hw.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">训练批次的示例图。它既有“正常”又有“异常”，所有异常样本都生成一条彩色线作为缺陷“疤痕”。</figcaption></figure><p id="43b6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这个结果是有意义的。</p><figure class="kt ku kv kw fd ij er es paragraph-image"><div class="er es mm"><img src="../Images/9fba94821c7da71269b7454c88908d2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:638/format:webp/1*gU2nTL0jbK20EqHRdyEcZA.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">在自我监督设置中训练的模型的AUC结果。改进了。</figcaption></figure><figure class="kt ku kv kw fd ij er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es mp"><img src="../Images/f29298608302bd28547499755ed1873d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JyA8iV3GLWuU3f4anwh_zg.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">AUC结果详情表。在这种情况下，CosFace或ArcFace是稳定的。</figcaption></figure><p id="a01e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">让我们用grad-CAM激活热图检查样本。成功案例表明，热图捕捉到了图像上的缺陷部分:</p><figure class="kt ku kv kw fd ij er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es mq"><img src="../Images/bb902b38872d1bd0801efb6f1d910460.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E_Tncn1UM_ARi7M6Bsnxpg.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">AUC为99%的榛子ArcFace的示例结果。测试样本及其热图(上图和中图)以及用于距离计算的最接近的对应训练样本(下图)。</figcaption></figure><p id="68be" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">下面的失败案例表明，模型没有考虑缺陷。模型没有正确地学习来发现这些类型的缺陷。像这样的例子还有很多，说明它还有很多需要改进的地方。</p><figure class="kt ku kv kw fd ij er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es mr"><img src="../Images/f218f420e950e516afd5d18bfe7c8f4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y-C7cHQaTCjNiPo0zkquHA.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">在AUC 62.3%处具有螺钉的ArcFace的示例结果，热图显示模型被背景分散了注意力。它未能发现螺丝尖端的缺陷。</figcaption></figure><h1 id="8c97" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">还有一个:所有类别的AUC都超过90%</h1><p id="c760" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">作为最终结果，以下是调整模型以实现AUC 90%后的grad-CAM热图。这很容易调整，我们可以调整如何创建异常孪生样本，使其模拟缺陷模式。</p><p id="bdb0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">但这意味着什么呢？这是通过使用测试样本中发生的缺陷模式的知识来完成的。就像作弊一样。</p><ul class=""><li id="0b12" class="le lf hi is b it iu ix iy jb lg jf lh jj li jn lj lk ll lm bi translated">因此，这不适用于没有先前缺陷模式可用的用例。</li><li id="51da" class="le lf hi is b it ln ix lo jb lp jf lq jj lr jn lj lk ll lm bi translated">但是在很多情况下，很多缺陷模式是已知的。(通常在生产线上，主要缺陷通过其百分比或ppm进行分类。)<br/>那么这对于自动检测已知或可能的故障模式仍然是有用的。</li></ul><figure class="kt ku kv kw fd ij er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es mr"><img src="../Images/f91601798147fd4f7792d0c46ffef9fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x4iqM-Cj9ESy_klYn-SJbg.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">带有螺钉的ArcFace的示例结果为AUC 91%，比62.3%有所提高。该模型在螺钉尖端发现缺陷。</figcaption></figure><figure class="kt ku kv kw fd ij er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es mq"><img src="../Images/76d81fd6854cf31e7a0c087ee20bbfca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4zZfKDZFlET4OXE8yAyerw.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">ArcFace的示例结果，晶体管的AUC为95.8%，比89%有所提高。模型发现有缺陷的腿。</figcaption></figure><figure class="kt ku kv kw fd ij er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es mq"><img src="../Images/c5f2973f081e41e9a24c33add6637a3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EcJfkjPO7WrGC6anbKHIVw.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">ArcFace的示例结果，网格的AUC为99.9%，比79.8%有所提高。热图显示缺陷零件。</figcaption></figure><figure class="kt ku kv kw fd ij er es paragraph-image"><div class="er es ms"><img src="../Images/ff2fdc42f6661ad241600422e9219bf5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1088/format:webp/1*Br6qr9hRqE3FjkeNmCXRWA.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">ArcFace的要素(嵌入)分布示例，栅格的AUC为99.9%。“好的”(正常的)特征是在左下角形成一个圆，远离右上角的其他缺陷样本。</figcaption></figure><figure class="kt ku kv kw fd ij er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es mq"><img src="../Images/a122672b47495b602a2df39c69dc14fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IA-VFE-1Zx5CoQ6ab_NWVw.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">服用避孕药的ArcFace结果示例AUC为93.5%，比70%有所改善。一些缺陷被正确地发现，但是正确的两个例子表明模型被分散了注意力(未来可能的例子失败的风险)。</figcaption></figure></div><div class="ab cl ly lz gp ma" role="separator"><span class="mb bw bk mc md me"/><span class="mb bw bk mc md me"/><span class="mb bw bk mc md"/></div><div class="hb hc hd he hf"><h1 id="326e" class="jo jp hi bd jq jr mf jt ju jv mg jx jy jz mh kb kc kd mi kf kg kh mj kj kk kl bi translated">与纸张的比较</h1><p id="3eed" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">原始MVTec广告论文[1]上的所有结果都基于分段输出。然后基本上很难比较。</p><ul class=""><li id="f9cc" class="le lf hi is b it iu ix iy jb lg jf lh jj li jn lj lk ll lm bi translated">纸上的AUC结果显示低于90%，如“地毯”、“电缆”、“金属螺母”和“拉链”。</li><li id="99d1" class="le lf hi is b it ln ix lo jb lp jf lq jj lr jn lj lk ll lm bi translated">但它是基于分割像素TPR/FPR计算的。这将是一个比基于图像距离更困难的问题。</li><li id="3a40" class="le lf hi is b it ln ix lo jb lp jf lq jj lr jn lj lk ll lm bi translated">只要简单地判断图像是正常的还是异常的，深度度量学习可能是有用的，因为它简单，相比于本文讨论的需要复杂阈值确定的基于分割的检测。</li></ul><h1 id="5e91" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">最后的想法</h1><p id="d4d1" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">本文的实验表明:</p><ul class=""><li id="8267" class="le lf hi is b it iu ix iy jb lg jf lh jj li jn lj lk ll lm bi translated">深度度量学习方法可以用作MVTec AD数据集的自监督异常检测；</li><li id="e61a" class="le lf hi is b it ln ix lo jb lp jf lq jj lr jn lj lk ll lm bi translated">其grad-CAM可用于在成功的情况下引导有缺陷的零件，</li><li id="649c" class="le lf hi is b it ln ix lo jb lp jf lq jj lr jn lj lk ll lm bi translated">或者至少可以用AUC 90%或更高的性能来区分缺陷与否。</li><li id="d8a7" class="le lf hi is b it ln ix lo jb lp jf lq jj lr jn lj lk ll lm bi translated">基于分割和基于深度度量学习的组合/集成使用可以获得更好的性能，或者为一些潜在的应用开辟新的可能性。</li></ul><h1 id="2ecc" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">源代码</h1><p id="d560" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">在这里找到示例代码:<a class="ae kr" href="https://github.com/daisukelab/metric_learning/tree/master/MVTecAD" rel="noopener ugc nofollow" target="_blank">https://github . com/daisukelab/metric _ learning/tree/master/MVTecAD</a></p><p id="146e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">非常感谢<a class="ae kr" href="https://github.com/fastai/fastai" rel="noopener ugc nofollow" target="_blank"> fast.ai库</a>【7】将开发实验的时间减到最少。</p><h1 id="70af" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">资源</h1><ul class=""><li id="3d8c" class="le lf hi is b it km ix kn jb mt jf mu jj mv jn lj lk ll lm bi translated">[1]保罗·博格曼、迈克尔·福瑟、大卫·萨特勒格、卡斯滕·斯特格。<a class="ae kr" href="https://www.mvtec.com/fileadmin/Redaktion/mvtec.com/company/research/mvtec_ad.pdf" rel="noopener ugc nofollow" target="_blank"><strong class="is hj">MVTec AD——无监督异常检测的综合真实数据集</strong></a>；2019年6月，IEEE计算机视觉和模式识别大会(CVPR)</li><li id="d7fd" class="le lf hi is b it ln ix lo jb lp jf lq jj lr jn lj lk ll lm bi translated">[2] R. Ranjan、C. D. Castillo和R. Chellappa。用于鉴别性人脸验证的L2约束软最大损失。arXiv预印本arXiv:1703.09507，2017。<a class="ae kr" href="https://arxiv.org/pdf/1703.09507.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1703.09507.pdf</a></li><li id="e1d7" class="le lf hi is b it ln ix lo jb lp jf lq jj lr jn lj lk ll lm bi translated">[3]邓俊杰、郭俊杰和S. Zafeiriou。Arcface:深度人脸识别的附加角裕度损失。arXiv预印本arXiv:1801.07698，2018。<a class="ae kr" href="https://arxiv.org/pdf/1801.07698.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1801.07698.pdf</a></li><li id="6204" class="le lf hi is b it ln ix lo jb lp jf lq jj lr jn lj lk ll lm bi translated">[4] H. Wang，Y. Wang，Z. Zhou，X. Ji，D. Gong，J. Zhou，Z. Li，和W. Liu，CosFace:用于深度人脸识别的大幅度余弦损失，arXiv预印本arXiv:1801.09414，2018 .【https://arxiv.org/pdf/1801.09414.pdf T2】号</li><li id="014b" class="le lf hi is b it ln ix lo jb lp jf lq jj lr jn lj lk ll lm bi translated">[5]刘文伟、温、于、李、拉杰和宋。用于人脸识别的深度超球面嵌入。2017年在CVPR。【https://arxiv.org/pdf/1704.08063.pdf T4】</li><li id="99be" class="le lf hi is b it ln ix lo jb lp jf lq jj lr jn lj lk ll lm bi translated">[6]文，张，李，乔，一种用于深度人脸识别的判别特征学习方法，“欧洲计算机视觉会议.斯普林格，2016年，第499–515页。<a class="ae kr" href="https://ydwen.github.io/papers/WenECCV16.pdf" rel="noopener ugc nofollow" target="_blank">https://ydwen.github.io/papers/WenECCV16.pdf</a></li><li id="db72" class="le lf hi is b it ln ix lo jb lp jf lq jj lr jn lj lk ll lm bi translated">[7]杰瑞米·霍华德等人(2018年)。fast.ai深度学习库，<a class="ae kr" href="https://github.com/fastai/fastai" rel="noopener ugc nofollow" target="_blank">https://github.com/fastai/fastai</a>。</li></ul></div></div>    
</body>
</html>