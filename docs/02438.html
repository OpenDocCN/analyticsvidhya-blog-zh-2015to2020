<html>
<head>
<title>Building Blocks of Neural Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">神经网络的构建模块</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/building-blocks-of-neural-networks-6713fa51375f?source=collection_archive---------22-----------------------#2019-12-16">https://medium.com/analytics-vidhya/building-blocks-of-neural-networks-6713fa51375f?source=collection_archive---------22-----------------------#2019-12-16</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><h2 id="abad" class="hg hh hi bd b fp hj hk hl hm hn ho dx hp translated" aria-label="kicker paragraph">深度学习的祈祷:第三部分</h2><div class=""/><div class=""><h2 id="be5d" class="pw-subtitle-paragraph io hr hi bd b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf dx translated">张量及其运算的介绍</h2></div><p id="e72f" class="pw-post-body-paragraph jg jh hi ji b jj jk is jl jm jn iv jo jp jq jr js jt ju jv jw jx jy jz ka kb hb bi translated">在上一篇文章中，我们已经讨论了机器学习/深度学习项目的基本架构。现在，我们将更加专注于深度学习概念。因此，如果你错过了我以前的文章，这里有我的个人资料的链接来阅读那些内容——IJAS·阿·H</p><figure class="kf kg kh ki fd kj er es paragraph-image"><div role="button" tabindex="0" class="kk kl di km bf kn"><div class="er es ke"><img src="../Images/19439b531174469ac2d939e59dbd81df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_TfwCGCeIXD9PiV0cFYazA.png"/></div></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">深度学习封面的祈祷</figcaption></figure><p id="a73a" class="pw-post-body-paragraph jg jh hi ji b jj jk is jl jm jn iv jo jp jq jr js jt ju jv jw jx jy jz ka kb hb bi translated">我们知道数据是建立任何学习模型的基本要求。但是单纯的原始数据并不能满足我们的要求。我们需要以某种特定的格式表示数据，作为神经网络的输入。因此，让我们讨论神经网络的数据表示。</p><h2 id="f09e" class="ku kv hi bd kw kx ky kz la lb lc ld le jp lf lg lh jt li lj lk jx ll lm ln ho bi translated">数据表示</h2><p id="1b6c" class="pw-post-body-paragraph jg jh hi ji b jj lo is jl jm lp iv jo jp lq jr js jt lr jv jw jx ls jz ka kb hb bi translated">在深度学习中，无论我们处理什么数据(文本、音频、视频等。)我们先把数据转换成<strong class="ji hs"> <em class="lt">张量</em> </strong> <em class="lt">。</em>这个将数据转换成张量的过程叫做<strong class="ji hs"> <em class="lt">数据矢量化</em> </strong> <em class="lt">。那么什么是张量呢？</em> <strong class="ji hs">张量是存储在多维数组中的数据。</strong></p><blockquote class="lu lv lw"><p id="ac05" class="jg jh lt ji b jj jk is jl jm jn iv jo lx jq jr js ly ju jv jw lz jy jz ka kb hb bi translated"><strong class="ji hs">注意:这里存储在多维数组中的数据将是实际数据的数字表示。</strong></p></blockquote><p id="8de4" class="pw-post-body-paragraph jg jh hi ji b jj jk is jl jm jn iv jo jp jq jr js jt ju jv jw jx jy jz ka kb hb bi translated">基于数据，张量可以有不同的维度。所以我们来探讨一些不同维度的张量。这里我们使用python中的<a class="ae ma" href="https://numpy.org/" rel="noopener ugc nofollow" target="_blank"> Numpy </a>库来创建张量。</p><p id="534f" class="pw-post-body-paragraph jg jh hi ji b jj jk is jl jm jn iv jo jp jq jr js jt ju jv jw jx jy jz ka kb hb bi translated"><strong class="ji hs"> 0维张量:</strong> 0维张量也叫<em class="lt">标量</em>。在Numpy中，float32或float64数是一个标量张量。</p><p id="730b" class="pw-post-body-paragraph jg jh hi ji b jj jk is jl jm jn iv jo jp jq jr js jt ju jv jw jx jy jz ka kb hb bi translated">这里<em class="lt"> ndim </em>用来显示轴的数量。</p><pre class="kf kg kh ki fd mb mc md me aw mf bi"><span id="28ed" class="ku kv hi mc b fi mg mh l mi mj">import numpy as np<br/>x = np.array(100)<br/>print("Array",x)<br/>print("dimension",x.ndim)</span><span id="9a3f" class="ku kv hi mc b fi mk mh l mi mj"><strong class="mc hs">output<br/></strong>Array 100 <br/>dimension 0</span></pre><p id="cb9c" class="pw-post-body-paragraph jg jh hi ji b jj jk is jl jm jn iv jo jp jq jr js jt ju jv jw jx jy jz ka kb hb bi translated"><strong class="ji hs">一维张量:</strong>一个数列可以认为是一维张量(1D张量，也叫<em class="lt">向量</em>)。</p><pre class="kf kg kh ki fd mb mc md me aw mf bi"><span id="783e" class="ku kv hi mc b fi mg mh l mi mj">import numpy as np<br/>x = np.array([1,5,2,7,11,24,25,12])<br/>print(“Array:”, x)<br/>print(“Dimension:”, x.ndim)</span><span id="db23" class="ku kv hi mc b fi mk mh l mi mj"><strong class="mc hs">Output<br/></strong>Array: [ 1  5  2  7 11 24 25 12] <br/>Dimension 1</span></pre><p id="ce35" class="pw-post-body-paragraph jg jh hi ji b jj jk is jl jm jn iv jo jp jq jr js jt ju jv jw jx jy jz ka kb hb bi translated"><strong class="ji hs">二维张量:</strong>二维张量是一维张量的集合。</p><pre class="kf kg kh ki fd mb mc md me aw mf bi"><span id="26fa" class="ku kv hi mc b fi mg mh l mi mj">import numpy as np<br/>x = np.array(<br/>[<br/>[1,5,2,7,11,24,25,12],<br/>[1,2,3,4,5,6,7,8]<br/>]<br/>)<br/>print(“Array:”, x)<br/>print(“Dimension”, x.ndim)</span><span id="7f51" class="ku kv hi mc b fi mk mh l mi mj"><strong class="mc hs">Output<br/></strong>Array: [[ 1  5  2  7 11 24 25 12]  [ 1  2  3  4  5  6  7  8]] Dimension 2</span></pre><p id="cea5" class="pw-post-body-paragraph jg jh hi ji b jj jk is jl jm jn iv jo jp jq jr js jt ju jv jw jx jy jz ka kb hb bi translated"><strong class="ji hs">多维张量:</strong>二维张量的集合产生三维张量，三维张量的集合又产生四维张量，如此继续。</p><figure class="kf kg kh ki fd kj er es paragraph-image"><div role="button" tabindex="0" class="kk kl di km bf kn"><div class="er es ml"><img src="../Images/45d6c191a4cabd220a096ad548f87643.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PYPyPFVcL1AI6lxRa6wmDA.jpeg"/></div></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">图1:不同维度张量的图示</figcaption></figure><h2 id="f238" class="ku kv hi bd kw kx ky kz la lb lc ld le jp lf lg lh jt li lj lk jx ll lm ln ho bi translated">真实世界的张量</h2><p id="2de0" class="pw-post-body-paragraph jg jh hi ji b jj lo is jl jm lp iv jo jp lq jr js jt lr jv jw jx ls jz ka kb hb bi translated">我们已经将数据表示为张量，现在让我们探索一些真实世界的张量表示来进一步理解这个概念。</p><p id="831a" class="pw-post-body-paragraph jg jh hi ji b jj jk is jl jm jn iv jo jp jq jr js jt ju jv jw jx jy jz ka kb hb bi translated"><strong class="ji hs">图像数据</strong> —图像是4D张量。因此，在图像相关的深度学习问题中，图像数据将被表示为具有形状<em class="lt">(样本、高度、宽度、通道)</em>的4D张量</p><p id="a2a8" class="pw-post-body-paragraph jg jh hi ji b jj jk is jl jm jn iv jo jp jq jr js jt ju jv jw jx jy jz ka kb hb bi translated"><strong class="ji hs">视频数据</strong> —视频用形状<em class="lt">(样本、帧、高度、宽度、通道)</em>的5D张量表示</p><h2 id="2c1d" class="ku kv hi bd kw kx ky kz la lb lc ld le jp lf lg lh jt li lj lk jx ll lm ln ho bi translated">张量运算</h2><figure class="kf kg kh ki fd kj er es paragraph-image"><div role="button" tabindex="0" class="kk kl di km bf kn"><div class="er es mm"><img src="../Images/65db543a4dd12c364511fc636dd65b0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9CZRkc3tU2b4UyCXSLUBIw.jpeg"/></div></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">图2:元素张量运算</figcaption></figure><p id="1a72" class="pw-post-body-paragraph jg jh hi ji b jj jk is jl jm jn iv jo jp jq jr js jt ju jv jw jx jy jz ka kb hb bi translated">如上图所示，我们可以用元素的方式对张量进行加减乘除。</p><p id="d29f" class="pw-post-body-paragraph jg jh hi ji b jj jk is jl jm jn iv jo jp jq jr js jt ju jv jw jx jy jz ka kb hb bi translated"><em class="lt">两个维数相同的张量的元素运算产生一个维数相同的新张量，其中每个标量值是父张量中标量的元素运算(加、减、乘、除)。</em></p><p id="eaa8" class="pw-post-body-paragraph jg jh hi ji b jj jk is jl jm jn iv jo jp jq jr js jt ju jv jw jx jy jz ka kb hb bi translated">现在，让我们看看如何使用numpy实现这些张量运算。</p><pre class="kf kg kh ki fd mb mc md me aw mf bi"><span id="64c6" class="ku kv hi mc b fi mg mh l mi mj">import numpy as np</span><span id="2f8c" class="ku kv hi mc b fi mk mh l mi mj">A = np.array([<br/>[[1,2,3], [4,5,6], [7,8,9]],<br/>[[11,12,13], [14,15,16], [17,18,19]],<br/>[[21,22,23], [24,25,26], [27,28,29]],<br/>])</span><span id="ac00" class="ku kv hi mc b fi mk mh l mi mj">B = np.array([<br/>[[1,2,3], [4,5,6], [7,8,9]],<br/>[[11,12,13], [14,15,16], [17,18,19]],<br/>[[21,22,23], [24,25,26], [27,28,29]],<br/>])</span><span id="40fd" class="ku kv hi mc b fi mk mh l mi mj">print(“Array A”,A)<br/>print()<br/>print(“Array B”,B)<br/>print()<br/>print("Array A+B:",A+B)<br/>print()<br/>print("Array A-B:", A-B)<br/>print()<br/>print("Array A*B:", A*B)<br/>print()<br/>print("Array A/B:", A/B)</span><span id="25f0" class="ku kv hi mc b fi mk mh l mi mj"><strong class="mc hs">Output</strong></span><span id="cf1c" class="ku kv hi mc b fi mk mh l mi mj">Array A [[[ 1  2  3]   [ 4  5  6]   [ 7  8  9]]   [[11 12 13]   [14 15 16]   [17 18 19]]   [[21 22 23]   [24 25 26]   [27 28 29]]]</span><span id="cab3" class="ku kv hi mc b fi mk mh l mi mj">Array B [[[ 1  2  3]   [ 4  5  6]   [ 7  8  9]]   [[11 12 13]   [14 15 16]   [17 18 19]]   [[21 22 23]   [24 25 26]   [27 28 29]]]</span><span id="f91f" class="ku kv hi mc b fi mk mh l mi mj">Array A+B: [[[ 2  4  6]   [ 8 10 12]   [14 16 18]]   [[22 24 26]   [28 30 32]   [34 36 38]]   [[42 44 46]   [48 50 52]   [54 56 58]]]</span><span id="2f81" class="ku kv hi mc b fi mk mh l mi mj">Array A-B: [[[0 0 0]   [0 0 0]   [0 0 0]]   [[0 0 0]   [0 0 0]   [0 0 0]]   [[0 0 0]   [0 0 0]   [0 0 0]]]</span><span id="c2b9" class="ku kv hi mc b fi mk mh l mi mj">Array A*B: [[[  1   4   9]   [ 16  25  36]   [ 49  64  81]]   [[121 144 169]   [196 225 256]   [289 324 361]]   [[441 484 529]   [576 625 676]   [729 784 841]]]</span><span id="3ed2" class="ku kv hi mc b fi mk mh l mi mj">Array A/B: [[[1. 1. 1.]   [1. 1. 1.]   [1. 1. 1.]]   [[1. 1. 1.]   [1. 1. 1.]   [1. 1. 1.]]   [[1. 1. 1.]   [1. 1. 1.]   [1. 1. 1.]]]</span></pre><h2 id="a0ec" class="ku kv hi bd kw kx ky kz la lb lc ld le jp lf lg lh jt li lj lk jx ll lm ln ho bi translated">广播</h2><p id="71a5" class="pw-post-body-paragraph jg jh hi ji b jj lo is jl jm lp iv jo jp lq jr js jt lr jv jw jx ls jz ka kb hb bi translated">我们已经讨论了形状相同的张量的numpy运算。现在我们来讨论不同形状张量上的运算。<em class="lt">受某些约束，较小的数组被“</em> <strong class="ji hs"> <em class="lt">”广播</em> </strong> <em class="lt">”穿过较大的数组以便它们具有兼容的形状。广播提供了一种向量化数组操作的方法，因此循环在C而不是Python中发生。这样做不会产生不必要的数据副本，并且通常会导致高效的算法实现。</em></p><p id="b9e4" class="pw-post-body-paragraph jg jh hi ji b jj jk is jl jm jn iv jo jp jq jr js jt ju jv jw jx jy jz ka kb hb bi translated">Numpy操作通常以元素对元素的方式成对进行。换句话说，两个张量必须有相同的形状。</p><pre class="kf kg kh ki fd mb mc md me aw mf bi"><span id="c850" class="ku kv hi mc b fi mg mh l mi mj">import numpy as np<br/>a = np.array([1.0, 2.0, 3.0])<br/>b = np.array([2.0, 2.0, 2.0])<br/>print(a * b)</span><span id="f2bc" class="ku kv hi mc b fi mk mh l mi mj"><strong class="mc hs">Output<br/></strong>array([2., 4., 6.])</span></pre><p id="1a7d" class="pw-post-body-paragraph jg jh hi ji b jj jk is jl jm jn iv jo jp jq jr js jt ju jv jw jx jy jz ka kb hb bi translated">当数组的形状满足一定的约束时，Numpy广播规则放宽了这一点。一个简单的例子是标量值与向量相乘。</p><pre class="kf kg kh ki fd mb mc md me aw mf bi"><span id="dd96" class="ku kv hi mc b fi mg mh l mi mj">import numpy as np<br/>a = np.array([1.0, 2.0, 3.0])<br/>b = 2<br/>print(a * b)<br/><strong class="mc hs">Output<br/></strong>array([2., 4., 6.])</span></pre><p id="604c" class="pw-post-body-paragraph jg jh hi ji b jj jk is jl jm jn iv jo jp jq jr js jt ju jv jw jx jy jz ka kb hb bi translated">这里，上面的两个代码片段产生相同的输出，第一个是通过使用简单的张量乘法，第二个是通过使用张量广播。</p><p id="42ce" class="pw-post-body-paragraph jg jh hi ji b jj jk is jl jm jn iv jo jp jq jr js jt ju jv jw jx jy jz ka kb hb bi translated">有关广播的更多信息，请访问:<a class="ae ma" href="https://docs.scipy.org/doc/numpy-1.13.0/user/basics.broadcasting.html#broadcasting" rel="noopener ugc nofollow" target="_blank">广播</a></p><p id="eb9d" class="pw-post-body-paragraph jg jh hi ji b jj jk is jl jm jn iv jo jp jq jr js jt ju jv jw jx jy jz ka kb hb bi translated"><strong class="ji hs">张量积</strong></p><p id="a82b" class="pw-post-body-paragraph jg jh hi ji b jj jk is jl jm jn iv jo jp jq jr js jt ju jv jw jx jy jz ka kb hb bi translated">张量<em class="lt">乘积</em>运算与逐元素张量乘法不同。给定一个维度为<em class="lt"> q </em>的张量和另一个维度为<em class="lt"> r </em>的张量，两个张量的乘积将产生一个维度为<em class="lt">q+r</em>的新张量</p><figure class="kf kg kh ki fd kj er es paragraph-image"><div class="er es mn"><img src="../Images/8d5d387d1f3cb5a91cb188058366c71c.png" data-original-src="https://miro.medium.com/v2/resize:fit:942/format:webp/1*YeQ0f6u8Cm9_ttijz4WvbQ.jpeg"/></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">图3:张量点运算</figcaption></figure><p id="9e61" class="pw-post-body-paragraph jg jh hi ji b jj jk is jl jm jn iv jo jp jq jr js jt ju jv jw jx jy jz ka kb hb bi translated">为了计算A和B的张量积，张量A中的每个元素都要乘以张量B。</p><p id="a11c" class="pw-post-body-paragraph jg jh hi ji b jj jk is jl jm jn iv jo jp jq jr js jt ju jv jw jx jy jz ka kb hb bi translated">现在，让我们看看如何使用numpy实现张量点运算</p><p id="c679" class="pw-post-body-paragraph jg jh hi ji b jj jk is jl jm jn iv jo jp jq jr js jt ju jv jw jx jy jz ka kb hb bi translated">为此，我们使用numpy中的<em class="lt"> tensordot(张量A，张量B，轴= '值')</em>函数</p><blockquote class="lu lv lw"><p id="d30f" class="jg jh lt ji b jj jk is jl jm jn iv jo lx jq jr js ly ju jv jw lz jy jz ka kb hb bi translated">轴值的三个常见用例是:</p><p id="1150" class="jg jh lt ji b jj jk is jl jm jn iv jo lx jq jr js ly ju jv jw lz jy jz ka kb hb bi translated"><code class="du mo mp mq mc b">axes = 0</code>:张量积</p><p id="d038" class="jg jh lt ji b jj jk is jl jm jn iv jo lx jq jr js ly ju jv jw lz jy jz ka kb hb bi translated"><code class="du mo mp mq mc b">axes = 1</code>:张量点积</p><p id="a30c" class="jg jh lt ji b jj jk is jl jm jn iv jo lx jq jr js ly ju jv jw lz jy jz ka kb hb bi translated"><code class="du mo mp mq mc b">axes = 2</code>:(默认)张量双收缩</p></blockquote><p id="7b61" class="pw-post-body-paragraph jg jh hi ji b jj jk is jl jm jn iv jo jp jq jr js jt ju jv jw jx jy jz ka kb hb bi translated">因为我们试图找到张量积<em class="lt">我们指定轴值为‘0’</em></p><pre class="kf kg kh ki fd mb mc md me aw mf bi"><span id="9c81" class="ku kv hi mc b fi mg mh l mi mj">import numpy as np<br/>A = np.array([2,24])<br/>B = np.array([5,8])<br/>C = np.tensordot(A,B,axes = 0)<br/>print(C)</span><span id="f810" class="ku kv hi mc b fi mk mh l mi mj"><strong class="mc hs">Output<br/></strong>[[ 10  16]  [120 192]]</span></pre><h2 id="45f8" class="ku kv hi bd kw kx ky kz la lb lc ld le jp lf lg lh jt li lj lk jx ll lm ln ho bi translated">参考</h2><ol class=""><li id="2fb4" class="mr ms hi ji b jj lo jm lp jp mt jt mu jx mv kb mw mx my mz bi translated"><a class="ae ma" href="https://en.wikipedia.org/wiki/Tensor" rel="noopener ugc nofollow" target="_blank">维基百科上的张量</a></li><li id="cda6" class="mr ms hi ji b jj na jm nb jp nc jt nd jx ne kb mw mx my mz bi translated"><a class="ae ma" href="https://en.wikipedia.org/wiki/Tensor_product" rel="noopener ugc nofollow" target="_blank">维基百科上的张量积</a></li><li id="e41f" class="mr ms hi ji b jj na jm nb jp nc jt nd jx ne kb mw mx my mz bi translated"><a class="ae ma" href="https://en.wikipedia.org/wiki/Tensor_algebra" rel="noopener ugc nofollow" target="_blank">维基百科上的张量代数</a></li><li id="e4dd" class="mr ms hi ji b jj na jm nb jp nc jt nd jx ne kb mw mx my mz bi translated"><a class="ae ma" href="https://machinelearningmastery.com/introduction-to-tensors-for-machine-learning/" rel="noopener ugc nofollow" target="_blank">用NumPy对张量进行机器学习的温和介绍</a></li><li id="fe77" class="mr ms hi ji b jj na jm nb jp nc jt nd jx ne kb mw mx my mz bi translated"><a class="ae ma" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.tensordot.html#:~:targetText=Compute%20tensor%20dot%20product%20along,specified%20by%20a_axes%20and%20b_axes%20." rel="noopener ugc nofollow" target="_blank"> numpy.tensordot </a></li></ol></div></div>    
</body>
</html>