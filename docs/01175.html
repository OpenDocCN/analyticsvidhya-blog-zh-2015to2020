<html>
<head>
<title>Detecting Fires using Tensorflow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用张量流检测火灾</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/detecting-fires-using-tensorflow-b5b148952495?source=collection_archive---------5-----------------------#2019-10-06">https://medium.com/analytics-vidhya/detecting-fires-using-tensorflow-b5b148952495?source=collection_archive---------5-----------------------#2019-10-06</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/></div><div class="ab cl if ig gp ih" role="separator"><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik"/></div><div class="hb hc hd he hf"><figure class="in io ip iq fd ir er es paragraph-image"><div role="button" tabindex="0" class="is it di iu bf iv"><div class="er es im"><img src="../Images/0aa52d3bf37e19c0b63324ae10ec2d11.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lyAKVTyRFqUhVPeOFVJaqw.png"/></div></div><figcaption class="iy iz et er es ja jb bd b be z dx translated">来源:<a class="ae jc" href="https://www.ft.com/content/1ba48b1a-cd69-11e9-b018-ca4456540ea6" rel="noopener ugc nofollow" target="_blank">https://www . ft . com/content/1 ba 48 B1 a-cd69-11e 9-b018-ca 4456540 ea 6</a></figcaption></figure><p id="b432" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">不言而喻，驯服火是人类最伟大的成就之一，并使我们成为今天这样一个社会。但是，尽管它有令人惊奇的积极作用，不必要的火灾仍然是我们每天面临的一个问题，在它们蔓延之前检测它们是绝对必要的。</p><p id="f721" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">本文旨在使用机器学习来检测视频中的火灾，具体讲讲如何在计算机视觉上使用Tensorflow的对象检测API和google cloud开始。让我们开始吧。</p><p id="f770" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">PS:与本文相关的所有文件都可以在这个github资源库中找到[ <a class="ae jc" href="https://github.com/popoago/Fire-Detection" rel="noopener ugc nofollow" target="_blank">这里</a> ]。</p><h1 id="78b6" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">背景</h1><figure class="in io ip iq fd ir er es paragraph-image"><div role="button" tabindex="0" class="is it di iu bf iv"><div class="er es kz"><img src="../Images/28a827bff1e160256668b32fa6ddb538.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZeDQGWRoERxO9dW9Sqgc_w.jpeg"/></div></div><figcaption class="iy iz et er es ja jb bd b be z dx translated">来源:<a class="ae jc" href="https://github.com/tensorflow/models/tree/master/research/object_detection" rel="noopener ugc nofollow" target="_blank">https://github . com/tensor flow/models/tree/master/research/object _ detection</a></figcaption></figure><p id="b9b8" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">Tensorflow的<a class="ae jc" href="https://github.com/tensorflow/models/tree/master/research/object_detection" rel="noopener ugc nofollow" target="_blank">对象检测API </a>是一个基于TensorFlow构建的开源框架，可以轻松构建、训练和部署对象检测模型。它提供了经过预训练的模型，易于阅读的文档有助于构建和部署强大的应用程序，并且支持<a class="ae jc" href="https://www.tensorflow.org/lite/models/object_detection/overview" rel="noopener ugc nofollow" target="_blank"> tensorflow lite </a>以帮助您在手机上运行该模型。</p><p id="94da" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">API接受png或jpeg格式的图像，以及边界框的坐标，特别是xmin、ymin、xmax和ymax。</p><p id="10c0" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">我使用过数据集可以从这里下载:</p><div class="la lb ez fb lc ld"><a href="https://github.com/steffensbola/furg-fire-dataset" rel="noopener  ugc nofollow" target="_blank"><div class="le ab dw"><div class="lf ab lg cl cj lh"><h2 class="bd hj fi z dy li ea eb lj ed ef hh bi translated">steffensbola/furg-fire-数据集</h2><div class="lk l"><h3 class="bd b fi z dy li ea eb lj ed ef dx translated">一个数据集，用于比较不同的基于非稳态视频的火灾探测器的性能。每个视频文件都有一个…</h3></div><div class="ll l"><p class="bd b fp z dy li ea eb lj ed ef dx translated">github.com</p></div></div><div class="lm l"><div class="ln l lo lp lq lm lr iw ld"/></div></div></a></div><p id="b10e" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">虽然存储库不再更新，但是它包含了足够的例子来开始使用。您会注意到的第一件事是，在存储库中有多个正面和负面例子的视频以及相应的xml文件。xml文件包含与视频中每一帧相关联的注释(标签)。因为模型需要图像和相关边界框坐标形式的数据，我们必须将上面的数据转换成<a class="ae jc" href="https://www.tensorflow.org/tutorials/load_data/tfrecord" rel="noopener ugc nofollow" target="_blank"> TFRecord文件格式</a>。</p><p id="10dd" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">虽然有一些文件可以将您的数据转换成所需的格式，如<a class="ae jc" href="https://github.com/tensorflow/models/blob/master/research/object_detection/create_pascal_tf_record.py" rel="noopener ugc nofollow" target="_blank"><strong class="jf hj">create _ Pascal _ TF _ record . py</strong></a><strong class="jf hj">，</strong>但它可能需要根据您的数据集进行修改。在这里，我创建了自己的脚本，它读取视频中的每一帧和相应的注释，并将它们分别存储在一个image和xml文件夹中，每隔20个image和xml存储在单独的文件夹中进行测试/验证。</p><figure class="in io ip iq fd ir"><div class="bz dy l di"><div class="ls lt l"/></div><figcaption class="iy iz et er es ja jb bd b be z dx translated">可从<a class="ae jc" href="https://github.com/popoago/Fire-Detection/blob/master/dataset_creation.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/Popo ago/Fire-Detection/blob/master/dataset _ creation . ipynb</a>获得</figcaption></figure><p id="8aa3" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">下一步是将xml文件转换成csv文件，这是我从这个优秀的<a class="ae jc" href="https://github.com/datitran/raccoon_dataset" rel="noopener ugc nofollow" target="_blank">资源库</a>中获得的，也是这篇博客的灵感来源。一旦为训练和测试(验证)集生成了csv文件，我们就使用<a class="ae jc" href="https://github.com/popoago/Fire-Detection/blob/master/create_tf.py" rel="noopener ugc nofollow" target="_blank">这个文件</a>创建TFRecords，得到train.record和val.record文件。</p><p id="e2f8" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">除了记录文件，我们还需要标签映射，这是我们在fire_label_map.pbtxt中定义的。</p><figure class="in io ip iq fd ir er es paragraph-image"><div class="er es lu"><img src="../Images/b8c76c09f1145bc640d35ee90bffca9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:686/format:webp/1*8nAI3GW3TOhgtfY1Q4lY-Q.png"/></div><figcaption class="iy iz et er es ja jb bd b be z dx translated">它包含一个标签</figcaption></figure><p id="55b1" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">我们还需要设置一个项目谷歌云开始培训。<a class="ae jc" href="https://github.com/floydhub/object-detection-template/blob/master/object_detection/g3doc/running_pets.md" rel="noopener ugc nofollow" target="_blank">这个库</a>解释了如何为<a class="ae jc" href="http://www.robots.ox.ac.uk/~vgg/data/pets/" rel="noopener ugc nofollow" target="_blank">牛津-IIIT Pets数据集</a>做这件事，我已经为这个特殊的问题做了相应的编辑。在遵循创建GCS bucket的步骤之后，我们可以将上面创建的文件上传到google cloud。</p><figure class="in io ip iq fd ir er es paragraph-image"><div role="button" tabindex="0" class="is it di iu bf iv"><div class="er es lv"><img src="../Images/443114e5684f32b97a3ceb0c0142420d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xwc0uCM4MITO8NjVKnF7pw.png"/></div></div><figcaption class="iy iz et er es ja jb bd b be z dx translated">上传tfrecord和。pbtxt文件</figcaption></figure><h1 id="9eb6" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">培养</h1><p id="e7d7" class="pw-post-body-paragraph jd je hi jf b jg lw ji jj jk lx jm jn jo ly jq jr js lz ju jv jw ma jy jz ka hb bi translated">设置好输入文件后，我们就可以开始训练了。我们需要确定的第一件事是我们将使用的模型。有很好的资源可以解释它们，其中一些我已经在这篇博客的结尾提到了。我选择的是<a class="ae jc" href="https://arxiv.org/pdf/1506.01497" rel="noopener ugc nofollow" target="_blank">更快的RCNN </a>，一种广泛用于对象检测任务的网络架构。尽管<a class="ae jc" href="https://arxiv.org/pdf/1512.02325" rel="noopener ugc nofollow" target="_blank"> SSD </a>相对更快(咳咳)，但前者以速度为代价提供了更好的精度。我们首先要做的就是编辑<strong class="jf hj">faster _ rcnn _ resnet 101 _ coco . config</strong>文件。除了将num_classes更改为1并编辑检查点的路径以及输入和标签路径。然后，我们可以将上面的配置文件上传到我们的GCS bucket。</p><p id="4492" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">对于你的问题，使用预先训练好的模型总是明智的。虽然检测火灾显然不是COCO数据集中的一个标签，但模型学习和捕捉的特征几乎总是比从头开始训练要好。下载并解包<a class="ae jc" href="http://storage.googleapis.com/download.tensorflow.org/models/object_detection/faster_rcnn_resnet101_coco_11_06_2017.tar.gz" rel="noopener ugc nofollow" target="_blank"> COCO-pretrained用Resnet-101 model </a>更快的R-CNN后，我们也可以把这些文件上传到云端。</p><figure class="in io ip iq fd ir er es paragraph-image"><div role="button" tabindex="0" class="is it di iu bf iv"><div class="er es mb"><img src="../Images/9a95ef7fae98db4289c6241d8bdb94e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2u-fG7pFGUYID_Pr-u1Qfg.png"/></div></div><figcaption class="iy iz et er es ja jb bd b be z dx translated">上传权重和配置文件。</figcaption></figure><p id="f5e2" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">在遵循文档中的剩余步骤之后，即打包对象检测代码并为我们的Google Cloud ML作业编写集群配置，我们可以通过在我们的机器上运行<a class="ae jc" href="https://www.tensorflow.org/tutorials" rel="noopener ugc nofollow" target="_blank"> Tensorboard </a>来监控进度。</p><figure class="in io ip iq fd ir er es paragraph-image"><div role="button" tabindex="0" class="is it di iu bf iv"><div class="er es mc"><img src="../Images/9db6f3fb733afb62f509ffc8e5598c95.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MtQU6kYW0K4v4OeN2ukgJA.png"/></div></div><figcaption class="iy iz et er es ja jb bd b be z dx translated">开始谷歌云培训</figcaption></figure><h1 id="84fd" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">导出模型</h1><p id="2b37" class="pw-post-body-paragraph jd je hi jf b jg lw ji jj jk lx jm jn jo ly jq jr js lz ju jv jw ma jy jz ka hb bi translated">模型经过训练后，需要导出到Tensorflow graph proto，以便可以用于推理。</p><figure class="in io ip iq fd ir er es paragraph-image"><div role="button" tabindex="0" class="is it di iu bf iv"><div class="er es md"><img src="../Images/5f2fdcae1df9045c98dfab715b0c2312.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NeVp5FFJ5oO0N8fPRot7jg.png"/></div></div><figcaption class="iy iz et er es ja jb bd b be z dx translated">将检查点编号替换为您停止训练的位置</figcaption></figure><h1 id="8959" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">后续步骤</h1><p id="c00c" class="pw-post-body-paragraph jd je hi jf b jg lw ji jj jk lx jm jn jo ly jq jr js lz ju jv jw ma jy jz ka hb bi translated">虽然该模型在给定的数据集上表现得相当准确，但由于训练图像有限，它不会给出很高的准确性。我在这里忽略的另一个因素是人们在处理视频时会观察到的闪烁，我计划在未来处理这个问题。</p><h1 id="698f" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">参考资料/资源</h1><ol class=""><li id="c155" class="me mf hi jf b jg lw jk lx jo mg js mh jw mi ka mj mk ml mm bi translated"><a class="ae jc" href="https://towardsdatascience.com/deep-learning-for-object-detection-a-comprehensive-review-73930816d8d9" rel="noopener" target="_blank">https://towards data science . com/deep-learning-for-object-detection-a-comprehensive-review-73930816 d8d 9</a></li><li id="c74e" class="me mf hi jf b jg mn jk mo jo mp js mq jw mr ka mj mk ml mm bi translated"><a class="ae jc" href="https://towardsdatascience.com/how-to-train-your-own-object-detector-with-tensorflows-object-detector-api-bec72ecfe1d9" rel="noopener" target="_blank">https://towards data science . com/how-to-train-your-own-object-detector-tensor flows-API-bec 72 ecfe 1d 9</a></li><li id="fc50" class="me mf hi jf b jg mn jk mo jo mp js mq jw mr ka mj mk ml mm bi translated">【https://machinelearningmastery.com/what-is-computer-vision/ T2】号</li><li id="b287" class="me mf hi jf b jg mn jk mo jo mp js mq jw mr ka mj mk ml mm bi translated"><a class="ae jc" href="https://towardsdatascience.com/going-deep-into-object-detection-bed442d92b34" rel="noopener" target="_blank">https://towards data science . com/going-deep-into-object-detection-bed 442d 92 b 34</a></li></ol></div></div>    
</body>
</html>