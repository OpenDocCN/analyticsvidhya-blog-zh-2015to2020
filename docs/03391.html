<html>
<head>
<title>An Introduction to Big Data &amp; ML Pipeline in AWS.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">AWS中的大数据和ML管道介绍。</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/big-data-ml-pipeline-using-aws-533dc9b9d774?source=collection_archive---------5-----------------------#2020-01-29">https://medium.com/analytics-vidhya/big-data-ml-pipeline-using-aws-533dc9b9d774?source=collection_archive---------5-----------------------#2020-01-29</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/abc1d6f364372361c84e028582cd58b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZyVZqzhVK5zOFb7uuKLl2g.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd iu">大数据&amp;使用AWS的ML管道。</strong></figcaption></figure><h2 id="ad19" class="iv iw hi bd iu ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated"><strong class="ak">这个故事代表了AWS中以下项目的简单路径:</strong></h2><ol class=""><li id="acea" class="js jt hi ju b jv jw jx jy jf jz jj ka jn kb kc kd ke kf kg bi translated">为静态和流数据构建大数据管道。</li><li id="4844" class="js jt hi ju b jv kh jx ki jf kj jj kk jn kl kc kd ke kf kg bi translated">使用Hive在Apache Hadoop中处理数据。</li><li id="111a" class="js jt hi ju b jv kh jx ki jf kj jj kk jn kl kc kd ke kf kg bi translated">将处理过的数据加载到Redshift等数据仓库解决方案和MySQL等RDS中。</li><li id="747f" class="js jt hi ju b jv kh jx ki jf kj jj kk jn kl kc kd ke kf kg bi translated">使用像Kinesis Streaming和Kinesis Firehose这样的AWS服务收集流数据。</li><li id="9448" class="js jt hi ju b jv kh jx ki jf kj jj kk jn kl kc kd ke kf kg bi translated">使用Kinesis Analytics对实时流数据进行实时分析。</li><li id="7c7f" class="js jt hi ju b jv kh jx ki jf kj jj kk jn kl kc kd ke kf kg bi translated">使用SageMaker和API构建和部署图像分类器ML模型。</li><li id="f933" class="js jt hi ju b jv kh jx ki jf kj jj kk jn kl kc kd ke kf kg bi translated">使用Flask构建和部署一个实时Web应用程序来推断图像分类器。</li></ol><h1 id="f525" class="km iw hi bd iu kn ko kp ja kq kr ks je kt ku kv ji kw kx ky jm kz la lb jq lc bi translated">内容:</h1><ol class=""><li id="bbab" class="js jt hi ju b jv jw jx jy jf jz jj ka jn kb kc kd ke kf kg bi translated">静态数据收集和预处理流水线。</li><li id="a6d5" class="js jt hi ju b jv kh jx ki jf kj jj kk jn kl kc kd ke kf kg bi translated">流式数据收集和预处理流水线。</li><li id="44d7" class="js jt hi ju b jv kh jx ki jf kj jj kk jn kl kc kd ke kf kg bi translated">构建、部署、监控和推断ML模型。</li></ol><h1 id="6aa0" class="km iw hi bd iu kn ko kp ja kq kr ks je kt ku kv ji kw kx ky jm kz la lb jq lc bi translated">使用的工具/软件:</h1><ol class=""><li id="bfe4" class="js jt hi ju b jv jw jx jy jf jz jj ka jn kb kc kd ke kf kg bi translated">服务— EC2、EMR、Hive、Kinesis数据流、FireHose &amp; Analytics、Lambda、SageMaker、API Gateway、CloudWatch、Jupyter Notebook。</li><li id="c50a" class="js jt hi ju b jv kh jx ki jf kj jj kk jn kl kc kd ke kf kg bi translated">存储— S3、Hdfs、RDS和红移。</li><li id="45a8" class="js jt hi ju b jv kh jx ki jf kj jj kk jn kl kc kd ke kf kg bi translated">语言— FS Shell、HQL、SQL和Python。</li></ol><p id="ba14" class="pw-post-body-paragraph ld le hi ju b jv lf lg lh jx li lj lk jf ll lm ln jj lo lp lq jn lr ls lt kc hb bi translated"><strong class="ju hj">静态数据</strong>是从具有超过10亿条大小大于80 GB的记录的房地美单一家庭贷款级别数据集收集的。EMR和Hive用于收集和预处理数据。处理后的数据然后被加载到S3进行机器学习。除了S3之外，处理后的数据还会加载到SQL和Redshift中，以便用于构建报告和仪表板。</p><p id="bb80" class="pw-post-body-paragraph ld le hi ju b jv lf lg lh jx li lj lk jf ll lm ln jj lo lp lq jn lr ls lt kc hb bi translated"><strong class="ju hj">流数据</strong>从实时数据发生器收集。使用Kinesis数据流消费实时数据。Kinesis数据分析用于使用SQL进行实时数据分析和转换。Lambda用于下一步的数据转换，FireHose用于将最终数据写入S3。类似的管道可以用于服务器日志分析或Twitter分析。</p><p id="f0e3" class="pw-post-body-paragraph ld le hi ju b jv lf lg lh jx li lj lk jf ll lm ln jj lo lp lq jn lr ls lt kc hb bi translated">作为<strong class="ju hj"> ML </strong>的一部分，使用AWS SageMaker训练、构建和部署图像分类器来实时分类图像。还开发了一个前端web应用程序，用于使用Flask从外部AWS进行实时推断。</p><h1 id="5929" class="km iw hi bd iu kn ko kp ja kq kr ks je kt ku kv ji kw kx ky jm kz la lb jq lc bi translated">1.静态数据收集和预处理:</h1><figure class="lv lw lx ly fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lu"><img src="../Images/f5df7e3f72e47e5edef6bf1dc0e095b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ERuj4L1GBvKNUngBzMAeSg.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd iu">从静态源采集、预处理和加载数据。</strong></figcaption></figure><p id="0eb3" class="pw-post-body-paragraph ld le hi ju b jv lf lg lh jx li lj lk jf ll lm ln jj lo lp lq jn lr ls lt kc hb bi translated">在处理80 GB的原始数据时，使用EMR和Hive进行预处理。在EMR中还可以使用Spark对大量数据进行预处理，比Hive快得多。这是因为，Spark使用内存而不是磁盘进行中间处理。预处理步骤可以根据特定的机器学习要求进行修改。</p><figure class="lv lw lx ly fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lz"><img src="../Images/3abf666b799ddb3e072dfe9bb1930991.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hWDonNxJZowYtfJMW33vTw.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd iu"> EMR集群用于处理数据。</strong></figcaption></figure><p id="de6d" class="pw-post-body-paragraph ld le hi ju b jv lf lg lh jx li lj lk jf ll lm ln jj lo lp lq jn lr ls lt kc hb bi translated">收集和预处理静态数据的步骤如下:</p><blockquote class="ma mb mc"><p id="2886" class="ld le md ju b jv lf lg lh jx li lj lk me ll lm ln mf lo lp lq mg lr ls lt kc hb bi translated"><em class="hi">步骤— 1: </em> Web报废房地美数据网站，查找1999年至2017年每一个季度文件的确切位置。所有的文件都被下载并解压到本地电脑。它花了大约60分钟，大小是81 GB。代替EC2或EMR，PC被用来节省一些钱。需要在房地美创建一个帐户来下载数据。</p><p id="7758" class="ld le md ju b jv lf lg lh jx li lj lk me ll lm ln mf lo lp lq mg lr ls lt kc hb bi translated"><em class="hi">第二步:</em>生吃。然后，从本地PC使用AWS CLI命令将txt文件加载到S3。将原始数据传输到S3大约需要60分钟。</p></blockquote><figure class="lv lw lx ly fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mh"><img src="../Images/d410a140b605a6c1423d356dfc3150c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q_c0pS0SoU3wuPx-bHBgJw.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd iu">本地PC向S3传输数据。</strong></figcaption></figure><blockquote class="ma mb mc"><p id="258e" class="ld le md ju b jv lf lg lh jx li lj lk me ll lm ln mf lo lp lq mg lr ls lt kc hb bi translated"><em class="hi">步骤— 3: </em>在Hive中使用S3作为文件位置创建原始文件和已处理文件的外部表。创建外部表是为了即使在删除表后也能保留数据。使用位置参数，因为原始数据已经在S3，而处理后的数据需要移动到S3进行机器学习。</p><p id="7d02" class="ld le md ju b jv lf lg lh jx li lj lk me ll lm ln mf lo lp lq mg lr ls lt kc hb bi translated"><em class="hi">步骤— 4: </em>对采集数据进行数据转换等预处理。将2500万条记录加载到以S3为数据位置的已处理采集表需要大约140秒。原始和处理后的采集文件大小分别为3.7和3.8 GB。</p><p id="b67b" class="ld le md ju b jv lf lg lh jx li lj lk me ll lm ln mf lo lp lq mg lr ls lt kc hb bi translated">作为快速Hive查询的一种优化技术，采集数据也每年加载到一个分区表中。</p></blockquote><figure class="lv lw lx ly fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mi"><img src="../Images/b83221e5ab719993913e32ccbf81945c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8-0QoUHiEXtBd5fLdUe8kw.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd iu">将数据加载到分区表。</strong></figcaption></figure><blockquote class="ma mb mc"><p id="234e" class="ld le md ju b jv lf lg lh jx li lj lk me ll lm ln mf lo lp lq mg lr ls lt kc hb bi translated">在性能数据上，执行数据转换和排序等预处理。将13亿条记录加载到已处理的性能表需要大约3.5小时。原始和处理后的采集文件大小为78和140 GB。其他预处理步骤可以用于特定的用例。</p></blockquote><figure class="lv lw lx ly fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mj"><img src="../Images/9f343d7b08736761f3ca75ef03533e70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WzmkIJo56aQJLEqn8nGE9w.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd iu">将已处理的数据加载到配置单元。</strong></figcaption></figure><blockquote class="ma mb mc"><p id="ad43" class="ld le md ju b jv lf lg lh jx li lj lk me ll lm ln mf lo lp lq mg lr ls lt kc hb bi translated"><em class="hi">第5步:</em>在AWS RDS中创建MySQL表，并使用EMR Linux中的Sqoop从S3加载数据。传输具有2500万行的3.7 GB的已处理采集数据大约需要723秒。由于空格同时作为行结束符和字段值出现，所以很少出现错误。数据格式化后加载成功。</p></blockquote><figure class="lv lw lx ly fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mk"><img src="../Images/593ef744adfd814e990d26c1704df4b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cQGph-HXeHbsbMH7EpkzyQ.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd iu">加载采集数据后的SQL记录计数。</strong></figcaption></figure><blockquote class="ma mb mc"><p id="730f" class="ld le md ju b jv lf lg lh jx li lj lk me ll lm ln mf lo lp lq mg lr ls lt kc hb bi translated"><em class="hi">步骤— 6: </em>创建红移表，并使用复制命令将处理后的数据从S3拉入红移。提取140 GB经过性能处理的数据需要大约3个小时。卸载可用于相反的情况。</p></blockquote><figure class="lv lw lx ly fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ml"><img src="../Images/655679c4f0872a8b67ffecdd509e2252.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0j8crzSnNOmzrg_9HfNfzg.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd iu">加载性能数据后的红移记录计数。</strong></figcaption></figure><p id="b2cd" class="pw-post-body-paragraph ld le hi ju b jv lf lg lh jx li lj lk jf ll lm ln jj lo lp lq jn lr ls lt kc hb bi translated">使用的语言有Python，AWS CLI，HQL，SQL，Sqoop <em class="md">。</em> <a class="ae mm" href="https://github.com/abhilash499/Big-Data-ML-Pipeline-using-AWS./tree/master/Static%20Data" rel="noopener ugc nofollow" target="_blank"> <strong class="ju hj"> <em class="md"> Git链接为静态数据。</em> </strong> </a></p><h1 id="ad9a" class="km iw hi bd iu kn ko kp ja kq kr ks je kt ku kv ji kw kx ky jm kz la lb jq lc bi translated">2.流式数据收集和预处理:</h1><figure class="lv lw lx ly fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mn"><img src="../Images/98686a0754a621c8754c859b7d3f1e64.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6es3esBE6welW4Orrd4_Kg.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd iu">采集、预处理和加载来自流媒体源的数据。</strong></figcaption></figure><p id="e898" class="pw-post-body-paragraph ld le hi ju b jv lf lg lh jx li lj lk jf ll lm ln jj lo lp lq jn lr ls lt kc hb bi translated">虚拟数据是从随机用户流URL收集的。AWS Kinesis系列用于采集和预处理流数据。对于任何特定用例，可以使用类似的管道来消耗大量的实时数据。在这里，数据存储到S3进行进一步的ML处理，但也可以将处理后的数据从Firehose发送到RDS、Redshift、DynamoDB和EMR。Firehose还可以直接使用流数据，以避免数据流和分析导致的任何延迟，代价是不将流数据存储到磁盘中。</p><blockquote class="ma mb mc"><p id="8c97" class="ld le md ju b jv lf lg lh jx li lj lk me ll lm ln mf lo lp lq mg lr ls lt kc hb bi translated"><em class="hi">步骤— 1: </em>使用AWS Kinesis控制台创建数据流。使用的碎片数量是一个，因为这里的流数据小于1mb/秒。数据流使用碎片来收集和传输数据。</p><p id="a070" class="ld le md ju b jv lf lg lh jx li lj lk me ll lm ln mf lo lp lq mg lr ls lt kc hb bi translated"><em class="hi">步骤— 2: </em>在本地PC上使用AWS凭证执行的python脚本，从实时流中读取数据并写入数据流。一旦脚本被成功触发，Kinesis数据流将接收从数据流监控控制台验证的记录。在python脚本中，Put_Record与数据记录和分区键一起用于将数据加载到数据流中。</p><p id="8fd0" class="ld le md ju b jv lf lg lh jx li lj lk me ll lm ln mf lo lp lq mg lr ls lt kc hb bi translated"><em class="hi">步骤3: </em> Kinesis Analytics用于从Kinesis数据流中提取数据，使用SQL执行实时查询，并根据需要转换数据。分析能够自动确定输入记录的模式。如果没有，也可以定义自己的模式。</p><p id="b31e" class="ld le md ju b jv lf lg lh jx li lj lk me ll lm ln mf lo lp lq mg lr ls lt kc hb bi translated">改造后，Kinesis Analytics用于创建两个不同的数据流。一个用于SQL查询转换的数据，一个用于错误。这两股不同的水流分别被输送到不同的消防水龙带输送水流，以便进一步输送。</p><p id="3819" class="ld le md ju b jv lf lg lh jx li lj lk me ll lm ln mf lo lp lq mg lr ls lt kc hb bi translated"><em class="hi">步骤— 4: </em>一旦数据被推送到Firehose Delivery-Stream，就会调用Lambda函数(Python脚本)对SQL转换成功的数据执行进一步的数据转换。在这种情况下，每条记录后都会添加一个新的行字符。转换后，Lambda函数将转换后的记录返回给Firehose，以便进一步传输。上一步的失败记录被直接写入S3，供以后处理。</p><p id="0272" class="ld le md ju b jv lf lg lh jx li lj lk me ll lm ln mf lo lp lq mg lr ls lt kc hb bi translated">一旦达到在传送流设置期间定义的特定缓冲区大小，传送流就将处理过的数据加载到S3。任何由Lambda函数记录的转换失败也通过Delivery Stream写入S3。</p></blockquote><p id="dc7c" class="pw-post-body-paragraph ld le hi ju b jv lf lg lh jx li lj lk jf ll lm ln jj lo lp lq jn lr ls lt kc hb bi translated">一旦所有的设置都正确完成，转换后的数据就会到达S3。如果有任何失败记录，无论是在SQL期间还是在Lambda转换期间，都会被写入S3以供进一步处理。</p><p id="e0bc" class="pw-post-body-paragraph ld le hi ju b jv lf lg lh jx li lj lk jf ll lm ln jj lo lp lq jn lr ls lt kc hb bi translated">使用的语言是Python和SQL。所有Kinesis系列设置都是使用AWS控制台完成的。<a class="ae mm" href="https://github.com/abhilash499/Big-Data-ML-Pipeline-using-AWS./tree/master/Stream%20Data" rel="noopener ugc nofollow" target="_blank"> <strong class="ju hj"> <em class="md">流数据的Git链接。</em> </strong> </a></p><h1 id="28d0" class="km iw hi bd iu kn ko kp ja kq kr ks je kt ku kv ji kw kx ky jm kz la lb jq lc bi translated">3.构建、部署、监控和推断ML模型:</h1><figure class="lv lw lx ly fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mo"><img src="../Images/6b3802d722896e8c85e978b980d37f29.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*11ivVIRzIL6PFsczsnXt5Q.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd iu">AWS sage maker中的机器学习生命周期。</strong></figcaption></figure><p id="9cca" class="pw-post-body-paragraph ld le hi ju b jv lf lg lh jx li lj lk jf ll lm ln jj lo lp lq jn lr ls lt kc hb bi translated">作为机器学习的一部分，建立一个图像分类器来分类图像是不是企鹅。从web应用程序实时部署和推断最终模型。</p><blockquote class="ma mb mc"><p id="0e50" class="ld le md ju b jv lf lg lh jx li lj lk me ll lm ln mf lo lp lq mg lr ls lt kc hb bi translated">第一步。原始图像数据从谷歌收集并保存在S3。SageMaker Jupyter Notebook用于执行分析和预处理，如调整大小、格式化、合成更多样本、将数据拆分为训练和验证列表。经过处理后，数据连同。lst文件存储到S3以备将来使用。125幅原始图像被转换成2500个经过处理的样本。</p><p id="cf8f" class="ld le md ju b jv lf lg lh jx li lj lk me ll lm ln mf lo lp lq mg lr ls lt kc hb bi translated">当使用实际图像文件进行训练时，AWS图像分类器算法需要使用实际图像进行训练和验证列表。。lst是一个列表文件，包含实际图像的序列号、标签和位置。请参考AWS文档，了解特定于算法的内置算法i/p和o/p格式。预处理应该在Linux环境中完成。创建的lst文件具有精确的文件夹位置，并以“/”作为文件夹分隔符，将由SageMaker使用，SageMaker也是Linux。</p></blockquote><figure class="lv lw lx ly fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mp"><img src="../Images/22f782f1b1802eb58646db711ccab64e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fb1Xnjpd8kWFd6AbKyUGmw.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd iu">。SageMaker图像分类器的lst文件。</strong></figcaption></figure><blockquote class="ma mb mc"><p id="80f1" class="ld le md ju b jv lf lg lh jx li lj lk me ll lm ln mf lo lp lq mg lr ls lt kc hb bi translated">第二步。一旦训练和验证数据在S3，通过使用SageMaker训练触发训练作业来执行模型训练。触发培训作业时，提供算法ECR详细信息、EC2实例类型、超参数、培训通道和o/p S3位置等参数。</p><p id="1401" class="ld le md ju b jv lf lg lh jx li lj lk me ll lm ln mf lo lp lq mg lr ls lt kc hb bi translated">这里使用的细节是SageMaker内置算法图像分类、GPU实例ml.p2.xlarge、超参数，如类别数、图像维数、训练实例计数等。根据AWS的要求，四个通道(如train、validation、train_lst和validation_lst)定义了精确的S3位置。O/P位置作为一个S3存储桶提供，用于存储最终的模型工件。训练工作花费了大约一个小时来训练和存储大小为6GB的模型工件到S3，训练准确率和验证准确率分别为97%和94%。</p></blockquote><figure class="lv lw lx ly fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mq"><img src="../Images/3f3d877c9602ec8dd986352560975250.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OXNeJ7fx5Sw_5bDG40Q-rQ.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">【SageMaker的培训工作日志。</figcaption></figure><figure class="lv lw lx ly fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mr"><img src="../Images/1665793b6d9b91c1a051ea08f3280840.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Jvcu4ACli_BB8ZcrgZXjtQ.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd iu">保存到S3的模型文物。</strong></figcaption></figure><figure class="lv lw lx ly fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ms"><img src="../Images/64e7411b0a32b6a5cd2c9b192ff4e5e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M5Kwuv2PLbo9mNF3FxD7cA.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd iu">保存在S3的模型。</strong></figcaption></figure><blockquote class="ma mb mc"><p id="046a" class="ld le md ju b jv lf lg lh jx li lj lk me ll lm ln mf lo lp lq mg lr ls lt kc hb bi translated">步骤3:在工件被保存到S3之后，SageMaker推理被用于在线部署。在AWS中部署在线模型需要三个步骤，如模型创建、定义端点配置和端点创建。对于模型创建，提供了诸如用于训练的ECR容器的确切位置和已训练模型工件的S3位置之类的细节。一旦创建了模型，就定义了一个端点配置，该配置包括创建的模型、实例类型和实例数量等细节。这里ml.m4xlarge用于配置。在最后一部分，使用上一步中定义的配置细节创建一个端点。</p><p id="f51a" class="ld le md ju b jv lf lg lh jx li lj lk me ll lm ln mf lo lp lq mg lr ls lt kc hb bi translated">步骤3.1:一旦成功创建，就可以使用“AWS sage maker-runtime invoke-endpoint”从AWS网络内部直接访问端点。o/p是一个json文件，包含对象所属的每个类的概率，如下所示。</p></blockquote><figure class="lv lw lx ly fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mi"><img src="../Images/f5692b3e1003369adb8864b78254049d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3Nc2Nnlfu7aPoks7zRi5Rg.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">从AWS内部调用端点。</figcaption></figure><blockquote class="ma mb mc"><p id="0915" class="ld le md ju b jv lf lg lh jx li lj lk me ll lm ln mf lo lp lq mg lr ls lt kc hb bi translated">步骤3.2:为了从AWS外部访问SageMaker端点，使用了Lambda和API网关。作为Lambda的一部分，定义了一个python脚本，它将接受Base-64编码的字符串，解码为Base-64，创建有效负载，并调用SageMaker端点进行推理。一旦推断出结果，将比较每个类的概率，最终返回企鹅或非企鹅的实际类名。这里最重要的部分是定义lambda的安全角色和访问SageMaker的策略。接下来，用POST方法创建一个Rest API。在创建该方法时，它与先前创建的Lambda函数相集成。一旦方法被创建，API最终被部署，现在可以从任何地方访问它。</p></blockquote><figure class="lv lw lx ly fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mt"><img src="../Images/a1182f78e78ebc22074d5a0a87ea26ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YdiGlPZOai42Kg-vTIiIdg.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">最终API网关。</figcaption></figure><blockquote class="ma mb mc"><p id="d712" class="ld le md ju b jv lf lg lh jx li lj lk me ll lm ln mf lo lp lq mg lr ls lt kc hb bi translated">步骤3.3:为了通过加载图像来访问API，使用Flask开发了一个小的web应用程序。Web应用程序将从用户上传图像，将I/p图像处理为ML模型正在寻找的正确格式，将I/p图像编码为Base-64字符串，调用端点，最后通过解码来自AWS API的json响应来显示结果。</p></blockquote><figure class="lv lw lx ly fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mu"><img src="../Images/a0508bd458e45bd1976e584a0557147e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6bwGJ0hKUpz7qz9xEfr-Bw.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd iu">烧瓶Web App进行最后的推断。</strong></figcaption></figure><p id="b789" class="pw-post-body-paragraph ld le hi ju b jv lf lg lh jx li lj lk jf ll lm ln jj lo lp lq jn lr ls lt kc hb bi translated">使用的语言是Python。所有SageMaker设置都是使用AWS控制台完成的。<a class="ae mm" href="https://github.com/abhilash499/Big-Data-ML-Pipeline-using-AWS./tree/master/Machine%20Learning" rel="noopener ugc nofollow" target="_blank"> <strong class="ju hj"> <em class="md">用于机器学习的Git链接。</em> </strong> </a></p><p id="54c6" class="pw-post-body-paragraph ld le hi ju b jv lf lg lh jx li lj lk jf ll lm ln jj lo lp lq jn lr ls lt kc hb bi translated">请访问Git Hub获取所有必要的脚本。欢迎提问和建议。</p><p id="abcb" class="pw-post-body-paragraph ld le hi ju b jv lf lg lh jx li lj lk jf ll lm ln jj lo lp lq jn lr ls lt kc hb bi translated">这标志着AWS大数据和ML管道介绍的结束。</p><p id="0d4c" class="pw-post-body-paragraph ld le hi ju b jv lf lg lh jx li lj lk jf ll lm ln jj lo lp lq jn lr ls lt kc hb bi translated"><em class="md"> *此处使用的AWS服务将产生费用。</em></p><p id="0444" class="pw-post-body-paragraph ld le hi ju b jv lf lg lh jx li lj lk jf ll lm ln jj lo lp lq jn lr ls lt kc hb bi translated">感谢阅读。欢迎提问和建议。</p><p id="7c58" class="pw-post-body-paragraph ld le hi ju b jv lf lg lh jx li lj lk jf ll lm ln jj lo lp lq jn lr ls lt kc hb bi translated">问候</p><p id="1a98" class="pw-post-body-paragraph ld le hi ju b jv lf lg lh jx li lj lk jf ll lm ln jj lo lp lq jn lr ls lt kc hb bi translated">阿比。</p></div></div>    
</body>
</html>