<html>
<head>
<title>Convolutional Neural Networks Using Numpy — Part 2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Numpy的卷积神经网络—第2部分</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/convolutional-neural-networks-using-numpy-part-2-27bdd34a32a3?source=collection_archive---------14-----------------------#2020-01-09">https://medium.com/analytics-vidhya/convolutional-neural-networks-using-numpy-part-2-27bdd34a32a3?source=collection_archive---------14-----------------------#2020-01-09</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/99b03b81a3934fb28862081bcaee6383.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hII1L9fIarfSCfURnetD1g.png"/></div></div></figure><h1 id="52df" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated"><strong class="ak">动机</strong></h1><p id="541a" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">这篇文章展示了使用numpy实现卷积神经网络(CNN)。我早些时候在<a class="ae km" href="https://blog.lore.ai/convolutional-neural-networks-using-numpy-part-1/" rel="noopener ugc nofollow" target="_blank">写过一篇类似的文章</a>，但那篇文章更侧重于解释什么是卷积，特别是CNN，而在这篇文章中，重点将更多地放在<em class="kn">通过使用矢量化</em>在numpy中有效地实现它们。</p><p id="43db" class="pw-post-body-paragraph jo jp hi jq b jr ko jt ju jv kp jx jy jz kq kb kc kd kr kf kg kh ks kj kk kl hb bi translated">值得指出的是，与tensorflow、pytorch等软件包相比。一般来说，使用numpy在速度上没有任何好处。事实上，如果包括开发时间，它很可能更慢。帖子的想法不是宣传numpy对速度的使用，而是分享作者重建轮子的经验。虽然同样的东西经常被嘲笑，甚至被妖魔化，但只有改造几个轮子，人们才能发明新的机器。更不用说，有时重建车轮只是普通的乐趣！</p><p id="7a89" class="pw-post-body-paragraph jo jp hi jq b jr ko jt ju jv kp jx jy jz kq kb kc kd kr kf kg kh ks kj kk kl hb bi translated">我们将只关注它的CNN部分，其他相关方面如激活函数和maxpooling等将不会在这里讨论，因为它们可以作为作用于CNN层输出的独立层来实现。然而，我们确实讨论了卷积过程固有的填充和步幅。<br/> <br/>这篇文章的代码可以在<a class="ae km" href="https://github.com/borundev/DNN_Lectures" rel="noopener ugc nofollow" target="_blank">资源库</a>中找到，大部分代码包含在文件<a class="ae km" href="https://github.com/borundev/DNN_Lectures/blob/master/Layers/CNN.py" rel="noopener ugc nofollow" target="_blank"> CNN.py </a>中</p><p id="d230" class="pw-post-body-paragraph jo jp hi jq b jr ko jt ju jv kp jx jy jz kq kb kc kd kr kf kg kh ks kj kk kl hb bi translated">因为这篇文章的目标是展示如何在numpy中高效地实现CNN，所以我不会在这篇文章中提供所有代码，而是解释用大量可视化和相关代码来做什么的想法。当然，所有代码都可以在前面提到的存储库中找到。</p><h1 id="02f6" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">卷积神经网络</h1><h2 id="f3d9" class="kt ir hi bd is ku kv kw iw kx ky kz ja jz la lb je kd lc ld ji kh le lf jm lg bi translated">前进传球</h2><p id="fcfd" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">我们将使用多通道处理<strong class="jq hj">二维图像。对于实际图像，单色图像的通道数为1，彩色图像的通道数为3(简称为红/绿/蓝或RGB)。然而，CNN本身可以作用于前一个CNN的输出，然后通道的含义是前一层的不同滤波器的输出，因此通道的数量可以是任何正整数。然而，在下面的<strong class="jq hj">中，我们具体讨论了3个通道，同时将它们着色为RGB，以帮助可视化该过程</strong>。</strong></p><p id="cd5e" class="pw-post-body-paragraph jo jp hi jq b jr ko jt ju jv kp jx jy jz kq kb kc kd kr kf kg kh ks kj kk kl hb bi translated">卷积层具有作为可学习参数的过滤器权重和两个超参数-步幅和填充。这些在下面表示为</p><figure class="li lj lk ll fd ij er es paragraph-image"><div class="er es lh"><img src="../Images/4e8c5a2682d94f10e4a1e26d0122de69.png" data-original-src="https://miro.medium.com/v2/resize:fit:360/format:webp/1*_33jQkzhed1xl98LURsCxA.png"/></div><figcaption class="lm ln et er es lo lp bd b be z dx translated">重量、步幅和衬垫。对于权重，第一和第二索引以及卷积滤波器行和列以及第三和第四索引标识输入和输出通道的滤波器。原则上，对于不同的方向，步幅和填充可以不同，但是为了符号的简单，我们保持它们相同。存储库中的代码更加通用。</figcaption></figure><p id="c9d8" class="pw-post-body-paragraph jo jp hi jq b jr ko jt ju jv kp jx jy jz kq kb kc kd kr kf kg kh ks kj kk kl hb bi translated">它们分别是一个四维张量和两个标量。权重的前两个维度在卷积滤波器的行和列上运行，而第三个维度在输入通道上运行，第四个维度在输出通道上运行。注意，对于图像的每个维度，步幅和填充可以不同，但是为了表示简单，我们在下面保持它们相同(尽管在实际代码中允许不同的值)。</p><p id="e65b" class="pw-post-body-paragraph jo jp hi jq b jr ko jt ju jv kp jx jy jz kq kb kc kd kr kf kg kh ks kj kk kl hb bi translated">我们将卷积层的输入表示为</p><figure class="li lj lk ll fd ij er es paragraph-image"><div class="er es lq"><img src="../Images/0583023e1d0d31c323f0a73bad369d1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:292/format:webp/1*1hoF23mPOhekLPbgOts99Q.png"/></div><figcaption class="lm ln et er es lo lp bd b be z dx translated">CNN的输入。第一个索引是minibatch索引，第二个和第三个是行和列，第四个是通道。</figcaption></figure><p id="2b03" class="pw-post-body-paragraph jo jp hi jq b jr ko jt ju jv kp jx jy jz kq kb kc kd kr kf kg kh ks kj kk kl hb bi translated">其中索引分别是小批次、行、列和通道。输出类似地表示为</p><figure class="li lj lk ll fd ij er es paragraph-image"><div class="er es lr"><img src="../Images/865b3f6c87008110787eb584fbfff27b.png" data-original-src="https://miro.medium.com/v2/resize:fit:240/format:webp/1*3nH6xZ9pjY-uHlnaAJHIuw.png"/></div><figcaption class="lm ln et er es lo lp bd b be z dx translated">CNN的输出。索引与输入的意义相同。</figcaption></figure><p id="c317" class="pw-post-body-paragraph jo jp hi jq b jr ko jt ju jv kp jx jy jz kq kb kc kd kr kf kg kh ks kj kk kl hb bi translated">但是，请注意，除了小批量指数之外，其他指数的范围可能与输入指数的范围不同。这意味着输出图像大小和通道数量可能不同。</p><p id="5d45" class="pw-post-body-paragraph jo jp hi jq b jr ko jt ju jv kp jx jy jz kq kb kc kd kr kf kg kh ks kj kk kl hb bi translated"><strong class="jq hj">填充</strong>的概念来自于将该图像嵌入(可能)更大的0填充数组中</p><figure class="li lj lk ll fd ij er es paragraph-image"><div class="er es ls"><img src="../Images/939120c78dfea0027532fbaf5060517e.png" data-original-src="https://miro.medium.com/v2/resize:fit:692/format:webp/1*oLS69ISOfTsx7oHIkULgUw.png"/></div><figcaption class="lm ln et er es lo lp bd b be z dx translated">输入图像被填充(如果需要)在一个在行和列方向较大的数组中，并且被零填充。</figcaption></figure><p id="c258" class="pw-post-body-paragraph jo jp hi jq b jr ko jt ju jv kp jx jy jz kq kb kc kd kr kf kg kh ks kj kk kl hb bi translated">其中<em class="kn"> 𝑃 </em>是填充。<strong class="jq hj">卷积</strong>运算定义为</p><figure class="li lj lk ll fd ij er es paragraph-image"><div class="er es lt"><img src="../Images/e33c266a058e942fa577f1347b447328.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/format:webp/1*IvP1wxhQ0i3f2E-VOLHBlA.png"/></div><figcaption class="lm ln et er es lo lp bd b be z dx translated">卷积运算。求和指数覆盖卷积滤波器的整个尺寸。</figcaption></figure><p id="47c2" class="pw-post-body-paragraph jo jp hi jq b jr ko jt ju jv kp jx jy jz kq kb kc kd kr kf kg kh ks kj kk kl hb bi translated">其中<em class="kn"> 𝑠 </em>为<strong class="jq hj">步距</strong>。</p><p id="237c" class="pw-post-body-paragraph jo jp hi jq b jr ko jt ju jv kp jx jy jz kq kb kc kd kr kf kg kh ks kj kk kl hb bi translated">为了理解上面的内容，我们通过拍摄一个大小为6×8的“图像”来可视化这个过程，该图像有三个通道，我们在其中顺序地填充值。因此，红色通道的第一行从0到7，第二行从8到15，依此类推，直到第六行上升到47。绿色通道从48开始，以同样的方式填充。</p><figure class="li lj lk ll fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lu"><img src="../Images/63a576dc261650e88018a792a694a157.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9IwLFQX76OPNCijrNI1HRA.png"/></div></div><figcaption class="lm ln et er es lo lp bd b be z dx translated">图像是三维阵列</figcaption></figure><p id="b508" class="pw-post-body-paragraph jo jp hi jq b jr ko jt ju jv kp jx jy jz kq kb kc kd kr kf kg kh ks kj kk kl hb bi translated">在上面我们沿着深度方向绘制了通道。</p><p id="41d3" class="pw-post-body-paragraph jo jp hi jq b jr ko jt ju jv kp jx jy jz kq kb kc kd kr kf kg kh ks kj kk kl hb bi translated">我们制作了一个结构相同但大小不同的“过滤器”。具体来说，我们采用5×3尺寸的过滤器。<em class="kn">请注意，虽然这里有三个滤波器，每个滤波器对应一个输入通道，但这组滤波器只会产生一个输出通道。对于输出的每个通道，我们需要这三个滤波器的单独副本</em>。</p><figure class="li lj lk ll fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lv"><img src="../Images/77e2b843dbf88c5ef928053c6745538a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-JQFvaQiiropYAnmrQ39EA.png"/></div></div><figcaption class="lm ln et er es lo lp bd b be z dx translated">卷积滤波器是一个四维阵列，这里显示的是前三个维度。这三个与图像一起将在卷积上产生单个通道输出。因此，必须对输出的每个通道进行下面详述的操作。这听起来比实际困难，因为numpy矢量化处理了所有这些问题。</figcaption></figure><p id="09b6" class="pw-post-body-paragraph jo jp hi jq b jr ko jt ju jv kp jx jy jz kq kb kc kd kr kf kg kh ks kj kk kl hb bi translated">现在我们考虑红色滤光片对红色通道的影响。在此之前，再看一下上面的卷积表达式，试着理解发生了什么。</p><p id="021e" class="pw-post-body-paragraph jo jp hi jq b jr ko jt ju jv kp jx jy jz kq kb kc kd kr kf kg kh ks kj kk kl hb bi translated">在下图的例子中，我们在y方向上采用了2的<strong class="jq hj">填充</strong>,在x方向上采用了1的填充。这意味着原始图像嵌入在一个0填充的数组的中心，该数组在y方向上大4倍，在x方向上大2倍。这确保了卷积的输出与输入大小相同(在没有步幅的情况下)，但我们不必这样做。填充可大可小。</p><figure class="li lj lk ll fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lw"><img src="../Images/a3c008a31be65f13cd0bbf23c9cb9612.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mRAqAI9EV7Ur8EikWqLa_Q.png"/></div></div><figcaption class="lm ln et er es lo lp bd b be z dx translated">补零的原始红色通道与红色通道滤镜的卷积。敦促读者验证一些结果，以确保他们理解什么是卷积运算。</figcaption></figure><p id="a4d5" class="pw-post-body-paragraph jo jp hi jq b jr ko jt ju jv kp jx jy jz kq kb kc kd kr kf kg kh ks kj kk kl hb bi translated">现在，看看红色滤镜对(较大的嵌入)图像部分的卷积效果，该图像位于从(4，3)开始的框中，大小与用纯蓝绘制的滤镜相同。窗口的每个元素乘以滤波器的相应元素，然后将结果相加。请注意，这涉及一行用零填充的值。这个和是红色通道卷积的第(4，3)个元素。如果我们没有零填充，我们甚至不能有这个条目，并且输出将被限制为来自完全适合原始(非零填充)图像的卷积滤波器的那些值。</p><p id="6fc8" class="pw-post-body-paragraph jo jp hi jq b jr ko jt ju jv kp jx jy jz kq kb kc kd kr kf kg kh ks kj kk kl hb bi translated">让我们也来看看<strong class="jq hj">大步走</strong>。步幅的影响可以从理论表达式中看出。默认步幅为1，其结果如上所示。然而，例如，如果我们选择步幅为2，那么所使用的窗口将类似于蓝色虚线窗口，我们看到它们以步长2移动。</p><p id="e0e0" class="pw-post-body-paragraph jo jp hi jq b jr ko jt ju jv kp jx jy jz kq kb kc kd kr kf kg kh ks kj kk kl hb bi translated">三个通道的<em class="kn">一个滤波器</em>的最终输出通过对三个通道的卷积求和给出，如下所示。</p><figure class="li lj lk ll fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/3dcbae06fc2f35c344b672283ecd1482.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZKJTtPSD9_F79koSYczRww.png"/></div></div><figcaption class="lm ln et er es lo lp bd b be z dx translated">通过对每个输入通道的卷积值求和，产生最终输出。再次注意，这是单个输出通道上的输出。其他信道的输出使用相应的卷积权重组类似地产生。</figcaption></figure><h2 id="d06f" class="kt ir hi bd is ku kv kw iw kx ky kz ja jz la lb je kd lc ld ji kh le lf jm lg bi translated">反向传播</h2><p id="02d3" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">在反向传播期间，层<strong class="jq hj">接收损耗相对于正向传递输出的导数作为输入</strong>，并且<strong class="jq hj">输出损耗相对于正向传递输入的导数</strong>。如果权重是可学习的，则在反向传播期间，该层还根据权重更新规则调整权重。为了<strong class="jq hj">权重更新</strong>，需要损失相对于权重的导数。(<em class="kn">注意，我们隐含地只考虑依赖于损失的一阶导数的更新，但是讨论可以直接推广到使用高阶导数计算动量等的更新方法。)</em> <br/> <em class="kn"> <br/> </em>损失相对于权重的导数(熟悉微积分的人可以容易地导出)由下式给出</p><figure class="li lj lk ll fd ij er es paragraph-image"><div class="er es lx"><img src="../Images/16b3164644dcc7216bb29f980eba4d31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1212/format:webp/1*m1o27nxON2GqaW8yxe4P_A.png"/></div><figcaption class="lm ln et er es lo lp bd b be z dx translated">从损耗相对于输出的偏导数获得损耗相对于滤波器的偏导数。</figcaption></figure><p id="6c47" class="pw-post-body-paragraph jo jp hi jq b jr ko jt ju jv kp jx jy jz kq kb kc kd kr kf kg kh ks kj kk kl hb bi translated">损耗相对于输入的导数由下式给出</p><figure class="li lj lk ll fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ly"><img src="../Images/c41af1fc13d36a20975093f43b179031.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WHWWU-2p_eJUFu_iLEpsUQ.png"/></div></div><figcaption class="lm ln et er es lo lp bd b be z dx translated">从损耗相对于输出的偏导数获得损耗相对于输入的偏导数。</figcaption></figure><p id="b302" class="pw-post-body-paragraph jo jp hi jq b jr ko jt ju jv kp jx jy jz kq kb kc kd kr kf kg kh ks kj kk kl hb bi translated">在哪里</p><figure class="li lj lk ll fd ij er es paragraph-image"><div class="er es lz"><img src="../Images/5cac56d439db97ed20d72550d1acfca6.png" data-original-src="https://miro.medium.com/v2/resize:fit:880/format:webp/1*cUL6xLC2n3X-CGiBni75BA.png"/></div></figure><p id="0837" class="pw-post-body-paragraph jo jp hi jq b jr ko jt ju jv kp jx jy jz kq kb kc kd kr kf kg kh ks kj kk kl hb bi translated">并且<em class="kn"> 𝐾 </em>是过滤器尺寸。所有这些都可以用简单的代数和微积分的链式法则来计算。</p><p id="a89b" class="pw-post-body-paragraph jo jp hi jq b jr ko jt ju jv kp jx jy jz kq kb kc kd kr kf kg kh ks kj kk kl hb bi translated">并且<em class="kn"> 𝐾 </em>是过滤器尺寸。所有这些都可以用简单的代数和微积分的链式法则来计算。</p><p id="fb97" class="pw-post-body-paragraph jo jp hi jq b jr ko jt ju jv kp jx jy jz kq kb kc kd kr kf kg kh ks kj kk kl hb bi translated">我们观察到，损耗相对于输入层的导数仅仅是误差相对于损耗相对于输出的导数的卷积，其中滤波器具有沿前两个方向相反的折射率。</p><p id="c087" class="pw-post-body-paragraph jo jp hi jq b jr ko jt ju jv kp jx jy jz kq kb kc kd kr kf kg kh ks kj kk kl hb bi translated">这一观察告诉我们，我们可以重复使用卷积代码，但在此之前，我们仍需要处理包含损耗对输出的导数的数组。我们可以首先将关于输出的错误嵌入到一个数组中</p><figure class="li lj lk ll fd ij er es paragraph-image"><div class="er es ma"><img src="../Images/740cfa20f24c113c532a7e74a46a88ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:888/format:webp/1*K0wqTbSeY5u-9s2falJKJg.png"/></div><figcaption class="lm ln et er es lo lp bd b be z dx translated">零填充损耗相对于输出的导数</figcaption></figure><p id="cd05" class="pw-post-body-paragraph jo jp hi jq b jr ko jt ju jv kp jx jy jz kq kb kc kd kr kf kg kh ks kj kk kl hb bi translated">根据<em class="kn">𝑃</em>—<em class="kn">𝐾</em>+1的符号，z的一部分被嵌入到右零填充的数组y中，或者z被嵌入到左零填充和右零填充的数组y中。这种推理不容易解释，我必须做的是仔细考虑填充大小的所有可能性，并找出正确的逻辑。当然，填充大小超过过滤器大小的一半似乎是不合理的，但是必须解决逻辑问题，以确保代码不会中断。如果读者找到一个简单的解释，我会很高兴收到同样的解释并更新这篇文章。这部分的代码如下。</p><pre class="li lj lk ll fd mb mc md me aw mf bi"><span id="2862" class="kt ir hi mc b fi mg mh l mi mj">def _prepare_back(self,der_y):<br/>    mb, n1, n2, _ = self.prev_layer.shape<br/>    ch = der_y.shape[3]<br/><br/>    m1 = max(self.stride_1 * der_y.shape[1], n1)<br/>    m2 = max(self.stride_2 * der_y.shape[2], n2)<br/><br/>    z = np.zeros(shape=(mb, m1, m2, ch))<br/>    y = np.zeros(shape=(<br/>    mb, m1 + self.filter_size_1 - 1, m2 + self.filter_size_2 - 1, ch))<br/><br/>    z[:,<br/>    :self.stride_1 * der_y.shape[1]:self.stride_1,<br/>    :self.stride_2 * der_y.shape[2]:self.stride_2<br/>    ] = der_y<br/><br/>    p1_left = self.padding_1 + 1 - self.filter_size_1<br/>    p2_left = self.padding_2 + 1 - self.filter_size_2<br/><br/>    # i1,i2 are the start positions in z and iy1,iy2 are the start<br/>    # positions in y<br/>    i1 = i2 = iy1 = iy2 = 0<br/><br/>    if p1_left &gt; 0:<br/>        i1 = p1_left<br/>    else:<br/>        iy1 = -p1_left<br/><br/>    if p2_left &gt; 0:<br/>        i2 = p2_left<br/>    else:<br/>        iy2 = -p2_left<br/><br/>    # size of array taken from x<br/>    f1 = z.shape[1] - i1<br/>    f2 = z.shape[2] - i2<br/><br/>    y[:,<br/>    iy1:iy1 + f1,<br/>    iy2:iy2 + f2<br/>    ] = z[:, i1:, i2:, :]<br/>    return y</span></pre><p id="d8e7" class="pw-post-body-paragraph jo jp hi jq b jr ko jt ju jv kp jx jy jz kq kb kc kd kr kf kg kh ks kj kk kl hb bi translated">最后，我们有</p><figure class="li lj lk ll fd ij er es paragraph-image"><div class="er es mk"><img src="../Images/ca33a79163dda5d1488f188595eff2e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1124/format:webp/1*cB8ips43BwzqpR_YLZa-AQ.png"/></div></figure><p id="0430" class="pw-post-body-paragraph jo jp hi jq b jr ko jt ju jv kp jx jy jz kq kb kc kd kr kf kg kh ks kj kk kl hb bi translated">这只是一个简单的卷积。</p><h1 id="41db" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">一种高效的数字实现</h1><p id="b468" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">这一切都很好，但以上述方式天真地实施，过程非常缓慢。这是因为有几个循环:</p><p id="59dc" class="pw-post-body-paragraph jo jp hi jq b jr ko jt ju jv kp jx jy jz kq kb kc kd kr kf kg kh ks kj kk kl hb bi translated">(I)在整个声道上移动声道特定滤波器(实际卷积)，<br/> (ii)在输入声道上循环，<br/> (iii)在输出声道上循环。<br/>(四)在迷你吧上循环</p><p id="5c55" class="pw-post-body-paragraph jo jp hi jq b jr ko jt ju jv kp jx jy jz kq kb kc kd kr kf kg kh ks kj kk kl hb bi translated">如果实现巧妙，代码不仅可以使用numpy矢量化，还可以使用已经编写好的密集层(您可以在上面提到的库中找到实现)。在思考如何做到这一点时，我看到了西尔万·格鲁格的一个帖子，他做了一些类似的事情，我的想法也受到了同样的启发。但是，有两个不同之处:</p><p id="8534" class="pw-post-body-paragraph jo jp hi jq b jr ko jt ju jv kp jx jy jz kq kb kc kd kr kf kg kh ks kj kk kl hb bi translated">(I)对于他的分析，通道索引是第二个，紧接在minibatch之后，标准图像格式将其作为最后一个，这就是我实现代码的方式</p><p id="ff51" class="pw-post-body-paragraph jo jp hi jq b jr ko jt ju jv kp jx jy jz kq kb kc kd kr kf kg kh ks kj kk kl hb bi translated">(ii)我对反向传播的实现是不同的。老实说，我不能跟随他的实现，我(显然)认为我的更干净，但他可能不同意。我将让读者自己决定哪个更好。</p><p id="5725" class="pw-post-body-paragraph jo jp hi jq b jr ko jt ju jv kp jx jy jz kq kb kc kd kr kf kg kh ks kj kk kl hb bi translated">让我们再来看看卷积的表达式</p><figure class="li lj lk ll fd ij er es paragraph-image"><div class="er es ml"><img src="../Images/8aacccc69cf99f5466c2f59c75209681.png" data-original-src="https://miro.medium.com/v2/resize:fit:1160/format:webp/1*zrHqUcnQYASDs5mHkETmvA.png"/></div></figure><p id="d781" class="pw-post-body-paragraph jo jp hi jq b jr ko jt ju jv kp jx jy jz kq kb kc kd kr kf kg kh ks kj kk kl hb bi translated">我们看到可以将滤镜<em class="kn">的指标<em class="kn"> 𝛼 </em>、<em class="kn"> 𝛽 </em>、<em class="kn">𝑘</em>𝑊</em>折叠成一个指标<em class="kn">𝜇</em>=<em class="kn">𝛼</em>∫<em class="kn">𝑓</em>2∫<em class="kn">𝑐</em>+<em class="kn">t22∫<em class="kn">在numpy中，这可以简单地通过</em></em></p><pre class="li lj lk ll fd mb mc md me aw mf bi"><span id="d481" class="kt ir hi mc b fi mg mh l mi mj">W.reshape(-1,W.shape[-1])</span></pre><p id="ca61" class="pw-post-body-paragraph jo jp hi jq b jr ko jt ju jv kp jx jy jz kq kb kc kd kr kf kg kh ks kj kk kl hb bi translated">我们需要相应地建立一个新的张量，它的元素要乘以整形后的𝑊的元素。可以肯定的是，这是一个复杂的过程，输出会有冗余，但它将允许加速，更重要的是，看看表达式</p><figure class="li lj lk ll fd ij er es paragraph-image"><div class="er es mm"><img src="../Images/703b3333d1d7c8181c7876ca5b338700.png" data-original-src="https://miro.medium.com/v2/resize:fit:836/format:webp/1*U1kbYImU7Xv7yCZSzLOyYg.png"/></div></figure><p id="140b" class="pw-post-body-paragraph jo jp hi jq b jr ko jt ju jv kp jx jy jz kq kb kc kd kr kf kg kh ks kj kk kl hb bi translated">我们看到，它现在只是一个密集层，我们可以使用相同的前向传递和反向传播过程中的权重更新。寻找损失相对于<em class="kn"> 𝑙 </em> 0的导数的反向传播是我们将很快解决的事情。</p><p id="0730" class="pw-post-body-paragraph jo jp hi jq b jr ko jt ju jv kp jx jy jz kq kb kc kd kr kf kg kh ks kj kk kl hb bi translated">从" tilde l0 "(我希望medium允许MathJax)获取" bar l0 "的过程非常简单，下面给出的代码很好地解释了这一过程。然而，让我们首先想象正在发生什么。</p><figure class="li lj lk ll fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/b30b518754a8056443f655869f81ab5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1a2Y8wEYQ6ghdbmSOMPPcA.png"/></div></div></figure><p id="5f02" class="pw-post-body-paragraph jo jp hi jq b jr ko jt ju jv kp jx jy jz kq kb kc kd kr kf kg kh ks kj kk kl hb bi translated">在上面的图像中，转换的原始图像由重新排列的零填充图像的元素组成(带有副本),因此每个面板(面板在深度方向上布局)包含所有要乘以卷积滤波器的一个元素的元素。卷积滤镜本身在深度方向上是散开的(在上面的图像中我们称之为扁平滤镜)。这两者乘积如下所示。</p><figure class="li lj lk ll fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/f4d6d7eb4734a476ea8e7095c08ff32f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CdXpHVAZFAE5KM1qEytitw.png"/></div></div></figure><p id="5f7a" class="pw-post-body-paragraph jo jp hi jq b jr ko jt ju jv kp jx jy jz kq kb kc kd kr kf kg kh ks kj kk kl hb bi translated">再次显示转换图像和平坦化滤波器的乘积，然后我们显示所有这些面板的总和。人们可以证实结果是相同的。</p><p id="7903" class="pw-post-body-paragraph jo jp hi jq b jr ko jt ju jv kp jx jy jz kq kb kc kd kr kf kg kh ks kj kk kl hb bi translated">下面给出了从零填充图像获得上述变换图像的代码，这是本文的要点。同样，代码是CNN层的一部分，因此引用了“自我”,但是意思应该很清楚。</p><pre class="li lj lk ll fd mb mc md me aw mf bi"><span id="7b0e" class="kt ir hi mc b fi mg mh l mi mj">def _take(self, y, stride=(1, 1)):</span><span id="ca2e" class="kt ir hi mc b fi mn mh l mi mj">    stride_1, stride_2 = stride<br/>    mb, en1, en2, ch = y.shape</span><span id="b3e7" class="kt ir hi mc b fi mn mh l mi mj">    # Till we discuss the minibatch index, all comments are for the first<br/>    # image</span><span id="e02d" class="kt ir hi mc b fi mn mh l mi mj">    # Make a 2d array of indices of the top-left edges of the windows<br/>    # from which to take elements. These are to be the indices on the<br/>    # first channel. This makes the indices the top-left-back end of the<br/>    # cuboid to be taken<br/>    s1 = np.arange(0, en1 - self.filter_size_1 + 1, stride_1)<br/>    s2 = np.arange(0, en2 - self.filter_size_2 + 1, stride_2)<br/>    start_idx = (s1[:, None] * en2 * ch + s2[None, :] * ch)</span><span id="cbc5" class="kt ir hi mc b fi mn mh l mi mj">    # Make a grid of elements to be taken in the entire cuboid whose<br/>    # top-left-back indices we have taken above. This is done only for<br/>    # the first of the above cuboids in mind.<br/>    # Note the cuboid elements are flattened and will now be along the<br/>    # 4th direction of the output<br/>    g1 = np.arange(self.filter_size_1)<br/>    g2 = np.arange(self.filter_size_2)<br/>    g3 = np.arange(ch)<br/>    grid = (g1[:, None, None] * en2 * ch + g2[None, :, None] *<br/>            ch + g3[None, None, :]).ravel()</span><span id="4d2c" class="kt ir hi mc b fi mn mh l mi mj">    # Combine the above two to make a 3d array which corresponds to just<br/>    # the first image in a minibatch.<br/>    grid_to_take = start_idx[:, :, None] + grid[None, None, :]</span><span id="e552" class="kt ir hi mc b fi mn mh l mi mj">    # Make and index for the starting entry in every image in a minibatch<br/>    batch = np.array(range(0, mb)) * ch * en1 * en2</span><span id="69be" class="kt ir hi mc b fi mn mh l mi mj">    # This is the final result<br/>    res = y.take(batch[:, None, None, None] + grid_to_take[None, :, :, :])<br/>    return res</span></pre><p id="4fba" class="pw-post-body-paragraph jo jp hi jq b jr ko jt ju jv kp jx jy jz kq kb kc kd kr kf kg kh ks kj kk kl hb bi translated">相同的代码可用于损失相对于输出的准备好的导数(见上面的代码),以给出相应的变换版本来执行反向传播的卷积。</p><p id="15e8" class="pw-post-body-paragraph jo jp hi jq b jr ko jt ju jv kp jx jy jz kq kb kc kd kr kf kg kh ks kj kk kl hb bi translated">剩下的代码非常简单，可以在本文开头提到的资源库中找到。</p></div></div>    
</body>
</html>