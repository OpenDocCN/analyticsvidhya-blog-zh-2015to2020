<html>
<head>
<title>Training Deep Neural Networks on a GPU with PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用PyTorch在GPU上训练深度神经网络</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/training-deep-neural-networks-on-a-gpu-with-pytorch-2851ccfb6066?source=collection_archive---------4-----------------------#2020-08-19">https://medium.com/analytics-vidhya/training-deep-neural-networks-on-a-gpu-with-pytorch-2851ccfb6066?source=collection_archive---------4-----------------------#2020-08-19</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="f2bc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd"> MNIST使用前馈神经网络</em></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="ab fe cl jj"><img src="../Images/24cb3033ab1500eee98bbcad80b664da.png" data-original-src="https://miro.medium.com/v2/0*s_pUUEjXuAL8KTtH"/></div><figcaption class="jm jn et er es jo jp bd b be z dx translated"><a class="ae jq" href="https://www.risk.net/investing/7182261/credit-suisse-uses-neural-nets-to-call-minute-ahead-forex" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure></div><div class="ab cl jr js gp jt" role="separator"><span class="ju bw bk jv jw jx"/><span class="ju bw bk jv jw jx"/><span class="ju bw bk jv jw"/></div><div class="hb hc hd he hf"><p id="b975" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在我之前的帖子中，我们已经讨论过了</p><ol class=""><li id="ec38" class="jy jz hi ih b ii ij im in iq ka iu kb iy kc jc kd ke kf kg bi translated"><a class="ae jq" rel="noopener" href="/analytics-vidhya/deep-learning-artificial-neural-network-ann-13b54c3f370f?source=your_stories_page---------------------------">深度学习——人工神经网络</a></li><li id="aa42" class="jy jz hi ih b ii kh im ki iq kj iu kk iy kl jc kd ke kf kg bi translated"><a class="ae jq" rel="noopener" href="/@arun.purakkatt/tensors-basics-of-pytorch-programming-5de82ea45ebf?source=your_stories_page---------------------------">张量PyTorch编程基础</a></li><li id="fa51" class="jy jz hi ih b ii kh im ki iq kj iu kk iy kl jc kd ke kf kg bi translated"><a class="ae jq" rel="noopener" href="/analytics-vidhya/linear-regression-with-pytorch-147fed55f138">使用PyTorch进行线性回归</a></li><li id="1b32" class="jy jz hi ih b ii kh im ki iq kj iu kk iy kl jc kd ke kf kg bi translated">【PyTorch图像分类<em class="jd"> —逻辑回归</em> </li></ol><p id="394a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">让我们尝试通过在MNIST数据集上使用前馈神经网络。</em></p><p id="0f8d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jd">第一步:导入库&amp;探索数据</em>和数据准备</strong></p><p id="d8e7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">随着必要的库的导入和数据作为pytorch张量的加载，MNIST数据集包含60000个标记图像。数据被随机分成分别具有50000和10000的训练集和验证集。</p><pre class="je jf jg jh fd km kn ko kp aw kq bi"><span id="55ee" class="kr ks hi kn b fi kt ku l kv kw">val_size = 10000<br/>train_size = len(dataset) - val_size<br/><br/>train_ds, val_ds = random_split(dataset, [train_size, val_size])<br/>len(train_ds), len(val_ds)</span></pre><p id="7567" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们正在创建数据加载器，它允许我们批量加载数据，特别是当您有大型数据集时，它将不适合用于训练的内存。因此我们使用数据加载器。这里我们使用的批量是128。我们如何决定批量大小？通常，您可以尝试不同的批量大小，如128，256，512..直到你的GPU/内存适合它，处理得更快。当它慢下来的时候，你可以把批量减少一步。</p><p id="871c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在train_loader中，我们使用shuffle = True，因为它为数据pin_memory提供了随机化—如果为True，数据加载器将在返回张量之前将其复制到CUDA固定内存中。num_workers —用于数据加载的子流程数量。它致力于并行化。</p><p id="f13a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">试着看看文档:<a class="ae jq" href="https://pytorch.org/docs/stable/data.html" rel="noopener ugc nofollow" target="_blank">https://pytorch.org/docs/stable/data.html</a></p><pre class="je jf jg jh fd km kn ko kp aw kq bi"><span id="8b43" class="kr ks hi kn b fi kt ku l kv kw">batch_size=128<br/>train_loader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)<br/>val_loader = DataLoader(val_ds, batch_size*2, num_workers=4, pin_memory=True)</span></pre><p id="c801" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们使用来自<code class="du kx ky kz kn b">torchvision</code>的<code class="du kx ky kz kn b">make_grid</code>函数在网格中可视化一批数据。我们还将使用张量上的<code class="du kx ky kz kn b">.permute</code>方法将通道移动到最后一个维度，正如<code class="du kx ky kz kn b">matplotlib</code>所预期的。每批有128个图像，其中1个通道作为其灰度图像，28×28像素大小，换句话说28行和28列。如果它是一个彩色图像通道，即RGB将是3。</p><pre class="je jf jg jh fd km kn ko kp aw kq bi"><span id="0c55" class="kr ks hi kn b fi kt ku l kv kw">for images, _ in train_loader:<br/>    print('images.shape:', images.shape)<br/>    plt.figure(figsize=(16,8))<br/>    plt.axis('off')<br/>    plt.imshow(make_grid(images, nrow=16).permute((1, 2, 0)))<br/>    break</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es la"><img src="../Images/d4c4ceeb4e015f7098af543d2c9d906f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GHkBJu-nUU32l8184VoBjw.png"/></div></div><figcaption class="jm jn et er es jo jp bd b be z dx translated">图像。形状:火炬。大小([128，1，28，28])</figcaption></figure><p id="fe31" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jd">第二步:模型准备</em> </strong></p><p id="f78e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是我们模型的样子。我们正在创建一个只有一个隐藏层的神经网络。结构将像输入层，隐藏层，输出层。让我们详细了解每一层。</p><p id="79c5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">输入层</em> —这里我们有28x28大小，而我们使用128的批量大小，我们将得到28x28作为输入矩阵。</p><p id="710e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">隐藏层— </em>第一层(也称为隐藏层)将把形状<code class="du kx ky kz kn b">batch_size x 784</code>的输入矩阵转换成形状<code class="du kx ky kz kn b">batch_size x hidden_size</code>的中间输出矩阵，其中<code class="du kx ky kz kn b">hidden_size</code>是一个预先配置的参数(通常如32或64)。</p><p id="0cf7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后，中间输出被传递到非线性<em class="jd">激活函数</em>，该函数对输出矩阵的单个元素进行操作。</p><p id="c3cb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">输出层— </em>激活函数的结果，也是大小为<code class="du kx ky kz kn b">batch_size x hidden_size</code>的，被传递到第二层(也称为输出层)，该层将其转换成大小为<code class="du kx ky kz kn b">batch_size x 10</code>的矩阵</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lf"><img src="../Images/8c25f9a6051f591d39c4181cda3de651.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y2ANRPU134VcL5x-PgcgfQ.png"/></div><figcaption class="jm jn et er es jo jp bd b be z dx translated"><a class="ae jq" href="https://jovian.ml/aakashns/04-feedforward-nn" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="782b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jd">什么是激活功能&amp; ReLu？</em> </strong></p><p id="5004" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">激活函数通过计算加权和并进一步加上偏差来决定是否激活一个神经元。激活函数的目的是将非线性引入神经元的输出。</p><p id="0251" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">ReLu:校正的线性单位，relu(x) = max(0，x)即，如果一个元素是负的，我们用0代替它，否则我们保持它不变。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es lg"><img src="../Images/b15af05ee59e483866d248b638fa4918.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*_7z3MSwSlrvYuOf_.png"/></div></div><figcaption class="jm jn et er es jo jp bd b be z dx translated">激活功能(<a class="ae jq" href="https://towardsdatascience.com/complete-guide-of-activation-functions-34076e95d044" rel="noopener" target="_blank">源</a>)</figcaption></figure><p id="8add" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jd">我们为什么要使用隐藏层和激活功能？</em> </strong></p><p id="6c4a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这允许我们的模型学习输入和目标之间更复杂、多层和非线性的关系。</p><p id="dc7c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将Mnistmodel类定义如下。我们有__init__接受in_size，hidden_size，out_size。我们有一个隐藏层和输出层。这是我们的构造函数。</p><p id="618e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在正向函数中，我们获取一批图像xb，即128x1x28x28，然后将其展平，因为我们的线性层需要一个二维矢量。然后我们使用隐藏层得到中间输出，在它上面我们应用激活函数。即我们简单地用零代替负数。然后，ReLu的输出被传递到输出层。因此，在每个图像的输出中，我们有10个输出。</p><p id="e7c1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在training_step函数中，我们使用交叉熵生成预测并计算损失。cross_entropy去掉了数据的实际标签，并将返回loss。</p><p id="ce67" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在validation_step中，我们获取一批图像、标签并将其传递到模型中，生成预测、计算损失并计算准确度。</p><p id="b17f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在validation_epoch_end中，我们计算损失、epoch_loss、batch _ losses。batch_accs epoch_acc被堆叠并取平均值。</p><p id="1424" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在epoch_end中val_loss和val_acc被返回。</p><pre class="je jf jg jh fd km kn ko kp aw kq bi"><span id="45a1" class="kr ks hi kn b fi kt ku l kv kw">class MnistModel(nn.Module):<br/>    """Feedfoward neural network with 1 hidden layer"""<br/>    def __init__(self, in_size, hidden_size, out_size):<br/>        super().__init__()<br/>        # hidden layer<br/>        self.linear1 = nn.Linear(in_size, hidden_size)<br/>        # output layer<br/>        self.linear2 = nn.Linear(hidden_size, out_size)<br/>        <br/>    def forward(self, xb):<br/>        # Flatten the image tensors<br/>        xb = xb.view(xb.size(0), -1)<br/>        # Get intermediate outputs using hidden layer<br/>        out = self.linear1(xb)<br/>        # Apply activation function<br/>        out = F.relu(out)<br/>        # Get predictions using output layer<br/>        out = self.linear2(out)<br/>        return out<br/>    <br/>    def training_step(self, batch):<br/>        images, labels = batch <br/>        out = self(images)                  # Generate predictions<br/>        loss = F.cross_entropy(out, labels) # Calculate loss<br/>        return loss<br/>    <br/>    def validation_step(self, batch):<br/>        images, labels = batch <br/>        out = self(images)                    # Generate predictions<br/>        loss = F.cross_entropy(out, labels)   # Calculate loss<br/>        acc = accuracy(out, labels)           # Calculate accuracy<br/>        return {'val_loss': loss, 'val_acc': acc}<br/>        <br/>    def validation_epoch_end(self, outputs):<br/>        batch_losses = [x['val_loss'] for x in outputs]<br/>        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses<br/>        batch_accs = [x['val_acc'] for x in outputs]<br/>        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies<br/>        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}<br/>    <br/>    def epoch_end(self, epoch, result):<br/>        print("Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}".format(epoch, result['val_loss'], result['val_acc']))</span></pre><p id="abac" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们正在创建隐藏尺寸层32的模型，我们可以改变这一点。可以添加更多的隐藏层。每个隐藏层从我们的数据中学习一些东西，并试图建立输入和目标之间的关系。这里，我们的输入大小为784，隐藏大小为32，输出大小或num_classes为10。模型参数会给你权重和偏差。</p><pre class="je jf jg jh fd km kn ko kp aw kq bi"><span id="0188" class="kr ks hi kn b fi kt ku l kv kw">input_size = 784<br/>hidden_size = 32 # you can change this<br/>num_classes = 10</span><span id="e85a" class="kr ks hi kn b fi lh ku l kv kw">model = MnistModel(input_size, hidden_size=32, out_size=num_classes)</span><span id="7137" class="kr ks hi kn b fi lh ku l kv kw">for t in model.parameters():<br/>    print(t.shape)</span></pre><p id="b8ee" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jd">第三步:在GPU上训练模型并评估精度。</em> </strong></p><p id="0e9e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">随着我们的模型和数据集的大小增加，我们需要使用GPU在合理的时间内训练我们的模型。定义一个助手函数，确保我们的代码使用GPU(如果可用的话),如果不可用，默认使用CPU。</p><pre class="je jf jg jh fd km kn ko kp aw kq bi"><span id="6325" class="kr ks hi kn b fi kt ku l kv kw">torch.cuda.is_available()</span><span id="b8ef" class="kr ks hi kn b fi lh ku l kv kw">def <strong class="kn hj">get_default_device</strong>():<br/>    """Pick GPU if available, else CPU"""<br/>    if torch.cuda.is_available():<br/>        return torch.device('cuda')<br/>    else:<br/>        return torch.device('cpu')</span><span id="194e" class="kr ks hi kn b fi lh ku l kv kw">device = get_default_device()<br/>device</span></pre><p id="3baf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了将数据移动到设备，我们创建了一个助手函数。它接受列表、元组和对每个张量上的设备方法的调用。这里，数据从当前设备(CPU)复制到GPU。我们正在尝试使用to_device功能，从train_loader接收图像并打印图像，图像将显示为张量。</p><pre class="je jf jg jh fd km kn ko kp aw kq bi"><span id="d739" class="kr ks hi kn b fi kt ku l kv kw">def <strong class="kn hj">to_device</strong>(data, device):<br/>    """Move tensor(s) to chosen device"""<br/>    if isinstance(data, (list,tuple)):<br/>        return [to_device(x, device) for x in data]<br/>    return data.to(device, non_blocking=True)</span><span id="5e9d" class="kr ks hi kn b fi lh ku l kv kw">for images, labels in train_loader:<br/>    print(images.shape)<br/>    images = to_device(images, device)<br/>    print(images.device)<br/>    break</span></pre><p id="2325" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们定义了一个<code class="du kx ky kz kn b">DeviceDataLoader</code>类来包装我们现有的数据加载器，并在访问一批数据时将数据移动到选定的设备。有趣的是，我们不需要扩展现有的类来创建PyTorch数据加载器。我们只需要一个<code class="du kx ky kz kn b">__iter__</code>方法来检索数据批次，以及一个<code class="du kx ky kz kn b">__len__</code>方法来获得批次的数量。</p><pre class="je jf jg jh fd km kn ko kp aw kq bi"><span id="9a81" class="kr ks hi kn b fi kt ku l kv kw">class DeviceDataLoader():<br/>    """Wrap a dataloader to move data to a device"""<br/>    def __init__(self, dl, device):<br/>        self.dl = dl<br/>        self.device = device<br/>        <br/>    def __iter__(self):<br/>        """Yield a batch of data after moving it to device"""<br/>        for b in self.dl: <br/>            yield to_device(b, self.device)</span><span id="fb23" class="kr ks hi kn b fi lh ku l kv kw">def __len__(self):<br/>        """Number of batches"""<br/>        return len(self.dl)</span></pre><p id="0afc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们使用evaluate函数来评估验证数据集上的模型。它在val_loader上循环，validation_step计算损失和准确性。这个输出被传递到validation_epoch_end。</p><p id="439f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">默认情况下，fit函数采用历元数、学习率、模型、train_loader、val_loader、opt_fun ie优化函数及其SGD。让我们理解每一行代码。optimizer = opt _ func(model . parameters()，lr) —这基本上是通过获取模型参数和学习率来执行SGD的。我们正在循环遍历纪元的数量。在训练阶段，我们遍历训练数据加载器。loss = model . training _ step(batch)-计算每个批次的损失。loss . backward()-计算权重的梯度或导数。<br/>optimizer . step()-根据当前梯度执行参数更新。<br/>optimizer . zero _ grad()-将渐变设置为零。由于backward()函数会累积梯度，并且您不希望在批次之间混淆梯度，因此您必须在新的小型批次开始时将它们归零。验证阶段我们正在val_loader和model.epoch_end上评估模型，我们正在打印损失和准确性。</p><pre class="je jf jg jh fd km kn ko kp aw kq bi"><span id="9188" class="kr ks hi kn b fi kt ku l kv kw">def <strong class="kn hj">evaluate</strong>(model, val_loader):<br/>    outputs = [model.validation_step(batch) for batch in val_loader]<br/>    return model.validation_epoch_end(outputs)<br/><br/>def <strong class="kn hj">fit</strong>(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):<br/>    history = []<br/>    optimizer = opt_func(model.parameters(), lr)<br/>    for epoch in range(epochs):<br/>        <em class="jd"># Training Phase </em><br/>        for batch in train_loader:<br/>            loss = model.training_step(batch)<br/>            loss.backward()<br/>            optimizer.step()<br/>            optimizer.zero_grad()<br/>        <em class="jd"># Validation phase</em><br/>        result = evaluate(model, val_loader)<br/>        model.epoch_end(epoch, result)<br/>        history.append(result)<br/>    return history</span></pre><p id="1e22" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在我们训练模型之前，我们需要确保数据和模型的参数(权重和偏差)在同一个设备上(CPU或GPU)。我们可以重用to_device函数将模型的参数移动到正确的设备。在我们训练之前，我们可以用初始的权重和偏差集来检查模型在验证集上的表现。</p><pre class="je jf jg jh fd km kn ko kp aw kq bi"><span id="07c0" class="kr ks hi kn b fi kt ku l kv kw"><em class="jd"># Model (on GPU)</em><br/>model = MnistModel(input_size, hidden_size=hidden_size, out_size=num_classes)<br/>to_device(model, device)</span><span id="4995" class="kr ks hi kn b fi lh ku l kv kw">history = [evaluate(model, val_loader)]<br/>history</span></pre><p id="e8d8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们训练5个纪元，看看结果。我们可以用相对较高的0.5的学习。因为学习率是基于你的模型来实验的。我们有大约96%的准确率。</p><p id="6638" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一种方法是固定一个标准值，如0.01，如果你的损失太大，或者尝试减少10倍，即从10e-2到10e-3。如果你的损失在慢慢减少，试着增加10倍。</p><p id="89f1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">96%就相当不错了！让我们以0.1的较低学习率再训练模型5个时期，以进一步提高精度。</p><pre class="je jf jg jh fd km kn ko kp aw kq bi"><span id="67b0" class="kr ks hi kn b fi kt ku l kv kw">history += fit(5, 0.5, model, train_loader, val_loader)</span><span id="1010" class="kr ks hi kn b fi lh ku l kv kw">history += fit(5, 0.1, model, train_loader, val_loader)</span></pre><p id="b97f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们正在绘制损失与时代数量的关系图，我们可以看到它下降得相当快，并趋于平缓。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es li"><img src="../Images/e65e5ffe504734108571fa87911c0602.png" data-original-src="https://miro.medium.com/v2/resize:fit:1380/format:webp/1*vrLF5BQfh8yJEOR3RpbxQw.png"/></div><figcaption class="jm jn et er es jo jp bd b be z dx translated">丢失与纪元数量</figcaption></figure><p id="fee2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们正在绘制精度与时代数的关系图，我们可以很快看到它上升并变平。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lj"><img src="../Images/e5d2a2f5480a2ad91a148b2d12da93b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1396/format:webp/1*h6PNpdyrJD4VzRIm3fBMzg.png"/></div><figcaption class="jm jn et er es jo jp bd b be z dx translated">精确度与纪元数量</figcaption></figure><p id="56ad" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们的模型很快就达到了97%的准确率，但除此之外没有太大的改进。为了进一步提高精度，我们需要使模型更强大，这可以通过增加隐藏层的大小或添加更多的隐藏层来实现。</p></div><div class="ab cl jr js gp jt" role="separator"><span class="ju bw bk jv jw jx"/><span class="ju bw bk jv jw jx"/><span class="ju bw bk jv jw"/></div><div class="hb hc hd he hf"><p id="d05b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">请查看笔记本<a class="ae jq" href="https://github.com/Arun-purakkatt/Deep_Learning_Pytorch" rel="noopener ugc nofollow" target="_blank"> <em class="jd"> Github </em> </a>上的全部代码，在 中的<em class="jd"> </em> <a class="ae jq" href="https://www.linkedin.com/in/arun-purakkatt-mba-m-tech-31429367/" rel="noopener ugc nofollow" target="_blank"> <em class="jd">上与我保持联系。</em></a></p><p id="6167" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jd">演职员表&amp;参考文献:</em> </strong></p><ol class=""><li id="2e35" class="jy jz hi ih b ii ij im in iq ka iu kb iy kc jc kd ke kf kg bi translated"><a class="ae jq" href="https://jovian.ml/aakashns/04-feedforward-nn" rel="noopener ugc nofollow" target="_blank">https://jovian.ml/aakashns/04-feedforward-nn</a></li><li id="c3d9" class="jy jz hi ih b ii kh im ki iq kj iu kk iy kl jc kd ke kf kg bi translated">https://pytorch.org/docs/stable/tensors.html<a class="ae jq" href="https://pytorch.org/docs/stable/tensors.html" rel="noopener ugc nofollow" target="_blank"/></li></ol></div></div>    
</body>
</html>