<html>
<head>
<title>TensorFlow Tutorial : A Beginner’s Guide to TensorFlow (Part -2)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">张量流教程:张量流初学者指南(第2部分)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/tensorflow-tutorial-a-beginners-guide-to-tensorflow-part-2-5d1219a8ba5c?source=collection_archive---------9-----------------------#2020-03-15">https://medium.com/analytics-vidhya/tensorflow-tutorial-a-beginners-guide-to-tensorflow-part-2-5d1219a8ba5c?source=collection_archive---------9-----------------------#2020-03-15</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="6edd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">【TensorFlow是如何工作的？</p><ul class=""><li id="afce" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated">TensorFlow将计算定义为图形，这些图形是通过运算(也称为“ops”)完成的。所以，当我们使用TensorFlow时，它与在图形中定义一系列操作是一样的。</li><li id="7097" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">要将这些操作作为计算来执行，我们必须将图形启动到会话中。该会话将图形中表示的操作转换并传递到您想要在其上执行这些操作的设备，无论是GPU还是CPU。</li><li id="9be7" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">例如，下图表示TensorFlow中的一个图形。<strong class="ih hj"> W，x </strong>和<strong class="ih hj"> b </strong>是这个图的边上的张量。<strong class="ih hj"> MatMul </strong>是对张量<strong class="ih hj"> W </strong>和<strong class="ih hj"> x </strong>的运算，之后调用<strong class="ih hj"> Add </strong>，将前一个运算符的结果与<strong class="ih hj"> b </strong>相加。每个操作的合成张量与下一个操作交叉，直到可能得到想要的结果为止。</li></ul><figure class="js jt ju jv fd jw er es paragraph-image"><div role="button" tabindex="0" class="jx jy di jz bf ka"><div class="er es jr"><img src="../Images/bfb86ecb035f9275871681cf1ebfdf14.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S33UXOECrFWyUC7rU8sDqg.png"/></div></div><figcaption class="kd ke et er es kf kg bd b be z dx translated">(图片来源:谷歌)</figcaption></figure><p id="22ff" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">导入张量流</strong></p><p id="5887" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">要使用TensorFlow，我们需要导入库。我们导入它，并可选地给它命名为“tf”，这样模块就可以被<strong class="ih hj"> tf访问。</strong></p><pre class="js jt ju jv fd kh ki kj kk aw kl bi"><span id="65b0" class="km kn hi ki b fi ko kp l kq kr">import tensorflow as tf</span></pre><h2 id="3354" class="km kn hi bd ks kt ku kv kw kx ky kz la iq lb lc ld iu le lf lg iy lh li lj lk bi translated">构建图表</h2><p id="8e65" class="pw-post-body-paragraph if ig hi ih b ii ll ik il im lm io ip iq ln is it iu lo iw ix iy lp ja jb jc hb bi translated">正如我们之前讨论的，TensorFlow作为一个<strong class="ih hj">图形计算模型</strong>工作。让我们创建我们的第一个图表，命名为<strong class="ih hj"> graph1 </strong>。</p><pre class="js jt ju jv fd kh ki kj kk aw kl bi"><span id="fde2" class="km kn hi ki b fi ko kp l kq kr">graph1 = tf.Graph()</span></pre><p id="743a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在我们调用构造新的<strong class="ih hj"> tf的张量流函数。操作</strong>和<strong class="ih hj"> tf。张量</strong>对象并将它们添加到<strong class="ih hj">图1 </strong>中。如上所述，每个<strong class="ih hj"> tf。操作</strong>是一个<strong class="ih hj">节点</strong>和每个<strong class="ih hj"> tf。张量</strong>是图中的一条边。</p><p id="d29a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们在图表中添加两个常数。例如，调用tf.constant([2]，name = 'constant_a ')会添加一个<strong class="ih hj"> tf。操作</strong>到默认图形。该操作产生值2，并返回一个<strong class="ih hj"> tf。张量</strong>表示常量的值。<br/> <strong class="ih hj">注意:</strong> tf.constant([2]，name="constant_a ")创建一个新的tf。名为“constant_a”的操作，并返回一个tf。名为“常数_a:0”的张量。</p><pre class="js jt ju jv fd kh ki kj kk aw kl bi"><span id="9cc6" class="km kn hi ki b fi ko kp l kq kr">with graph1.as_default():<br/>    a = tf.constant([2], name = 'constant_a')<br/>    b = tf.constant([3], name = 'constant_b')</span></pre><p id="d853" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">看看张量a</p><pre class="js jt ju jv fd kh ki kj kk aw kl bi"><span id="189f" class="km kn hi ki b fi ko kp l kq kr">a</span></pre><p id="1602" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">正如你所看到的，它只是显示了图形中张量的名称，形状和类型。当我们在TensorFlow会话中运行它时，我们将看到它的价值。</p><pre class="js jt ju jv fd kh ki kj kk aw kl bi"><span id="bd94" class="km kn hi ki b fi ko kp l kq kr"># Printing the value of a<br/>sess = tf.Session(graph = graph1)<br/>result = sess.run(a)<br/>print(result)<br/>sess.close()</span></pre><p id="fe79" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，让我们对这些张量进行运算。函数<strong class="ih hj"> tf.add() </strong>添加两个张量(也可以使用<code class="du lq lr ls ki b">c = a + b</code>)。</p><pre class="js jt ju jv fd kh ki kj kk aw kl bi"><span id="f118" class="km kn hi ki b fi ko kp l kq kr">with graph1.as_default():<br/>    c = tf.add(a, b)<br/>    #c = a + b is also a way to define the sum of the terms</span></pre><p id="8ceb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后TensorFlow需要初始化一个会话来运行我们的代码。在某种程度上，会话是在TensorFlow中创建图形的上下文。让我们来定义我们的会话:</p><pre class="js jt ju jv fd kh ki kj kk aw kl bi"><span id="49df" class="km kn hi ki b fi ko kp l kq kr">sess = tf.Session(graph = graph1)</span></pre><p id="16b9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们运行该会话，以获得之前定义的“c”操作的结果:</p><pre class="js jt ju jv fd kh ki kj kk aw kl bi"><span id="ada6" class="km kn hi ki b fi ko kp l kq kr">result = sess.run(c)<br/>print(result)</span></pre><p id="f626" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">关闭会话以释放资源:</p><pre class="js jt ju jv fd kh ki kj kk aw kl bi"><span id="91c3" class="km kn hi ki b fi ko kp l kq kr">sess.close()</span></pre><p id="7570" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了避免每次都必须关闭会话，我们可以在带有块的<strong class="ih hj">中定义它们，这样在运行带有</strong>块的<strong class="ih hj">后，会话将自动关闭:</strong></p><pre class="js jt ju jv fd kh ki kj kk aw kl bi"><span id="5cb8" class="km kn hi ki b fi ko kp l kq kr">with tf.Session(graph = graph1) as sess:<br/>    result = sess.run(c)<br/>    print(result)</span></pre><p id="88fa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">甚至这个添加两个常数以达到简单结果的愚蠢例子也定义了张量流的基础。定义您的操作(在本例中是我们的常量和<em class="lt"> tf.add </em>)，并启动一个会话来构建一个图。</p><h2 id="ebdb" class="km kn hi bd ks kt ku kv kw kx ky kz la iq lb lc ld iu le lf lg iy lh li lj lk bi translated">使用张量流定义多维数组</h2><p id="8ad2" class="pw-post-body-paragraph if ig hi ih b ii ll ik il im lm io ip iq ln is it iu lo iw ix iy lp ja jb jc hb bi translated">现在我们将尝试使用TensorFlow来定义这样的数组:</p><pre class="js jt ju jv fd kh ki kj kk aw kl bi"><span id="60e4" class="km kn hi ki b fi ko kp l kq kr">graph2 = tf.Graph()<br/>with graph2.as_default():<br/>    Scalar = tf.constant(2)<br/>    Vector = tf.constant([5,6,2])<br/>    Matrix = tf.constant([[1,2,3],[2,3,4],[3,4,5]])<br/>    Tensor = tf.constant( [ [[1,2,3],[2,3,4],[3,4,5]] , [[4,5,6],[5,6,7],[6,7,8]] , [[7,8,9],[8,9,10],[9,10,11]] ] )<br/>with tf.Session(graph = graph2) as sess:<br/>    result = sess.run(Scalar)<br/>    print ("Scalar (1 entry):\n %s \n" % result)<br/>    result = sess.run(Vector)<br/>    print ("Vector (3 entries) :\n %s \n" % result)<br/>    result = sess.run(Matrix)<br/>    print ("Matrix (3x3 entries):\n %s \n" % result)<br/>    result = sess.run(Tensor)<br/>    print ("Tensor (3x3x3 entries) :\n %s \n" % result)</span></pre><p id="9adf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">tf.shape 返回我们的数据结构的形状。</p><pre class="js jt ju jv fd kh ki kj kk aw kl bi"><span id="713f" class="km kn hi ki b fi ko kp l kq kr">Scalar.shape<br/>Matrix.shape<br/>Tensor.shape</span></pre><p id="99ab" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，根据它们的结构类型，尝试使用一些以前的函数，看看它们的行为如何:</p><pre class="js jt ju jv fd kh ki kj kk aw kl bi"><span id="1663" class="km kn hi ki b fi ko kp l kq kr">graph3 = tf.Graph()<br/>with graph3.as_default():<br/>    Matrix_one = tf.constant([[1,2,3],[2,3,4],[3,4,5]])<br/>    Matrix_two = tf.constant([[2,2,2],[2,2,2],[2,2,2]])</span><span id="ee2f" class="km kn hi ki b fi lu kp l kq kr">add_1_operation = tf.add(Matrix_one, Matrix_two)<br/>    add_2_operation = Matrix_one + Matrix_two</span><span id="71c7" class="km kn hi ki b fi lu kp l kq kr">with tf.Session(graph =graph3) as sess:<br/>    result = sess.run(add_1_operation)<br/>    print ("Defined using tensorflow function :")<br/>    print(result)<br/>    result = sess.run(add_2_operation)<br/>    print ("Defined using normal expressions :")<br/>    print(result)</span></pre><p id="6d46" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">利用常规符号定义和张量流函数，我们能够得到元素级乘法，也称为哈达玛乘积。但是如果我们想要正规的矩阵乘积呢？然后我们需要使用另一个名为<strong class="ih hj"> tf.matmul(): </strong>的张量流函数</p><pre class="js jt ju jv fd kh ki kj kk aw kl bi"><span id="6607" class="km kn hi ki b fi ko kp l kq kr">graph4 = tf.Graph()<br/>with graph4.as_default():<br/>    Matrix_one = tf.constant([[2,3],[3,4]])<br/>    Matrix_two = tf.constant([[2,3],[3,4]])</span><span id="4ff6" class="km kn hi ki b fi lu kp l kq kr">mul_operation = tf.matmul(Matrix_one, Matrix_two)</span><span id="8a14" class="km kn hi ki b fi lu kp l kq kr">with tf.Session(graph = graph4) as sess:<br/>    result = sess.run(mul_operation)<br/>    print ("Defined using tensorflow function :")<br/>    print(result)</span></pre><p id="d6eb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们也可以自己定义这个乘法，但是已经有一个函数可以做到这一点，所以没有必要重新发明轮子！</p><h2 id="6b36" class="km kn hi bd ks kt ku kv kw kx ky kz la iq lb lc ld iu le lf lg iy lh li lj lk bi translated">变量</h2><p id="61b0" class="pw-post-body-paragraph if ig hi ih b ii ll ik il im lm io ip iq ln is it iu lo iw ix iy lp ja jb jc hb bi translated">现在我们更熟悉数据的结构，我们将看看TensorFlow如何处理变量。<strong class="ih hj">首先，有张量，我们为什么需要变量？TensorFlow变量用于共享和持久化一些由我们的程序操作的统计数据。也就是定义变量时，TensorFlow加一个<strong class="ih hj"> tf。操作</strong>到你的图表。然后，该操作将存储一个可写的张量值，该值在tf。会话.运行调用。因此，您可以通过每次运行来更新变量的值，而不能通过在一个会话中多次运行来更新张量(例如由tf.constant()创建的张量)。</strong></p><p id="349a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">如何定义变量？</strong> <br/>我们使用命令<strong class="ih hj"> tf来定义变量。变量()</strong>。为了能够在计算图形中使用变量，有必要在会话中运行图形之前初始化它们。这是通过运行<strong class="ih hj">TF . global _ variables _ initializer()</strong>来完成的。</p><p id="5db6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">要更新变量的值，我们只需运行一个赋值操作，为变量赋值:</p><pre class="js jt ju jv fd kh ki kj kk aw kl bi"><span id="4ee0" class="km kn hi ki b fi ko kp l kq kr">v = tf.Variable(0)</span></pre><p id="7775" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们首先创建一个简单的计数器，一个每次增加一个单位的变量:</p><p id="91da" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为此，我们使用<strong class="ih hj">TF . assign(reference _ variable，value_to_update) </strong>命令。<strong class="ih hj"> tf.assign </strong>接受两个参数，要更新的<strong class="ih hj"> reference_variable </strong>，并将其赋值给<strong class="ih hj"> value_to_update </strong> it by。</p><pre class="js jt ju jv fd kh ki kj kk aw kl bi"><span id="967e" class="km kn hi ki b fi ko kp l kq kr">update = tf.assign(v, v+1)</span></pre><p id="c96b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">启动图形后，必须通过运行初始化操作来初始化变量。我们首先必须将初始化操作添加到图形中:</p><pre class="js jt ju jv fd kh ki kj kk aw kl bi"><span id="897e" class="km kn hi ki b fi ko kp l kq kr">init_op = tf.global_variables_initializer()</span></pre><p id="7708" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后，我们启动一个会话来运行图形，首先初始化变量，然后打印<strong class="ih hj">状态</strong>变量的初始值，然后运行更新<strong class="ih hj">状态</strong>变量的操作，并在每次更新后打印结果:</p><pre class="js jt ju jv fd kh ki kj kk aw kl bi"><span id="7155" class="km kn hi ki b fi ko kp l kq kr">with tf.Session() as session:<br/>    session.run(init_op)<br/>    print(session.run(v))<br/>    for _ in range(3):<br/>        session.run(update)<br/>        print(session.run(v))</span></pre><h2 id="a4c6" class="km kn hi bd ks kt ku kv kw kx ky kz la iq lb lc ld iu le lf lg iy lh li lj lk bi translated">占位符</h2><p id="030b" class="pw-post-body-paragraph if ig hi ih b ii ll ik il im lm io ip iq ln is it iu lo iw ix iy lp ja jb jc hb bi translated">现在我们知道了如何在张量流图中操作变量，但是如何在张量流图之外输入数据呢？</p><p id="de3b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果要从图形外部向张量流图形提供数据，需要使用占位符。</p><p id="e42d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">那么<strong class="ih hj">这些占位符是什么，它们有什么作用？</strong></p><p id="1db3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">占位符可以被视为模型中的“洞”，您可以使用<br/> <strong class="ih hj"> tf来创建这些“洞”。placeholder( <em class="lt">数据类型</em> ) </strong>，其中<strong class="ih hj"> <em class="lt">数据类型</em> </strong>指定数据的类型(整数、浮点、字符串、布尔值)及其精度(8、16、32、64)位。</p><p id="39d0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">具有各自python语法的每种数据类型的定义如下:</p><figure class="js jt ju jv fd jw er es paragraph-image"><div role="button" tabindex="0" class="jx jy di jz bf ka"><div class="er es lv"><img src="../Images/c0bd0401dab4256825d694234e4b3856.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*--aGNYgyAzr61orgCKpRQg.png"/></div></div></figure><p id="b3e3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以我们在这里创建一个占位符:</p><pre class="js jt ju jv fd kh ki kj kk aw kl bi"><span id="e902" class="km kn hi ki b fi ko kp l kq kr">a = tf.placeholder(tf.float32)</span></pre><p id="5055" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">并定义一个简单乘法运算:</p><pre class="js jt ju jv fd kh ki kj kk aw kl bi"><span id="4bdd" class="km kn hi ki b fi ko kp l kq kr">b = a * 2</span></pre><p id="5d6b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在我们需要定义和运行会话，但是由于我们在模型中创建了一个“洞”来传递数据，所以当我们初始化会话时，我们有义务传递一个带有数据的参数，否则我们会得到一个错误。</p><p id="1f33" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了将数据传递到模型中，我们使用一个额外的参数<strong class="ih hj"> feed_dict </strong>调用session，在这个参数中，我们应该传递一个字典，每个占位符名称后面跟有它各自的数据，就像这样:</p><pre class="js jt ju jv fd kh ki kj kk aw kl bi"><span id="b529" class="km kn hi ki b fi ko kp l kq kr">with tf.Session() as sess:<br/>    result = sess.run(b,feed_dict={a:3.5})<br/>    print (result)</span></pre><p id="8432" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">由于TensorFlow中的数据是以多维数组的形式传递的，因此我们可以通过占位符传递任何类型的张量，以获得简单乘法运算的答案:</p><pre class="js jt ju jv fd kh ki kj kk aw kl bi"><span id="d24d" class="km kn hi ki b fi ko kp l kq kr">dictionary={a: [ [ [1,2,3],[4,5,6],[7,8,9],[10,11,12] ] , [ [13,14,15],[16,17,18],[19,20,21],[22,23,24] ] ] }</span><span id="37f9" class="km kn hi ki b fi lu kp l kq kr">with tf.Session() as sess:<br/>    result = sess.run(b,feed_dict=dictionary)<br/>    print (result)</span></pre><p id="69a5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">运算是表示图上张量的数学运算的节点。这些操作可以是任何类型的函数，比如加减张量或者激活函数。</p><p id="5d5e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> tf.constant </strong>，<strong class="ih hj"> tf.matmul </strong>，<strong class="ih hj"> tf.add </strong>，<strong class="ih hj"> tf.nn.sigmoid </strong>是TensorFlow中的一些操作。这些类似于python中的函数，但是直接在张量上操作，每个函数做一件特定的事情。</p><pre class="js jt ju jv fd kh ki kj kk aw kl bi"><span id="0430" class="km kn hi ki b fi ko kp l kq kr">graph5 = tf.Graph()<br/>with graph5.as_default():<br/>    a = tf.constant([5])<br/>    b = tf.constant([2])<br/>    c = tf.add(a,b)<br/>    d = tf.subtract(a,b)</span><span id="355a" class="km kn hi ki b fi lu kp l kq kr">with tf.Session(graph = graph5) as sess:<br/>    result = sess.run(c)<br/>    print ('c =: %s' % result)<br/>    result = sess.run(d)<br/>    print ('d =: %s' % result)</span></pre><p id="9cec" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> tf.nn.sigmoid </strong>是一个激活函数，稍微复杂一点，但是这个函数帮助学习模型评估什么样的信息是好的还是不好的。</p><p id="5609" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">参考:</p><p id="d9e8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae lw" href="http://jrmeyer.github.io/tutorial/2016/02/01/TensorFlow-Tutorial.html" rel="noopener ugc nofollow" target="_blank">http://Jr Meyer . github . io/tutorial/2016/02/01/tensor flow-tutorial . html</a><br/>T3】https://www . tensor flow . org/versions/r 0.9/API _ docs/python/index . html<br/><a class="ae lw" href="https://www.tensorflow.org/api_docs/python/" rel="noopener ugc nofollow" target="_blank">https://www . tensor flow . org/versions/r 0.9/resources/dims _ types . html</a><br/><a class="ae lw" href="https://en.wikipedia.org/wiki/Dimension" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Dimension</a><br/></p></div></div>    
</body>
</html>