<html>
<head>
<title>Mathematics and Vectorization behind Neural Network</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">神经网络背后的数学和矢量化</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/mathematics-and-vectorization-behind-neural-network-b6d491fa617d?source=collection_archive---------22-----------------------#2020-05-12">https://medium.com/analytics-vidhya/mathematics-and-vectorization-behind-neural-network-b6d491fa617d?source=collection_archive---------22-----------------------#2020-05-12</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="60ae" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这个拥有许多高级、专门的库和框架的时代，例如<strong class="ih hj"><em class="jd"/></strong><strong class="ih hj"><em class="jd">tensor flow</em></strong>或<strong class="ih hj"> <em class="jd"> PyTorch </em> </strong>，我们不需要经常担心我们的权重矩阵的大小或记住我们决定使用的激活函数的导数的公式。这篇文章旨在讨论什么是神经网络，以及我们如何在机器学习模型中表示它。随后的帖子将涵盖更高级的主题，如培训和优化模型，但我发现首先对我们实际构建的内容有一个坚实的理解，并对我们将使用的矩阵表示感到舒适，这很有帮助。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/f84df0cef7f775c6a18e926fa9c05110.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9R71-SPtUiAfkwftOfN5sw.jpeg"/></div></div></figure><h1 id="658a" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">神经元的计算模型</h1><p id="15ba" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">在第一步中，我们将了解单个神经元如何作为逻辑函数工作，然后向更深的方面发展，使用多层/深层网络框架计算更复杂的函数。</p><p id="734f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在逻辑回归中，我们用逻辑函数<strong class="ih hj"> g(z) </strong>组成一个线性模型<strong class="ih hj"> z(x) </strong>来构成我们的预测器。这个线性模型是特征输入<strong class="ih hj">x</strong>T18】I和权重<strong class="ih hj">w</strong>T22】I的组合。</p><p id="9904" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">z(x)</strong>=<strong class="ih hj">w1x 1+w2x 2+w3x 3+w4x 4+b</strong>=<strong class="ih hj">wTx+b</strong></p><p id="61e6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们试着想象一下。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es kt"><img src="../Images/1ce0e3e09e066f627cbcbb755396e2f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z5WP-hMd_i7KWSpWCbp06g.png"/></div></div></figure><p id="5b6e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第一层或最终层(在本例中)包含输入特征向量中每个值的节点。这些值按其对应的权重进行缩放，<strong class="ih hj"> w </strong> <em class="jd"> i </em>，并与偏置项<strong class="ih hj"> <em class="jd"> b </em> </strong>一起相加。偏差项允许我们建立不固定在原点的线性模型。</p><p id="d0b9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在计算出<strong class="ih hj"> z(x)之后，</strong>然后传递给具有某个阈值<em class="jd"> (θ)的某个非线性激活函数。</em>如果输入和权重的线性组合(<strong class="ih hj"> z(x) </strong>)高于阈值，则神经元触发，如果组合(<strong class="ih hj"> z(x) </strong>)低于阈值，则不触发。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es ku"><img src="../Images/54ceb75a025678531cf064762a1ac76e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ykKnsiDnmfX0EZ3moPRVpw.png"/></div></div></figure><h1 id="1231" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">损失函数</h1><p id="449a" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">关于学习过程进度的信息的基本来源是损失函数值。一般来说，损失函数旨在显示我们离“理想”解决方案有多远。在我们的例子中，我们使用了二元交叉熵，但是根据我们处理的问题，可以使用不同的函数。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es kv"><img src="../Images/34b3bad0e1925d72dc0916d23695a783.png" data-original-src="https://miro.medium.com/v2/resize:fit:634/1*HopoKQrX-AbXo3bumhL9Xg.gif"/></div></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es kw"><img src="../Images/6c19b12abb99c171ca3c8f2dbc0ff546.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I4wvXBXl7Mh2sygG8MKd2w.png"/></div></div></figure><p id="bafc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">反向传播的主要目的是修改网络的<strong class="ih hj"> <em class="jd">权重</em> </strong>和<strong class="ih hj"> <em class="jd">偏差</em> </strong>，然后给出相应模型的<strong class="ih hj"> <em class="jd">成本函数</em> </strong>的局部/全局最优值。这是在如下所示的<strong class="ih hj">计算图</strong>方法的帮助下完成的。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es kx"><img src="../Images/60d729985e9faa4d31b8ede5ae2acbc4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vuuaRSG9fECczkcd2GWQbA.jpeg"/></div></div></figure><p id="fc87" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们看看整个过程是如何更新神经网络模型的权重和偏差的。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es ky"><img src="../Images/fb892660088b8467194f44447bc0dc9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ag1P2uOkUYw1N3NQ5K4wQg.jpeg"/></div></div></figure><h1 id="0dae" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">建立一个神经元网络</h1><p id="726c" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">以前的模型只能进行二元分类；然而，回想一下，我们可以通过构建逻辑回归模型的集合来执行多类分类。让我们扩展我们的“网络”来表示这一点。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es kz"><img src="../Images/2366d2eabe3640f2524437bd9e116d87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FlJ_ZPMSlpCdeuAYzC0gPw.png"/></div></div></figure><p id="7463" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里，我们建立了三个不同的逻辑回归模型，每个模型都有自己的一组参数。花点时间确保你理解了这个矩阵表示。(这也是为什么把矩阵乘法列为先决条件的原因。)利用矩阵运算非常方便，因为它允许我们快速有效地执行这些计算。</p><p id="3bf9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上面的例子显示了对单个例子进行多类分类的情况，但是我们也可以扩展我们的输入矩阵来对一组例子进行分类。这不仅有用，而且对于我们的优化算法(在后面的文章中)在找到最佳参数时以有效的方式从所有示例中学习是必要的。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es la"><img src="../Images/4e97fc2d8bebd516c482b56652c3cbc6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5p1XEvXVPcoqPi9BWeqJHQ.png"/></div></div></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lb"><img src="../Images/79ac544fec23614c94c2145dbf67b66a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CBrO60TSwnAdtXoIQPvq0g.png"/></div></div></figure><h1 id="08ef" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">矩阵表示</h1><p id="010d" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">设<strong class="ih hj"><em class="jd">n【l】</em></strong>代表<strong class="ih hj"> <em class="jd"> l </em> </strong>层的单元数。对于给定的层，我们将有一个形状为<strong class="ih hj"> <em class="jd"> (n[l]，n[L1])</em></strong>的权重矩阵<strong class="ih hj"> <em class="jd"> W[l] </em> </strong>和形状为<strong class="ih hj"> <em class="jd"> (n[l]，1) </em> </strong>的偏移向量。</p><p id="872c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">给定层的激活将是形状为<strong class="ih hj"> <em class="jd"> (n[l]，m) </em> </strong>的矩阵，其中m表示通过网络馈送的观察值的数量</p><p id="5325" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">感觉你有把握了吗？</p><p id="87d6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">感谢您的阅读。</p></div></div>    
</body>
</html>