<html>
<head>
<title>Matrix Operations Using TensorFlow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用张量流的矩阵运算</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/matrix-operations-using-tensorflow-61a6666ded8f?source=collection_archive---------7-----------------------#2020-01-19">https://medium.com/analytics-vidhya/matrix-operations-using-tensorflow-61a6666ded8f?source=collection_archive---------7-----------------------#2020-01-19</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/013103fcd2cb2361062a2c113b500675.png" data-original-src="https://miro.medium.com/v2/resize:fit:684/1*Nyx7NCBP6Wdf-lZg41bmCw.gif"/></div></figure><p id="5b27" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在前一篇文章<strong class="io hj">TensorFlow入门</strong>的基础上更进一步，将提供关于使用tensor flow执行矩阵运算的额外指南。如果你错过了第一个，你可以点击下面的链接。</p><div class="jk jl ez fb jm jn"><a rel="noopener follow" target="_blank" href="/@minixtrator/getting-started-with-tensorflow-7bf021cce0b4"><div class="jo ab dw"><div class="jp ab jq cl cj jr"><h2 class="bd hj fi z dy js ea eb jt ed ef hh bi translated">TensorFlow入门</h2><div class="ju l"><h3 class="bd b fi z dy js ea eb jt ed ef dx translated">本指南将帮助您了解如何开始使用TensorFlow 2.x</h3></div><div class="jv l"><p class="bd b fp z dy js ea eb jt ed ef dx translated">medium.com</p></div></div><div class="jw l"><div class="jx l jy jz ka jw kb ik jn"/></div></div></a></div></div><div class="ab cl kc kd gp ke" role="separator"><span class="kf bw bk kg kh ki"/><span class="kf bw bk kg kh ki"/><span class="kf bw bk kg kh"/></div><div class="hb hc hd he hf"><h1 id="1c76" class="kj kk hi bd kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg bi translated"><strong class="ak"> 01。矩阵介绍</strong></h1><p id="8d22" class="pw-post-body-paragraph im in hi io b ip lh ir is it li iv iw ix lj iz ja jb lk jd je jf ll jh ji jj hb bi translated">在数学中，<strong class="io hj">矩阵</strong>(复数<strong class="io hj">矩阵</strong>)是数字、符号或表达式的矩形阵列，排列在<em class="lm">行</em>和<em class="lm">列</em>中。请注意，这篇文章的中心不是教你矩阵。如果你是矩阵新手，请在网上查找，否则，你可以用下面的<strong class="io hj">矩阵计算器</strong>找点乐子。</p><div class="jk jl ez fb jm jn"><a href="https://github.com/Adminixtrator/Numpy_Matrix_Calculator" rel="noopener  ugc nofollow" target="_blank"><div class="jo ab dw"><div class="jp ab jq cl cj jr"><h2 class="bd hj fi z dy js ea eb jt ed ef hh bi translated">矩阵计算器</h2><div class="ju l"><h3 class="bd b fi z dy js ea eb jt ed ef dx translated">Numpy矩阵计算器</h3></div><div class="jv l"><p class="bd b fp z dy js ea eb jt ed ef dx translated">github.com</p></div></div><div class="jw l"><div class="ln l jy jz ka jw kb ik jn"/></div></div></a></div></div><div class="ab cl kc kd gp ke" role="separator"><span class="kf bw bk kg kh ki"/><span class="kf bw bk kg kh ki"/><span class="kf bw bk kg kh"/></div><div class="hb hc hd he hf"><blockquote class="lo lp lq"><p id="52c8" class="im in lm io b ip iq ir is it iu iv iw lr iy iz ja ls jc jd je lt jg jh ji jj hb bi translated"><strong class="io hj"> 1.1。创建我们的第一个矩阵</strong></p></blockquote><p id="c819" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">TensorFlow提供了创建矩阵的快捷方式最常用的矩阵，例如单位矩阵，这是使用<code class="du lu lv lw lx b">tf.eye()</code>创建的</p><figure class="lz ma mb mc fd ij er es paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="er es ly"><img src="../Images/313c281f02349bedf75064f028405ec8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GYs6YIW25eBz_ZAoHeS5zQ.png"/></div></div><figcaption class="mh mi et er es mj mk bd b be z dx translated">创建标识矩阵</figcaption></figure><p id="a23f" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">TensorFlow提供创建快捷方式的另一个矩阵是对角矩阵。使用<code class="du lu lv lw lx b">tf.diag()</code> <br/>创建对角矩阵创建对角矩阵最简单和最容易的方法是使用<code class="du lu lv lw lx b">tf.range()</code>属性，然后使用<code class="du lu lv lw lx b">tf.diag()</code>属性将结果向量用于构建矩阵。</p><figure class="lz ma mb mc fd ij er es paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="er es ml"><img src="../Images/f74546a1e3ebfa4d24ae13542b51edf1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zekmV5L1tKtGfuqxrTB4cg.png"/></div></div><figcaption class="mh mi et er es mj mk bd b be z dx translated">创建对角矩阵</figcaption></figure><blockquote class="lo lp lq"><p id="1793" class="im in lm io b ip iq ir is it iu iv iw lr iy iz ja ls jc jd je lt jg jh ji jj hb bi translated"><strong class="io hj">本指南中使用的所有笔记本都可以在下面的存储库中找到</strong></p></blockquote><div class="jk jl ez fb jm jn"><a href="https://github.com/Adminixtrator/Deep_Learning" rel="noopener  ugc nofollow" target="_blank"><div class="jo ab dw"><div class="jp ab jq cl cj jr"><h2 class="bd hj fi z dy js ea eb jt ed ef hh bi translated">管理员/深度学习</h2><div class="ju l"><h3 class="bd b fi z dy js ea eb jt ed ef dx translated">❍这些笔记本将基于你已经看过之前的笔记本的假设，❍指南将基于…</h3></div><div class="jv l"><p class="bd b fp z dy js ea eb jt ed ef dx translated">github.com</p></div></div><div class="jw l"><div class="mm l jy jz ka jw kb ik jn"/></div></div></a></div><blockquote class="lo lp lq"><p id="04e3" class="im in lm io b ip iq ir is it iu iv iw lr iy iz ja ls jc jd je lt jg jh ji jj hb bi translated"><strong class="io hj"> 1.2。对矩阵进行运算</strong></p></blockquote><p id="289a" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">令人惊讶的是，TensorFlow可以对矩阵执行一些有趣的操作。我们首先要看的是<strong class="io hj">行列式</strong>。为了得到矩阵的行列式，使用了<code class="du lu lv lw lx b">tf.matrix_determinant(</code>属性。<code class="du lu lv lw lx b">matrix_determinant()</code>函数接受一个矩阵作为输入，如下例所示。</p><figure class="lz ma mb mc fd ij er es paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="er es mn"><img src="../Images/636bef82a5dc72647791a49c77254382.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iX0YtQidYcmdIGqEl_XcJw.png"/></div></div><figcaption class="mh mi et er es mj mk bd b be z dx translated">矩阵的行列式</figcaption></figure><p id="3545" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">可以执行的另一个有趣的操作是矩阵的转置。这是使用<code class="du lu lv lw lx b">tf.matrix_transpose()</code>属性完成的。<code class="du lu lv lw lx b">matrix_transpose()</code>函数接受一个矩阵作为输入。看看下面的例子。</p><figure class="lz ma mb mc fd ij er es paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="er es mo"><img src="../Images/f5e389ec3e908f5ba836aaacfc0640a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EJ0yyhbUXJZAIVdnGx1c_A.png"/></div></div><figcaption class="mh mi et er es mj mk bd b be z dx translated">矩阵的转置</figcaption></figure><p id="18d4" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">矩阵的求逆也可以使用TensorFlow的<code class="du lu lv lw lx b">tf.matrix_inverse</code>属性来完成。正如<code class="du lu lv lw lx b">matrix_transpose</code>和<code class="du lu lv lw lx b">matrix_determinant</code>一样，它接受一个矩阵作为输入。下面显示了绕过该操作的一种简单方法。</p><figure class="lz ma mb mc fd ij er es paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="er es mp"><img src="../Images/7d8fdf6d4f3bf5a9b84074ed84b51ba1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aba31c6gdRNeZfdnB-SVvg.png"/></div></div><figcaption class="mh mi et er es mj mk bd b be z dx translated">矩阵的逆</figcaption></figure><p id="cb7d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">就像常量、数组等一样，矩阵也可以被整数或小数加减乘除。加、减和除矩阵的步骤仍然与前一篇文章中使用的步骤相同。<code class="du lu lv lw lx b">tf.add</code>、<code class="du lu lv lw lx b">tf.subtract</code>和<code class="du lu lv lw lx b">tf.divide</code>或<code class="du lu lv lw lx b">tf.div</code></p><p id="5559" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">当矩阵相乘时,<code class="du lu lv lw lx b">tf.multiply()</code>在这种情况下不起作用——正如我们所知，矩阵相乘的理论不同于常规的乘法思想。<br/>在矩阵的情况下，当矩阵相乘时，我们使用<code class="du lu lv lw lx b">tf.matmul()</code>。该函数<strong class="io hj">接受两个矩阵</strong>作为输入。让我们快速看一下使用该函数的简单方法，如下例所示:</p><figure class="lz ma mb mc fd ij er es paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="er es mq"><img src="../Images/d68b73d9983ec82bb56cf5cbad364286.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AQLfiqV6Hc9wMwp-BOzO7g.png"/></div></div><figcaption class="mh mi et er es mj mk bd b be z dx translated">矩阵乘法</figcaption></figure><p id="3261" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">如果你是矩阵概念的新手，或者是一个有趣的爱好者，你可以试试下面的库:</p><div class="jk jl ez fb jm jn"><a href="https://github.com/Adminixtrator/Numpy_Matrix_Calculator" rel="noopener  ugc nofollow" target="_blank"><div class="jo ab dw"><div class="jp ab jq cl cj jr"><h2 class="bd hj fi z dy js ea eb jt ed ef hh bi translated">adminixtrator/Numpy _ Matrix _ Calculator</h2><div class="ju l"><h3 class="bd b fi z dy js ea eb jt ed ef dx translated">用numpy构建的矩阵计算器。为Adminixtrator/Numpy _ Matrix _ Calculator开发做贡献，创建一个…</h3></div><div class="jv l"><p class="bd b fp z dy js ea eb jt ed ef dx translated">github.com</p></div></div><div class="jw l"><div class="mr l jy jz ka jw kb ik jn"/></div></div></a></div></div><div class="ab cl kc kd gp ke" role="separator"><span class="kf bw bk kg kh ki"/><span class="kf bw bk kg kh ki"/><span class="kf bw bk kg kh"/></div><div class="hb hc hd he hf"><blockquote class="lo lp lq"><p id="b122" class="im in lm io b ip iq ir is it iu iv iw lr iy iz ja ls jc jd je lt jg jh ji jj hb bi translated"><strong class="io hj"> 1.3。类型转换</strong></p></blockquote><p id="8c6f" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">毫无疑问，一致的观察应该会注意到我们一直在研究的张量的数据类型的变化(你一定见过像<code class="du lu lv lw lx b">dtype=int32</code> <code class="du lu lv lw lx b">dtype=float32</code>之类的东西。).这一部分是操纵不同数据类型的张量的指南。<br/>我们首先要考虑的是<code class="du lu lv lw lx b">int32</code> <strong class="io hj"> dtype </strong>。这个数据类型由<strong class="io hj"> 32位整数</strong>组成，所以我们将把它转换成<code class="du lu lv lw lx b">float32</code>数据类型。</p><p id="efeb" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">为了将一个张量从一种数据类型转换成另一种数据类型，我们使用<code class="du lu lv lw lx b">tf.to</code>标志，例如，当转换成<strong class="io hj">浮点型</strong>时，我们使用<code class="du lu lv lw lx b">tf.to_float()</code>，转换成<strong class="io hj">整型</strong>时，我们使用<code class="du lu lv lw lx b">tf.to_int</code>，同样地，转换成<strong class="io hj">双精度型</strong>时，我们使用<code class="du lu lv lw lx b">tf.to_double()</code></p><blockquote class="lo lp lq"><p id="80d5" class="im in lm io b ip iq ir is it iu iv iw lr iy iz ja ls jc jd je lt jg jh ji jj hb bi translated"><strong class="io hj">笔记本上写的例子上传到下面的图片中</strong></p></blockquote><figure class="lz ma mb mc fd ij er es paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="er es ms"><img src="../Images/83cb9cc747c07029f2e3fed7b3543662.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*df16Pp6hXZC86hesAEkbPw.png"/></div></div><figcaption class="mh mi et er es mj mk bd b be z dx translated">笔记本上的例子</figcaption></figure><figure class="lz ma mb mc fd ij er es paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="er es mt"><img src="../Images/55a92c494f5a138eea98d94b3bb600e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SfGLNpeiCaiERsAe3rE8-A.png"/></div></div><figcaption class="mh mi et er es mj mk bd b be z dx translated">笔记本上的例子</figcaption></figure><p id="aff8" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">同样，当使用关键字<code class="du lu lv lw lx b">dtype</code>创建张量时，可以声明张量的数据类型。它接受数据类型输入，如<code class="du lu lv lw lx b">tf.int32</code>、<code class="du lu lv lw lx b">tf.float32</code>等。下面的截屏显示了一个如何创建张量的简单示例:</p><figure class="lz ma mb mc fd ij er es paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="er es mu"><img src="../Images/30c61cbd6dbc437de12a0288aebda377.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EP783orsiKNAPLPRlvTetg.png"/></div></div><figcaption class="mh mi et er es mj mk bd b be z dx translated">创建张量时声明数据类型</figcaption></figure></div><div class="ab cl kc kd gp ke" role="separator"><span class="kf bw bk kg kh ki"/><span class="kf bw bk kg kh ki"/><span class="kf bw bk kg kh"/></div><div class="hb hc hd he hf"><blockquote class="lo lp lq"><p id="eb63" class="im in lm io b ip iq ir is it iu iv iw lr iy iz ja ls jc jd je lt jg jh ji jj hb bi translated"><strong class="io hj"> 1.4。形状操作</strong></p></blockquote><p id="6a2d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">最后，在本指南中，我们将考虑可以用TensorFlow执行的另一个有趣的操作— <strong class="io hj">形状操纵</strong>😃。<br/>在我们学习的过程中，我们可能已经注意到了张量的形状属性(你一定听过类似<code class="du lu lv lw lx b">shape=(3,4)</code>、<code class="du lu lv lw lx b">shape=(1,4,1)</code>等的东西。).</p><p id="d9e8" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">TensorFlow提供了一种简单的方法，可以通过一个或多个维度对矩阵进行简单的扩展或缩减。与其他方面相比，这部分需要对矩阵有更深入的理解。</p><p id="b149" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">扩大矩阵大小最简单的方法是使用TensorFlow的<code class="du lu lv lw lx b">tf.expand_dims()</code>属性。<code class="du lu lv lw lx b">expand_dims()</code>函数接受一个<strong class="io hj">矩阵</strong>和<strong class="io hj">它应该扩展的维数</strong>作为其输入，从<strong class="io hj">零</strong>开始它的索引。考虑下面的例子:</p><figure class="lz ma mb mc fd ij er es paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="er es mt"><img src="../Images/bf00f5475597c04eb1342c47a337775a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nFGoDoqqSAeiEB6SvwfXJQ.png"/></div></div><figcaption class="mh mi et er es mj mk bd b be z dx translated">使用expand_dims()属性</figcaption></figure><p id="fbe6" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">矩阵的形状也可以通过调用上面截图中使用的<code class="du lu lv lw lx b">tf.shape()</code>属性的<code class="du lu lv lw lx b">shape()</code>函数来获得。</p><p id="0422" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在来减小矩阵的大小。这是使用<code class="du lu lv lw lx b">tf.squeeze() </code>属性完成的。它删除所有尺寸为1的维度。<code class="du lu lv lw lx b">squeeze()</code>功能接收一个<strong class="io hj">矩阵</strong>到<em class="lm">挤压。考虑下面的例子:</em></p><figure class="lz ma mb mc fd ij er es paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="er es mv"><img src="../Images/f87bbc1033c12919a83c58157c9885ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LAVEAJDeyCCTC466svFrjg.png"/></div></div><figcaption class="mh mi et er es mj mk bd b be z dx translated">使用挤压功能</figcaption></figure></div><div class="ab cl kc kd gp ke" role="separator"><span class="kf bw bk kg kh ki"/><span class="kf bw bk kg kh ki"/><span class="kf bw bk kg kh"/></div><div class="hb hc hd he hf"><h1 id="1bce" class="kj kk hi bd kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg bi translated">02。张量流广播</h1><p id="a1d0" class="pw-post-body-paragraph im in hi io b ip lh ir is it li iv iw ix lj iz ja jb lk jd je jf ll jh ji jj hb bi translated">广播是在<strong class="io hj"> Numpy </strong>中引入的一个术语。在TensorFlow中，指的是将张量系统矩阵加到不同大小的向量上。<br/>它提供了很多便利，比如给矩阵的每一行添加一个<strong class="io hj">向量</strong>。我们不会深究这些规则，我们所要做的只是了解在一些情况下如何使用它。</p><p id="2d1a" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">向量(与对应矩阵具有相同的数据类型)可以沿着矩阵的行进行<strong class="io hj">加法</strong>、<strong class="io hj">减法</strong>、<strong class="io hj">除法或乘法</strong>。例如，一个3×3的矩阵乘以一个1×3的向量。笔记本中显示的示例上传如下:</p><figure class="lz ma mb mc fd ij er es paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="er es mw"><img src="../Images/6b842a1c431bdae4fe26fb40fa9f6a85.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WjPlA_xblfLwTS26i9U5KQ.png"/></div></div><figcaption class="mh mi et er es mj mk bd b be z dx translated">沿着矩阵的行广播</figcaption></figure><figure class="lz ma mb mc fd ij er es paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="er es mt"><img src="../Images/65984f64b1c99fc28fa103f1a7cd65e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y9Y-sgz-vsBdOmaZEwKWMg.png"/></div></div><figcaption class="mh mi et er es mj mk bd b be z dx translated">沿着矩阵的行广播</figcaption></figure><p id="5379" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">Keynote读者会指出，这些相同的操作可以用一个<strong class="io hj">列向量</strong>来执行(前面的称为行向量)。在这里，我们可以在一个大小为4x4的矩阵上传播一个大小为1x4的列向量，假设它们具有相同的数据类型。<br/>考虑下面的例子:</p><figure class="lz ma mb mc fd ij er es paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="er es mx"><img src="../Images/11160119d0d90130401e84c8a1d55bfc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x8fsZYhQZfiFa9SLAb7YwA.png"/></div></div><figcaption class="mh mi et er es mj mk bd b be z dx translated">沿着矩阵的每一列广播</figcaption></figure><figure class="lz ma mb mc fd ij er es paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="er es mw"><img src="../Images/a1ae06471e3d73b84cda3ba1cc01c3dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_DoOXUR74C2YVhDJKUGL9g.png"/></div></div><figcaption class="mh mi et er es mj mk bd b be z dx translated">沿着矩阵的每一列广播</figcaption></figure><blockquote class="lo lp lq"><p id="b414" class="im in lm io b ip iq ir is it iu iv iw lr iy iz ja ls jc jd je lt jg jh ji jj hb bi translated">结束注释</p></blockquote><p id="83f7" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">关于张量流中的矩阵，这就是你现在需要知道的全部。持续的练习将有助于掌握这门艺术。<br/>下一篇文章将是关于使用TensorFlow的<strong class="io hj">线性回归。</strong> <br/>本文针对深度学习的TensorFlow。感谢您的时间，下一篇文章再见。</p></div></div>    
</body>
</html>