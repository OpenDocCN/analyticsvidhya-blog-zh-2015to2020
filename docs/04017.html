<html>
<head>
<title>A Brief Introduction to Hyper Parameter Optimization(learners at Medium level)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">超参数优化简介(中等水平的学习者)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/a-brief-introduction-to-hyper-parameter-optimization-learners-at-medium-level-a5270306abcd?source=collection_archive---------16-----------------------#2020-03-01">https://medium.com/analytics-vidhya/a-brief-introduction-to-hyper-parameter-optimization-learners-at-medium-level-a5270306abcd?source=collection_archive---------16-----------------------#2020-03-01</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/8d4b4ac8173afcc7a76f6f3e04944390.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IH69BCgqiaq5M_j_m3aNvg.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd iu">来自谷歌图片</strong></figcaption></figure><p id="f79e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">首先让我们了解什么是超参数:-</p><p id="a867" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">超参数</strong>是算法的参数，其值与模型的行为和性能成正比。</p><p id="7a38" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">不要混淆超参数和模型参数之间的区别。</p><p id="825f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">模型参数</strong>是模型内部的参数，这些内部的东西(参数)可以从给定的数据(我们可以说是训练数据)中计算出来。</p><p id="52a2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">当你看到这两件事的一些例子时，你会更清楚这种区别，</p><p id="85c6" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">所以，在这里我将通过考虑<strong class="ix hj">线性回归</strong>、<strong class="ix hj">随机森林</strong>、<strong class="ix hj"> K-Means聚类</strong>算法来展示例子(假设你使用过这些算法)。</p><h1 id="1694" class="jt ju hi bd iu jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">超参数:-</h1><p id="90d7" class="pw-post-body-paragraph iv iw hi ix b iy kq ja jb jc kr je jf jg ks ji jj jk kt jm jn jo ku jq jr js hb bi translated"><strong class="ix hj">线性回归:- </strong></p><p id="49aa" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在线性回归中，拟合截距是一个超参数，</p><p id="3a33" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">也就是说，</p><p id="a625" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">fit_intercept =在函数形式中是否包含β项。</p><p id="4534" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">随机森林:- </strong></p><p id="1699" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在随机森林中，超参数是</p><ol class=""><li id="d510" class="kv kw hi ix b iy iz jc jd jg kx jk ky jo kz js la lb lc ld bi translated">n _估计量</li><li id="c9aa" class="kv kw hi ix b iy le jc lf jg lg jk lh jo li js la lb lc ld bi translated">标准</li></ol><p id="b3c3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这解释了，</p><p id="9b90" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">n_estimators =森林中的树木数量，</p><p id="c582" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">criterion =“Gini”或“信息增益”(假设您使用了这些算法)。</p><p id="4fb2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> K均值聚类:- </strong></p><p id="929c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在K均值中，超参数为</p><ol class=""><li id="08aa" class="kv kw hi ix b iy iz jc jd jg kx jk ky jo kz js la lb lc ld bi translated">初始化</li></ol><p id="a5cb" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">也就是说，</p><p id="7c78" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">init =质心的初始化方法。</p><h1 id="d1a8" class="jt ju hi bd iu jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">模型参数:-</h1><p id="9e20" class="pw-post-body-paragraph iv iw hi ix b iy kq ja jb jc kr je jf jg ks ji jj jk kt jm jn jo ku jq jr js hb bi translated"><strong class="ix hj">线性回归:- </strong></p><p id="975d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在线性回归中，当我们用训练数据训练模型时，将形成最佳拟合线，</p><p id="755c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">y =α+β* X</p><p id="52fc" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">其中X =输入数据，</p><p id="99f3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">Y =标记数据(训练时)</p><p id="e283" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如果你想了解更多关于线性回归的知识，请点击链接。</p><p id="145e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这里β是模型参数之一。</p><p id="3833" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">不幸的是，<strong class="ix hj">随机森林</strong>和<strong class="ix hj"> K-Means聚类</strong>没有模型参数可以向你解释😢。</p><p id="a9d3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">对于<strong class="ix hj">支持向量机</strong>，支持向量是模型参数。</p><p id="e6cf" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">所以现在，我希望你对模型参数和超参数之间的区别有所了解。</p><p id="eb33" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在让我们进入主要部分，</p><ol class=""><li id="9521" class="kv kw hi ix b iy iz jc jd jg kx jk ky jo kz js la lb lc ld bi translated"><strong class="ix hj">一个算法的超参数优化有什么用？</strong></li></ol><p id="506a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">a)正如我们上面讨论的，超参数是对算法性能有很大控制的参数。因此，通过优化超参数，使我们的数据以优化的方式适合算法，从而提高算法的精度。</p><p id="7c40" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们可以将<strong class="ix hj">超参数优化</strong>定义为“将超参数的优化值分配给算法以获得更高精度的过程”。</p><p id="1eeb" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">2.<strong class="ix hj">我们如何将超参数优化应用到算法中？</strong></p><p id="8b3e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">a)这里我们将讨论一些最流行的超参数优化技术，即随机搜索、网格搜索。</p><p id="09e7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">a.<strong class="ix hj">随机搜索:- </strong></p><p id="c5e7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在这种技术中，随机搜索将建立超参数值的网格，并选择该超参数值的随机组合来训练和评分模型。</p><p id="da8a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">只需浏览下面的代码片段就能理解<strong class="ix hj">随机</strong>搜索:-</p><pre class="lk ll lm ln fd lo lp lq lr aw ls bi"><span id="3c58" class="lt ju hi lp b fi lu lv l lw lx">from sklearn.model_selection import RandomizedSearchCV<br/>from sklearn import datasets<br/>from sklearn.ensemble import RandomForestClassifier<br/>from scipy.stats import uniform, truncnorm, randint</span><span id="0745" class="lt ju hi lp b fi ly lv l lw lx"># get iris data<br/>iris = datasets.load_iris()<br/>X = iris.data<br/>y = iris.target<br/>model_params = {<br/>    'n_estimators': randint(4,200),<br/>    'max_features': truncnorm(a=0, b=1, loc=0.25, scale=0.1),<br/>    'min_samples_split': uniform(0.01, 0.199)<br/>}<br/>rf_model = RandomForestClassifier()<br/>clf = RandomizedSearchCV(rf_model, model_params, n_iter=100, cv=5, random_state=1)<br/>model = clf.fit(X, y)<br/>from pprint import pprint<br/>pprint(model.best_estimator_.get_params())</span></pre><p id="9407" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">不要为代码而烦恼，比如“那是什么东西？”诸如此类的事情。因为所有这些东西，你都会在练习的时候得到。</p><p id="531c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">网格搜索:- </strong></p><p id="4052" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在这种技术中，网格搜索将用超参数值的所有可能组合来训练算法。</p><p id="0cbd" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在这里，我们可以通过使用<strong class="ix hj">交叉验证</strong>技术来衡量性能。</p><p id="c8ee" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">使用K <strong class="ix hj">实现交叉验证的最佳方法之一——折叠交叉验证</strong></p><p id="28ef" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这项技术使我们能够确保训练好的模型是由数据集中数据的所有模式和行为训练出来的。</p><p id="ebee" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">只需浏览下面的代码片段就可以理解网格搜索:-</p><pre class="lk ll lm ln fd lo lp lq lr aw ls bi"><span id="cf89" class="lt ju hi lp b fi lu lv l lw lx">import pandas as pd <br/>import numpy as np<br/>dataset = pd.read_csv(r"D:/Datasets/winequality-red.csv", sep=';')<br/>  X = dataset.iloc[:, 0:11].values <br/>  y = dataset.iloc[:, 11].values<br/>  from sklearn.model_selection import train_test_split <br/>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0, random_state=0)<br/>  from sklearn.ensemble import RandomForestClassifier <br/>classifier = RandomForestClassifier(n_estimators=300, random_state=0)<br/>  grid_param = {     <br/>'n_estimators': [100, 300, 500, 800, 1000],     <br/>'criterion': ['gini', 'entropy'],     <br/>}<br/>  gd_sr = GridSearchCV(<br/>estimator=classifier,                      <br/>param_grid=grid_param,                      <br/>scoring='accuracy',                      <br/>cv=5)<br/>gd_sr.fit(X_train, y_train)</span><span id="d48a" class="lt ju hi lp b fi ly lv l lw lx">best_parameters = gd_sr.best_params_ <br/>print(best_parameters)<br/>best_result = gd_sr.best_score_ <br/>print(best_result)</span></pre><p id="7bbd" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我再说一遍，先不要纠结代码，先试着学习核心概念。在编码的时候，你会很容易熟悉这些东西。</p><h1 id="2842" class="jt ju hi bd iu jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">一些重要注意事项:-</h1><p id="6cb7" class="pw-post-body-paragraph iv iw hi ix b iy kq ja jb jc kr je jf jg ks ji jj jk kt jm jn jo ku jq jr js hb bi translated">→如果你对自己的计算能力和成本没问题，那就去网格搜索吧。因为网格搜索比随机搜索需要更多的计算能力。</p><p id="01ea" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">随机搜索将只选择超参数值的随机组合，而网格搜索将通过包括所有可能的组合来选择最佳超参数值。这就是为什么网格搜索比随机搜索需要更多的计算能力。</p><p id="eb5c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">→尽管网格搜索需要更多的计算能力，但它会给出比随机搜索更准确的结果</p><p id="7703" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">→但是随机搜索会以较低的计算能力和成本更好地给出准确的结果。</p><h2 id="bf77" class="lt ju hi bd iu lz ma mb jy mc md me kc jg mf mg kg jk mh mi kk jo mj mk ko ml bi translated">快乐阅读！✌✌</h2></div></div>    
</body>
</html>