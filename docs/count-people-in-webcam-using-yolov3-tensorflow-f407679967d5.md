# ä½¿ç”¨é¢„å…ˆè®­ç»ƒçš„ YOLOv3 è®¡ç®—ç½‘ç»œæ‘„åƒå¤´ä¸­çš„äººæ•°

> åŸæ–‡ï¼š<https://medium.com/analytics-vidhya/count-people-in-webcam-using-yolov3-tensorflow-f407679967d5?source=collection_archive---------1----------------------->

## äº†è§£å¦‚ä½•ä½¿ç”¨å®ä¾‹åˆ†æ®µ(YOLOv3)é€šè¿‡ python ä¸­çš„ TensorFlow å’Œ OpenCV ä½¿ç”¨å…¶é¢„è®­ç»ƒçš„æƒé‡æ¥ç»Ÿè®¡äººæ•°ã€‚

![](img/dda6c533c8139832353c04ede43c33e8.png)

ä¸æ»¡Â·æ–¯å›¾å¾·å‹’åœ¨ [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) ä¸Šçš„ç…§ç‰‡

# ç›®å½•

*   **è¦æ±‚**
*   **ç®€ä»‹**

1.  *å®ä¾‹åˆ‡åˆ† vs è¯­ä¹‰åˆ‡åˆ†*
2.  *YOLOv3 vs æ›´å¿«çš„ RCNN vs SSD*
3.  *çº¦æ´›å¤« 3*
4.  *é”šç®±*
5.  *éæœ€å¤§æŠ‘åˆ¶*

*   **ä»£ç **

# è¦æ±‚

å¯¹äºè¿™ä¸ªé¡¹ç›®ï¼Œæˆ‘ä»¬éœ€è¦ Tensorflowã€OpenCV å’Œ wget-python(æ¥ä¸‹è½½ YOLOv3 æƒé‡ã€‚æ‚¨ä¹Ÿå¯ä»¥æ‰‹åŠ¨ä¸‹è½½å®ƒä»¬ã€‚)

ä½¿ç”¨ç”»ä¸­ç”»:

```
pip install tensorflow-gpu # this is the gpu version
pip install tensorflow # if you don't have gpu like me ğŸ˜¥
pip install opencv-python
pip install wget
```

å¦‚æœæ‚¨ä½¿ç”¨ anacondaï¼Œé‚£ä¹ˆä½¿ç”¨ conda:

```
conda install -c anaconda tensorflow-gpu # this is the gpu version
conda install -c conda-forge tensorflow # if you don't have gpu version
conda install -c conda-forge opencv
conda install -c conda-forge python-wget
```

# ä»‹ç»

åœ¨è¿™é‡Œï¼Œæˆ‘å°†ç®€è¦è®¨è®ºä¸ YOLOv3 å’Œå®ä¾‹åˆ†å‰²ç›¸å…³çš„åŸºæœ¬æœ¯è¯­ï¼Œå¹¶æä¾›é¢å¤–çš„é˜…è¯»èµ„æºã€‚å¦‚æœæ‚¨äº†è§£å®ƒä»¬ï¼Œå¹¶æƒ³è·³è¿‡å®ƒä»¬ï¼Œè¯·éšæ„è¿›å…¥ä¸‹ä¸€éƒ¨åˆ†ã€‚

## å®ä¾‹åˆ†å‰²ä¸è¯­ä¹‰åˆ†å‰²

åœ¨è¯­ä¹‰åˆ†å‰²ä¸­ï¼ŒåŸºäºå„ç§æ ‡ç­¾(å¦‚äººã€ç‹—ã€çŒ«ç­‰)å¯¹å›¾åƒè¿›è¡Œåˆ†å‰²ï¼Œä½†æ˜¯æ²¡æœ‰åŠæ³•åŒºåˆ†ä¸¤ä¸ªäººç‰©ã€‚è¿™ä¸ªç¼ºç‚¹åœ¨å®ä¾‹åˆ†å‰²ä¸­å¾—åˆ°è§£å†³ï¼Œå…¶ä¸­é™¤äº†åŒºåˆ†ä¸åŒçš„æ ‡ç­¾ä¹‹å¤–ï¼Œæˆ‘ä»¬è¿˜èƒ½å¤ŸåŒºåˆ†è¯¥æ ‡ç­¾çš„å¤šä¸ªå¯¹è±¡ã€‚

![](img/a655235f1ec7bfa63a0f74de38740d9a.png)

è¯­ä¹‰åˆ†æ®µ(å·¦)ä¸å®ä¾‹åˆ†æ®µ(å³)å¦‚æœæŒ‰è¾¹æ•°åˆ†æ®µã€‚

## YOLOv3 ä¸æ›´å¿«çš„ RCNN å’Œ SSD

é€‰æ‹©å“ªä¸€ä¸ªï¼Œä¸ºä»€ä¹ˆï¼Ÿ

æƒ³è¦æœ€å¥½çš„ç²¾ç¡®åº¦ï¼Ÿæ›´å¿«çš„ RCNN

æƒ³è¦æœ€å¿«çš„é€Ÿåº¦ï¼ŸYOLOv3

æƒ³è¦åœ¨ä¸¤è€…ä¹‹é—´è¿›è¡Œæƒè¡¡å—ï¼Ÿï¼ˆåŒ solid-statediskï¼‰å›ºæ€ï¼ˆç£ï¼‰ç›˜

æˆ‘è¯•å›¾é€šè¿‡ CPU (LOL)ä¸Šçš„ç½‘ç»œæ‘„åƒå¤´è¿›è¡Œå®æ—¶å®ç°ï¼Œæ‰€ä»¥æˆ‘é€‰æ‹©äº† YOLOv3ã€‚æˆ‘ä¹Ÿå°è¯•è¿‡å¾®å°çš„ YOLOï¼Œä½†å®ƒçš„é¢„æµ‹ä¸å‡†ç¡®ï¼Œæ‰€ä»¥æˆ‘æ”¾å¼ƒäº†å®ƒã€‚ä½ å¯ä»¥é€‰æ‹©æœ€é€‚åˆä½ çš„ã€‚

*æ·±å…¥äº†è§£è¿™äº›æ¨¡å‹çš„è¡¥å……é˜…è¯»*

fast RCNNâ€”[https://towardsdatascience . com/fast-r-CNN-for-object-detection-a-technical-summary-474 C5 b 857 b 46](https://towardsdatascience.com/faster-r-cnn-for-object-detection-a-technical-summary-474c5b857b46)

SSDâ€”[https://towards data science . com/understanding-SSD-multi box-real-time-object-detection-in-deep-learning-495 ef 744 fab](https://towardsdatascience.com/understanding-ssd-multibox-real-time-object-detection-in-deep-learning-495ef744fab)

ä»–ä»¬ä¹‹é—´çš„æ¯”è¾ƒâ€”[https://medium . com/@ Jonathan _ hui/object-detection-speed-and-accuracy-comparison-fast-r-CNN-r-fcn-SSD-and-yolo-5425656 AE 359](/@jonathan_hui/object-detection-speed-and-accuracy-comparison-faster-r-cnn-r-fcn-ssd-and-yolo-5425656ae359)

## YOLOv3

![](img/8e1fa824da2b78f982cc8acd24f39c6d.png)

å›¾ç‰‡å–è‡ª[è¿™é‡Œ](https://towardsdatascience.com/yolo-v3-object-detection-53fb7d3bfe6b)ã€‚

YOLOv3 é¢„è®­ç»ƒæ¨¡å‹å¯ç”¨äºåˆ†ç±» 80 ä¸ªå¯¹è±¡ï¼Œé€Ÿåº¦è¶…å¿«ï¼Œå‡ ä¹ä¸ SSD ä¸€æ ·å‡†ç¡®ã€‚å®ƒæœ‰ 53 ä¸ªå·ç§¯å±‚ï¼Œæ¯ä¸ªå·ç§¯å±‚åé¢éƒ½æœ‰ä¸€ä¸ªæ‰¹é‡å½’ä¸€åŒ–å±‚å’Œä¸€ä¸ªæ³„æ¼ RELU æ¿€æ´»ã€‚ä¸ºäº†ä¸‹é‡‡æ ·ï¼Œä»–ä»¬åœ¨å·ç§¯å±‚ä¸­ä½¿ç”¨äº†æ­¥é•¿ 2ï¼Œè€Œä¸æ˜¯ä½¿ç”¨æ± ã€‚å®ƒçš„è¾“å…¥æ ¼å¼æ˜¯å›¾åƒåº”è¯¥æ˜¯ RGB æ ¼å¼(æ‰€ä»¥å¦‚æœä½¿ç”¨ OpenCV è®°å¾—è½¬æ¢)ï¼Œè¾“å…¥ç±»å‹æ˜¯ float32ï¼Œå°ºå¯¸å¯ä»¥æ˜¯ 320x320 æˆ– 416x416 æˆ– 608x608ã€‚

è¡¥å……é˜…è¯»:[https://towards data science . com/yolo-v3-object-detection-53 FB 7d 3 bfe 6 b](https://towardsdatascience.com/yolo-v3-object-detection-53fb7d3bfe6b)

## é”šç®±

é”šç›’æœ‰åŠ©äºæ¨¡å‹æ›´å¥½åœ°ä¸“é—¨åŒ–ã€‚ä¸¾ä¸€ä¸ªç«™ç€çš„äººå’Œæ±½è½¦çš„ä¾‹å­ã€‚äººéœ€è¦ä¸€ä¸ªé«˜ç®±å­ï¼Œè€Œæ±½è½¦éœ€è¦ä¸€ä¸ªèƒ–ç®±å­ã€‚æˆ‘ä»¬çš„æ¨¡å‹å¦‚ä½•çŸ¥é“è¿™äº›ï¼Ÿè¿™æ˜¯é€šè¿‡ä¸åŒå°ºå¯¸çš„é”šç®±å®ç°çš„ã€‚è¿™æ„å‘³ç€æ‰€æœ‰å¯¹è±¡éƒ½æœ‰ä¸æ­¢ä¸€ä¸ªè¾¹ç•Œæ¡†ã€‚ä¸ºäº†å†³å®šä¿ç•™å“ªä¸ªè¾¹ç•Œæ¡†ï¼Œä½¿ç”¨äº†éæœ€å¤§æŠ‘åˆ¶ã€‚å½“ä¸åŒå¯¹è±¡çš„ä¸­å¿ƒåœ¨åŒä¸€ä½ç½®æ—¶ï¼Œé”šå®šæ¡†ä¹Ÿæœ‰åŠ©äºé¢„æµ‹è¿™ä¸¤ä¸ªå¯¹è±¡ã€‚

è¡¥å……é˜…è¯»:[https://medium . com/@ anderssac/anchor-boxes-the-key-to-quality-object-detection-ddf9d 612 D4 f 9](/@andersasac/anchor-boxes-the-key-to-quality-object-detection-ddf9d612d4f9)

## éæœ€å¤§æŠ‘åˆ¶

éæœ€å¤§æŠ‘åˆ¶æˆ– NMS ä½¿ç”¨ IOU å·¥ä½œã€‚äº¤é›†è¶…è¿‡å¹¶é›†(IOU)é¡¾åæ€ä¹‰å°±æ˜¯ä¸¤ä¸ªç›’å­çš„äº¤é›†å’Œå¹¶é›†ä¹‹æ¯”ã€‚é€‰æ‹©å…·æœ‰æœ€é«˜æ£€æµ‹æ¦‚ç‡çš„ç›’å­ã€‚ç„¶åï¼Œä¸è¯¥æ¡†å…·æœ‰é«˜ IOU çš„æ‰€æœ‰æ¡†è¢«ç§»é™¤ã€‚

è¡¥å……é˜…è¯»:[https://medium . com/@ sarangzambare/object-detection-using-non-max-suppression-over-yolov 2-382 a 90212 b 51](/@sarangzambare/object-detection-using-non-max-supression-over-yolov2-382a90212b51)

# å¯†ç 

ç¬¬ä¸€ä¸ªä»»åŠ¡æ˜¯ä¸‹è½½é¢„è®­ç»ƒçš„æƒé‡ï¼Œè¿™å¯ä»¥é€šè¿‡ä½¿ç”¨ wget æ¥å®Œæˆã€‚

```
import wgeturl = '[https://pjreddie.com/media/files/yolov3.weights'](https://pjreddie.com/media/files/yolov3.weights')
yolov3 = wget.download(url, out='yolov3.weights')
```

åœ¨æ‚¨çš„å·¥ä½œç›®å½•ä¸­è¿è¡Œè¿™æ®µä»£ç å°†ä¼šåœ¨é‚£é‡Œä¿å­˜æƒé‡ã€‚

ç°åœ¨ï¼Œåœ¨å±•ç¤ºå’Œè§£é‡Šä»£ç ä¹‹å‰ï¼Œæˆ‘è¦æ„Ÿè°¢ Tensorflow 2 ä¸­ YOLO å®ç°çš„è¿™ä¸ª [Github](https://github.com/zzh8829/yolov3-tf2/) åº“ï¼Œå› ä¸ºæˆ‘å¤§éƒ¨åˆ†éƒ½æ˜¯ä»è¿™é‡Œå¤åˆ¶çš„ã€‚

è¿›è¡Œå¿…è¦çš„è¿›å£

```
import tensorflow as tf
import numpy as np
import cv2
from tensorflow.keras import Model
from tensorflow.keras.layers import (
    Add,
    Concatenate,
    Conv2D,
    Input,
    Lambda,
    LeakyReLU,
    UpSampling2D,
    ZeroPadding2D,
    BatchNormalization
)
from tensorflow.keras.regularizers import l2
```

åŠ è½½æš—ç½‘æƒé‡ï¼Œå¹¶å°†è¿™äº›æƒé‡åˆ†é…ç»™æ¨¡å‹çš„å±‚ã€‚åˆ›å»ºä¸€ä¸ªå‡½æ•°æ¥å®šä¹‰å·ç§¯å±‚ä»¥åŠæ˜¯å¦å¯¹å…¶åº”ç”¨æ‰¹é‡å½’ä¸€åŒ–ã€‚

```
def load_darknet_weights(model, weights_file):
    '''
    Helper function used to load darknet weights.

    :param model: Object of the Yolo v3 model
    :param weights_file: Path to the file with Yolo V3 weights
    '''

    #Open the weights file
    wf = open(weights_file, 'rb')
    major, minor, revision, seen, _ = np.fromfile(wf, dtype=np.int32, count=5)#Define names of the Yolo layers (just for a reference)    
    layers = ['yolo_darknet',
            'yolo_conv_0',
            'yolo_output_0',
            'yolo_conv_1',
            'yolo_output_1',
            'yolo_conv_2',
            'yolo_output_2']for layer_name in layers:
        sub_model = model.get_layer(layer_name)
        for i, layer in enumerate(sub_model.layers):

            if not layer.name.startswith('conv2d'):
                continue

            #Handles the special, custom Batch normalization layer
            batch_norm = None
            if i + 1 < len(sub_model.layers) and \
                    sub_model.layers[i + 1].name.startswith('batch_norm'):
                batch_norm = sub_model.layers[i + 1]filters = layer.filters
            size = layer.kernel_size[0]
            in_dim = layer.input_shape[-1]if batch_norm is None:
                conv_bias = np.fromfile(wf, dtype=np.float32, count=filters)
            else:
                # darknet [beta, gamma, mean, variance]
                bn_weights = np.fromfile(
                    wf, dtype=np.float32, count=4 * filters)
                # tf [gamma, beta, mean, variance]
                bn_weights = bn_weights.reshape((4, filters))[[1, 0, 2, 3]]# darknet shape (out_dim, in_dim, height, width)
            conv_shape = (filters, in_dim, size, size)
            conv_weights = np.fromfile(
                wf, dtype=np.float32, count=np.product(conv_shape))
            # tf shape (height, width, in_dim, out_dim)
            conv_weights = conv_weights.reshape(
                conv_shape).transpose([2, 3, 1, 0])if batch_norm is None:
                layer.set_weights([conv_weights, conv_bias])
            else:
                layer.set_weights([conv_weights])
                batch_norm.set_weights(bn_weights)assert len(wf.read()) == 0, 'failed to read all data'
    wf.close()def DarknetConv(x, filters, kernel_size, strides=1, batch_norm=True):
    '''
    Call this function to define a single Darknet convolutional layer

    :param x: inputs
    :param filters: number of filters in the convolutional layer
    :param kernel_size: Size of kernel in the Conv layer
    :param strides: Conv layer strides
    :param batch_norm: Whether or not to use the custom batch norm layer.
    '''
    #Image padding
    if strides == 1:
        padding = 'same'
    else:
        x = ZeroPadding2D(((1, 0), (1, 0)))(x)  # top left half-padding
        padding = 'valid'

    #Defining the Conv layer
    x = Conv2D(filters=filters, kernel_size=kernel_size,
               strides=strides, padding=padding,
               use_bias=not batch_norm, kernel_regularizer=l2(0.0005))(x)

    if batch_norm:
        x = BatchNormalization()(x)
        x = LeakyReLU(alpha=0.1)(x)
    return x
```

åˆ›å»ºå‡½æ•°æ¥å®šä¹‰æš—ç½‘æ®‹å·®å±‚å’Œæš—ç½‘å—ï¼Œå®ƒä»¬å°†ä½ ä¸Šé¢åˆ›å»ºçš„å·ç§¯å±‚ï¼Œç„¶åæ˜¯ä¸€ä¸ªå‡½æ•°æ¥ä½¿ç”¨å®ƒä»¬å¹¶åˆ›å»ºæ•´ä¸ªæš—ç½‘æ¨¡å‹ã€‚

```
def DarknetResidual(x, filters):
    '''
    Call this function to define a single DarkNet Residual layer

    :param x: inputs
    :param filters: number of filters in each Conv layer.
    '''
    prev = x
    x = DarknetConv(x, filters // 2, 1)
    x = DarknetConv(x, filters, 3)
    x = Add()([prev, x])
    return x

def DarknetBlock(x, filters, blocks):
    '''
    Call this function to define a single DarkNet Block (made of multiple Residual layers)

    :param x: inputs
    :param filters: number of filters in each Residual layer
    :param blocks: number of Residual layers in the block
    '''
    x = DarknetConv(x, filters, 3, strides=2)
    for _ in range(blocks):
        x = DarknetResidual(x, filters)
    return xdef Darknet(name=None):
    '''
    The main function that creates the whole DarkNet.
    '''
    x = inputs = Input([None, None, 3])
    x = DarknetConv(x, 32, 3)
    x = DarknetBlock(x, 64, 1)
    x = DarknetBlock(x, 128, 2)  # skip connection
    x = x_36 = DarknetBlock(x, 256, 8)  # skip connection
    x = x_61 = DarknetBlock(x, 512, 8)
    x = DarknetBlock(x, 1024, 4)
    return tf.keras.Model(inputs, (x_36, x_61, x), name=name)
```

ç°åœ¨ï¼Œæˆ‘ä»¬éœ€è¦ä¸º YOLOv3 æ¨¡å‹åˆ›å»ºè¾…åŠ©å‡½æ•°ï¼Œä»¥å®šä¹‰ YOLOv3 å·ç§¯å±‚ã€YOLO æ¨¡å‹çš„è¾“å‡ºã€ç»˜åˆ¶è¾“å‡ºã€æ ¹æ®é¢„æµ‹åˆ›å»ºè¾¹ç•Œæ¡†ä»¥åŠéæœ€å¤§æŠ‘åˆ¶å‡½æ•°ã€‚æˆ‘ä»¬è¿˜éœ€è¦å®šä¹‰æˆ‘ä»¬çš„é”šç›’ï¼Œå¹¶æœ€ç»ˆåˆ›å»ºä¸€ä¸ªå‡½æ•°æ¥ç»„åˆæ‰€æœ‰çš„é”šç›’ï¼Œä»¥ç”Ÿæˆæˆ‘ä»¬çš„æ¨¡å‹ã€‚

```
def draw_outputs(img, outputs, class_names):
    '''
    Helper, util, function that draws predictons on the image.

    :param img: Loaded image
    :param outputs: YoloV3 predictions
    :param class_names: list of all class names found in the dataset
    '''
    boxes, objectness, classes, nums = outputs
    boxes, objectness, classes, nums = boxes[0], objectness[0], classes[0], nums[0]
    wh = np.flip(img.shape[0:2])
    for i in range(nums):
        x1y1 = tuple((np.array(boxes[i][0:2]) * wh).astype(np.int32))
        x2y2 = tuple((np.array(boxes[i][2:4]) * wh).astype(np.int32))
        img = cv2.rectangle(img, x1y1, x2y2, (255, 0, 0), 2)
        img = cv2.putText(img, '{} {:.4f}'.format(
            class_names[int(classes[i])], objectness[i]),
            x1y1, cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (0, 0, 255), 2)
    return imgyolo_anchors = np.array([(10, 13), (16, 30), (33, 23), (30, 61), (62, 45),
                         (59, 119), (116, 90), (156, 198), (373, 326)],
                        np.float32) / 416yolo_anchor_masks = np.array([[6, 7, 8], [3, 4, 5], [0, 1, 2]])
def YoloConv(filters, name=None):
    '''
    Call this function to define the Yolo Conv layer.

    :param flters: number of filters for the conv layer
    :param name: name of the layer
    '''
    def yolo_conv(x_in):
        if isinstance(x_in, tuple):
            inputs = Input(x_in[0].shape[1:]), Input(x_in[1].shape[1:])
            x, x_skip = inputs# concat with skip connection
            x = DarknetConv(x, filters, 1)
            x = UpSampling2D(2)(x)
            x = Concatenate()([x, x_skip])
        else:
            x = inputs = Input(x_in.shape[1:])x = DarknetConv(x, filters, 1)
        x = DarknetConv(x, filters * 2, 3)
        x = DarknetConv(x, filters, 1)
        x = DarknetConv(x, filters * 2, 3)
        x = DarknetConv(x, filters, 1)
        return Model(inputs, x, name=name)(x_in)
    return yolo_convdef YoloOutput(filters, anchors, classes, name=None):
    '''
    This function defines outputs for the Yolo V3\. (Creates output projections)

    :param filters: number of filters for the conv layer
    :param anchors: anchors
    :param classes: list of classes in a dataset
    :param name: name of the layer
    '''
    def yolo_output(x_in):
        x = inputs = Input(x_in.shape[1:])
        x = DarknetConv(x, filters * 2, 3)
        x = DarknetConv(x, anchors * (classes + 5), 1, batch_norm=False)
        x = Lambda(lambda x: tf.reshape(x, (-1, tf.shape(x)[1], tf.shape(x)[2],
                                            anchors, classes + 5)))(x)
        return tf.keras.Model(inputs, x, name=name)(x_in)
    return yolo_outputdef yolo_boxes(pred, anchors, classes):
    '''
    Call this function to get bounding boxes from network predictions

    :param pred: Yolo predictions
    :param anchors: anchors
    :param classes: List of classes from the dataset
    '''

    # pred: (batch_size, grid, grid, anchors, (x, y, w, h, obj, ...classes))
    grid_size = tf.shape(pred)[1]
    #Extract box coortinates from prediction vectors
    box_xy, box_wh, objectness, class_probs = tf.split(
        pred, (2, 2, 1, classes), axis=-1)#Normalize coortinates
    box_xy = tf.sigmoid(box_xy)
    objectness = tf.sigmoid(objectness)
    class_probs = tf.sigmoid(class_probs)
    pred_box = tf.concat((box_xy, box_wh), axis=-1)  # original xywh for loss# !!! grid[x][y] == (y, x)
    grid = tf.meshgrid(tf.range(grid_size), tf.range(grid_size))
    grid = tf.expand_dims(tf.stack(grid, axis=-1), axis=2)  # [gx, gy, 1, 2]box_xy = (box_xy + tf.cast(grid, tf.float32)) / \
        tf.cast(grid_size, tf.float32)
    box_wh = tf.exp(box_wh) * anchorsbox_x1y1 = box_xy - box_wh / 2
    box_x2y2 = box_xy + box_wh / 2
    bbox = tf.concat([box_x1y1, box_x2y2], axis=-1)return bbox, objectness, class_probs, pred_boxdef yolo_nms(outputs, anchors, masks, classes):
    # boxes, conf, type
    b, c, t = [], [], []for o in outputs:
        b.append(tf.reshape(o[0], (tf.shape(o[0])[0], -1, tf.shape(o[0])[-1])))
        c.append(tf.reshape(o[1], (tf.shape(o[1])[0], -1, tf.shape(o[1])[-1])))
        t.append(tf.reshape(o[2], (tf.shape(o[2])[0], -1, tf.shape(o[2])[-1])))bbox = tf.concat(b, axis=1)
    confidence = tf.concat(c, axis=1)
    class_probs = tf.concat(t, axis=1)scores = confidence * class_probs
    boxes, scores, classes, valid_detections = tf.image.combined_non_max_suppression(
        boxes=tf.reshape(bbox, (tf.shape(bbox)[0], -1, 1, 4)),
        scores=tf.reshape(
        scores, (tf.shape(scores)[0], -1, tf.shape(scores)[-1])),
        max_output_size_per_class=100,
        max_total_size=100,
        iou_threshold=0.5,
        score_threshold=0.6
    )return boxes, scores, classes, valid_detectionsdef YoloV3(size=None, channels=3, anchors=yolo_anchors,
           masks=yolo_anchor_masks, classes=80):

    x = inputs = Input([size, size, channels], name='input')x_36, x_61, x = Darknet(name='yolo_darknet')(x)x = YoloConv(512, name='yolo_conv_0')(x)
    output_0 = YoloOutput(512, len(masks[0]), classes, name='yolo_output_0')(x)x = YoloConv(256, name='yolo_conv_1')((x, x_61))
    output_1 = YoloOutput(256, len(masks[1]), classes, name='yolo_output_1')(x)x = YoloConv(128, name='yolo_conv_2')((x, x_36))
    output_2 = YoloOutput(128, len(masks[2]), classes, name='yolo_output_2')(x)boxes_0 = Lambda(lambda x: yolo_boxes(x, anchors[masks[0]], classes),
                     name='yolo_boxes_0')(output_0)
    boxes_1 = Lambda(lambda x: yolo_boxes(x, anchors[masks[1]], classes),
                     name='yolo_boxes_1')(output_1)
    boxes_2 = Lambda(lambda x: yolo_boxes(x, anchors[masks[2]], classes),
                     name='yolo_boxes_2')(output_2)outputs = Lambda(lambda x: yolo_nms(x, anchors, masks, classes),
                     name='yolo_nms')((boxes_0[:3], boxes_1[:3], boxes_2[:3]))return Model(inputs, outputs, name='yolov3')
```

ç°åœ¨æ‰€æœ‰çš„å‡½æ•°éƒ½å®šä¹‰å¥½äº†ï¼Œæ˜¯æ—¶å€™åˆ›å»ºä¸€ä¸ª YOLOv3 æ¨¡å‹äº†ï¼Œå¯ä»¥ä½¿ç”¨:

```
yolo = YoloV3()
load_darknet_weights(yolo, 'yolov3.weights')
```

å¯åŠ¨ç½‘ç»œæ‘„åƒå¤´ï¼Œè®©æ¯ä¸€å¸§éƒ½ä¸ºé¢„æµ‹åšå¥½å‡†å¤‡ã€‚å½“æˆ‘ä»¬ä½¿ç”¨ OpenCV æ—¶ï¼Œæˆ‘ä»¬éœ€è¦å°†æˆ‘ä»¬çš„å›¾åƒè½¬æ¢ä¸º RGBï¼Œå°†å®ƒä»¬çš„å¤§å°è°ƒæ•´ä¸º 320x320 æˆ– 416x416 æˆ– 608x608ï¼Œå°†å®ƒä»¬çš„æ•°æ®ç±»å‹è½¬æ¢ä¸º float32ï¼Œå°†å®ƒä»¬æ‰©å±•ä¸ºå››ç»´å¹¶é™¤ä»¥ 255ã€‚

```
cap = cv2.VideoCapture(0)
while(True):
    ret, image = cap.read()
    if ret==True:
        img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        img = cv2.resize(img, (320, 320))
        img = img.astype(np.float32)
        img = np.expand_dims(img, 0)
        img = img / 255
```

ä½¿ç”¨ yolo è·å¾—å›¾åƒä¸Šçš„é¢„æµ‹ã€‚åŠ è½½ç±»åæ–‡ä»¶ï¼Œå…¶ä¸­åŒ…å«ä¸ºå…¶è®­ç»ƒæ¨¡å‹çš„æ‰€æœ‰å¯¹è±¡åã€‚è¿™é‡Œå¯ä»¥æ‰¾åˆ°[ã€‚æ‚¨å¯ä»¥ç»˜åˆ¶è¾“å‡ºæ¥æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·¥ä½œã€‚](https://github.com/vardanagarwal/Proctoring-AI/blob/master/models/classes.TXT)

```
boxes, scores, classes, nums = yolo(img)
class_names = [c.strip() for c in open("classes.txt").readlines()]
image = draw_outputs(image, (boxes, scores, classes, nums), class_names)
cv2.imshow('Prediction', image)
if cv2.waitKey(1) & 0xFF == ord('q'):
    break
```

![](img/f2e0cf2fca48b3f135133ba57d003322.png)

ä½¿ç”¨ YOLOv3 è¿›è¡Œé¢„æµ‹

ç°åœ¨ï¼Œä¸ºäº†ç»Ÿè®¡ classes.txt ä¸­çš„äººå‘˜æˆ–ä»»ä½•å†…å®¹ï¼Œæˆ‘ä»¬éœ€è¦çŸ¥é“å®ƒåœ¨å…¶ä¸­çš„ç´¢å¼•ã€‚person çš„ç´¢å¼•æ˜¯ 0ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦æ£€æŸ¥é¢„æµ‹çš„ç±»æ˜¯å¦æ˜¯ 0ï¼Œç„¶åæˆ‘ä»¬å¢åŠ ä¸€ä¸ªè®¡æ•°å™¨ã€‚

```
count=0
for i in range(nums[0]):
    if int(classes[0][i] == 0):
        count +=1print('Number of people:', count)
```

ä½ å¯ä»¥åœ¨æˆ‘çš„ [Github repo](https://github.com/vardanagarwal/Proctoring-AI) ä¸Šæ‰¾åˆ°å®Œæ•´çš„ä»£ç ã€‚