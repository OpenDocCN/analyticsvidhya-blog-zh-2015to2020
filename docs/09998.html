<html>
<head>
<title>Probability and Likelihood</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">概率和可能性</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/probability-and-likelihood-b62f015b65ce?source=collection_archive---------6-----------------------#2020-09-29">https://medium.com/analytics-vidhya/probability-and-likelihood-b62f015b65ce?source=collection_archive---------6-----------------------#2020-09-29</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/ceedd5ce75554e5904f6d18811315405.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*uEQKj7cOr0cSLGaj"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">照片由<a class="ae iu" href="https://unsplash.com/@mvds?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Mads Schmidt Rasmussen </a>在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="1cc5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">概率是某些事件的确切结果。你可能知道一个事件发生的结果是什么。然而，很可能你对结果并不确定。这里的结果取决于各种因素。比如说，在一场比赛中，两个队之间发生掷硬币的事件；现在，掷硬币的结果不是正面就是反面。假设一个队选择了头，他赢得了掷硬币，那么获胜队选择击球的概率将是0.5或。这里我们知道确切的结果。现在，可能性并没有给出直接的答案，我们知道选择为获胜队击球的概率是0.5。但是我们确定或者肯定赢的队会先击球吗？可能性来了；他们首先击球的队的可能性有多大？这取决于很多因素:比如球场的条件；无论是干燥还是潮湿，天气状况，哪个球员在对面的队里？有弱点，有力量，还有许多其他的东西。</p><p id="a259" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如果这些条件不利于获胜队，他们会选择先放弃击球，或者我们可以说他们选择先击球的可能性会非常非常小，如果上述条件对他们有利，那么他们先击球的可能性会更大。因此，正如概率给你直接的答案一样，可能性取决于各种条件和参数。概率值的范围从0到1，但可能性的结果没有确定性。可能性告诉我们一个事件发生的可能性有多大。</p><p id="a9b2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们通过<a class="ae iu" href="https://en.wikipedia.org/wiki/Binomial_distribution" rel="noopener ugc nofollow" target="_blank">二项式分布</a>来理解这种可能性:</p><p id="d13a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><a class="ae iu" href="https://en.wikipedia.org/wiki/Binomial_distribution" rel="noopener ugc nofollow" target="_blank">二项式分布</a>是离散概率分布。当满足以下条件时，称随机变量X服从二项分布:</p><p id="e0d4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">1)随机变量只有两种结果。</p><p id="c160" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="jt">成败(结果的结果)</em></p><p id="a9cc" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="jt">头还是尾(扔硬币)</em></p><p id="96e2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="jt">欺诈索赔或真实索赔(欺诈保险索赔)</em></p><p id="7d9e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="jt">违约或不违约(贷款还款违约)</em></p><p id="4b8e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">2)目标是找出n次试验中x次成功的概率。</p><p id="866e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">3)成功的概率为p，失败的概率为(1-p)。</p><p id="493c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">4)概率p是常数，不随试验而变化。</p><p id="1611" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">二项分布的概率质量函数(PMF )( n次试验中成功次数恰好为x的概率)由下式给出:</p><figure class="jv jw jx jy fd ij er es paragraph-image"><div class="er es ju"><img src="../Images/aaa5787978d2db7aead4e544cd40e825.png" data-original-src="https://miro.medium.com/v2/resize:fit:1210/format:webp/1*zV5NLqTZ1NzcPrGeTaTxJQ.png"/></div></figure><p id="57fc" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">二项式分布的累积分布函数(CDF )( n次试验中成功次数为x或小于x的概率)由下式给出:</p><figure class="jv jw jx jy fd ij er es paragraph-image"><div class="er es jz"><img src="../Images/13b6ad3f66fc8b9b536d93cd8e822457.png" data-original-src="https://miro.medium.com/v2/resize:fit:1182/format:webp/1*7EcRg2uo1Jvv1M6PcPu7Mg.png"/></div></figure><p id="a5cc" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，回到我们的案例。可能性是条件概率。我们知道抛硬币的结果要么是正面，要么是反面，各有0.5的概率。如果我们把同一个硬币抛10次，比方说，10次中有7次是正面，3次是反面。从二项分布，我们可以计算可能性；</p><figure class="jv jw jx jy fd ij er es paragraph-image"><div class="er es ka"><img src="../Images/cb7df8ffaac3bcebd76d5935e2a90a36.png" data-original-src="https://miro.medium.com/v2/resize:fit:980/format:webp/1*ewEEugkZd03pFm0hMJkE5g.png"/></div></figure><p id="7e6c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如果结果是头出现的概率为0.5，头出现7次的可能性。</p><p id="6671" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">d是观察数据集，θ是似然函数的参数。</p><p id="3933" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">可能性是已经发生的事件会产生特定结果的可能性。然而，概率是指将来会发生的事件。如果硬币被抛了一定的次数，并且是一枚公平的硬币，那么每次硬币落地时会出现正面朝上的概率是多少。概率用于描述给定固定参数的结果函数。这里的函数是每次硬币落地时产生的，给定一个固定的参数，硬币是公平的。</p><p id="54cc" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">然而，可能性恰恰相反。可能性是描述给定固定结果的参数函数。如果硬币被抛了一定次数，每次落地都是正面朝上，那么硬币是公平的概率是多少？这里的固定参数是抛硬币的结果，函数是硬币是否公平？</p><figure class="jv jw jx jy fd ij er es paragraph-image"><div class="er es kb"><img src="../Images/88d17d77da0eda2aa4201b6cce7cd71b.png" data-original-src="https://miro.medium.com/v2/resize:fit:720/format:webp/1*xWQbzkJouQLAdGCh2OA5nw.png"/></div></figure><p id="8df2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="jt">你也可以阅读我在Medium上的其他文章:</em></p><div class="kc kd ez fb ke kf"><a rel="noopener follow" target="_blank" href="/analytics-vidhya/bias-variance-trade-off-2f3146700f5a"><div class="kg ab dw"><div class="kh ab ki cl cj kj"><h2 class="bd hj fi z dy kk ea eb kl ed ef hh bi translated">偏差-方差权衡</h2><div class="km l"><h3 class="bd b fi z dy kk ea eb kl ed ef dx translated">有监督的学习可以在偏差-方差权衡的帮助下得到最好的理解。任何模型的主要目的来…</h3></div><div class="kn l"><p class="bd b fp z dy kk ea eb kl ed ef dx translated">medium.com</p></div></div><div class="ko l"><div class="kp l kq kr ks ko kt io kf"/></div></div></a></div><div class="kc kd ez fb ke kf"><a rel="noopener follow" target="_blank" href="/analytics-vidhya/linear-regression-and-fitting-a-line-to-a-data-6dfd027a0fe2"><div class="kg ab dw"><div class="kh ab ki cl cj kj"><h2 class="bd hj fi z dy kk ea eb kl ed ef hh bi translated">线性回归和对数据进行直线拟合</h2><div class="km l"><h3 class="bd b fi z dy kk ea eb kl ed ef dx translated">线性回归是预测连续值输出的监督机器学习算法。在线性…</h3></div><div class="kn l"><p class="bd b fp z dy kk ea eb kl ed ef dx translated">medium.com</p></div></div><div class="ko l"><div class="ku l kq kr ks ko kt io kf"/></div></div></a></div><div class="kc kd ez fb ke kf"><a rel="noopener follow" target="_blank" href="/analytics-vidhya/an-introduction-to-time-series-analysis-2a12d3702299"><div class="kg ab dw"><div class="kh ab ki cl cj kj"><h2 class="bd hj fi z dy kk ea eb kl ed ef hh bi translated">时间序列分析导论</h2><div class="km l"><h3 class="bd b fi z dy kk ea eb kl ed ef dx translated">通过这篇文章，我们将了解:</h3></div><div class="kn l"><p class="bd b fp z dy kk ea eb kl ed ef dx translated">medium.com</p></div></div><div class="ko l"><div class="kv l kq kr ks ko kt io kf"/></div></div></a></div><p id="fcdc" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi kw translated"><span class="l kx ky kz bm la lb lc ld le di">B</span><strong class="ix hj">T5】ayesian或frequent istT7】</strong></p><p id="9159" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><a class="ae iu" href="https://www.youtube.com/watch?v=GEFxFVESQXc" rel="noopener ugc nofollow" target="_blank"> <em class="jt">这个视频帮助我很好的理解了这个概念:</em> </a></p><p id="86b6" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这可能会让你有点困惑，但是耐心点，一切都会好的。我们很多人一定听说过量子物理中的<a class="ae iu" href="https://en.wikipedia.org/wiki/Schr%C3%B6dinger's_cat" rel="noopener ugc nofollow" target="_blank"> <strong class="ix hj"> <em class="jt">薛定谔的猫实验</em> </strong> </a>。如果没有，我来解释一下:把一只猫放在一个封闭的盒子里，盒子里有一点点放射性物质。当放射性物质衰变时，它会变成一种毒药或一次小爆炸，导致猫死于此。但是，这里有一个问题:由于猫和放射性物质被封闭在一个密封的盒子里，我们不知道猫是死是活，直到我们打开盒子。</p><p id="cf81" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，回到硬币的问题:如果我们把硬币扔出去，拿在手里，或者闭上眼睛，看不到硬币落地的结果；那么硬币落地的概率是多少？现在，有两种情况:</p><p id="ee11" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> <em class="jt">情况一</em> </strong> —我们可以说，人头拿到的概率会是0.5。</p><p id="f00e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> <em class="jt">案例二— </em> </strong>我们可以说，当我们还没看到结果或硬币落地，事件已经发生。得到正面的概率要么是100%，要么是零，以防我们得到反面(就像我们可以说的薛定谔的硬币)。</p><p id="fbf8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">案例一，这里是<a class="ae iu" href="https://en.wikipedia.org/wiki/Bayesian_statistics" rel="noopener ugc nofollow" target="_blank"> <strong class="ix hj">贝叶斯统计</strong> </a>。如果我们遵循贝叶斯统计；我们可能有自己的观点。得到人头的可能性是50%。</p><p id="8039" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">案例二，这是常客。我们的观点是不是并不重要；我们在这里遵循事实，事实是硬币已经落地，我们说什么都不重要，结果已经写好了。如果是正面，那么概率将是100 %,如果是反面，概率将是零。</p><p id="2d34" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> <em class="jt">记得到现在，我们还没有看到结果。它是隐藏的。贝叶斯会说，得到正面的概率是50 %,而Frequentist会说，硬币已经落地了，所以我们说什么都不重要；事实是——如果是正面，那么概率将是100 %,否则为零。</em> </strong></p><p id="1d82" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们已经看到贝叶斯和频率主义者。现在的问题是，哪一个是对的，哪一个是错的，我们应该遵循哪一个？这里的重点不是哪种方法是对的或错的；从他们自己的角度来看，他们都同样正确。</p><p id="2e75" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">贝叶斯遵从他们的意见；他们不寻求真理。对他们来说，总有一个事件的结果。他们永远不会错。</p><p id="9256" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">但是常客追求结果的质量。结果的真正价值。如果该事件发生多次，则发生100%结果的可能性会大于0 %,反之亦然。</p><p id="3a82" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如果我们想根据我们的观点进行实验，看看实验进行的如何，我们可以选择贝叶斯。如果，在对结果的无知和我们实验的质量总是正确的情况下，那么我们就走频率主义的道路。如果我们的实验是正确的，那就没问题，但如果我们失败了，我们可以根据我们的证据改变场景和我们之前采取的行动。我们来看看实验的质量。</p><p id="8e7e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">贝叶斯统计是似然的条件概率，概率模型是指频数。</p><p id="c74d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi kw translated"><span class="l kx ky kz bm la lb lc ld le di">P</span><strong class="ix hj">T3】参数估计T5】</strong></p><p id="8deb" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">StatQuest帮助我很好地理解了它。T9】</p><p id="6711" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><a class="ae iu" href="https://home.aero.polimi.it/lovera/ea/1_3.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="jt">你也可以跟着这篇论文去了解更多细节。</em>T13】</a></p><p id="61f3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">参数估计的必要性是什么？估计器有助于估计数据集中独立特征的参数值，以了解独立特征和响应(目标变量)之间的关系，并最小化成本函数以提高模型的准确性。</p><p id="6f3e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">有许多类型的估计量。在这里，我将讨论最大似然估计和贝叶斯估计。</p><p id="ee4b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">最大似然估计</strong></p><p id="5a60" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">最大似然估计(MLE)是通过最大化似然函数来寻找最可能的观测数据，从而估计概率函数参数的估计方法。我们在数据的正态分布(高斯分布)中使用MLE，以均值和方差为参数，取高斯函数的导数，通过最大化得到计算均值和方差的函数。最大似然估计使用数据的概率模型。</p><p id="f17c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> <em class="jt">二项分布的最大似然</em> </strong></p><p id="e200" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">比方说，我们随机选择一组人，问他们，他们更喜欢漫威漫画还是DC扩展宇宙漫画。很少有人选择漫威，其余的人选择DC扩展宇宙。</p><figure class="jv jw jx jy fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lf"><img src="../Images/d3acf802ae735d66d5ebc9d92a003adb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*upFpO_w7KwknT2v1S7mNRQ.png"/></div></div></figure><p id="27e4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">p= 0.5的可能性有多大？</p><p id="2ff7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">p(选择漫威的概率)的可能性，给定n=10(被问人数)，x=7(选择漫威的人数)。</p><figure class="jv jw jx jy fd ij er es paragraph-image"><div class="er es lg"><img src="../Images/3782b10efb0e056b1227c98ac8b3ff5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1110/format:webp/1*SHDL6oVw1Epw9W6o-Fs1Cw.png"/></div></figure><p id="18ad" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> <em class="jt">求导求最大似然。</em> </strong></p><figure class="jv jw jx jy fd ij er es paragraph-image"><div class="er es lh"><img src="../Images/125ce97ac2bad70e6102897d5cd27c71.png" data-original-src="https://miro.medium.com/v2/resize:fit:1330/format:webp/1*SgNBK3OgGh2og4pWQev20g.png"/></div></figure><p id="cf7d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">p的最大似然估计是平均值。</p><p id="45bf" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> <em class="jt">正态分布的最大似然</em> </strong></p><figure class="jv jw jx jy fd ij er es paragraph-image"><div class="er es li"><img src="../Images/3e3f80eef1faa659abab483465398a96.png" data-original-src="https://miro.medium.com/v2/resize:fit:1064/format:webp/1*kyTGaQda8nRQYLiBafYCfg.png"/></div></figure><p id="2638" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">关于μ(平均值)的对数似然函数:</p><figure class="jv jw jx jy fd ij er es paragraph-image"><div class="er es lj"><img src="../Images/97097cb29fdf46420af3a832d460375a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1178/format:webp/1*bgtfgmJWByNVymWkSUxePw.png"/></div></figure><p id="895c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">关于sigma(标准偏差)的对数似然函数:</p><figure class="jv jw jx jy fd ij er es paragraph-image"><div class="er es lk"><img src="../Images/44442da7a684ec03acb33e45f7e30b2c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1348/format:webp/1*ktdkV5vCvOmnbohIBs7tPw.png"/></div></figure><p id="ca60" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">高斯分布中心位置的最大似然估计:</p><figure class="jv jw jx jy fd ij er es paragraph-image"><div class="er es ll"><img src="../Images/390db18cffb2228671c60d5403420b29.png" data-original-src="https://miro.medium.com/v2/resize:fit:764/format:webp/1*jwcHM_Qykc5DIDR9OeKrVQ.png"/></div></figure><p id="faf4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">高斯曲线宽度的最大似然估计:</p><figure class="jv jw jx jy fd ij er es paragraph-image"><div class="er es lm"><img src="../Images/124c653361cd12f318ffca7d4074baa7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*xo1Z1Bq98WUdxa8Og1VptQ.png"/></div></figure><p id="be1c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> <em class="jt">贝叶斯估计:</em> </strong></p><p id="2ba5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">贝叶斯估计或最大后验概率(MAP)估计最小化损失函数的后验期望值。它作用于后验分布，而不仅仅是可能性。我们可以将后验概率作为似然函数和先验函数的乘积。贝叶斯定理基于已知先验函数的概念。当两个事件发生时(事件A和B)，一个事件发生的概率基于另一个已经发生的事件。</p><figure class="jv jw jx jy fd ij er es paragraph-image"><div class="er es ln"><img src="../Images/9ba315fb9faf532466863f25d4a6e7d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:788/format:webp/1*nDh93BDN_lMiWlrzmHxFYw.png"/></div></figure><p id="8019" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">对于贝叶斯估计的推导部分，我们可以按照<a class="ae iu" href="https://en.wikipedia.org/wiki/Bayes_estimator" rel="noopener ugc nofollow" target="_blank"> <strong class="ix hj"> <em class="jt">维基</em> </strong> </a>来理解，因为它不太复杂。我们也可以按照<strong class="ix hj"><em class="jt"/></strong><a class="ae iu" href="https://wiseodd.github.io/techblog/2017/01/01/mle-vs-map/" rel="noopener ugc nofollow" target="_blank"><strong class="ix hj"><em class="jt">这篇文章</em> </strong> </a>对它进行详细的解释。这里有<a class="ae iu" href="https://www.ics.uci.edu/~smyth/courses/cs274/readings/bayesian_regression_overview.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="ix hj"> <em class="jt">另一个</em> </strong> </a>帮助我更好地理解，但这需要时间来消化。</p></div><div class="ab cl lo lp gp lq" role="separator"><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt lu"/><span class="lr bw bk ls lt"/></div><div class="hb hc hd he hf"><p id="c522" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如果这里写错了什么或者想补充什么，请在这里帮我改正。因为我也是一个初学者，这只是我学到的。关于这个话题还有很多要学的。如果你知道更多简单的贝叶斯统计方法，请告诉我。积极的批评是非常鼓励的。</p></div></div>    
</body>
</html>