<html>
<head>
<title>How I built a web scraper in Python to get car prices</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">我如何用Python构建一个web scraper来获取汽车价格</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/scraping-car-prices-using-python-97086c30cd65?source=collection_archive---------4-----------------------#2020-01-02">https://medium.com/analytics-vidhya/scraping-car-prices-using-python-97086c30cd65?source=collection_archive---------4-----------------------#2020-01-02</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/5472ffb99b316fd8f434b73c3465063a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cXvdQk918gy3FYjReUGLSg.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">扎卡里亚·扎亚恩在<a class="ae iu" href="https://unsplash.com/s/photos/new-car?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="6507" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">从几天前我已经决定寻找我的第一辆车，这是一项艰巨的任务，如果你不知道很多关于汽车规格和其他与汽车市场相关的事情，我决定利用这种情况来提高我的Python技能，通过创建一个web scraper从网站上获取汽车信息和价格，这将允许我进行比较并做出决定。</p><p id="b947" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在这篇文章中，我想告诉你如何从哥伦比亚(我住的地方)的一个主要汽车销售商网站上收集所有搜索结果，并建立一个包含所有找到的列表的数据库。被刮掉的网站名字叫<a class="ae iu" href="https://www.carroya.com/" rel="noopener ugc nofollow" target="_blank">卡萝亚</a>。</p><p id="9619" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">开始之前，我将使用过滤器页面，我可以指定一些参数(如城市，汽车类型，最高价格等。)来缩减整个结果列表。</p><figure class="ju jv jw jx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es jt"><img src="../Images/0f0af94452c9e4c13b674f0fc73d6c48.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b1GNBl3LKoxjOlMX0Z8v2A.png"/></div></div></figure><h1 id="3182" class="jy jz hi bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">入门指南</h1><p id="8398" class="pw-post-body-paragraph iv iw hi ix b iy kw ja jb jc kx je jf jg ky ji jj jk kz jm jn jo la jq jr js hb bi translated">我们需要导入一些模块来处理html数据。我将使用Beautiful Soup来解析我所检查的网站的HTML文档。此外，我们需要验证网站是否允许我们通过查看url中的“robot.txt”文档来删除内容，您可以通过在网站url中添加“/robot.txt”来完成此操作。</p><p id="b40e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">有些网站会自动阻止任何形式的抓取，然后我会定义一个头来传递<strong class="ix hj"> <em class="lb"> get </em> </strong>命令，让我们的查询看起来像是来自一个真实的浏览器。当我在页面之间运行程序时，我也会使用sleep命令，这将有助于这个过程看起来更自然。</p><pre class="ju jv jw jx fd lc ld le lf aw lg bi"><span id="cde0" class="lh jz hi ld b fi li lj l lk ll">from bs4 import BeautifulSoup<br/>from requests import get<br/>import pandas as pd</span><span id="8f98" class="lh jz hi ld b fi lm lj l lk ll">headers = ({'User-Agent':<br/>            '<!-- -->Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit\<br/>/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36<!-- -->'})</span></pre><p id="5a1b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在设置我们的标题后，我将定义将用于废弃信息的基本url:</p><pre class="ju jv jw jx fd lc ld le lf aw lg bi"><span id="9a79" class="lh jz hi ld b fi li lj l lk ll">base_url =   "<a class="ae iu" href="https://www.carroya.com/buscar/vehiculos/automovil/t4v1d30c71.do#paginaActual=1" rel="noopener ugc nofollow" target="_blank">https://www.carroya.com/buscar/vehiculos/automovil/t4v1d30c71.do#paginaActual=1</a>"</span><span id="aa99" class="lh jz hi ld b fi lm lj l lk ll">response = get(base_url, headers=headers)<br/>print(response)</span></pre><p id="eab1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在定义了基本url并设置了我们的头之后，我们可以通过运行下面的代码来测试网站是否有响应。如果响应代码是200，这意味着我们的请求已经成功。</p><figure class="ju jv jw jx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ln"><img src="../Images/58e658312801723a8fd096cda2ccf6a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BLx8a5CEjCuzspBwu4BGIg.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">运行我们的代码后来自carroya网站的响应。</figcaption></figure><p id="98eb" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在我们必须定义漂亮的Soup对象来帮助我们阅读这个html。这段代码的结果将是解析器html，这是我们看到的网站的源代码。</p><figure class="ju jv jw jx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lo"><img src="../Images/871f23c876a29bdcc8e99f64a21940d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3ydE9NSzQ6qV2AOPNMnEQA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">使用BeautifulSoup命令后解析我们网站的html。</figcaption></figure><h1 id="3bbb" class="jy jz hi bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">检查网站</h1><p id="b21e" class="pw-post-body-paragraph iv iw hi ix b iy kw ja jb jc kx je jf jg ky ji jj jk kz jm jn jo la jq jr js hb bi translated">当我们抓取一个网站时，要执行的一个重要任务是用浏览器提供的开发工具检查网站，以便检查我们将要浏览的信息的架构。</p><figure class="ju jv jw jx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lp"><img src="../Images/07583e343688bab692b88470d3db06e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rc5dehtdbTc0g38IviJ1hw.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">使用浏览器提供的开发工具检查网站。</figcaption></figure><p id="0f59" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们还可以在html文档中找到某个特定对象的位置，比如汽车的价格和您想从网站上获取的其他信息。</p><figure class="ju jv jw jx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lq"><img src="../Images/20cc8c09aefd45128fb2a7f5c342c106.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Xj7q2PeZQ43gXLes6YD0nw.png"/></div></div></figure><p id="5012" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">当我们检查网站时，我们看到内容部分中的每个汽车信息都有一个类<code class="du lr ls lt ld b">car-ad sft-ad</code>,然后我决定通过使用<code class="du lr ls lt ld b">find_all</code>方法找到所有具有该类的列表项，从而通过美丽的Soup对象来查找它。</p><h1 id="a32e" class="jy jz hi bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">一些代码</h1><pre class="ju jv jw jx fd lc ld le lf aw lg bi"><span id="bb58" class="lh jz hi ld b fi li lj l lk ll">html_soup = BeautifulSoup(response.text, 'html.parser')<br/>content_list = html_soup.find_all('div', attrs={'class': 'car-ad sft-ad'})<br/>print(content_list)</span></pre><p id="eee1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">打印完<code class="du lr ls lt ld b">car_list</code>变量后，我们可以在最初几行中看到以下结构:</p><figure class="ju jv jw jx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lu"><img src="../Images/24b8c4837741fac2994b853db8d4bdb0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dVFp9KPDAp4HUx6za62N_A.png"/></div></div></figure><pre class="ju jv jw jx fd lc ld le lf aw lg bi"><span id="4f81" class="lh jz hi ld b fi li lj l lk ll">basic_info = []<br/>for item in content_list:<br/>    basic_info.append(item.find_all('div', attrs={'class': 'car-ad-info'}))<br/>print(basic_info)</span></pre><p id="322e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">输出:</p><figure class="ju jv jw jx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lv"><img src="../Images/f17790fb45824a3a70ee0b1d1eedae54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*77Szlou30iArrlNKFqT06g.png"/></div></div></figure><p id="2e32" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">从这个输出中，我们需要选择<code class="du lr ls lt ld b">car-ad-name</code>、<code class="du lr ls lt ld b">car-ad-year</code>和<code class="du lr ls lt ld b">car-ad-price</code>。为此，我决定为每个标签创建一个数组，保存来自<code class="du lr ls lt ld b">h2</code>、<code class="du lr ls lt ld b">h3</code>和<code class="du lr ls lt ld b">div</code>标签的信息，我对年份和价格也做了同样的处理。</p><pre class="ju jv jw jx fd lc ld le lf aw lg bi"><span id="fb7a" class="lh jz hi ld b fi li lj l lk ll">def get_names(basic_info):<br/>    names = []<br/>    for item in basic_info:<br/>        for i in item:<br/>            names.append(i.find_all("h2", attrs = {"class" : "car-ad-name"})[0].text.strip())<br/>    return names</span><span id="2bf3" class="lh jz hi ld b fi lm lj l lk ll">def get_years(basic_info):<br/>    years = []<br/>    for item in basic_info:<br/>        for i in item:<br/>            years.append(i.find_all("h3", attrs = {"class" : "car-ad-year"})[0].text.strip())<br/>    return years</span><span id="dc58" class="lh jz hi ld b fi lm lj l lk ll">def get_prices(basic_info):<br/>    prices = []<br/>    for item in basic_info:<br/>        for i in item:<br/>            prices.append(i.find_all("div", attrs = {"class" : "car-ad-price"})[0].string.replace(u'\xa0', u' ').strip())<br/>    return prices</span></pre><p id="d1dc" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">输出:</p><pre class="ju jv jw jx fd lc ld le lf aw lg bi"><span id="c090" class="lh jz hi ld b fi li lj l lk ll">#Names<br/>Chevrolet Sonic 1.6 Lt Sedan 2015<br/>Mazda 2 Grand Touring LX 2020<br/>Mazda 3 2.0 Sport Grand Touring Aut 2020</span><span id="1425" class="lh jz hi ld b fi lm lj l lk ll">#Prices<br/>$ 28,500,000<br/>$ 63,900,000<br/>$ 102,150,000</span><span id="7b21" class="lh jz hi ld b fi lm lj l lk ll">#Years<br/>2015<br/>2020<br/>2020</span></pre><p id="cd4f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为了提取每辆车的发动机排量和里程，我通过<code class="du lr ls lt ld b">used-specs-table</code>表创建了一个循环:</p><pre class="ju jv jw jx fd lc ld le lf aw lg bi"><span id="3d22" class="lh jz hi ld b fi li lj l lk ll">def get_motor(basic_info):<br/>    tables = []<br/>    motors = []<br/>    mileages = []<br/>    data = [motors, mileages]<br/>    for item in basic_info:<br/>        for i in item:<br/>            tables.append(i.find_all("table", attrs = {"class" : "used-specs-table"})[0])<br/>    for table in tables:<br/>        motors.append(table.find("td", attrs={"class" : "car-ad-cc"}).string)<br/>        mileages.append(table.find("td", attrs={"class" : "car-ad-km"}).string)<br/>    return data</span></pre><p id="c5d3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">输出:</p><pre class="ju jv jw jx fd lc ld le lf aw lg bi"><span id="256c" class="lh jz hi ld b fi li lj l lk ll">#Motor<br/>1600 <br/>1496 <br/>1998</span><span id="29e8" class="lh jz hi ld b fi lm lj l lk ll">#Mileages<br/>89731 Km<br/>86000 Km<br/>0 Km</span></pre><h1 id="93e8" class="jy jz hi bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">保存我们的数据</h1><p id="c023" class="pw-post-body-paragraph iv iw hi ix b iy kw ja jb jc kx je jf jg ky ji jj jk kz jm jn jo la jq jr js hb bi translated">我们应该将这些数组组织在一个数据帧中，这样我就可以将其保存为csv或excel文件，以后可以访问这些信息，而不必重复上述过程。</p><p id="cb20" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我将定义列的名称，并将数组合并到一个数据帧中。</p><pre class="ju jv jw jx fd lc ld le lf aw lg bi"><span id="40b5" class="lh jz hi ld b fi li lj l lk ll">data = pd.DataFrame({"Name" : names, "Year" : years, "Motor" : motors, "Mileage (Km)": mileages, "Price" : prices})[["Name", "Year", "Motor", "Mileage (Km)", "Price"]]<br/>data.head()<br/>data.drop_duplicates().to_excel('Car_list.xls')</span></pre><p id="088a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">输出:</p><figure class="ju jv jw jx fd ij er es paragraph-image"><div class="er es lw"><img src="../Images/a9c74c3d782d3f4dbe3f86f79428558c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1308/format:webp/1*70QiZ28j5ZgPVXY3PkD0yw.png"/></div></figure><figure class="ju jv jw jx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lx"><img src="../Images/5ff740b929a37a809f038b5e3a9a748d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lUjtqmWHpDd01bMMB5-sZw.png"/></div></div></figure><h1 id="b88f" class="jy jz hi bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">结论</h1><p id="01f9" class="pw-post-body-paragraph iv iw hi ix b iy kw ja jb jc kx je jf jg ky ji jj jk kz jm jn jo la jq jr js hb bi translated">网络抓取是从网站下载数据并从数据中提取信息的过程。当您使用Python时，它是一个有用的工具，因为它允许您开发重复的任务，并以更简单的方式检索丰富的数据。</p><p id="20fa" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">本文涵盖的代码可以从<a class="ae iu" href="https://github.com/jfdelgadovargas/web_scraping/blob/master/Web%20scraping.ipynb" rel="noopener ugc nofollow" target="_blank"> Github资源库</a>获得。</p></div><div class="ab cl ly lz gp ma" role="separator"><span class="mb bw bk mc md me"/><span class="mb bw bk mc md me"/><span class="mb bw bk mc md"/></div><div class="hb hc hd he hf"><p id="2b95" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="lb">感谢阅读！如果你有任何问题、建议或批评，可以通过评论区联系我。</em></p></div></div>    
</body>
</html>