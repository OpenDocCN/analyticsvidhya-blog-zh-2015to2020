<html>
<head>
<title>Linear Regression from Scratch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从头开始线性回归</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/linear-regression-from-scratch-98688848bd4e?source=collection_archive---------14-----------------------#2020-07-27">https://medium.com/analytics-vidhya/linear-regression-from-scratch-98688848bd4e?source=collection_archive---------14-----------------------#2020-07-27</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="7746" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">线性回归无需介绍。这是机器学习世界的“你好世界”。让我们深入探究线性回归的用例及其背后的数学直觉。</p><p id="1631" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们身处一个由数据驱动的世界。一般说，<strong class="ih hj"> </strong> <a class="ae jd" href="https://www.economist.com/leaders/2017/05/06/the-worlds-most-valuable-resource-is-no-longer-oil-but-data" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj"> <em class="je">【数据是新油】</em> </strong> </a>。回归是最重要的数据分析类型之一。回归旨在建立一个数学模型，该模型可用于根据一个<em class="je">自变量</em>的值来预测一个<em class="je">因变量</em>的值。如果你曾经在大学里上过统计学入门课程，那么你最后涉及的话题很可能是线性回归。</p></div><div class="ab cl jf jg gp jh" role="separator"><span class="ji bw bk jj jk jl"/><span class="ji bw bk jj jk jl"/><span class="ji bw bk jj jk"/></div><div class="hb hc hd he hf"><p id="58f0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">回归是机器学习中的一个基本问题，回归问题出现在各种研究领域和应用中，包括时间序列分析、控制和机器人、优化和深度学习应用。</p><p id="9d94" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">线性回归是我们工具包中最简单的监督学习算法之一。线性模型使用输入要素的线性函数进行预测。当目标向量是一个量化值(如房价、工资等)时，这是一种常见且有用的预测方法。</p><p id="e7ca" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">线性回归有两种类型，简单线性回归和多元线性回归:</p><ol class=""><li id="85fe" class="jm jn hi ih b ii ij im in iq jo iu jp iy jq jc jr js jt ju bi translated"><strong class="ih hj">一元线性回归:</strong>单个自变量用于预测因变量的值。</li><li id="ced9" class="jm jn hi ih b ii jv im jw iq jx iu jy iy jz jc jr js jt ju bi translated"><strong class="ih hj">多元线性回归:</strong>用两个或两个以上的自变量来预测因变量的值。</li></ol><p id="9b92" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">唯一的区别在于自变量的数量。在这两种情况下，只有一个因变量。为了理解和简单起见，我们将集中讨论一元线性回归。</p><p id="8a4b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">将哪些列标识为从属或独立列？</strong></p><p id="560a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">数据集的自变量不能基于数学模型等进行预测。因变量，也称为“目标值”，是我们得到的观察值。它依赖于独立变量。让我们用一个例子来理解</p><figure class="kb kc kd ke fd kf er es paragraph-image"><div role="button" tabindex="0" class="kg kh di ki bf kj"><div class="er es ka"><img src="../Images/ed1a82bb5c72c9bcbedf9ac472907932.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sm0nHxjExbflLdcdN9nOAg.png"/></div></div></figure><p id="925d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里，<strong class="ih hj">经验</strong>栏是<em class="je">自变量</em>而<strong class="ih hj">工资</strong>栏是<em class="je">因变量</em></p><p id="95ab" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们把这些数据画在图表上，使之形象化</p><figure class="kb kc kd ke fd kf er es paragraph-image"><div role="button" tabindex="0" class="kg kh di ki bf kj"><div class="er es km"><img src="../Images/85269f683df40829f2ab18a86833a666.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8I6awma1nmpyx49p6meagg.png"/></div></div></figure><p id="a975" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果我们能找到一条最佳拟合直线y=f(x ),我们就能预测出对应于x值的y值。</p><p id="6a0f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">直线方程由下式给出:</p><p id="c9d4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">y= m*x + b，</p><p id="d3c6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">其中m是斜率</p><p id="4523" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">b是截距，</p><p id="2c28" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">您可能想知道不同的线可以适合不同的斜率和截距值。那么如何在所有曲线中选择<strong class="ih hj">‘一’</strong>曲线呢？</p><p id="e7ba" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了解决这种不确定性，我们引入了误差平方和或残差平方和的概念，其公式如下</p><figure class="kb kc kd ke fd kf er es paragraph-image"><div role="button" tabindex="0" class="kg kh di ki bf kj"><div class="er es kn"><img src="../Images/f26045291a94c2abdf822e081d0badf1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jtyzyeRl_p0lfVAE9n19xw.png"/></div></div></figure><p id="6c36" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">点的残差是因变量的观测值(<em class="je"> y </em>)和预测值(<em class="je"> ŷ).)</em>高于预测值的观测值为正值，低于预测值的观测值为负值，因此我们取每个点的残差平方和，这样大的残差会受到惩罚。</p><figure class="kb kc kd ke fd kf er es paragraph-image"><div role="button" tabindex="0" class="kg kh di ki bf kj"><div class="er es ko"><img src="../Images/516bed635367aaf05679abec6f610efc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AH11fnsdgf8cdB_NB4ti5g.png"/></div></div></figure><p id="be28" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">残差平方和最小的线是<strong class="ih hj"> <em class="je">最佳拟合线。</em>T9】</strong></p><blockquote class="kp"><p id="e98d" class="kq kr hi bd ks kt ku kv kw kx ky jc dx translated">真的有必要拟合一条直线吗？为什么我们不能绘制一条拟合所有数据点的不同次数的多项式曲线？不是更可取吗？</p></blockquote><p id="e113" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">不，我们的模型有过度拟合的问题。术语<a class="ae jd" rel="noopener" href="/@martinezbielosdaniel/bias-variance-tradeoff-overfitting-and-underfitting-c63799cb4851"> <strong class="ih hj"> <em class="je">过度拟合</em> </strong> </a>指的是一个模型非常适合它用来训练的数据，但它很难概括这些数据，这意味着当面对新值时，该模型产生的结果很差。</p><p id="0bcd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们的目标是找到斜率和截距的值，使得残差平方和最小。最简单和最常见的方法是，使用普通的最小二乘法</p><p id="c634" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用<strong class="ih hj">普通最小二乘法的斜率和截距公式；</strong></p><figure class="kb kc kd ke fd kf er es paragraph-image"><div class="er es le"><img src="../Images/caf99309754d69678e5c8fd8e380630c.png" data-original-src="https://miro.medium.com/v2/resize:fit:374/format:webp/1*O_SlcKJkThbGJsiRdLiswA.png"/></div></figure><figure class="kb kc kd ke fd kf er es paragraph-image"><div class="er es lf"><img src="../Images/a14f53ecb749b04b23a93cc2d19dd00b.png" data-original-src="https://miro.medium.com/v2/resize:fit:564/format:webp/1*3nnh8AKMyzYoNm53ANAu5g.png"/></div></figure><p id="552a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们进入代码部分:</p><figure class="kb kc kd ke fd kf er es paragraph-image"><div role="button" tabindex="0" class="kg kh di ki bf kj"><div class="er es lg"><img src="../Images/b6f9c6129473b62f96d89986fb60183a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e03kysqYW9dlDXiKwFqnTg.png"/></div></div></figure><figure class="kb kc kd ke fd kf er es paragraph-image"><div role="button" tabindex="0" class="kg kh di ki bf kj"><div class="er es lh"><img src="../Images/c5a8fa519c6639c15265af2b4ed548fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FlzhUWlwbKY-UTmtY8MIyQ.png"/></div></div></figure><figure class="kb kc kd ke fd kf er es paragraph-image"><div role="button" tabindex="0" class="kg kh di ki bf kj"><div class="er es li"><img src="../Images/2cf50d5c21d5db885db106771c03bfee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JwPu2mVkDC0ZvT1Yslildw.png"/></div></div></figure><p id="f8a7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们的模型已经训练好了。让我们预测一下</p><figure class="kb kc kd ke fd kf er es paragraph-image"><div role="button" tabindex="0" class="kg kh di ki bf kj"><div class="er es lj"><img src="../Images/a0a636da046d5f69220783aea3f0414f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*01Ypng0F3JPv0T3kkgQ74A.png"/></div></div></figure><p id="d953" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Tada！！我们已经学习了线性回归的基础知识。</p></div><div class="ab cl jf jg gp jh" role="separator"><span class="ji bw bk jj jk jl"/><span class="ji bw bk jj jk jl"/><span class="ji bw bk jj jk"/></div><div class="hb hc hd he hf"><p id="0c26" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">结论:</p><p id="5248" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">普通的最小二乘法易于理解和实现，但它需要自己的甜蜜时间来训练模型。它的计算量很大。它对异常数据点很敏感。异常值有时会扭曲结果。<a class="ae jd" href="https://youtu.be/sDv4f4s2SB8" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">梯度下降</strong> </a>是另一种线性回归算法，计算速度更快，节省了大量计算时间，我们将在下一篇文章中介绍。</p></div></div>    
</body>
</html>