<html>
<head>
<title>Do You Really Know Naive Bayes?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">你真的了解朴素贝叶斯吗？</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/do-you-really-know-naive-bayes-6d5e07460aaf?source=collection_archive---------24-----------------------#2020-12-22">https://medium.com/analytics-vidhya/do-you-really-know-naive-bayes-6d5e07460aaf?source=collection_archive---------24-----------------------#2020-12-22</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/ad3595e6b993ac43616ea4891c39413e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0HJtZO0fLInjNyUMgD41-Q.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">来源:<a class="ae iu" href="https://www.kdnuggets.com/2020/06/naive-bayes-algorithm-everything.html" rel="noopener ugc nofollow" target="_blank"> KDnuggets </a></figcaption></figure><p id="7a7b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="jt">我们下一个机器学习算法是朴素贝叶斯分类器。像我其他关于机器学习算法的文章一样，跟大家一起学习。</em></p></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><h1 id="d4c1" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">这个贝叶斯定理是什么？</h1><blockquote class="kz la lb"><p id="8bbe" class="iv iw jt ix b iy iz ja jb jc jd je jf lc jh ji jj ld jl jm jn le jp jq jr js hb bi translated">在概率论和统计中，以托马斯·贝叶斯牧师的名字命名的贝叶斯定理(或者是贝叶斯定律或贝叶斯法则)描述了一个事件发生的概率，它基于与该事件相关的条件的先验知识。</p></blockquote><p id="b9a9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">可能看起来很复杂，但事实上，很容易理解。我知道，听起来很垃圾，等我解释。有时候，来自其他网站的定义，比如上面这个来自维基百科的，可能很难消化。当你有一个例子来引用这个话题时，它会变得非常简单。这是我这篇文章的目标。让我们开始吧！</p></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><p id="8895" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">想象一下，你有一些概率，你想用这些概率找到另一个概率的存在。那就是<em class="jt">贝叶斯定理</em>是什么。</strong></p><p id="58a0" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们继续研究这个公式:</p><figure class="lg lh li lj fd ij er es paragraph-image"><div class="er es lf"><img src="../Images/42862d557c2bbc28c3d380638b11e124.png" data-original-src="https://miro.medium.com/v2/resize:fit:556/format:webp/1*pQYwvT5m5dc9OSIKnIVvvQ.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">来源:<a class="ae iu" href="https://www.mathsisfun.com/data/bayes-theorem.html" rel="noopener ugc nofollow" target="_blank">马蒂斯芬</a></figcaption></figure><p id="580a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">P(A | B)</strong>→A 与 B 的存在多久发生一次？</p><p id="a8cd" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">P(B | A)</strong>→B 与 A 的存在多久发生一次？</p><p id="dfdd" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">P(A)</strong>→A 多久发生一次？</p><p id="752f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">P(B)</strong>→B 多久发生一次？</p><p id="87ec" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">继续一个很好的例子:</p><p id="7448" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> P(火|烟)</strong> →有烟有火的频率？</p><p id="6ddc" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> P(烟|火)</strong> →有烟有火的存在多久？</p><p id="f815" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> P(火)</strong> →多久发生一次火灾？</p><p id="1e57" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> P(冒烟)</strong> →多久冒烟一次？</p><p id="19bf" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我想我们差不多涵盖了这一部分。就像我之前说的，这真的很简单。现在是朴素贝叶斯算法的时候了！</p><h2 id="3259" class="lk kc hi bd kd ll lm ln kh lo lp lq kl jg lr ls kp jk lt lu kt jo lv lw kx lx bi translated">朴素贝叶斯算法？</h2><blockquote class="kz la lb"><p id="b71e" class="iv iw jt ix b iy iz ja jb jc jd je jf lc jh ji jj ld jl jm jn le jp jq jr js hb bi translated">朴素贝叶斯方法是一组基于应用贝叶斯定理的监督学习算法，其“朴素”假设是在给定类变量的值的情况下，每对要素之间的条件独立性。</p></blockquote><p id="78c1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这个定义来自 Sklearn 的文档。这是一个伟大的解释，但让我们最后一次尝试。</p><p id="011b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">朴素贝叶斯算法是最简单也是最有效的算法之一。这是一种根据贝叶斯定理工作的算法。它也是准确可靠的，这是我们对模型的全部要求。每个分类类别的值相互独立。</p><p id="8c2e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">虽然它是一种可以用于许多不同目的的算法，但是它在 NLP 中表现得特别好。</p><blockquote class="ly"><p id="c282" class="lz ma hi bd mb mc md me mf mg mh js dx translated">朴素贝叶斯做出的假设在现实世界中通常是不正确的。</p></blockquote><p id="a1c2" class="pw-post-body-paragraph iv iw hi ix b iy mi ja jb jc mj je jf jg mk ji jj jk ml jm jn jo mm jq jr js hb bi translated">上面我给的公式是一个只能用一个特征 x 计算的公式，如果我们有多个 x 特征呢？让我们检查一下新公式。</p><figure class="lg lh li lj fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mn"><img src="../Images/cb275df2129aea1e609094bee103a844.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WcpX8twHcq36XbFnvSBQpw.png"/></div></div></figure><p id="7b6a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">没什么变化。</p><p id="1265" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">使用简单的条件独立性假设:</p><figure class="lg lh li lj fd ij er es paragraph-image"><div class="er es mo"><img src="../Images/449cae346723877cac5b3c78ff5f704e.png" data-original-src="https://miro.medium.com/v2/resize:fit:720/format:webp/1*Etmq1zopc3yqQf6Dbok12Q.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">来源:<a class="ae iu" href="https://scikit-learn.org/stable/modules/naive_bayes.html" rel="noopener ugc nofollow" target="_blank"> Sklearn </a></figcaption></figure><p id="e5b7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">对于所有的<em class="jt"> i </em>，这种关系简化为:</p><figure class="lg lh li lj fd ij er es paragraph-image"><div class="er es mp"><img src="../Images/6d20711c8d3244feb736da79906f8db6.png" data-original-src="https://miro.medium.com/v2/resize:fit:716/format:webp/1*beglaaf-9bo8TFqvDJzpag.png"/></div></figure><p id="2d34" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">由于 P( <em class="jt"> x1，…，xn </em>)对于给定的输入是常数，我们可以使用以下分类规则:</p><figure class="lg lh li lj fd ij er es paragraph-image"><div class="er es mq"><img src="../Images/638e9f1eca27315b8c6eaba0fd7e1cbc.png" data-original-src="https://miro.medium.com/v2/resize:fit:714/format:webp/1*FzOS5gHaCAufIiO0u0P-PA.png"/></div></figure><p id="a1f9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这么多数学！我知道。确切的说，我不知道或者不完全理解上面所有的方程，除了贝叶斯定理。希望不会造成大问题。手指交叉，让我们继续！</p><p id="03e6" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="jt">朴素贝叶斯分类器的优点之一是，与数值变量相比，它可以在较少的训练数据和分类变量的情况下表现良好。</em></p><p id="3793" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">所以，也许我们应该看看实际情况。这个例子取自<a class="ae iu" href="https://www.analyticsvidhya.com/blog/2017/09/naive-bayes-explained/" rel="noopener ugc nofollow" target="_blank"> <strong class="ix hj">这个环节</strong> </a>。</p><figure class="lg lh li lj fd ij er es paragraph-image"><div class="er es mr"><img src="../Images/5adff984c3ce28ec8c1ada0bde480ff0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1258/format:webp/1*nNjapS4okZOF2jD8hPVdYg.png"/></div></figure><p id="8e99" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们有一些关于“天气”和“游戏”功能的信息。表格根据天气告诉我们游戏是否进行。就像你在上面看到的，首先我们需要把这个表转换成一个频率表。现在，我们可以看清楚什么时候是什么了。我们可以用贝叶斯定理方程。</p><p id="5eca" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">问题将会是:P(是|Sunny)？那是什么意思？试着理解一下。(提示:上面我刚给了你答案！)</p><h2 id="e2d4" class="lk kc hi bd kd ll lm ln kh lo lp lq kl jg lr ls kp jk lt lu kt jo lv lw kx lx bi translated">如果天气晴朗，玩家会玩吗？</h2><p id="587e" class="pw-post-body-paragraph iv iw hi ix b iy ms ja jb jc mt je jf jg mu ji jj jk mv jm jn jo mw jq jr js hb bi translated">我很确定，你找到了答案！干得好！</p><p id="b716" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，是时候把它变成一个贝叶斯定理方程了。</p><p id="6128" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> <em class="jt"> P(是|晴)= P(晴|是)* P(是)/ P(晴)</em> </strong></p><p id="10b9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> <em class="jt"> P(Sunny|Yes) </em> </strong>的答案是 3/9 = 0.33。从可能性表中，你可以看到天气晴朗时从 9 个游戏玩到了 3 个游戏。</p><p id="8402" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> <em class="jt"> P(是)</em> </strong>的答案是 9/14 = 0.64。9 是播放次数，14 是播放与否的总播放次数。</p><p id="6d22" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> <em class="jt"> P(晴)</em> </strong>的答案是 5/14 = 0.36。5 是天气晴朗时的播放次数，14 是天气好坏时的总播放次数。</p><p id="9be4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们得到了我们需要的一切。</p><p id="2ea1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> <em class="jt"> P(是|晴)</em> </strong> = 0.33 * 0.64 / 0.36 = 0.60 哪个概率大。</p><p id="1f47" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">是的，我们做到了。</p><blockquote class="ly"><p id="7a1f" class="lz ma hi bd mb mc md me mf mg mh js dx translated">这通常用于文本分类，如果你有多个类。</p></blockquote><h2 id="a63b" class="lk kc hi bd kd ll mx ln kh lo my lq kl jg mz ls kp jk na lu kt jo nb lw kx lx bi translated">高斯朴素贝叶斯</h2><blockquote class="kz la lb"><p id="a3b1" class="iv iw jt ix b iy iz ja jb jc jd je jf lc jh ji jj ld jl jm jn le jp jq jr js hb bi translated"><code class="du nc nd ne nf b"><a class="ae iu" href="https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html#sklearn.naive_bayes.GaussianNB" rel="noopener ugc nofollow" target="_blank"><strong class="ix hj">GaussianNB</strong></a></code>实现高斯朴素贝叶斯算法进行分类。假设特征的似然性是高斯的:</p></blockquote><figure class="lg lh li lj fd ij er es paragraph-image"><div class="er es ng"><img src="../Images/418e77799302c47ae55844c7feeca6cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:750/format:webp/1*V-qxiCPVgIY_oBHnxx8KVQ.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">来源:<a class="ae iu" href="https://scikit-learn.org/stable/modules/naive_bayes.html" rel="noopener ugc nofollow" target="_blank"> Sklearn </a></figcaption></figure><pre class="lg lh li lj fd nh nf ni nj aw nk bi"><span id="8d32" class="lk kc hi nf b fi nl nm l nn no"><strong class="nf hj">from</strong> <strong class="nf hj">sklearn.datasets</strong> <strong class="nf hj">import</strong> load_iris<br/><strong class="nf hj">from</strong> <strong class="nf hj">sklearn.model_selection</strong> <strong class="nf hj">import</strong> train_test_split<br/><strong class="nf hj">from</strong> <strong class="nf hj">sklearn.naive_bayes</strong> <strong class="nf hj">import</strong> GaussianNB<br/>X, y = load_iris(return_X_y=<strong class="nf hj">True</strong>)<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)<br/>gnb = GaussianNB()<br/>y_pred = gnb.fit(X_train, y_train).predict(X_test)</span></pre><h2 id="f658" class="lk kc hi bd kd ll lm ln kh lo lp lq kl jg lr ls kp jk lt lu kt jo lv lw kx lx bi translated">多项式朴素贝叶斯</h2><blockquote class="kz la lb"><p id="71ed" class="iv iw jt ix b iy iz ja jb jc jd je jf lc jh ji jj ld jl jm jn le jp jq jr js hb bi translated"><code class="du nc nd ne nf b"><a class="ae iu" href="https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB" rel="noopener ugc nofollow" target="_blank"><strong class="ix hj">MultinomialNB</strong></a></code>为多项式分布数据实现朴素贝叶斯算法，是文本分类中使用的两种经典朴素贝叶斯算法之一(其中数据通常表示为词向量计数，尽管 tf-idf 向量在实践中也很有效)。该分布由每个类别 y 的向量θy=(θy1，…，θyn)来参数化，其中 n 是特征的数量(在文本分类中，词汇表的大小),θyi 是特征 I 出现在属于类别 y 的样本中的概率 P(xi∣y</p></blockquote><figure class="lg lh li lj fd ij er es paragraph-image"><div class="er es np"><img src="../Images/9be44b4bf4fff6740992e5a0377306dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:350/format:webp/1*dZpJUeo1juldcR4y6trnnA.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">来源:<a class="ae iu" href="https://scikit-learn.org/stable/modules/naive_bayes.html" rel="noopener ugc nofollow" target="_blank"> Sklearn </a></figcaption></figure><pre class="lg lh li lj fd nh nf ni nj aw nk bi"><span id="d26d" class="lk kc hi nf b fi nl nm l nn no"><strong class="nf hj">import</strong> <strong class="nf hj">numpy</strong> <strong class="nf hj">as</strong> <strong class="nf hj">np</strong><br/>rng = np.random.RandomState(1)<br/>X = rng.randint(5, size=(6, 100))<br/>y = np.array([1, 2, 3, 4, 5, 6])<br/><strong class="nf hj">from</strong> <strong class="nf hj">sklearn.naive_bayes</strong> <strong class="nf hj">import</strong> MultinomialNB<br/>clf = MultinomialNB()<br/>clf.fit(X, y)</span></pre><h2 id="8dd9" class="lk kc hi bd kd ll lm ln kh lo lp lq kl jg lr ls kp jk lt lu kt jo lv lw kx lx bi translated">伯努利朴素贝叶斯</h2><blockquote class="kz la lb"><p id="205c" class="iv iw jt ix b iy iz ja jb jc jd je jf lc jh ji jj ld jl jm jn le jp jq jr js hb bi translated"><code class="du nc nd ne nf b"><a class="ae iu" href="https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html#sklearn.naive_bayes.BernoulliNB" rel="noopener ugc nofollow" target="_blank"><strong class="ix hj">BernoulliNB</strong></a></code>为根据多元伯努利分布分布的数据实现朴素贝叶斯训练和分类算法；即，可能有多个特征，但每个特征都被假设为二进制值(伯努利、布尔)变量。因此，该类要求将样本表示为二进制值特征向量；如果传递任何其他类型的数据，<code class="du nc nd ne nf b">BernoulliNB</code>实例可能会将其输入二进制化(取决于<code class="du nc nd ne nf b">binarize</code>参数)。</p></blockquote><figure class="lg lh li lj fd ij er es paragraph-image"><div class="er es nq"><img src="../Images/bc3ef1d2775c23992a99aa5b2af2bd0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:780/format:webp/1*2E31fZleRWHzjjjkGtrvNQ.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">来源:<a class="ae iu" href="https://scikit-learn.org/stable/modules/naive_bayes.html" rel="noopener ugc nofollow" target="_blank"> Sklearn </a></figcaption></figure><pre class="lg lh li lj fd nh nf ni nj aw nk bi"><span id="8790" class="lk kc hi nf b fi nl nm l nn no"><strong class="nf hj">import</strong> <strong class="nf hj">numpy</strong> <strong class="nf hj">as</strong> <strong class="nf hj">np</strong><br/>rng = np.random.RandomState(1)<br/>X = rng.randint(5, size=(6, 100))<br/>Y = np.array([1, 2, 3, 4, 4, 5])<br/><strong class="nf hj">from</strong> <strong class="nf hj">sklearn.naive_bayes</strong> <strong class="nf hj">import</strong> BernoulliNB<br/>clf = BernoulliNB()<br/>clf.fit(X, Y)</span></pre><p id="d565" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="jt">我从 Sklearn 上获取了定义和代码样本，因为我认为它们是解释性的。我找不到更好的词来形容他们。</em></p></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><p id="3703" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这就是我给你的全部。我希望对你理解朴素贝叶斯的基础知识有所帮助。你要做的就是练习，练习，再练习。</p><p id="dc7e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">下一篇文章再见！快乐学习！</p></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><h2 id="a4bf" class="lk kc hi bd kd ll lm ln kh lo lp lq kl jg lr ls kp jk lt lu kt jo lv lw kx lx bi translated">参考文献</h2><div class="nr ns ez fb nt nu"><a href="https://en.wikipedia.org/wiki/Bayes%27_theorem" rel="noopener  ugc nofollow" target="_blank"><div class="nv ab dw"><div class="nw ab nx cl cj ny"><h2 class="bd hj fi z dy nz ea eb oa ed ef hh bi translated">贝叶斯定理</h2><div class="ob l"><h3 class="bd b fi z dy nz ea eb oa ed ef dx translated">在概率论和数理统计中，以牧师命名的贝叶斯定理(或称贝叶斯定律或贝叶斯法则)</h3></div><div class="oc l"><p class="bd b fp z dy nz ea eb oa ed ef dx translated">en.wikipedia.org</p></div></div><div class="od l"><div class="oe l of og oh od oi io nu"/></div></div></a></div><div class="nr ns ez fb nt nu"><a href="https://www.kdnuggets.com/2020/06/naive-bayes-algorithm-everything.html" rel="noopener  ugc nofollow" target="_blank"><div class="nv ab dw"><div class="nw ab nx cl cj ny"><h2 class="bd hj fi z dy nz ea eb oa ed ef hh bi translated">朴素贝叶斯算法:你需要知道的一切</h2><div class="ob l"><h3 class="bd b fi z dy nz ea eb oa ed ef dx translated">朴素贝叶斯是一种基于贝叶斯定理的概率机器学习算法，广泛用于各种…</h3></div><div class="oc l"><p class="bd b fp z dy nz ea eb oa ed ef dx translated">www.kdnuggets.com</p></div></div><div class="od l"><div class="oj l of og oh od oi io nu"/></div></div></a></div><p id="405c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><a class="ae iu" href="https://www.geeksforgeeks.org/naive-bayes-classifiers/#:~:text=Naive%20Bayes%20classifiers%20are%20a,is%20independent%20of%20each%20other" rel="noopener ugc nofollow" target="_blank">https://www . geeks forgeeks . org/Naive-Bayes-classifiers/#:~:text = Naive % 20 Bayes % 20 classifiers % 20 are % 20a，is % 20 independent % 20 of % 20 each % 20 other</a>。</p><div class="nr ns ez fb nt nu"><a href="https://scikit-learn.org/stable/modules/naive_bayes.html" rel="noopener  ugc nofollow" target="_blank"><div class="nv ab dw"><div class="nw ab nx cl cj ny"><h2 class="bd hj fi z dy nz ea eb oa ed ef hh bi translated">1.9.朴素贝叶斯-sci kit-学习 0.23.2 文档</h2><div class="ob l"><h3 class="bd b fi z dy nz ea eb oa ed ef dx translated">朴素贝叶斯方法是一组监督学习算法，基于应用贝叶斯定理和“朴素”学习理论</h3></div><div class="oc l"><p class="bd b fp z dy nz ea eb oa ed ef dx translated">scikit-learn.org</p></div></div><div class="od l"><div class="ok l of og oh od oi io nu"/></div></div></a></div><div class="nr ns ez fb nt nu"><a href="https://www.mathsisfun.com/data/bayes-theorem.html" rel="noopener  ugc nofollow" target="_blank"><div class="nv ab dw"><div class="nw ab nx cl cj ny"><h2 class="bd hj fi z dy nz ea eb oa ed ef hh bi translated">贝叶斯定理</h2><div class="ob l"><h3 class="bd b fi z dy nz ea eb oa ed ef dx translated">想知道计算机是如何了解人的吗？在网上搜索“电影自动鞋带”会出现“回到…</h3></div><div class="oc l"><p class="bd b fp z dy nz ea eb oa ed ef dx translated">www.mathsisfun.com</p></div></div><div class="od l"><div class="ol l of og oh od oi io nu"/></div></div></a></div><div class="nr ns ez fb nt nu"><a href="https://www.analyticsvidhya.com/blog/2017/09/naive-bayes-explained/" rel="noopener  ugc nofollow" target="_blank"><div class="nv ab dw"><div class="nw ab nx cl cj ny"><h2 class="bd hj fi z dy nz ea eb oa ed ef hh bi translated">用 Python 和 R 语言学习朴素贝叶斯算法的 6 个简单步骤</h2><div class="ob l"><h3 class="bd b fi z dy nz ea eb oa ed ef dx translated">注意:本文最初发布于 2015 年 9 月 13 日，更新于 2017 年 9 月 11 日概述了解其中一个…</h3></div><div class="oc l"><p class="bd b fp z dy nz ea eb oa ed ef dx translated">www.analyticsvidhya.com</p></div></div><div class="od l"><div class="om l of og oh od oi io nu"/></div></div></a></div></div></div>    
</body>
</html>