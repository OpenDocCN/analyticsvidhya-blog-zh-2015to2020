<html>
<head>
<title>Evolution of Object Detection</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">目标检测的发展</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/evolution-of-object-detection-582259d2aa9b?source=collection_archive---------1-----------------------#2020-11-01">https://medium.com/analytics-vidhya/evolution-of-object-detection-582259d2aa9b?source=collection_archive---------1-----------------------#2020-11-01</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/9a4ac6374a4859c864ea77b81fd6fc83.png" data-original-src="https://miro.medium.com/v2/resize:fit:994/1*gJmQdjT3YcGCcZ2H1PK7SA.gif"/></div></figure><p id="8e45" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">计算机视觉已经取得了相当大的进步，但在匹配人类感知的精度方面仍然面临挑战。然而，看到我们已经走了多远总是好的。检测和识别图像中未知数量的单个对象的任务，称为<em class="jk">对象检测</em>，仅在几年前还被认为是一个极其困难的问题，现在已经是可行的，甚至已经被像<a class="ae jl" href="https://cloud.google.com/vision/docs/drag-and-drop" rel="noopener ugc nofollow" target="_blank"> <strong class="io hj">【谷歌】</strong> </a>和<a class="ae jl" href="https://www.ibm.com/watson/services/visual-recognition/" rel="noopener ugc nofollow" target="_blank"> <strong class="io hj"> IBM </strong> </a> <strong class="io hj">这样的公司产品化。</strong></p><p id="26a6" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在这个故事中，我们将回顾对象检测的历史，从“传统对象检测时期(2014年之前)”到“基于深度学习的检测时期(2014年之后)”。</p><h2 id="74c0" class="jm jn hi bd jo jp jq jr js jt ju jv jw ix jx jy jz jb ka kb kc jf kd ke kf kg bi translated"><strong class="ak">传统物体检测时代:</strong></h2><p id="1d17" class="pw-post-body-paragraph im in hi io b ip kh ir is it ki iv iw ix kj iz ja jb kk jd je jf kl jh ji jj hb bi translated">时光倒流20年，我们将见证“冷兵器时代的智慧”。由于当时缺乏有效的图像表示，早期的大多数对象检测算法都是基于手工制作的特征构建的。</p><p id="d578" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">维奥拉·琼斯探测器:</strong></p><p id="7973" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">由Paul Viola和Michael Jones在2001年开发的这个对象识别框架允许实时检测人脸。它使用滑动窗口来遍历图像中所有可能的位置和比例，以查看是否有任何窗口包含人脸。滑动窗口本质上搜索“类哈尔”特征(以提出哈尔小波概念的阿尔弗雷德·哈尔命名)。</p><figure class="kn ko kp kq fd ij er es paragraph-image"><div class="er es km"><img src="../Images/d59bc706649892777aff02cbb70dc59b.png" data-original-src="https://miro.medium.com/v2/resize:fit:542/format:webp/1*GDx-HQYaCPx-LmL94L6Lgg.jpeg"/></div><figcaption class="kr ks et er es kt ku bd b be z dx translated">类似哈尔的特征。</figcaption></figure><p id="fd8a" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">因此，haar小波被用作图像的特征表示。为了加快检测速度，它使用了<em class="jk">积分图像</em>，使得每个滑动窗口的计算复杂度与其窗口大小无关。作者使用的另一个提高检测速度的技巧是使用Adaboost算法进行<em class="jk">特征选择</em>，该算法从大量随机特征池中选择一小组对人脸检测最有帮助的特征。该算法还使用了<em class="jk">检测级联，这是一种</em>多阶段检测范式，通过在背景窗口上花费更少的计算而在人脸目标上花费更多的计算来减少其计算开销。</p><p id="2292" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">生猪检测器:</strong></p><figure class="kn ko kp kq fd ij er es paragraph-image"><div class="er es kv"><img src="../Images/aa9616476b124f4535b5b04518cabaf2.png" data-original-src="https://miro.medium.com/v2/resize:fit:652/format:webp/1*P8IeGKSz3Tf1ZAjbtMD1Rg.jpeg"/></div></figure><p id="f204" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">Hog最初由N. Dalal和B. Triggs在2005年提出，是对当时的尺度不变特征变换和形状上下文的改进。HOG使用一种叫做<em class="jk">块</em>(类似于滑动窗口)的东西，这是一种密集的像素网格，其中梯度由块内像素强度变化的幅度和方向组成。猪因其在行人检测中的应用而广为人知。为了检测不同大小的对象，HOG检测器会多次重新缩放输入图像，同时保持检测窗口的大小不变。</p><p id="c61b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">基于可变形零件的模型(DPM): </strong></p><figure class="kn ko kp kq fd ij er es paragraph-image"><div class="er es kw"><img src="../Images/681891c79a2852fcac93afedc0d4a5ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*HCZiMm6PigWwR4_CpZ5FQA.jpeg"/></div></figure><p id="65d0" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">DPM最初由P. Felzenszwalb在2008年提出，作为HOG检测器的扩展。后来，R. Girshick做了各种改进。检测一辆“汽车”的问题可以通过检测它的窗户、车身和车轮来分解为一个“<em class="jk">分而治之”</em>策略。DPM使用这种策略。训练过程包括学习分解对象的适当方式，而推理包括组合不同对象部分的检测。</p><p id="be4e" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">DPM检测器由一个根滤波器和多个部分滤波器组成。在DPM中开发了弱监督学习方法，其中所有配置(大小、位置等。)可以作为潜在变量被自动学习。为了提高检测精度，R. Girshick为此使用了多示例学习的特例，以及其他一些重要的技术，如“硬负挖掘”、“包围盒回归”和“上下文启动”。后来，他甚至使用了一种实现级联架构的技术，这种技术在不牺牲精度的情况下实现了10倍以上的加速。</p><h2 id="3e6f" class="jm jn hi bd jo jp jq jr js jt ju jv jw ix jx jy jz jb ka kb kc jf kd ke kf kg bi translated">深度学习时代:</h2><p id="87b1" class="pw-post-body-paragraph im in hi io b ip kh ir is it ki iv iw ix kj iz ja jb kk jd je jf kl jh ji jj hb bi translated">不幸的是，随着手工制作功能的性能变得饱和，对象检测在2010年后达到了一个平台期。然而，在2012年，世界见证了卷积神经网络的重生，深度卷积网络成功地学习了图像的鲁棒和高级特征表示。2014年，具有CNN特征的区域(RCNN)用于物体检测的提议打破了物体检测的僵局。在这个深度学习时代，物体检测分为“两阶段检测”和“一阶段检测”两个流派。</p><p id="034f" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj"> RCNN: </strong></p><figure class="kn ko kp kq fd ij er es paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="er es kx"><img src="../Images/8af529f1b5e816135bd11c92a521741d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iEW-FQchaOIqmrglRlJbCQ.png"/></div></div></figure><p id="8e5d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">它从通过选择性搜索提取一组对象建议(对象候选框)开始。然后，每个建议被重新调整为固定大小的图像，并输入到预先训练的CNN模型中以提取特征。最后，使用线性SVM分类器来预测每个区域中对象的存在，并识别对象类别。</p><blockquote class="lc ld le"><p id="193d" class="im in jk io b ip iq ir is it iu iv iw lf iy iz ja lg jc jd je lh jg jh ji jj hb bi translated">虽然RCNN比传统方法好得多，但它有几个缺点。对大量重叠提议(来自一幅图像的超过2000个框)的冗余特征计算导致了极其缓慢的检测速度。选择性搜索算法也是一种固定算法。因此，在那个阶段没有学习发生。这可能导致产生坏的候选区域提议。</p></blockquote><p id="e77d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj"> SPPNet: </strong></p><figure class="kn ko kp kq fd ij er es paragraph-image"><div class="er es li"><img src="../Images/de842f2aa377fcc6b302fd74d5aeefe3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1374/format:webp/1*ntJDQMp56bebXsCj6C2wkg.png"/></div></figure><p id="467c" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">2014年，K. He等人提出了空间金字塔池网络。传统上，在卷积层和全连接层的过渡处，只有一个汇集层，甚至没有汇集层。在SPPNet中，它建议使用不同规模的多个池层。此外，以前的CNN模型需要固定大小的输入。SPPNet中的空间金字塔池(SPP)层使CNN能够生成固定长度的表示，而不管感兴趣的图像/区域的大小，而无需重新缩放。</p><p id="ef4a" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">上图说明了这个过程。我们看到，输入图像仅通过卷积网络进入SPPNet一次。选择性搜索用于生成区域提议，就像在R-CNN中一样。在最后一个卷积层，由每个区域提议限定的特征图进入SPP层，然后进入FC层。</p><blockquote class="lc ld le"><p id="3c34" class="im in jk io b ip iq ir is it iu iv iw lf iy iz ja lg jc jd je lh jg jh ji jj hb bi translated">与R-CNN相比，SPPNet仅在conv层处理图像一次，而R-CNN在conv层处理图像的次数与区域提议的次数一样多。然而，缺点包括:训练仍然是多阶段的，SPPNet仅微调其完全连接的层，而完全忽略所有先前的层。</p></blockquote><p id="7262" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">快速RCNN: </strong></p><figure class="kn ko kp kq fd ij er es paragraph-image"><div class="er es lj"><img src="../Images/deb00230c4cc5f4eee0ed1ec664605e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1268/format:webp/1*b3CKrf1bIUMKlCaSTGA0VA.png"/></div></figure><p id="5440" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">与R-CNN模型相比，快速R-CNN模型使用整个图像作为特征提取的CNN输入，而不是每个提议的区域。对图像应用选择性搜索，并且假设它生成n个建议区域，它们的不同形状指示不同形状的感兴趣区域(ROI)。快速R-CNN引入了RoI pooling，它使用CNN输出和RoI作为输入，输出从每个建议区域提取的特征的串联，并在类别预测期间馈入全连接层，全连接层输出的形状再次转换为n×q，我们使用softmax回归(q是类别的数量，n是建议区域的数量)。在边界框预测期间，完全连接的层输出的形状再次被变换为n×4。这意味着我们预测每个建议区域的类别和边界框。</p><p id="7949" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">“快速R-CNN”比R-CNN更快的原因是因为我们不必每次都将所有区域提议馈送给卷积神经网络。相反，每个图像只进行一次卷积运算，并从中生成特征图。</p><blockquote class="lc ld le"><p id="3c73" class="im in jk io b ip iq ir is it iu iv iw lf iy iz ja lg jc jd je lh jg jh ji jj hb bi translated">虽然Fast-RCNN成功地结合了R-CNN和SPPNet的优点，但其检测速度仍然受到建议检测的限制</p></blockquote><p id="aca0" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">更快的RCNN: </strong></p><figure class="kn ko kp kq fd ij er es paragraph-image"><div class="er es lj"><img src="../Images/7705b47d1e9848c63bb98adf66318e6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1268/format:webp/1*-BrpDpmOJc2zp7y1d0w5fw.png"/></div></figure><p id="689a" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">2015年，S. Ren等人在快速RCNN之后不久提出了更快的RCNN检测器。它是第一个端到端的，也是第一个接近实时的深度学习对象检测器。上述所有算法(R-CNN、SPPNet和Fast R-CNN)都使用选择性搜索来找出区域建议。选择性搜索是一个缓慢而耗时的过程，会影响网络的性能。更快的R-CNN消除了选择性搜索算法，并让网络学习区域建议。</p><p id="7a04" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">类似于快速R-CNN，图像作为输入被提供给卷积网络，该网络提供卷积特征图。不是在特征图上使用选择性搜索算法来识别区域提议，而是使用单独的网络来预测区域提议。然后，使用RoI池层对预测的区域提议进行整形，然后使用RoI池层对提议区域内的图像进行分类，并预测边界框的偏移值。</p><p id="ce07" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">作为更快的R-CNN模型的一部分，区域提议网络与模型的其余部分一起被训练。此外，更快的R-CNN目标函数包括对象检测中的类别和边界框预测，以及区域提议网络中锚框的类别和边界框预测。最后，区域建议网络可以学习如何生成高质量的建议区域，这减少了建议区域的数量，同时保持了对象检测的精度。</p><blockquote class="lc ld le"><p id="75d8" class="im in jk io b ip iq ir is it iu iv iw lf iy iz ja lg jc jd je lh jg jh ji jj hb bi translated">虽然快速RCNN突破了快速RCNN的速度瓶颈，但在后续检测阶段仍然存在计算冗余。后来，各种各样的改进被提出，包括RFCN和轻型头RCNN</p></blockquote><p id="9f5c" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">特征金字塔网络(FPN): </strong></p><figure class="kn ko kp kq fd ij er es paragraph-image"><div class="er es lk"><img src="../Images/cfd705c153515817fd1bdad2b6a28b34.png" data-original-src="https://miro.medium.com/v2/resize:fit:538/format:webp/1*r5OeVqonKzuf9LLHtxHGwg.jpeg"/></div></figure><p id="6116" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">2017年，T.-Y. Lin等人提出了特征金字塔网络。如果我们深入研究更快的RCNN，我们会发现它大多无法捕捉图像中的小对象。为了解决这个问题，可以使用一个简单的图像金字塔将图像缩放到不同的大小，并将其发送到网络。一旦在每个尺度上检测到检测，可以使用不同的方法组合所有的预测。</p><p id="3483" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在FPN之前，大多数基于深度学习的检测器仅在网络的顶层运行检测。虽然CNN更深层的特征有利于类别识别，但不利于定位对象。FPN开发了一种具有横向连接的自上而下的体系结构，用于在所有尺度上构建高级语义。由于CNN通过其前向传播自然地形成特征金字塔，FPN在检测具有各种尺度的对象方面显示出巨大的进步。</p><blockquote class="lc ld le"><p id="f06c" class="im in jk io b ip iq ir is it iu iv iw lf iy iz ja lg jc jd je lh jg jh ji jj hb bi translated">FPN现已成为许多最新探测器的基本构件。</p></blockquote><p id="dfcb" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">你只看一次(YOLO): </strong></p><figure class="kn ko kp kq fd ij er es paragraph-image"><div class="er es lj"><img src="../Images/35443fc8c7cb614553701f597d9b6433.png" data-original-src="https://miro.medium.com/v2/resize:fit:1268/format:webp/1*7O_2t_ZFDHd1CRpWaEJH_w.jpeg"/></div></figure><p id="7c49" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">所有先前的对象检测算法都使用区域来定位图像中的对象。该网络不查看完整的图像，而是查看图像中包含该对象的概率较高的部分。</p><p id="f2a9" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">YOLO在全图像上训练，直接优化检测性能。有了YOLO，单个CNN同时预测多个边界框和这些框的类别概率。它还可以同时预测图像中所有类别的所有边界框。<em class="jk">它</em>将输入图像划分成一个S × S的网格。如果一个物体的中心落入一个网格单元，该网格单元负责检测该物体<em class="jk">。</em>每个网格单元预测B个边界框和这些框的置信度得分。这些置信度得分反映了模型对盒子包含对象的置信度，以及它认为它预测的盒子有多准确。</p><p id="3371" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">每个边界框由6个数字(pc，bx，by，bh，bw，c)表示，其中pc是存在于边界框中的对象的置信度；bx，by，bh，bw代表包围盒本身；c是包含类别概率的向量。我们还通过探索训练数据来定义<em class="jk">锚盒</em>，以选择代表不同类别的合理的高/宽比。锚定框可以有多个边界框。对于(每个网格单元的)每个锚定框，我们计算逐元素乘积pc*c[i]并提取包含某个类别的框的概率得分。与最大分数相关联的类连同分数本身一起被分配给锚定框。</p><p id="e232" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">然后，我们可以通过使用概率得分的阈值来去除得分低的盒子。然而，我们仍然得到许多盒子。因此，我们使用一种称为非极大值抑制(NMS)的方法，当几个框相互重叠并检测到相同的对象时，我们只选择一个框。</p><blockquote class="lc ld le"><p id="688d" class="im in jk io b ip iq ir is it iu iv iw lf iy iz ja lg jc jd je lh jg jh ji jj hb bi translated">尽管其检测速度有了很大的提高，但与两级检测器相比，YOLO的定位精度有所下降，尤其是对于一些小物体。YOLO的后续版本(YOLO V2，YOLO V3和最新的YOLO V4)和后者提出的SSD(单次多盒探测器)已经更加重视这个问题。</p></blockquote><p id="3b97" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">单次多盒探测器(SSD): </strong></p><figure class="kn ko kp kq fd ij er es paragraph-image"><div class="er es ll"><img src="../Images/fccbce2bd7c193431b5604ad29638e9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:626/format:webp/1*JVq-XWgS1kyVVbUL0FZpXQ.jpeg"/></div></figure><p id="a2c6" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">SSD是W. Liu等人在2015年提出的。然后在2016年11月，C. Szegedy等人发表了关于<a class="ae jl" href="https://arxiv.org/abs/1512.02325?source=post_page" rel="noopener ugc nofollow" target="_blank"> SSD:单次多盒检测器</a>的论文，该论文在对象检测任务的性能和精度方面创下了新纪录。它是一个一步到位的物体探测器，就像yolo一样。SSD的主要贡献是引入了多参考和多分辨率检测技术，显著提高了一级检测器的检测精度，特别是对于一些小物体..在YOLO和更快的RCNN之后发布，对于300x300输入大小的图像，本文在59fps下实现了74.3 mAP。这个网络叫做SSD300。类似地，SSD512实现了76.9%的mAP，超过了更快的R-CNN结果。</p><p id="b2ef" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">它从<em class="jk">基础网络开始提取特征地图</em>。标准预训练网络用于高质量图像分类，并且在任何分类层之前被截断。在他们的论文中，C. Szegedy等人使用了VGG16网络。可以使用像VGG19和ResNet这样的其他网络，并且应该产生良好的结果。然后<em class="jk">多尺度特征层</em>是在基本网络之后添加的一系列卷积滤波器。这些层的尺寸逐渐减小，以便预测多种尺度的探测。然后<em class="jk">非最大值抑制</em>用于消除重叠的框，并为每个检测到的对象只保留一个框。</p><p id="9709" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj"> RetinaNet: </strong></p><figure class="kn ko kp kq fd ij er es paragraph-image"><div class="er es lm"><img src="../Images/232004fa3835777311c7b6409146a4f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:572/format:webp/1*vPQEf1JXMRBmwbVQCXVW0w.jpeg"/></div></figure><p id="df2b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">发现在密集一级检测器的训练中存在极端的类不平衡问题。尽管单级检测器速度快且简单，但据信这是其性能不如两级检测器的主要原因<strong class="io hj">。RetinaNet中引入了一个名为“焦点损失”的新损失函数，其中“容易”的阴性样本<strong class="io hj"> </strong>会产生较低的损失，因此检测器在训练期间会将更多的注意力放在困难、错误分类的样本上。焦点损失使一级检测器能够达到与两级检测器相当的精度，同时保持非常高的检测速度。</strong></p><p id="70b1" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">以<strong class="io hj"/><a class="ae jl" href="https://towardsdatascience.com/review-resnet-winner-of-ilsvrc-2015-image-classification-localization-detection-e39402bfa5d8" rel="noopener" target="_blank">ResNet</a>+<a class="ae jl" href="https://towardsdatascience.com/review-fpn-feature-pyramid-network-object-detection-262fc7482610" rel="noopener" target="_blank">FPN</a>为骨干<strong class="io hj"> </strong>进行特征提取，<strong class="io hj"> </strong>加上两个用于分类和包围盒回归的特定任务子网，<strong class="io hj"> </strong> RetinaNe实现了最先进的性能，并优于更快的R-CNN等知名的两级检测器。</p><p id="0b8a" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">目前就这些。</p><p id="24f8" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我们简要讨论了目标检测的发展，这是计算机视觉中一个非常具有挑战性、高度复杂且高度发展的领域。每年，新的算法都不断超越以前的算法。今天，有太多的预先训练好的模型用于物体检测。目标检测也在许多有趣的领域得到了应用，包括<em class="jk">跟踪目标</em>(如在足球世界杯的一场比赛中跟踪一个球)<em class="jk">自动闭路电视监控</em>、<em class="jk">人物检测</em>(用于智能视频监控框架中)<em class="jk">车辆检测</em>等。它还在自动驾驶中得到了应用，这是现代最有趣和最值得期待的创新之一。</p><figure class="kn ko kp kq fd ij er es paragraph-image"><div class="er es ln"><img src="../Images/e3b50dd7511d1dc3ceda9b328a014096.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/1*U1Y_upa2Pnkho5DXz92nmQ.gif"/></div></figure><h2 id="9081" class="jm jn hi bd jo jp jq jr js jt ju jv jw ix jx jy jz jb ka kb kc jf kd ke kf kg bi translated">参考资料:</h2><ol class=""><li id="c0eb" class="lo lp hi io b ip kh it ki ix lq jb lr jf ls jj lt lu lv lw bi translated">20年来的物体探测:一项调查→<a class="ae jl" href="https://arxiv.org/pdf/1905.05055.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1905.05055.pdf</a></li><li id="a93f" class="lo lp hi io b ip lx it ly ix lz jb ma jf mb jj lt lu lv lw bi translated">RCNN→<a class="ae jl" href="https://arxiv.org/pdf/1311.2524.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1311.2524.pdf</a></li><li id="8b34" class="lo lp hi io b ip lx it ly ix lz jb ma jf mb jj lt lu lv lw bi translated">快速RCNN→<a class="ae jl" href="https://arxiv.org/pdf/1504.08083.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1504.08083.pdf</a></li><li id="26d4" class="lo lp hi io b ip lx it ly ix lz jb ma jf mb jj lt lu lv lw bi translated">更快的RCNN→<a class="ae jl" href="https://arxiv.org/pdf/1506.01497.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1506.01497.pdf</a></li><li id="ac4d" class="lo lp hi io b ip lx it ly ix lz jb ma jf mb jj lt lu lv lw bi translated">Yolo → Coursera吴恩达深度学习专业化。</li><li id="870a" class="lo lp hi io b ip lx it ly ix lz jb ma jf mb jj lt lu lv lw bi translated">HOG→<a class="ae jl" href="https://www.learnopencv.com/histogram-of-oriented-gradients/" rel="noopener ugc nofollow" target="_blank">https://www . learnopencv . com/histogram-of-oriented-gradients/</a></li><li id="bc2d" class="lo lp hi io b ip lx it ly ix lz jb ma jf mb jj lt lu lv lw bi translated">SSD→<a class="ae jl" href="https://arxiv.org/abs/1512.02325" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1512.02325</a></li><li id="dd9f" class="lo lp hi io b ip lx it ly ix lz jb ma jf mb jj lt lu lv lw bi translated">FPN→<a class="ae jl" href="https://jonathan-hui.medium.com/understanding-feature-pyramid-networks-for-object-detection-fpn-45b227b9106c" rel="noopener">https://Jonathan-hui . medium . com/understanding-feature-pyramid-networks-for-object-detection-fpn-45b 227 b 9106 c</a></li><li id="3b84" class="lo lp hi io b ip lx it ly ix lz jb ma jf mb jj lt lu lv lw bi translated">spp net→<a class="ae jl" href="https://arxiv.org/abs/1406.4729" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1406.4729</a></li></ol></div></div>    
</body>
</html>