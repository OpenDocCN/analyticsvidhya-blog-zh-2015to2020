<html>
<head>
<title>RNNs, LSTMs, CNNs, Transformers and BERT</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">RNNs、LSTMs、CNN、Transformers和BERT</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/rnns-lstms-cnns-transformers-and-bert-be003df3492b?source=collection_archive---------1-----------------------#2020-02-09">https://medium.com/analytics-vidhya/rnns-lstms-cnns-transformers-and-bert-be003df3492b?source=collection_archive---------1-----------------------#2020-02-09</a></blockquote><div><div class="ds hc hd he hf hg"/><div class="hh hi hj hk hl"><div class=""/><h1 id="8990" class="il im ho bd in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji bi translated">递归神经网络</h1><p id="9e14" class="pw-post-body-paragraph jj jk ho jl b jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg hh bi translated">rnn确实有记忆来跟踪事物，所以它们允许信息在网络上持久存在。看下面给出的图片。图像的左侧显示了一个RNN单元，它接受一些输入，比如x，并在隐藏单元h中进行处理，最终以输出o做出响应。除了线性之外，隐藏层中的循环还允许将数据发送到下一层。总的来说，我们可以说RNN是一组相似的网络块。如果我们展开左边的图像，我们会得到…</p></div></div>    
</body>
</html>