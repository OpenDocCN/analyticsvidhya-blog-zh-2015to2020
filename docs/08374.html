<html>
<head>
<title>Monocular Depth Estimation and Background/Foreground Extraction using UNet Deep Learning Architecture</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用UNet深度学习架构的单目深度估计和背景/前景提取</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/monocular-depth-estimation-and-background-foreground-extraction-using-unet-deep-learning-bdfd19909aca?source=collection_archive---------10-----------------------#2020-07-27">https://medium.com/analytics-vidhya/monocular-depth-estimation-and-background-foreground-extraction-using-unet-deep-learning-bdfd19909aca?source=collection_archive---------10-----------------------#2020-07-27</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="9488" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">深度估计包括物体相对于相机有多远。深度估计用于各种应用，如机器人、增强现实、虚拟现实、自动驾驶等。由于场景中的动态对象以及遮挡、光照和各种背景，这是一项具有挑战性的任务。前景/背景分离也是一项具有挑战性的任务，因为涉及到预测前景的掩模。</p><p id="f718" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这篇文章中，我使用了120万幅图像的自定义图像数据集来执行以下操作:</p><ol class=""><li id="eb45" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated">从单目图像估计深度</li><li id="22c7" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">通过估计前景图像的掩模来分离前景和背景</li></ol><p id="85fc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在<a class="ae jr" href="https://github.com/monimoyd/15A_Generate_Mask_Depth_Dataset" rel="noopener ugc nofollow" target="_blank">https://github.com/monimoyd/15A_Generate_Mask_Depth_Dataset</a>中给出了关于自定义图像数据集及其生成方式的详细信息</p><p id="784a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">图像数据集以10个zip文件的形式给出(batch1_images.zip、batch2_images.zip …、batch10_images.zip)。每个zip包含以下文件夹:</p><p id="f1ec" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一、bg_jpg:背景jpg图片尺寸:160x160</p><p id="9378" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">二。fg_bg_jpg:叠加在背景图像上的前景图像，尺寸:(160x160)</p><p id="7a5e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">三。mask_black_jpg:黑色背景上前景图像蒙版的地面真实度，尺寸:(160x160)</p><p id="cf93" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">四。depth_fg_bg_jpg:深度图像的地面真实度，尺寸:(80x80)</p><p id="d7cf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">完整的数据集可在google drive链接中找到:</p><p id="12db" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae jr" href="https://drive.google.com/drive/folders/1YF4HvfTdDwDLYPmBokx4b5QzInMVyAzA?usp=sharing" rel="noopener ugc nofollow" target="_blank">https://drive . Google . com/drive/folders/1 YF 4 hvftddwdlypmbokx 4b 5 qzinmvyaza？usp =共享</a></p><p id="0b3e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">GitHub实施链接:</p><p id="9c74" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae jr" href="https://github.com/monimoyd/PredictingMaskAndDepthUsingDeepLearning/blob/master/assignment15_final_api.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/monimoyd/predicting maskanddepthusingdeeplearning</a></p><p id="790b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">主要亮点</strong>:</p><ul class=""><li id="41d2" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc js jj jk jl bi translated">使用只有748K参数的UNet架构</li><li id="19f8" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc js jj jk jl bi translated">定制数据加载器加载120万张图片，并在Google Colab上进行培训</li><li id="4546" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc js jj jk jl bi translated">使用图像增强I .高斯噪声ii。色彩抖动</li><li id="5126" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc js jj jk jl bi translated">预测遮罩的IoU值接近0.95，而深度图像非常接近地面真实情况</li><li id="3f72" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc js jj jk jl bi translated">使用各种分析工具tensorboard、cprofile、GPU profiler</li><li id="a01a" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc js jj jk jl bi translated">在训练、复制、解压缩图像期间测量的时间</li><li id="26d4" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc js jj jk jl bi translated">仅使用了5个时期来获得非常好的结果</li><li id="0fbf" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc js jj jk jl bi translated">使用Pytorch来实现这个项目</li></ul><h1 id="b660" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">一.培训</h1><p id="2e48" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">下图显示了培训的主要组成部分</p><figure class="kx ky kz la fd lb er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es kw"><img src="../Images/12e59fd361ee6b6e4026fafcd16cda0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*04LNy9WhNCIGCPGXTN9_Fw.png"/></div></div></figure><p id="c560" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里的输入是</p><ul class=""><li id="8d88" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc js jj jk jl bi translated">160x160背景图像</li><li id="ea1b" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc js jj jk jl bi translated">叠加在背景上的160x160前景图像</li><li id="8c59" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc js jj jk jl bi translated">黑色背景上前景蒙版的160x160地面真实度</li><li id="86ff" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc js jj jk jl bi translated">80x80地面真实深度图像</li></ul><p id="72cc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">处理由以下人员完成:</p><ul class=""><li id="70b3" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc js jj jk jl bi translated">数据加载器加载数据，而图像增强执行图像的增强。</li><li id="a1f1" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc js jj jk jl bi translated">模型用于正向通过神经网络并预测掩码</li><li id="687c" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc js jj jk jl bi translated">损失函数计算预测掩模图像和真实掩模图像之间以及预测深度图像和真实深度图像之间的损失值。损失值通过神经网络反向传播，并更新模型的权重</li></ul><p id="9d5e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">产出包括:</p><ul class=""><li id="b5be" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc js jj jk jl bi translated">黑色背景上的前景蒙版(尺寸:160x160)</li><li id="6a96" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc js jj jk jl bi translated">预测深度图像(尺寸:80x80)</li></ul><h1 id="8f26" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">I .数据加载器</h1><p id="73b2" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">数据加载器从图像中加载数据。</p><p id="2da7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面的流程图解释了数据加载器的工作流程:</p><figure class="kx ky kz la fd lb er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es li"><img src="../Images/7e604ab7b7a26a6635ebb034d29ec180.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jCw7iGD9WWXPQYzxjo-o1g.png"/></div></div></figure><p id="77a4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所涉及的过程如下:</p><ul class=""><li id="11ca" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc js jj jk jl bi translated">将google drive中的所有zip文件复制到Google Colab本地文件夹/内容/数据中</li><li id="de21" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc js jj jk jl bi translated">将每个zip文件解压到各自的批处理文件夹中。例如，batch1_images.zip被解压缩到/content/data/batch1文件夹。</li></ul><p id="a7d4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对其他批次也进行类似的处理</p><ul class=""><li id="45a4" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc js jj jk jl bi translated">有两个数据集:</li></ul><p id="6282" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">i. TrainImageDataset —该数据集由9个zip文件(batch1_images.zip，batch1_images.zip，… batch9_images.zip)构成，这些文件解压缩到相应的批处理文件夹(batch1，batch2 4，..batch9)并用于训练。</p><p id="9849" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">二。TestImageDataset此数据集仅使用在batch10文件夹中解压缩的batch10_images.zip构建</p><p id="7c55" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">记录填充如下</p><ul class=""><li id="e7c7" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc js jj jk jl bi translated">fg_bg_jpg文件夹中所有文件的多级索引(批次id，偏移量)</li><li id="999d" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc js jj jk jl bi translated"><strong class="ih hj"> getitem </strong>方法将index作为参数。</li><li id="5077" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc js jj jk jl bi translated">index用于通过将index除以40000来计算batch_id。余数用于计算偏移量</li><li id="d5cb" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc js jj jk jl bi translated">一旦fg_bg图像文件被识别，相应的背景图像文件就基于命名约定被识别。例如，fg_bg图像文件名为fg_bg_1_100_1_15.jpg，那么按照惯例，fg_bg后面的第二个数字将是背景图像，在这种情况下，它将是bg_100.jpg，并且可在相应批次id目录下的bg_jpg文件夹中获得</li></ul><p id="f634" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">根据地面真实遮罩图像的惯例，文件名将具有与fg_bg图像文件名相同的后缀。例如，如果fg_bg图像文件名为fg_bg_1_100_1_15.jpg，则地面实况掩模图像对应的文件名将为bg_mask_1_100_1_15.jpg，该文件名可在批次id目录下的mask_black_jpg文件夹中找到</p><p id="6ef7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">类似地，地面真实深度图像文件名将具有与fg_bg图像文件名相同的后缀。例如，如果fg_bg图像文件名是fg_bg_1_100_1_15.jpg，则对应深度图像的文件名将是depth_1_100_1_15.jpg，该文件名将在相应批处理目录下的depth_fg_bg_jpg目录中可用。</p><h1 id="2628" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">二。数据扩充</h1><p id="1f8a" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">对于训练图像，使用了两种增强:</p><ul class=""><li id="1c36" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc js jj jk jl bi translated">火炬视觉的色彩抖动，亮度:0.075，对比度:0.075，饱和度:0.075，色调:0.075</li><li id="4801" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc js jj jk jl bi translated">自定义类别GaussianNoise平均值为0，标准差为0.05，概率为0.2。</li></ul><p id="dfd1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">相同的数据扩充应用于输入bg、fg_bg、mask以及地面真实遮罩和深度图像</p><h1 id="e112" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">三。模型</h1><p id="e34b" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">我用的是UNet模型。UNet模型适用于分割作品。</p><p id="2d6b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">UNet的原始架构如下[来源:<a class="ae jr" href="https://towardsdatascience.com/u-net-b229b32b4a71" rel="noopener" target="_blank">https://towardsdatascience.com/u-net-b229b32b4a71</a></p><figure class="kx ky kz la fd lb er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es lj"><img src="../Images/d0fa48320e0a50ecb435fa9affe87193.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*f7jERjmNmPqcS-ezV_vZiw.png"/></div></div></figure><p id="9073" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">该建筑看起来像一个“U”形，名副其实。这个架构由三个部分组成:收缩部分、瓶颈部分和扩展部分。收缩段由许多收缩块组成。每个块接受一个输入，应用两个3×3卷积层，然后是一个2×2最大池。每个块之后的核或特征图的数量加倍，以便架构可以有效地学习复杂的结构。最底层介于收缩层和膨胀层之间。它使用两个3X3 CNN层，然后是2X2 up卷积层。</p><p id="69f2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">但是这个架构的核心在于扩展部分。类似于收缩层，也是由几个膨胀块组成。每个模块将输入传递到两个3X3 CNN层，然后是一个2×2上采样层。同样在每个块之后，卷积层所使用的特征映射数得到一半以保持对称性。然而，每次输入也得到相应收缩层的附加特征图。这个动作将确保在收缩图像时学习的特征将被用于重建图像。扩展块的数量与收缩块的数量相同。之后，所得到的映射通过另一个3X3 CNN层，其特征映射的数量等于期望的分段数量。</p><p id="53fe" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最初的UNet模型有大约2500万个参数，因此要减少参数:</p><ul class=""><li id="b97e" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc js jj jk jl bi translated">使用深度方向可分离卷积</li><li id="65f6" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc js jj jk jl bi translated">频道的数量也减少了</li></ul><p id="b9be" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">减少后，参数总数为748K，甚至不到一百万。</p><p id="f79a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">该模型的输出具有两个头，一个用于预测尺寸(160×160)的掩模，另一个头用于预测深度(80×80)</p><h1 id="3151" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">四。损失函数</h1><p id="dec7" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">使用了两种损失函数:</p><h1 id="224c" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">a.BCEWitLogitsLoss:</h1><p id="6380" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">这种损失将一个<code class="du lk ll lm ln b">Sigmoid</code>层和二进制交叉熵损失组合在一个单独的类中。</p><p id="aafb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我用这个损失函数来预测遮罩，因为它需要像素级别的比较</p><h1 id="06ed" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">b.SSIM:</h1><p id="ef89" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">结构相似性(SSIM)指数是一种预测数字电视和电影以及其他类型的数字图像和视频的感知质量的方法。SSIM用于度量两幅图像之间的相似性。</p><p id="32b7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我使用SSIM作为损失函数来计算预测和地面真实深度图像之间的损失。</p><p id="0f29" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">总损失我用了公式:</p><p id="7ea0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">总损失= 2 *(掩模图像的BCEWitLogitsLoss(深度图像的1-SSIM损失)</p><p id="62ff" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">(我使用1-SSIM损失，因为SSIM损失在0到1的范围内，1是完全匹配的)</p><h1 id="a800" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">动词 （verb的缩写）使用的度量</h1><p id="2c3d" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">损失:这将计算(预测的遮罩图像与地面真实遮罩图像)和(预测的深度图像与地面真实深度图像)的总损失值</p><p id="3004" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">IOU:使用jaccard相似系数计算预测掩码的IoU。Jaccard相似性系数定义为交集的大小除以两个标签集的并集的大小，用于将样本的预测标签集与y_true中的相应标签集进行比较</p><p id="0ef6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">首先，为预测掩模图像和地面掩模图像的每个像素值定义阈值。如果像素值大于阈值，则认为是1，否则为零。接下来sklearn.metrics的jaccard_score用于计算IoU值。</p><h1 id="75db" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">动词 （verb的缩写）超参数</h1><p id="b17b" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">使用以下超级参数:</p><blockquote class="lo lp lq"><p id="7b30" class="if ig lr ih b ii ij ik il im in io ip ls ir is it lt iv iw ix lu iz ja jb jc hb bi translated">批量:100个</p><p id="f4b8" class="if ig lr ih b ii ij ik il im in io ip ls ir is it lt iv iw ix lu iz ja jb jc hb bi translated">历元数:5</p><p id="46cf" class="if ig lr ih b ii ij ik il im in io ip ls ir is it lt iv iw ix lu iz ja jb jc hb bi translated">初始学习率:0.01</p><p id="efdb" class="if ig lr ih b ii ij ik il im in io ip ls ir is it lt iv iw ix lu iz ja jb jc hb bi translated">动量:0.9</p><p id="97f4" class="if ig lr ih b ii ij ik il im in io ip ls ir is it lt iv iw ix lu iz ja jb jc hb bi translated">重量衰减:1e-5</p></blockquote><h1 id="32fb" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">不及物动词使用的优化程序和调度程序:</h1><p id="f91b" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">使用带有动量的SGD优化器。使用步长为2且gamma为0.1的StepLR可以降低学习率</p><h1 id="11a2" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">二。测试</h1><p id="d954" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">下图显示了测试的主要组成部分</p><figure class="kx ky kz la fd lb er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es kw"><img src="../Images/12e59fd361ee6b6e4026fafcd16cda0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*04LNy9WhNCIGCPGXTN9_Fw.png"/></div></div></figure><p id="f41b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里的输入是</p><ul class=""><li id="8011" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc js jj jk jl bi translated">160x160背景图像</li><li id="e09b" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc js jj jk jl bi translated">叠加在背景上的160x160前景图像</li></ul><p id="5889" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">处理由以下人员完成:</p><ul class=""><li id="0b63" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc js jj jk jl bi translated">数据加载器加载数据。Dataloader使用batch10中的图像，即batch10_images.jpg</li><li id="af3c" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc js jj jk jl bi translated">模型用于通过神经网络进行前向传递，并预测掩码</li></ul><p id="cfb6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">产出包括:</p><ul class=""><li id="cc93" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc js jj jk jl bi translated">黑色背景上前景的160x160蒙版</li><li id="6f57" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc js jj jk jl bi translated">80x80预测深度图像</li></ul><p id="56a9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于测试，加载来自训练的最佳模型，然后在输入图像上进行评估</p><h1 id="432f" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">三。结果</h1><h1 id="011e" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">测试结果:</h1><h1 id="ef04" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">爱达荷（Idaho的缩写）</h1><h1 id="e2c8" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">背景图像:</h1><figure class="kx ky kz la fd lb er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es lv"><img src="../Images/af491a0823b7fe83a45df4491b8d3803.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jU2a94F0zqC1vcd-T0jz8Q.jpeg"/></div></div></figure><h1 id="f9d8" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">前景和背景图像:</h1><figure class="kx ky kz la fd lb er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es lv"><img src="../Images/f2285d3e48c8a9b85110bb8a29b4a154.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DBq8YHtGcHA3gE3-DZ1Dfw.jpeg"/></div></div></figure><h1 id="ebfe" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">地面真实遮罩图像:</h1><figure class="kx ky kz la fd lb er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es lv"><img src="../Images/c5f68e2f5228d181fe12b1a894083e05.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ktmLOmZABvFy7--c1Qr4ng.jpeg"/></div></div></figure><h1 id="ef12" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">预测遮罩图像:</h1><figure class="kx ky kz la fd lb er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es lv"><img src="../Images/d822c7b6debf762522a47393f11753d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YYXswFTSCSYTKul12gnNLA.jpeg"/></div></div></figure><p id="e12e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">预测的掩码IoU值:0.9565858394563042</p><h1 id="96ca" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">地面真实深度图像(带等离子显示器):</h1><figure class="kx ky kz la fd lb er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es lv"><img src="../Images/1c4b12969ff8715e5fc96439b7e15387.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rgpQfRKIfS0rOtiqSkExSA.jpeg"/></div></div></figure><h1 id="dad9" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">预测掩模图像(带等离子显示器):</h1><figure class="kx ky kz la fd lb er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es lv"><img src="../Images/8455b25b25caa0bbedac4a9d948c6e7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oHNwZy8mWkTcXTZ-3iaThQ.jpeg"/></div></div></figure><p id="60f4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">二。</p><h1 id="190f" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">背景图像:</h1><figure class="kx ky kz la fd lb er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es lv"><img src="../Images/888a3690aa47650f5bba8e7d2b04eb94.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w3Y9qzwCNrAlvdjrYQ98rw.jpeg"/></div></div></figure><h1 id="0dec" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">前景和背景图像:</h1><figure class="kx ky kz la fd lb er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es lv"><img src="../Images/40c24bf326ad97f11fbce713367f8886.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c2yWh1kusD6Sc-DzU3TbvA.jpeg"/></div></div></figure><h1 id="cc09" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">地面真实遮罩图像:</h1><figure class="kx ky kz la fd lb er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es lv"><img src="../Images/fde0c77aee1d11d790cd2eef8e7a8bb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VWmQMuBIairGH-7hcQc77g.jpeg"/></div></div></figure><h1 id="4aeb" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">预测遮罩图像:</h1><figure class="kx ky kz la fd lb er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es lv"><img src="../Images/ec0ca85402844a719dfb07b5a259c84e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*__DkpBr1g3fZyahQ_C3WLg.jpeg"/></div></div></figure><p id="d5b6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">预测的掩码IoU值:0.94254576767867</p><h1 id="43ea" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">地面真实深度图像(带等离子显示器):</h1><figure class="kx ky kz la fd lb er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es lv"><img src="../Images/0570e253dcdcb6279a886054e128c016.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3ampKIqTDDfog7exawF2EQ.jpeg"/></div></div></figure><h1 id="a995" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">预测深度图像(带等离子显示器):</h1><figure class="kx ky kz la fd lb er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es lv"><img src="../Images/d0b66fccbd1777ae575d2a9d34d6674c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NfFuoxs1onvg1kEJ4vftXg.jpeg"/></div></div></figure><h1 id="e08c" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">四。剖析:</h1><h1 id="a904" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">一.冲浪板</h1><p id="7d40" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">TensorBoard是一个分析器和可视化工具，它用于以下目的:</p><ul class=""><li id="504d" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc js jj jk jl bi translated">跟踪和可视化损失和准确性等指标</li><li id="f210" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc js jj jk jl bi translated">可视化模型图(操作和层)</li><li id="618f" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc js jj jk jl bi translated">查看权重、偏差或其他张量随时间变化的直方图</li></ul><p id="43a9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我已经使用torch.utils.tensorboard中的SummaryWriter为培训和测试添加了度量、IoU和损耗值的标量值</p><p id="d888" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">tensorboard配置文件是使用Google Colab的runs文件夹创建的。我从本地下载的runs文件夹中创建了一个tar.gz。</p><p id="5016" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">解压缩后，使用命令启动tensorboard:</p><p id="3e96" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">张量板— logdir=runs</p><p id="a1db" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">输出可以在<a class="ae jr" href="http://localhost:6006" rel="noopener ugc nofollow" target="_blank"> http://localhost:6006 </a>中找到</p><p id="886f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">各种张量板图如下:</p><h1 id="9fef" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">a.培训和测试损失</h1><figure class="kx ky kz la fd lb er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es kw"><img src="../Images/f9f15b7114fe7b0b23584b5c291ed050.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hvK8KlRECX7--K7Slktbdw.png"/></div></div></figure><h1 id="c48d" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">分析:</h1><p id="96ae" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">从图中可以明显看出，训练损失在第一个时期减少到大约0.2，并在那里保持不变</p><p id="6ddb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">测试图在0.118和0.126之间小范围波动。所以测试中的损失值比训练好。这可能是因为我在训练中使用了图像增强</p><h1 id="b84f" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">b.培训和测试IoU值</h1><figure class="kx ky kz la fd lb er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es kw"><img src="../Images/22aaae012eafe9774466693f1b20cd4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0AIsVQSJbiN9-CASnrJEKw.png"/></div></div></figure><p id="7ca2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">根据训练IoU，很明显，IoU值最初增加到大约0.92，然后在0.94和0.95之间保持稳定</p><p id="77c4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于测试，IoU值在0.948和0.95的小范围内保持稳定</p><h1 id="54e1" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">二。cProfile:</h1><p id="827e" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">cProfile用于分析Python程序。</p><p id="5751" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我在Jupyter笔记本的开头使用下面几行代码启用了cProfile</p><p id="323e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">pr = cProfile。Profile() pr.enable()</p><p id="c1ce" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在Jupyter notebook的末尾，我禁用了cProfile，并将统计数据转储到文件cprofile_stats.txt中</p><p id="1c07" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我已经在本地下载了文件cprofile_stats.txt，并使用cprofilev程序进行分析</p><p id="e10b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">cprofilev -f cprofile_stats.txt</p><p id="d652" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">cProfile输出可在<a class="ae jr" href="http://127.0.0.1:4000" rel="noopener ugc nofollow" target="_blank"> http://127.0.0.1:4000 </a>获得</p><p id="d8a4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">以下是cProfile的部分截图:</p><figure class="kx ky kz la fd lb er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es kw"><img src="../Images/87fc35d78f1aebded3924db77d419896.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aWdtY11ZMABTsVlpCOc9nw.png"/></div></div></figure><figure class="kx ky kz la fd lb er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es kw"><img src="../Images/6731b085a410e4b6fac03a668130c333.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zwOzTSQPekLVdWBImN502w.png"/></div></div></figure><h1 id="dedb" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">分析:</h1><p id="175a" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">train_test_utils.py第77、24和29行消耗大量时间。第77行与训练方法相关，第24行和第29行与使用的GPU分析挂钩相关，将被删除</p><p id="0e05" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">另一个消耗时间的组件是unet_model_small.py，第115行中的转发函数也消耗了大量时间</p><p id="9457" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">像tornado/stack _ context . py zmq/event loop/zmq _ stream . py这样的Python库也会消耗大量时间</p><p id="c352" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">另一个耗时的方法是tqdm/notebook.py tqdm/std.py，我可以探索任何可用的轻量级版本。</p><p id="f3a8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">torch/util/data/data_loader.py和torch/util/data/_ utils/fetch . py同样消耗时间，可以通过增加num_workers属性来改善。</p><h1 id="a336" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">三。GPU评测</h1><p id="571b" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">我已经根据以下文章编写了GPU性能分析的培训代码:</p><p id="b52e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae jr" href="https://www.sicara.ai/blog/2019-28-10-deep-learning-memory-usage-and-pytorch-optimization-tricks" rel="noopener ugc nofollow" target="_blank">https://www . si cara . ai/blog/2019-28-10-deep-learning-memory-usage-and-py torch-optimization-tricks</a></p><p id="7d86" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我已经将内存配置文件转换为熊猫数据帧，并从那里下载了。csv文件。下面显示了一些记录:</p><figure class="kx ky kz la fd lb er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es lw"><img src="../Images/ae85705f5a30cce8ee591bdfb2679e00.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3lwrvBUZNLcASXbf1CZT_A.png"/></div></div></figure><p id="feb2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后几条记录depthwise_separable_conv，BatchNorm2d使用的mem_cached值1000341504太高，需要进一步注意。</p><h1 id="9324" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">四。时间测量</h1><p id="8fd3" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">我测量了复制zip文件、解压zip文件以及训练的时间。</p><p id="2d2f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">(所有测量单位都是秒)</p><p id="3d5f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">复制压缩文件所花的总时间:16860.688686868617</p><p id="1aa3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">解压压缩文件所花的总时间:18660.688686868617</p><h1 id="191e" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">a.历元与训练时间图</h1><figure class="kx ky kz la fd lb er es paragraph-image"><div class="er es lx"><img src="../Images/3a96af924a4f3f3ee94cac14934dd88e.png" data-original-src="https://miro.medium.com/v2/resize:fit:678/format:webp/1*SYUEXxzpn19tTBiYY-m3bg.png"/></div></figure><h1 id="affa" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">b.历元与数据加载时间图</h1><figure class="kx ky kz la fd lb er es paragraph-image"><div class="er es ly"><img src="../Images/b5e44eec6bb84df8052d4ae601202631.png" data-original-src="https://miro.medium.com/v2/resize:fit:686/format:webp/1*jLCaD0l9TmgLXPA0gUCjRg.png"/></div></figure><h1 id="e3e9" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">c.历元与杂项时间图</h1><figure class="kx ky kz la fd lb er es paragraph-image"><div class="er es lz"><img src="../Images/e4c932d901bbacc093b9a8b6d9337d5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:654/format:webp/1*1K-PZPkIYdNXFwOBhA0-fA.png"/></div></figure><h1 id="7144" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">分析:</h1><p id="4090" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">根据该数据，训练时间逐渐增加到大约60秒，然后略微减少。数据加载时间和杂项时间在各个时期几乎是恒定的。</p><p id="0147" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">通过更改Dataloader中的num_workers属性，可以进一步减少数据加载时间。</p><h1 id="7a91" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">动词 （verb的缩写）型号的MACs值:</h1><p id="be8b" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">乘加(MAC)运算给出了模型在运算次数方面的表现。安装thop库并使用profile方法计算MACs值，如下所示:</p><p id="0b3b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">苹果电脑:892294400.0</p><h1 id="faa6" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">动词 （verb的缩写）面临的问题和我如何解决</h1><h1 id="1331" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">I .损失函数</h1><p id="0a92" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">最初，我使用BCELogitsLoss进行遮罩和深度预测，但是深度图像质量并不好。当我使用SSIM深度和BCEWitLogitsLoss蒙版，我发现深度图像更好，甚至蒙版图像IoU约为0.95，这是非常好的</p><h1 id="b18a" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">二。解压缩批处理zip图像文件</h1><p id="c772" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">最初我试图在google drive中解压图片的zip文件。每批图像拍摄时间接近2小时。因此，我改变了策略，尝试将图像压缩文件复制到本地的Colab，然后解压缩，这大大减少了时间。然而，缺点是</p><h1 id="8133" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">三。禁用Colab GPU访问:</h1><p id="da8b" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">我的GPU访问Colab帐户被暂停，原因是我的使用限制很高。所以改成了Colab Pro按月付费订阅</p><h1 id="1174" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">四。Jupyter笔记本挂了，colab经常断线</h1><p id="7700" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">Jupyter笔记本挂了很多次(比如说断网一段时间后)。我意识到这是因为我在几次迭代后显示了太多的图像。所以我把每个时期的图像显示次数减少到只有两次。尽管如此，我还是遇到了问题，所以我使用了来自https://github.com/satyajitghana/colab-keepalive的chrome扩展。因为我也定期保存模型到谷歌驱动器。万一我不能查看Jupyter笔记本，我会继续查看新的模型权重文件，以了解Colab仍在Jupyter笔记本上工作</p><h1 id="4996" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">不及物动词批量选择</h1><p id="936e" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">最初我尝试更大的批量(256，124)，但是我的内存不够了。最后，我发现批量100没有任何内存问题</p><h1 id="33d7" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">不及物动词结论</h1><p id="0007" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">在这个项目中，我致力于预测给定背景和前景叠加背景图像的遮罩和深度。我使用了只有748K参数(即小于1M的参数)的简化UNet模型，并预测了几乎更接近地面真实值的掩模和深度。Mask IoU在0.95左右。</p><p id="6787" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我使用了各种分析工具:tensorboard、cprofile、GPU profiler以及为模型计算的MACS值。</p><h1 id="5e77" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">七。承认</h1><p id="25bf" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">本文基于人工智能学院的泛视觉人工智能4第一阶段的最终项目。非常感谢人工智能学院为这个项目提供机会。另外，特别感谢Chunduri Balaji Tilak在这个项目上对我的帮助</p></div></div>    
</body>
</html>