<html>
<head>
<title>Wine quality prediction using PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用PyTorch预测葡萄酒质量</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/wine-quality-prediction-using-pytorch-2a291670dd66?source=collection_archive---------12-----------------------#2020-05-29">https://medium.com/analytics-vidhya/wine-quality-prediction-using-pytorch-2a291670dd66?source=collection_archive---------12-----------------------#2020-05-29</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><blockquote class="if ig ih"><p id="9898" class="ii ij ik il b im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg hb bi translated"><strong class="il hj">葡萄酒是你唯一能喝的艺术品</strong> <em class="hi">(引自路易斯·费尔南多·奥利韦利)</em></p></blockquote><figure class="ji jj jk jl fd jm er es paragraph-image"><div role="button" tabindex="0" class="jn jo di jp bf jq"><div class="er es jh"><img src="../Images/dfa28f88831ff4c0936bc4bb1da79690.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fOkcWRLk2w03C9FdySAYmw.png"/></div></div></figure><p id="d3ed" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">这句话推断了我们社会的葡萄酒标准。它不仅是一种饮料，本身也是一种生活方式。因此，葡萄酒的质量真的很重要。</p><p id="f0b2" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">一般来说，葡萄酒是根据其质量的感官数据来评分的。但是如果我们有一些关于它的心理测量数据，比如酸度、密度、含糖量等等。那么我们也可以预测质量分数。</p><p id="0105" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">正如你们中的一些人可能已经猜到的，这里我们可以使用机器学习或神经网络模型来做到这一点。我们只需要在具有与其相关联的质量分数的心理测量数据上进行训练，然后使用优化的模型来从心理测量数据预测质量分数。</p><blockquote class="if ig ih"><p id="5cf0" class="ii ij ik il b im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg hb bi translated">如果你是深度学习的初学者，这肯定适合你…..</p><p id="d109" class="ii ij ik il b im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg hb bi translated">坚持住。最后你会对如何从神经网络开始有一个清晰的想法。</p></blockquote><p id="0bad" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">因此，在这里我们将建立一个非常简单的神经网络，PyTorch只有输入和输出层。</p><p id="778f" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated"><strong class="il hj"> PyTorch </strong>是基于<a class="ae jw" href="https://en.wikipedia.org/wiki/Torch_(machine_learning)" rel="noopener ugc nofollow" target="_blank"> Torch </a>库的开源机器学习库，用于各种深度学习应用，如计算机视觉和自然语言处理，主要由脸书的AI研究实验室(FAIR)开发。</p><p id="2019" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated"><strong class="il hj"> Tensorflow，Keras，MXNet，Caffe2 </strong>等。是pytorch的一些替代品。</p><p id="c406" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">张量<strong class="il hj">是一个n维数据容器。和NumPy的ndarray挺像的。比如1d-张量是向量，2d-张量是矩阵，3d-张量是立方体，4d-张量是立方体的向量。</strong></p><p id="df5d" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">这些张量被用作深度学习网络的基本构建模块。</p><blockquote class="if ig ih"><p id="2f96" class="ii ij ik il b im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg hb bi translated"><em class="hi">你可以在这里</em>  <em class="hi">阅读我关于几个基本PyTorch张量函数</em> <a class="ae jw" rel="noopener" href="/@sksplay7/5-important-pytorch-tensor-functions-7ff9b5940285?source=your_stories_page---------------------------"> <em class="hi">的帖子。</em></a></p></blockquote><h1 id="804f" class="jx jy hi bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku bi translated">但是首先，让我们得到数据</h1><p id="bc7e" class="pw-post-body-paragraph ii ij hi il b im kv io ip iq kw is it jt kx iw ix ju ky ja jb jv kz je jf jg hb bi translated">数据集链接:<a class="ae jw" href="https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/UC IML/red-wine-quality-cortez-et-al-2009</a></p><figure class="ji jj jk jl fd jm"><div class="bz dy l di"><div class="la lb l"/></div></figure><p id="c9ec" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">这里我们将根据其他特征预测<strong class="il hj">葡萄酒质量</strong>。</p><h1 id="27a6" class="jx jy hi bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku bi translated">分成训练集和测试集</h1><figure class="ji jj jk jl fd jm"><div class="bz dy l di"><div class="la lb l"/></div></figure><figure class="ji jj jk jl fd jm"><div class="bz dy l di"><div class="la lb l"/></div></figure><p id="b6a6" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">我们提到数据类型为float32，因为PyTorch张量的数据类型默认为float32。由于我们将创建权重和偏差张量，拥有相同的数据类型将避免任何未来的冲突。</p><figure class="ji jj jk jl fd jm"><div class="bz dy l di"><div class="la lb l"/></div></figure><figure class="ji jj jk jl fd jm"><div class="bz dy l di"><div class="la lb l"/></div></figure><figure class="ji jj jk jl fd jm"><div class="bz dy l di"><div class="la lb l"/></div></figure><p id="d5a0" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">因此，我们保留了1200份培训记录和399份测试记录。让我们看看训练集和测试集的形状。</p><figure class="ji jj jk jl fd jm"><div class="bz dy l di"><div class="la lb l"/></div></figure><h1 id="1f79" class="jx jy hi bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku bi translated">将输入和目标矩阵转换成张量</h1><p id="6f04" class="pw-post-body-paragraph ii ij hi il b im kv io ip iq kw is it jt kx iw ix ju ky ja jb jv kz je jf jg hb bi translated">我们需要将数据转换为张量来执行进一步的操作，并在我们的神经网络中使用它们。</p><figure class="ji jj jk jl fd jm"><div class="bz dy l di"><div class="la lb l"/></div></figure><p id="b420" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated"><strong class="il hj">。from_numpy() </strong> - &gt;将numpy数组转换为张量</p><h1 id="e8f6" class="jx jy hi bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku bi translated">线性回归模型</h1><p id="bfda" class="pw-post-body-paragraph ii ij hi il b im kv io ip iq kw is it jt kx iw ix ju ky ja jb jv kz je jf jg hb bi translated">在线性回归中，模型函数是一个线性方程，其中变量的阶数为1，带有系数和偏差项。</p><p id="e1c9" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">因此，由于输入矩阵中有11个变量，等式的形式如下:</p><blockquote class="if ig ih"><p id="d0b8" class="ii ij ik il b im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg hb bi translated">w1 \feature 1+w2 \feature 2+…..+w11 \feature 11+b =目标</p><p id="b0c8" class="ii ij ik il b im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg hb bi translated">w1∫x(1，1)+w2∫x(1，2) +…..+w11∫x(1，11) + b = y1</p><p id="9463" class="ii ij ik il b im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg hb bi translated">w1∫x(2，1)+w2∫x(2，2) +…..+w11∫x(2，11) + b = y2</p><p id="21a7" class="ii ij ik il b im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg hb bi">…………</p><p id="9182" class="ii ij ik il b im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg hb bi translated">w1∫x(1599，1)+w2∫x(1599，2) +…..+w11∫x(1599，11) + b = y1599</p></blockquote><p id="e131" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated"><strong class="il hj"> w </strong> =权重矩阵和<strong class="il hj">b</strong>=偏差</p><figure class="ji jj jk jl fd jm er es paragraph-image"><div class="er es lc"><img src="../Images/8297807b8f39a6c8e7e2fb002f44d090.png" data-original-src="https://miro.medium.com/v2/resize:fit:1118/format:webp/1*Tq87aM5b5c5V2c4ElMpenw.png"/></div><figcaption class="ld le et er es lf lg bd b be z dx translated">无隐层神经网络</figcaption></figure><h2 id="bf1f" class="lh jy hi bd jz li lj lk kd ll lm ln kh jt lo lp kl ju lq lr kp jv ls lt kt lu bi translated">为模型创建权重和偏差</h2><figure class="ji jj jk jl fd jm"><div class="bz dy l di"><div class="la lb l"/></div></figure><p id="bc8b" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated"><strong class="il hj"> requires_grad = True </strong> - &gt;它被设置为True，因为我们需要损失函数的梯度或导数w.r.t .的权重和偏差来优化模型以获得低误差或损失。</p><h1 id="fe99" class="jx jy hi bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku bi translated">定义模型</h1><figure class="ji jj jk jl fd jm"><div class="bz dy l di"><div class="la lb l"/></div><figcaption class="ld le et er es lf lg bd b be z dx translated">这将返回预测值</figcaption></figure><p id="bbb4" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated"><strong class="il hj">。mm() </strong> - &gt;矩阵乘法</p><p id="41d2" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated"><strong class="il hj">。t() </strong> - &gt;转置</p><h1 id="085c" class="jx jy hi bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku bi translated">损失函数</h1><p id="e428" class="pw-post-body-paragraph ii ij hi il b im kv io ip iq kw is it jt kx iw ix ju ky ja jb jv kz je jf jg hb bi translated">为了比较实际值和预测值，我们可以使用不同的指标，其中之一是<strong class="il hj">均方误差</strong>。</p><p id="cf78" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">它是实际值与其各自预测值之差的平方和的平均值。</p><figure class="ji jj jk jl fd jm er es paragraph-image"><div class="er es lv"><img src="../Images/b52c84505716c8c7861270d12fd43128.png" data-original-src="https://miro.medium.com/v2/resize:fit:710/format:webp/1*JCGJpM4sleClep1wyeWqXQ.png"/></div><figcaption class="ld le et er es lf lg bd b be z dx translated">均方误差公式</figcaption></figure><figure class="ji jj jk jl fd jm"><div class="bz dy l di"><div class="la lb l"/></div></figure><p id="5670" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated"><strong class="il hj">。加法运算的sum() </strong> - &gt;</p><p id="d06e" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated"><strong class="il hj">。numel() </strong> - &gt;返回该张量中元素的数量</p><h1 id="0690" class="jx jy hi bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku bi translated">流程:</h1><ul class=""><li id="16f7" class="lw lx hi il b im kv iq kw jt ly ju lz jv ma jg mb mc md me bi translated">采用权重和偏差的随机值计算预测值</li><li id="71cb" class="lw lx hi il b im mf iq mg jt mh ju mi jv mj jg mb mc md me bi translated">根据指标找出实际值和预测值之间的损失或误差</li><li id="afd0" class="lw lx hi il b im mf iq mg jt mh ju mi jv mj jg mb mc md me bi translated">找出损失函数相对于权重和偏差的梯度</li><li id="41c0" class="lw lx hi il b im mf iq mg jt mh ju mi jv mj jg mb mc md me bi translated">基于梯度调整权重和偏差</li><li id="d57e" class="lw lx hi il b im mf iq mg jt mh ju mi jv mj jg mb mc md me bi translated">将梯度重置为零</li><li id="9781" class="lw lx hi il b im mf iq mg jt mh ju mi jv mj jg mb mc md me bi translated">使用权重和偏差的更新值预测结果</li></ul><p id="d683" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">我们将看到，随着这一过程的每次重复，误差在减小。因此，重复这个过程，直到误差减少到令人满意的值。</p><h1 id="38eb" class="jx jy hi bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku bi translated">模特培训</h1><figure class="ji jj jk jl fd jm"><div class="bz dy l di"><div class="la lb l"/></div></figure><p id="4b33" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated"><strong class="il hj">历元</strong>:表示单遍通过训练数据。在这里，我们将根据数据对模型进行200次训练。</p><p id="38dd" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated"><strong class="il hj">。向后()</strong>:计算渐变。</p><p id="c598" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated"><strong class="il hj">。grad </strong>:损失函数w.r.t. <strong class="il hj"> w </strong>和<strong class="il hj"> b </strong>的梯度存储在它们的。梯度属性</p><p id="5990" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated"><strong class="il hj">。zero() </strong>:用于在下一次计算前将存储的梯度归零。实际上渐变被添加到了<em class="ik">。对每个历元的属性进行分级，而不是用新值替换它。因此，我们需要在存储新值之前清除该值</em></p><p id="09c5" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated"><strong class="il hj">学习率</strong>:这里的<em class="ik"> 1e-5 </em>是学习率。我们不是通过梯度值直接减少权重和偏差，而是通过梯度的一部分来减少权重和偏差，以便我们采取小的下坡步骤(朝向损失函数曲线的最小值)。这确保了我们不会跳过最小值而到达点。</p><p id="817f" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">我们可以看到，随着时间的推移，损失在减少。通过训练50000个时期的模型，我们可以得到0.57的误差，这是非常令人满意的，因为分数是从0到10，差1。</p><p id="b4ef" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated"><strong class="il hj">让我们使用优化了权重和值的模型在测试数据集上进行预测。</strong></p><h1 id="ffdd" class="jx jy hi bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku bi translated">合法性错误</h1><figure class="ji jj jk jl fd jm"><div class="bz dy l di"><div class="la lb l"/></div></figure><p id="856f" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">我们得到了0.66的验证误差，这是非常令人满意的。我们可以通过打印出<strong class="il hj"> preds </strong>变量来得到预测值。</p><p id="55db" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">损失或误差取决于我们随机选择的权重和偏差。我们可以重新运行该单元和模型训练单元，以查看损耗是否有轻微变化。</p></div><div class="ab cl mk ml gp mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="hb hc hd he hf"><p id="95e4" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated"><em class="ik">为了达到低错误率，我们还可以在开始建模部分之前进行一些数据处理。</em></p><h2 id="8e19" class="lh jy hi bd jz li lj lk kd ll lm ln kh jt lo lp kl ju lq lr kp jv ls lt kt lu bi translated">让我们试一试…..</h2><p id="68de" class="pw-post-body-paragraph ii ij hi il b im kv io ip iq kw is it jt kx iw ix ju ky ja jb jv kz je jf jg hb bi translated">在这里，我试图从数据中显示一些随机观察的实际和预测的质量分数。</p><p id="3221" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">但是在将输入传递给linear_model()方法之前，我们需要将其转换为所需形状的张量。</p><figure class="ji jj jk jl fd jm"><div class="bz dy l di"><div class="la lb l"/></div></figure><p id="eafa" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">这里我们可以看到实际值和预测值非常接近。</p></div><div class="ab cl mk ml gp mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="hb hc hd he hf"><p id="ef79" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated"><strong class="il hj"> <em class="ik">但是等等…..</em>T13】</strong></p><p id="19f4" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">我们在这里手动操作，从定义模型、生成随机权重和偏差到优化参数。PyTorch有没有可以自动做到这一点的库和方法？</p><p id="5c74" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated"><em class="ik">有，有。</em></p><p id="a3ca" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated"><strong class="il hj">我们将在接下来的帖子中讨论如何使用内置函数和使用神经网络中的隐藏层来构建相同的模型。</strong></p><blockquote class="if ig ih"><p id="3967" class="ii ij ik il b im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg hb bi translated">敬请关注…..</p></blockquote><h1 id="8dbb" class="jx jy hi bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku bi translated">参考</h1><p id="9e03" class="pw-post-body-paragraph ii ij hi il b im kv io ip iq kw is it jt kx iw ix ju ky ja jb jv kz je jf jg hb bi translated">可以参考Aakash N S的这本精彩笔记本:</p><p id="f2ce" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated"><a class="ae jw" href="https://jovian.ml/aakashns/02-linear-regression" rel="noopener ugc nofollow" target="_blank">https://jovian.ml/aakashns/02-linear-regression</a></p><p id="979d" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">感谢FreeCodeCamp提供这个精彩的深度学习课程。</p><p id="43fe" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">Pytorch的官方文件:<a class="ae jw" href="https://pytorch.org/docs/stable/index.html" rel="noopener ugc nofollow" target="_blank">https://pytorch.org/docs/stable/index.html</a></p><p id="fbc5" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">请随时提供您的反馈。</p><p id="7e0f" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated"><strong class="il hj">在</strong>:<a class="ae jw" href="https://www.linkedin.com/in/subham-kumar-sahoo-55563a136" rel="noopener ugc nofollow" target="_blank">https://www.linkedin.com/in/subham-kumar-sahoo-55563a136</a>和我联系</p></div></div>    
</body>
</html>