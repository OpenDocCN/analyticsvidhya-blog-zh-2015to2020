<html>
<head>
<title>Sentiment Classifier using Tfidf</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Tfidf的情感分类器</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/sentiment-classifier-using-tfidf-3ffce3f1cbd5?source=collection_archive---------0-----------------------#2019-11-04">https://medium.com/analytics-vidhya/sentiment-classifier-using-tfidf-3ffce3f1cbd5?source=collection_archive---------0-----------------------#2019-11-04</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/678c41c2bd15c0a630a324b32a16cca7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1374/format:webp/1*gPNocfF6D-eFSOvZPrCPfw.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated"><a class="ae iq" href="https://webhose.io/blog/api/how-to-use-rated-reviews-for-sentiment-classification/" rel="noopener ugc nofollow" target="_blank">图片来源</a></figcaption></figure><p id="10d1" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated"><em class="jp">本文是</em><strong class="it hj">NLP入门系列<em class="jp">的第二篇。</em> </strong> <em class="jp">既然我已经在</em> <a class="ae iq" rel="noopener" href="/@ajeet.singh.ec14/everything-to-get-started-with-nlp-3ccfbb7405a2?source=friends_link&amp;sk=a66eaccadf8dcc00e4baf07d70ee1c33"> <strong class="it hj"> <em class="jp">第一部分</em> </strong> </a> <em class="jp">中解释了所有的理论，这里就不再解释了。</em></p><blockquote class="jq jr js"><p id="bc59" class="ir is jp it b iu iv iw ix iy iz ja jb jt jd je jf ju jh ji jj jv jl jm jn jo hb bi translated">注意:我假设你有一些Python编码的经验。</p></blockquote><p id="8849" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">在这篇文章中，我们将制作一个情感分类器。所以没有进一步的告别，让我们开始吧。</p><h1 id="40e0" class="jw jx hi bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">数据集</h1><p id="892b" class="pw-post-body-paragraph ir is hi it b iu ku iw ix iy kv ja jb jc kw je jf jg kx ji jj jk ky jm jn jo hb bi translated">第一步是下载数据集。这将会:</p><pre class="kz la lb lc fd ld le lf lg aw lh bi"><span id="a638" class="li jx hi le b fi lj lk l ll lm">!wget <a class="ae iq" href="http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz" rel="noopener ugc nofollow" target="_blank">http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz</a></span></pre><p id="d6ba" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">你会得到这样的东西:</p><figure class="kz la lb lc fd ij er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es ln"><img src="../Images/daeb4616c7f9a3d19e446e8229ee59b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q66-6BkiOPHSidmIZrLxJg.png"/></div></div></figure><p id="23bc" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">下载的数据集在一个<strong class="it hj"> tar </strong>文件中。让我们使用<strong class="it hj"> shutil </strong>模块提取它。<code class="du ls lt lu le b"><a class="ae iq" href="https://docs.python.org/3/library/shutil.html#module-shutil" rel="noopener ugc nofollow" target="_blank">shutil</a></code>模块提供了许多对文件和文件集合的高级操作。特别地，提供了支持文件复制和删除的功能。更多信息请点击<a class="ae iq" href="https://docs.python.org/3/library/shutil.html" rel="noopener ugc nofollow" target="_blank">此处</a></p><pre class="kz la lb lc fd ld le lf lg aw lh bi"><span id="cd43" class="li jx hi le b fi lj lk l ll lm">import shutil<br/>shutil.unpack_archive("aclImdb_v1.tar.gz", "/content/")</span></pre><p id="d8ef" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">如果你做的一切都是正确的，你将有一个这样的文件结构:</p><figure class="kz la lb lc fd ij er es paragraph-image"><div class="er es lv"><img src="../Images/8615dcbbdb5ec0550c6b970f2d439a50.png" data-original-src="https://miro.medium.com/v2/resize:fit:844/format:webp/1*bm28bd1-VnlWLmIT1f3I7Q.png"/></div></figure><h2 id="3591" class="li jx hi bd jy lw lx ly kc lz ma mb kg jc mc md kk jg me mf ko jk mg mh ks mi bi translated">数据集概述</h2><ul class=""><li id="1110" class="mj mk hi it b iu ku iy kv jc ml jg mm jk mn jo mo mp mq mr bi translated">这是IMDB电影评论数据集。多亏了斯坦福大学的研究人员，这个数据集被标注了正负标签。数据集可以通过<a class="ae iq" href="http://ai.stanford.edu/~amaas/data/sentiment/" rel="noopener ugc nofollow" target="_blank">链接</a>访问。</li><li id="f76f" class="mj mk hi it b iu ms iy mt jc mu jg mv jk mw jo mo mp mq mr bi translated">这个数据集包含25000个正面和25000个负面的例子，这些例子都预先标注了标签。这个数据集还包含未注释的例子，可供研究人员进一步使用。</li><li id="c356" class="mj mk hi it b iu ms iy mt jc mu jg mv jk mw jo mo mp mq mr bi translated">在训练和测试文件夹中，我们将有12，500个正面和12，500个负面示例。请注意，每个例子是一个电影评论，它是在一个单独的文本文件中。所以我们将有25K个文本文件用于训练和测试。</li><li id="01cf" class="mj mk hi it b iu ms iy mt jc mu jg mv jk mw jo mo mp mq mr bi translated">数据集最多包含每部电影30条评论。确保没有一部电影变得更有影响力。</li><li id="428e" class="mj mk hi it b iu ms iy mt jc mu jg mv jk mw jo mo mp mq mr bi translated">如果这部电影被给予超过7颗星，那么它是一个积极的评论，如果低于4，那么消极的评论。</li><li id="bf1d" class="mj mk hi it b iu ms iy mt jc mu jg mv jk mw jo mo mp mq mr bi translated">正反例数量相等，所以可以用准确率作为度量。</li></ul><h1 id="c899" class="jw jx hi bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">下载和导入包</h1><figure class="kz la lb lc fd ij er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es mx"><img src="../Images/ed765999d011c934bd72c5f5b144f73a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MV8jpTug2tCZceYNKJNfrQ.jpeg"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">托比·斯托达特在<a class="ae iq" href="https://unsplash.com/s/photos/packages?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><p id="b9cb" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">我们将下载wordnet和stopwords包。这两个包对于文本预处理都是必要的。这些是由NLTK提供的。</p><pre class="kz la lb lc fd ld le lf lg aw lh bi"><span id="ffe3" class="li jx hi le b fi lj lk l ll lm">import nltk<br/>nltk.download('wordnet')<br/>nltk.download('stopwords')</span></pre><p id="6e65" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">让我们进口其他重要的东西。</p><pre class="kz la lb lc fd ld le lf lg aw lh bi"><span id="d6b1" class="li jx hi le b fi lj lk l ll lm">import os<br/>import pandas as pd<br/>import numpy as np<br/>from nltk.corpus import stopwords<br/>from sklearn.feature_extraction.text import TfidfVectorizer<br/>from sklearn.linear_model import LogisticRegression</span></pre><h1 id="8283" class="jw jx hi bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">数据集的数据帧</h1><p id="1469" class="pw-post-body-paragraph ir is hi it b iu ku iw ix iy kv ja jb jc kw je jf jg kx ji jj jk ky jm jn jo hb bi translated">让我们从给定的数据集制作训练和测试数据帧。这里，我们将从文件夹中读取文件，并在数据帧中用相应的标签标记它们。例如，在<strong class="it hj"> Train </strong>文件夹内的<strong class="it hj"> pos </strong>文件夹中，我们有12500条评论。都是正面评价。我们将制作一个熊猫数据框架，它将有两列:<br/> 1。点评:文件的正文<br/> 2。标签:1 <br/>因为所有的评论都是正面的，所以我们将在<strong class="it hj">标签</strong>列中有12，500行作为1。</p><pre class="kz la lb lc fd ld le lf lg aw lh bi"><span id="1cd7" class="li jx hi le b fi lj lk l ll lm">path = "/content/aclImdb/train/pos/"<br/>temp = []</span><span id="2788" class="li jx hi le b fi my lk l ll lm">for file in os.listdir(path):<br/>    with open(os.path.join(path + file), "r") as f:<br/>        temp.append(f.readlines()[0])</span><span id="1f03" class="li jx hi le b fi my lk l ll lm">pos = pd.DataFrame({"reviews": temp, <br/>               "labels": list(np.ones(len(first_1000), dtype=int))})</span></pre><p id="fe08" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">下面的图片会让事情变得清晰。如前所述，我们在<strong class="it hj">评论</strong>栏中有电影评论，在<strong class="it hj">标签</strong>栏中有1ns。</p><figure class="kz la lb lc fd ij er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es mz"><img src="../Images/c73af60684875b92fd13a8a84a3d9832.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xr0wtz98ETF824gje6idtA.png"/></div></div></figure><p id="6c33" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">现在，类似地为训练数据的负面评论创建一个数据框架，或者您可以直接合并到该数据集中。不管你最后做什么，你都应该有一个数据集<strong class="it hj"> train_data </strong>(你可以选择任何你喜欢的名字)，其中前半行有正面评价，后半行有负面评价。尽管你也可以混淆这些行。无论你喜欢什么。</p><p id="a43f" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">最后，您应该有类似这样的标签分布:</p><figure class="kz la lb lc fd ij er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es na"><img src="../Images/05f83aead2ae8aafc8a3651a231a7b1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9fNyqDUCBxDkXfJW7ucMwA.png"/></div></div></figure><p id="a3f8" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">如你所见，我们有相同数量的正面和负面例子。同样，创建一个数据集<strong class="it hj"> test_data </strong>进行测试。</p></div><div class="ab cl nb nc gp nd" role="separator"><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng"/></div><div class="hb hc hd he hf"><h1 id="3dd8" class="jw jx hi bd jy jz ni kb kc kd nj kf kg kh nk kj kk kl nl kn ko kp nm kr ks kt bi translated">预处理</h1><figure class="kz la lb lc fd ij er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es nn"><img src="../Images/07231cff5a3861aba1bac5dd954f336f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fkbRDeElt0f-79MmzuYpng.jpeg"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">照片由<a class="ae iq" href="https://unsplash.com/@shemul?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">沙哈达特·谢穆尔</a>在<a class="ae iq" href="https://unsplash.com/s/photos/processing?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="afa4" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">我们将为以下预处理任务创建一些辅助函数:</p><p id="8580" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated"><strong class="it hj"> <em class="jp">标记化</em> </strong></p><pre class="kz la lb lc fd ld le lf lg aw lh bi"><span id="33bf" class="li jx hi le b fi lj lk l ll lm">def tokenize_data(dataset):<br/>    tokenizer = nltk.tokenize.TreebankWordTokenizer()<br/>    for i in range(dataset.shape[0]):<br/>       dataset["reviews"][i] = tokenizer.tokenize(dataset["reviews"][i])<br/>    return dataset</span></pre><p id="2105" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated"><strong class="it hj"> <em class="jp">停止字清除</em> </strong></p><pre class="kz la lb lc fd ld le lf lg aw lh bi"><span id="e6ea" class="li jx hi le b fi lj lk l ll lm">def remove_stop_words(dataset):<br/>    stop_words = set(stopwords.words('english'))<br/>    for i in range(dataset.shape[0]):<br/>        dataset["reviews"][i] = ([token.lower() for token in dataset["reviews"][i] if token not in stop_words])<br/>    <br/>    return dataset</span></pre><p id="d513" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated"><strong class="it hj"> <em class="jp">规范化</em> </strong></p><pre class="kz la lb lc fd ld le lf lg aw lh bi"><span id="12ed" class="li jx hi le b fi lj lk l ll lm">def normalize(dataset):<br/>    lemmatizer = nltk.stem.WordNetLemmatizer()<br/>    for i in range(dataset.shape[0]):<br/>        dataset.reviews[i] = " ".join([lemmatizer.lemmatize(token) for token in dataset.reviews[i]]).strip()</span><span id="df1d" class="li jx hi le b fi my lk l ll lm">    return dataset</span></pre><p id="388f" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated"><strong class="it hj"> <em class="jp">标点符号去除</em> </strong></p><pre class="kz la lb lc fd ld le lf lg aw lh bi"><span id="831b" class="li jx hi le b fi lj lk l ll lm">def remove_garbage(dataset):<br/>    garbage = "~`!@#$%^&amp;*()_-+={[}]|\:;'&lt;,&gt;.?/"<br/>    for i in range(dataset.shape[0]):<br/>    dataset.reviews[i] = "".join([char for char in dataset.reviews[i] if char not in garbage])</span><span id="6b3b" class="li jx hi le b fi my lk l ll lm">    return dataset</span></pre><blockquote class="jq jr js"><p id="6e16" class="ir is jp it b iu iv iw ix iy iz ja jb jt jd je jf ju jh ji jj jv jl jm jn jo hb bi translated"><strong class="it hj">请注意:</strong>这种为相似的处理创建单独的函数是非常糟糕的编码实践。这只是为了解释清楚。我们可以用很少的步骤完成所有这些。并且肯定在具有非常低的计算复杂度的单个函数内。</p></blockquote><p id="791b" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">创建这些函数后(可以在单个函数中完成)，将这些函数应用于数据集。</p><pre class="kz la lb lc fd ld le lf lg aw lh bi"><span id="0f71" class="li jx hi le b fi lj lk l ll lm">train_data = tokenize_data(train_data)<br/>train_data = remove_stop_words(train_data)<br/>train_data = normalize(train_data)<br/>train_data = remove_garbage(train_data)</span><span id="9916" class="li jx hi le b fi my lk l ll lm">test_data = tokenize_data(test_data)<br/>test_data = remove_stop_words(test_data)<br/>test_data = normalize(test_data)<br/>test_data = remove_garbage(test_data)</span></pre><p id="4165" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">数据集的状态应该是这样的。</p><figure class="kz la lb lc fd ij er es paragraph-image"><div class="er es no"><img src="../Images/ca5e5f2446596144c152d2321057f961.png" data-original-src="https://miro.medium.com/v2/resize:fit:1068/format:webp/1*GZAUHatLIoluDPufhdI3Ow.png"/></div></figure><p id="fe13" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">该数据集仍未完全处理。因为这篇文章不是用于文本处理的，即使这么多的处理也会产生好的结果，所以我们将把进一步的处理留到以后。</p></div><div class="ab cl nb nc gp nd" role="separator"><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng"/></div><div class="hb hc hd he hf"><h1 id="d451" class="jw jx hi bd jy jz ni kb kc kd nj kf kg kh nk kj kk kl nl kn ko kp nm kr ks kt bi translated">特征抽出</h1><p id="13a1" class="pw-post-body-paragraph ir is hi it b iu ku iw ix iy kv ja jb jc kw je jf jg kx ji jj jk ky jm jn jo hb bi translated">现在让我们提取特征。我们将使用来自<a class="ae iq" href="https://scikit-learn.org/stable/" rel="noopener ugc nofollow" target="_blank"> sklearn </a>库的<a class="ae iq" href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html" rel="noopener ugc nofollow" target="_blank">tfidf矢量器</a>模块。我们可以创建自己的tfidf函数，但是创建已经存在并且运行良好的函数是徒劳的。</p><p id="3c64" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">第一步是拟合矢量器。我们将在整个数据集上安装矢量器。这是所有评论(培训和测试)中的内容。我们可以仅在训练数据集上拟合矢量器，但这可能有负面影响。因为一些在训练中不存在的单词可以存在于测试数据集中。这个函数将为我们完成这项工作。</p><pre class="kz la lb lc fd ld le lf lg aw lh bi"><span id="2af2" class="li jx hi le b fi lj lk l ll lm">def fit_corpus(train_data, test_data):<br/>    corpus = pd.DataFrame({"reviews": train_data["reviews"]})<br/>    corpus.reviews.append(test_data["reviews"], ignore_index=True)<br/>    tfidf = TfidfVectorizer(min_df=2, max_df=0.5, ngram_range=(1,2))<br/>    tfidf.fit(corpus["reviews"])<br/>    return tfidf</span></pre><p id="940a" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">在拟合之后，我们将转换数据集。这个函数将我们的数据集转换成tfidf向量。</p><pre class="kz la lb lc fd ld le lf lg aw lh bi"><span id="40db" class="li jx hi le b fi lj lk l ll lm">def transform_data(tfidf, dataset):<br/>    features = tfidf.transform(dataset["reviews"])<br/>    return pd.DataFrame(features.todense(), columns = tfidf.get_feature_names())</span></pre><p id="12e5" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">现在让我们调用上述两个函数并转换我们的数据集。此外，我们将培训和测试标签放在单独的变量中。</p><pre class="kz la lb lc fd ld le lf lg aw lh bi"><span id="188b" class="li jx hi le b fi lj lk l ll lm">tfidf = fit_corpus(train_data, test_data)  #Fitting the vecorizer</span><span id="7dd4" class="li jx hi le b fi my lk l ll lm">train_features = transform_data(tfidf, train_data)  #transforming <br/>test_features = transform_data(tfidf, test_data)    #Train and Test</span><span id="0e58" class="li jx hi le b fi my lk l ll lm">train_labels = train_data["labels"]  #Taking lables in separate<br/>test_labels = test_data["labels"]    #variables</span></pre><p id="8497" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">数据集应该如下所示:</p><figure class="kz la lb lc fd ij er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es np"><img src="../Images/62016156aa9008e80d3dd5ff0d281f84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IBohr7mJg5KzwvmYCwHWfQ.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">注意:列数可以变化</figcaption></figure></div><div class="ab cl nb nc gp nd" role="separator"><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng"/></div><div class="hb hc hd he hf"><h1 id="5991" class="jw jx hi bd jy jz ni kb kc kd nj kf kg kh nk kj kk kl nl kn ko kp nm kr ks kt bi translated">训练模型</h1><figure class="kz la lb lc fd ij er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es nq"><img src="../Images/1ce14681c409bd28713a3c59cde501c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Tz18n1AReRLLMtUbr0jR0A.jpeg"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">克里斯·利维拉尼在<a class="ae iq" href="https://unsplash.com/s/photos/graph?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><p id="50a6" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">因为我们已经将文本转换为特征，所以我们可以在训练数据集上应用任何分类模型。由于数据是长稀疏矩阵，简单的逻辑回归工作良好。</p><p id="fccd" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">首先，我们将<strong class="it hj">初始化模型</strong>:</p><pre class="kz la lb lc fd ld le lf lg aw lh bi"><span id="e1ad" class="li jx hi le b fi lj lk l ll lm">clf = LogisticRegression(random_state=0, solver='lbfgs')</span></pre><p id="cc6d" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">您可以从<a class="ae iq" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html" rel="noopener ugc nofollow" target="_blank">文档</a>中了解更多关于物流管理的其他参数。</p><p id="b805" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">下一步是<strong class="it hj">根据训练数据拟合模型</strong>。</p><pre class="kz la lb lc fd ld le lf lg aw lh bi"><span id="037a" class="li jx hi le b fi lj lk l ll lm">clf.fit(train_features, train_labels)</span></pre><p id="98f5" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">看来我们结束了。我们制作了情感分类模型。</p><p id="c381" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">让我们给出一些输入并检查输出:</p><figure class="kz la lb lc fd ij er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es nr"><img src="../Images/4bdc832644bde6eaaa5f9171c4d3fad1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZGCs0Pg-08vwAIA59-s88w.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">预测输出:0</figcaption></figure><figure class="kz la lb lc fd ij er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es ns"><img src="../Images/16b6232f8eab26c7f0519e8eccdf77a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Wl4UX_ZZAE-uolKhgwA0Ug.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">预测产量:1</figcaption></figure><p id="64b5" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">让我们检查一下测试数据集的准确性:</p><figure class="kz la lb lc fd ij er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es nt"><img src="../Images/7e498b2525ae766fde3da6f06a2b2d53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mykK9ie8Acd_5jHBYW2Lzg.png"/></div></div></figure><p id="ba68" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">我们得到了84.25 % 的<strong class="it hj">分。找到了。！！</strong></p><figure class="kz la lb lc fd ij er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es nu"><img src="../Images/6de67412d83c7b18815dc322b22b03b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*J73G0RtGIaSoMylUB8icDA.jpeg"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">由<a class="ae iq" href="https://unsplash.com/@benwhitephotography?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">本·怀特</a>在<a class="ae iq" href="https://unsplash.com/s/photos/success?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="119c" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">没有太多的预处理和一个基本模型，我们得到了很好的结果。ML好容易啊！！！</p><p id="f16a" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">如果你是这样想的，那么:</p><blockquote class="jq jr js"><p id="2f26" class="ir is jp it b iu iv iw ix iy iz ja jb jt jd je jf ju jh ji jj jv jl jm jn jo hb bi translated">ML比分数多得多。通过使用一些预建的库来运行模型不是ML。多探索，多学习。</p></blockquote><p id="7f8e" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">我这么说是因为我们得到了那个精确度，因为数据集已经处于相当好的状态。如果你真的想挑战自己，那就试着提高分数。</p><p id="8182" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">您可以调整参数或使用不同的算法，或者进一步清理数据集。无论你喜欢什么。</p><blockquote class="jq jr js"><p id="4c4e" class="ir is jp it b iu iv iw ix iy iz ja jb jt jd je jf ju jh ji jj jv jl jm jn jo hb bi translated">只是不要<strong class="it hj"> <em class="hi"> </em> </strong> <a class="ae iq" href="https://machinelearningmastery.com/overfitting-and-underfitting-with-machine-learning-algorithms/" rel="noopener ugc nofollow" target="_blank"> <strong class="it hj">过度拟合</strong> </a>。</p></blockquote><h2 id="5d2b" class="li jx hi bd jy lw lx ly kc lz ma mb kg jc mc md kk jg me mf ko jk mg mh ks mi bi translated">关于改进Logistic回归结果的几点注记</h2><ol class=""><li id="d4ec" class="mj mk hi it b iu ku iy kv jc ml jg mm jk mn jo nv mp mq mr bi translated">玩符号化:表情符号、感叹词等的特殊符号。可以帮忙。这些是人们经常使用的一些标记，可以告诉你很多关于评论的观点。例如，一个微笑的表情符号可能是一个很好的评价指标，而悲伤或愤怒的表情符号可能指向一个不好的评价。</li><li id="a768" class="mj mk hi it b iu ms iy mt jc mu jg mv jk mw jo nv mp mq mr bi translated">尝试不同的模型，如SVM，朴素贝叶斯等。</li><li id="524e" class="mj mk hi it b iu ms iy mt jc mu jg mv jk mw jo nv mp mq mr bi translated">扔掉BOW，用深度学习。尽管深度学习对于这种情绪分析任务的准确性提高并不令人兴奋。</li></ol><h1 id="0de1" class="jw jx hi bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">关于实现的一些注意事项</h1><ol class=""><li id="df6d" class="mj mk hi it b iu ku iy kv jc ml jg mm jk mn jo nv mp mq mr bi translated">这个tfidf矢量化和文本预处理需要大量的处理。尽量用Google Colab。它是免费的，并提供25GB内存的GPU和TPU支持。</li><li id="4f5e" class="mj mk hi it b iu ms iy mt jc mu jg mv jk mw jo nv mp mq mr bi translated">但是如果你有其他资源，你可以随时使用它们。</li><li id="88e9" class="mj mk hi it b iu ms iy mt jc mu jg mv jk mw jo nv mp mq mr bi translated">你可以在我的Github上找到代码。</li></ol><div class="nw nx ez fb ny nz"><a href="https://github.com/AjeetSingh02/Overview_of_NLP/blob/master/sentimentClassification.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="oa ab dw"><div class="ob ab oc cl cj od"><h2 class="bd hj fi z dy oe ea eb of ed ef hh bi translated">AjeetSingh02/Overview_of_NLP</h2><div class="og l"><h3 class="bd b fi z dy oe ea eb of ed ef dx translated">此时您不能执行该操作。您已使用另一个标签页或窗口登录。您已在另一个选项卡中注销，或者…</h3></div><div class="oh l"><p class="bd b fp z dy oe ea eb of ed ef dx translated">github.com</p></div></div><div class="oi l"><div class="oj l ok ol om oi on ik nz"/></div></div></a></div></div><div class="ab cl nb nc gp nd" role="separator"><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng"/></div><div class="hb hc hd he hf"><p id="b3f8" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">如果你喜欢这篇文章，那么你可以想按多少次拍手按钮就按多少次。还有，你可以在<a class="ae iq" href="https://www.linkedin.com/in/singhajeet23/" rel="noopener ugc nofollow" target="_blank"><strong class="it hj">LinkedIn</strong></a><strong class="it hj">上联系我，或者在</strong><a class="ae iq" href="https://github.com/AjeetSingh02" rel="noopener ugc nofollow" target="_blank"><strong class="it hj">GitHub</strong></a><strong class="it hj">上关注我。</strong></p><h2 id="d0d3" class="li jx hi bd jy lw lx ly kc lz ma mb kg jc mc md kk jg me mf ko jk mg mh ks mi bi translated">让我们进一步移动到<a class="ae iq" rel="noopener" href="/@ajeet.singh.ec14/nlp-libraries-and-pretrained-models-94c9a53a295a?sk=f45c6cb78399e55b30eaf0ed7b647515">下一个</a> …</h2><figure class="kz la lb lc fd ij er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es oo"><img src="../Images/bbc50f5463f7f9b6800fd64ec04b0dba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eDBY9GPq0a-M2sNlmJNF0g.jpeg"/></div></div></figure></div></div>    
</body>
</html>