<html>
<head>
<title>Generative Adversarial Networks: An encompassed view</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">生成性对抗网络:一个包含的观点</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/generative-adversarial-networks-an-encompassed-view-304258f9f238?source=collection_archive---------15-----------------------#2020-01-22">https://medium.com/analytics-vidhya/generative-adversarial-networks-an-encompassed-view-304258f9f238?source=collection_archive---------15-----------------------#2020-01-22</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="9562" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">什么是生成性对抗网络？如果你还没有听说过生成敌对网络，不要担心，你会的。深度学习中最热门的话题，他们被称为GANs，有潜力创造出在更少的人类帮助下学习更多的系统。</p><p id="31ff" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">传统观点认为，生成对抗网络(GANs)是机器学习领域一项令人兴奋的最新创新。gan是生成模型:它们创建新的数据实例，类似于你的训练数据。</p><p id="d448" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在机器学习领域，一切都可以用它们的名字来解释。因此，每当我们听到<em class="jd">生殖</em>这个名字，我们会立即想象一个场景，一个物体有能力拥有产生、起源、生产或繁殖的能力或功能。而这正是我们在甘的尝试。在机器学习中，“生成性”描述了一类统计模型，与判别模型形成对比。</p><p id="6149" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了开始这个讨论，我们可以非正式地描述一下GAN的架构。非正式的<strong class="ih hj">生成型</strong>模型可以生成新的数据实例，而<strong class="ih hj">鉴别型</strong>模型可以区分不同种类的数据实例。生成模型可以生成看起来像真实动物的新动物照片，而辨别模型可以区分狗和猫。gan只是一种生成模型。</p><p id="12e7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">通过引入一些概率概念，转向GAN的更正式的定义，其中给定一组数据实例X和一组标签Y:</p><p id="a719" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">生成型</strong>模型捕捉联合概率p(X，Y)，或者如果没有标签，只捕捉p(X)。</p><p id="e58b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">判别</strong>模型捕捉条件概率p(Y | X)。</p><p id="a6a6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">要理解GAN的，我们需要理解生成新数据的概念并不新鲜。因此，了解生成数据的传统统计和概率方法非常重要。我们有马尔可夫链来解释一个有点类似的概念。</p><p id="320d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">马尔可夫链是一个<em class="jd">离散时间随机过程:</em>一个发生在一系列时间步骤中的过程，在每个时间步骤中进行随机选择。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/e540a3d80f9fd8663fb4d4086ccdd3b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5iKKX1Kx_3152bdU3h6Miw.png"/></div></div></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es jq"><img src="../Images/2adc38026aa43421efd52842b1b72dfd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qp-uejTY0S8vuAJJefTglg.png"/></div></div></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es jr"><img src="../Images/0e423c052d3936de163037ef0b3cbce9.png" data-original-src="https://miro.medium.com/v2/resize:fit:308/format:webp/1*juEShi19-qvp0425b4xLJA.png"/></div></figure><p id="79e8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">而且，</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es js"><img src="../Images/423ce998ef181fb9a58df27977e37935.png" data-original-src="https://miro.medium.com/v2/resize:fit:324/format:webp/1*WLLPWvvrF6Ej2j0Zh0fYDg.png"/></div></figure><p id="ae9d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">满足上述等式的具有非负条目的矩阵被称为<em class="jd">随机矩阵</em>。随机矩阵的一个关键性质是它有一个<em class="jd">主左特征向量</em>对应其最大特征值，即1。</p><p id="5aa9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在马尔可夫链中，马尔可夫链的下一个状态的概率分布只取决于当前状态，而不取决于马尔可夫链如何到达当前状态。图1显示了一个具有三种状态的简单马尔可夫链。从中间状态A开始，我们以0.5的(相等)概率继续到B或C。从B或C开始，我们以1的概率继续到A。该马尔可夫链的转移概率矩阵为</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es jt"><img src="../Images/7b93e9498b863aadc93e28759f39f591.png" data-original-src="https://miro.medium.com/v2/resize:fit:448/format:webp/1*ci6UT0_2S_-O4S8llUUETw.png"/></div></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es ju"><img src="../Images/a2ae881a9afa67d8c02bb6b10c9b80ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:660/format:webp/1*RwSmAZEMb9YMsjLUig8Mvw.png"/></div><figcaption class="jv jw et er es jx jy bd b be z dx translated"><strong class="bd jz"> <em class="ka">图1: </em> </strong> <em class="ka">一个简单的三态马尔可夫链；链接上的数字表示转移概率。</em></figcaption></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es kb"><img src="../Images/816ce03f31761b78c355f366ba860604.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0EhMQmAtQ4o6w5leNTJUpg.png"/></div></div></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es kc"><img src="../Images/30955a131e88b7e8900b4f684242d620.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Fe3HFslTIEtMdYAbWxGxvg.png"/></div></div></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es kd"><img src="../Images/2050126c62c6034a4522d82601cd17bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*verjRpfZjif3Ep2N0JR-qQ.png"/></div></div></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es ke"><img src="../Images/3da67f31e58989843ec97c226bb48fdf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dyw9G3N7t6f6wBQ9YrUueQ.png"/></div></div></figure><p id="1e2c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在仔细研究了马氏链之后，我们现在处于一个非常舒适的境地来研究更多关于甘的。<em class="jd">生成模型包括数据本身的分布，并告诉你给定示例的可能性有多大。例如，预测序列中下一个单词的模型通常是生成模型(通常比GANs简单得多)，因为它们可以为单词序列分配概率。</em></p><p id="dce3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">判别模型忽略了一个给定实例是否可能的问题，只是告诉你一个标签应用于该实例的可能性有多大。</em></p><p id="d053" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">*注意:这是GAN非常一般化的定义，因为它们是生成性对抗网络的许多其他变体。</em></p><p id="7c77" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这两种模型都不需要返回代表概率的数字。我们可以通过模拟数据的分布来模拟该分布。</p><p id="adbc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">令人惊讶的是，在决策树分类器和GAN的分类器之间也存在一般的直觉。像决策树这样的判别分类器可以标记一个实例，而不需要为该标记分配概率。这种分类器仍然是一个模型，因为所有预测标签的分布将模拟标签在数据中的真实分布。</p><p id="9bd1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">类似地，生成模型可以通过产生令人信服的“假”数据来模拟分布，这些数据看起来像是从该分布中提取的。</p><p id="dc1c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">生成模型很难:</strong></p><p id="fbd7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">生成模型比类似的判别模型处理更困难的任务。生成模型必须建模更多。图像的生成模型可以捕捉像“看起来像船的东西可能会出现在看起来像水的东西附近”和“眼睛不太可能出现在额头上”这样的相关性。这些是非常复杂的分布。相比之下，一个有辨别能力的模型可能通过寻找一些泄露秘密的模式来了解“帆船”或“非帆船”之间的区别。它可能会忽略生成模型必须正确处理的许多相关性。判别模型试图在数据空间中绘制边界，而生成模型试图对数据在整个空间中的放置方式进行建模。例如，下图显示了手写数字的判别和生成模型:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es kf"><img src="../Images/1958ac8be0ff0d60f8e41fc8f100636f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rIqidxpqQhyb4a5n2QQBTg.png"/></div></div><figcaption class="jv jw et er es jx jy bd b be z dx translated"><strong class="bd jz"> <em class="ka">图2:手写数字的判别和生成模型。</em>T3】</strong></figcaption></figure><p id="b163" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">判别模型试图通过在数据空间中画一条线来区分手写的0和1。如果它得到了正确的线，它可以区分0和1，而不必精确地建模实例在线的任何一边的数据空间中的位置。相比之下，生成模型试图通过生成接近数据空间中真实对应数字的数字来产生令人信服的1和0。它必须对整个数据空间的分布进行建模。GANs提供了一种有效的方法来训练这种丰富的模型，以模拟真实的分布。为了理解它们是如何工作的，我们需要了解GAN的基本结构。</p><p id="41b5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">甘概述:</strong></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es kg"><img src="../Images/8cfb0185972065e7065b0c5efc12797c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q_wE4mwTJRhxTxSGw8QhYA.png"/></div></div><figcaption class="jv jw et er es jx jy bd b be z dx translated"><strong class="bd jz"> <em class="ka">图3 </em> </strong></figcaption></figure><p id="b32a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">生成器和鉴别器都是神经网络。发生器输出直接连接到鉴频器输入。通过反向传播，鉴别器的分类提供了一个信号，生成器用它来更新其权重。</p><p id="8ec1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">鉴别器:</strong></p><p id="16b9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">GAN中的鉴别器只是一个分类器。它试图区分真实数据和生成器创建的数据。它可以使用任何适合其分类数据类型的网络架构。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es kh"><img src="../Images/aaa356c8fc470046a80aa894a1df9b8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GJfZL7smHQ_FPREhelBmbw.png"/></div></div><figcaption class="jv jw et er es jx jy bd b be z dx translated">图4</figcaption></figure><p id="34fb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">鉴别器的训练数据来自两个来源:</p><ul class=""><li id="05b4" class="ki kj hi ih b ii ij im in iq kk iu kl iy km jc kn ko kp kq bi translated"><strong class="ih hj">真实数据</strong>实例，如人的真实照片。鉴别器在训练中使用这些实例作为正面例子。</li><li id="36ea" class="ki kj hi ih b ii kr im ks iq kt iu ku iy kv jc kn ko kp kq bi translated"><strong class="ih hj">假数据</strong>由生成器创建的实例。鉴别器在训练中使用这些实例作为反面例子。</li></ul><p id="fdbc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从图4中我们可以看到，两个“样本”框代表这两个输入鉴别器的数据源。在鉴别器训练期间，发电机不训练。它的权重保持不变，同时为鉴别器提供训练样本。</p><p id="0c23" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">鉴别器连接到两个损失函数。在鉴频器训练期间，鉴频器忽略发电机损耗，仅使用鉴频器损耗。</p><p id="7ef3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在鉴频器训练期间:</p><ol class=""><li id="0e65" class="ki kj hi ih b ii ij im in iq kk iu kl iy km jc kw ko kp kq bi translated">鉴别器对来自生成器的真实数据和虚假数据进行分类。</li><li id="688d" class="ki kj hi ih b ii kr im ks iq kt iu ku iy kv jc kw ko kp kq bi translated">鉴别器损失惩罚将真实实例误分类为假实例或将假实例误分类为真实实例的鉴别器。</li><li id="28a5" class="ki kj hi ih b ii kr im ks iq kt iu ku iy kv jc kw ko kp kq bi translated">鉴别器通过鉴别器网络从鉴别器损耗反向传播来更新其权重。</li></ol><p id="3373" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">发电机:</strong></p><p id="f07e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">GAN的发生器部分通过结合来自鉴别器的反馈来学习创建假数据。它学习使鉴别器将其输出分类为真实的。</p><p id="032a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">发生器训练要求发生器和鉴别器之间的集成比鉴别器训练要求的更紧密。训练发电机的GAN部分包括:</p><ul class=""><li id="db52" class="ki kj hi ih b ii ij im in iq kk iu kl iy km jc kn ko kp kq bi translated">随机输入</li><li id="4b9c" class="ki kj hi ih b ii kr im ks iq kt iu ku iy kv jc kn ko kp kq bi translated">生成器网络，将随机输入转换为数据实例</li><li id="6001" class="ki kj hi ih b ii kr im ks iq kt iu ku iy kv jc kn ko kp kq bi translated">鉴别器网络，对生成的数据进行分类</li><li id="1972" class="ki kj hi ih b ii kr im ks iq kt iu ku iy kv jc kn ko kp kq bi translated">鉴频器输出</li><li id="0fee" class="ki kj hi ih b ii kr im ks iq kt iu ku iy kv jc kn ko kp kq bi translated">发电机损耗，惩罚发电机未能欺骗鉴别器</li></ul><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es kx"><img src="../Images/f44b036b228fa842b5515e6df13783dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*n1Xm-2DBoGJU-O7IrU-dfg.png"/></div></div><figcaption class="jv jw et er es jx jy bd b be z dx translated">图5</figcaption></figure><p id="75d1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">神经网络需要某种形式的输入。通常我们会输入我们想要处理的数据，比如我们想要分类或预测的实例。但是对于一个输出全新数据实例的网络，我们用什么作为输入呢？</p><p id="367d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在其最基本的形式中，GAN将随机噪声作为其输入。然后，发生器将这种噪声转换成有意义的输出。通过引入噪声，我们可以让GAN产生各种各样的数据，从目标分布的不同地方采样。</p><p id="31cf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">实验表明，噪声的分布并不重要，所以我们可以选择一些容易采样的东西，比如均匀分布。为了方便起见，对噪声进行采样的空间的维数通常小于输出空间的维数。</p><p id="c19d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了训练神经网络，我们改变网络的权重，以减少其输出的误差或损失。然而，在我们的GAN中，发电机与我们试图影响的损耗没有直接联系。发电机馈入鉴别器网络，<em class="jd">鉴别器</em>产生我们试图影响的输出。发生器损耗惩罚发生器产生被鉴别器网络分类为假的样本。</p><p id="85ba" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这个额外的网络块必须包含在反向传播中。反向传播通过计算权重对输出的影响(如果改变权重，输出会如何变化)来调整每个权重的方向。但是发电机重量的影响取决于它所输入的鉴别器重量的影响。因此，反向传播从输出端开始，通过鉴频器流回发生器。</p><p id="995b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">同时，我们不希望鉴别器在生成器训练期间改变。试图击中一个移动的目标会使一个困难的问题变得更加困难。</p><p id="bfb4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，我们按照以下步骤训练发电机:</p><ol class=""><li id="3b05" class="ki kj hi ih b ii ij im in iq kk iu kl iy km jc kw ko kp kq bi translated">样本随机噪声。</li><li id="3aa3" class="ki kj hi ih b ii kr im ks iq kt iu ku iy kv jc kw ko kp kq bi translated">从采样的随机噪声产生发电机输出。</li><li id="dd2f" class="ki kj hi ih b ii kr im ks iq kt iu ku iy kv jc kw ko kp kq bi translated">获取生成器输出的鉴别器“真实”或“虚假”分类。</li><li id="857a" class="ki kj hi ih b ii kr im ks iq kt iu ku iy kv jc kw ko kp kq bi translated">计算鉴别器分类的损失。</li><li id="31bb" class="ki kj hi ih b ii kr im ks iq kt iu ku iy kv jc kw ko kp kq bi translated">通过鉴别器和发生器反向传播以获得梯度。</li><li id="b232" class="ki kj hi ih b ii kr im ks iq kt iu ku iy kv jc kw ko kp kq bi translated">使用渐变仅更改发生器权重。</li></ol><p id="0015" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是发电机训练的一个迭代。在下一节中，我们将看到如何同时训练生成器和鉴别器。</p><p id="b8b6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">收敛:</strong></p><p id="e2e3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">随着生成器随着训练而提高，鉴别器的性能变得更差，因为鉴别器不容易区分真假。如果发生器完全成功，那么鉴别器具有50%的准确度。实际上，鉴别者通过抛硬币来做出预测。</p><p id="a589" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这种进展给GAN的整体收敛带来了问题:随着时间的推移，鉴别器反馈变得越来越没有意义。如果GAN继续训练超过鉴别器给出完全随机反馈的点，那么发生器开始在垃圾反馈上训练，并且它自己的质量可能崩溃。</p><p id="00ec" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于GAN来说，收敛通常是短暂的，而不是稳定的状态。</p><p id="abca" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">损失函数:</strong></p><p id="760c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">甘斯试图复制一个概率分布。因此，他们应该使用反映由GAN产生的数据分布和真实数据分布之间的距离的损失函数。</p><p id="a811" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，我们确实会遇到这样一种情况，问题是我们如何捕捉GAN损耗函数中两种分布之间的差异？这个问题是一个活跃的研究领域，已经提出了许多方法。</p><p id="12c3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本文中，我们将讨论GAN提出的两个主要损失函数。</p><p id="f320" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">GAN可以有两个损失函数:一个用于发电机训练，一个用于鉴别器训练。但是现在我们有一个值得问的问题，“<em class="jd">两个损失函数如何共同作用来反映概率分布之间的一个距离度量？”</em></p><p id="063f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在我们这里要讨论的损耗方案中，发生器和鉴频器损耗来自概率分布之间的单一距离度量。然而，在这两种方案中，生成器只能影响距离度量中的一项:反映虚假数据分布的项。因此，在生成器训练期间，我们去掉了另一项，它反映了真实数据的分布。</p><p id="de82" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">发生器和鉴频器损耗最终看起来不同，尽管它们来自同一个公式。</p><p id="4021" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在介绍GANs的论文中，生成器试图最小化以下函数，而鉴别器试图最大化它:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es ky"><img src="../Images/62d95d9f55066b5f2750e2323c21ea83.png" data-original-src="https://miro.medium.com/v2/resize:fit:946/format:webp/1*Bj-RRABJhnwp2OgG32jw-g.png"/></div><figcaption class="jv jw et er es jx jy bd b be z dx translated">损失函数</figcaption></figure><p id="7d15" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在此功能中:</p><ul class=""><li id="483d" class="ki kj hi ih b ii ij im in iq kk iu kl iy km jc kn ko kp kq bi translated">D(x)是鉴别器对真实数据实例x是真实的概率的估计。</li><li id="3ff6" class="ki kj hi ih b ii kr im ks iq kt iu ku iy kv jc kn ko kp kq bi translated">Ex是所有真实数据实例的期望值。</li><li id="dc55" class="ki kj hi ih b ii kr im ks iq kt iu ku iy kv jc kn ko kp kq bi translated">G(z)是给定噪声z时发电机的输出。</li><li id="bb12" class="ki kj hi ih b ii kr im ks iq kt iu ku iy kv jc kn ko kp kq bi translated">D(G(z))是鉴别者对假实例为真的概率的估计。</li><li id="cdc3" class="ki kj hi ih b ii kr im ks iq kt iu ku iy kv jc kn ko kp kq bi translated">Ez是对生成器的所有随机输入的期望值(实际上，是对所有生成的伪实例G(z)的期望值)。</li><li id="0386" class="ki kj hi ih b ii kr im ks iq kt iu ku iy kv jc kn ko kp kq bi translated">该公式源自真实分布和生成分布之间的交叉熵。</li></ul><p id="6ebe" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">发生器不能直接影响函数中的log(D(x))项，所以，对于发生器来说，最小化损耗等价于最小化log(1 — D(G(z))。</p><p id="3631" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">但如果我们看看TF-GAN的，我们会发现它使用了Wasserstein损耗。</p><p id="1329" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这个损失函数依赖于GAN方案的修改(称为“Wasserstein GAN”或“WGAN”)，其中鉴别器实际上不分类实例。对于每个实例，它输出一个数字。这个数字不一定要小于1或者大于0，所以我们不能用0.5作为阈值来决定一个实例是真的还是假的。鉴别器训练只是试图使真实实例的输出大于虚假实例的输出。</p><p id="8cae" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">由于不能真正辨别真假，WGAN鉴别器实际上被称为“批评家”，而不是“鉴别器”。这种区别具有理论上的重要性，但出于实际目的，我们可以把它看作是承认损失函数的输入不一定是概率。</p><p id="389b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">损失函数本身看似简单:</p><p id="7c00" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">临界损失:</strong> <em class="jd"> D(x) — D(G(z)) </em></p><p id="b5e3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">鉴别器试图最大化这个函数。换句话说，它试图最大化真实实例上的输出和虚假实例上的输出之间的差异。</p><p id="fbad" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">发电机损耗:</strong> <em class="jd"> D(G(z)) </em></p><p id="a067" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">生成器试图最大化该功能。换句话说，它试图最大化伪实例的鉴别器输出。</p><p id="7027" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Wasserstein GANs比基于minimax的gan更不容易被卡住，并且避免了消失梯度的问题。推土机距离还有一个优点，那就是它是一个真实的度量:一个概率分布空间中的距离度量。交叉熵不是这个意义上的度量。</p><p id="5374" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于一个更实际的方法，我将链接附加到我的github库，在那里有我的python笔记本的web副本。ipynb文件),它描述了WGAN的完整实现。</p><p id="f616" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">链接:</em><a class="ae kz" href="https://github.com/ayajnik/WGAN_bc" rel="noopener ugc nofollow" target="_blank">https://github.com/ayajnik/WGAN_bc</a></p></div></div>    
</body>
</html>