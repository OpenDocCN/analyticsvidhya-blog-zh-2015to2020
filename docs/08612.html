<html>
<head>
<title>Munchausen Reinforcement Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">孟乔森强化学习</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/munchausen-reinforcement-learning-9876efc829de?source=collection_archive---------3-----------------------#2020-08-05">https://medium.com/analytics-vidhya/munchausen-reinforcement-learning-9876efc829de?source=collection_archive---------3-----------------------#2020-08-05</a></blockquote><div><div class="ds hc hd he hf hg"/><div class="hh hi hj hk hl"><div class=""/><figure class="ev ex im in io ip er es paragraph-image"><div class="er es il"><img src="../Images/2a9f443d97d693649fb5373eb17aed13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1020/format:webp/1*c7mRBsjyM4AoJFidRYL6BQ.jpeg"/></div></figure><p id="e7b9" class="pw-post-body-paragraph is it ho iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hh bi translated">一种改进的 DQN 网络，其性能优于<a class="ae jq" href="https://arxiv.org/abs/1710.02298" rel="noopener ugc nofollow" target="_blank"> <strong class="iu hp">【彩虹】</strong> </a> <strong class="iu hp"> </strong>，而没有利用<strong class="iu hp">优先化经验重放</strong>缓冲器或<strong class="iu hp"> n 步引导</strong>的进步。</p><p id="d82f" class="pw-post-body-paragraph is it ho iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hh bi translated">论文的作者<a class="ae jq" href="https://arxiv.org/abs/2007.14430" rel="noopener ugc nofollow" target="_blank"> <strong class="iu hp"> Munchausen 强化学习</strong></a><strong class="iu hp">【M-RL】</strong>通过一个非常简单的想法实现了这些令人印象深刻的结果:将比例对数策略添加到即时奖励中。</p></div></div>    
</body>
</html>