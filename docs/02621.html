<html>
<head>
<title>Reinforcement Learning — Beginners</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">强化学习——初学者</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/reinforcement-learning-beginners-8b8ce043b408?source=collection_archive---------16-----------------------#2019-12-25">https://medium.com/analytics-vidhya/reinforcement-learning-beginners-8b8ce043b408?source=collection_archive---------16-----------------------#2019-12-25</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/e24ba1a9d34d70ee6d648bf3ad4eb4ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PO_d7obKy1gES-KuIj8f2Q.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">高点击率优化了点击付费成本和流量</figcaption></figure><h1 id="210f" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated"><strong class="ak">在没有任何数据的情况下开始的模型</strong></h1><p id="5544" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">你可能认为所有的机器学习模型都可以分为有监督的、半监督的或者无监督的。然而，这是不正确的，有些算法不属于上述任何类型。其中之一就是强化学习模型。</p><p id="72e1" class="pw-post-body-paragraph js jt hi ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp hb bi translated">使用奖励和惩罚作为输入来训练强化学习算法，以最大化企业的总收益。<em class="kv">从错误中学习</em>是捕捉这种算法本质的完美短语。</p><p id="e74c" class="pw-post-body-paragraph js jt hi ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp hb bi translated">在这个项目中，我们将了解强化学习中两种常用的算法——置信上限(UCB)和汤姆逊抽样。</p><h1 id="65f7" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">强化学习的应用</h1><p id="54a5" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">强化学习在数字营销中广泛使用，以增加网页流量和/或在线销售产品。常见的用例包括在用户账户上创建推荐，优化广告显示以最大化CTR(点击率)，预测客户行为以及为广告选择最佳内容。</p><h1 id="5bdb" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated"><strong class="ak">问题陈述</strong></h1><p id="0ed5" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">在我们的问题中，一家销售电动汽车的虚构汽车公司Vesla希望向浏览其网站的用户显示广告。该公司数字营销团队的经理已经从内容团队收到了10幅新推出汽车Fybertruck的出色广告图像。她不知道应该在网站上使用哪个广告图像。由于为结账页面带来更多流量的压力很大，她更喜欢使用强化学习而不是A/B测试。</p><h1 id="1502" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated"><strong class="ak">数据集</strong></h1><p id="c657" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">数据集是从Kaggle下载的(数据集名称—<a class="ae kw" href="https://www.kaggle.com/akram24/ads-ctr-optimisation" rel="noopener ugc nofollow" target="_blank"><em class="kv">Ads _ CTR _ optimization</em></a>)。这10，000个数据点中的每一个都有用户点击不同广告的信息(总共10个广告)。例如，数据集中的用户1点击了广告# 1、#5和#9。</p><h1 id="8f8d" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated"><strong class="ak">置信上限</strong></h1><p id="52ea" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">UCB是一种确定性算法。我们首先假设所有10个广告在开始时产生了相同的收益(在这种情况下是点击数)。最初的几轮是实验性的。我们向用户随机展示10个广告中的任何一个，并开始收集那些产生点击的广告的信息。例如，如果用户点击广告#5和广告#7，这两个广告被奖励，因此他们有更好的信心(更高的信心意味着下次显示广告#5或广告#7时有更好的机会产生点击)。如果下一个用户下次没有点击这些广告中的一个，则广告#5和广告#7的可信度下降。这样，我们基于最大回报方法继续迭代10，000次。</p><h1 id="671c" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated"><strong class="ak">汤姆逊采样</strong></h1><p id="95eb" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">汤姆森采样是一种概率算法。每个广告都有其奖励分配(点击数)。在这个算法中，我们尝试猜测广告的报酬分布，然后尝试最大化总报酬。我们首先假设广告的某种类型的分布，然后在分布上随机抽取一个点。接下来，我们检查广告是否有回报，然后调整广告的总回报，反过来，我们在每次迭代中调整广告的分布。经过10，000次迭代后，大数定律开始发挥作用，总回报收敛于广告的预期回报。</p><h1 id="9613" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated"><strong class="ak">代码背后的直觉</strong></h1><p id="c263" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">该代码应被视为地面真实信息。我们在10，000次迭代中随机展示10个广告，然后与真实情况进行匹配。一万次迭代后奖励最高的广告就是最好的。因此，我们不需要等到10，000个用户在网站上互动后才找到最好的，我们可以随时产生点击。</p><h1 id="289d" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated"><strong class="ak">结果</strong></h1><p id="ed34" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">以下是从用于该问题的两种算法中获得的结果:</p><figure class="ky kz la lb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kx"><img src="../Images/40ecc0a053b7e295cfd69e983243841e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vRydzSdDmlfIWmKGDr008w.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">UCB和汤姆森抽样的结果</figcaption></figure><p id="4ea6" class="pw-post-body-paragraph js jt hi ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp hb bi translated">A/B测试结果:(这是通过在10，000次迭代之后取点击的总和来完成的):</p><figure class="ky kz la lb fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lc"><img src="../Images/1794308f7d26671a777bfbd4dcef1f0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*36L_8PvQl_JlGBWHzWha7g.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">A/B测试的结果</figcaption></figure><p id="a936" class="pw-post-body-paragraph js jt hi ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp hb bi translated">汤姆森抽样似乎是提高用户参与度的最佳方法。A/B测试好像挺贵的。</p><p id="bf3d" class="pw-post-body-paragraph js jt hi ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp hb bi translated">广告#4显示Fybertruck为结账网页带来了最高的流量。</p><p id="4435" class="pw-post-body-paragraph js jt hi ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp hb bi translated">人们发现，汤姆逊抽样提供了更多的经验证据。虽然结果需要在每一轮UCB后更新，但汤姆逊采样可以批量运行，因此在计算效率上得到了额外的分数。</p><h1 id="307d" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated"><strong class="ak">代码</strong></h1><div class="ld le ez fb lf lg"><a href="https://github.com/chandravenky/Machine-Learning---Python-Predictive/tree/master/12%20Reinforcement%20Learning" rel="noopener  ugc nofollow" target="_blank"><div class="lh ab dw"><div class="li ab lj cl cj lk"><h2 class="bd hj fi z dy ll ea eb lm ed ef hh bi translated">chandravenky/机器学习-Python-预测</h2><div class="ln l"><h3 class="bd b fi z dy ll ea eb lm ed ef dx translated">此时您不能执行该操作。您已使用另一个标签页或窗口登录。您已在另一个选项卡中注销，或者…</h3></div><div class="lo l"><p class="bd b fp z dy ll ea eb lm ed ef dx translated">github.com</p></div></div><div class="lp l"><div class="lq l lr ls lt lp lu io lg"/></div></div></a></div><h1 id="a23d" class="iu iv hi bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated"><strong class="ak">参考文献</strong></h1><p id="4ec0" class="pw-post-body-paragraph js jt hi ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">机器学习A-Z —超级数据科学</p></div></div>    
</body>
</html>