<html>
<head>
<title>Types of Categorical Data Encoding Schemes</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">分类数据编码方案的类型</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/types-of-categorical-data-encoding-schemes-a5bbeb4ba02b?source=collection_archive---------0-----------------------#2019-08-22">https://medium.com/analytics-vidhya/types-of-categorical-data-encoding-schemes-a5bbeb4ba02b?source=collection_archive---------0-----------------------#2019-08-22</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="cb82" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们知道大多数机器学习库只接受数字形式的数据，因此将数据集中的分类变量转换为数字是非常重要的。我们不能把它们从我们的数据集中删除，因为它们隐藏了很多有趣的信息。学习处理这些变量的方法是至关重要的。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/d97253704852a8b020943286c5ef7ab1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UMNB50RGLE9oFiRYebX6gA.png"/></div></div></figure><h1 id="c7d8" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated"><strong class="ak">编码方案的类型</strong></h1><p id="6afe" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated"><strong class="ih hj">序数编码或标签编码</strong></p><p id="e910" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">它用于将非数字标签转换为数字标签(或名义分类变量)。数字标签始终介于1和类别数之间。</p><p id="5cda" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为类别选择的标签没有关系。因此，有一些联系或彼此接近的类别在编码后会丢失这些信息。列中的第一个唯一值变为1，第二个变为2，第三个变为3，依此类推。</p><pre class="je jf jg jh fd ks kt ku kv aw kw bi"><span id="1b64" class="kx jq hi kt b fi ky kz l la lb">import pandas as pd<br/>import category_encoders as ce</span><span id="077c" class="kx jq hi kt b fi lc kz l la lb">data = pd.DataFrame({<br/>    'city' : ['delhi', 'hyderabad', 'delhi', 'delhi', 'gurgaon', 'hyderabad']<br/>})</span><span id="304f" class="kx jq hi kt b fi lc kz l la lb"># create an object of the OrdinalEncoding<br/>ce_ordinal = ce.OrdinalEncoder(cols=['city'])</span><span id="5732" class="kx jq hi kt b fi lc kz l la lb"># fit and transform and you will get the encoded data<br/>ce_ordinal.fit_transform(data)</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ld"><img src="../Images/0c4ddbcbda750eb7773147a67d2d91c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:162/format:webp/1*SbX2vFCHB6YwyLTIXTttrw.png"/></div></figure><p id="916c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">一热编码</strong></p><p id="4c93" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里，我们将每个类别映射到一个向量，该向量包含1和0，表示该特征是否存在。向量的数量取决于数据集中的类别。对于高基数特性，这种方法会产生大量的列，从而显著降低模型的学习速度。</p><pre class="je jf jg jh fd ks kt ku kv aw kw bi"><span id="8d22" class="kx jq hi kt b fi ky kz l la lb">data = pd.DataFrame({<br/>    'gender' : ['M', 'F', 'M', 'F', 'F']<br/>})</span><span id="fce9" class="kx jq hi kt b fi lc kz l la lb"># create an object of the OneHotEncoder<br/>ce_OHE = ce.OneHotEncoder(cols=['gender'])</span><span id="e799" class="kx jq hi kt b fi lc kz l la lb"># fit and transform and you will get the encoded data<br/>ce_OHE.fit_transform(data)</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es le"><img src="../Images/f986916d7676983ecc11fee918fed5d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:364/format:webp/1*MEzleCMwoLMBY_jAQPVH3A.png"/></div></figure><p id="93a6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">二进制编码</strong></p><p id="c0f8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">首先，将类别编码为序数，然后将这些整数转换为二进制代码，然后将二进制字符串中的数字拆分为单独的列。</p><p id="1a98" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当您有大量类别，并且进行一次性编码会增加维度，从而增加模型的复杂性时，这是非常有用的。因此，二进制编码是对维数较少的分类变量进行编码的好选择。</p><pre class="je jf jg jh fd ks kt ku kv aw kw bi"><span id="e6c6" class="kx jq hi kt b fi ky kz l la lb"># make some data<br/>data = pd.DataFrame({<br/> 'class' : ['a', 'b', 'a', 'b', 'd', 'e', 'd', 'f', 'g', 'h', 'h', 'k', 'h', 'i', 's', 'p', 'z']})</span><span id="626e" class="kx jq hi kt b fi lc kz l la lb"># create object of BinaryEncoder<br/>ce_binary = ce.BinaryEncoder(cols = ['class'])</span><span id="150a" class="kx jq hi kt b fi lc kz l la lb"># fit and transform and you will get the encoded data<br/>ce_binary.fit_transform(data)</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lf"><img src="../Images/86bd35e216eeb8e5651b1a06f831bb6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/1*VwVWCWMjvibuLUl8eXOY3Q.png"/></div></figure><p id="4548" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> BaseN编码</strong></p><p id="5c9d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在二进制编码中，我们将整数转换为二进制，即基数为2。BaseN允许我们将整数转换成任何底数的值。因此，如果您的数据集中有类似于<strong class="ih hj"> city_name </strong>的数据，可能有数千个，那么建议使用BaseN，因为它会在使用二进制编码后进一步降低维数。</p><p id="6fbc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">您可以设置参数基数。这里，我在一个样本数据集上使用基值4和3进行了编码。</p><pre class="je jf jg jh fd ks kt ku kv aw kw bi"><span id="e470" class="kx jq hi kt b fi ky kz l la lb"># make some data<br/>data = pd.DataFrame({<br/> 'class' : ['a', 'b', 'a', 'b', 'd', 'e', 'd', 'f', 'g', 'h', 'h', 'k', 'h', 'i', 's', 'p', 'z']})</span><span id="e2ae" class="kx jq hi kt b fi lc kz l la lb"># create an object of the BaseNEncoder<br/>ce_baseN4 = ce.BaseNEncoder(cols=['class'],base=4)</span><span id="5631" class="kx jq hi kt b fi lc kz l la lb"># fit and transform and you will get the encoded data<br/>ce_baseN4.fit_transform(data)</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lg"><img src="../Images/0b3b335b4aa4f74930d0d5380d334b67.png" data-original-src="https://miro.medium.com/v2/resize:fit:448/format:webp/1*VLVZWQpN11DI_jkh8l2hSA.png"/></div></figure><pre class="je jf jg jh fd ks kt ku kv aw kw bi"><span id="abaf" class="kx jq hi kt b fi ky kz l la lb"># create an object of the BaseNEncoder<br/>ce_baseN3 = ce.BaseNEncoder(cols=['class'],base=3)</span><span id="37fe" class="kx jq hi kt b fi lc kz l la lb"># fit and transform and you will get the encoded data<br/>ce_baseN3.fit_transform(data)</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lh"><img src="../Images/8819a4b6841b994016f702c1cf8a5fe0.png" data-original-src="https://miro.medium.com/v2/resize:fit:560/format:webp/1*DHXYJ8d7F4_9vrvrKNvzlw.png"/></div></figure><p id="8925" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">哈希</strong></p><p id="23dd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">哈希是使用表示原始字符串的算法将字符串转换为通常较短的固定长度值的过程。</p><p id="4d60" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">它使用<strong class="ih hj"> md5 </strong>算法将字符串转换成我们可以使用参数n_components定义的固定长度的较短字符串。如果您将参数设置为5，那么不管类别的长度是7还是700，算法都会将其转换为长度为5的字符串，最终得到5个不同的列来表示我们的分类值。</p><p id="5764" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们在一个样本数据上尝试一下:</p><pre class="je jf jg jh fd ks kt ku kv aw kw bi"><span id="9f68" class="kx jq hi kt b fi ky kz l la lb">data = pd.DataFrame({<br/>    'color' : ['Yellow', 'Black', 'Green', 'Blue', 'Blue', 'Green', 'Black', 'Blue']<br/>})</span><span id="59ef" class="kx jq hi kt b fi lc kz l la lb"># create an object of the HashingEncoder<br/>ce_HE = ce.HashingEncoder(cols=['color'],n_components=5)</span><span id="0278" class="kx jq hi kt b fi lc kz l la lb"># fit and transform and you will get the encoded data<br/>ce_HE.fit_transform(data)</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lh"><img src="../Images/bd0d1f1e0c800b3208a899be648e83e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:560/format:webp/1*Z3Osq4U7evkYYS6ccDPYMw.png"/></div></figure><p id="d7bb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">目标编码</strong></p><p id="acda" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里，用给定特定类别值的目标的后验概率和所有训练数据上的目标的先验概率的混合来替换特征。此外，它们不是为测试数据生成的。我们通常保存从训练数据集中获得的目标编码，并使用相同的编码对测试数据集中的特征进行编码。</p><pre class="je jf jg jh fd ks kt ku kv aw kw bi"><span id="e39c" class="kx jq hi kt b fi ky kz l la lb">data = pd.DataFrame({<br/>    'color' : ['Blue', 'Black', 'Black','Blue', 'Blue'],<br/>    'outcome' : [1,      2,        1,     1,      2,]<br/>})</span><span id="587f" class="kx jq hi kt b fi lc kz l la lb"># column to perform encoding<br/>X = data['color']<br/>Y = data['outcome']</span><span id="4445" class="kx jq hi kt b fi lc kz l la lb"># create an object of the TargetEncoder<br/>ce_TE = ce.TargetEncoder(cols=['color'])</span><span id="13d5" class="kx jq hi kt b fi lc kz l la lb"># fit and transform and you will get the encoded data<br/>ce_TE.fit(X,Y)</span><span id="79b8" class="kx jq hi kt b fi lc kz l la lb">ce_TE.transform(X)</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es li"><img src="../Images/294e6f130d23f0e6854c6dfad02999d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:212/format:webp/1*G5KkdmlgNqxNXOsbpCMc_A.png"/></div></figure><pre class="je jf jg jh fd ks kt ku kv aw kw bi"><span id="8cb6" class="kx jq hi kt b fi ky kz l la lb">test_data = pd.DataFrame({<br/>    'color' : ['Blue', 'Black', 'Black'],<br/>})</span><span id="9e52" class="kx jq hi kt b fi lc kz l la lb">ce_TE.transform(test_data)</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lj"><img src="../Images/70849d36cdf58440f3429af1c440b727.png" data-original-src="https://miro.medium.com/v2/resize:fit:230/format:webp/1*Zksne_9J96d0flqshE3z4g.png"/></div></figure><p id="5fc7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">漏掉一个</strong></p><p id="2f1f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这与目标编码非常相似，但在计算某个级别的平均目标以减少异常值的影响时，会排除当前行的目标。</p><pre class="je jf jg jh fd ks kt ku kv aw kw bi"><span id="6905" class="kx jq hi kt b fi ky kz l la lb">data = pd.DataFrame({<br/>    'color' : ['Blue', 'Black', 'Black','Blue', 'Blue'],<br/>    'outcome' : [2,      1,        1,     1,      2]<br/>})</span><span id="ecb1" class="kx jq hi kt b fi lc kz l la lb"># column to perform encoding<br/>X = data['color']<br/>Y = data['outcome']</span><span id="ec76" class="kx jq hi kt b fi lc kz l la lb"># create an object of the TargetEncoder<br/>ce_TE = ce.LeaveOneOutEncoder(cols=['color'])</span><span id="ee5d" class="kx jq hi kt b fi lc kz l la lb"># fit and transform and you will get the encoded data<br/>ce_TE.fit_transform(X,Y)</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ld"><img src="../Images/13a9245fa004c8d799f2a9cd38ec1d13.png" data-original-src="https://miro.medium.com/v2/resize:fit:162/format:webp/1*Vn0GyV_75AONArJDUpP_uw.png"/></div></figure><h1 id="e748" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">结论</h1><p id="31a4" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">在本文中，我们介绍了处理数据集中分类变量的各种技术。我希望这篇文章对你有用。你可以通过下面的评论区联系我！</p></div></div>    
</body>
</html>