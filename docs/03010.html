<html>
<head>
<title>Step by step implementation of BERT for text categorization task</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于文本分类任务的BERT的分步实现</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/step-by-step-implementation-of-bert-for-text-categorization-task-aba80417bd84?source=collection_archive---------5-----------------------#2020-01-12">https://medium.com/analytics-vidhya/step-by-step-implementation-of-bert-for-text-categorization-task-aba80417bd84?source=collection_archive---------5-----------------------#2020-01-12</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="6719" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在过去的3年中，大型NLP实验室已经开发了强大的新神经网络框架，有助于学习数据的良好表示，这些表示将在一系列任务中表现良好。这些框架是计算密集型的，可以根据语言建模目标进行预训练，并根据特定任务进行微调。</p><p id="0a0c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">其中之一是谷歌开发的名为BERT(变压器的双向编码器表示)的工具。BERT是一种深度双向、无监督的语言表示，仅使用纯文本语料库进行预训练。我们可以使用BERT来获得文档/文本的向量表示。这些矢量表示可用作模型中的预测特征。</p><p id="d76e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本文中，我们将尝试通过使用BERT进行文本分类任务来实现它，并更好地理解如何使用BERT。此外，我们还对BERT执行分类任务的效果进行了度量分析。</p><p id="e09f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">假设我们得到一个由非英语母语作者创作的英语文本数据集。我们的任务是预测每个作者的母语。</p><p id="ba2c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">训练数据集lang_id_train.csv具有大约6000行和2列，即本地语言和文本。测试数据集lang_id_test.csv大约有2000条记录。Lang_id_eval.csv是用于评估指标的文件。现在，让我们通过在训练数据上构建文本分类模型来尝试在测试数据中识别作者的母语。</p><p id="7c95" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">数据集的链接如下所示:</p><p id="340c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">lang _ id _ train . CSV-<a class="ae jd" href="https://docs.google.com/spreadsheets/d/14e0Lq--YA6YtxcOlQFg2jB7TqeI1z8qf_U1_6VdaEIA/edit?usp=sharing" rel="noopener ugc nofollow" target="_blank">https://docs.google.com/spreadsheets/d/14e0Lq-ya 6 ytxcolqfg 2 JB 7 tqei 1 z 8 qf _ U1 _ 6 vdaeia/编辑？usp =共享</a></p><p id="f74c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">lang _ id _ test . CSV-h<a class="ae jd" href="https://docs.google.com/spreadsheets/d/1W0p1gJq1_zo21VjmvmusmfbkGnKAWXRRbTrT5Ka3b4g/edit?usp=sharing" rel="noopener ugc nofollow" target="_blank">ttps://docs . Google . com/spreadsheets/d/1 w0 P1 gjq 1 _ zo 21 vjmvmusmfbkgnkawxrrbtrt 5 ka 3 B4 g/edit？usp =共享</a></p><p id="763b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">lang _ id _ eval . CSV-h<a class="ae jd" href="https://docs.google.com/spreadsheets/d/1VPYca7fTLnw2ceqLprGqCobs0hFFu_mOBHTPpLpW46Q/edit?usp=sharing" rel="noopener ugc nofollow" target="_blank">ttps://docs . Google . com/spreadsheets/d/1 vpyca 7 ftlnw 2 eqlprgqcobs 0 hffu _ mobhtppplpw 46 q/edit？usp =分享</a></p><p id="8439" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">第一节。使用BERT进行文本分类的步骤</strong></p><p id="e561" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="je">第一步:从git </em> </strong>获取BERT存储库</p><p id="515d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">将维护人员的BERT存储库克隆到名为“bert-master”的计算机上的本地目录中。您可以运行命令:git clone<a class="ae jd" href="https://github.com/google-research/bert.git" rel="noopener ugc nofollow" target="_blank">https://github.com/google-research/bert.git</a></p><p id="a1ef" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="je">第二步:获取预先训练好的BERT模型</em> </strong></p><p id="68b9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将使用这个预训练的BERT模型来生成特征，因为即使使用预训练的模型，这项任务也很耗时。在CPU中生成文档向量大约需要40分钟。</p><p id="13c3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，我们下载了一个预先训练好的BERT模型<a class="ae jd" href="https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip" rel="noopener ugc nofollow" target="_blank"> BERT-Base，Uncased </a>，并将其解压缩到一个我们称之为“模型”的本地目录中。</p><p id="3dfe" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="je">第三步:格式化输入文件，供BERT处理并产生输出</em> </strong></p><p id="27d2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">ORIGINAL _ DATA _ DIR-包含三个输入csv文件的文件夹，我们使用这些文件进行各种操作</p><p id="2f97" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">BERT_FEATURE_DIR- folder是保存BERT输出的json文件的文件夹</p><p id="542c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">BERT_DATA_DIR文件夹也包含原始的输入csv文件。此文件夹中的文件将不会被编辑或用于任何操作或更改。</p><p id="63db" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这三个输入文件被复制到新文件夹bert_input_data中。使用jupyter笔记本在os.path.join中更新了bert_input_data和bert_output_data路径，如下所示。</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div class="er es jf"><img src="../Images/14d9f2499e3d223211614e8ea53ce888.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*3x70w8TrtZrCnz5OtXTBBQ.png"/></div></figure><p id="e906" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">以编程方式重新格式化输入文件，以便可以由BASE_DATA_DIR文件夹中的BERT extract_features.py脚本进行处理。这个脚本要求每个输入文件在一行中包含每个文本，没有其他信息。</p><p id="56ec" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为此，我们分别删除了标题为“text”的第一行和包含每个输入文件的native_language属性值的第一列。例如，我们通过以下代码对lang_id_train.csv文件执行此操作。</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div class="er es jn"><img src="../Images/6689d65435bce1ea6f7eb61f8bdc3335.png" data-original-src="https://miro.medium.com/v2/resize:fit:1222/format:webp/1*oaB6YMjesuzUz8lyQ58JGA.png"/></div></figure><figure class="jg jh ji jj fd jk er es paragraph-image"><div class="er es jf"><img src="../Images/0f0c2655538229b2e2d1604bfcf47a2c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*VWmMEpOhZ8vVlq5qBPVw6A.png"/></div></figure><figure class="jg jh ji jj fd jk er es paragraph-image"><div class="er es jo"><img src="../Images/677224ec5b29bcbbc062b293b19bc697.png" data-original-src="https://miro.medium.com/v2/resize:fit:794/format:webp/1*uTRIG4qeKmakNLlNWOSe5A.png"/></div></figure><p id="9a5a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将数据帧转换成csv格式。</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div class="er es jf"><img src="../Images/af3db0fa750958242a529804b7a5747c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*DAAGcQdLc-mW-2okdOd46w.png"/></div></figure><p id="175c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">注意，我们为每个输入文件train和train_df创建2个数据帧，其中train用于存储原始输入文件，train_df用于格式化输入文件以提取BERT特征。</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div class="er es jf"><img src="../Images/e7f09907b0ebba2327d5198aa8e29125.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*-yiDmGNXsFED7uos_xLOtQ.png"/></div></figure><p id="8962" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，train_df是使用BERT获取文档向量所需的格式。类似地，我们以必要的格式获得test_df和eval_df。</p><p id="0922" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="je">第四步:编辑并运行run_bert_fv.sh脚本。</em>T13】</strong></p><p id="7f84" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">输入文件格式化后，我们使用run_bert_fv.sh脚本通过BERT运行格式化的csv文件中的文本，以生成代表每个文本的特征向量。这会产生3个jsonlines文件，大约7.67 GB的数据。</p><p id="4770" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Unix脚本run_Bert_fv.sh代码如下:</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div class="er es jp"><img src="../Images/00a14d81ab1bc40ddd572a3d78f56199.png" data-original-src="https://miro.medium.com/v2/resize:fit:970/format:webp/1*DYE5JGMQUA78A5sr-yfQvQ.png"/></div></figure><p id="e2c3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了让run_bert_fv.sh脚本处理输入文件并生成输出，我们需要在脚本中指向输入文件文件夹和输入文件的名称。</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div class="er es jq"><img src="../Images/0ce6a3832d89e898e5d8a2ec5bdf3644.png" data-original-src="https://miro.medium.com/v2/resize:fit:1076/format:webp/1*UzDFvA6sQI5Md26UEYjgUQ.png"/></div></figure><p id="26a5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里克隆的BERT储存库指向BERT_BASE_DIR，预训练的BERT模型指向BERT_DATA_DIR。</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div class="er es jr"><img src="../Images/0d5fb4c0b805b206ba90c79fc90a8302.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*3n-xZPJfD9v9La5tV33DFw.png"/></div></figure><p id="57f9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">for循环中指出了3个输入文件名。</p><p id="4a73" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="je">第五步:从json文件中获取BERT矢量</em> </strong></p><p id="bc5f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们执行run_bert_fv.sh脚本。生成3个jsonlines文件大约需要一个小时。这些文件在前面步骤中指出的BERT_FEATURE_DIR文件夹中生成。</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="er es jf"><img src="../Images/4c8f3f55122734e512a53526d7343305.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*SPUZGBe7I9WneH3icTCpJw.png"/></div></div></figure><p id="0a57" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下一步是读取BERT向量，并在sklearn模型中使用它们。为了做到这一点，我们通过使用notebook中的以下代码将jsonlines文件转换为BERT矢量。</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div class="er es jw"><img src="../Images/ad61ac8867d8287a70c95cc629f6c7cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*uAlF39aIyEhsqOyUYwMZUg.png"/></div></figure><p id="389c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">请注意，我们首先将lang_id_train.jsonlines转换为BERT向量，以便获得用于开发模型的训练数据的向量。总共生成了6000个向量。每个文件对应于输入csv文件的每一行。</p><p id="a425" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="je">步骤六:训练模型</em> </strong></p><p id="6cec" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用从BERT派生的功能来训练逻辑回归模型，以便预测所提供数据的native_language属性。</p><p id="9d63" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">模型X_train的输入来自步骤5中训练数据的bert_vectors。我们把它转换成一个Numpy数组，这样我们就可以用X_train来拟合一个模型。</p><p id="f5ae" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">y_train使用我们在步骤3中定义的训练数据帧来获取训练输入文件中每个文本的native_language值。</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="er es jx"><img src="../Images/9b87e3935cf871921a44d074927d06d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:860/format:webp/1*_3I0_sI8-5qO0fooy41wCg.png"/></div></div></figure><p id="35fa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">LogisticRegression模型定义如下，遵循l2范数正则化，c =1.0，这意味着我们用l2罚函数强烈约束该模型。我们将训练数据及其对应的y值拟合到模型中。</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div class="er es jy"><img src="../Images/07f7c2729314ca98c95cc77ce4782c8f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1030/format:webp/1*YoYdH6tPnZMEW5VmO8w8Sw.png"/></div></figure><p id="987f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="je">第七步:使用模型拟合进行预测</em> </strong></p><p id="0034" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们使用训练好的模型model_Fit对测试数据(lang_id_test.csv)进行预测。为此，我们再次从lang_id_test.csv json文件生成BERT_vectors。</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div class="er es jf"><img src="../Images/cf1e52cdf10d742b4bf441f2124e115d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*gVRzwrJtFoh2Zx3N0_4lfQ.png"/></div></figure><p id="f7a7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这将产生2000个伯特矢量。我们把它转换成一个np数组，作为x_test存储。</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div class="er es jz"><img src="../Images/831ee7a6b2ff90ade2e820dca9359253.png" data-original-src="https://miro.medium.com/v2/resize:fit:898/format:webp/1*o6Ajnf2JFy7kQI29eSH6HQ.png"/></div></figure><p id="d15e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们使用预测函数来预测y值，即lang_id_test.csv文件中2000个文本的每一个的native_language值。</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div class="er es jf"><img src="../Images/66b57e921fd357f227bfb3b45e99129e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*_8Vfv7N6pqT9gkQIWtIAwA.png"/></div></figure><p id="7c5a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">第2部分—评估结果</strong></p><p id="3f71" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">此部分包括评估结果的摘要，总体包括性能、按类别划分的指标以及类别之间的错误频率。</p><p id="8040" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为此，我们使用lang_id_eval.csv输入文件。我们从这个文件中获取native_language值。y的实际值定义如下。</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div class="er es ka"><img src="../Images/3146726d381649c68b66dba0d4415199.png" data-original-src="https://miro.medium.com/v2/resize:fit:804/format:webp/1*fF4H8NvlTZzYnw0sv0KMRg.png"/></div></figure><h1 id="f72b" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">使用精确度测量模型性能:</h1><p id="9fa5" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">我们首先使用准确性作为度量标准来衡量测试集的整体性能。准确度被定义为正确预测的分数=正确预测/预测总数</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div class="er es le"><img src="../Images/0cd023c333045c18225e9b68091bf1b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1090/format:webp/1*gtMb3olLf_qGeDTIGyYZmQ.png"/></div></figure><p id="58eb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们得到了38%的准确率(大约。)在我们的模型中。尽管准确性给出了模型的整体性能，但它本身不足以衡量模型的性能，尤其是在数据有偏差的情况下。评估模型的其他重要指标是精确度、召回率和f1值，即使数据有偏差，这些指标也能准确衡量模型的性能。</p><p id="20ff" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">以下指标将给出更好地评估模型的值。</p><p id="8048" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">使用分类报告按类划分指标。</strong></p><figure class="jg jh ji jj fd jk er es paragraph-image"><div class="er es lf"><img src="../Images/6b299bfc231de008e16de24483f0af6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:980/format:webp/1*Bs1Fedk3ZSLnk0kTsQxqaA.png"/></div></figure><p id="c94c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="je">精度= </em> </strong>精度是tp / (tp + fp)的比值，其中tp是真阳性的数量，fp是假阳性的数量。精确度直观上是分类器不将阴性样品标记为阳性的能力。</p><p id="6553" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="je">召回</em> </strong> =召回率是tp / (tp + fn)的比值，其中tp是真阳性的数量，fn是假阴性的数量。召回直观上是分类器找到所有肯定样本的能力。</p><p id="b834" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="je"> F1得分</em></strong>= F1得分可以解释为精确度和召回率的加权平均值，其中F1得分在1时达到其最佳值，在0时达到其最差得分。</p><p id="cf6a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="je">支持</em></strong>= y _ true中每个标签出现的次数。</p><p id="c382" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">分析:</strong></p><p id="5bd1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从上面的分类报告中，我们发现模型对泰语的准确预测数量最多，其次是日语和俄语，因为它们的f1分数在10个类别中最高。</p><p id="5b51" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">泰语的精度是所有类中最高的</p><p id="3552" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">日语的回忆是所有类别中最高的，因此日语的f1分数也很高，尽管精确度较低。</p><p id="c210" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">即使越南语和粤语的错误频率相同，越南语的f1分数也远低于粤语。所以汉语，越南语，阿拉伯语的预测最少。</p><p id="4058" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">使用混淆矩阵的类间错误频率</strong></p><p id="66e8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用混淆矩阵可以获得每一类的预测数与实际数的计数。我们给出实际y值y_eval和从模型predict_y获得的预测值作为输入。</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div class="er es lg"><img src="../Images/ccc50d1c39658c0d81bdd222defeaf7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:978/format:webp/1*RESjBqiNEHBavvflAXg-ng.png"/></div></figure><figure class="jg jh ji jj fd jk er es paragraph-image"><div class="er es lh"><img src="../Images/00b73830ecc7ab2a390f407c53f58096.png" data-original-src="https://miro.medium.com/v2/resize:fit:910/format:webp/1*izOIesAB3p13nO67yCgTng.png"/></div></figure><p id="a791" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">cm的图示如下所示</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div class="er es li"><img src="../Images/b9fe04de35d81514f9204cf726c6e863.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*83RYEx0gzbmcrg_SfxYg4g.png"/></div></figure><figure class="jg jh ji jj fd jk er es paragraph-image"><div class="er es lj"><img src="../Images/b271f0d604974e683c4cdc99f17390e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1266/format:webp/1*K77sJrWnJFIuz2eK0Hs5sw.png"/></div></figure><p id="2012" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">分析:</strong></p><p id="ae2a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用从混淆矩阵获得的值，如上计算每个类别的错误频率。我们发现，日本人、泰国人和俄罗斯人的模型预测正确率最高。对于普通话、越南语和阿拉伯语获得最不正确预测。</p><p id="524b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">结论:</strong></p><p id="2c09" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">以38%的准确度完成了用于找到作者的母语的逻辑斯蒂模型和伯特向量的实现。来自混淆矩阵的f1分数和错误频率都表明，与其他母语相比，日语、泰语和俄语被很好地预测。</p></div></div>    
</body>
</html>