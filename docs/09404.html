<html>
<head>
<title>Real-time Image classification using Tensorflow Lite and Flutter</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 Tensorflow Lite 和 Flutter 的实时图像分类</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/real-time-image-classification-using-tensorflow-lite-and-flutter-878e3700607a?source=collection_archive---------2-----------------------#2020-09-05">https://medium.com/analytics-vidhya/real-time-image-classification-using-tensorflow-lite-and-flutter-878e3700607a?source=collection_archive---------2-----------------------#2020-09-05</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="f1a7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">随着时间的推移，智能手机等边缘设备变得越来越强大，并支持越来越多的设备上机器学习用例。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/a71b27714b58104c0ed3eb1c3ac9dfa7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DodDQQsYm93vP0tscQ-ahA.png"/></div></div></figure><h1 id="21df" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated"><strong class="ak">什么是张量流？</strong></h1><p id="c3c4" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">TensorFlow 是<strong class="ih hj">构建和训练神经网络</strong>的平台，它允许检测和破译模式和相关性，类似于人类使用的学习和推理。<br/> TensorFlow 的灵活架构使开发人员能够使用单一 API 将计算部署到台式机、服务器或移动设备上的一个或多个 CPU 或 GPU。它最初是由机器智能研究部门谷歌大脑团队的研究人员和工程师开发的，目的是进行机器学习和深度神经网络研究。</p><h2 id="6aa6" class="kt jr hi bd js ku kv kw jw kx ky kz ka iq la lb ke iu lc ld ki iy le lf km lg bi translated"><strong class="ak"> Tensorflow lite </strong></h2><p id="2c42" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated"><a class="ae lh" href="http://tensorflow.org/lite" rel="noopener ugc nofollow" target="_blank"> TensorFlow Lite </a>是在<strong class="ih hj">边缘设备</strong>上运行 TensorFlow 模型推理的官方框架。它运行在全球超过 40 亿台活跃设备上，运行在各种平台上，包括 Android、iOS 和基于 Linux 的物联网设备，以及裸机微控制器上。</p><h2 id="abc7" class="kt jr hi bd js ku kv kw jw kx ky kz ka iq la lb ke iu lc ld ki iy le lf km lg bi translated">「精简版」有什么优势？</h2><p id="51b6" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">TensorFlow Lite 被设计成轻量级的<strong class="ih hj">，具有较小的二进制大小和快速初始化</strong>。它还兼容多种平台，包括 Android 和 iOS。为了增强移动体验，它针对移动设备进行了优化，具有改进的加载时间和硬件加速。</p><h2 id="9903" class="kt jr hi bd js ku kv kw jw kx ky kz ka iq la lb ke iu lc ld ki iy le lf km lg bi translated">它是如何工作的？</h2><p id="7730" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated"><strong class="ih hj"> 1-选择模型:</strong>tensor flow Lite 团队提供了一组预先训练好的模型，可以解决各种机器学习问题。这些模型已被转换为与 TensorFlow Lite 一起使用，并准备在您的应用程序中使用。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es li"><img src="../Images/d2978d09241037fe6addb8f25677b59c.png" data-original-src="https://miro.medium.com/v2/resize:fit:268/format:webp/1*RthTx9l-iLZZ2_iswTqxhQ.png"/></div></figure><p id="7997" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 2-转换模型:</strong> TensorFlow Lite 设计用于在内存和计算资源有限的移动和其他嵌入式设备上高效运行模型。这种效率部分来自于使用一种特殊的格式来存储模型。TensorFlow 模型必须转换为此格式，TensorFlow Lite 才能使用它们。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es lj"><img src="../Images/0318415953f44684a6dc236c6d80abc8.png" data-original-src="https://miro.medium.com/v2/resize:fit:336/format:webp/1*1U8DNnhhZ8g6oY0NaLTePw.png"/></div></figure><p id="f8ae" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">用模型进行三次推理:</strong>推理是通过模型运行数据以获得识别的过程。它需要一个模型、一个解释器和输入数据。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es lk"><img src="../Images/ad3d8dfb67673e1aa0a7dba0f8997770.png" data-original-src="https://miro.medium.com/v2/resize:fit:392/format:webp/1*RUGpGRKfFFgJx2LM8j9D6g.png"/></div></figure><p id="6813" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 4-优化您的模型:</strong> TensorFlow Lite 提供工具来优化您的模型的大小和性能，通常对准确性的影响最小。优化的模型可能需要稍微复杂一些的训练、转换或集成。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es lk"><img src="../Images/8ac40e0ed66d3214d6f397d682bc521e.png" data-original-src="https://miro.medium.com/v2/resize:fit:392/format:webp/1*WTU3b78L8sFIX3_esuE2Fg.png"/></div></figure><p id="d18f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你想了解更多关于 TensorFlow lite 的功能，并开始实现你自己的模型，我建议你访问<a class="ae lh" href="https://www.tensorflow.org/lite/guide/get_started" rel="noopener ugc nofollow" target="_blank">这篇文章</a>。</p><h1 id="55a6" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">Mobilenet</h1><p id="96a8" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">MobileNet 模型执行图像分类—它们将图像作为输入，并将图像中的主要对象分类到一组预定义的类别中。这些型号在速度和尺寸方面也非常高效，因此非常适合嵌入式和移动应用。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es ll"><img src="../Images/9e6bbef55d2696cb87aa7fe91999649d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AWlITS5nxLbGVKC2T1Yb2g.png"/></div></div></figure><h2 id="bac2" class="kt jr hi bd js ku kv kw jw kx ky kz ka iq la lb ke iu lc ld ki iy le lf km lg bi translated">关于 mobilenet 效率</h2><p id="3baf" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">MobileNet 架构基于将传统卷积分解为两种类型的层，第一卷积层“深度方向”和卷积 1×1 层“点方向”。这种划分允许减少计算成本和模型的大小。<br/>标准卷积层的计算成本<strong class="ih hj">比深度方向层和角度方向层的计算成本</strong>大 8 到 9 倍。此外，增加了一些参数，允许<strong class="ih hj">减小神经网络</strong>的大小和速度。</p><h2 id="5875" class="kt jr hi bd js ku kv kw jw kx ky kz ka iq la lb ke iu lc ld ki iy le lf km lg bi translated">Mobilenets 培训</h2><p id="02a1" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">他们在 ImageNet 数据集上接受训练，该数据集包含来自本要点<a class="ae lh" href="https://gist.github.com/MCarlomagno/6ab99d0ebd4ef3ef2d6c903c7341332f" rel="noopener ugc nofollow" target="_blank">中详述的 1000 个类别的图像。</a></p><p id="c1d0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">欲了解更多信息，请访问<a class="ae lh" href="https://arxiv.org/pdf/1704.04861.pdf" rel="noopener ugc nofollow" target="_blank">本文</a>。</p><h1 id="7426" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">Mobilenet in flutter 用于实时图像识别</h1><p id="c8e9" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">在这个项目中，我将使用<a class="ae lh" href="https://pub.dev/packages/tflite" rel="noopener ugc nofollow" target="_blank"> tflite 库</a>实现 Mobilenet 模型，这是一个用于访问 TensorFlow Lite API 的 Flutter 插件。</p><h2 id="ed76" class="kt jr hi bd js ku kv kw jw kx ky kz ka iq la lb ke iu lc ld ki iy le lf km lg bi translated"><strong class="ak">安装</strong></h2><p id="6a1a" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">在您的 pubspec.yml 中，添加:</p><figure class="jf jg jh ji fd jj"><div class="bz dy l di"><div class="lm ln l"/></div></figure><p id="d974" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> Android: </strong>在 android/app/build.gradle 中，在 android block 中添加如下设置。</p><figure class="jf jg jh ji fd jj"><div class="bz dy l di"><div class="lm ln l"/></div></figure><p id="f80c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> iOS: </strong>在 iOS 上构建错误的解决方案</p><ul class=""><li id="04a7" class="lo lp hi ih b ii ij im in iq lq iu lr iy ls jc lt lu lv lw bi translated"><strong class="ih hj">“vector”文件未找到:</strong> <br/>在 Xcode 中打开 ios/Runner.xcworkspace，单击 Runner&gt;Tagets&gt;Runner&gt;构建设置，搜索编译源为，将值更改为 Objective-C++</li><li id="4d90" class="lo lp hi ih b ii lx im ly iq lz iu ma iy mb jc lt lu lv lw bi translated"><strong class="ih hj">' tensorflow/lite/kernels/register . h '文件未找到:<br/> </strong>插件假定 tensor flow 头文件位于路径<code class="du mc md me mf b">tensorflow/lite/kernels</code>中。<br/>然而，对于 tensorflow 的早期版本，头路径是<code class="du mc md me mf b">tensorflow/contrib/lite/kernels</code>。使用<code class="du mc md me mf b">CONTRIB_PATH</code>来切换路径。取消此处<a class="ae lh" href="https://github.com/shaqian/flutter_tflite/blob/master/ios/Classes/TflitePlugin.mm#L1" rel="noopener ugc nofollow" target="_blank">的<code class="du mc md me mf b">//#define CONTRIB_PATH</code>注释。</a></li></ul><h2 id="57d1" class="kt jr hi bd js ku kv kw jw kx ky kz ka iq la lb ke iu lc ld ki iy le lf km lg bi translated"><strong class="ak">用法</strong></h2><p id="d055" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated"><strong class="ih hj">第一步</strong></p><p id="af27" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将通过从<a class="ae lh" href="https://www.tensorflow.org/lite/models/image_classification/overview" rel="noopener ugc nofollow" target="_blank">这里</a>下载文件 labels.txt 和 mobilenet _ v1 _ 1.0 _ 224 _ quant . tflite 来将模型导入到我们的应用程序中，然后我们创建 assets 文件夹并将标签和模型文件放入其中。</p><p id="8155" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">第二步</strong></p><p id="77e1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">完成第 1 步后，在 pubspec.yaml 中添加:</p><figure class="jf jg jh ji fd jj"><div class="bz dy l di"><div class="lm ln l"/></div></figure><p id="a39b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后我们将在终端中运行<code class="du mc md me mf b">flutter pub get</code>。</p><p id="8f62" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">第三步:</strong></p><p id="bd62" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">制作一个使用相机的简单应用程序。您可以在下面的<a class="ae lh" href="https://flutter.dev/docs/cookbook/plugins/picture-using-camera" rel="noopener ugc nofollow" target="_blank">链接</a>中使用 flutter 文档作为指南。</p><p id="e717" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">第四步:</strong></p><p id="cc74" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们为张量流创建一个服务，用于管理模型。<br/>应用程序初始化后，我们将加载模型，以便它可以开始预测，代码如下:</p><figure class="jf jg jh ji fd jj"><div class="bz dy l di"><div class="lm ln l"/></div></figure><p id="3fa4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">第五步:</strong></p><p id="dbdc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们使用相机控制器来捕捉每一帧，然后我们使用它们来生成一个识别，瞧！该模型给出了每一帧的识别结果。</p><figure class="jf jg jh ji fd jj"><div class="bz dy l di"><div class="lm ln l"/></div></figure><h2 id="e9c4" class="kt jr hi bd js ku kv kw jw kx ky kz ka iq la lb ke iu lc ld ki iy le lf km lg bi translated">考虑因素:</h2><p id="683e" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">1-结果是具有以下结构的按置信度排序的列表:</p><figure class="jf jg jh ji fd jj"><div class="bz dy l di"><div class="lm ln l"/></div></figure><p id="502b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2-在实现它时，我决定在每次识别之间留出 1 秒钟的延迟，以提高性能。</p><figure class="jf jg jh ji fd jj"><div class="bz dy l di"><div class="lm ln l"/></div></figure><p id="093f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后可以对 UI 进行改进，以更美观的方式显示数据😄。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es mg"><img src="../Images/61258af0e6462a2c72a43cc8f2192541.png" data-original-src="https://miro.medium.com/v2/resize:fit:576/1*NMvEl-YR1o2eG1momnd5qg.gif"/></div></figure><blockquote class="mh"><p id="988f" class="mi mj hi bd mk ml mm mn mo mp mq jc dx translated">你可以访问这个 github 库来查看完整的实现。</p></blockquote><h2 id="d4fb" class="kt jr hi bd js ku mr kw jw kx ms kz ka iq mt lb ke iu mu ld ki iy mv lf km lg bi translated">其他型号</h2><p id="6aea" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated"><strong class="ih hj"> MobileNet SSD: </strong>又名“单次多盒检测器”模型用于检测同一图像中的多个对象，并为每个对象分配一个置信度。<br/> <a class="ae lh" href="https://www.tensorflow.org/lite/models/object_detection/overview" rel="noopener ugc nofollow" target="_blank">更多信息</a></p><p id="eb47" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">微小的 YOLOv2: </strong>它另辟蹊径。我们将单个神经网络应用于整个图像。该网络将图像分成多个区域，并预测每个区域的边界框和概率。这些边界框由预测概率加权。小 YOLO 架构比它的大兄弟快了大约 442%，在单个 GPU 上达到 244 FPS 以上。<br/>小的模型尺寸(&lt; 50MB)和快速的推理速度使得微小 YOLO 物体检测器自然地适合用于嵌入式计算机视觉/深度学习设备。<br/> <a class="ae lh" href="https://www.tensorflow.org/lite/models/object_detection/overview" rel="noopener ugc nofollow" target="_blank">更多信息</a></p><p id="f7c1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> Pix2Pix: </strong>这些网络不仅学习输入图像到输出图像的映射，还学习一个损失函数来训练这个映射。这使得将相同的通用方法应用于传统上需要非常不同的损失公式的问题成为可能。<br/> <a class="ae lh" href="https://www.tensorflow.org/tutorials/generative/pix2pix" rel="noopener ugc nofollow" target="_blank">更多信息</a></p><p id="d15e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> Deeplab: </strong> DeepLab 是一个最先进的深度学习模型，用于语义图像分割，目标是为输入图像中的每个像素分配语义标签(例如，人、狗、猫等)。<br/> <a class="ae lh" href="https://arxiv.org/pdf/1606.00915.pdf" rel="noopener ugc nofollow" target="_blank">更多信息</a></p></div></div>    
</body>
</html>