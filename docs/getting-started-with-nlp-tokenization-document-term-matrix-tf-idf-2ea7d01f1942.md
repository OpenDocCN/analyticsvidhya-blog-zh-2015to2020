# NLP 入门:标记化、文档术语矩阵、TF-IDF

> 原文：<https://medium.com/analytics-vidhya/getting-started-with-nlp-tokenization-document-term-matrix-tf-idf-2ea7d01f1942?source=collection_archive---------7----------------------->

应用基本的自然语言处理技术对推文进行文本分类:真的还是假的？

在这篇文章中，我们继续描述一些传统的方法来处理自然语言处理任务，文本分类。

这是一个简单快速的文本分类器，基于传统的自然语言处理方法。接下来的步骤是:

*   描述标记化的过程
*   如何建立一个术语文档矩阵(使用一些方法，如字数统计和 TFIDF)作为数字化方法
*   然后应用机器学习分类器来预测或分类一条推文是真的还是假的。

**博文及代码可在** [**我的 fastai pages 博客**](https://edumunozsala.github.io/BlogEms/jupyter/nlp/classification/python/2020/07/31/Intro_NLP_1_TFIDF_Text_Classification.html) **上获取。**

# 问题描述

*推特已经成为紧急时刻的重要沟通渠道。智能手机的普及使人们能够实时宣布他们正在观察的紧急情况。正因为如此，越来越多的机构对有计划地监控 Twitter 感兴趣(如救灾组织和新闻机构)。但是，人们并不总是清楚一个人的话是否实际上是在宣布一场灾难。*

*在这个问题中，你面临的挑战是建立一个机器学习模型，预测哪些推文是关于真正的灾难，哪些不是。你将可以访问一个由 10，000 条推文组成的数据集，这些推文已经过人工分类。*

这是 NLP 入门的一场竞赛。

训练和测试集中的每个样本都有以下信息:

*   一条推文的文本
*   那条推文中的一个关键词(虽然这可能是空白的！)
*   发送推文的位置(也可以是空白的)

你在预测一条推文是否是关于一场真正的灾难。如果是，预测一个 1。如果没有，预测 0。

**代码在我的 github 账号** **的一个** [**笔记本上。**](https://github.com/edumunozsala/Intro-NLP-Text-Classification/blob/master/Intro_NLP_1_TFIDF_Text_Classification.ipynb)

# 准备数据

**这篇文章不包括如何实现最好的预处理来清理我们的推文**。因此，我们将按原样向我们的模型提供 tweet，或者只删除字母数字字符。为了更好的结果，我们应该检查推文，并应用一些清除无用的单词，拼写错误的单词，表情符号，也许 URIs，…

我们将训练数据集分为训练和验证数据集，这样我们就可以评估结果并应用交叉验证等技巧。这项工作是在许多其他笔记本中使用 sklearn 完成的。

# 标记化

标记化是自然语言处理中的一项常见任务。无论是在计数矢量器等传统方法中，还是在 RNN 或变形金刚等基于深度学习的架构中，这都是一个基本步骤。

> 给定一个字符序列和一个已定义的文档单元，标记化是将它分割成称为标记的片段的任务，可能同时丢弃某些字符，如标点符号。这里有一个标记化的例子:

![](img/17b72ae6b7a03c73ef20499c017f62a3.png)

单词标记化

> 这些标记通常被笼统地称为术语或单词，但有时区分类型/标记是很重要的。令牌是某个特定文档中字符序列的实例，这些字符被组合在一起作为有用的语义单元进行处理。类型是包含相同字符序列的所有标记的类。术语是包含在 IR 系统字典中的(可能是规范化的)类型。该组索引项可以完全不同于令牌。
> 
> [1]斯坦福大学 NLP 小组，[https://NLP . Stanford . edu/IR-book/html/html edition/token ization-1 . html](https://nlp.stanford.edu/IR-book/html/htmledition/tokenization-1.html)

*“标记化是文本数据建模的首要步骤。对语料库执行标记化以获得标记。然后，使用以下标记来准备词汇表。词汇指的是语料库中的唯一标记集。请记住，可以通过考虑语料库中的每个唯一标记或通过考虑前 K 个频繁出现的单词来构建词汇”。[2]* 什么是 NLP 中的标记化？这里有你需要知道的一切由 Aravind Pai，[https://www . analyticsvidhya . com/blog/2020/05/what-is-token ization-NLP/](https://www.analyticsvidhya.com/blog/2020/05/what-is-tokenization-nlp/)

在我们的示例中，标记化过程是在用于处理文本的函数内部完成的。sklearn 库和它们的模块将标记文本，然后应用一种技术将这些标记转换成数字表示。

# 创建特征或数字化文本:术语-文档矩阵

*“文档-术语矩阵或术语-文档矩阵是描述术语在文档集合中出现的频率的数学矩阵。在文档-术语矩阵中，行对应于集合中的文档，列对应于术语。有各种方案来确定矩阵中每个条目应取的值。tf-idf 就是这样一个方案。它们在自然语言处理领域很有用。”*

我们可以将**文档术语矩阵(DTM)** 视为单词袋概念的实现。术语文档矩阵通过每个文档跟踪每个术语的术语频率。您从文档的单词包表示开始，然后对于每个文档，您跟踪一个术语存在的次数。根据语料库中的文档数量和每个文档中的术语数量，文档术语矩阵可以变成非常大的稀疏矩阵(0 比值多很多)。

考虑到我们的数据是文本格式的 tweets(文档)的集合，该过程将需要对文本进行标记以获得一组标记(我们词汇表中的项目)，在这个阶段，我们通常会减少标记的术语数量，删除那些似乎不相关的术语。如果我们的 vocab 包含太多的单词，其中许多是不相关的，我们将花费许多资源，并且我们的 DTM 可能对该过程无用。

![](img/953ab151930eae61e67dc6afb6786d9c.png)

文档术语矩阵

# 计数矢量器

现在是时候将一组文本文档(我们的推文)转换成一个令牌/字数矩阵(DTM)。如果您不提供先验词典，并且不使用进行某种特征选择的分析器，那么特征的数量将等于通过分析数据找到的词汇大小。

我们简单地统计这个术语在文档中出现的次数，它将是 cell (document，term)的值。

# TF-IDF

另一种制造 DTM 的技术是 **TF-IDF** 。

> “在信息检索中，TF–IDF 或 TFIDF 是*词频–逆文档频率*的缩写，是一种数字统计，旨在反映一个词对集合或语料库中的文档有多重要。在信息检索、文本挖掘和用户建模的搜索中，它经常被用作加权因子。TF–IDF 值与某个单词在文档中出现的次数成比例增加，并被语料库中包含该单词的文档数抵消，这有助于调整某些单词通常出现频率更高的事实。TF–IDF 是当今最受欢迎的术语加权方案之一。”—维基百科

**代码在我的 github 账号** **的一个** [**笔记本上。**](https://github.com/edumunozsala/Intro-NLP-Text-Classification/blob/master/Intro_NLP_1_TFIDF_Text_Classification.ipynb)

# 朴素贝叶斯

我们将使用文本分类中常用的传统分类器:使用多项式模型的朴素贝叶斯。

*“多项式朴素贝叶斯分类器适用于具有离散特征的分类(例如，用于文本分类的字数)。多项式分布通常需要整数特征计数。但是，在实践中，分数计数(如 tf-idf)也可能有效。”*，摘自 Ritchie Ng 的《*矢量化、多项式朴素贝叶斯分类器及评估*》。

我们不会详细描述这个算法是如何工作的，在以后的文章中我们会。此时此刻，我们可以确认它已经在多年的许多 NLP 任务中产生了巨大的成果。

只是为了比较，我们将为二元分类构建其他分类器，以检查我们的模型性能是否足够好，作为改进的初始解决方案。

# 支持向量机

> *“支持向量机算法的目标是在一个 N 维空间(N——特征的数量)中找到一个超平面，该超平面可以清楚地对数据点进行分类。”，*
> 
> *——*Rohith Gandhi 的《机器学习算法的支持向量机介绍》。

我们可以使用 SVM 算法来预测一条推文是假还是真，这只是一个二元分类问题。

# XGBoost 分类器

XGBoost 是梯度增强决策树的一种实现，旨在提高速度和性能，是占主导地位的竞争机器学习。对于第一个 XGBoost 模型来说，这是一个很好的数据集，因为所有的输入变量都是数值型的，并且问题是一个简单的二元分类问题。

**代码在我的 github 账号** **的一个** [**笔记本上。**](https://github.com/edumunozsala/Intro-NLP-Text-Classification/blob/master/Intro_NLP_1_TFIDF_Text_Classification.ipynb)

# 评估和指标

我们的算法已经表现出类似的性能，正如我们之前所说的，我们并不是在寻找一个优化和调整的分类器，我们的目标是描述我们如何在几个步骤中轻松地对文本进行分类。投入时间和试验参数，我们会取得更好的结果。

现在，我们的分类器在测试集上达到了 81%的准确率和 0.75 的 F1 值。在下图中，我们绘制了 ROC 和混淆矩阵

![](img/24a0b35aece28b3778254df7ec9234aa.png)

评估指标

因此，我们可以观察到，应用一些“旧的”和简单的技术而不进行“微调”,我们可以用几行代码和不超过一个小时的处理时间获得一个分类器。这个分类器可以以相对较高的可信度预测一条推文何时宣布一场虚假或真实的灾难。

**代码在我的 github 账号** **中的** [**笔记本上。**](https://github.com/edumunozsala/Intro-NLP-Text-Classification/blob/master/Intro_NLP_1_TFIDF_Text_Classification.ipynb)