<html>
<head>
<title>Understanding Logistic Regression the Geometric Way!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">以几何方式理解逻辑回归！</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/understanding-logistic-regression-the-geometric-way-6538012a4449?source=collection_archive---------14-----------------------#2020-05-29">https://medium.com/analytics-vidhya/understanding-logistic-regression-the-geometric-way-6538012a4449?source=collection_archive---------14-----------------------#2020-05-29</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="8be9" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">逻辑回归的几何起点</h2></div><h2 id="ebba" class="ix iy hi bd iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju bi translated">什么是逻辑回归？</h2><p id="f6de" class="pw-post-body-paragraph jv jw hi jx b jy jz ij ka kb kc im kd ji ke kf kg jm kh ki kj jq kk kl km kn hb bi translated">逻辑回归是解决<strong class="jx hj">分类</strong>问题的基本和流行算法之一，不像它的名字中包含回归。它被命名为“逻辑回归”，因为它的基本技术与线性回归完全相同。逻辑回归的优势之一是它可以处理各种类型的关系，而不仅限于线性关系。</p><figure class="kp kq kr ks fd kt er es paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="er es ko"><img src="../Images/f4436b8e83bb3dac2942f242e6720232.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*n2Yhin53lFn-7xloKg_sfQ.gif"/></div></div><figcaption class="la lb et er es lc ld bd b be z dx translated">逻辑回归</figcaption></figure><h2 id="9be3" class="ix iy hi bd iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju bi translated">让我们试着理解逻辑回归背后的几何直觉:</h2><p id="5102" class="pw-post-body-paragraph jv jw hi jx b jy jz ij ka kb kc im kd ji ke kf kg jm kh ki kj jq kk kl km kn hb bi translated">理解逻辑回归的方法不止一种，主要有<strong class="jx hj">概率法</strong>、<strong class="jx hj">几何法、</strong>和<strong class="jx hj">损失函数最小化法</strong>，但在所有的<strong class="jx hj">几何法</strong>中，我个人觉得更直观理解。让我们来看看:</p><p id="b998" class="pw-post-body-paragraph jv jw hi jx b jy le ij ka kb lf im kd ji lg kf kg jm lh ki kj jq li kl km kn hb bi translated"><strong class="jx hj">假设</strong>:逻辑回归的基本假设是数据几乎或完全线性可分，即所有(+ve)和(-ve)类都是可分的，如果不可分，只有极少数是混合的。</p><p id="e436" class="pw-post-body-paragraph jv jw hi jx b jy le ij ka kb lf im kd ji lg kf kg jm lh ki kj jq li kl km kn hb bi translated"><strong class="jx hj">目标</strong>:我们的目标是找到一个平面(<strong class="jx hj"> π) </strong>最好的分离(+ve)和(-ve)类。</p><p id="7f9f" class="pw-post-body-paragraph jv jw hi jx b jy le ij ka kb lf im kd ji lg kf kg jm lh ki kj jq li kl km kn hb bi translated">基础知识:让我们来看看一些基本术语，它们会使事情更容易理解。</p><p id="68b3" class="pw-post-body-paragraph jv jw hi jx b jy le ij ka kb lf im kd ji lg kf kg jm lh ki kj jq li kl km kn hb bi translated">我们将代表一架飞机。Pi(𝜋)并垂直于带有<strong class="jx hj"> W </strong>的平面</p><p id="145a" class="pw-post-body-paragraph jv jw hi jx b jy le ij ka kb lf im kd ji lg kf kg jm lh ki kj jq li kl km kn hb bi translated">平面方程:</p><figure class="kp kq kr ks fd kt er es paragraph-image"><div class="er es lj"><img src="../Images/639d8ea2d94126672bf26bf30151085a.png" data-original-src="https://miro.medium.com/v2/resize:fit:518/format:webp/1*jnse3HSmcyYAhG3Ik08VHA.png"/></div><figcaption class="la lb et er es lc ld bd b be z dx translated">平面可视化</figcaption></figure><p id="262a" class="pw-post-body-paragraph jv jw hi jx b jy le ij ka kb lf im kd ji lg kf kg jm lh ki kj jq li kl km kn hb bi translated"><strong class="jx hj"> w^t*xi+b=0 </strong>，其中<strong class="jx hj"> b </strong>为标量，<strong class="jx hj"> xi </strong>为第I个观测值。如果平面通过原点，方程变成<strong class="jx hj"> w^t*xi = 0，</strong></p><p id="4b0e" class="pw-post-body-paragraph jv jw hi jx b jy le ij ka kb lf im kd ji lg kf kg jm lh ki kj jq li kl km kn hb bi translated">其中<strong class="jx hj"> w^t( </strong>读作Wtranspose <strong class="jx hj"> ) </strong>是<a class="ae lk" href="https://en.wikipedia.org/wiki/Row_and_column_vectors" rel="noopener ugc nofollow" target="_blank">行向量</a>而<strong class="jx hj"> xi </strong>是<a class="ae lk" href="https://en.wikipedia.org/wiki/Row_and_column_vectors" rel="noopener ugc nofollow" target="_blank">列向量</a></p><h2 id="ad58" class="ix iy hi bd iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju bi translated">几何解释:</h2><figure class="kp kq kr ks fd kt er es paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="er es ll"><img src="../Images/c6690de02f878aad0fc45cafa7f514e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VtfxLaFklW2-o6lVo0Ukew.png"/></div></div><figcaption class="la lb et er es lc ld bd b be z dx translated">分隔+ve和-ve类的平面</figcaption></figure><p id="9df2" class="pw-post-body-paragraph jv jw hi jx b jy le ij ka kb lf im kd ji lg kf kg jm lh ki kj jq li kl km kn hb bi translated">如果我们取任何+ve类点，它们离平面的距离di计算如下:</p><p id="4355" class="pw-post-body-paragraph jv jw hi jx b jy le ij ka kb lf im kd ji lg kf kg jm lh ki kj jq li kl km kn hb bi translated">(di = w^t*xi/||w||.设，范数向量(||w||)为1)</p><p id="83eb" class="pw-post-body-paragraph jv jw hi jx b jy le ij ka kb lf im kd ji lg kf kg jm lh ki kj jq li kl km kn hb bi translated">由于w和xi在判定边界的同一侧，那么距离将是<strong class="jx hj"> +ve </strong>。现在计算dj = w^t*xj，因为xj是w的对边，那么距离就是<strong class="jx hj"> -ve。</strong></p><p id="c12a" class="pw-post-body-paragraph jv jw hi jx b jy le ij ka kb lf im kd ji lg kf kg jm lh ki kj jq li kl km kn hb bi translated">通过使用if (w^t*x &gt;0) then +ve类和if (w^t*x &lt;0) then -ve类，我们可以很容易地将点分为-ve点和+ve点</p><p id="4dfc" class="pw-post-body-paragraph jv jw hi jx b jy le ij ka kb lf im kd ji lg kf kg jm lh ki kj jq li kl km kn hb bi translated">所以我们的分类器是:</p><pre class="kp kq kr ks fd lm ln lo lp aw lq bi"><span id="d1de" class="ix iy hi ln b fi lr ls l lt lu">If w^t * xi &gt; 0  :  then Y = +1    where Y is the class label<br/>If w^t * xi &lt; 0  :  then Y = -1    where Y is the class label</span></pre><p id="a199" class="pw-post-body-paragraph jv jw hi jx b jy le ij ka kb lf im kd ji lg kf kg jm lh ki kj jq li kl km kn hb bi translated">观察结果:</p><p id="a329" class="pw-post-body-paragraph jv jw hi jx b jy le ij ka kb lf im kd ji lg kf kg jm lh ki kj jq li kl km kn hb bi translated">仔细观察上图中的点，我们观察到以下情况:</p><pre class="kp kq kr ks fd lm ln lo lp aw lq bi"><span id="6093" class="ix iy hi ln b fi lr ls l lt lu"><strong class="ln hj"><em class="lv">case 1</em></strong>: Yi &gt;0 and  w^t * xi &gt; 0<br/>Yi = +1 means that the correct class label is +ve =&gt; <strong class="ln hj">Yi* w^t * xi &gt;0</strong> means that we have <strong class="ln hj">correctly predicted</strong> the class label.<br/>as +ve * +ve = +ve</span><span id="c26f" class="ix iy hi ln b fi lw ls l lt lu"><strong class="ln hj"><em class="lv">case 2</em></strong>: Yi &lt;0 and  w^t * xi &lt;0<br/>Yi = -1 means that the correct class label is -ve =&gt; <strong class="ln hj">Yi* w^t * xi &gt;0 </strong>means that we have <strong class="ln hj">correctly predicted</strong> the class label.<br/>as -ve * -ve = +ve</span><span id="b78d" class="ix iy hi ln b fi lw ls l lt lu"><strong class="ln hj"><em class="lv">case 3</em></strong>: Yi &gt;0 and  w^t * xi &lt;0<br/>Yi = +1 means that the correct class label is -ve =&gt; <strong class="ln hj">Yi* w^t * xi &lt;0</strong> means that we have <strong class="ln hj">wrongly predicted</strong> the class label.<br/>as +ve * -ve = -ve </span><span id="8447" class="ix iy hi ln b fi lw ls l lt lu"><strong class="ln hj"><em class="lv">case 2</em></strong>: Yi &lt;0 and  w^t * xi &gt;0<br/>Yi = -1 means that the correct class label is -ve =&gt; <strong class="ln hj">Yi* w^t * xi &lt;0</strong> means that we have <strong class="ln hj">wrongly predicted</strong> the class label.<br/>as -ve * +ve = -ve </span></pre><p id="9f55" class="pw-post-body-paragraph jv jw hi jx b jy le ij ka kb lf im kd ji lg kf kg jm lh ki kj jq li kl km kn hb bi translated">现在有无限多的平面可以用来把点或类分成+ve和-ve。最佳平面是将更多的点分类到正确的类别中，即，为了找到最佳平面，我们需要最大化所有点的分类器的总和。<br/>这就给出了我们的优化函数:</p><figure class="kp kq kr ks fd kt er es paragraph-image"><div class="er es lx"><img src="../Images/36be7806ab86d72e0fab6e1e136acf3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:494/format:webp/1*c-mnm59Dwu7nuKVRqeu7EA.png"/></div><figcaption class="la lb et er es lc ld bd b be z dx translated">优化功能</figcaption></figure><h2 id="e24f" class="ix iy hi bd iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju bi translated">挤压:需要逻辑函数或S形函数或S形曲线</h2><p id="dfec" class="pw-post-body-paragraph jv jw hi jx b jy jz ij ka kb kc im kd ji ke kf kg jm kh ki kj jq kk kl km kn hb bi translated">我们已经得到了我们的优化函数，那么为什么我们还需要另一个函数呢？？</p><p id="1447" class="pw-post-body-paragraph jv jw hi jx b jy le ij ka kb lf im kd ji lg kf kg jm lh ki kj jq li kl km kn hb bi translated">上面的优化函数有问题，为了理解什么，让我们考虑以下场景:</p><figure class="kp kq kr ks fd kt er es paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="er es ly"><img src="../Images/8b9e3505197f5885177516e8f28f2f9b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UdJaIJ7yD9ZziQVxPgMmtg.png"/></div></div><figcaption class="la lb et er es lc ld bd b be z dx translated">LR中的异常问题</figcaption></figure><p id="db6b" class="pw-post-body-paragraph jv jw hi jx b jy le ij ka kb lf im kd ji lg kf kg jm lh ki kj jq li kl km kn hb bi translated">在图1中。平面的距离(𝜋)正确地将d=1处的所有点分类，除了在d=100处的一个异常值。平面1的优化函数的输出为-90°</p><p id="e7a0" class="pw-post-body-paragraph jv jw hi jx b jy le ij ka kb lf im kd ji lg kf kg jm lh ki kj jq li kl km kn hb bi translated">而在图2中。第一个蓝色(+ve)点在d=1处，所有其他点彼此相距d=1，类似地，有一个绿色点(-ve)被正确分类，并且与平面相距d=1，而其余点被错误分类。<br/>优化函数给出的输出为+1</p><p id="d6b2" class="pw-post-body-paragraph jv jw hi jx b jy le ij ka kb lf im kd ji lg kf kg jm lh ki kj jq li kl km kn hb bi translated">直观地看一下上图，你会发现(图1: 𝜋)比(图2: 𝜋)更好，因为(图1: 𝜋)正确地分类了更多的数据点，而(图2: 𝜋)只正确地分类了一个数据点，但是根据我们的优化函数(图2: 𝜋)，它更好，因为+1 &gt; -90</p><p id="c445" class="pw-post-body-paragraph jv jw hi jx b jy le ij ka kb lf im kd ji lg kf kg jm lh ki kj jq li kl km kn hb bi translated">为了解决这个由异常值引起的问题，我们需要一个稳健的函数，它不会受到异常值的太大影响。</p><p id="7fd1" class="pw-post-body-paragraph jv jw hi jx b jy le ij ka kb lf im kd ji lg kf kg jm lh ki kj jq li kl km kn hb bi translated">一种这样的函数是S形函数或“S”形函数:</p><figure class="kp kq kr ks fd kt er es paragraph-image"><div class="er es lz"><img src="../Images/6062f8634124f71d923b1aa4ac2f3973.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*a2e-ozEcNCm_s0trFzf-DA.jpeg"/></div><figcaption class="la lb et er es lc ld bd b be z dx translated">Sigmoid函数图</figcaption></figure><h2 id="16ed" class="ix iy hi bd iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju bi translated">为什么是乙状结肠函数？</h2><ol class=""><li id="9205" class="ma mb hi jx b jy jz kb kc ji mc jm md jq me kn mf mg mh mi bi translated">这是一个单调的<a class="ae lk" href="https://en.wikipedia.org/wiki/Monotonic_function" rel="noopener ugc nofollow" target="_blank">函数</a>，它挤压0和1之间的值:无论异常值是多少，它的值都不会超过0-1，因此整个过程被称为挤压</li><li id="7769" class="ma mb hi jx b jy mj kb mk ji ml jm mm jq mn kn mf mg mh mi bi translated">它提供了一个很好的概率解释。例如，如果一个点位于决策面上(d = 0)，那么凭直觉，它的概率应该是1/2，因为它可以属于任何类别，这里我们也可以看到，适马(0) = 1/2。</li><li id="3f10" class="ma mb hi jx b jy mj kb mk ji ml jm mm jq mn kn mf mg mh mi bi translated">容易微分，</li></ol><p id="3943" class="pw-post-body-paragraph jv jw hi jx b jy le ij ka kb lf im kd ji lg kf kg jm lh ki kj jq li kl km kn hb bi translated">因此，我们需要最大化sigmoid函数，其定义为:</p><figure class="kp kq kr ks fd kt er es paragraph-image"><div class="er es mo"><img src="../Images/c3469dd32937397c9a689a305c27d4a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:666/format:webp/1*FFUtcHCmE2_48dDoFCN9BA.png"/></div><figcaption class="la lb et er es lc ld bd b be z dx translated">Sigmoid函数</figcaption></figure><p id="8b16" class="pw-post-body-paragraph jv jw hi jx b jy le ij ka kb lf im kd ji lg kf kg jm lh ki kj jq li kl km kn hb bi translated">这为我们提供了优化函数:</p><figure class="kp kq kr ks fd kt er es paragraph-image"><div class="er es mp"><img src="../Images/97b52edc9372425375ad308a008e02e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:870/format:webp/1*_EHWmDDr-jmjaROslyRrlw.png"/></div><figcaption class="la lb et er es lc ld bd b be z dx translated">优化功能</figcaption></figure><p id="9d74" class="pw-post-body-paragraph jv jw hi jx b jy le ij ka kb lf im kd ji lg kf kg jm lh ki kj jq li kl km kn hb bi translated">等等什么？？？？？？想知道我们怎么从sigmoid函数得到上面的函数？方法如下:</p><p id="79a0" class="pw-post-body-paragraph jv jw hi jx b jy le ij ka kb lf im kd ji lg kf kg jm lh ki kj jq li kl km kn hb bi translated">我们利用了sigmoid函数是<a class="ae lk" href="https://en.wikipedia.org/wiki/Monotonic_function" rel="noopener ugc nofollow" target="_blank">单调函数</a>的性质，并且f(x)= log(x)也是单调函数:我们取sigmoid函数的log来简化它。</p><p id="b98f" class="pw-post-body-paragraph jv jw hi jx b jy le ij ka kb lf im kd ji lg kf kg jm lh ki kj jq li kl km kn hb bi translated">我们将使用以下属性来获得所需形式的优化函数</p><ol class=""><li id="6666" class="ma mb hi jx b jy le kb lf ji mq jm mr jq ms kn mf mg mh mi bi translated"><strong class="jx hj"> log(1/x) = -log(x) </strong></li><li id="9b4a" class="ma mb hi jx b jy mj kb mk ji ml jm mm jq mn kn mf mg mh mi bi translated"><strong class="jx hj">arg max(-f(x))= arg min(f(x))</strong>ie。最大化负函数和最小化正函数是一样的。</li></ol><p id="458c" class="pw-post-body-paragraph jv jw hi jx b jy le ij ka kb lf im kd ji lg kf kg jm lh ki kj jq li kl km kn hb bi translated">应用以上两个性质，我们得到:</p><figure class="kp kq kr ks fd kt er es paragraph-image"><div class="er es mp"><img src="../Images/97b52edc9372425375ad308a008e02e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:870/format:webp/1*_EHWmDDr-jmjaROslyRrlw.png"/></div><figcaption class="la lb et er es lc ld bd b be z dx translated">优化功能</figcaption></figure><h2 id="80d3" class="ix iy hi bd iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju bi translated">最小化策略:</h2><p id="eafc" class="pw-post-body-paragraph jv jw hi jx b jy jz ij ka kb kc im kd ji ke kf kg jm kh ki kj jq kk kl km kn hb bi translated">让我们重新审视这个等式:</p><pre class="kp kq kr ks fd lm ln lo lp aw lq bi"><span id="680b" class="ix iy hi ln b fi lr ls l lt lu">                     n<br/>W(optimal) = argmin(∑i=1  log(1 + exp(- Yi * w^t * xi)) </span><span id="768a" class="ix iy hi ln b fi lw ls l lt lu">Let z= Yi * w^t * xi               <br/>                     n <br/>W(optimal) = argmin(∑i=1  log(1 + exp(- Zi))</span></pre><figure class="kp kq kr ks fd kt er es paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="er es mt"><img src="../Images/80653f8b6d89bd5206ee0a5f21165396.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gJij9i2K8QH3IUqcP_3jSA.png"/></div></div><figcaption class="la lb et er es lc ld bd b be z dx translated">exp(-z)的图形</figcaption></figure><p id="e23e" class="pw-post-body-paragraph jv jw hi jx b jy le ij ka kb lf im kd ji lg kf kg jm lh ki kj jq li kl km kn hb bi translated">从上图可以看出，exp(-Zi)总是正的。</p><pre class="kp kq kr ks fd lm ln lo lp aw lq bi"><span id="1aa2" class="ix iy hi ln b fi lr ls l lt lu"> exp(-Zi) — &gt; 0 to +∞ </span><span id="bfc4" class="ix iy hi ln b fi lw ls l lt lu">                     n<br/>W(optimal) = argmin(∑i=1 log(1 + exp(- Zi)) &gt;= 0 </span><span id="9840" class="ix iy hi ln b fi lw ls l lt lu">when exp(-Zi)-&gt; 0 =&gt; argmin(∑i=1 log(1 + 0))  and as log(1) = 0</span></pre><p id="78cc" class="pw-post-body-paragraph jv jw hi jx b jy le ij ka kb lf im kd ji lg kf kg jm lh ki kj jq li kl km kn hb bi translated">优化函数的So-min <strong class="jx hj">值是0 </strong>，并且当<strong class="jx hj"> exp(- Zi) = 0 </strong> <br/>时出现，因此我们的优化函数的整体最小值将出现在</p><p id="6f98" class="pw-post-body-paragraph jv jw hi jx b jy le ij ka kb lf im kd ji lg kf kg jm lh ki kj jq li kl km kn hb bi translated"><code class="du mu mv mw ln b">Zi -&gt; +∞ for all i</code></p><p id="8dd1" class="pw-post-body-paragraph jv jw hi jx b jy le ij ka kb lf im kd ji lg kf kg jm lh ki kj jq li kl km kn hb bi translated">现在我们知道子=易* w^t * xi，这里<strong class="jx hj">是特征，</strong>是标签，唯一可以操作的就是<strong class="jx hj">了</strong></p><p id="ab49" class="pw-post-body-paragraph jv jw hi jx b jy le ij ka kb lf im kd ji lg kf kg jm lh ki kj jq li kl km kn hb bi translated">为了将Zi的值移至无穷大，我们将为w选择一个非常大的值(要么+要么-)。</p><pre class="kp kq kr ks fd lm ln lo lp aw lq bi"><span id="7a54" class="ix iy hi ln b fi lr ls l lt lu"><strong class="ln hj">case 1: </strong><strong class="ln hj">Yi =+1</strong><br/>(Yi * w^t * xi) = +1 * (very large +ve value of W ) * xi   =  Very large +ve value ~&gt; <!-- -->+∞</span><span id="6051" class="ix iy hi ln b fi lw ls l lt lu"><strong class="ln hj">case 2: Yi= -1</strong><br/>(Yi * w^t * xi) = -1 * (very large -ve value of W ) * xi   =  Very large +ve value ~&gt; <!-- -->+∞<!-- --> </span></pre><p id="ca80" class="pw-post-body-paragraph jv jw hi jx b jy le ij ka kb lf im kd ji lg kf kg jm lh ki kj jq li kl km kn hb bi translated">这样就完成了使Zi → +∞的任务</p><h1 id="d870" class="mx iy hi bd iz my mz na jd nb nc nd jh io ne ip jl ir nf is jp iu ng iv jt nh bi translated">正规化:</h1><p id="bb91" class="pw-post-body-paragraph jv jw hi jx b jy jz ij ka kb kc im kd ji ke kf kg jm kh ki kj jq kk kl km kn hb bi translated">上述策略的问题是，我们可以通过找到w的这么大的值来使Zi →+∞为I的所有值。<br/>为什么这是一个问题:这里的问题是过度拟合我们正在制作我们的模型，通过制作<code class="du mu mv mw ln b">Zi -&gt; +∞</code>好得不真实</p><figure class="kp kq kr ks fd kt er es paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="er es ni"><img src="../Images/ac2ae3dc58fd479aa4900aec2399950b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UCd6KrmBxpzUpWt3bnoKEA.png"/></div></div></figure><p id="45d1" class="pw-post-body-paragraph jv jw hi jx b jy le ij ka kb lf im kd ji lg kf kg jm lh ki kj jq li kl km kn hb bi translated">如果决策边界过度拟合，形状可能会严重扭曲，只适合训练数据，而无法对看不见的数据进行归纳。</p><p id="e581" class="pw-post-body-paragraph jv jw hi jx b jy le ij ka kb lf im kd ji lg kf kg jm lh ki kj jq li kl km kn hb bi translated">因此我们使用<strong class="jx hj">正则化</strong>，因此逻辑回归的成本函数被更新以惩罚参数的高值。</p><p id="ae97" class="pw-post-body-paragraph jv jw hi jx b jy le ij ka kb lf im kd ji lg kf kg jm lh ki kj jq li kl km kn hb bi translated">有两种最常用的规范化类型:</p><ol class=""><li id="6c5b" class="ma mb hi jx b jy le kb lf ji mq jm mr jq ms kn mf mg mh mi bi translated">L2正规化</li><li id="24f9" class="ma mb hi jx b jy mj kb mk ji ml jm mm jq mn kn mf mg mh mi bi translated">L1正规化</li></ol><h2 id="aabe" class="ix iy hi bd iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju bi translated"><strong class="ak"> L2正规化:</strong></h2><p id="0679" class="pw-post-body-paragraph jv jw hi jx b jy jz ij ka kb kc im kd ji ke kf kg jm kh ki kj jq kk kl km kn hb bi translated">在L2正则化中，我们引入了一个称为正则化参数的附加术语来防止过度拟合。</p><figure class="kp kq kr ks fd kt er es paragraph-image"><div class="er es nj"><img src="../Images/a2e0b8f98deee2d7e49fed9712e4f1c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1380/format:webp/1*bu8vvfJOOy5pQxgdlbLLgA.png"/></div><figcaption class="la lb et er es lc ld bd b be z dx translated">L2正则化</figcaption></figure><p id="d995" class="pw-post-body-paragraph jv jw hi jx b jy le ij ka kb lf im kd ji lg kf kg jm lh ki kj jq li kl km kn hb bi translated">超参数:<strong class="jx hj"> λ </strong></p><p id="7f9a" class="pw-post-body-paragraph jv jw hi jx b jy le ij ka kb lf im kd ji lg kf kg jm lh ki kj jq li kl km kn hb bi translated"><em class="lv">正规化术语</em> <strong class="jx hj"> : </strong> <strong class="jx hj"> λW^TW </strong></p><p id="b81f" class="pw-post-body-paragraph jv jw hi jx b jy le ij ka kb lf im kd ji lg kf kg jm lh ki kj jq li kl km kn hb bi translated"><em class="lv">损失函数</em><strong class="jx hj">:w * = arg min(∑I = 1 log(1+exp(-易W^TXi)) </strong></p><p id="1431" class="pw-post-body-paragraph jv jw hi jx b jy le ij ka kb lf im kd ji lg kf kg jm lh ki kj jq li kl km kn hb bi translated">现在，如果我们试图通过增加w的值并使<em class="lv">损失项</em> ~ &gt;为0来使Zi →+∞，我们的<em class="lv">正则项</em>将通过变成+∞ as来对此进行补偿，我们有<strong class="jx hj"> λW^TW </strong>作为正则项。因此，在损失项和<em class="lv">调整项</em>之间本质上有一个权衡</p><h2 id="5b32" class="ix iy hi bd iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju bi translated"><strong class="ak">的意义λ: </strong></h2><p id="7e79" class="pw-post-body-paragraph jv jw hi jx b jy jz ij ka kb kc im kd ji ke kf kg jm kh ki kj jq kk kl km kn hb bi translated">λ在优化我们的功能方面起着关键作用。</p><ul class=""><li id="7d85" class="ma mb hi jx b jy le kb lf ji mq jm mr jq ms kn nk mg mh mi bi translated">如果我们显著降低λ的值，那么模型会过拟合，因为正则化项的影响变得可以忽略不计。</li><li id="9090" class="ma mb hi jx b jy mj kb mk ji ml jm mm jq mn kn nk mg mh mi bi translated">如果我们显著地增加λ的值，那么我们的模型会欠拟合，因为损失项变得可以忽略，并且正则化项不包含任何训练数据。</li></ul><h2 id="1af0" class="ix iy hi bd iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju bi translated">L1正规化:</h2><p id="14af" class="pw-post-body-paragraph jv jw hi jx b jy jz ij ka kb kc im kd ji ke kf kg jm kh ki kj jq kk kl km kn hb bi translated">L1正则化也起到了和L2一样的作用，即避免过度拟合，但不同于L2正则化</p><p id="3267" class="pw-post-body-paragraph jv jw hi jx b jy le ij ka kb lf im kd ji lg kf kg jm lh ki kj jq li kl km kn hb bi translated"><em class="lv">正则化术语</em> <strong class="jx hj"> : λ||W|| </strong></p><p id="41a7" class="pw-post-body-paragraph jv jw hi jx b jy le ij ka kb lf im kd ji lg kf kg jm lh ki kj jq li kl km kn hb bi translated">其中| | W | | = I = 1到n的所有W的绝对值之和</p><p id="a47c" class="pw-post-body-paragraph jv jw hi jx b jy le ij ka kb lf im kd ji lg kf kg jm lh ki kj jq li kl km kn hb bi translated">L1正则化的重要性在于特征减少，因为L1正则化创建了稀疏向量，因此对于特征fi，如果其不重要，则在L1正则化的情况下，其对应的权重将为0，而在L2正则化中，其将显著更小但不为0</p><p id="3916" class="pw-post-body-paragraph jv jw hi jx b jy le ij ka kb lf im kd ji lg kf kg jm lh ki kj jq li kl km kn hb bi translated"><strong class="jx hj">弹力网:</strong></p><p id="a6ac" class="pw-post-body-paragraph jv jw hi jx b jy le ij ka kb lf im kd ji lg kf kg jm lh ki kj jq li kl km kn hb bi translated">甚至还有一个被认为是世界上和这里最好的规则</p><p id="ffef" class="pw-post-body-paragraph jv jw hi jx b jy le ij ka kb lf im kd ji lg kf kg jm lh ki kj jq li kl km kn hb bi translated"><em class="lv">正则化术语:</em> <strong class="jx hj"> λW^TW + λ`||W|| </strong></p><p id="4275" class="pw-post-body-paragraph jv jw hi jx b jy le ij ka kb lf im kd ji lg kf kg jm lh ki kj jq li kl km kn hb bi translated">_____________________ _ _ _ _ _ _ _ _ _结束_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _</p><p id="78d7" class="pw-post-body-paragraph jv jw hi jx b jy le ij ka kb lf im kd ji lg kf kg jm lh ki kj jq li kl km kn hb bi translated">在<a class="ae lk" href="https://www.linkedin.com/in/v-shaal/" rel="noopener ugc nofollow" target="_blank"> LINKEDIN </a>上与我联系</p></div></div>    
</body>
</html>