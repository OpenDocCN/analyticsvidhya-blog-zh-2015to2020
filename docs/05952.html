<html>
<head>
<title>Using AI to Predict if a Paper will be in a Top-Tier Journal</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用人工智能预测一篇论文是否会出现在顶级期刊上</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/using-ai-to-predict-if-a-paper-will-be-in-a-top-tier-journal-27c7edccf32e?source=collection_archive---------30-----------------------#2020-05-06">https://medium.com/analytics-vidhya/using-ai-to-predict-if-a-paper-will-be-in-a-top-tier-journal-27c7edccf32e?source=collection_archive---------30-----------------------#2020-05-06</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/0d2123c4fa8e6430933c93085ff54d37.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zyEa0azVzIdn18eO2GZ4Hw.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">(图片来源:<a class="ae iu" href="https://software.intel.com/en-us/articles/deep-learning-for-natural-language-processing" rel="noopener ugc nofollow" target="_blank">英特尔</a>)</figcaption></figure><p id="34f3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">最近几个月，我一直在与斯坦福大学的<a class="ae iu" href="https://profiles.stanford.edu/sophiaywang" rel="noopener ugc nofollow" target="_blank">王思佳</a>博士合作，应用<a class="ae iu" href="https://en.wikipedia.org/wiki/Deep_learning" rel="noopener ugc nofollow" target="_blank">深度学习/人工智能</a>技术，利用医生在电子病历(EMR)中写的笔记进行预测。虽然这些方法背后的数学可能非常复杂，但像<a class="ae iu" href="https://www.tensorflow.org/" rel="noopener ugc nofollow" target="_blank"> Tensorflow </a>和<a class="ae iu" href="https://keras.io/" rel="noopener ugc nofollow" target="_blank"> Keras </a>这样的工具使得没有经过正式培训的人能够更广泛地应用它们。我想分享一些我学到的东西，以帮助那些想开始类似工作但在开始时有困难的人。</p><p id="9e57" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">对于本教程(<a class="ae iu" href="https://github.com/BenjaminTseng/ophthalmology-pubmed-predict/" rel="noopener ugc nofollow" target="_blank">Github</a>上可用的所有代码)，我们将编写一个简单的算法来预测一篇论文，仅基于其摘要和标题，是否是发表在<a class="ae iu" href="https://scholar.google.com/citations?view_op=top_venues&amp;hl=en&amp;vq=med_ophthalmologyoptometry" rel="noopener ugc nofollow" target="_blank">眼科领域前15名期刊之一的论文</a>(根据2014-2018年的<a class="ae iu" href="https://en.wikipedia.org/wiki/H-index" rel="noopener ugc nofollow" target="_blank"> h-index </a>进行衡量)。它将在一个数据集上进行训练和测试，该数据集包括2010年至2019年发表的所有英文眼科相关文章，以及Pubmed (由NIH运营的免费搜索引擎，几乎涵盖所有生命科学相关论文)中的摘要。它还将包含我在多个项目中使用过的一些功能，但这些功能似乎是在线良好教程中所缺乏的，例如使用带有<code class="du jt ju jv jw b">tf.keras</code>和<code class="du jt ju jv jw b">tf.data</code>的多个输入模型，在多个输入序列上使用相同的嵌入层，以及使用带有<code class="du jt ju jv jw b">tf.data</code>的填充批处理来合并序列数据。这篇文章还假设您了解Python 3(和Numpy)的基础知识，并且已经安装了<a class="ae iu" href="https://www.tensorflow.org/install" rel="noopener ugc nofollow" target="_blank"> Tensorflow 2 </a>(有GPU支持)、BeautifulSoup、lxml和Tensorflow数据集。</p></div><div class="ab cl jx jy gp jz" role="separator"><span class="ka bw bk kb kc kd"/><span class="ka bw bk kb kc kd"/><span class="ka bw bk kb kc"/></div><div class="hb hc hd he hf"><h1 id="c425" class="ke kf hi bd kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb bi translated">从Pubmed获取数据</h1><p id="668e" class="pw-post-body-paragraph iv iw hi ix b iy lc ja jb jc ld je jf jg le ji jj jk lf jm jn jo lg jq jr js hb bi translated">要训练这样的算法，我们需要大量的数据。令人欣慰的是，Pubmed使得建立一个相当完整的生命科学相关语言内容的数据集变得很容易。使用国家医学图书馆的MeSH浏览器，它维护了一个显示不同生命科学主题如何相关的“知识树”，我找到了涵盖眼科文献的四个网格术语:“<a class="ae iu" href="https://meshb-prev.nlm.nih.gov/record/ui?ui=D005128" rel="noopener ugc nofollow" target="_blank">眼病</a>”、“<a class="ae iu" href="https://meshb-prev.nlm.nih.gov/record/ui?ui=D009885" rel="noopener ugc nofollow" target="_blank">眼科</a>”、“<a class="ae iu" href="https://meshb-prev.nlm.nih.gov/record/ui?ui=D009799" rel="noopener ugc nofollow" target="_blank">眼部生理现象</a>”和“<a class="ae iu" href="https://meshb-prev.nlm.nih.gov/record/ui?ui=D013508" rel="noopener ugc nofollow" target="_blank">眼科手术过程</a>”。这些可以输入到Pubmed高级搜索界面，左侧的搜索过滤器可以用于缩小相关标准(英语，人类物种，2010年1月至2019年12月出版，有摘要文本，以及期刊文章或综述论文):</p><figure class="li lj lk ll fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lh"><img src="../Images/afd62b73f969b5e534bfd193ce5bbf5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YbO7citCOXsVOvnuPig4_w.png"/></div></div></figure><p id="f6a5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们可以使用右上方的“发送到”按钮下载138，425个摘要(以及相关的元数据)作为一个巨大的XML文件(见下面的截图)。生成的文件大约有1.9 GB(所以请给它一些时间)</p><figure class="li lj lk ll fd ij er es paragraph-image"><div class="er es lm"><img src="../Images/79c1ea0d628bb8fdf370efbba77c72e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:762/format:webp/1*krQKlct3uAqQXrt6lsQQGA.png"/></div></figure><p id="5dc9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">一个1.9 GB的XML文件很难处理，不适合在模型中使用，所以我们应该首先预处理数据，以创建较小的文本文件，这些文件只包含训练和测试模型所需的信息。下面的Python脚本逐个读取XML文件的每一行，每次看到新条目的开头时，它都会使用<a class="ae iu" href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/" rel="noopener ugc nofollow" target="_blank"> BeautifulSoup </a>(以及它所依赖的<a class="ae iu" href="https://lxml.de/index.html" rel="noopener ugc nofollow" target="_blank"> lxml解析器</a>)解析前一个条目，并提取摘要、标题和日志名称，以及为模型构建一个单词(词汇)列表。</p><p id="5170" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><a class="ae iu" href="https://www.nlm.nih.gov/bsd/licensee/elements_descriptions.html" rel="noopener ugc nofollow" target="_blank">Pubmed</a>使用的XML格式比较基础(文章元数据包装在<code class="du jt ju jv jw b">&lt;PubmedArticle&gt;</code>标签中，标题包装在<code class="du jt ju jv jw b">&lt;ArticleTitle&gt;</code>标签中，期刊名缩写在<code class="du jt ju jv jw b">&lt;MedlineTA&gt;</code>标签中等等。).然而，摘要并不总是以完全相同的方式存储(有时在<code class="du jt ju jv jw b">&lt;Abstract&gt;</code>标签中，有时在<code class="du jt ju jv jw b">&lt;OtherAbstract&gt;</code>标签中，有时在多个<code class="du jt ju jv jw b">&lt;AbstractText&gt;</code>标签之间划分)，所以大部分代码被设计成处理那些不同的情况:</p><figure class="li lj lk ll fd ij"><div class="bz dy l di"><div class="ln lo l"/></div></figure><p id="132d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在解析XML之后，语料库中出现至少25次(<code class="du jt ju jv jw b">smallestfreq</code>)的每个单词都被存储在词汇表中(稍后将使用该词汇表将单词转换为机器学习算法可以使用的数字)，并且存储的摘要、标题和期刊名称在被写入(每行一个)不同的文本文件之前被混洗。</p><figure class="li lj lk ll fd ij"><div class="bz dy l di"><div class="ln lo l"/></div></figure><p id="e809" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">查看生成的文件，很明显，谷歌学术确定为眼科前15名的期刊是数据集中多产的期刊(占条目最多的10种期刊中的8种)。特别值得注意的是，数据集中约21%的文章发表在排名前15的期刊中:</p><figure class="li lj lk ll fd ij er es paragraph-image"><div class="er es lp"><img src="../Images/484d768f70f8d4e28dd018fc93e58751.png" data-original-src="https://miro.medium.com/v2/resize:fit:1272/format:webp/1*N9yFAFPUZCnSx_6gb3iz3w.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">Pubmed查询中10个最多产的期刊和来自<a class="ae iu" href="https://scholar.google.com/citations?view_op=top_venues&amp;hl=en&amp;vq=med_ophthalmologyoptometry" rel="noopener ugc nofollow" target="_blank">前15名(按H-index)眼科期刊的文章总数百分比</a></figcaption></figure></div><div class="ab cl jx jy gp jz" role="separator"><span class="ka bw bk kb kc kd"/><span class="ka bw bk kb kc kd"/><span class="ka bw bk kb kc"/></div><div class="hb hc hd he hf"><h1 id="5bcd" class="ke kf hi bd kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb bi translated">使用Tensorflow和Keras建立模型</h1><p id="8d30" class="pw-post-body-paragraph iv iw hi ix b iy lc ja jb jc ld je jf jg le ji jj jk lf jm jn jo lg jq jr js hb bi translated">将一个简单的深度学习想法翻译成代码可能是一场噩梦，需要完成所有的矩阵运算。幸运的是，AI社区已经开发了像<a class="ae iu" href="https://www.tensorflow.org/" rel="noopener ugc nofollow" target="_blank"> Tensorflow </a>和<a class="ae iu" href="https://keras.io/" rel="noopener ugc nofollow" target="_blank"> Keras </a>这样的工具来使这变得更加容易(现在加倍如此，因为<a class="ae iu" href="https://www.tensorflow.org/guide/keras/overview" rel="noopener ugc nofollow" target="_blank"> Tensorflow已经选择在<code class="du jt ju jv jw b">tf.keras</code>中采用Keras作为其主要API </a>)。现在，没有经过正式培训的程序员(更不用说什么是矩阵运算或它如何工作的知识了)可以将深度学习方法应用于一系列问题。虽然文档的质量并不总是很好，但丰富的在线课程和教程(我个人推荐<a class="ae iu" href="https://www.deeplearning.ai/deep-learning-specialization/" rel="noopener ugc nofollow" target="_blank"> DeepLearning.ai的Coursera specialization </a>)让愿意“动手”的自学者可以接触到这些方法。</p><p id="6ab0" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">因此，虽然我们可以关注我们将使用的模型架构如何工作的所有数学细节，但事实是没有必要的。我们需要关注的是模型的主要组件是什么以及它们的作用:</p><figure class="li lj lk ll fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lh"><img src="../Images/ad1b97430ac9a800a1c1b25cf9ba6eb4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q-fwKQB0TdGzDjx5Nq97ZQ.png"/></div></div></figure><ol class=""><li id="5dfd" class="lq lr hi ix b iy iz jc jd jg ls jk lt jo lu js lv lw lx ly bi translated">该模型使用<a class="ae iu" href="https://keras.io/layers/embeddings/" rel="noopener ugc nofollow" target="_blank"> Keras嵌入层</a>将<em class="lz">标题</em>中的单词转换成称为<a class="ae iu" href="https://en.wikipedia.org/wiki/Word_embedding" rel="noopener ugc nofollow" target="_blank">单词嵌入</a>的数字向量。这提供了数学模型可以理解的数字输入。</li><li id="a280" class="lq lr hi ix b iy ma jc mb jg mc jk md jo me js lv lw lx ly bi translated">然后，基于<a class="ae iu" href="https://en.wikipedia.org/wiki/Gated_recurrent_unit" rel="noopener ugc nofollow" target="_blank">门控递归单元</a>(通过使用<a class="ae iu" href="https://keras.io/layers/wrappers/" rel="noopener ugc nofollow" target="_blank">Keras双向层包装器</a>和<a class="ae iu" href="https://keras.io/layers/recurrent/" rel="noopener ugc nofollow" target="_blank">Keras GRU层</a>的组合来实现)，将表示摘要的单词嵌入序列馈送到<a class="ae iu" href="https://en.wikipedia.org/wiki/Bidirectional_recurrent_neural_networks" rel="noopener ugc nofollow" target="_blank">双向递归神经网络</a>。这是一个深度学习架构，众所周知，它擅长理解事物的序列，这在语言任务中是有价值的(其中你需要区分“狗坐在椅子上”和“椅子坐在狗上”，即使它们使用相同的单词)。</li><li id="6ca3" class="lq lr hi ix b iy ma jc mb jg mc jk md jo me js lv lw lx ly bi translated">双向GRU层输出一个数字向量(实际上是两个连接在一起的数字，但这是在幕后完成的)，然后通过一个<a class="ae iu" href="https://keras.io/layers/core/" rel="noopener ugc nofollow" target="_blank">丢弃层</a>进行馈送，以帮助减少<a class="ae iu" href="https://en.wikipedia.org/wiki/Overfitting" rel="noopener ugc nofollow" target="_blank">过拟合</a>(算法学习“记忆”它看到的数据，而不是关系)。</li><li id="b4d4" class="lq lr hi ix b iy ma jc mb jg mc jk md jo me js lv lw lx ly bi translated">然后，步骤3的结果通过单层<a class="ae iu" href="https://en.wikipedia.org/wiki/Feedforward_neural_network" rel="noopener ugc nofollow" target="_blank">前馈神经网络</a>(使用<a class="ae iu" href="https://keras.io/layers/core/" rel="noopener ugc nofollow" target="_blank">Keras密集层</a>)反馈，产生另一个向量，该向量可以被认为是“算法对标题的理解”</li><li id="4b1b" class="lq lr hi ix b iy ma jc mb jg mc jk md jo me js lv lw lx ly bi translated">对<em class="lz">摘要</em>中的单词重复步骤1–4(使用与步骤1相同的嵌入层)</li><li id="92c1" class="lq lr hi ix b iy ma jc mb jg mc jk md jo me js lv lw lx ly bi translated">将摘要(步骤4)和标题(步骤5)的输出结合起来，将两个向量粘在一起，形成一个更大的向量，然后通过一个2层前馈神经网络运行这种结合(该网络将“结合”算法对摘要和标题的“理解”)，并插入一个脱落层(以防止过度拟合)。</li><li id="07b0" class="lq lr hi ix b iy ma jc mb jg mc jk md jo me js lv lw lx ly bi translated">最后一层应该使用<a class="ae iu" href="https://en.wikipedia.org/wiki/Sigmoid_function" rel="noopener ugc nofollow" target="_blank"> sigmoid激活</a>输出一个数字，因为模型正在尝试学习预测二进制结果(这篇论文是否在顶级期刊上[1]或[0])</li></ol><p id="e4b1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">上面的描述跳过了许多数学细节(例如，GRU如何工作，下降如何防止过拟合，前馈神经网络中的数学情况)，其他教程和论文以更长的篇幅涵盖了这些细节。它还略述了一些关键的实现细节(什么大小的字嵌入，我们应该在前向神经网络中使用什么样的激活函数，什么样的随机变量初始化，要实现什么样的丢失量)。</p><p id="7b87" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">但是有了像<code class="du jt ju jv jw b">tf.keras</code>这样的高级框架，这些细节就变成了配置变量，你要么接受建议的缺省值(就像我们对随机变量初始化和偏差使用所做的那样)，要么试验值/遵循惯例来找到工作良好的东西(就像我们对嵌入维度、丢失量和激活函数所做的那样)。概述模型的代码相对简单(如果去掉注释和多余的空格，只有22行)就说明了这一点:</p><figure class="li lj lk ll fd ij"><div class="bz dy l di"><div class="ln lo l"/></div></figure></div><div class="ab cl jx jy gp jz" role="separator"><span class="ka bw bk kb kc kd"/><span class="ka bw bk kb kc kd"/><span class="ka bw bk kb kc"/></div><div class="hb hc hd he hf"><h1 id="4c51" class="ke kf hi bd kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb bi translated">使用<code class="du jt ju jv jw b">tf.data</code>构建数据管道</h1><p id="34be" class="pw-post-body-paragraph iv iw hi ix b iy lc ja jb jc ld je jf jg le ji jj jk lf jm jn jo lg jq jr js hb bi translated">现在我们有了一个模型，如何将之前从Pubmed解析的数据输入其中呢？为了处理人工智能研究人员在处理数据时经常遇到的一些复杂问题，Tensorflow发布了<code class="du jt ju jv jw b">tf.data</code>、<a class="ae iu" href="https://www.tensorflow.org/guide/data" rel="noopener ugc nofollow" target="_blank">一个用于构建数据管道的框架</a>，以处理太大而不适合内存和/或需要进行大量预处理工作的数据集。</p><p id="07d0" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们首先创建两个函数</p><ol class=""><li id="148a" class="lq lr hi ix b iy iz jc jd jg ls jk lt jo lu js lv lw lx ly bi translated"><code class="du jt ju jv jw b">encode_journal</code>它将期刊名称作为输入，如果是顶级眼科期刊，则返回1，如果不是，则返回0(通过与正确的期刊名称列表进行简单比较)</li><li id="4fc6" class="lq lr hi ix b iy ma jc mb jg mc jk md jo me js lv lw lx ly bi translated"><code class="du jt ju jv jw b">encode_text</code>它将给定期刊文章的标题和摘要作为输入，并将它们转换成算法可以处理的数字列表。它通过使用<a class="ae iu" href="https://www.tensorflow.org/datasets/api_docs/python/tfds/features/text/TokenTextEncoder" rel="noopener ugc nofollow" target="_blank">tensor flow数据集库</a>提供的<code class="du jt ju jv jw b">TokenTextEncoder</code>函数来实现这一点，该函数将我们最初解析Pubmed XML时创建的词汇表作为输入</li></ol><p id="966f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这些方法将在我们的数据管道中使用，以将输入转换成模型可用的东西(顺便说一句:这就是为什么您会在<code class="du jt ju jv jw b">encode_text</code>中看到<code class="du jt ju jv jw b">.numpy()</code>——它用于将<code class="du jt ju jv jw b">tf.data</code>将传递给它们的张量对象转换成模型可用的东西)</p><figure class="li lj lk ll fd ij"><div class="bz dy l di"><div class="ln lo l"/></div></figure><p id="d102" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">由于Tensorflow的运行方式，<code class="du jt ju jv jw b">encode_text</code>和<code class="du jt ju jv jw b">encode_journal</code>需要包装在<code class="du jt ju jv jw b">tf.py_function</code>调用中(这允许您在Tensorflow图上运行“普通”Python代码)，这就是<code class="du jt ju jv jw b">encode_text_map_fn</code>和<code class="du jt ju jv jw b">encode_journal_map_fn</code>(参见下面的代码片段)的用武之地。</p><p id="b5ed" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">最后，为了完善数据管道，我们:</p><ol class=""><li id="91d0" class="lq lr hi ix b iy iz jc jd jg ls jk lt jo lu js lv lw lx ly bi translated">使用<code class="du jt ju jv jw b">tf.data.TextLineDataset</code>摄取解析后的标题、摘要和期刊名称所在的文本文件</li><li id="7d80" class="lq lr hi ix b iy ma jc mb jg mc jk md jo me js lv lw lx ly bi translated">使用<code class="du jt ju jv jw b">tf.data.Dataset.zip</code>方法将标题和抽象数据集合并成一个输入数据集(<code class="du jt ju jv jw b">input_dataset</code>)。</li><li id="e7e9" class="lq lr hi ix b iy ma jc mb jg mc jk md jo me js lv lw lx ly bi translated">使用<code class="du jt ju jv jw b">input_dataset</code>的<code class="du jt ju jv jw b">map</code>方法来应用<code class="du jt ju jv jw b">encode_text_map_fn</code>，以便模型将输入作为数字列表使用</li><li id="66f4" class="lq lr hi ix b iy ma jc mb jg mc jk md jo me js lv lw lx ly bi translated">获取日志名称数据集(<code class="du jt ju jv jw b">journal_dataset</code>)并应用其<code class="du jt ju jv jw b">map</code>方法来应用<code class="du jt ju jv jw b">encode_journal_map_fn</code>，以便模型根据日志是否是前15名之一来使用输入1或0</li><li id="a0a6" class="lq lr hi ix b iy ma jc mb jg mc jk md jo me js lv lw lx ly bi translated">使用<code class="du jt ju jv jw b">tf.data.Dataset.zip</code>方法将输入(<code class="du jt ju jv jw b">input_dataset</code>)和输出(<code class="du jt ju jv jw b">journal_dataset</code>)合并到我们的模型可以使用的单个数据集中</li></ol><figure class="li lj lk ll fd ij"><div class="bz dy l di"><div class="ln lo l"/></div></figure><p id="910a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为了帮助模型一般化，将数据分成四组是一个很好的做法，以避免对已经看到的数据进行算法训练或评估(即，为什么一个好老师会进行与作业相关但不相同的测试)，主要是:</p><ol class=""><li id="b23b" class="lq lr hi ix b iy iz jc jd jg ls jk lt jo lu js lv lw lx ly bi translated"><strong class="ix hj">训练集</strong>是我们的算法将学习的数据(因此，应该是四个中最大的)。</li><li id="a012" class="lq lr hi ix b iy ma jc mb jg mc jk md jo me js lv lw lx ly bi translated">(我还没有看到一个一致的名称，但我创建了一个<strong class="ix hj"> stoptrain set </strong>,用于在每个时期(训练集的完整运行)后检查训练过程，以便在结果模型开始过度拟合训练集时停止训练。</li><li id="6f12" class="lq lr hi ix b iy ma jc mb jg mc jk md jo me js lv lw lx ly bi translated"><strong class="ix hj">验证集</strong>是我们用来比较不同模型架构和配置在完成培训后表现如何的数据。</li><li id="9a8e" class="lq lr hi ix b iy ma jc mb jg mc jk md jo me js lv lw lx ly bi translated"><strong class="ix hj">保持集或测试集</strong>是我们将用来衡量我们的最终算法如何执行的。它被称为保留集，因为它直到最后才被使用，以使它成为真正公平的基准。</li></ol><p id="2d8f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><code class="du jt ju jv jw b">tf.data</code>使这一步变得非常简单(使用<code class="du jt ju jv jw b">skip</code> —跳过输入条目——和<code class="du jt ju jv jw b">take</code>,顾名思义，获取给定数量的条目)。最后，<code class="du jt ju jv jw b">tf.data</code>还提供类似于<code class="du jt ju jv jw b">padded_batch</code>的批处理方法，以在算法将连续训练的100篇文章的批次之间标准化输入的长度(由于不同的摘要和标题将具有不同的长度，我们将截断或填充每个标题分别为72个单词和200个单词长):</p><figure class="li lj lk ll fd ij"><div class="bz dy l di"><div class="ln lo l"/></div></figure></div><div class="ab cl jx jy gp jz" role="separator"><span class="ka bw bk kb kc kd"/><span class="ka bw bk kb kc kd"/><span class="ka bw bk kb kc"/></div><div class="hb hc hd he hf"><h1 id="19a5" class="ke kf hi bd kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb bi translated">训练和测试模型</h1><p id="b5f0" class="pw-post-body-paragraph iv iw hi ix b iy lc ja jb jc ld je jf jg le ji jj jk lf jm jn jo lg jq jr js hb bi translated">现在我们已经有了模型和数据管道，培训和评估实际上相对简单，包括指定要跟踪的指标以及培训应该如何进行的细节:</p><ul class=""><li id="b111" class="lq lr hi ix b iy iz jc jd jg ls jk lt jo lu js mf lw lx ly bi translated">因为目标是衡量模型有多好，所以在算法训练时，我要求模型报告四个方面的情况:<code class="du jt ju jv jw b">metrics</code> ( <a class="ae iu" href="https://en.wikipedia.org/wiki/Sensitivity_and_specificity" rel="noopener ugc nofollow" target="_blank">敏感度/召回率</a>[你正确获得前15名期刊文章的比例】、精确度【你预测的前15名期刊文章的比例实际上是正确的】、准确度【模型获得正确答案的频率】和<a class="ae iu" href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve" rel="noopener ugc nofollow" target="_blank"> AUROC </a>(衡量你的模型在敏感度和精确度之间权衡的程度)</li><li id="2945" class="lq lr hi ix b iy ma jc mb jg mc jk md jo me js mf lw lx ly bi translated">训练将使用应用于<a class="ae iu" href="https://en.wikipedia.org/wiki/Cross_entropy" rel="noopener ugc nofollow" target="_blank">二元交叉熵</a>损失函数的<a class="ae iu" href="https://arxiv.org/abs/1412.6980" rel="noopener ugc nofollow" target="_blank"> Adam优化器</a>(一种流行、高效的训练方法)(这在算法进行是/否二元预测时是有意义的)。</li><li id="e3d0" class="lq lr hi ix b iy ma jc mb jg mc jk md jo me js mf lw lx ly bi translated">一旦stoptrain组显示出过度拟合的迹象，该模型也被设置为停止训练(使用<code class="du jt ju jv jw b">callbacks</code>中的<code class="du jt ju jv jw b">tf.keras.callbacks.EarlyStopping</code>)</li><li id="727c" class="lq lr hi ix b iy ma jc mb jg mc jk md jo me js mf lw lx ly bi translated">训练集(<code class="du jt ju jv jw b">train_dataset</code>)、最大历元数(通过训练集的完整迭代)和停止训练集(<code class="du jt ju jv jw b">stoptrain_dataset</code>)被传递到<code class="du jt ju jv jw b">model.fit</code>以开始训练</li><li id="8450" class="lq lr hi ix b iy ma jc mb jg mc jk md jo me js mf lw lx ly bi translated">训练后，可以使用<code class="du jt ju jv jw b">model.evaluate</code>在验证集(<code class="du jt ju jv jw b">validation_dataset</code>)上评估模型:</li></ul><figure class="li lj lk ll fd ij"><div class="bz dy l di"><div class="ln lo l"/></div></figure><p id="3012" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在对模型架构和参数进行多次迭代以找到一个好的工作模型之后，最终可以在维持集(<code class="du jt ju jv jw b">test_dataset</code>)上对模型进行评估，以查看它将如何执行:<code class="du jt ju jv jw b">model.evaluate(test_dataset)</code></p></div><div class="ab cl jx jy gp jz" role="separator"><span class="ka bw bk kb kc kd"/><span class="ka bw bk kb kc kd"/><span class="ka bw bk kb kc"/></div><div class="hb hc hd he hf"><h1 id="fabb" class="ke kf hi bd kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb bi translated">结果</h1><p id="962c" class="pw-post-body-paragraph iv iw hi ix b iy lc ja jb jc ld je jf jg le ji jj jk lf jm jn jo lg jq jr js hb bi translated">您的结果将根据数据的确切顺序、算法开始训练时使用的初始随机变量以及许多其他因素而有所不同，但当我运行它时，训练通常在2-3个时期内完成，性能类似于下表:</p><figure class="li lj lk ll fd ij er es paragraph-image"><div class="er es mg"><img src="../Images/f3094adc67983bd97e3463386c01a954.png" data-original-src="https://miro.medium.com/v2/resize:fit:1270/format:webp/1*YUor7ke7R6CXKElIWHdD6A.png"/></div></figure><p id="c86e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">评估该模型的另一种方法是显示其<a class="ae iu" href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic" rel="noopener ugc nofollow" target="_blank"> ROC(接收器工作特性)曲线</a>，AUROC(ROC曲线下面积)数的基础，以及该模型在真阳性(y轴上)和假阳性(x轴上)与纯粹随机猜测(蓝色对红色)之间进行权衡的可视化表示。在91% AUROC(最大值:100%，最小值:50%)时，该模型优于许多常见的风险分值，更不用说随机猜测了:</p><figure class="li lj lk ll fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mh"><img src="../Images/f8603c8e597ce68ad7116fbd7414a2b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hrJkfUGeoYRC25j4WmHrMw.png"/></div></div></figure><p id="8306" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">有趣的是，尽管该模型的性能很强(AUROC和point对灵敏度、精确度和准确度的估计)，但当我分享一组得分很高和得分很低的摘要和标题时，我或我调查的一小部分人类科学家样本并不立即清楚该算法在寻找什么。这是许多人工智能方法的怪癖和缺点之一——它们的“黑箱”性质——后续分析可能会揭示更多。</p><p id="94f1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="lz">特别感谢王思佳</em> <em class="lz">和安东尼·潘</em> <em class="lz">审阅摘要和阅读早期版本！</em></p><p id="56b9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">(本文原载<a class="ae iu" href="https://benjamintseng.com/portfolio/nlp-pubmed-data-using-tensorflow-and-keras/" rel="noopener ugc nofollow" target="_blank">此处</a>)</p><p id="6a52" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><a class="ae iu" href="https://github.com/BenjaminTseng/ophthalmology-pubmed-predict/" rel="noopener ugc nofollow" target="_blank">链接到包含所有代码的GitHub页面</a></p></div></div>    
</body>
</html>