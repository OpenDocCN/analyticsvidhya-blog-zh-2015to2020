<html>
<head>
<title>How I built a powerful object detector in under 100 lines of code.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">我如何用不到100行代码构建了一个强大的对象检测器。</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/how-i-built-a-powerful-object-detector-in-under-100-lines-of-code-ec8c2dcdd1e0?source=collection_archive---------12-----------------------#2020-02-17">https://medium.com/analytics-vidhya/how-i-built-a-powerful-object-detector-in-under-100-lines-of-code-ec8c2dcdd1e0?source=collection_archive---------12-----------------------#2020-02-17</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/219007284acdc1625b866f6207d754a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*97Er3UJjrb0JzSzc63h8MA.png"/></div></div></figure><p id="a54c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">目标检测一直是计算机科学领域最热门的话题之一。自从<a class="ae jo" href="https://en.wikipedia.org/wiki/AlexNet" rel="noopener ugc nofollow" target="_blank"> AlexNet </a>在<a class="ae jo" href="https://en.wikipedia.org/wiki/ImageNet#ImageNet_Challenge" rel="noopener ugc nofollow" target="_blank"> ImageNet大规模视觉识别挑战</a>中大获全胜，取得15.3%的前五名误差，比亚军低10.8个百分点以上以来，卷积神经网络和深度学习在各种计算机视觉任务中的使用一直在增加。已经提出了各种不同的架构，并且已经采用了各种不同的方法。R-CNN模型族、固态硬盘、YOLO等是目前使用最多的目标检测架构。</p><p id="1746" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">目标检测框架主要可以分为两部分:单镜头检测器和多镜头检测器。像YOLO或SSD这样的单触发检测架构提供了更好的推断速度，而多触发检测器比单触发检测器具有更高的准确性。然而，一些新的单镜头检测架构(如FAIR的RetinaNet)声称与更快的RCNN等双镜头检测器一样好。</p><p id="fcad" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">目标检测是世界范围内最广泛的研究课题之一，用于此目的的算法只会与日俱增。今天，我们将学习如何使用预训练的YOLO模型来创建我们自己的通用对象检测器。</p><p id="412b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">YOLOv3已经在上下文中的公共对象(COCO)数据集上接受了训练，并且能够识别80种不同类别的对象。</p><p id="1128" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">对于那些想详细了解YOLOv3架构的人，这里有一个YOLOv3原文的链接。</p><blockquote class="jp jq jr"><p id="d19f" class="iq ir js is b it iu iv iw ix iy iz ja jt jc jd je ju jg jh ji jv jk jl jm jn hb bi translated">【https://pjreddie.com/media/files/papers/YOLOv3.pdf T4】</p></blockquote><p id="2c6a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这里，我们将使用opencv的dnn模块推理在预训练的YOLOv3模型上创建我们自己的对象检测器。</p><p id="f9a1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在我们开始之前，前往<a class="ae jo" href="https://pjreddie.com/darknet/yolo/" rel="noopener ugc nofollow" target="_blank">https://pjreddie.com/darknet/yolo/</a><br/>下载预训练的重量和配置文件。七个不同版本的YOLO模型被放在网站上，每一个都有自己的优点和缺点。选择你喜欢使用的任何一个。出于我的目的，我使用的是YOLOv3-spp，地图为60.6(可以说是站点中托管的最好的YOLOv3模型)。</p><p id="264c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">然后前往https://drive.google.com/open?id = 1 adjbud 0 pn-n1 gdrx-QQD-4g ygr x05 GW 2下载coco.names文件，同样放在项目目录下。该文件包含YOLOv3能够对其执行检测的类名。</p><p id="00aa" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">既然YOLOv3-spp.weights、YOLOv3-spp.cfg和coco.names已经在项目目录中，现在是时候进行一些简短而有效的编码了。</p><h1 id="298f" class="jw jx hi bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">导入库</h1><p id="ae1c" class="pw-post-body-paragraph iq ir hi is b it ku iv iw ix kv iz ja jb kw jd je jf kx jh ji jj ky jl jm jn hb bi translated">我们将使用OpenCV库来执行图像处理，并使用非常高效的Numpy来执行数组操作。我们将使用argparse库来解析命令行参数。</p><blockquote class="kz"><p id="721e" class="la lb hi bd lc ld le lf lg lh li jn dx translated"><em class="lj">import cv2<br/>import numpy as NP<br/>import arperse</em></p></blockquote><h1 id="0fa1" class="jw jx hi bd jy jz ka kb kc kd ke kf kg kh lk kj kk kl ll kn ko kp lm kr ks kt bi translated">加载图像类</h1><p id="d6e1" class="pw-post-body-paragraph iq ir hi is b it ku iv iw ix kv iz ja jb kw jd je jf kx jh ji jj ky jl jm jn hb bi translated">然后我们将定义一个短函数来加载coco.names文件中的不同类。</p><figure class="ln lo lp lq fd ij"><div class="bz dy l di"><div class="lr ls l"/></div></figure><h1 id="d650" class="jw jx hi bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">奇迹发生的地方</h1><p id="ace9" class="pw-post-body-paragraph iq ir hi is b it ku iv iw ix kv iz ja jb kw jd je jf kx jh ji jj ky jl jm jn hb bi translated">我们现在锁定并加载了辅助函数load_classes。让我们编写驱动对象检测过程的主运行函数。</p><p id="5528" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">首先，我们将使用OpenCV的dnn模块，通过权重和我们之前下载的cfg文件来读取暗网架构。</p><blockquote class="kz"><p id="4b1b" class="la lb hi bd lc ld le lf lg lh li jn dx translated">net = cv2 . dnn . readnet(opt . weights，opt.cfg)</p></blockquote><p id="8758" class="pw-post-body-paragraph iq ir hi is b it lt iv iw ix lu iz ja jb lv jd je jf lw jh ji jj lx jl jm jn hb bi translated">opt是我们的参数解析器对象，我们将在后面讨论。</p><p id="e6a5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">然后我们将使用我们的帮助函数load_classes获得类名。它采用*的路径。将文件命名为它的唯一参数，也将通过命令行提供。</p><blockquote class="kz"><p id="1653" class="la lb hi bd lc ld le lf lg lh li jn dx translated">classes = load_classes(可选名称)</p></blockquote><p id="a617" class="pw-post-body-paragraph iq ir hi is b it lt iv iw ix lu iz ja jb lv jd je jf lw jh ji jj lx jl jm jn hb bi translated">现在，我们将从预定义的暗网架构中检索输出层名称。</p><blockquote class="kz"><p id="259a" class="la lb hi bd lc ld le lf lg lh li jn dx translated">layer_names = net.getLayerNames()</p><p id="bcb1" class="la lb hi bd lc ld le lf lg lh li jn dx translated">output layers =[layer _ names[I[0]-1]for I in net . getunconnectedoutlayers()]</p></blockquote><p id="f405" class="pw-post-body-paragraph iq ir hi is b it lt iv iw ix lu iz ja jb lv jd je jf lw jh ji jj lx jl jm jn hb bi translated">我们还将定义颜色和字体，稍后我们将在输入图像中写入这些内容。</p><blockquote class="kz"><p id="540c" class="la lb hi bd lc ld le lf lg lh li jn dx translated">colors = np.random.uniform(0，255，size = len(classes)，3)) <br/> font = cv2。字体_好时_单纯形</p></blockquote><p id="6975" class="pw-post-body-paragraph iq ir hi is b it lt iv iw ix lu iz ja jb lv jd je jf lw jh ji jj lx jl jm jn hb bi translated">现在该初始化VideoCapture对象了。它将用于从一个流中捕获视频。我将使用来自网络摄像头的视频流，随意使用任何视频通过其各自的路径。有关如何将各种视频流作为输入的更多信息，请参见V <a class="ae jo" href="https://docs.opencv.org/2.4/modules/highgui/doc/reading_and_writing_images_and_video.html" rel="noopener ugc nofollow" target="_blank"> ideoCapture </a>文档。</p><blockquote class="kz"><p id="24f6" class="la lb hi bd lc ld le lf lg lh li jn dx translated">cap = cv2。视频捕获(0)</p></blockquote><p id="771e" class="pw-post-body-paragraph iq ir hi is b it lt iv iw ix lu iz ja jb lv jd je jf lw jh ji jj lx jl jm jn hb bi translated">现在我们将启动一个while循环。循环的每一次迭代将获取一帧，对其执行检测，并将其显示在输出屏幕上。</p><p id="a780" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">首先，我们将从VideoCapture对象中读取一帧，从中生成blobs，然后将其传递给darknet架构。</p><blockquote class="kz"><p id="6296" class="la lb hi bd lc ld le lf lg lh li jn dx translated">_，frame = cap.read() <br/>高度，宽度，通道= frame.shape</p><p id="7ee0" class="la lb hi bd lc ld le lf lg lh li jn dx translated">blob = cv2 . dnn . blobfromimage(frame，0.00392，(320，320)，(0，0，0)，True，crop=False)</p><p id="641e" class="la lb hi bd lc ld le lf lg lh li jn dx translated">net . set input(blob)<br/>outs = net . forward(output layers)</p></blockquote><p id="d254" class="pw-post-body-paragraph iq ir hi is b it lt iv iw ix lu iz ja jb lv jd je jf lw jh ji jj lx jl jm jn hb bi translated">现在，我们将得到在斑点中检测目标的算法的置信度得分。然后使用给定对象斑点的最高置信度生成class_id。其被附加到列表中。为此，我们将启动三个不同的列表，class _ ids、confidences和box，每一个都包含顾名思义的信息。</p><figure class="ln lo lp lq fd ij"><div class="bz dy l di"><div class="lr ls l"/></div></figure><p id="a9fe" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">然后，我们将执行非最大值抑制，以过滤掉同一对象的多个检测。这可以使用dnn库的NMSBoxes函数来完成。</p><blockquote class="jp jq jr"><p id="7a23" class="iq ir js is b it iu iv iw ix iy iz ja jt jc jd je ju jg jh ji jv jk jl jm jn hb bi translated">indexes = cv2 . dnn . NMS box(盒子，置信度，0.4，0.6)</p></blockquote><p id="bf0b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在是时候获取所有检测到的对象，在它们周围绘制适当的边界框和置信度值，在边界框上绘制类别标签，然后将后续帧写入输出屏幕。</p><figure class="ln lo lp lq fd ij"><div class="bz dy l di"><div class="lr ls l"/></div></figure><h1 id="618a" class="jw jx hi bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">参数分析器</h1><p id="cf6f" class="pw-post-body-paragraph iq ir hi is b it ku iv iw ix kv iz ja jb kw jd je jf kx jh ji jj ky jl jm jn hb bi translated">我们的目标检测算法已经准备好了。现在，我们只需要定义参数解析器来接受命令行输入，并使用权重文件、cfg文件和*的适当路径调用检测算法。名字文件，我们就可以上路了。</p><blockquote class="kz"><p id="5a34" class="la lb hi bd lc ld le lf lg lh li jn dx translated">parser = argparse。argument parser()<br/>parser . add _ argument('—weights '，type = str，default = '。/yolov3-spp.weights '，help = '权重文件的路径')</p><p id="2abe" class="la lb hi bd lc ld le lf lg lh li jn dx translated">parser.add_argument(' — cfg '，type = str，default = '。/yolov3-spp.cfg '，help = ' CFG文件的路径')</p><p id="6d4a" class="la lb hi bd lc ld le lf lg lh li jn dx translated">parser.add_argument(' — names '，type = str，default = '。/coco.names '，help = '*。名称路径’)</p><p id="0b7e" class="la lb hi bd lc ld le lf lg lh li jn dx translated">opt= parser.parse_args()</p></blockquote><p id="b0aa" class="pw-post-body-paragraph iq ir hi is b it lt iv iw ix lu iz ja jb lv jd je jf lw jh ji jj lx jl jm jn hb bi translated">如果文件保存在项目目录本身(。/*)，我们不需要传递命令行输入，因为路径值已经被定义为默认值。如果路径改变了，我们需要从命令行使用适当的参数显式地提供路径。</p><h1 id="0a2a" class="jw jx hi bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">最终代码</h1><p id="04c9" class="pw-post-body-paragraph iq ir hi is b it ku iv iw ix kv iz ja jb kw jd je jf kx jh ji jj ky jl jm jn hb bi translated">下面提供了代码的完整实现:</p><figure class="ln lo lp lq fd ij"><div class="bz dy l di"><div class="lr ls l"/></div></figure><p id="6c14" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">正如承诺的那样，我们只用了不到100行代码(准确地说是84行)就构建了一个非常强大的通用对象检测器😉).给定的实现只能使用您的CPU执行推理，因此可能会有一些性能相关的问题。我们需要使用深度学习框架来利用我们的GPU的能力，并加快这个过程。稍后会有更多相关信息…..</p></div></div>    
</body>
</html>