<html>
<head>
<title>Convolutional Neural Networks- an Illustrated Explanation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">卷积神经网络-图解说明</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/convolutional-neural-networks-an-illustrated-explanation-f9450ecc1bb1?source=collection_archive---------8-----------------------#2020-01-25">https://medium.com/analytics-vidhya/convolutional-neural-networks-an-illustrated-explanation-f9450ecc1bb1?source=collection_archive---------8-----------------------#2020-01-25</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><blockquote class="if ig ih"><p id="342c" class="ii ij ik il b im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg hb bi translated">编辑:写完这篇文章后不久，我做了一个解释CNN的YouTube视频。请随意查看！</p></blockquote><figure class="jh ji jj jk fd jl"><div class="bz dy l di"><div class="jm jn l"/></div></figure><p id="eee6" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jo iv iw ix jp iz ja jb jq jd je jf jg hb bi translated">到目前为止，神经网络的主要用途之一是对数据进行分类。这些数据可以是任何东西，从判断肿瘤是否恶性到你从尼日利亚王子那里收到的电子邮件是否是垃圾邮件。</p><figure class="jh ji jj jk fd jl er es paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="er es jr"><img src="../Images/41dfd976ad2ba324612065983e6c478b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZSI_PlOVlOR5fQRHbbYDBA.png"/></div></div></figure><p id="f41f" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jo iv iw ix jp iz ja jb jq jd je jf jg hb bi translated">图像/视频是最受欢迎的数据类型之一。<strong class="il hj"> <em class="ik">计算机视觉</em> </strong>是深度学习中的子领域，处理图像和视频以及其中包含的内容。</p><p id="1c0a" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jo iv iw ix jp iz ja jb jq jd je jf jg hb bi translated">计算机视觉有许多流行的应用，如图像搜索算法、自动车辆中的物体检测和疾病诊断。</p><figure class="jh ji jj jk fd jl er es paragraph-image"><div class="er es jy"><img src="../Images/43e1aaa005040bce732475c1d82b1de8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/0*NNWNjwtatVGNfcyJ.gif"/></div><figcaption class="jz ka et er es kb kc bd b be z dx translated">资料来源:Rahul Agarwal</figcaption></figure><p id="1e4f" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jo iv iw ix jp iz ja jb jq jd je jf jg hb bi translated">用于图像数据的最流行的神经网络之一是卷积神经网络，也称为CNN。CNN的亮点是能够从图像中提取边缘、纹理和形状等特征。</p><p id="94f8" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jo iv iw ix jp iz ja jb jq jd je jf jg hb bi translated">在这篇文章中，我想通过一系列的插图来解释CNN中的主要层是如何工作的。</p><h2 id="a8a9" class="kd ke hi bd kf kg kh ki kj kk kl km kn jo ko kp kq jp kr ks kt jq ku kv kw kx bi translated">卷积步骤</h2><p id="736c" class="pw-post-body-paragraph ii ij hi il b im ky io ip iq kz is it jo la iw ix jp lb ja jb jq lc je jf jg hb bi translated">想象你有一只狗的图像。</p><figure class="jh ji jj jk fd jl er es paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="er es ld"><img src="../Images/fadf7425923d4baea5de04147ba4767f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*s9fvHkwQY9pIHJT2hj8tXw.png"/></div></div><figcaption class="jz ka et er es kb kc bd b be z dx translated">一张非常逼真的狗的照片</figcaption></figure><p id="1374" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jo iv iw ix jp iz ja jb jq jd je jf jg hb bi translated">现在我们在这张照片中看到一只狗，尽管我的绘图能力很差，但计算机看到的是不同的。计算机将其视为一系列像素，每个像素都有一个RGB值。</p><figure class="jh ji jj jk fd jl er es paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="er es ld"><img src="../Images/08af54ad3413f5748c0ec8f0614d8451.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*88OHk5W5bDBrvRKf4PkgLA.png"/></div></div><figcaption class="jz ka et er es kb kc bd b be z dx translated">电脑看到的</figcaption></figure><p id="f514" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jo iv iw ix jp iz ja jb jq jd je jf jg hb bi translated">在这种情况下，每个方框代表一个像素。当然，在真实的图片中，像素会小得多。接下来是卷积层。</p><figure class="jh ji jj jk fd jl er es paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="er es ld"><img src="../Images/d4d535c7d5d26a025aa4773f0c3c6735.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w3RDlFQKFKwvZ26xKYm3DQ.png"/></div></div><figcaption class="jz ka et er es kb kc bd b be z dx translated">卷积滤波器</figcaption></figure><p id="f20a" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jo iv iw ix jp iz ja jb jq jd je jf jg hb bi translated">卷积层所做的是将滤镜应用于图块，图块是图像的一个子部分。然后，滤波器将输入值乘以滤波器值，然后将它们相加，得到一个和。该模型在训练期间学习过滤器的正确值，因此它可以提取好的特征。</p><figure class="jh ji jj jk fd jl er es paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="er es ld"><img src="../Images/7961a47827bb2fed18555a7d154fdac6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4RIB78tAOXwyysqhkKn5Aw.png"/></div></div><figcaption class="jz ka et er es kb kc bd b be z dx translated">过滤器翻转了</figcaption></figure><p id="7e6e" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jo iv iw ix jp iz ja jb jq jd je jf jg hb bi translated">然后，过滤器滑过，做同样的过程。你可以注意到一些像素实际上是如何重叠的。然后模型继续这个过程。</p><figure class="jh ji jj jk fd jl er es paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="er es ld"><img src="../Images/50c2d9d190f6b16e40ba92748bd3d27f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z_-_A7f15ei2SJ1L76KgpA.png"/></div></div></figure><p id="d69e" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jo iv iw ix jp iz ja jb jq jd je jf jg hb bi translated">然后我们剩下的是一个输出特征图，它(希望)从输入中提取了一些有用的特征。</p><p id="8574" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jo iv iw ix jp iz ja jb jq jd je jf jg hb bi translated">卷积完成后，对特征图进行ReLU变换。要阅读更多关于激活功能的信息，请查看<a class="ae le" href="https://developers.google.com/machine-learning/practica/image-classification/convolutional-neural-networks" rel="noopener ugc nofollow" target="_blank">这篇</a>文章。</p><h2 id="2662" class="kd ke hi bd kf kg kh ki kj kk kl km kn jo ko kp kq jp kr ks kt jq ku kv kw kx bi translated">汇集步骤</h2><p id="e2c4" class="pw-post-body-paragraph ii ij hi il b im ky io ip iq kz is it jo la iw ix jp lb ja jb jq lc je jf jg hb bi translated">典型CNN结构的下一部分是一个汇集步骤。合并步骤的作用是获取由卷积生成的输出特征图，并缩小尺寸以减少模型中的维数，从而节省处理时间。</p><figure class="jh ji jj jk fd jl er es paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="er es ld"><img src="../Images/615ef94ed4500ed46ff5a79130d2e06e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MFxxgEvSnLZxVpI4uFWUQQ.png"/></div></div><figcaption class="jz ka et er es kb kc bd b be z dx translated">复杂特征图</figcaption></figure><p id="f19c" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jo iv iw ix jp iz ja jb jq jd je jf jg hb bi translated">想象这是dog卷积+ ReLU示例的输出。我们想缩小这个特征地图，一个非常常见的方法是通过最大池。</p><figure class="jh ji jj jk fd jl er es paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="er es ld"><img src="../Images/c90332af46129bc328c1444203c6ca56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u_sqr7Vhl16PfvC-tLaV1g.png"/></div></div></figure><p id="d0c6" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jo iv iw ix jp iz ja jb jq jd je jf jg hb bi translated">最大池所做的只是取一个图块的最大值(通常为2x2)。它非常类似于卷积步骤，在输入中滑动。我们继续这个过程，直到汇集完成。</p><figure class="jh ji jj jk fd jl er es paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="er es ld"><img src="../Images/6a85384dcaddccb7d932ec21a90e19c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lkH2jOtqIgAqkQgHZLUJlQ.png"/></div></div></figure><p id="e5c5" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jo iv iw ix jp iz ja jb jq jd je jf jg hb bi translated">然后，这最终连接到一个密集层，这是你的典型，香草多层感知器。查看<a class="ae le" rel="noopener" href="/datadriveninvestor/deep-learning-is-not-just-import-tensorflow-c27136aaa65e">这篇文章</a>以了解更多相关信息。</p><h2 id="d9c2" class="kd ke hi bd kf kg kh ki kj kk kl km kn jo ko kp kq jp kr ks kt jq ku kv kw kx bi translated">在CIFAR-10数据集中使用CNN</h2><p id="92ed" class="pw-post-body-paragraph ii ij hi il b im ky io ip iq kz is it jo la iw ix jp lb ja jb jq lc je jf jg hb bi translated">最近，我使用CNN在一个名为<a class="ae le" href="https://www.cs.toronto.edu/~kriz/cifar.html" rel="noopener ugc nofollow" target="_blank"> CIFAR-10 </a>的数据集上进行图像分类。数据集由10个不同物体的60，000幅图像组成(因此是CIFAR-10中的10幅)。</p><figure class="jh ji jj jk fd jl er es paragraph-image"><div class="er es lf"><img src="../Images/54ac26b4008a08afe43fb91989085da0.png" data-original-src="https://miro.medium.com/v2/resize:fit:984/format:webp/0*gDmmy0-_N4ioHYNN.png"/></div></figure><p id="c971" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jo iv iw ix jp iz ja jb jq jd je jf jg hb bi translated">结果非常好，仅经过3个时期的训练，测试数据的损失就达到了74%。下面是一段代码。</p><pre class="jh ji jj jk fd lg lh li lj aw lk bi"><span id="a10d" class="kd ke hi lh b fi ll lm l ln lo">model = models.Sequential()</span><span id="18b2" class="kd ke hi lh b fi lp lm l ln lo">model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))<br/>model.add(layers.MaxPooling2D((2, 2)))<br/>model.add(layers.Conv2D(64, (3, 3), activation='relu'))<br/>model.add(layers.MaxPooling2D((2, 2)))<br/>model.add(layers.Conv2D(64, (3, 3), activation='relu')) model.add(layers.Flatten())<br/>model.add(layers.Dense(64, activation='relu'))<br/>model.add(layers.Dense(10, activation='softmax')) </span><span id="9dbe" class="kd ke hi lh b fi lp lm l ln lo">model.compile(optimizer='adam',              loss='sparse_categorical_crossentropy',metrics=['accuracy'])</span></pre><p id="4557" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jo iv iw ix jp iz ja jb jq jd je jf jg hb bi translated">通过额外的数据扩充和正则化，精确度可能会变得更高，因为这将解决一些问题，如过度拟合和增加数据集大小。</p><p id="41d5" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jo iv iw ix jp iz ja jb jq jd je jf jg hb bi translated">另一种可能性是在<a class="ae le" href="https://en.wikipedia.org/wiki/Transfer_learning" rel="noopener ugc nofollow" target="_blank">迁移学习</a>中，它使用预先训练的模型，如谷歌的Inception，然后将其应用到我们的模型中。</p><p id="7595" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jo iv iw ix jp iz ja jb jq jd je jf jg hb bi translated">你可以通过这个<a class="ae le" href="https://github.com/lewwwis/cifarrcnnreplicate" rel="noopener ugc nofollow" target="_blank">链接</a>在Github上查看我的模型的完整代码。</p><h2 id="f028" class="kd ke hi bd kf kg kh ki kj kk kl km kn jo ko kp kq jp kr ks kt jq ku kv kw kx bi translated">在你走之前！</h2><p id="b968" class="pw-post-body-paragraph ii ij hi il b im ky io ip iq kz is it jo la iw ix jp lb ja jb jq lc je jf jg hb bi translated"><em class="ik">我目前正在继续进行额外的ML项目，我将在未来几周内在Medium上分享这些项目！</em></p><ul class=""><li id="8a58" class="lq lr hi il b im in iq ir jo ls jp lt jq lu jg lv lw lx ly bi translated">在<a class="ae le" href="https://www.linkedin.com/in/aaron-lewis-64284a188/" rel="noopener ugc nofollow" target="_blank"> Linkedin </a>上连接</li><li id="3310" class="lq lr hi il b im lz iq ma jo mb jp mc jq md jg lv lw lx ly bi translated">在我的<a class="ae le" href="http://aaronvlewis.me" rel="noopener ugc nofollow" target="_blank">网站</a>上查看我的其他作品</li><li id="c94d" class="lq lr hi il b im lz iq ma jo mb jp mc jq md jg lv lw lx ly bi translated">或者<a class="ae le" href="http://eepurl.com/gENgmb" rel="noopener ugc nofollow" target="_blank">订阅</a>我的时事通讯</li><li id="458a" class="lq lr hi il b im lz iq ma jo mb jp mc jq md jg lv lw lx ly bi translated">谢谢大家！:-)</li></ul></div></div>    
</body>
</html>