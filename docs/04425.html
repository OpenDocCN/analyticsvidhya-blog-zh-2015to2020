<html>
<head>
<title>Introduction to Automatic Hyperparameter Optimization with Hyperopt</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Hyperopt自动超参数优化简介</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/introduction-to-automatic-hyperparameter-optimization-with-hyperopt-e0b9c84d1059?source=collection_archive---------1-----------------------#2020-03-19">https://medium.com/analytics-vidhya/introduction-to-automatic-hyperparameter-optimization-with-hyperopt-e0b9c84d1059?source=collection_archive---------1-----------------------#2020-03-19</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><figure class="hh hi ez fb hj hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es hg"><img src="../Images/ac89ff6fc09e26e402cde68c4fcf303c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KxHr_phzCyJfaU9UCvCyWw.png"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">图片来源:<a class="ae hv" href="https://github.com/fmfn/BayesianOptimization" rel="noopener ugc nofollow" target="_blank">https://github.com/fmfn/BayesianOptimization</a></figcaption></figure><div class=""/><div class=""><h2 id="0b18" class="pw-subtitle-paragraph iv hx hy bd b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm dx translated">机器学习模型的参数和超参数是什么？</h2></div><p id="25ff" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">每个机器学习模型都有一组参数&amp;在训练过程中设置的超参数。参数是直接从训练数据中学习的值，例如线性/逻辑回归模型中的系数、基于树的模型中的分割变量和分割值、神经网络中的权重等。参数值由机器学习算法估计，无需任何人工参与。</p><p id="5069" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">超参数是确定机器学习模型复杂性的值。超参数的最佳选择确保该模型在拾取训练数据中的噪声时既不太灵活(过拟合)，也不太僵硬(可能丢失训练数据中的重要信号)(欠拟合)。与参数不同，超参数不能直接从训练数据中学习，需要由机器学习从业者来设置。随机森林/梯度增强模型中的预测器数量、神经网络中的学习速率、要使用的数量或正则化等是超参数的几个例子。超参数通常通过为不同的超参数值集迭代训练模型，并在保留的验证集或使用交叉验证上评估模型的性能来设置。</p><p id="9603" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hz">超参数调谐方法</strong></p><p id="ca74" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">以下是超参数调整的常用方法。在所有这些方法中，将选择在验证集上提供最佳性能的超参数值:</p><ul class=""><li id="a9bf" class="kj kk hy jp b jq jr jt ju jw kl ka km ke kn ki ko kp kq kr bi translated">手动调整:机器学习实践者根据他的领域知识设置超参数值。他可能会尝试不同的价值观，然后选择最好的。</li><li id="8d1d" class="kj kk hy jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">网格搜索:模型在由从业者设置的预定义的超参数值网格上进行调整。评估由网格定义的超参数值的所有可能组合，以选择最佳集合。</li><li id="600b" class="kj kk hy jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">随机搜索:机器学习实践者为每个超参数提供要评估的值的概率分布。从这些分布中抽取指定数量的样本，并对每个样本评估模型的性能。</li><li id="4e4c" class="kj kk hy jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">贝叶斯优化:贝叶斯优化跟踪先前评估的结果，以选择要评估的下一组超参数值。我们将在下面的章节中详细讨论贝叶斯优化。</li></ul><h2 id="b03c" class="kx ky hy bd kz la lb lc ld le lf lg lh jw li lj lk ka ll lm ln ke lo lp lq lr bi translated">贝叶斯优化</h2><p id="0cb3" class="pw-post-body-paragraph jn jo hy jp b jq ls iz js jt lt jc jv jw lu jy jz ka lv kc kd ke lw kg kh ki hb bi translated">贝叶斯优化(也称为基于序列模型的优化(SMBO))使用过去评估的结果来形成目标函数的概率模型&amp;使用该模型来选择下一组超参数值。概率模型称为“代理模型”，用p(y|x)表示；y是模型的性能度量，x是超参数值。这里，目标函数是将超参数值映射到模型在验证集(或使用交叉验证)上选择的性能指标(如RMSE、准确度、ROC AUC等)的函数。与实际的目标函数相比，代理模型更容易优化。替代模型方法可用于在时间或金钱方面评估实际目标函数过于昂贵的情况(贝叶斯优化技术最初是为石油勘探应用开发的)。贝叶斯优化的基本步骤是:</p><ol class=""><li id="a3c9" class="kj kk hy jp b jq jr jt ju jw kl ka km ke kn ki lx kp kq kr bi translated">使用过去评估的结果建立目标函数的代理模型。</li><li id="02dc" class="kj kk hy jp b jq ks jt kt jw ku ka kv ke kw ki lx kp kq kr bi translated">找到在代理模型上表现最好的超参数。</li><li id="05d5" class="kj kk hy jp b jq ks jt kt jw ku ka kv ke kw ki lx kp kq kr bi translated">使用步骤2中选择的超参数值评估实际目标函数(即训练模型和评估性能指标)。</li><li id="b3cc" class="kj kk hy jp b jq ks jt kt jw ku ka kv ke kw ki lx kp kq kr bi translated">通过添加步骤3中获得的新结果来更新代理模型。</li><li id="244b" class="kj kk hy jp b jq ks jt kt jw ku ka kv ke kw ki lx kp kq kr bi translated">重复2到4，直到达到停止标准，如最大迭代次数或时间。</li><li id="af3a" class="kj kk hy jp b jq ks jt kt jw ku ka kv ke kw ki lx kp kq kr bi translated">从所有试验中选择性能最佳的超参数。</li></ol><p id="af52" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">贝叶斯优化方法的许多变体(hyperopt是其中之一)可用于机器学习模型的超参数优化。这些方法的不同之处在于它们构建的代理模型的类型以及它们在上述算法的步骤2中使用的优化标准。Hyperopt使用Tree Parzen估计器(TPE)作为代理模型，使用期望改进(EI)作为优化代理模型的标准。</p><p id="0465" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hz">树形结构Parzen估计量(TPE): </strong>不直接建模p(y|x)，TPE建模p(x|y)和p(y)。TPE使用两种密度定义p(x|y ):</p><figure class="lz ma mb mc fd hk er es paragraph-image"><div class="er es ly"><img src="../Images/180686059e3db09f6008f31fb2a38b04.png" data-original-src="https://miro.medium.com/v2/resize:fit:624/format:webp/1*mmNH9LTV0I3cNbF-S58iuA.png"/></div></figure><p id="868e" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">其中l(x)是通过使用来自过去评估的观测值xᵢ形成的密度，使得相应的损失(即，模型的性能度量)小于某个阈值y*，g(x)是通过使用剩余观测值形成的密度。这里，我们假设我们想要最小化模型的性能度量(例如RMSE损失)。如果我们希望使用一个需要最大化的指标(如准确性、f1得分、ROC AUC等)，我们只需取该指标的负值，并尝试将其最小化。TPE算法使用y*作为观察值的某个分位数γ，因此p(y &lt; y*) = γ.</p><p id="5a3f" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hz">期望改善(EI): </strong>期望改善是在f(x)的某个模型M下f(x)将超过(负)某个阈值y*的期望。</p><figure class="lz ma mb mc fd hk er es paragraph-image"><div class="er es md"><img src="../Images/0ba9c747f83f13c747b1ec6223bd1d7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:970/format:webp/1*UtqRSNCL_-2jepfxrgfalw.png"/></div></figure><p id="51fb" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">在TPE算法下，可以证明最大化EI相当于选择最小化g(x)/l(x)的x值。即，我们希望点在l(x)下具有高值，而在g(x)下具有低值。在每次迭代中，该算法从l(x)中抽取几个样本，根据g(x)/l(x)对它们进行评估，并返回具有最高EI的候选项。</p><h2 id="0b61" class="kx ky hy bd kz la lb lc ld le lf lg lh jw li lj lk ka ll lm ln ke lo lp lq lr bi translated">远视</h2><p id="67de" class="pw-post-body-paragraph jn jo hy jp b jq ls iz js jt lt jc jv jw lu jy jz ka lv kc kd ke lw kg kh ki hb bi translated">如上所述，Hyperopt使用Tree-Parzen估计器来构建代理模型，并将预期改进作为优化标准。此外，hyperopt要求机器学习从业者定义以下内容:</p><ol class=""><li id="0f0c" class="kj kk hy jp b jq jr jt ju jw kl ka km ke kn ki lx kp kq kr bi translated">定义将超参数值映射到模型所选性能指标的目标函数。</li><li id="f105" class="kj kk hy jp b jq ks jt kt jw ku ka kv ke kw ki lx kp kq kr bi translated">定义一个配置空间。配置空间描述了域(即超参数的概率分布。)在其上允许远视搜索。这使得机器学习实践者能够对他的领域专业知识进行编码，以帮助超视识别最佳超参数值。hyperopt库中有许多选项可用于描述概率分布。</li><li id="25d7" class="kj kk hy jp b jq ks jt kt jw ku ka kv ke kw ki lx kp kq kr bi translated">选择搜索算法。Hyperopt目前支持TPE算法和随机搜索。</li><li id="2906" class="kj kk hy jp b jq ks jt kt jw ku ka kv ke kw ki lx kp kq kr bi translated">指定一个trials对象来存储中间结果。这是可选的。</li></ol><p id="1527" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">hyperopt.hp模块定义了几个超参数分布，可用于指定配置空间。可用选项包括:</p><ul class=""><li id="4118" class="kj kk hy jp b jq jr jt ju jw kl ka km ke kn ki ko kp kq kr bi translated">hp.choice(label，options):返回其中一个选项。选项可以是列表、元组，甚至是嵌套表达式。嵌套表达式格式允许我们指定条件参数，如果我们需要在不同类型的机器学习模型之间进行优化，这将非常方便。示例:在boosting或随机森林之间，或者在不同架构的神经网络模型之间。我们将看到一个说明该选项的代码示例。</li><li id="7121" class="kj kk hy jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">hp.pchoice(label，p_options):类似于hp.choice()，但是为每个选项指定了概率。</li><li id="32fd" class="kj kk hy jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">hp.uniform(标签，低，高):低和高(包括两端)之间的均匀分布。</li><li id="c397" class="kj kk hy jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">hp.quniform(label，low，high，q):q * round给出的分布(uniform(low，high)/q)。适用于取离散值的超参数。</li><li id="3bd3" class="kj kk hy jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">HP . loqui form(label，low，high):由exp(uniform(low，high))给出的分布。超参数将被限制在区间[eˡᵒʷ，eʰⁱᵍʰ]</li><li id="3f61" class="kj kk hy jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">hp.normal(label，mu，sigma):一个正态分布变量。优化时，此超参数不受约束。</li><li id="c899" class="kj kk hy jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">hp.qnormal(label，mu，sigma，q):q * round给出的分布(uniform(mu，sigma)/q)。这个变量也是无约束的。</li><li id="8804" class="kj kk hy jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">hp.lognormal(label，mu，sigma):由exp(normal(mu，sigma))给出的分布。这个变量被限定为正数。</li><li id="0bfe" class="kj kk hy jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">hp.qlognormal(label，mu，sigma，q):q * round(exp(normal(mu，sigma))/q)给出的分布。这个变量被限定为正数。</li><li id="1936" class="kj kk hy jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">hp.randint(label，upper):返回一个在[0，upper]范围内的随机整数。这种分布假设邻近整数值之间的损失函数没有相关性(例如，对于随机种子值)。</li></ul><h2 id="56e5" class="kx ky hy bd kz la lb lc ld le lf lg lh jw li lj lk ka ll lm ln ke lo lp lq lr bi translated">远视在行动</h2><p id="562c" class="pw-post-body-paragraph jn jo hy jp b jq ls iz js jt lt jc jv jw lu jy jz ka lv kc kd ke lw kg kh ki hb bi translated">让我们使用来自UCI机器学习知识库的银行营销数据来演示hyperopt的工作。该数据与一家葡萄牙银行机构的直接营销活动相关。营销活动以电话为基础。目标变量是客户是否从银行订购了定期存款。许多与客户、营销活动、以前与客户的联系以及社会经济指标相关的变量都可以作为解释变量。UCI站点有四个数据集，我们将使用文件“bank-additional-full.csv”。你可以在这里阅读更多关于数据集<a class="ae hv" href="https://archive.ics.uci.edu/ml/datasets/Bank+Marketing" rel="noopener ugc nofollow" target="_blank">的内容。我们将使用Google colab来运行我们的代码。代码文件上传到</a><a class="ae hv" href="https://github.com/Rakeshsuku/Medium-Blog" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><figure class="lz ma mb mc fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es me"><img src="../Images/6784e1642aa74b3d7a4c6407b9aea523.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wp3_xOaBAuhNjBgmsXTzXw.png"/></div></div></figure><figure class="lz ma mb mc fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mf"><img src="../Images/32c8ff5da6c7e7bcbe8f5e075756a6f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MuV-g_HtvdHhWZyZ3yR0Dg.png"/></div></div></figure><figure class="lz ma mb mc fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mg"><img src="../Images/f00147033a6a4d86e32a09e967af10ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3dYkzSggwr1RyMHUW1LKmA.png"/></div></div></figure><p id="2015" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">我们看到数据集是不平衡的，在数据集中的41188个客户中，只有4640个客户订阅了定期存款。根据UCI网站上的数据集信息，记录与客户通话持续时间的“持续时间”变量与目标高度相关。由于银行在发出呼叫之前无法获得该信息，因此我们将丢弃该变量。还要注意，“pdays”中的值“999”实际上是一个缺失的值指示符，表示银行以前没有联系过该客户。让我们删除“duration”变量，并将我们的目标复制到一个新变量y。我们还将创建一个二进制变量来表示“银行以前没有联系过”，并将“pdays”中的“999”替换为nan。</p><figure class="lz ma mb mc fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mh"><img src="../Images/9d17050b70f6bdacbc578ea7972fd268.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DPHiXotuWR6dANUjvsiUxA.png"/></div></div></figure><p id="623b" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">接下来，我们将数据分成训练集和测试集，并对分类变量执行标签编码。</p><figure class="lz ma mb mc fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mh"><img src="../Images/2e7d2df772f7bf7201b91d170578bc73.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Sw22QXsOP4o4naG9Z6Nhkg.png"/></div></div></figure><figure class="lz ma mb mc fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mi"><img src="../Images/b8f3f464fd9451fd215752243de1fd0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c1q3b4K8cIDNpRmAIzX0Ow.png"/></div></div></figure><figure class="lz ma mb mc fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mg"><img src="../Images/3a46748773d15b23a120c7a7c891fb8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-cQH0MZP1MzOtxSi1o21_A.png"/></div></div></figure><p id="99aa" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">让我们将XGBoost模型作为基线模型。我们将使用ROC AUC作为评估标准，因为我们有一个不平衡的分类问题。请注意，我们在这里没有使用早期停止。</p><figure class="lz ma mb mc fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mj"><img src="../Images/0240fe3cf6dd40f34df782095931de3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6M2EX-lmgE3J7CsLh51B3g.png"/></div></div></figure><figure class="lz ma mb mc fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mk"><img src="../Images/b80da571ab254b086e0d13996e4740e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZumbpQ6xz86M3IwkPhlRsA.png"/></div></div></figure><p id="2a07" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">接下来，我们将使用hyperopt来优化该模型的超参数。首先，我们将定义一个函数，该函数为给定的一组超参数值计算测试集的ROC AUC。注意，我们返回一个字典作为这个函数的输出。Hyperopt最小化输出字典中的“损失”值，因此我们返回-1 * ROC AUC作为损失。</p><figure class="lz ma mb mc fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es ml"><img src="../Images/db35458241a7b8a56baee2db19d683ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*peUd0q7fOZrUjJmfQzUxbQ.png"/></div></div></figure><p id="4fa2" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">default_params是我们不希望优化的超参数。如果我们将参数“params”中的相同超参数传递给hyperopt_xgb_train()函数，default_params中的值将被忽略。请注意，我们这里不是针对“num_round”进行调优；当我们拟合最终模型时，我们宁愿使用提前停止。让我们用之前使用的超参数值来测试这个函数。</p><figure class="lz ma mb mc fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mm"><img src="../Images/9e2fe39b11291d5bfe071e106a1bb154.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZTaqRp66VVvbxVTIkWiUQQ.png"/></div></div></figure><p id="9a3e" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">接下来，我们将定义两个函数，这两个函数将帮助我们可视化所调整的超参数的配置空间(即概率分布)。我们将设想以下两种情况:</p><ul class=""><li id="b0cf" class="kj kk hy jp b jq jr jt ju jw kl ka km ke kn ki ko kp kq kr bi translated">我们根据我们的领域知识(plot_params_space())定义并提供给hyperopt作为输入的概率分布。</li><li id="54c3" class="kj kk hy jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">hyperopt根据之前的评估历史实际消耗的超参数值的分布。(plot _ params _ tried())。该函数还返回所有试验结果的数据帧。</li></ul><p id="d45a" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">这将有助于我们清楚地了解远视的工作原理。请注意，下面定义的绘图功能不适用于嵌套配置空间。</p><figure class="lz ma mb mc fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mn"><img src="../Images/d794646bbbd4cd315ddbfa9d6b590e84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NgpvshmTXJIh-m9sM_mTaA.png"/></div></div></figure><figure class="lz ma mb mc fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mo"><img src="../Images/bc5bfcd1ef28d082ce906da8b5ecaaf1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JfrhaKo1HudcRQogCvO0OQ.png"/></div></div></figure><figure class="lz ma mb mc fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mp"><img src="../Images/8b254a66f1571f1323b7e1f9fd5edec6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2zkgS8np6vMnbderYiaUkA.png"/></div></div></figure><p id="bd0a" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">让我们定义xgb模型的配置空间，并将其可视化。</p><figure class="lz ma mb mc fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mg"><img src="../Images/3501c84dae9e5558d64d1032179b6dc9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kuQD75diT17E-aIMGARVAA.png"/></div></div></figure><figure class="lz ma mb mc fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mq"><img src="../Images/e3a1db50c51161338b07de3a30dda766.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2JCMEpFvWmO1D3kEFoWn4g.png"/></div></div></figure><p id="c57f" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">注意使用pyll.scope.int()函数将max_depth值转换为整数类型。hyperopt.pyll.scope模块允许我们在定义超参数的概率空间时使用自定义函数。更多例子请参见hyperopt论文。</p><p id="d903" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">我们将定义一个trials对象来存储hyperopt进行的所有评估的结果。我们还将使用这个对象来绘制评估的结果。如果没有提供trials对象，下面的fmin()函数将只返回最佳的超参数值。</p><figure class="lz ma mb mc fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mf"><img src="../Images/16cbf1e0d926f947eb14b708c1b30ef8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JvmeIHzc_XdSeYaSNTzRtA.png"/></div></div></figure><p id="aa0a" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">fmin()函数是执行超参数优化的主力。fmin的第一个参数是目标函数，第二个参数是配置空间。fmin()的其他参数有:</p><ul class=""><li id="795a" class="kj kk hy jp b jq jr jt ju jw kl ka km ke kn ki ko kp kq kr bi translated">algo:指定要使用的优化算法。可用选项有‘tpe . suggest’(用TPE算法实现贝叶斯优化)；和' rand.suggest '(实现随机搜索)。</li><li id="d0c6" class="kj kk hy jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">max_evals:要执行的评估次数。</li><li id="de59" class="kj kk hy jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">trials: Trials()对象保存由hyperopt执行的所有评估的结果。的。trials对象的Trials属性是一个列表，其中包含fmin所做的每个评估的元素。</li></ul><figure class="lz ma mb mc fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mi"><img src="../Images/723284f7fd427396f7c7310b51d82323.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AcblYXwiduQaiaabhInrbA.png"/></div></div></figure><p id="461e" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">对于上述超参数值，我们得到了大约0.82的最佳auc roc分数。请注意使用hyperopt的space_eval()函数从best获取超参数值。space_eval()是必需的，因为best将拥有由hp.choice()定义的任何超参数的整数索引。让我们画出由hyperopt完成的评估结果。</p><figure class="lz ma mb mc fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mr"><img src="../Images/5593f723aa0caa00ca3b06ea3ff8b291.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UnAqRHxqT5Hn3K2M-LC1pg.png"/></div></div></figure><p id="0f79" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">我们可以看到，由hyperopt评估的值的分布与我们定义的分布非常不同。让我们也绘制超参数值对损失(ROC AUC的ve)的散点图。</p><figure class="lz ma mb mc fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es ms"><img src="../Images/a61b52433f39af082d7e44aa59e56a0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KsiZsv2sYkZGxYpjJ-DeWQ.png"/></div></div></figure><p id="d933" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">产生最佳结果的超参数值为:</p><figure class="lz ma mb mc fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mt"><img src="../Images/53b09891e0b8a4ebe49efd459fa708a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*26ALUWfH1ll1GFsuLVsZXw.png"/></div></div></figure><p id="732a" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">对于最终的模型，我们将把num_round增加到1000，并启用50轮提前停止。</p><figure class="lz ma mb mc fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mu"><img src="../Images/31d08359ea581a94cbcb9e2084241093.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VM0JBt8uKYjsfXxIp_gvMQ.png"/></div></div></figure><figure class="lz ma mb mc fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mf"><img src="../Images/28b1cdf9a8d9529ca595498e20dfdfb7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZYtKefJgM0ffxYuM409tYg.png"/></div></div></figure><p id="4339" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">请注意，xgboost.train()将返回上一次迭代(这里是147次迭代)的模型，而不是最佳模型。我们可以得到如下的最佳迭代:</p><figure class="lz ma mb mc fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mt"><img src="../Images/2cbe1d5d273db03099fae9b72b169768.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rLlM9oI2gzcGnIXYsZi2kQ.png"/></div></div></figure><h2 id="b5d6" class="kx ky hy bd kz la lb lc ld le lf lg lh jw li lj lk ka ll lm ln ke lo lp lq lr bi translated">嵌套配置空间</h2><p id="d849" class="pw-post-body-paragraph jn jo hy jp b jq ls iz js jt lt jc jv jw lu jy jz ka lv kc kd ke lw kg kh ki hb bi translated">接下来，我们将使用嵌套配置空间来同时调优xgboost模型和随机森林模型&amp;选择性能最佳的模型。我们还将绘制几个样本，看看我们从这个嵌套的配置空间中得到什么。</p><figure class="lz ma mb mc fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mq"><img src="../Images/6b3e897e31ec7673a1d0d114cfcf7666.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qCK6etne4emG-lNPNTzMLg.png"/></div></div></figure><figure class="lz ma mb mc fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mq"><img src="../Images/7faa42324359c4006c22a2e96a86395f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Fv4ZWMTjdeyOcOKnG0ZOBA.png"/></div></div></figure><p id="b3f1" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">接下来，我们将为这个嵌套的配置空间创建一个目标函数。我们将用随机森林模型的中值替换pdays列中缺少的值。</p><figure class="lz ma mb mc fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mk"><img src="../Images/a4465d906f5b303487edb33a0b9d03ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fxd5osPMvbGFHedqosIgyg.png"/></div></div></figure><figure class="lz ma mb mc fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mp"><img src="../Images/39c2c2c15d0163f6f6270f7208860d78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XgEZwSczG-nJB7jBzGkt7A.png"/></div></div></figure><figure class="lz ma mb mc fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mk"><img src="../Images/b339e0ab40c82e05673fd5a1b7587060.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HrR6MC9x9oXvqHJCinftxw.png"/></div></div></figure><p id="310f" class="pw-post-body-paragraph jn jo hy jp b jq jr iz js jt ju jc jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">在这里找到上传<a class="ae hv" href="https://github.com/Rakeshsuku/Medium-Blog" rel="noopener ugc nofollow" target="_blank">的代码文件。</a></p><h2 id="6a59" class="kx ky hy bd kz la lb lc ld le lf lg lh jw li lj lk ka ll lm ln ke lo lp lq lr bi translated">参考</h2><ol class=""><li id="1aec" class="kj kk hy jp b jq ls jt lt jw mv ka mw ke mx ki lx kp kq kr bi translated">伯格斯特拉，詹姆斯和巴登内，r .和凯格尔，巴拉兹和本吉奥，Y..(2011).超参数优化算法。</li><li id="37a6" class="kj kk hy jp b jq ks jt kt jw ku ka kv ke kw ki lx kp kq kr bi translated">Hyperopt:用于优化机器学习算法的超参数的Python库</li><li id="216d" class="kj kk hy jp b jq ks jt kt jw ku ka kv ke kw ki lx kp kq kr bi translated"><a class="ae hv" href="https://towardsdatascience.com/a-conceptual-explanation-of-bayesian-model-based-hyperparameter-optimization-for-machine-learning-b8172278050f" rel="noopener" target="_blank">威尔·科尔森对机器学习的贝叶斯超参数优化的概念性解释</a></li><li id="4fc6" class="kj kk hy jp b jq ks jt kt jw ku ka kv ke kw ki lx kp kq kr bi translated"><a class="ae hv" href="https://districtdatalabs.silvrback.com/parameter-tuning-with-hyperopt" rel="noopener ugc nofollow" target="_blank">Kris Wright的超视参数调谐</a></li></ol></div></div>    
</body>
</html>