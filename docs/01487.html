<html>
<head>
<title>Scraping Youtube Video with BeautifulSoup (python)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用BeautifulSoup抓取Youtube视频(python)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/scraping-youtube-video-with-beautifulsoup-python-d30598285965?source=collection_archive---------2-----------------------#2019-10-26">https://medium.com/analytics-vidhya/scraping-youtube-video-with-beautifulsoup-python-d30598285965?source=collection_archive---------2-----------------------#2019-10-26</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/a0c3ab1fc19febcd4e9ca976a38a1741.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pQawQbMHRt4nqEhLlq1NLg.jpeg"/></div></div></figure><p id="67cd" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">最近我沉迷于youtube视频的洞察力，因此我试图用我最喜欢的python- BeautifulSoup包来抓取这个网站。现有的爬虫并没有给我一个明确的方向，最重要的是我发现它们都没有涵盖如何提取视频类别。所以我决定从头开始做自己的爬虫。</p><p id="4525" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">嗯，我不擅长文字，所以没有延误，我会去我的编码。</p><p id="dba7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">首先，让我们从加载所需的存储库开始:</p><pre class="jo jp jq jr fd js jt ju jv aw jw bi"><span id="26b9" class="jx jy hi jt b fi jz ka l kb kc">from bs4 import BeautifulSoup #for scraping<br/>import requests               #required for reading the file<br/>import pandas as pd           #(optional) Pandas for dataframes <br/>import json                   #(optional) If you want to export json<br/>import os</span></pre><p id="a8f6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">既然已经成功加载了所需的存储库，那么让我们开始我们的主要目标，搜索所需的信息。对于那些不熟悉BeautifulSoup的人，我会建议他们去阅读软件包的文档。有教程定义了如何使用BeautifulSoup进行刮擦。</p><p id="a7ba" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">由于这只是一个爬虫，我使用了youtube链接的用户输入。但是我在youtube的链接列表中使用了相同的代码，这很好，你可以根据自己的需要修改代码。</p><pre class="jo jp jq jr fd js jt ju jv aw jw bi"><span id="4b22" class="jx jy hi jt b fi jz ka l kb kc">url = input('Enter Youtube Video Url- ') # user input for the link<br/>Vid={}<br/>Link = url<br/>source= requests.get(url).text<br/>soup=BeautifulSoup(source,'lxml')<br/>div_s = soup.findAll('div')</span><span id="9d1e" class="jx jy hi jt b fi kd ka l kb kc">Title = div_s[1].find('span',class_='watch-title').text.strip()<br/>Vid['Title']=Title<br/>Vid['Link']=Link<br/>Channel_name = div_s[1].find('a',class_="yt-uix-sessionlink spf-link").text.strip()<br/>Channel_link = ('<a class="ae ke" href="http://www.youtube.com'+div_s[1].find('a',class_=" rel="noopener ugc nofollow" target="_blank">www.youtube.com'+div_s[1].find('a',class_=</a>"yt-uix-sessionlink spf-link").get('href'))<br/>Subscribers = div_s[1].find('span',class_="yt-subscription-button-subscriber-count-branded-horizontal yt-subscriber-count").text.strip()<br/>if len(Channel_name) ==0<br/>    Channel_name ='None'<br/>    Channel_link = 'None'<br/>    Subscribers = 'None'<br/>Vid['Channel']=Channel_name<br/>Vid['Channel_link']=Channel_link<br/>Vid['Channel_subscribers']=Subscribers</span></pre><p id="c1d7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">对于类别，我发现这种提取类别信息的方法不起作用，这主要是因为类别信息会随着语言设置的变化而变化。所以我找到的最好的方法是采用类别Id，它是数字，并且只能是这15个类别中的一个(带有相应的类别Id:类别名称):</p><p id="b43c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">1:'电影&amp;动画'，<br/> 2:'汽车&amp;车辆'，<br/> 10:'音乐'，<br/> 15:'宠物&amp;动物'，<br/> 17:'体育'，<br/> 19:'旅游&amp;事件'，<br/> 20:'博彩'，<br/> 22:'人&amp;博客'，<br/> 23:'喜剧'，<br/> 24:'娱乐'，<br/> 25:'新闻&amp;政治'，【T10</p><p id="311d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">一旦定义了这一点，剩下的任务就简单了:</p><pre class="jo jp jq jr fd js jt ju jv aw jw bi"><span id="ed8a" class="jx jy hi jt b fi jz ka l kb kc">Category_index = {<br/>     1 : 'Film &amp; Animation',<br/>     2 : 'Autos &amp; Vehicles',<br/>     10 : 'Music',<br/>     15 : 'Pets &amp; Animals',<br/>     17 : 'Sports',<br/>     19 : 'Travel &amp; Events',<br/>     20 : 'Gaming',<br/>     22 : 'People &amp; Blogs',<br/>     23 : 'Comedy',<br/>     24 : 'Entertainment',<br/>     25 : 'News &amp; Politics',<br/>     26 : 'Howto &amp; Style',<br/>     27 : 'Education',<br/>     28 : 'Science &amp; Technology',<br/>     29 : 'Nonprofits &amp; Activism'}<br/>Sp = div_s[1].text.split(':')<br/>subs = 'categoryId'<br/>for j in range(len(Sp)):<br/>    if subs in Sp[j]:<br/>        value =int(Sp[j+1].split(',')[0])<br/>Video_category=Category_index[value]        <br/>Vid['Category']=Video_category</span><span id="d161" class="jx jy hi jt b fi kd ka l kb kc">View_count = div_s[1].find(class_= 'watch-view-count')<br/>View_count = View_count.text.strip().split()[0]<br/>Vid['Views']=View_count</span><span id="1874" class="jx jy hi jt b fi kd ka l kb kc">Likes = div_s[1].find('button',class_="yt-uix-button yt-uix-button-size-default yt-uix-button-opacity yt-uix-button-has-icon no-icon-markup like-button-renderer-like-button like-button-renderer-like-button-unclicked yt-uix-clickcard-target yt-uix-tooltip" ).text.strip()<br/>Vid['Likes']=Likes<br/>Dislikes = div_s[1].find('button',class_="yt-uix-button yt-uix-button-size-default yt-uix-button-opacity yt-uix-button-has-icon no-icon-markup like-button-renderer-dislike-button like-button-renderer-dislike-button-unclicked yt-uix-clickcard-target yt-uix-tooltip" ).text.strip()<br/>Vid['Dislikes']=Dislikes</span><span id="6ddc" class="jx jy hi jt b fi kd ka l kb kc">Related_videos = div_s[1].findAll('a',class_='content-link spf-link yt-uix-sessionlink spf-link')<br/>Title_Related=[]<br/>Link_Related =[]<br/>for i in range(len(Related_videos)):<br/>    Title_Related.append(Related_videos[i].get('title'))<br/>    Link_Related.append(Related_videos[i].get('href'))<br/>Related_dictionary = dict(zip(Title_Related, Link_Related))    <br/>Vid['Related_vids']=Related_dictionary</span></pre><p id="fbfb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">成功抓取所需信息后，存储在Vid字典中，您可以将其导出为JSON文件:</p><pre class="jo jp jq jr fd js jt ju jv aw jw bi"><span id="5d35" class="jx jy hi jt b fi jz ka l kb kc">with open('vfile.json', 'w', encoding='utf8') as ou:<br/>    json.dump(Vid, ou, ensure_ascii=False)</span></pre><p id="7498" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">或数据帧:</p><pre class="jo jp jq jr fd js jt ju jv aw jw bi"><span id="0861" class="jx jy hi jt b fi jz ka l kb kc">df = pd.DataFrame(Vid, index =[0])</span></pre><p id="58de" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">vfile.json将保存在脚本的同一个目录中，或者如果您想继续进行一些探索性的数据分析，您可以继续使用data frames——我个人认为这更有用。</p><p id="ac15" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">注意:这里描述的所有代码都可以在我的github账户中找到——<a class="ae ke" href="https://github.com/DiproMondal/Youtube_crawler" rel="noopener ugc nofollow" target="_blank">https://github.com/DiproMondal/Youtube_crawler</a></p><p id="5ad8" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果任何人有任何问题/意见，随时联系我这里或邮件:dipro.mondal12ms@gmail.com</p><p id="2903" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">谢谢你</p></div></div>    
</body>
</html>