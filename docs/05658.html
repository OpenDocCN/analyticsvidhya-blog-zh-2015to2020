<html>
<head>
<title>Data Science : Decision Tree</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">数据科学:决策树</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/data-science-decision-tree-f87c2e272749?source=collection_archive---------8-----------------------#2020-04-28">https://medium.com/analytics-vidhya/data-science-decision-tree-f87c2e272749?source=collection_archive---------8-----------------------#2020-04-28</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><figure class="hh hi ez fb hj hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es hg"><img src="../Images/bee01355a27d96b64cffa0c8987da920.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q1M5cnDASmlbmBczSvdGEw.jpeg"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">决策树</figcaption></figure><div class=""/><p id="7d1c" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">决策树很容易解释</p><h2 id="2631" class="js jt hx bd ju jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km bi translated"><strong class="ak">什么是决策树？</strong></h2><p id="766d" class="pw-post-body-paragraph iu iv hx iw b ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn kr jp jq jr hb bi translated">决策树是用于分类和回归问题的监督机器学习算法。</p><p id="a639" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">分类处理预测离散值的类别，如0/1，或预测某人是否患有疾病，而回归处理预测连续值，如个人工资、房价等。</p><h2 id="a070" class="js jt hx bd ju jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km bi translated"><strong class="ak">直觉</strong></h2><p id="cadd" class="pw-post-body-paragraph iu iv hx iw b ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn kr jp jq jr hb bi translated">顾名思义，它使用树状模型进行决策。决策树是倒过来画的，它的根在顶部。它还包括内部节点<strong class="iw hy">、</strong>叶节点，我们将进一步讨论。</p><p id="0fbf" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">它像人脑一样决定。如下图所示，如果我们需要检查一个人是否合适，它会检查某些标准，并根据这些标准做出决定并返回结果。在机器学习中，我们可以用决策树分类器来做到这一点。</p><p id="eb36" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">年龄<strong class="iw hy"> = </strong>根节点，吃披萨/运动<strong class="iw hy"> = </strong>内部节点，健康/不健康<strong class="iw hy"> = </strong>叶节点</p><figure class="kt ku kv kw fd hk er es paragraph-image"><div class="er es ks"><img src="../Images/da4ad303b1810af2fa200777c435a8f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1084/format:webp/1*U6twhNSe1I37feFfBaeXLw.png"/></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">决策树。来源不明</figcaption></figure></div><div class="ab cl kx ky gp kz" role="separator"><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc ld"/><span class="la bw bk lb lc"/></div><div class="hb hc hd he hf"><h2 id="53c1" class="js jt hx bd ju jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km bi translated">决策树中的拆分标准:</h2><p id="b2e4" class="pw-post-body-paragraph iu iv hx iw b ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn kr jp jq jr hb bi translated">这是一个大问题，选择正确的特征，最好的分裂树，我们可以在更少的迭代中到达叶节点，这将用于决策。有各种技术用于决定哪些特征可以用作根节点和内部节点。</p><h2 id="4e2b" class="js jt hx bd ju jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km bi translated">分类技术:</h2><p id="cb7d" class="pw-post-body-paragraph iu iv hx iw b ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn kr jp jq jr hb bi translated">1.CHAID(卡方自动交互检测)</p><p id="b79f" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">2.CART(分类回归树)使用基尼指数(基尼杂质)作为度量。</p><p id="3ab9" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">3.ID3(迭代二分法3)使用<strong class="iw hy"> <em class="le">熵</em> </strong>和<a class="ae lf" href="https://en.wikipedia.org/wiki/Information_gain_in_decision_trees" rel="noopener ugc nofollow" target="_blank"> <strong class="iw hy"> <em class="le">信息增益</em></strong></a><strong class="iw hy"><em class="le"/></strong>作为度量。</p><p id="fa41" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">我们将在这里讨论使用基尼指数或基尼系数的CART技术。</p><h2 id="ba23" class="js jt hx bd ju jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km bi translated">GINI指数或GINI杂质:</h2><p id="cc4d" class="pw-post-body-paragraph iu iv hx iw b ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn kr jp jq jr hb bi translated">基尼指数或基尼不纯度被用作决策树中节点的不纯度的度量。如果所有的记录都属于同一个类(因变量)，则称一个节点是100%纯的。在二进制分类中，如果一半的记录属于一个类，另一半的记录属于另一个类，则称节点为100%不纯</p><figure class="kt ku kv kw fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lg"><img src="../Images/780bd7aeacc9c3f527083ca939972fca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P172LagFmb3HLhKt71kmaw.jpeg"/></div></div></figure><p id="fc5c" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">具有最小基尼系数特征将被选择用于分割。基尼系数<strong class="iw hy">的计算方法是从1中减去每个等级概率的平方和。它倾向于更大的分区。</strong></p><p id="25f3" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">计算基尼指数的公式如下。</p><figure class="kt ku kv kw fd hk er es paragraph-image"><div class="er es lh"><img src="../Images/9f71bf4c76f69b333a597b76d952ce76.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/1*MsRZ-QJKVhb0kIM__bNTiw.jpeg"/></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">未知来源</figcaption></figure><p id="8935" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">分裂的基尼系数计算为分裂节点级别的每个节点的加权平均值。</p><figure class="kt ku kv kw fd hk er es paragraph-image"><div class="er es lh"><img src="../Images/d60e6dcd22d15c6c32e72179252a14d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/1*JplJmNcngsfbpGf_wzysUA.jpeg"/></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">未知来源</figcaption></figure><p id="494a" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">让我们看一个带有数据集的例子，以便于理解。</p><p id="df37" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">这是我们的数据集。让我们用一个简单的例子来了解基尼指数是如何工作的。列<strong class="iw hy">‘Return’</strong>是我们的目标变量</p><figure class="kt ku kv kw fd hk er es paragraph-image"><div class="er es li"><img src="../Images/614eade8273874cb469fbda1330fc4a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1306/format:webp/1*lL0ypx2fOmQ3V1CDPZ8Iog.png"/></div></figure><h1 id="43a2" class="lj jt hx bd ju lk ll lm jy ln lo lp kc lq lr ls kf lt lu lv ki lw lx ly kl lz bi translated">让我们从计算“过去趋势”的基尼指数开始。</h1><p id="dc81" class="pw-post-body-paragraph iu iv hx iw b ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn kr jp jq jr hb bi translated">注:这里的“P”表示概率</p><p id="2679" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">p(过去趋势=正):6/10</p><p id="acfb" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">p(过去趋势=负):4/10</p><p id="827e" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">当(过去趋势=正，回报=涨)时，概率= 4/6</p><p id="5cb4" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">当(过去趋势=正，回报=负)时，概率= 2/6</p><p id="e7c3" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">基尼指数= 1 — ((4/6) + (2/6) ) = <strong class="iw hy"> 0.45 </strong></p><p id="f2b4" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">When(过去趋势=负&amp;回报=正)，则概率= 0</p><p id="6e42" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">当(过去趋势=负&amp;回报=跌)时，概率= 4/4</p><p id="f807" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">基尼指数= 1 — ((0) + (4/4) ) = <strong class="iw hy"> 0 </strong></p><p id="e904" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hy">基尼系数的加权平均值可计算如下:</strong></p><p id="1970" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hy">过去趋势的基尼指数</strong>=(6/10)<em class="le">0.45+(4/10)</em>0 =<strong class="iw hy">0.27</strong></p><h1 id="ec04" class="lj jt hx bd ju lk ll lm jy ln lo lp kc lq lr ls kf lt lu lv ki lw lx ly kl lz bi translated">未平仓利息基尼指数的计算</h1><p id="8b0a" class="pw-post-body-paragraph iu iv hx iw b ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn kr jp jq jr hb bi translated">p(未平仓利息=高):4/10</p><p id="07c3" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">p(未平仓权益=低):6/10</p><p id="deb5" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">当(未平仓利息=高&amp;回报=高)时，概率= 2/4</p><p id="505d" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">When(未平仓利息=高&amp;回报=低)，那么概率= 2/4</p><p id="efd8" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">基尼指数= 1 — ((2/4) + (2/4) ) = <strong class="iw hy"> 0.5 </strong></p><p id="3153" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">当(未平仓利息=低&amp;回报=高)时，概率= 2/6</p><p id="c0e3" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">When(未平仓利息=低&amp;回报=低)，那么概率= 4/6</p><p id="eed5" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">基尼指数= 1 — ((2/6) + (4/6) ) = <strong class="iw hy"> 0.45 </strong></p><p id="75aa" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hy">基尼系数的加权和可计算如下:</strong></p><p id="261d" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hy">未平仓合约基尼指数</strong>=(4/10)<em class="le">0.5+(6/10)</em>0.45 =<strong class="iw hy">0.47</strong></p><h1 id="0fa6" class="lj jt hx bd ju lk ll lm jy ln lo lp kc lq lr ls kf lt lu lv ki lw lx ly kl lz bi translated">交易量基尼指数的计算</h1><p id="5234" class="pw-post-body-paragraph iu iv hx iw b ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn kr jp jq jr hb bi translated">p(交易量=高):7/10</p><p id="0265" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">p(交易量=低):3/10</p><p id="0506" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">当(交易量=高&amp;回报=涨)时，那么概率= 4/7</p><p id="545f" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">当(交易量=高&amp;回报=低)时，那么概率= 3/7</p><p id="cca1" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">基尼指数= 1 — ((4/7) + (3/7) ) = <strong class="iw hy"> 0.49 </strong></p><p id="7df7" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">当(交易量=低&amp;回报=高)时，概率= 0</p><p id="1657" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">当(交易量=低&amp;回报=低)时，那么概率= 3/3</p><p id="6697" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">基尼指数= 1 — ((0) + (1) ) = <strong class="iw hy"> 0 </strong></p><p id="b1d7" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hy">基尼系数的加权和可计算如下:</strong></p><p id="4aca" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hy">交易量基尼指数</strong>=(7/10)<em class="le">0.49+(3/10)</em>0 =<strong class="iw hy">0.34</strong></p><figure class="kt ku kv kw fd hk er es paragraph-image"><div class="er es ma"><img src="../Images/25cac657c475dc9349f92875cf8e275b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1294/format:webp/0*dsqSXJG8QlWF5rj_.png"/></div></figure><p id="5cd4" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">从上表中，我们观察到“过去趋势”具有最低的基尼指数，因此它将被选为我们决策树的根节点。</p><p id="4cff" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">类似地，我们将重复相同的过程来确定决策树的子节点或分支，并到达叶节点或定义的最大深度。</p><h1 id="dbf8" class="lj jt hx bd ju lk ll lm jy ln lo lp kc lq lr ls kf lt lu lv ki lw lx ly kl lz bi translated"><strong class="ak">熵:</strong></h1><p id="0340" class="pw-post-body-paragraph iu iv hx iw b ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn kr jp jq jr hb bi translated">它是另一种度量决策树中一个节点的杂质、无序或不确定性的技术。熵值介于<strong class="iw hy"> 0到1之间。</strong></p><p id="7885" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">如果一个节点具有相等数量的可用类(在两类分类问题中相等数量的“是”和相等数量的“否”)，则称该节点是完全不纯的</p><p id="c305" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">如果一个节点包含“是”或“否”的类标签(全是“是”和零个“否”或者全是“否”和零个“是”)，则称该节点是完全纯的</p><p id="ab8c" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hy">信息增益(IG) </strong>衡量一个变量或特征给了我们多少关于类的“信息”。</p><p id="78a4" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">信息增益基于在变量/特征上分割数据集后熵的减少。</p><h1 id="af2f" class="lj jt hx bd ju lk ll lm jy ln lo lp kc lq lr ls kf lt lu lv ki lw lx ly kl lz bi translated">为什么它很重要？</h1><ol class=""><li id="053e" class="mb mc hx iw b ix kn jb ko jf md jj me jn mf jr mg mh mi mj bi translated"><strong class="iw hy">信息增益</strong>是<strong class="iw hy">决策树算法</strong>用来构建决策树的主键。</li><li id="9359" class="mb mc hx iw b ix mk jb ml jf mm jj mn jn mo jr mg mh mi mj bi translated">信息增益内部使用熵来计算节点的杂质。</li><li id="c9f6" class="mb mc hx iw b ix mk jb ml jf mm jj mn jn mo jr mg mh mi mj bi translated">具有最高<strong class="iw hy">信息增益</strong>的<strong class="iw hy">特征/变量</strong>将被考虑首先构建树。</li></ol><p id="6a14" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hy">熵的方程式:</strong></p><figure class="kt ku kv kw fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mp"><img src="../Images/bec31fe0553ff2f5d53260a89c9c6738.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ylu7ooadl0cczbl3qlUjRA.jpeg"/></div></div></figure><p id="7b4e" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hy">信息增益方程:</strong></p><figure class="kt ku kv kw fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mq"><img src="../Images/d5b56078cfb8c08701c9d1390017f403.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bXHi-2C14E7MoAdEEPNs-A.jpeg"/></div></div></figure><p id="50df" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">计算数据集中每个特征/变量的信息增益，具有最高信息增益的特征将用于构建决策树。</p><p id="f663" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hy">参考代码</strong>:</p><figure class="kt ku kv kw fd hk"><div class="bz dy l di"><div class="mr ms l"/></div></figure><h2 id="15cf" class="js jt hx bd ju jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km bi translated"><strong class="ak">决策树分类器可视化:</strong></h2><p id="3f7d" class="pw-post-body-paragraph iu iv hx iw b ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn kr jp jq jr hb bi translated">这种可视化需要安装sklearn，0.21或更高版本。下面代码中提到的步骤。</p><figure class="kt ku kv kw fd hk"><div class="bz dy l di"><div class="mr ms l"/></div></figure><h2 id="45da" class="js jt hx bd ju jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km bi translated">决策树的优势:</h2><ol class=""><li id="c03a" class="mb mc hx iw b ix kn jb ko jf md jj me jn mf jr mg mh mi mj bi translated">它的计算速度非常快。</li><li id="cef1" class="mb mc hx iw b ix mk jb ml jf mm jj mn jn mo jr mg mh mi mj bi translated">决策树不需要数据集的标准化/缩放，因为它使用概率函数来训练决策树模型，并且不使用任何距离度量。</li><li id="9891" class="mb mc hx iw b ix mk jb ml jf mm jj mn jn mo jr mg mh mi mj bi translated">数据中的缺失值也不会在很大程度上影响决策树的构建过程。</li><li id="0217" class="mb mc hx iw b ix mk jb ml jf mm jj mn jn mo jr mg mh mi mj bi translated">很容易解释。</li><li id="1cee" class="mb mc hx iw b ix mk jb ml jf mm jj mn jn mo jr mg mh mi mj bi translated">基尼系数优于熵，因为它计算速度快，基尼系数不需要计算像熵这样的任何值的“对数”。</li></ol><h2 id="d517" class="js jt hx bd ju jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km bi translated">缺点:</h2><ol class=""><li id="8103" class="mb mc hx iw b ix kn jb ko jf md jj me jn mf jr mg mh mi mj bi translated">决策树学习者可以创建过于复杂的树，不能很好地概括数据。这被称为过度拟合。(当模型的训练精度高而测试精度低时，会发生过拟合)</li><li id="dcf5" class="mb mc hx iw b ix mk jb ml jf mm jj mn jn mo jr mg mh mi mj bi translated">决策树可能不稳定，因为数据的微小变化可能导致生成完全不同的树。这称为方差，需要通过装袋或增压等方法来降低。</li><li id="e85b" class="mb mc hx iw b ix mk jb ml jf mm jj mn jn mo jr mg mh mi mj bi translated">如果某个类别(来自目标特征)占主导地位，决策树学习器会创建有偏向的树。因此，建议在拟合决策树之前平衡数据集。</li></ol><p id="aa3a" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hy">结论</strong>:这都是关于基尼指数的决策树。还有一种叫做熵的技术，使用信息增益，我将在后面添加。希望你喜欢阅读。如果你喜欢我的文章并想看更多，请张贴<strong class="iw hy"> 50个掌声</strong>和<strong class="iw hy">关注</strong>我的博客。</p><p id="e389" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">想要连接:</p><p id="ac70" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">链接进来:<a class="ae lf" href="https://www.linkedin.com/in/anjani-kumar-9b969a39/" rel="noopener ugc nofollow" target="_blank">https://www.linkedin.com/in/anjani-kumar-9b969a39/</a></p><p id="2415" class="pw-post-body-paragraph iu iv hx iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">如果你喜欢我在Medium上的帖子，并希望我继续做这项工作，请考虑在<a class="ae lf" href="https://www.patreon.com/anjanikumar" rel="noopener ugc nofollow" target="_blank"><strong class="iw hy"/></a>上支持我</p></div></div>    
</body>
</html>