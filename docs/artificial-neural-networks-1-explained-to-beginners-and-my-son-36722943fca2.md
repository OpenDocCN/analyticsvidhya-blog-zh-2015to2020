# 人工神经网络-1，对我儿子的解释不同

> 原文：<https://medium.com/analytics-vidhya/artificial-neural-networks-1-explained-to-beginners-and-my-son-36722943fca2?source=collection_archive---------15----------------------->

![](img/75bde8c2d19e00e426b7caba71c16811.png)

宇宙的一角，我们智慧进化的地方。是否存在一种普遍的智慧？

![](img/85a61ca292d8bec9c836af4abfb08f9c.png)

虽然可能存在一种普遍的智能，而人类的智能只是其中的一部分，但我们还没有超越模仿人类大脑的生物学。人工神经网络(ANN)是大脑神经网络模型的数字版本，它幸存了下来，并成为现代人工智能的主要工具。今天，神经模型对于人工智能应用就像晶体管对于整个计算机系统一样。

**目标**

这一系列文章的目标是以最简单直观的方式解释人工神经网络的本质。ANN 的本质是在训练过程中。

这个职位的目标是为人工神经网络的训练技术的研究奠定基础。该技术本身将在下一篇文章中探讨。

**这篇文章不同——它很冗长，几乎没有代码。**

这篇文章试图通过关注一个最简单的问题来区分自己，同时保留通用性和与现代人工智能视野的联系。尽管我们将与一个单一维度的特征进行斗争，但它暗示了多维度特征的普遍性。不要迷于多维度，而要迷于本质。简单中更能体现精髓。

如果这篇文章的部分内容重复冗长，部分原因是我试图谈论月球的另一面。很少有人关注安的阴暗面。我想照顾那些深刻的思考者，他们会提出一系列关于人工神经网络基础的问题。谈论直觉在 ANN 中的作用是这篇文章的特色之一。

**智能代理**

一个被广泛接受的人工智能框架假设了一个智能代理、代理的目标和环境。

![](img/bfb145ff74b04710445b3e7520a5c6b1.png)

[https://gungorbasa.com/intelligent-agents-dc5901daba7d](https://gungorbasa.com/intelligent-agents-dc5901daba7d)

一个常见的误解倾向于将机器人视为智能代理。很多情况下都是错的。智能代理不执行动作，而是选择动作。执行动作的主体是执行器。在这方面，致动器属于环境。

采取行动的机器人=

*   选择动作的软件(智能代理)，加上
*   执行动作的腿(致动器)。

![](img/f19bd3330bea3c5a3dac708dc7591cc7.png)

对代理的关键要求是代理必须完全控制自己。机器人的腿可能无法完成程序选择的命令。这意味着机器人不能完全控制自己。对自身有控制力的是程序。

**训练和预测**

我们用已知的环境事实训练智能代理，希望代理能预测未来未知的事实。

*   培训=让代理了解一些事实
*   预测=代理建议一个符合目标的新事实

或者，等价地

*   培训=让代理体验环境
*   预测=代理为给定的状态选择一个动作，以达到一个目标

我们将从一个鸡蛋问题开始:

*   一只母鸡在一月份下了五个蛋。她在三月份生了 25 个孩子。
*   (预测)她二月下了几个？

**特征空间、标签空间和事实空间**

智能代理现在知道两个事实:

*   这只母鸡在一月下了五个蛋。
*   这只母鸡在三月下了 25 个蛋

事实有两个组成部分:一组特性和一个标签。

*   特征集[一月]用标签[5 个蛋]标注，
*   特征集[March]用标签[25 个蛋]标注。

你有没有注意到我们正在逐渐从事实中去除特定领域的知识？我们移走母鸡，下蛋，然后下蛋。为什么不进一步去掉月和蛋呢？所以，事实被提炼为如下:

*   (1, 5)
*   (3, 25)

二维实空间 RxR 是容纳鸡蛋事实的最小空间。RxR 的第一个 R 是特性，另一个 R 是标签。因此，事实空间是特征空间和标签空间的产物。

![](img/1d3a96cfcbb9beee1d62c923d9c3052a.png)

事实是一对特征和它的标签

因此，鸡蛋问题可以定义如下，这是一个统计定义:

*   已知的事实有:(1，5)和(3，25)
*   如果(2，x)是事实，那么 x 是什么？

**一点领域知识都没有？**

问题的统计定义意味着我们忽略了领域知识——母鸡、下蛋、鸡蛋、月份等，尽管这对于解决问题有很大的帮助，甚至是关键的帮助。现代人工智能更关注数据而不是语义。这叫做统计方法。

虽然我们必须将领域技术(这里是母鸡生物学)与纯人工智能技术结合起来，以获得最大的成就，但出于本文的目的，让我们来看一下统计数据。把生物学研究留给别人吧。

**预言是独一无二的？相信直觉**

"如果(2，x)是事实，那么 x 是什么？"

这样的 x 到底存在吗？会是独一无二的吗？

以下哪一项是正确的？

*   这只母鸡在二月下了 17 个蛋
*   这只母鸡在二月下了六个蛋
*   这只母鸡在二月不下蛋

一抛开领域知识，15 个鸡蛋似乎是最直观的答案。我们知道我们的直觉有缺陷，尽管它反映了自然。例如，直觉似乎更喜欢单调的曲线，比如“越…越…”，而自然界则受波动曲线支配，就像正弦函数一样。直觉意味着简单自然。

![](img/dbcb080f97d30afb0cbecaa4835d7921.png)

一旦我们相信自己的直觉，解决问题的方法就是独一无二的。已经 15 了！我们在现实中尝试了 15 次。它工作了。搞定了。

如果它碰巧不起作用，那么我们用更多的事实来训练代理。潜在的基础是我们对直觉的信仰。

所以，这个预测是独一无二的，当它基于人类的直觉。这是一个直观的预测。直觉的缺陷将由数据的绝对大小和与数据大小匹配的计算的可用性来补偿。计算机可以将数以百万计的直观、简单和自然的思维层层叠加，形成一个巨大的智能机器，可以对数据和自然进行深入的探索。这似乎是 AI 社区的当代观点。

我们的直觉是大自然赐予的伟大礼物。太大了，以至于有时会深入大自然。爱因斯坦的相对论，嵌入模型的词，…

*   人类直觉*大数据*可扩展计算=现代人工智能
*   简单是最复杂的——达芬奇？

我们将在下一篇文章中再次讨论简单和直觉。

**分析与务实**

创建智能模型有两种基本方法:

*   分析/象征
*   实用/统计

分析解决方案可以:

*   当 x = 1 时 y = 5，
*   当 x = 3 时，y = 25。
*   所以，y = 10 * x -5，一般来说。

听起来很完美，不是吗？

![](img/93cb48fcfe5458d7e32d7aa03dfceee2.png)

特定领域的分析方程。很好，但在人工智能方面价值较低。

但是，世界上有多少关系可以用这样一个优雅的数学方程来表达呢？在那些有解析方程的关系中，有多少会用已知的初等函数，象征性地揭示它的方程，这样我们就可以在上面练习了？我不想在这里贬低数学。我自己其实也是个数学家，看到数学在其他方面的价值。即使是统计学上的，我们也不能依赖解析解。

**务实的解决方案**

历史似乎更喜欢人工智能中的非分析、非线性、领域中立、计算密集型、数据密集型、统计和实验方法。这里列举的属性是相互补充和支持的。人工神经网络似乎是拥有所有这些特性的最合适的技术。

![](img/37e5cc71a6163b0f2688c772a8fea822.png)

在实践中起作用的一切都是务实的解决方案，无论它看起来多么卑微和凌乱。对严格数学感兴趣的学生会发现在一个人工神经网络中有这么多冗余变量(权重)是很麻烦的。他们错了，因为正是精心设计的复杂冗余让 ANN 如此成功。冗余“融化”到非线性曲线的奇角。**安是对的，更多的是因为人工神经网络真的工作，而不是因为人工神经网络的冗余是复杂的。**

![](img/a6ffe7f7625ccc104d8662128dcb456d.png)

不太关注神经生物学

在这方面，不要太关注神经生物学，除非你想发明一种全新的人工神经网络范式，超越人工智能的伟大成就。务实一点。

**最简单的型号，从零开始**

对于我们的鸡蛋问题，最简单的神经元模型如下:

![](img/60b9df67459b8c9f03d23e9ff8fbea2c.png)

**通用神经模型**

我们得出了一个线性模型:out = 10 * in -5，或者 y = w * x + b。

这是一个线性回归模型。虽然我们知道线性回归是多么流行和强大，但我们希望神经模型能够将线性回归模型作为其特例。唯一的方法是在线性回归模型上放一个(非线性)函数。我们将得到一个通用模型:

y = f ( w * x + b)

![](img/668b06b6dc27ed30b8c08b78725b2455.png)

线性激活函数。

函数 f 称为激活函数。激活函数的巨大作用将在下一篇文章中解释。

如果 f(x) = x，那么 y = w * x + b，这是一个线性模型。现在，神经模型概括了线性模型。典型的人工神经网络模型内部有数百个以复杂方式编织的神经模型。请注意，彼此线性连接的线性回归模型没有任何意义，因为它们只会产生一个线性模型。但是，层层叠加的神经元产生了一个全新的模型空间。

[y = f2 ( w2 * f1 ( w1 * x + b1) + b2]与[y = w * x + b]

激活函数是人工神经网络模型的核心。如果把它变成线性的，这个模型将会是一堆无情的直东西。决定人工神经网络模型成败的向导是激活函数，它使模型比线性回归模型更好或更差。我们以后将有机会谈论它。

为了简单起见，我们暂时假设激活函数为 f(x) = x。这意味着我们有一个线性的，或者没有激活函数。

**务实地像昆虫一样爬向模特**

你是怎么找到第三款[out = 10 * in -5]的？诚实地说“我是通过代数分析做到的。”

对于少数像我们这样简单的问题，我们可以一下子找到一个显式的分析模型。但是绝大多数现实世界的问题都没有分析模型，或者不愿意揭示它。我们必须保持务实，努力爬行到模型，无论它有多慢，而不是立刻从天空射下一颗星星。现代的人工智能正在这样做。具体是怎样的？

在空间中“爬行”之前，我们需要定义模型和模型空间。

**什么是模型，再说一遍？**

慢慢地，我们变得数学化，而不是分析化。从狭义上讲，模型是从特征到标签的映射，它捕捉了现实中最少的必要信息。

*   模型:特征空间→标签空间
*   模型(特征)=特征上的标签

如前所述，我们问题的事实空间是 R x R。我们有两个事实:事实 1 和事实 2，它们只是模型的最小部分。例如，fact1 意味着模型(1)=5。

![](img/1d3a96cfcbb9beee1d62c923d9c3052a.png)

模型可以在事实空间上被描述为从特征空间到标签空间的映射。

![](img/e87c1008e909c45785bb5c6cc1618b11.png)

**车型，客观和主观**

我们可以发现每个问题都有两个模型。一个是客观模型，一个是主观模型。我们相信客观模型即使未知也是存在的。它必须精确地符合已知的事实。

![](img/fc6fdd0a82bab4e5e5c55d13c59014d2.png)

客观模型必须精确地符合已知的事实。除此之外，我们一无所知。

我们希望找到并使用一个尽可能接近客观模型的模型，这个模型叫做主观模型。主观模型是我们用来代替客观模型的最新模型。

(监督)学习的总体实践是将主观模型推向客观模型。我们通过驱动主观模型，向未知的客观模型爬行。

![](img/72b8efa3474ac3ab1560d02efb5bc85a.png)

爬行到 OM 之字形

在我们的先有鸡还是先有蛋的问题中，目标模型是什么？

我们不知道确切的数字。

但是，如果我们相信我们的直觉，并且如果这两个事实是我们所知道的关于客观模型的一切，那么最好的主观而非客观模型应该是如下的:

![](img/a5be78dbe367613125c680d32385c9fa.png)

客观模型应该接近最佳主观模型。

**如何找到目标模型在哪里？**

我们一定要找到它吗？

不。也不可能。我们所要做的就是将主观模型(SM)转化为客观模型(OM)。想办法把 SM 推到 OM 就够了。

客观模型是直接知道的，但部分是通过已知事实知道的。在我们的鸡蛋问题中，OM(1) = 5，OM(3) = 25。

**开始把我们的 SM 驶向 OM！**

我们要把我们的 SM 推向 OM，但是最初的 SM 是什么？人工智能实践对初始 SM 采用随机模型。

问题 03:为什么 AI 倾向于依赖随机性？有意思。

假设我们的随机，初始 SM 是[y = -10 x + 25]，如下所示:

![](img/4f16ada46b56f98ca0359980a4d640ee.png)

**该介绍模型空间了**

当我们要推动我们的 SM 走向 OM 时，我们必须考虑策略:起点、目标点和各点之间的路线图。道路上所有的点都是一个模型，我们需要一个底图显示所有可能的模型，这个底图就是模型空间。

不同的问题有不同类型的模型空间。如果我们确信母鸡生蛋问题有一个线性模型，一个模型的形式为 y = w*x + b，用(w，b)表示，模型空间为 R * R。

小心，模型空间可能不包含 OM。我们不能像 SM 那样假设 OM 具有 y = w*x + b 的形式。OM 通常更复杂，不太可能像 SM 那样有解析表达式。模型空间仅用于 SM。

![](img/1b3c0d2dfa593fe1122365e6a14b852d.png)

*   目标 OM 在哪里？—它是通过已知的事实部分知道的。
*   如何靠近奥姆？——我们可以部分地找到它，因为 OM 在哪里是部分已知的。

在我们致力于发现如何接近奥姆之前，我们必须再次弄清楚我们为什么要这样做。让我们在出发前明确目标。

**我们为什么这样做**

一旦我们做到了这一点，并将 SM 驱动到 SM 附近的最终点，我们将使用 SM 代替 OM，并找到 SM(2):母鸡在二月下了多少蛋？对新事实的预测、发明。

![](img/ae8dd3ec4c83ec4a0b74914df7ff0485.png)

整个过程只是从已知的事实中归纳出新的事实，新的真相。再自然不过了。我们必须跨越的唯一障碍是我们必须相信直觉。

![](img/c1911d6222c0e2febf54e9b03f742210.png)

像昆虫一样爬行。曲折像一个最愚蠢的生物，走向智慧。如何爬行？让我把它留给下一个帖子。

![](img/72b8efa3474ac3ab1560d02efb5bc85a.png)

**总结**

这个职位的目标是为人工神经网络的训练技术的研究奠定基础。到目前为止，在这篇文章中，我们通过一个最简单的问题得到了一个抽象而直观的神经模型图像。在保持问题尽可能简单的同时，我们探索了与实用人工智能领域的联系。纯数学家对人工神经网络的可能拒绝也被考虑在内。

现在，我们准备开始学习人工神经网络的精髓——训练技术。让我把它留给下一个帖子。我不会像在这篇文章中那样啰嗦，因为 AI 的许多奇怪的东西都来自它的实用主义本质，在这篇文章中已经解释过了。

**追加动员讲话**

不要害怕训练依赖于对直觉的信仰。人工智能有一些既定的方法来验证和测试学习的结果。请注意，人工智能似乎还没有在关键应用中普及，如空中交通管制和核反应堆控制。然而，也有令人鼓舞的成就。

有一天，我用英语写了一份商业计划书，谷歌把它翻译成了中文。为了验证，我用谷歌把中文版翻译成英文，生成了一个新的英文版。对比新旧英文版本，我发现新版本甚至比旧版本更好！(我的母语不是英语。)原来译者一个来回的翻译，一点语境都没丢！它甚至丰富了文档！

When I put “the chairman” in each of two successive sentences in doubt of the translator’s ability to track context, the second one was replaced with 他 — he/him in Chinese! I felt horrified. There seemed to be a man behind the screen monitoring me and my context! Have a look into the modern Natural Language Processing, and Machine Translation, in particular. Behind the google translator, there are digital neurons and simple intuition but layered and paralleled hundreds times.

人工神经网络的伟大成就之一是单词嵌入，通过单词嵌入，单词被分解成多个主成分。主成分不是从外部强加的。相反，它们是由人工神经网络模型感知的。人工神经网络模型也能感知到组件的分解。研究每个组成部分的含义会很有趣。一想到一百万个单词中的任何一个都是 300 个基本概念的组合，就令人兴奋。

单词嵌入是我们语言使用的数字模型，它最深刻地反映了文化，导致奇妙的应用。看看这个模型是如何工作的:

```
model.most_similar(positive=['woman', 'king'], negative=['man'])
'queen': 0.7
(The word that is most [similar to 'woman' & 'king' and dissimilar to 'man'] is 'queen'. The score is 0.7)model.doesnt_match("Apple, Microsoft, IBM".split())
'IBM'
('IBM' is the least integral to the word group. We know Apple and Microsoft are related to each other more closely than they are to IBM. They two are direct competitors.)model.doesnt_match("bank, account, river".split())
'river'
(A bank account is shown more often in our life than the bank of river.)model.similar_by_word("cat")
'dog': 0.8
(The word 'dog' is most similar to 'cat', in terms of what?)# Joking below:model.who_are_you(?)
I am nothing with millions of simple neural models interwoven with each other.model.what_shall_I_do_to_master_ANN(?)
Understand exhaustively a simplest neural model, and then study how to interweave them to get a goal.
```

我们将在下一篇文章中深入探讨训练的艺术。

> 这篇文章之后是另一篇文章:[人工神经网络-2，对我的儿子](/@fleetpro/artificial-neural-networks-2-explained-differently-to-my-son-e9fcfa19a5b7)有不同的解释。