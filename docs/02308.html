<html>
<head>
<title>Spark Structured Streaming Deep Dive</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">火花结构化流深潜</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/spark-structured-streaming-deep-dive-79fb236db22c?source=collection_archive---------14-----------------------#2019-12-10">https://medium.com/analytics-vidhya/spark-structured-streaming-deep-dive-79fb236db22c?source=collection_archive---------14-----------------------#2019-12-10</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/daa0add79fa0cf0061b425e6d97534b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*qvVMbMkKwPts-6Jf"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">Jez Timms 在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="0df1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这篇文章是关于spark结构化流的。关于spark结构化流的一个重要事实是，它基于<strong class="ix hj"> DataFrame API。</strong></p><p id="980b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">spark dataframe api的一个重要方面是使用现有的dataframe数据源，如JDBC JSON CSV等，我们将编写我们的处理逻辑，如过滤无效记录等，然后最终在使用writeStream时触发实际计算</p><p id="98fd" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们看看涉及流式应用程序的步骤</p><ol class=""><li id="4b5a" class="jt ju hi ix b iy iz jc jd jg jv jk jw jo jx js jy jz ka kb bi translated">连接到信号源</li><li id="f0e4" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">使用DataFrame API在流上应用转换逻辑(创建DAG)</li><li id="7274" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">使用writeStream写入接收器时触发写入的逻辑</li><li id="6c3c" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">检查点和为什么我们需要检查点</li><li id="5d7e" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">正在验证输出文件夹和配置单元中的输出</li><li id="bed5" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">通过添加新文件检查流式应用程序</li><li id="eaab" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">不同类型的信号源和输出模式选项(续)</li></ol><p id="90bb" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">准备输入和输出</strong></p><p id="b447" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这里的基本用例是在数据持续到达源目录时读取csv文件，我们将过滤无效记录，并将清理后的记录存储到输出路径中，然后将输出更新到包含聚合统计信息的配置单元表中。</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div class="er es kh"><img src="../Images/d9c97135744b7be0d4ff048f8d87fe35.png" data-original-src="https://miro.medium.com/v2/resize:fit:872/format:webp/1*HkNmo0GkZwJ243l2VwXTkA.png"/></div></figure><p id="9618" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">第一步:连接信号源</strong></p><p id="ed7e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">Spark现在允许以下来源</p><ol class=""><li id="e7d3" class="jt ju hi ix b iy iz jc jd jg jv jk jw jo jx js jy jz ka kb bi translated">战斗支援车</li><li id="8560" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">JSON</li><li id="3f60" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">镶木地板</li><li id="8d38" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">妖魔</li><li id="6bb3" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">速率-速率源是用于测试目的的测试源(将在另一篇文章中介绍源和目标)</li></ol><p id="0984" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">对于我们的示例，我们将使用csv作为源</p><p id="295d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们将使用readstream API从源目录中读取数据</p><p id="fe03" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> <em class="km">由于spark Readstream返回一个dataframe对象，我们可以使用schema、header等选项，spark.readStream.csv如下所示</em> </strong></p><figure class="ki kj kk kl fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kn"><img src="../Images/4ac5f755f14f368764c27dc72682e117.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wBAa5Sjc7_X9l5hKu8nn-A.png"/></div></div></figure><p id="1bf3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们可以看到spark流与批处理查询相同，我们可以使用is_streaming检查它是否是一个流，我们还将使用type命令验证readstream是否为dataframe类型</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div class="er es ko"><img src="../Images/c83416c8e15a76662f93778c0595acad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1240/format:webp/1*xHXNCTbkw6fvLW5VKcQhFA.png"/></div></figure><p id="4454" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">步骤2:使用DataFrame API(创建DAG)在流上应用转换逻辑</strong></p><p id="ae48" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">下一步是我们将创建两个流逻辑</p><ol class=""><li id="b5e3" class="jt ju hi ix b iy iz jc jd jg jv jk jw jo jx js jy jz ka kb bi translated">将过滤负交易的DF_filter</li><li id="7505" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">DF_group，它将聚合opt并将其写入配置单元</li></ol><p id="eed8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> DF_Filter </strong></p><p id="b1ea" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">由于上述流式查询是数据帧，我们将使用如下所示的过滤器过滤负面记录</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div class="er es kp"><img src="../Images/ba2ebc340164895c4bb2cd723606fa84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1072/format:webp/1*7bDbtk-qFy7Dph7kqZQnzA.png"/></div></figure><p id="9048" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> DF_group </strong></p><figure class="ki kj kk kl fd ij er es paragraph-image"><div class="er es kq"><img src="../Images/3c8c58d327a72b76ecf85f331ad7c433.png" data-original-src="https://miro.medium.com/v2/resize:fit:1162/format:webp/1*fA7bQSwCBdk38FYWZd_mcw.png"/></div></figure><p id="f9a5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">因为spark stream很懒，所以在触发查询之前我们看不到任何结果，</p><p id="63a4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">因此，定义任何显示结果的操作都会导致下面的异常</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kr"><img src="../Images/f33d48b7fc80eb05297ba786c210c127.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*boKA6FUqOR1aejRoC1smoQ.png"/></div></div></figure><p id="bfb4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">步骤3:使用writeStream触发写入接收器时写入的逻辑</strong></p><p id="a9c8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">1.将过滤后的有效记录写入opt文件夹</p><p id="3aaf" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">将过滤后的有效记录写入opt文件夹</strong></p><p id="1740" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们可以使用writestream启动流，然后如下所示给出start</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ks"><img src="../Images/15b95d2174d7be8a13b913a3f18834ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X3ZjXGU7G9cEHCSjjxOiLw.png"/></div></div></figure><p id="864d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">检查点和我们为什么需要检查点</strong></p><p id="3947" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这里的问题是写入像csv、orc这样的持久存储需要一个检查点位置，spark将从该位置检查以确保相同的数据不会被重新处理，因为它将包含已处理文件的列表</p><p id="cf6c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">设置检查点目录并重新运行流</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kt"><img src="../Images/348445a4167b295c45a20ca700d43b14.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t3X3ft_6TbKjM2_xHX8Cig.png"/></div></div></figure><p id="b8bc" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在保存流时，我们需要指定3个重要选项:</p><ol class=""><li id="5d78" class="jt ju hi ix b iy iz jc jd jg jv jk jw jo jx js jy jz ka kb bi translated">格式-csv</li><li id="27b9" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">output Mode-默认模式追加-允许更新，追加完成</li><li id="3ff1" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">触发(默认为0秒)spark应用程序应该在多少秒后检查输入目录(将在另一篇文章中讨论)</li></ol><p id="491e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">验证输出:</strong></p><p id="5f89" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">验证过滤的数据选项</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ku"><img src="../Images/4951e72c7b9d995f12e216c29653d999.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gjntff7D6bq5p6AxI_OOjg.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">正如我们看到的负面记录不见了</figcaption></figure><p id="a2eb" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">通过添加新文件检查流媒体应用</strong></p><p id="26c2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">当我们添加新文件时，spark会自动处理流逻辑，如下所示，输出文件夹也会更新，如下所示</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kv"><img src="../Images/583c9c7f7ce37ae929a6e172fcfa440e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g_qonsjcVNuc4Y6HLOmk7Q.png"/></div></div></figure><p id="7b7d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">今天就到这里吧！！:)</p><p id="01ee" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">Github链接:<a class="ae iu" href="https://github.com/SomanathSankaran/spark_medium/tree/master/spark_csv" rel="noopener ugc nofollow" target="_blank">https://github . com/SomanathSankaran/spark _ medium/tree/master/spark _ CSV</a></p><p id="9f31" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"/></p><p id="e229" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">学习并让别人学习！！</strong></p></div></div>    
</body>
</html>