<html>
<head>
<title>The journey of a Deep Neural Network Model.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度神经网络模型之旅。</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/the-journey-of-a-deep-neural-network-model-3a7697c88f7b?source=collection_archive---------13-----------------------#2020-02-23">https://medium.com/analytics-vidhya/the-journey-of-a-deep-neural-network-model-3a7697c88f7b?source=collection_archive---------13-----------------------#2020-02-23</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/805ffe19f5c91e477bc07ef53c2b1502.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/0*C7BM-NRxioYwu1IV.gif"/></div></figure><h1 id="59ed" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">第一轮</h1><p id="9eab" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">在第一轮中，我们将使用Pytorch为我们的DNN设置基本的代码设置。</p><figure class="kj kk kl km fd ij er es paragraph-image"><div class="er es ki"><img src="../Images/d557e49fc93386ec984c9ee2c839ee47.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/0*GY-rLN8f5hqmZ_qY.gif"/></div></figure><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="er es kn"><img src="../Images/3589b8e684b5a852f58b436c3889cb0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1086/0*Muv1ilXcGpz7W4Qk.gif"/></div></div></figure><p id="f466" class="pw-post-body-paragraph jk jl hi jm b jn ks jp jq jr kt jt ju jv ku jx jy jz kv kb kc kd kw kf kg kh hb bi translated">代码链接:-</p><div class="kx ky ez fb kz la"><a href="https://github.com/rashutyagi/Journey-of-a-DNN/blob/master/Round%20-%201%20Code%20Setup.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="lb ab dw"><div class="lc ab ld cl cj le"><h2 class="bd hj fi z dy lf ea eb lg ed ef hh bi translated">拉舒塔吉/DNN之旅</h2><div class="lh l"><h3 class="bd b fi z dy lf ea eb lg ed ef dx translated">permalink dissolve GitHub是4000多万开发人员的家园，他们一起工作来托管和审查代码，管理…</h3></div><div class="li l"><p class="bd b fp z dy lf ea eb lg ed ef dx translated">github.com</p></div></div><div class="lj l"><div class="lk l ll lm ln lj lo ik la"/></div></div></a></div><h1 id="2bf2" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">结果:-</h1><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="er es lp"><img src="../Images/c485ae56bf53eeb0d2245402e707bb5f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1286/format:webp/1*vg4hRammd0d75vJ4vA2rjg.png"/></div></div></figure><h2 id="753e" class="lq in hi bd io lr ls lt is lu lv lw iw jv lx ly ja jz lz ma je kd mb mc ji md bi translated">1.)最佳训练准确率:99.99%</h2><h2 id="08b6" class="lq in hi bd io lr ls lt is lu lv lw iw jv lx ly ja jz lz ma je kd mb mc ji md bi translated">2.)最佳测试准确率:99.41%</h2><h2 id="65dc" class="lq in hi bd io lr ls lt is lu lv lw iw jv lx ly ja jz lz ma je kd mb mc ji md bi translated">3.)参数数量:630万。</h2><h2 id="862e" class="lq in hi bd io lr ls lt is lu lv lw iw jv lx ly ja jz lz ma je kd mb mc ji md bi translated">正如我们可以看到的，我们的最佳训练精度为99.99%，最佳测试精度仅为99.41%，这意味着我们的模型无法进一步推进，因为它已经实现了99.4%的如此高的训练精度，并且与测试精度有很大的差距，因此模型过度拟合。</h2><h2 id="b96b" class="lq in hi bd io lr ls lt is lu lv lw iw jv lx ly ja jz lz ma je kd mb mc ji md bi translated">此外，请注意，对于这样一个简单的用例，我们使用了630万个参数，因此我们可以说，对于这样一个问题，它是一个极其沉重的模型。</h2><h2 id="14c1" class="lq in hi bd io lr ls lt is lu lv lw iw jv lx ly ja jz lz ma je kd mb mc ji md bi translated">转到第二轮，我们尝试进一步改进。</h2><h1 id="f30f" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">第二轮</h1><p id="33cd" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">在第一轮中，我们使用了类似的任何东西，如通道数和层数，我们必须记住，我们需要检查参数的数量，因此让我们在这一轮中尝试为我们的模型创建基本框架。</p><p id="8c7c" class="pw-post-body-paragraph jk jl hi jm b jn ks jp jq jr kt jt ju jv ku jx jy jz kv kb kc kd kw kf kg kh hb bi translated">代码链接:-</p><div class="kx ky ez fb kz la"><a href="https://github.com/rashutyagi/Journey-of-a-DNN/blob/master/Round%20-%202%20Basic%20Skeleton..ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="lb ab dw"><div class="lc ab ld cl cj le"><h2 class="bd hj fi z dy lf ea eb lg ed ef hh bi translated">拉舒塔吉/DNN之旅</h2><div class="lh l"><h3 class="bd b fi z dy lf ea eb lg ed ef dx translated">permalink dissolve GitHub是4000多万开发人员的家园，他们一起工作来托管和审查代码，管理…</h3></div><div class="li l"><p class="bd b fp z dy lf ea eb lg ed ef dx translated">github.com</p></div></div><div class="lj l"><div class="me l ll lm ln lj lo ik la"/></div></div></a></div><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="er es mf"><img src="../Images/39d9a9a4181b92cecb80e5c614fb5db4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ri5XSbfEsQbM7qbb8fnMyg.png"/></div></div></figure><h2 id="6a75" class="lq in hi bd io lr ls lt is lu lv lw iw jv lx ly ja jz lz ma je kd mb mc ji md bi translated">结果:-</h2><h2 id="5ace" class="lq in hi bd io lr ls lt is lu lv lw iw jv lx ly ja jz lz ma je kd mb mc ji md bi translated">1.)最佳训练准确率:99.41%</h2><h2 id="a53a" class="lq in hi bd io lr ls lt is lu lv lw iw jv lx ly ja jz lz ma je kd mb mc ji md bi translated">2.)最佳测试准确率:99.01%</h2><h2 id="70b5" class="lq in hi bd io lr ls lt is lu lv lw iw jv lx ly ja jz lz ma je kd mb mc ji md bi translated">3.)参数数量:194000</h2><h2 id="190e" class="lq in hi bd io lr ls lt is lu lv lw iw jv lx ly ja jz lz ma je kd mb mc ji md bi translated">该模型的参数数量仍然很多，因此模型仍然很大，尽管我们已经减少了过拟合，但模型中仍然存在一些过拟合。</h2><p id="84e3" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">通过过度拟合，我的意思是测试精度和训练精度之间的差异有点高，并且训练精度被推得如此之高，以至于进一步增加它将无助于增加测试精度。</p><h2 id="b84d" class="lq in hi bd io lr ls lt is lu lv lw iw jv lx ly ja jz lz ma je kd mb mc ji md bi translated">转到第3轮，我们尝试进一步改进。</h2><h1 id="f3cb" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">第三轮</h1><p id="5ce1" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">在这一轮中，我们将尝试建立一个具有更少参数的更轻的模型，并且可以通过减少模型的容量来减少参数的数量，这意味着减少层中的通道数量。</p><figure class="kj kk kl km fd ij er es paragraph-image"><div class="er es mg"><img src="../Images/2d83b1308054a7c4e41e8cb81db61dc2.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/0*GNZHofrtHGqmugVY.gif"/></div></figure><p id="0508" class="pw-post-body-paragraph jk jl hi jm b jn ks jp jq jr kt jt ju jv ku jx jy jz kv kb kc kd kw kf kg kh hb bi translated">代码链接:-</p><div class="kx ky ez fb kz la"><a href="https://github.com/rashutyagi/Journey-of-a-DNN/blob/master/Round%20-%203%20Lighter%20Model.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="lb ab dw"><div class="lc ab ld cl cj le"><h2 class="bd hj fi z dy lf ea eb lg ed ef hh bi translated">拉舒塔吉/DNN之旅</h2><div class="lh l"><h3 class="bd b fi z dy lf ea eb lg ed ef dx translated">permalink dissolve GitHub使上下文切换变得容易。阅读渲染文档，查看历史记录…</h3></div><div class="li l"><p class="bd b fp z dy lf ea eb lg ed ef dx translated">github.com</p></div></div><div class="lj l"><div class="mh l ll lm ln lj lo ik la"/></div></div></a></div><figure class="kj kk kl km fd ij er es paragraph-image"><div class="er es mi"><img src="../Images/747e1900f9493c126ab75c09844c4837.png" data-original-src="https://miro.medium.com/v2/resize:fit:1336/format:webp/1*9H4XnBlWRPDyWGqchCSUsQ.png"/></div></figure><h2 id="df3a" class="lq in hi bd io lr ls lt is lu lv lw iw jv lx ly ja jz lz ma je kd mb mc ji md bi translated">结果:-</h2><h2 id="b866" class="lq in hi bd io lr ls lt is lu lv lw iw jv lx ly ja jz lz ma je kd mb mc ji md bi translated">1.)最佳训练准确率:98.92%</h2><h2 id="ebbd" class="lq in hi bd io lr ls lt is lu lv lw iw jv lx ly ja jz lz ma je kd mb mc ji md bi translated">2.)最佳测试准确率:98.87%</h2><h2 id="def0" class="lq in hi bd io lr ls lt is lu lv lw iw jv lx ly ja jz lz ma je kd mb mc ji md bi translated">3.)参数数量:10，790</h2><h2 id="5a89" class="lq in hi bd io lr ls lt is lu lv lw iw jv lx ly ja jz lz ma je kd mb mc ji md bi translated">这里的参数数量太少，而且我们的模型在这些参数上也表现得很好。模型中完全没有过拟合，如果我们将模型推得更远一点，精度可以提高。</h2><h2 id="83e5" class="lq in hi bd io lr ls lt is lu lv lw iw jv lx ly ja jz lz ma je kd mb mc ji md bi translated">转到第4轮，我们将尝试进一步改进。</h2><h1 id="4a0f" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">第4轮:-</h1><p id="1223" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">现在我们将应用一个叫做批量标准化的概念。我们将发现用于加速深度学习神经网络训练的<strong class="jm hj">批量归一化</strong>方法<strong class="jm hj">。</strong></p><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="er es mj"><img src="../Images/b5d0d5a98cd44bc4e47a98c8b64b9a6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*m_24cRWgI5IWJUy9.jpg"/></div></div></figure><p id="5a19" class="pw-post-body-paragraph jk jl hi jm b jn ks jp jq jr kt jt ju jv ku jx jy jz kv kb kc kd kw kf kg kh hb bi translated">代码链接:-</p><div class="kx ky ez fb kz la"><a href="https://github.com/rashutyagi/Journey-of-a-DNN/blob/master/Round%20-%204%20Applying%20Batch%20Normalization..ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="lb ab dw"><div class="lc ab ld cl cj le"><h2 class="bd hj fi z dy lf ea eb lg ed ef hh bi translated">拉舒塔吉/DNN之旅</h2><div class="lh l"><h3 class="bd b fi z dy lf ea eb lg ed ef dx translated">permalink dissolve GitHub是4000多万开发人员的家园，他们一起工作来托管和审查代码，管理…</h3></div><div class="li l"><p class="bd b fp z dy lf ea eb lg ed ef dx translated">github.com</p></div></div><div class="lj l"><div class="mk l ll lm ln lj lo ik la"/></div></div></a></div><figure class="kj kk kl km fd ij er es paragraph-image"><div class="er es ml"><img src="../Images/59be185891234f1e347d3fd6be7c493e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1272/format:webp/1*SSgYzF013EbWOaoHP9QFSQ.png"/></div></figure><h2 id="f9d9" class="lq in hi bd io lr ls lt is lu lv lw iw jv lx ly ja jz lz ma je kd mb mc ji md bi translated">结果:-</h2><h2 id="a2f2" class="lq in hi bd io lr ls lt is lu lv lw iw jv lx ly ja jz lz ma je kd mb mc ji md bi translated">1.)最佳训练准确率:99.90%</h2><h2 id="b45c" class="lq in hi bd io lr ls lt is lu lv lw iw jv lx ly ja jz lz ma je kd mb mc ji md bi translated">2.)最佳测试准确度:99.25%</h2><h2 id="b076" class="lq in hi bd io lr ls lt is lu lv lw iw jv lx ly ja jz lz ma je kd mb mc ji md bi translated">3.)参数数量:10，760</h2><h2 id="3303" class="lq in hi bd io lr ls lt is lu lv lw iw jv lx ly ja jz lz ma je kd mb mc ji md bi translated">这里的参数数量太少，而且我们的模型在这些参数上也表现得很好。但是在模型中存在过度拟合，因为我们可以看到这次训练和测试精度之间的差距非常大。而且训练准确率不能再推一点，才能让我们的测试准确率达到99.4%。</h2><h2 id="ad41" class="lq in hi bd io lr ls lt is lu lv lw iw jv lx ly ja jz lz ma je kd mb mc ji md bi translated">为了消除过度拟合，我们使用正则化技术。</h2><h2 id="46ad" class="lq in hi bd io lr ls lt is lu lv lw iw jv lx ly ja jz lz ma je kd mb mc ji md bi translated">转到第5轮，我们尝试进一步改进。</h2><h1 id="2e9b" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">第5轮:-</h1><p id="f400" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">正如我们在第4轮模型中看到的，我们的模型中有很多过度拟合，因此我们的直接步骤是减少过度拟合，以更好地概括我们的模型，从而减少训练和测试准确性之间的差距。</p><p id="e5e5" class="pw-post-body-paragraph jk jl hi jm b jn ks jp jq jr kt jt ju jv ku jx jy jz kv kb kc kd kw kf kg kh hb bi translated">为了处理过度拟合，我们使用正则化的概念。有各种各样的正规化技术，其中一种就是我们将在第五轮中使用的“辍学”技术。</p><figure class="kj kk kl km fd ij er es paragraph-image"><div class="er es mm"><img src="../Images/3aab015ae4efae3e4ada2d66083f7a35.png" data-original-src="https://miro.medium.com/v2/resize:fit:920/0*oXAAx5d6L1YQSZ_U.gif"/></div><figcaption class="mn mo et er es mp mq bd b be z dx translated">辍学。</figcaption></figure><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="er es mr"><img src="../Images/a90d9f816ac9edf510aba56181fb226a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*gkw_kYYTn_WqaWvP.png"/></div></div></figure><h1 id="3f44" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated"><strong class="ak">代码链接:- </strong></h1><div class="kx ky ez fb kz la"><a href="https://github.com/rashutyagi/Journey-of-a-DNN/blob/master/Round%20-%205%20Bringing%20In%20Regularization.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="lb ab dw"><div class="lc ab ld cl cj le"><h2 class="bd hj fi z dy lf ea eb lg ed ef hh bi translated">拉舒塔吉/DNN之旅</h2><div class="lh l"><h3 class="bd b fi z dy lf ea eb lg ed ef dx translated">permalink dissolve GitHub是4000多万开发人员的家园，他们一起工作来托管和审查代码，管理…</h3></div><div class="li l"><p class="bd b fp z dy lf ea eb lg ed ef dx translated">github.com</p></div></div><div class="lj l"><div class="ms l ll lm ln lj lo ik la"/></div></div></a></div><figure class="kj kk kl km fd ij er es paragraph-image"><div class="er es mt"><img src="../Images/5c05a0236655f25cd2df343442b3b00b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1232/format:webp/1*CJOQxJ49NE-G43jHp8WZDA.png"/></div></figure><h1 id="47c7" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">结果:-</h1><h1 id="c783" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">1.)最佳训练准确率:99.53%</h1><h1 id="a871" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">2.)最佳测试准确率:99.35%</h1><h1 id="7d28" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">3.)参数数量:12，352</h1><h1 id="9cd3" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">正规化在这里确实起了作用，但这不是我们应该采取的理想方式。我们不是上帝。</h1><h1 id="7472" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">该模型可以进一步推进，但以目前的产能，这是不可能的。我们还可以看到，近一半的参数位于我们使用7*7内核的层中，因为这里我们使用了一个非常大的内核，而不是我们应该使用的全局平均池(GAP)层。</h1><h1 id="2e76" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">转到第6轮，我们将尝试进一步改进。</h1><h1 id="3687" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">第6轮:-</h1><p id="6192" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">在上一轮中，辍学者没有问题，但我们应用他们的方式有问题，这个问题是故意这样做的，以便更多地关注它，并将在即将到来的几轮中得到改善。</p><p id="e189" class="pw-post-body-paragraph jk jl hi jm b jn ks jp jq jr kt jt ju jv ku jx jy jz kv kb kc kd kw kf kg kh hb bi translated">现在，由于我们希望减少参数的数量，也希望我们的精度进一步提高，我们需要关注一件事，即在第5轮中，我们可以看到大约50%的参数将用于最后一个卷积层的计算，我们使用了7*7的巨大内核大小，因此我们的直接步骤是以某种方式处理这一问题</p><p id="f25c" class="pw-post-body-paragraph jk jl hi jm b jn ks jp jq jr kt jt ju jv ku jx jy jz kv kb kc kd kw kf kg kh hb bi translated">为了处理这个大内核卷积问题，我们将使用全局平均池(GAP)的概念。</p><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="er es mu"><img src="../Images/62223fa72aab0b956c68dc22a0d212fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*FkScNMEKeiKsqGWT.png"/></div></div></figure><h1 id="5a1e" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">代码链接:-</h1><div class="kx ky ez fb kz la"><a href="https://github.com/rashutyagi/Journey-of-a-DNN/blob/master/Round%20-%206%20Global%20Average%20Pooling.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="lb ab dw"><div class="lc ab ld cl cj le"><h2 class="bd hj fi z dy lf ea eb lg ed ef hh bi translated">拉舒塔吉/DNN之旅</h2><div class="lh l"><h3 class="bd b fi z dy lf ea eb lg ed ef dx translated">permalink dissolve GitHub是4000多万开发人员的家园，他们一起工作来托管和审查代码，管理…</h3></div><div class="li l"><p class="bd b fp z dy lf ea eb lg ed ef dx translated">github.com</p></div></div><div class="lj l"><div class="mv l ll lm ln lj lo ik la"/></div></div></a></div><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="er es mw"><img src="../Images/b1f3fceb28cd74ed7123d7ec76886cb0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Krhl0sjP0tpFm0iGUQKymQ.png"/></div></div></figure><h2 id="f6a5" class="lq in hi bd io lr ls lt is lu lv lw iw jv lx ly ja jz lz ma je kd mb mc ji md bi translated">结果:-</h2><h2 id="5de5" class="lq in hi bd io lr ls lt is lu lv lw iw jv lx ly ja jz lz ma je kd mb mc ji md bi translated">1.)最佳训练准确率:98.92%</h2><h2 id="7d5a" class="lq in hi bd io lr ls lt is lu lv lw iw jv lx ly ja jz lz ma je kd mb mc ji md bi translated">2.)最佳测试准确率:98.88%</h2><h2 id="c210" class="lq in hi bd io lr ls lt is lu lv lw iw jv lx ly ja jz lz ma je kd mb mc ji md bi translated">3.)参数数量:5688</h2><h2 id="264c" class="lq in hi bd io lr ls lt is lu lv lw iw jv lx ly ja jz lz ma je kd mb mc ji md bi translated">现在看到上面的结果决不能得出间隙层降低精度的结论，因为我们不能将11000参数模型的精度与6000参数模型的精度进行比较。</h2><h2 id="b2eb" class="lq in hi bd io lr ls lt is lu lv lw iw jv lx ly ja jz lz ma je kd mb mc ji md bi translated">正规化在这里确实起了作用，但这不是我们应该采取的理想方式。我们不是上帝。我们很快就会看到正确的方法。</h2><h2 id="96e1" class="lq in hi bd io lr ls lt is lu lv lw iw jv lx ly ja jz lz ma je kd mb mc ji md bi translated">该模型可以被进一步推进，但是对于当前的容量(通道数量)，这是不可能的。</h2><h2 id="c792" class="lq in hi bd io lr ls lt is lu lv lw iw jv lx ly ja jz lz ma je kd mb mc ji md bi translated">转到第7轮，我们尝试进一步改进。</h2><h1 id="3c8b" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">第7轮:-</h1><p id="3c75" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">现在，在这一轮中，我们将尝试增加模型的容量，通过模型的容量，我们的意思是说，我们在层中接近的通道数量现在将进一步增加，并将比较准确性。</p><p id="3455" class="pw-post-body-paragraph jk jl hi jm b jn ks jp jq jr kt jt ju jv ku jx jy jz kv kb kc kd kw kf kg kh hb bi translated">我们将增加到32个通道，因为我们必须记住在增加通道数量后参数数量会大幅增加，因此为了将参数数量保持在10，000以下，我们将增加到32个通道。</p><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="er es mx"><img src="../Images/a72e5483bbc8d7e68ee555b13c16c646.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*BDHFHttv_pPShMTR.png"/></div></div></figure><h1 id="20f2" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">代码链接:-</h1><div class="kx ky ez fb kz la"><a href="https://github.com/rashutyagi/Journey-of-a-DNN/blob/master/Round%20-%207%20Increasing%20the%20capacity%20of%20our%20model.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="lb ab dw"><div class="lc ab ld cl cj le"><h2 class="bd hj fi z dy lf ea eb lg ed ef hh bi translated">拉舒塔吉/DNN之旅</h2><div class="lh l"><h3 class="bd b fi z dy lf ea eb lg ed ef dx translated">permalink dissolve GitHub是4000多万开发人员的家园，他们一起工作来托管和审查代码，管理…</h3></div><div class="li l"><p class="bd b fp z dy lf ea eb lg ed ef dx translated">github.com</p></div></div><div class="lj l"><div class="my l ll lm ln lj lo ik la"/></div></div></a></div><figure class="kj kk kl km fd ij er es paragraph-image"><div class="er es mz"><img src="../Images/4663b06b8ac518c54131899a35f2737d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1344/format:webp/1*c6cZ1iNim_sRIayiFYqukg.png"/></div></figure><h2 id="1699" class="lq in hi bd io lr ls lt is lu lv lw iw jv lx ly ja jz lz ma je kd mb mc ji md bi translated">结果:-</h2><h2 id="3c3c" class="lq in hi bd io lr ls lt is lu lv lw iw jv lx ly ja jz lz ma je kd mb mc ji md bi translated">1.)最佳训练准确率:99.71%</h2><h2 id="8bbb" class="lq in hi bd io lr ls lt is lu lv lw iw jv lx ly ja jz lz ma je kd mb mc ji md bi translated">2.)最佳测试准确率:99.30%</h2><h2 id="1602" class="lq in hi bd io lr ls lt is lu lv lw iw jv lx ly ja jz lz ma je kd mb mc ji md bi translated">3.)参数数量:9896</h2><h2 id="ae67" class="lq in hi bd io lr ls lt is lu lv lw iw jv lx ly ja jz lz ma je kd mb mc ji md bi translated">正规化在这里确实起了作用，但没有我们希望的那么好，这是因为这不是我们应该采取的理想方式，靠我们自己在任何地方申请退学我们不是上帝。</h2><h2 id="c59d" class="lq in hi bd io lr ls lt is lu lv lw iw jv lx ly ja jz lz ma je kd mb mc ji md bi translated">转到第8轮，我们将尝试进一步改进。</h2><h1 id="a156" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">第8轮:-</h1><p id="3e36" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">现在，在这一轮中，我们将以正确的方式应用辍学正则化技术，正确的方式是不要在您选择的任何层之后应用它，因为我们永远无法知道它应该在哪里应用，因此我们遵循我们在除了最后一层之外的每一层之后应用的方法，然后与之前相比获得更好的结果。</p><p id="98fd" class="pw-post-body-paragraph jk jl hi jm b jn ks jp jq jr kt jt ju jv ku jx jy jz kv kb kc kd kw kf kg kh hb bi translated">第二件最重要的事情是，我们在最后应用间隙层，这不是一个好主意，因为这样一来，每个层都开始像一个热点矢量一样工作，这反过来意味着每个通道将开始表示数据集的一个类，这是我们不希望的，我们希望多个通道能够表示我们的单个类，因此我们也在间隙层后应用卷积。</p><figure class="kj kk kl km fd ij er es paragraph-image"><div class="er es na"><img src="../Images/490ecf6fa33cd558c72ee1946ffaec83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/0*XpGt13NGVNyS3BMx.png"/></div></figure><p id="a4e4" class="pw-post-body-paragraph jk jl hi jm b jn ks jp jq jr kt jt ju jv ku jx jy jz kv kb kc kd kw kf kg kh hb bi translated">此外，请记住，一旦我们的卷积覆盖了图像中的图案所需的感受野，我们就应该应用最大池来表示某些东西(就像在MNIST数据集中，当您缩放和查看数据集图像时，我使用它需要5个像素，因此我在第二次卷积后应用了最大池，在那里它已经达到了5*5的感受野)</p><figure class="kj kk kl km fd ij er es paragraph-image"><div class="er es nb"><img src="../Images/c69b911d3de8919f2f447156bcef7c2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1162/0*pIGvB6TmuxbQ7Ngb.gif"/></div></figure><p id="67fe" class="pw-post-body-paragraph jk jl hi jm b jn ks jp jq jr kt jt ju jv ku jx jy jz kv kb kc kd kw kf kg kh hb bi translated">代码链接:-</p><div class="kx ky ez fb kz la"><a href="https://github.com/rashutyagi/Journey-of-a-DNN/blob/master/Round%20-%208%20Some%20more%20changes%20.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="lb ab dw"><div class="lc ab ld cl cj le"><h2 class="bd hj fi z dy lf ea eb lg ed ef hh bi translated">拉舒塔吉/DNN之旅</h2><div class="lh l"><h3 class="bd b fi z dy lf ea eb lg ed ef dx translated">permalink dissolve GitHub是4000多万开发人员的家园，他们一起工作来托管和审查代码，管理…</h3></div><div class="li l"><p class="bd b fp z dy lf ea eb lg ed ef dx translated">github.com</p></div></div><div class="lj l"><div class="nc l ll lm ln lj lo ik la"/></div></div></a></div><figure class="kj kk kl km fd ij er es paragraph-image"><div class="er es nd"><img src="../Images/d61af1e4ea8c9a2d0b154434f66cae4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1226/format:webp/1*vR8pPJIFEGTt5QlKQw9vqg.png"/></div></figure><h2 id="6def" class="lq in hi bd io lr ls lt is lu lv lw iw jv lx ly ja jz lz ma je kd mb mc ji md bi translated">结果:-</h2><h2 id="b2c5" class="lq in hi bd io lr ls lt is lu lv lw iw jv lx ly ja jz lz ma je kd mb mc ji md bi translated">1.)最佳训练准确率:99.36%</h2><h2 id="69b1" class="lq in hi bd io lr ls lt is lu lv lw iw jv lx ly ja jz lz ma je kd mb mc ji md bi translated">2.)最佳测试准确率:99.36%</h2><h2 id="8789" class="lq in hi bd io lr ls lt is lu lv lw iw jv lx ly ja jz lz ma je kd mb mc ji md bi translated">3.)参数数量:13，848</h2><h2 id="6db5" class="lq in hi bd io lr ls lt is lu lv lw iw jv lx ly ja jz lz ma je kd mb mc ji md bi translated">正则化在这里工作得非常完美，因为我们根本没有过度拟合。</h2><h2 id="fbf1" class="lq in hi bd io lr ls lt is lu lv lw iw jv lx ly ja jz lz ma je kd mb mc ji md bi translated">转到第9轮，我们尝试进一步改进。</h2><h1 id="63d4" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">第9轮:-</h1><p id="7201" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">直到我们的模型8，我们达到了良好的准确性，但我们希望看到它更频繁。因此，我们将应用的下一个概念是图像增强的概念，简单来说，这意味着我们将通过在训练数据中引入旋转等变换来使训练数据更难学习。反过来，这有助于使我们的模型更加通用。</p><p id="2e2f" class="pw-post-body-paragraph jk jl hi jm b jn ks jp jq jr kt jt ju jv ku jx jy jz kv kb kc kd kw kf kg kh hb bi translated">当涉及更复杂的数据集和包含大量类的数据集时，图像增强是一个非常重要的概念。</p><p id="7420" class="pw-post-body-paragraph jk jl hi jm b jn ks jp jq jr kt jt ju jv ku jx jy jz kv kb kc kd kw kf kg kh hb bi translated">我们将把我们的训练数据图像旋转几度，然后将它们发送到训练中。</p><figure class="kj kk kl km fd ij er es paragraph-image"><div class="er es ne"><img src="../Images/ed8623078e8e9addcd2467f09f518684.png" data-original-src="https://miro.medium.com/v2/resize:fit:476/0*j9Swh8VK1JNGTmpk.gif"/></div><figcaption class="mn mo et er es mp mq bd b be z dx translated">如果你认不出我，你的DNN就没用了！训练更努力的家伙使用图像增强91狗黑帮！</figcaption></figure><h1 id="bb59" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">代码链接:-</h1><div class="kx ky ez fb kz la"><a href="https://github.com/rashutyagi/Journey-of-a-DNN/blob/master/Round%20-%209%20Introducing%20Image%20Augmentation%20.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="lb ab dw"><div class="lc ab ld cl cj le"><h2 class="bd hj fi z dy lf ea eb lg ed ef hh bi translated">拉舒塔吉/DNN之旅</h2><div class="lh l"><h3 class="bd b fi z dy lf ea eb lg ed ef dx translated">permalink dissolve GitHub是4000多万开发人员的家园，他们一起工作来托管和审查代码，管理…</h3></div><div class="li l"><p class="bd b fp z dy lf ea eb lg ed ef dx translated">github.com</p></div></div><div class="lj l"><div class="nf l ll lm ln lj lo ik la"/></div></div></a></div><figure class="kj kk kl km fd ij er es paragraph-image"><div class="er es ml"><img src="../Images/e81ee1bcfb7cc089427eb56d20aab7b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1272/format:webp/1*2jfBNzvvKRaUp1QjoPOKdA.png"/></div></figure><h2 id="ffbf" class="lq in hi bd io lr ls lt is lu lv lw iw jv lx ly ja jz lz ma je kd mb mc ji md bi translated">结果:-</h2><h2 id="3e79" class="lq in hi bd io lr ls lt is lu lv lw iw jv lx ly ja jz lz ma je kd mb mc ji md bi translated">1.)最佳训练准确率:98.88%</h2><h2 id="fc34" class="lq in hi bd io lr ls lt is lu lv lw iw jv lx ly ja jz lz ma je kd mb mc ji md bi translated">2.)最佳测试准确率:99.41%</h2><h2 id="0d1e" class="lq in hi bd io lr ls lt is lu lv lw iw jv lx ly ja jz lz ma je kd mb mc ji md bi translated">3.)参数数量:9896</h2><h2 id="a77c" class="lq in hi bd io lr ls lt is lu lv lw iw jv lx ly ja jz lz ma je kd mb mc ji md bi translated">正则化在这里工作得非常完美，因为我们根本没有过度拟合。</h2><h2 id="96f7" class="lq in hi bd io lr ls lt is lu lv lw iw jv lx ly ja jz lz ma je kd mb mc ji md bi translated">但我们可以看到一点点拟合不足，因为我们知道我们已经使我们的训练数据更难，因此训练精度预计会变低。我们在测试数据中可能没有这样硬的图像，因此测试精度是好的。</h2><h2 id="7c1b" class="lq in hi bd io lr ls lt is lu lv lw iw jv lx ly ja jz lz ma je kd mb mc ji md bi translated">转到第10轮，我们将尝试进一步改进</h2><h1 id="cd90" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">第十轮(决赛):-</h1><p id="ad93" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">这是我们最后的模型，我们使用了最后的技术</p><p id="be9a" class="pw-post-body-paragraph jk jl hi jm b jn ks jp jq jr kt jt ju jv ku jx jy jz kv kb kc kd kw kf kg kh hb bi translated">“学习率调度程序”。它的目的是在每一定数量的时期之后降低学习率，它也有助于我们的模型损失更快地收敛到它的最小可能。</p><p id="6cc3" class="pw-post-body-paragraph jk jl hi jm b jn ks jp jq jr kt jt ju jv ku jx jy jz kv kb kc kd kw kf kg kh hb bi translated">使用这种方法后，我们将尝试用尽可能少的参数和时期获得尽可能高的精度。</p><figure class="kj kk kl km fd ij er es paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="er es ng"><img src="../Images/156eb226cdaf984e16bc7d6b85b21f27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*0209XBlZq7MwIwGe.png"/></div></div></figure><p id="a60d" class="pw-post-body-paragraph jk jl hi jm b jn ks jp jq jr kt jt ju jv ku jx jy jz kv kb kc kd kw kf kg kh hb bi translated">代码链接:-</p><div class="kx ky ez fb kz la"><a href="https://github.com/rashutyagi/Journey-of-a-DNN/blob/master/Round%2010%20Final.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="lb ab dw"><div class="lc ab ld cl cj le"><h2 class="bd hj fi z dy lf ea eb lg ed ef hh bi translated">拉舒塔吉/DNN之旅</h2><div class="lh l"><h3 class="bd b fi z dy lf ea eb lg ed ef dx translated">permalink dissolve GitHub是4000多万开发人员的家园，他们一起工作来托管和审查代码，管理…</h3></div><div class="li l"><p class="bd b fp z dy lf ea eb lg ed ef dx translated">github.com</p></div></div><div class="lj l"><div class="nh l ll lm ln lj lo ik la"/></div></div></a></div><figure class="kj kk kl km fd ij er es paragraph-image"><div class="er es ni"><img src="../Images/63b67d1e232b547a7e280c457e875404.png" data-original-src="https://miro.medium.com/v2/resize:fit:1208/format:webp/1*swYU1xsLB0jBUdma3UcCZA.png"/></div></figure><h2 id="bb4e" class="lq in hi bd io lr ls lt is lu lv lw iw jv lx ly ja jz lz ma je kd mb mc ji md bi translated">结果:-</h2><h2 id="0dd8" class="lq in hi bd io lr ls lt is lu lv lw iw jv lx ly ja jz lz ma je kd mb mc ji md bi translated">1.)最佳训练准确率:99.97%</h2><h2 id="50ba" class="lq in hi bd io lr ls lt is lu lv lw iw jv lx ly ja jz lz ma je kd mb mc ji md bi translated">2.)最佳测试准确率:99.44%</h2><h2 id="938b" class="lq in hi bd io lr ls lt is lu lv lw iw jv lx ly ja jz lz ma je kd mb mc ji md bi translated">3.)参数数量:9896</h2><h2 id="44d3" class="lq in hi bd io lr ls lt is lu lv lw iw jv lx ly ja jz lz ma je kd mb mc ji md bi translated">在我们的最终模型中，我们在第12个时期使用9896个参数获得了99.44%的测试准确度。</h2><p id="4421" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">最终模型历元日志(20个历元):-</p><pre class="kj kk kl km fd nj nk nl nm aw nn bi"><span id="2e84" class="lq in hi nk b fi no np l nq nr">EPOCH: 0</span><span id="2587" class="lq in hi nk b fi ns np l nq nr">Loss=0.1162916049361229 Batch_id=468 Accuracy=91.29: 100%|███████████████████████████| 469/469 [00:07&lt;00:00, 80.91it/s]</span><span id="95d6" class="lq in hi nk b fi ns np l nq nr">Test set: Average loss: 0.0481, Accuracy: 9862/10000 (98.62%)<br/><br/>EPOCH: 1</span><span id="6b82" class="lq in hi nk b fi ns np l nq nr">Loss=0.05616094172000885 Batch_id=468 Accuracy=97.64: 100%|██████████████████████████| 469/469 [00:07&lt;00:00, 61.17it/s]</span><span id="0c97" class="lq in hi nk b fi ns np l nq nr">Test set: Average loss: 0.0513, Accuracy: 9836/10000 (98.36%)<br/><br/>EPOCH: 2</span><span id="0831" class="lq in hi nk b fi ns np l nq nr">Loss=0.11810651421546936 Batch_id=468 Accuracy=98.03: 100%|██████████████████████████| 469/469 [00:12&lt;00:00, 80.33it/s]</span><span id="ed15" class="lq in hi nk b fi ns np l nq nr">Test set: Average loss: 0.0314, Accuracy: 9899/10000 (98.99%)<br/><br/>EPOCH: 3</span><span id="71a4" class="lq in hi nk b fi ns np l nq nr">Loss=0.021130084991455078 Batch_id=468 Accuracy=98.24: 100%|█████████████████████████| 469/469 [00:07&lt;00:00, 80.65it/s]</span><span id="c770" class="lq in hi nk b fi ns np l nq nr">Test set: Average loss: 0.0363, Accuracy: 9887/10000 (98.87%)<br/><br/>EPOCH: 4</span><span id="2f40" class="lq in hi nk b fi ns np l nq nr">Loss=0.10834845155477524 Batch_id=468 Accuracy=98.39: 100%|██████████████████████████| 469/469 [00:07&lt;00:00, 62.83it/s]</span><span id="825e" class="lq in hi nk b fi ns np l nq nr">Test set: Average loss: 0.0300, Accuracy: 9914/10000 (99.14%)<br/><br/>EPOCH: 5</span><span id="6ac0" class="lq in hi nk b fi ns np l nq nr">Loss=0.03899098560214043 Batch_id=468 Accuracy=98.48: 100%|██████████████████████████| 469/469 [00:07&lt;00:00, 62.47it/s]</span><span id="9133" class="lq in hi nk b fi ns np l nq nr">Test set: Average loss: 0.0252, Accuracy: 9920/10000 (99.20%)<br/><br/>EPOCH: 6</span><span id="d110" class="lq in hi nk b fi ns np l nq nr">Loss=0.022102728486061096 Batch_id=468 Accuracy=98.58: 100%|█████████████████████████| 469/469 [00:07&lt;00:00, 60.85it/s]</span><span id="49e4" class="lq in hi nk b fi ns np l nq nr">Test set: Average loss: 0.0258, Accuracy: 9919/10000 (99.19%)<br/><br/>EPOCH: 7</span><span id="53a9" class="lq in hi nk b fi ns np l nq nr">Loss=0.0121208680793643 Batch_id=468 Accuracy=98.63: 100%|███████████████████████████| 469/469 [00:07&lt;00:00, 61.30it/s]</span><span id="47ef" class="lq in hi nk b fi ns np l nq nr">Test set: Average loss: 0.0216, Accuracy: 9935/10000 (99.35%)<br/><br/>EPOCH: 8</span><span id="2222" class="lq in hi nk b fi ns np l nq nr">Loss=0.030048644170165062 Batch_id=468 Accuracy=98.77: 100%|█████████████████████████| 469/469 [00:12&lt;00:00, 37.28it/s]</span><span id="fc8d" class="lq in hi nk b fi ns np l nq nr">Test set: Average loss: 0.0210, Accuracy: 9930/10000 (99.30%)<br/><br/>EPOCH: 9</span><span id="14ac" class="lq in hi nk b fi ns np l nq nr">Loss=0.002635945798829198 Batch_id=468 Accuracy=98.78: 100%|█████████████████████████| 469/469 [00:07&lt;00:00, 60.36it/s]</span><span id="37f1" class="lq in hi nk b fi ns np l nq nr">Test set: Average loss: 0.0225, Accuracy: 9924/10000 (99.24%)<br/><br/>EPOCH: 10</span><span id="acde" class="lq in hi nk b fi ns np l nq nr">Loss=0.03299098461866379 Batch_id=468 Accuracy=98.72: 100%|██████████████████████████| 469/469 [00:12&lt;00:00, 37.86it/s]</span><span id="ab2d" class="lq in hi nk b fi ns np l nq nr">Test set: Average loss: 0.0260, Accuracy: 9921/10000 (99.21%)<br/><br/>EPOCH: 11</span><span id="9e5d" class="lq in hi nk b fi ns np l nq nr">Loss=0.03195049613714218 Batch_id=468 Accuracy=98.73: 100%|██████████████████████████| 469/469 [00:07&lt;00:00, 61.06it/s]</span><span id="4020" class="lq in hi nk b fi ns np l nq nr">Test set: Average loss: 0.0217, Accuracy: 9926/10000 (99.26%)<br/><br/>EPOCH: 12</span><span id="4b18" class="lq in hi nk b fi ns np l nq nr">Loss=0.04026757553219795 Batch_id=468 Accuracy=98.86: 100%|██████████████████████████| 469/469 [00:07&lt;00:00, 59.72it/s]</span><span id="a9b6" class="lq in hi nk b fi ns np l nq nr">Test set: Average loss: 0.0181, Accuracy: 9944/10000 (99.44%)<br/><br/>EPOCH: 13</span><span id="b127" class="lq in hi nk b fi ns np l nq nr">Loss=0.0159068014472723 Batch_id=468 Accuracy=98.83: 100%|███████████████████████████| 469/469 [00:07&lt;00:00, 60.81it/s]</span><span id="93b0" class="lq in hi nk b fi ns np l nq nr">Test set: Average loss: 0.0215, Accuracy: 9927/10000 (99.27%)<br/><br/>EPOCH: 14</span><span id="1880" class="lq in hi nk b fi ns np l nq nr">Loss=0.011734549887478352 Batch_id=468 Accuracy=98.89: 100%|█████████████████████████| 469/469 [00:07&lt;00:00, 60.12it/s]</span><span id="4420" class="lq in hi nk b fi ns np l nq nr">Test set: Average loss: 0.0227, Accuracy: 9928/10000 (99.28%)<br/><br/>EPOCH: 15</span><span id="2599" class="lq in hi nk b fi ns np l nq nr">Loss=0.031209371984004974 Batch_id=468 Accuracy=98.91: 100%|█████████████████████████| 469/469 [00:08&lt;00:00, 58.46it/s]</span><span id="20a3" class="lq in hi nk b fi ns np l nq nr">Test set: Average loss: 0.0237, Accuracy: 9920/10000 (99.20%)<br/><br/>EPOCH: 16</span><span id="245e" class="lq in hi nk b fi ns np l nq nr">Loss=0.049311209470033646 Batch_id=468 Accuracy=98.88: 100%|█████████████████████████| 469/469 [00:07&lt;00:00, 59.71it/s]</span><span id="ad95" class="lq in hi nk b fi ns np l nq nr">Test set: Average loss: 0.0240, Accuracy: 9918/10000 (99.18%)<br/><br/>EPOCH: 17</span><span id="f39e" class="lq in hi nk b fi ns np l nq nr">Loss=0.05350984260439873 Batch_id=468 Accuracy=98.92: 100%|██████████████████████████| 469/469 [00:07&lt;00:00, 80.45it/s]</span><span id="7787" class="lq in hi nk b fi ns np l nq nr">Test set: Average loss: 0.0185, Accuracy: 9943/10000 (99.43%)<br/><br/>EPOCH: 18</span><span id="bba0" class="lq in hi nk b fi ns np l nq nr">Loss=0.0037606756668537855 Batch_id=468 Accuracy=98.93: 100%|████████████████████████| 469/469 [00:12&lt;00:00, 37.66it/s]</span><span id="8813" class="lq in hi nk b fi ns np l nq nr">Test set: Average loss: 0.0192, Accuracy: 9944/10000 (99.44%)<br/><br/>EPOCH: 19</span><span id="899b" class="lq in hi nk b fi ns np l nq nr">Loss=0.03514719009399414 Batch_id=468 Accuracy=98.97: 100%|██████████████████████████| 469/469 [00:07&lt;00:00, 60.26it/s]</span><span id="bb17" class="lq in hi nk b fi ns np l nq nr">Test set: Average loss: 0.0240, Accuracy: 9923/10000 (99.23%)</span></pre><figure class="kj kk kl km fd ij er es paragraph-image"><div class="er es nt"><img src="../Images/92f7261281cdeb775a9e8187771a9de6.png" data-original-src="https://miro.medium.com/v2/resize:fit:744/0*UgCFrkwMQzhfF7az.gif"/></div><figcaption class="mn mo et er es mp mq bd b be z dx translated">如果你在构建DNN时没有像上面所示的那样非常仔细地遵循每一个步骤，你会把这只猫当成狗，她会难过，所以不要让她难过，要始终遵循网络训练的基本原则。</figcaption></figure><h1 id="89f3" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">谢谢你！</h1></div></div>    
</body>
</html>