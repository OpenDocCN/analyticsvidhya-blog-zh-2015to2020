<html>
<head>
<title>Tensorflow and CUDA on processors without modern instructions</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">无现代指令的处理器上的Tensorflow和CUDA</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/tensorflow-and-cuda-on-processors-without-modern-instructions-84c425024b41?source=collection_archive---------29-----------------------#2020-10-18">https://medium.com/analytics-vidhya/tensorflow-and-cuda-on-processors-without-modern-instructions-84c425024b41?source=collection_archive---------29-----------------------#2020-10-18</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="9065" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">虽然在大多数情况下简单的<code class="du jd je jf jg b">pip install tensorflow</code>工作得很好，但某些硬件组合可能与存储库安装的tensorflow包不兼容。在这个简短的教程中，我将从源代码构建最新的tensorflow 2.3.1 python包。本教程也可能对那些想要在旧GPU上更新到最新tensorflow版本的人有所帮助，因为自<a class="ae jh" href="https://github.com/tensorflow/tensorflow/releases/tag/v2.3.0" rel="noopener ugc nofollow" target="_blank"> 2.3.0 </a>以来，旧硬件支持已从预编译版本中移除。</p><h1 id="d6fc" class="ji jj hi bd jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf bi translated">准备建筑环境</h1><p id="4e86" class="pw-post-body-paragraph if ig hi ih b ii kg ik il im kh io ip iq ki is it iu kj iw ix iy kk ja jb jc hb bi translated">获取以下docker容器:</p><pre class="kl km kn ko fd kp jg kq kr aw ks bi"><span id="2ff9" class="kt jj hi jg b fi ku kv l kw kx">docker pull tensorflow/tensorflow:devel-gpu</span></pre><p id="f7a8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">选择一个位置并创建一个将与容器共享的目录。在我的例子中，我将使用<code class="du jd je jf jg b">/home/alexandr/temp/tensorflow</code>。然后进入工作目录并启动docker容器</p><pre class="kl km kn ko fd kp jg kq kr aw ks bi"><span id="f8c3" class="kt jj hi jg b fi ku kv l kw kx">cd /home/alexandr/temp/tensorflow<br/>docker run -it -w /tensorflow_src -v $(pwd):/share tensorflow/tensorflow:devel-gpu bash</span></pre><p id="4351" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">更新容器中的存储库，并选择最新的稳定分支(在撰写本文时是2.3版)</p><pre class="kl km kn ko fd kp jg kq kr aw ks bi"><span id="8989" class="kt jj hi jg b fi ku kv l kw kx">git pull<br/>git checkout r2.3</span></pre><p id="b5ba" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">接下来，升级pip并安装一些python依赖项</p><pre class="kl km kn ko fd kp jg kq kr aw ks bi"><span id="3365" class="kt jj hi jg b fi ku kv l kw kx">/usr/bin/python3 -m pip install --upgrade pip<br/>pip3 install six numpy wheel keras_applications keras_preprocessing</span></pre><h1 id="438e" class="ji jj hi bd jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf bi translated">找出目标机器上的CPU限制</h1><p id="b584" class="pw-post-body-paragraph if ig hi ih b ii kg ik il im kh io ip iq ki is it iu kj iw ix iy kk ja jb jc hb bi translated">您需要告诉编译器在最终的二进制文件中应该避免哪些指令。这不是一个显而易见的步骤，因为这些限制是特定于机器的。您可能想要咨询internet，甚至使用一些试错法来查看需要什么标志来使二进制文件在您的特定机器上保持稳定。</p><p id="7ddd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你在目标机器上编译，<code class="du jd je jf jg b">-march=native</code>应该足够了，因为它应该启用你的CPU支持的所有指令。如果你交叉编译，就像我在这个例子中一样，那么你需要更深入地挖掘。</p><p id="0a9b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一种方法是查看显示CPU特性的<code class="du jd je jf jg b">grep flags /proc/cpuinfo | head -n 1</code>。在我的情况下，我有一台笔记本电脑，其中最新的tensorflow可以开箱即用，还有一台带GPU的台式电脑，其中没有GPU。比较两台机器的列表，我发现台式电脑缺少以下项目:<code class="du jd je jf jg b">'ida', 'bmi2', 'smep', 'rtm', 'bmi1', 'fma', 'f16c', 'hle', 'avx2', 'smx', 'adx', 'avx', 'mpx'</code>。</p><p id="6da4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae jh" href="https://unix.stackexchange.com/questions/43539/what-do-the-flags-in-proc-cpuinfo-mean" rel="noopener ugc nofollow" target="_blank">在这里</a>我们可以看到<code class="du jd je jf jg b">ida</code>代表英特尔动态加速，是CPU热量和电源管理的一部分，因此它不太可能是我的案例中的破坏因素。同样，<code class="du jd je jf jg b">smep, rtm, hle, smx,</code>和<code class="du jd je jf jg b">mpx</code>特性不太可能影响tensorflow的执行。我很难找到tensorflow二进制文件是否使用了<code class="du jd je jf jg b">f16c</code>和<code class="du jd je jf jg b">adx</code>。</p><p id="333b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">另一方面，<code class="du jd je jf jg b">avx</code>和<code class="du jd je jf jg b">avx2</code>(高级向量扩展)、<code class="du jd je jf jg b">bmi1, bmi2</code>(第一/组位操作扩展)和<code class="du jd je jf jg b">fma</code>(融合乘加)似乎对tensorflow相当重要。因此，我将使用下面的标志组合来构建tensorflow二进制文件</p><pre class="kl km kn ko fd kp jg kq kr aw ks bi"><span id="2ac5" class="kt jj hi jg b fi ku kv l kw kx">-march=native -mno-avx -mno-avx2 -mno-fma -mno-bmi -mno-bmi2</span></pre><h1 id="90fd" class="ji jj hi bd jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf bi translated">配置tensorflow的构建链</h1><p id="d415" class="pw-post-body-paragraph if ig hi ih b ii kg ik il im kh io ip iq ki is it iu kj iw ix iy kk ja jb jc hb bi translated">在docker容器中执行</p><pre class="kl km kn ko fd kp jg kq kr aw ks bi"><span id="608c" class="kt jj hi jg b fi ku kv l kw kx">python3 configure.py</span></pre><p id="8957" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">启动配置管理器。对于大多数问题，您可以选择默认答案。</p><p id="7313" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一个重要的问题是关于你的GPU的计算能力。由于默认选项可能不包括您的GPU类型，因此最好提前检查一下<a class="ae jh" href="https://developer.nvidia.com/cuda-gpus" rel="noopener ugc nofollow" target="_blank">这里的</a>并输入到提供的字段中。如果您错误地指定了您的GPU计算能力，那么在tensorflow中尝试使用CUDA时，您可能会收到以下错误消息:</p><pre class="kl km kn ko fd kp jg kq kr aw ks bi"><span id="5303" class="kt jj hi jg b fi ku kv l kw kx">InternalError: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid</span></pre><p id="e966" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当您遇到关于优化标志的问题时，您应该输入我们在上一节中提出的标志。在我的例子中，我还添加了一面<code class="du jd je jf jg b">-Wno-sign-compare</code>旗。完成后，您可以通过运行以下命令开始构建过程</p><pre class="kl km kn ko fd kp jg kq kr aw ks bi"><span id="06de" class="kt jj hi jg b fi ku kv l kw kx">bazel build //tensorflow/tools/pip_package:build_pip_package --local_ram_resources=16384</span></pre><p id="0185" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果bazel抱怨它的版本，它也可能会为您提供一个更新它的命令行程序。</p><p id="535e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">构建过程需要大量的RAM，尤其是在具有多个内核的机器上，因此您可能希望通过使用标志<code class="du jd je jf jg b">--local_ram_resources=16384</code>来限制RAM的使用。在我的例子中，我将它限制在机器上可用的24 GiB中的16 GiB。限制资源的另一种方式是使用标志<code class="du jd je jf jg b">--jobs 4</code>将线程数量限制到一个较小的数量。</p><p id="3b4a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这个建筑要花很长时间。</p><h1 id="d714" class="ji jj hi bd jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf bi translated">准备并安装python包</h1><p id="6ebe" class="pw-post-body-paragraph if ig hi ih b ii kg ik il im kh io ip iq ki is it iu kj iw ix iy kk ja jb jc hb bi translated">执行以下命令来组装python包</p><pre class="kl km kn ko fd kp jg kq kr aw ks bi"><span id="b6e3" class="kt jj hi jg b fi ku kv l kw kx">bazel-bin/tensorflow/tools/pip_package/build_pip_package /share</span></pre><p id="971d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，您应该能够在主机的挂载目录中看到一个<code class="du jd je jf jg b">.whl</code>文件。将该文件复制到目标机器上，然后用<code class="du jd je jf jg b">pip</code>安装。文件名建议您应该在目标机器上使用哪个python版本。如果您有不同的版本，可以使用conda的environments为tensorflow创建一个单独的环境，其中包含所需的python版本。</p><pre class="kl km kn ko fd kp jg kq kr aw ks bi"><span id="7b05" class="kt jj hi jg b fi ku kv l kw kx">conda create -n "tensorflow2" python=3.6<br/>conda activate tensorflow2<br/>pip install tensorflow-2.3.1-cp36-cp36m-linux_x86_64.whl</span></pre><p id="ac8e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，您应该能够在这个新环境中导入和使用tensorflow。</p><p id="faa8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">就是这样！</p><p id="24ae" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">附:这个故事最初出现在我的个人博客中，地址是<a class="ae jh" href="https://alexmoskalev.com/tensorflow-and-cuda-on-processors-without-modern-instructions/" rel="noopener ugc nofollow" target="_blank">https://alexmoskalev . com/tensor flow-and-cuda-on-processors-without-modern-instructions/</a></p></div></div>    
</body>
</html>