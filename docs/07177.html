<html>
<head>
<title>Text Summarization, Extractive, T5, Bahasa Indonesia, Huggingface’s Transformers</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">文本摘要，摘录，T5，印度尼西亚语，拥抱脸的变形金刚</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/text-summarization-t5-bahasa-indonesia-huggingfaces-transformers-ee9bfe368e2f?source=collection_archive---------7-----------------------#2020-06-16">https://medium.com/analytics-vidhya/text-summarization-t5-bahasa-indonesia-huggingfaces-transformers-ee9bfe368e2f?source=collection_archive---------7-----------------------#2020-06-16</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/bd9b86cad8204e6fab4f6485bafb2fa7.png" data-original-src="https://miro.medium.com/v2/resize:fit:636/format:webp/1*D2a-8iE1yCFigeC6X1lzNg.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">图片来自:<a class="ae iq" href="https://www.kdnuggets.com/2019/11/getting-started-automated-text-summarization.html" rel="noopener ugc nofollow" target="_blank">https://www . kdnugges . com/2019/11/getting-started-automated-text-summary . html</a></figcaption></figure><p id="9d29" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">是的，标题只是我在谷歌上搜索做这个实验时使用的一堆关键词。然而你在这里，想知道如何利用huggingface transfomers来制作你自己的<em class="jp">印尼语</em>文本摘要，不是吗？</p><h1 id="ebc7" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated"><strong class="ak">数据</strong></h1><p id="9957" class="pw-post-body-paragraph ir is hi it b iu ko iw ix iy kp ja jb jc kq je jf jg kr ji jj jk ks jm jn jo hb bi translated">在这个实验中，我使用的是kata . ai<a class="ae iq" href="https://github.com/kata-ai/indosum" rel="noopener ugc nofollow" target="_blank">Indosum</a>T8】数据集。你可以去那里的链接获取数据集。在这个实验中，我只使用他们数据集的第一个文件夹(17k训练数据)，并且文本被设置为段落，而不是全文文章和摘要的标记。</p><figure class="ku kv kw kx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="er es kt"><img src="../Images/40b54e2d29cb251cc60f2f5539d85f8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1236/format:webp/1*g-xBXXaGaQK-j9aYfarc2g.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">使用的数据快照。</figcaption></figure><h1 id="b0fd" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">模型</h1><p id="5748" class="pw-post-body-paragraph ir is hi it b iu ko iw ix iy kp ja jb jc kq je jf jg kr ji jj jk ks jm jn jo hb bi translated">自然地，在文本摘要任务中，我们想要使用具有编码器-解码器模型的模型(序列输入，序列输出//全文输入，摘要输出)。因此，在回购中，我们可以选择具有这种架构的模型。基于它的<a class="ae iq" href="https://huggingface.co/transformers/summary.html#sequence-to-sequence-models" rel="noopener ugc nofollow" target="_blank">页面</a>目前只有3款车型支持它:<strong class="it hj"> Bart，T5，MarianMT。</strong>因为我想为巴哈萨语做这个任务，所以只有一个用户<a class="ae iq" href="https://huggingface.co/huseinzol05" rel="noopener ugc nofollow" target="_blank"> huseinzol </a>用这种语言上传模型(尽管我很确定他是用巴哈萨马拉雅语而不是印尼语训练的)，但是<a class="ae iq" href="https://huggingface.co/huseinzol05/t5-base-bahasa-summarization-cased" rel="noopener ugc nofollow" target="_blank"> t5模型用于摘要</a>效果很好。(还有他的艾伯特，用于分类)。所以，我选择他的模型进行微调。</p><figure class="ku kv kw kx fd ij er es paragraph-image"><div class="er es lc"><img src="../Images/f23913d3edf9d54e53accf00bb6c64fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1370/format:webp/1*Asgatl__Xw4yHDgXbv5r8g.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">启动记号赋予器和模型</figcaption></figure><h1 id="9060" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">数据集类。</h1><figure class="ku kv kw kx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="er es ld"><img src="../Images/5361c835803e19a4c177ab4a0060042b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xM67y3eHOY0IBjV_R7kZCQ.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">数据集类。</figcaption></figure><p id="cc9c" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">这里是<strong class="it hj">使用t5模型的重要部分。</strong>因为它将nlp任务转换为文本到文本的格式，而不是像<strong class="it hj"> BERT </strong>这样的特殊记号，所以在输入中我们必须开始<strong class="it hj"><em class="jp">“summary:”。</em> </strong>你可以在上面的截屏中看到<strong class="it hj"> <em class="jp">编码_段落</em> </strong>变量中的代码。然后，模型需要知道整篇文章的结尾在哪里，对吗？所以我们可以添加<strong class="it hj"><em class="jp">EOS token</em></strong>(tokenizer的vocab中的<em class="jp">句尾</em>/<em class="jp">/s&gt;</em>)。在这个记号之后，记号赋予器将通过args<strong class="it hj"><em class="jp">pad _ to _ mask _ length</em></strong><em class="jp"/>填充输入，直到它达到max_length (512，因为…默认情况下t5也在编码器状态下使用它)。垫本身是有用的，所以我们可以有批量大小&gt; 1，如果设备可以处理它。<strong class="it hj"><em class="jp">return _ attention _ mask</em></strong><em class="jp"/>也被设置为<strong class="it hj"> True </strong>，因为那个填充。它让模型知道它加入的令牌是否是pad，然后它不会加入/记录它。我们设置好了序列输入。</p><p id="013e" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">现在序列目标的一部分。<a class="ae iq" href="https://huggingface.co/transformers/model_doc/t5.html#training" rel="noopener ugc nofollow" target="_blank"> t5是用老师逼的，</a>是说我们要转移seq。目标由一个令牌表示，通常是一个<strong class="it hj"> <em class="jp">句首&lt; sos &gt; </em> </strong>令牌。不过在文档中，写了我们可以使用<em class="jp"> pad </em> token作为<em class="jp"> &lt; sos &gt; </em> token，因此在我的<strong class="it hj"><em class="jp">encoding _ summary</em></strong>中，我将其添加到摘要文本中，与<em class="jp"> &lt; eos &gt; </em>并排，就像在输入中一样。max_length应该与输入相差小于，因为它的目标…<strong class="it hj"><em class="jp">pad _ to _ mask _ length</em></strong>仍然设置为<strong class="it hj"> <em class="jp"> True </em> </strong>跟序列输入的原因一样。</p><p id="bc1c" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">在<strong class="it hj"> <em class="jp"> __getitem__ </em> </strong>的返回中我把<strong class="it hj"> <em class="jp"> </em> </strong>全文(<em class="jp">句子_正文</em>)、摘要正文(<em class="jp">摘要_正文</em>)、全文' input_ids ( <em class="jp"> input_ids </em>)、全文' attention _ mask(<em class="jp">attention _ mask</em>)以及摘要的我们可以使用不同的配置，但不要忘记这两个主要输出。摘要的输入标识。</p><h1 id="191c" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">培训</h1><figure class="ku kv kw kx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="er es le"><img src="../Images/9e095021924d5bb806f2306ec364aa0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dYx0YX5ZJtMX66GZ38Efbw.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">训练日程</figcaption></figure><p id="71d5" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">在这里，培训本身就像pytorch开发的常规培训路线。</p><p id="f62b" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">model.train() -&gt;定义dataset -&gt;定义dataloader -&gt;遍历它-&gt;将数据放入设备(cpu/cuda) -&gt;训练模型-&gt;获取输出-&gt;获取损失值-&gt;将每个batch_size的损失值添加到完整的train_loss -&gt;反向损失-&gt;步进优化器。</p><p id="409b" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">然而，模型本身需要3个特定的输入。<em class="jp"> input_ids </em>(序列输入令牌)<em class="jp"> attention_mask </em>(序列输入pad令牌与否)<em class="jp"> lm_labels </em>(右移序列目标)。</p><p id="eeb0" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">验证是类似的，不同的是我们定义模型不更新其梯度，所以我们只需要它来计算损失，如果损失比前一个时期好，我们保存当前模型。</p><h1 id="3191" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">推理</h1><figure class="ku kv kw kx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="er es lf"><img src="../Images/b0161f3aee51e9e0b99384eccbd69d38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sFuMjpXnLcM3HjZJqQf6Kw.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">推理模型</figcaption></figure><p id="1ee5" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">为了进行推理(或者生成摘要本身)，transformer在model类中已经有了一个函数<strong class="it hj"> <em class="jp"> generate </em> </strong>。我们只需要input_ids和attention_mask的输入。差不多就是这样。其他参数是可选的。它的返回是摘要的<strong class="it hj"> <em class="jp">令牌id，</em> </strong>因此我们需要使用令牌化器对其进行解码。而且也已经有了，很方便。</p><h1 id="3f44" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">结果呢</h1><figure class="ku kv kw kx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="er es lg"><img src="../Images/b842ccea28b2039a10b7170c037b5006.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EyBap1nC0LBoYe2rhpMKtw.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">全文是原文，摘要来自数据，生成的摘要来自模型。</figcaption></figure><p id="ccee" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">我认为摘要本身的结果与全文的前几个部分非常相似。我想这是因为输入模型是一篇新闻文章，并且输入的摘要也被用作摘要。</p><p id="326c" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">总结任务中通常使用的指标是ROUGE。但在这一次，我不是计算指标，而是依靠收集的损失。在3个时期之后，对于第一次折叠的数据，我得到了大约0.35的训练损失和价值损失。</p><p id="65f2" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">你可以在这里看到完整的笔记本<a class="ae iq" href="https://github.com/imanueldrxl/NLPLearning/blob/master/Text%20Summarization.ipynb" rel="noopener ugc nofollow" target="_blank">，</a>但是不要忘记把“cuda”换成你拥有的设备…还有读/写文档的路径。</p><p id="41ba" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">干杯。</p></div></div>    
</body>
</html>