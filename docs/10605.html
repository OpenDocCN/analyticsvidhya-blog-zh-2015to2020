<html>
<head>
<title>Deep Learning with Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Python进行深度学习</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/deep-learning-with-python-f7b1898d16e0?source=collection_archive---------8-----------------------#2020-10-26">https://medium.com/analytics-vidhya/deep-learning-with-python-f7b1898d16e0?source=collection_archive---------8-----------------------#2020-10-26</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><figure class="hh hi ez fb hj hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es hg"><img src="../Images/17454865ffe72b57888b8677b75ec21e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Cm4uE6JwHzeNl_QkP7-aog.jpeg"/></div></div></figure><div class=""/><ul class=""><li id="44b3" class="iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh bi translated">介绍</li><li id="606a" class="iq ir ht is b it ji iv jj ix jk iz jl jb jm jd je jf jg jh bi translated">导入库</li><li id="a78b" class="iq ir ht is b it ji iv jj ix jk iz jl jb jm jd je jf jg jh bi translated">探索数据集</li><li id="4dd2" class="iq ir ht is b it ji iv jj ix jk iz jl jb jm jd je jf jg jh bi translated">处理数据集</li><li id="7112" class="iq ir ht is b it ji iv jj ix jk iz jl jb jm jd je jf jg jh bi translated">逻辑回归</li><li id="2eaa" class="iq ir ht is b it ji iv jj ix jk iz jl jb jm jd je jf jg jh bi translated">无sklearn的逻辑回归</li><li id="7c4a" class="iq ir ht is b it ji iv jj ix jk iz jl jb jm jd je jf jg jh bi translated">使用sklearn的逻辑回归</li><li id="905d" class="iq ir ht is b it ji iv jj ix jk iz jl jb jm jd je jf jg jh bi translated">层神经网络</li></ul><h1 id="8b4e" class="jn jo ht bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">介绍</h1><ul class=""><li id="6303" class="iq ir ht is b it kl iv km ix kn iz ko jb kp jd je jf jg jh bi translated">机器学习是指机器学习使用大数据集，而不是硬编码的规则。</li><li id="c412" class="iq ir ht is b it ji iv jj ix jk iz jl jb jm jd je jf jg jh bi translated">机器学习允许计算机自己学习。这种类型的学习利用了现代计算机的计算能力，可以轻松处理大型数据集。</li></ul><h2 id="a637" class="kq jo ht bd jp kr ks kt jt ku kv kw jx ix kx ky kb iz kz la kf jb lb lc kj ld bi translated">监督和非监督学习</h2><ul class=""><li id="2737" class="iq ir ht is b it kl iv km ix kn iz ko jb kp jd je jf jg jh bi translated">监督学习包括使用带有输入和预期输出的标记数据集。 <br/>当你使用监督学习训练一个人工智能时，你给它一个输入，并说出预期输出。如果人工智能产生的输出是错误的，它会调整自己的计算。这个过程在数据集上重复进行，直到最小化人工智能的错误率。监督学习的一个例子是决定天气的人工智能。学习使用历史数据预测天气。这些训练数据包括输入(压力、湿度、风速)和输出(温度)。</li><li id="98a6" class="iq ir ht is b it ji iv jj ix jk iz jl jb jm jd je jf jg jh bi translated"><strong class="is hu">无监督学习是使用没有特定结构的数据集进行机器学习的任务。</strong> <br/>如果你使用无监督学习训练一个AI，你就允许人工智能对数据进行逻辑分类。无监督学习的一个例子是为电子商务网站进行预测的人工智能的例子。因为在这里，它不是使用带标签的输入和输出数据集学习的。相反，它将使用输入数据创建自己的分类。它会告诉你哪些类型的用户可以购买更多不同的产品。</li></ul><h2 id="c316" class="kq jo ht bd jp kr ks kt jt ku kv kw jx ix kx ky kb iz kz la kf jb lb lc kj ld bi translated">什么是深度学习，它是如何工作的？</h2><ul class=""><li id="a6e4" class="iq ir ht is b it kl iv km ix kn iz ko jb kp jd je jf jg jh bi translated"><strong class="is hu">深度学习:</strong> <br/>深度学习是基于具有表示学习的人工神经网络的更广泛的机器学习方法家族的一部分。学习可以是有监督的、半监督的或无监督的。</li><li id="6a3d" class="iq ir ht is b it ji iv jj ix jk iz jl jb jm jd je jf jg jh bi translated"><strong class="is hu">为什么深度学习:</strong> <br/>当数据量增加时，机器学习技术在性能方面是不够的，深度学习给出了更好的性能，如准确性。</li></ul><figure class="lf lg lh li fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es le"><img src="../Images/bf5ef840b59b5a799cee10513d471115.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fdUwIWA-ta1ABrn02-TFSA.jpeg"/></div></div></figure><ul class=""><li id="65c5" class="iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh bi translated">深度学习是一种机器学习方法。它允许我们训练人工智能用给定的数据集预测输出。监督学习和非监督学习都可以用来训练人工智能。</li></ul><p id="1887" class="pw-post-body-paragraph lj lk ht is b it iu ll lm iv iw ln lo ix lp lq lr iz ls lt lu jb lv lw lx jd hb bi translated">我将尝试用深度学习的机票价格预测的例子来解释工作的逻辑。在这个例子中，我们将使用监督学习。在估算机票价格时，假设我们想要使用以下条目(现在我们考虑单程航班):</p><ul class=""><li id="8355" class="iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh bi translated">出发机场</li><li id="dd61" class="iq ir ht is b it ji iv jj ix jk iz jl jb jm jd je jf jg jh bi translated">到达机场</li><li id="ed7d" class="iq ir ht is b it ji iv jj ix jk iz jl jb jm jd je jf jg jh bi translated">启程日期</li><li id="798f" class="iq ir ht is b it ji iv jj ix jk iz jl jb jm jd je jf jg jh bi translated">公司</li></ul><h2 id="20d7" class="kq jo ht bd jp kr ks kt jt ku kv kw jx ix kx ky kb iz kz la kf jb lb lc kj ld bi translated">神经网络</h2><p id="9adf" class="pw-post-body-paragraph lj lk ht is b it kl ll lm iv km ln lo ix ly lq lr iz lz lt lu jb ma lw lx jd hb bi translated">人工神经网络是由神经元组成的，就像人脑一样。所有神经元都是相互连接的，并影响输出。</p><figure class="lf lg lh li fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mb"><img src="../Images/8877d9a0ec989904c6a990a19ca8e595.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3fA77_mLNiJTSgZFhYnU0Q.png"/></div></div></figure><p id="7e08" class="pw-post-body-paragraph lj lk ht is b it iu ll lm iv iw ln lo ix lp lq lr iz ls lt lu jb lv lw lx jd hb bi translated">神经元分为三个不同的层:</p><ul class=""><li id="0aa8" class="iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh bi translated">入口层</li><li id="c9e0" class="iq ir ht is b it ji iv jj ix jk iz jl jb jm jd je jf jg jh bi translated">隐藏层</li><li id="3f9e" class="iq ir ht is b it ji iv jj ix jk iz jl jb jm jd je jf jg jh bi translated">输出层</li></ul><p id="1d64" class="pw-post-body-paragraph lj lk ht is b it iu ll lm iv iw ln lo ix lp lq lr iz ls lt lu jb lv lw lx jd hb bi translated"><strong class="is hu">输入层</strong>接收输入数据。在我们的例子中，入口层有四个神经元:出发机场、到达机场、出发日期和公司。输入层将条目发送到第一个隐藏层。</p><p id="84a2" class="pw-post-body-paragraph lj lk ht is b it iu ll lm iv iw ln lo ix lp lq lr iz ls lt lu jb lv lw lx jd hb bi translated"><strong class="is hu">隐藏层</strong>在我们的输入中执行数学计算。创建人工神经网络的挑战之一是决定隐藏层的数量以及每层的神经元数量。</p><p id="6cb4" class="pw-post-body-paragraph lj lk ht is b it iu ll lm iv iw ln lo ix lp lq lr iz ls lt lu jb lv lw lx jd hb bi translated">深度学习中的“深”是指有不止一个隐藏层。</p><p id="e4de" class="pw-post-body-paragraph lj lk ht is b it iu ll lm iv iw ln lo ix lp lq lr iz ls lt lu jb lv lw lx jd hb bi translated"><strong class="is hu">输出层</strong>返回输出数据。在我们的例子中，它给出了一个价格估计。</p><p id="197b" class="pw-post-body-paragraph lj lk ht is b it iu ll lm iv iw ln lo ix lp lq lr iz ls lt lu jb lv lw lx jd hb bi translated"><strong class="is hu">那么价格预测是怎么做的呢？<br/> </strong>这就是深度学习开始的地方。<br/>神经元之间的每一个链接都与一个“权重”相关联。这个权重决定了输入值的重要性。第一个权重是随机设置的。估算机票价格时，最重要的(权重)因素之一是出发日期。因此，出发日期的神经元连接会有很大的权重。</p><figure class="lf lg lh li fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mc"><img src="../Images/3e4c4a10a0e77bc4cbf58ce9831c3e29.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Vv17tfRRUR3Y04mqVKMfSQ.jpeg"/></div></div></figure><p id="1afc" class="pw-post-body-paragraph lj lk ht is b it iu ll lm iv iw ln lo ix lp lq lr iz ls lt lu jb lv lw lx jd hb bi translated">每个神经元都有激活功能。激活函数的目标之一是“标准化”神经元的输出。</p><p id="5de0" class="pw-post-body-paragraph lj lk ht is b it iu ll lm iv iw ln lo ix lp lq lr iz ls lt lu jb lv lw lx jd hb bi translated">数据集通过神经网络的所有层后，将作为输出层的结果返回。</p><h1 id="f0b7" class="jn jo ht bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">导入库</h1><p id="b5b9" class="pw-post-body-paragraph lj lk ht is b it kl ll lm iv km ln lo ix ly lq lr iz lz lt lu jb ma lw lx jd hb bi translated">我们需要做的第一件事是导入库。</p><figure class="lf lg lh li fd hk"><div class="bz dy l di"><div class="md me l"/></div></figure><h1 id="3a95" class="jn jo ht bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">探索数据集</h1><figure class="lf lg lh li fd hk"><div class="bz dy l di"><div class="md me l"/></div></figure><figure class="lf lg lh li fd hk"><div class="bz dy l di"><div class="md me l"/></div></figure><figure class="lf lg lh li fd hk er es paragraph-image"><div class="er es mf"><img src="../Images/cf0650ea4369157b2299d7eeb421308d.png" data-original-src="https://miro.medium.com/v2/resize:fit:776/format:webp/1*qSe5QwqEI_DE-91rlO9hcg.png"/></div></figure><figure class="lf lg lh li fd hk"><div class="bz dy l di"><div class="md me l"/></div></figure><figure class="lf lg lh li fd hk er es paragraph-image"><div class="er es mf"><img src="../Images/1225bd43fafa6abfe44ef0d8c56a9a99.png" data-original-src="https://miro.medium.com/v2/resize:fit:776/format:webp/1*ZR2HTr8DZAhim24AeyjtYg.png"/></div></figure><figure class="lf lg lh li fd hk"><div class="bz dy l di"><div class="md me l"/></div></figure><figure class="lf lg lh li fd hk er es paragraph-image"><div class="er es mg"><img src="../Images/43880ff371254a46757174cec7f057ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:738/format:webp/1*tFzfzJ1KDdlqcfW6lYCB2g.png"/></div></figure><h1 id="1b00" class="jn jo ht bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">处理数据集</h1><p id="853e" class="pw-post-body-paragraph lj lk ht is b it kl ll lm iv km ln lo ix ly lq lr iz lz lt lu jb ma lw lx jd hb bi translated">现在我们需要修改图像。数据集包含不同大小的RGB彩色图像。首先，我们应该调整所有图像的大小，其次将图像转换为灰度。根据不同的目的，你可以选择RGB图像。但是灰度只有一个维度，而RGB图像有3个维度，帮助你避免错误的分类和复杂性。</p><figure class="lf lg lh li fd hk"><div class="bz dy l di"><div class="md me l"/></div></figure><figure class="lf lg lh li fd hk"><div class="bz dy l di"><div class="md me l"/></div></figure><pre class="lf lg lh li fd mh mi mj mk aw ml bi"><span id="9061" class="kq jo ht mi b fi mm mn l mo mp">humans: (527, 50, 50) horses: (500, 50, 50)<br/>train_dataset: (1027, 50, 50) train_values: (1027, 1)</span></pre><p id="7e3d" class="pw-post-body-paragraph lj lk ht is b it iu ll lm iv iw ln lo ix lp lq lr iz ls lt lu jb lv lw lx jd hb bi translated">缩小列车组图像，我们有:</p><p id="d027" class="pw-post-body-paragraph lj lk ht is b it iu ll lm iv iw ln lo ix lp lq lr iz ls lt lu jb lv lw lx jd hb bi translated">(527，50，50)大小的人和马数组— -&gt; total train_set (1027，50，50)相应标签值的标签数组，标签1表示人，标签0表示马— -&gt; total train_set_label (1027，1)</p><figure class="lf lg lh li fd hk"><div class="bz dy l di"><div class="md me l"/></div></figure><figure class="lf lg lh li fd hk"><div class="bz dy l di"><div class="md me l"/></div></figure><pre class="lf lg lh li fd mh mi mj mk aw ml bi"><span id="e77e" class="kq jo ht mi b fi mm mn l mo mp">humans: (128, 50, 50) horses: (128, 50, 50)<br/>test_dataset: (256, 50, 50) test_values: (256, 1)</span></pre><p id="dabf" class="pw-post-body-paragraph lj lk ht is b it iu ll lm iv iw ln lo ix lp lq lr iz ls lt lu jb lv lw lx jd hb bi translated">缩小列车组图像，我们有:</p><p id="14b6" class="pw-post-body-paragraph lj lk ht is b it iu ll lm iv iw ln lo ix lp lq lr iz ls lt lu jb lv lw lx jd hb bi translated">(128，50，50)大小的人和马数组— -&gt; total train_set (256，50，50)相应标签值的标签数组，标签1表示人，标签0表示马— -&gt; total train_set_label (256，1)</p><p id="7269" class="pw-post-body-paragraph lj lk ht is b it iu ll lm iv iw ln lo ix lp lq lr iz ls lt lu jb lv lw lx jd hb bi translated">我们组合图像字符串和标签，并展平“x”:</p><figure class="lf lg lh li fd hk"><div class="bz dy l di"><div class="md me l"/></div></figure><pre class="lf lg lh li fd mh mi mj mk aw ml bi"><span id="3075" class="kq jo ht mi b fi mm mn l mo mp">images: (1283, 2500) labels: (1283, 1)</span></pre><p id="f4ab" class="pw-post-body-paragraph lj lk ht is b it iu ll lm iv iw ln lo ix lp lq lr iz ls lt lu jb lv lw lx jd hb bi translated">下一步，我们需要确定训练和测试的数据量。您可以修改test_size，看看它如何影响准确性。我们分开吧！</p><figure class="lf lg lh li fd hk"><div class="bz dy l di"><div class="md me l"/></div></figure><pre class="lf lg lh li fd mh mi mj mk aw ml bi"><span id="cc3a" class="kq jo ht mi b fi mm mn l mo mp">Train Number:  1090<br/>Test Number:  193</span></pre><p id="a716" class="pw-post-body-paragraph lj lk ht is b it iu ll lm iv iw ln lo ix lp lq lr iz ls lt lu jb lv lw lx jd hb bi translated">然后我们需要对所有矩阵进行转置。这里引用的<a class="ae mq" href="https://www.quora.com/Why-do-we-transpose-matrices-in-machine-learning" rel="noopener ugc nofollow" target="_blank">的目的是:“在python中，通常情况下，转置将使您能够以给定的形式获得数据，这可能会使使用任何框架或算法变得更容易”</a></p><figure class="lf lg lh li fd hk"><div class="bz dy l di"><div class="md me l"/></div></figure><pre class="lf lg lh li fd mh mi mj mk aw ml bi"><span id="ce2e" class="kq jo ht mi b fi mm mn l mo mp">x train:  (2500, 1090)<br/>x test:  (2500, 193)<br/>y train:  (1, 1090)<br/>y test:  (1, 193)</span></pre><h1 id="5ffc" class="jn jo ht bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">无sklearn的逻辑回归</h1><figure class="lf lg lh li fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mr"><img src="../Images/1144806db1838c2f4db3e679437bea73.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g-kAovlzAZgLIEGwszaBkw.jpeg"/></div></div></figure><p id="7a4d" class="pw-post-body-paragraph lj lk ht is b it iu ll lm iv iw ln lo ix lp lq lr iz ls lt lu jb lv lw lx jd hb bi translated">“逻辑回归”使用以下函数:</p><ul class=""><li id="ea87" class="iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh bi translated">initialize_weights_and_bias:具有权重和偏差的初始值，这些值将在以后更新</li><li id="5bc5" class="iq ir ht is b it ji iv jj ix jk iz jl jb jm jd je jf jg jh bi translated">sigmoid:将输出限制在0和1之间的激活功能</li><li id="367a" class="iq ir ht is b it ji iv jj ix jk iz jl jb jm jd je jf jg jh bi translated">forward_backward propagation:用于计算成本函数(误差)和梯度下降(学习使误差最小化的适当权重和偏差值)</li><li id="da8e" class="iq ir ht is b it ji iv jj ix jk iz jl jb jm jd je jf jg jh bi translated">更新:更新学习参数“w”和“b ”,以找到它们的最佳值，从而进行更好的训练</li><li id="24d9" class="iq ir ht is b it ji iv jj ix jk iz jl jb jm jd je jf jg jh bi translated">预测:使用x_test作为正向传播的输入</li></ul><figure class="lf lg lh li fd hk"><div class="bz dy l di"><div class="md me l"/></div></figure><figure class="lf lg lh li fd hk er es paragraph-image"><div class="er es ms"><img src="../Images/33ec173bd850b9ba87755e1f36a42dca.png" data-original-src="https://miro.medium.com/v2/resize:fit:996/1*Be3Bhz0BA-NgZIYqRVZtug.gif"/></div></figure><figure class="lf lg lh li fd hk"><div class="bz dy l di"><div class="md me l"/></div></figure><figure class="lf lg lh li fd hk"><div class="bz dy l di"><div class="md me l"/></div></figure><figure class="lf lg lh li fd hk"><div class="bz dy l di"><div class="md me l"/></div></figure><p id="ea56" class="pw-post-body-paragraph lj lk ht is b it iu ll lm iv iw ln lo ix lp lq lr iz ls lt lu jb lv lw lx jd hb bi translated">整体情况:</p><figure class="lf lg lh li fd hk"><div class="bz dy l di"><div class="md me l"/></div></figure><figure class="lf lg lh li fd hk"><div class="bz dy l di"><div class="md me l"/></div></figure><pre class="lf lg lh li fd mh mi mj mk aw ml bi"><span id="241d" class="kq jo ht mi b fi mm mn l mo mp">Cost after iteration 0: 6.768180<br/>Cost after iteration 50: 0.671340<br/>Cost after iteration 100: 0.639800<br/>Cost after iteration 150: 0.614246<br/>Cost after iteration 200: 0.593256<br/>Cost after iteration 250: 0.575786<br/>Cost after iteration 300: 0.561055<br/>Cost after iteration 350: 0.548477<br/>Cost after iteration 400: 0.537610<br/>Cost after iteration 450: 0.528121<br/>Cost after iteration 500: 0.519752<br/>Cost after iteration 550: 0.512306<br/>Cost after iteration 600: 0.505626<br/>Cost after iteration 650: 0.499588<br/>Cost after iteration 700: 0.494095<br/>Cost after iteration 750: 0.489066<br/>Cost after iteration 800: 0.484436<br/>Cost after iteration 850: 0.480152<br/>Cost after iteration 900: 0.476169<br/>Cost after iteration 950: 0.472450<br/>Cost after iteration 1000: 0.468965<br/>Cost after iteration 1050: 0.465686<br/>Cost after iteration 1100: 0.462591<br/>Cost after iteration 1150: 0.459662<br/>Cost after iteration 1200: 0.456880<br/>Cost after iteration 1250: 0.454232<br/>Cost after iteration 1300: 0.451705<br/>Cost after iteration 1350: 0.449289<br/>Cost after iteration 1400: 0.446974<br/>Cost after iteration 1450: 0.444750<br/>Cost after iteration 1500: 0.442612<br/>Cost after iteration 1550: 0.440551<br/>Cost after iteration 1600: 0.438563<br/>Cost after iteration 1650: 0.436641<br/>Cost after iteration 1700: 0.434782<br/>Cost after iteration 1750: 0.432980<br/>Cost after iteration 1800: 0.431232<br/>Cost after iteration 1850: 0.429535<br/>Cost after iteration 1900: 0.427885<br/>Cost after iteration 1950: 0.426279</span></pre><figure class="lf lg lh li fd hk er es paragraph-image"><div class="er es mt"><img src="../Images/a483a95925afc40ddabd822a13d47b67.png" data-original-src="https://miro.medium.com/v2/resize:fit:744/format:webp/1*hnLw3scxQMF0ek7pq656RQ.png"/></div></figure><pre class="lf lg lh li fd mh mi mj mk aw ml bi"><span id="ce2b" class="kq jo ht mi b fi mm mn l mo mp">train accuracy: % 81.56<br/>test accuracy: % 79.79</span></pre><h1 id="37be" class="jn jo ht bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">使用sklearn的逻辑回归</h1><p id="2e0e" class="pw-post-body-paragraph lj lk ht is b it kl ll lm iv km ln lo ix ly lq lr iz lz lt lu jb ma lw lx jd hb bi translated">我们将使用sklearn获得逻辑回归的精度值。另外，我会用LR w/o sklearn比较两种不同线性模型的精度:</p><ul class=""><li id="dd81" class="iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh bi translated">逻辑回归</li><li id="6f4d" class="iq ir ht is b it ji iv jj ix jk iz jl jb jm jd je jf jg jh bi translated">感知器</li></ul><figure class="lf lg lh li fd hk"><div class="bz dy l di"><div class="md me l"/></div></figure><figure class="lf lg lh li fd hk"><div class="bz dy l di"><div class="md me l"/></div></figure><pre class="lf lg lh li fd mh mi mj mk aw ml bi"><span id="0e4f" class="kq jo ht mi b fi mm mn l mo mp">Fitting 10 folds for each of 40 candidates, totalling 400 fits</span><span id="5eda" class="kq jo ht mi b fi mu mn l mo mp">[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.<br/>[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.8s<br/>[Parallel(n_jobs=-1)]: Done 276 tasks      | elapsed:   18.5s</span><span id="831e" class="kq jo ht mi b fi mu mn l mo mp">accuracy:  0.8972477064220185</span><span id="f5b3" class="kq jo ht mi b fi mu mn l mo mp">[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:   29.9s finished</span></pre><figure class="lf lg lh li fd hk"><div class="bz dy l di"><div class="md me l"/></div></figure><figure class="lf lg lh li fd hk er es paragraph-image"><div class="er es mv"><img src="../Images/6f77a2911273d51996a10d8a0879b085.png" data-original-src="https://miro.medium.com/v2/resize:fit:658/format:webp/1*q5AvytvyCPeQJsEYxT1E1Q.jpeg"/></div></figure><h1 id="b558" class="jn jo ht bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">层神经网络</h1><figure class="lf lg lh li fd hk"><div class="bz dy l di"><div class="md me l"/></div></figure><pre class="lf lg lh li fd mh mi mj mk aw ml bi"><span id="55fe" class="kq jo ht mi b fi mm mn l mo mp">2500</span></pre><figure class="lf lg lh li fd hk"><div class="bz dy l di"><div class="md me l"/></div></figure><h2 id="e063" class="kq jo ht bd jp kr ks kt jt ku kv kw jx ix kx ky kb iz kz la kf jb lb lc kj ld bi translated">正向传播</h2><ul class=""><li id="d0ef" class="iq ir ht is b it kl iv km ix kn iz ko jb kp jd je jf jg jh bi translated">正向传播几乎与逻辑回归相同。</li><li id="cc0d" class="iq ir ht is b it ji iv jj ix jk iz jl jb jm jd je jf jg jh bi translated">唯一的区别是我们使用了双曲正切函数，所有的过程都做了两次。</li><li id="9d8c" class="iq ir ht is b it ji iv jj ix jk iz jl jb jm jd je jf jg jh bi translated">还有，NumPy有tanh功能。所以我们不需要实现它。</li></ul><figure class="lf lg lh li fd hk er es paragraph-image"><div class="er es mw"><img src="../Images/8516c352f3d0c867fa239de0a1bb9202.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/1*nCyfMAbArO5wY_dKaFeHKg.gif"/></div></figure><figure class="lf lg lh li fd hk"><div class="bz dy l di"><div class="md me l"/></div></figure><h2 id="0d10" class="kq jo ht bd jp kr ks kt jt ku kv kw jx ix kx ky kb iz kz la kf jb lb lc kj ld bi translated">损失函数和成本函数</h2><ul class=""><li id="6115" class="iq ir ht is b it kl iv km ix kn iz ko jb kp jd je jf jg jh bi translated">损失和成本函数与逻辑回归相同</li><li id="9cd7" class="iq ir ht is b it ji iv jj ix jk iz jl jb jm jd je jf jg jh bi translated">交叉熵函数</li></ul><figure class="lf lg lh li fd hk"><div class="bz dy l di"><div class="md me l"/></div></figure><h2 id="c437" class="kq jo ht bd jp kr ks kt jt ku kv kw jx ix kx ky kb iz kz la kf jb lb lc kj ld bi translated">反向传播</h2><ul class=""><li id="9abb" class="iq ir ht is b it kl iv km ix kn iz ko jb kp jd je jf jg jh bi translated">如你所知，反向传播意味着导数。</li></ul><figure class="lf lg lh li fd hk"><div class="bz dy l di"><div class="md me l"/></div></figure><h2 id="c5f2" class="kq jo ht bd jp kr ks kt jt ku kv kw jx ix kx ky kb iz kz la kf jb lb lc kj ld bi translated">更新参数</h2><figure class="lf lg lh li fd hk"><div class="bz dy l di"><div class="md me l"/></div></figure><h2 id="8330" class="kq jo ht bd jp kr ks kt jt ku kv kw jx ix kx ky kb iz kz la kf jb lb lc kj ld bi translated">利用学习参数权重和偏差进行预测</h2><figure class="lf lg lh li fd hk"><div class="bz dy l di"><div class="md me l"/></div></figure><h2 id="a24d" class="kq jo ht bd jp kr ks kt jt ku kv kw jx ix kx ky kb iz kz la kf jb lb lc kj ld bi translated">创建模型</h2><figure class="lf lg lh li fd hk"><div class="bz dy l di"><div class="md me l"/></div></figure><figure class="lf lg lh li fd hk"><div class="bz dy l di"><div class="md me l"/></div></figure><pre class="lf lg lh li fd mh mi mj mk aw ml bi"><span id="2c0c" class="kq jo ht mi b fi mm mn l mo mp">Cost after iteration 0: 0.335414<br/>Cost after iteration 100: 0.255368<br/>Cost after iteration 200: 0.209950<br/>Cost after iteration 300: 0.143634<br/>Cost after iteration 400: 0.093869<br/>Cost after iteration 500: 0.121465<br/>Cost after iteration 600: 0.063286<br/>Cost after iteration 700: 0.285031<br/>Cost after iteration 800: 0.207963<br/>Cost after iteration 900: 0.121714<br/>Cost after iteration 1000: 0.181648<br/>Cost after iteration 1100: 0.272117<br/>Cost after iteration 1200: 0.036312<br/>Cost after iteration 1300: 0.114032<br/>Cost after iteration 1400: 0.126075<br/>Cost after iteration 1500: 0.115258<br/>Cost after iteration 1600: 0.082057<br/>Cost after iteration 1700: 0.238091<br/>Cost after iteration 1800: 0.082687<br/>Cost after iteration 1900: 0.050634<br/>Cost after iteration 2000: 0.031490<br/>Cost after iteration 2100: 0.248394<br/>Cost after iteration 2200: 0.053589<br/>Cost after iteration 2300: 0.104359<br/>Cost after iteration 2400: 0.045909</span></pre><figure class="lf lg lh li fd hk er es paragraph-image"><div class="er es mx"><img src="../Images/4134871ea9f38ef5ad1cf2ae0cbb6298.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*OR3jMvDyCR6f1XQjvGRBdA.png"/></div></figure><pre class="lf lg lh li fd mh mi mj mk aw ml bi"><span id="6028" class="kq jo ht mi b fi mm mn l mo mp">train accuracy: 85.59633027522936 %<br/>test accuracy: 79.27461139896373 %</span></pre><h2 id="d828" class="kq jo ht bd jp kr ks kt jt ku kv kw jx ix kx ky kb iz kz la kf jb lb lc kj ld bi translated">l层神经网络</h2><figure class="lf lg lh li fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es my"><img src="../Images/a992908726666d074a1a5d15f47653e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*RpRKZqiNX6WRWu_g4_2wzA.gif"/></div></div></figure><figure class="lf lg lh li fd hk"><div class="bz dy l di"><div class="md me l"/></div></figure><figure class="lf lg lh li fd hk"><div class="bz dy l di"><div class="md me l"/></div></figure><pre class="lf lg lh li fd mh mi mj mk aw ml bi"><span id="7b88" class="kq jo ht mi b fi mm mn l mo mp">Using TensorFlow backend.</span></pre><figure class="lf lg lh li fd hk"><div class="bz dy l di"><div class="md me l"/></div></figure><pre class="lf lg lh li fd mh mi mj mk aw ml bi"><span id="406b" class="kq jo ht mi b fi mm mn l mo mp">Epoch 1/100<br/>872/872 [==============================] - 0s 379us/step - loss: 0.6913 - accuracy: 0.5161<br/>Epoch 2/100<br/>872/872 [==============================] - 0s 57us/step - loss: 0.6836 - accuracy: 0.5149<br/>...<br/>...<br/>...<br/>Epoch 98/100<br/>872/872 [==============================] - 0s 56us/step - loss: 0.0448 - accuracy: 0.9920<br/>Epoch 99/100<br/>872/872 [==============================] - 0s 57us/step - loss: 0.0430 - accuracy: 0.9931<br/>Epoch 100/100<br/>872/872 [==============================] - 0s 56us/step - loss: 0.0547 - accuracy: 0.9839<br/>218/218 [==============================] - 0s 127us/step</span></pre><figure class="lf lg lh li fd hk"><div class="bz dy l di"><div class="md me l"/></div></figure><pre class="lf lg lh li fd mh mi mj mk aw ml bi"><span id="1281" class="kq jo ht mi b fi mm mn l mo mp">Accuracies:  [0.87155962 0.90366971 0.90825689 0.8440367  0.84862387]</span></pre><figure class="lf lg lh li fd hk"><div class="bz dy l di"><div class="md me l"/></div></figure><pre class="lf lg lh li fd mh mi mj mk aw ml bi"><span id="9b8c" class="kq jo ht mi b fi mm mn l mo mp">Accuracy mean:  0.8752293586730957</span></pre></div><div class="ab cl mz na gp nb" role="separator"><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne"/></div><div class="hb hc hd he hf"><p id="5564" class="pw-post-body-paragraph lj lk ht is b it iu ll lm iv iw ln lo ix lp lq lr iz ls lt lu jb lv lw lx jd hb bi translated">这是一篇又长又详细的文章。我希望你已经理解了以上所有的主题。你可以按底部的双手按钮激励我，也可以在评论里说我哪里缺失，帮助我以后写出更好的文章。<br/>我的Kaggle工作的链接，从那里我得到了这篇文章:<a class="ae mq" href="https://www.kaggle.com/codeblogger/deep-learning-with-python" rel="noopener ugc nofollow" target="_blank">我的Kaggle笔记本</a></p></div></div>    
</body>
</html>