<html>
<head>
<title>Airlines on Twitter — Understanding Customer Complaints with NLP</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Twitter上的航空公司——使用NLP了解客户投诉</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/airlines-on-twitter-understanding-customer-complaints-with-nlp-81278f2b68dc?source=collection_archive---------2-----------------------#2020-06-12">https://medium.com/analytics-vidhya/airlines-on-twitter-understanding-customer-complaints-with-nlp-81278f2b68dc?source=collection_archive---------2-----------------------#2020-06-12</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="1aa2" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">作者:詹妮弗·西乌、艾米·李、马修·洛克、安尼施·卡拉加、马诺哈尔·阿卢</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="jl jm di jn bf jo"><div class="er es jf"><img src="../Images/b02b5bb33624b4949b6b527b927ef008.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Cg8aS-IHThErnRrz"/></div></div></figure></div><div class="ab cl jr js gp jt" role="separator"><span class="ju bw bk jv jw jx"/><span class="ju bw bk jv jw jx"/><span class="ju bw bk jv jw"/></div><div class="hb hc hd he hf"><p id="e417" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">在这个项目中，我们旨在了解社交媒体上的客户投诉，特别是Twitter上关于美国主要航空公司的投诉。要了解更多关于我们的项目和我们用来实现它的代码，请查看我们的Github库<a class="ae jy" href="https://github.com/jsiwu94/airline_tweet_nlp" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><h1 id="6657" class="jz ka hi bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated"><strong class="ak">目标</strong></h1><p id="f3d0" class="pw-post-body-paragraph ig ih hi ii b ij kx il im in ky ip iq ir kz it iu iv la ix iy iz lb jb jc jd hb bi translated"><em class="je">客户情绪:</em>识别积极和消极的意见、情绪和评价。</p><p id="b557" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated"><em class="je">识别负面话题:</em>引出人们在谈论他们与航空公司的经历时可能会提到的负面话题。</p><p id="c404" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated"><em class="je">获得可操作的见解:</em>这些见解可能会被航空公司用于规划和执行客户服务计划、媒体关系等。</p><h1 id="f610" class="jz ka hi bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated"><strong class="ak">数据集</strong></h1><p id="9653" class="pw-post-body-paragraph ig ih hi ii b ij kx il im in ky ip iq ir kz it iu iv la ix iy iz lb jb jc jd hb bi translated">数据可在<a class="ae jy" href="https://www.kaggle.com/crowdflower/twitter-airline-sentiment" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>上获得。twitter数据从2015年2月开始收集，历时两周，包含超过14K条推文及其对美国6家主要航空公司的看法(正面、中立或负面)。</p><h1 id="d2f0" class="jz ka hi bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated"><strong class="ak">数据分析</strong></h1><p id="ceac" class="pw-post-body-paragraph ig ih hi ii b ij kx il im in ky ip iq ir kz it iu iv la ix iy iz lb jb jc jd hb bi translated">在开始建模之前，我们做了一些初步的数据分析，以了解数据中的一些模式或趋势。</p><p id="5dc8" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated"><strong class="ii hj">推特情绪分布&amp;按航空公司统计的推文:</strong>推文数据有63%的负面，16%的正面和21%的中性推文。联合航空公司的#tweets最多，其次是全美航空公司、美国航空公司和西南航空公司。</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="jl jm di jn bf jo"><div class="er es lc"><img src="../Images/3228a476d18ca2b412208dcf2e0249ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z1o0QikK2Jt19AE7_FeqMQ.png"/></div></div></figure><p id="4703" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated"><strong class="ii hj">按地点划分的推文情绪:</strong>推文集中在东海岸，因为那里是最繁忙的国际机场所在地。</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="jl jm di jn bf jo"><div class="er es ld"><img src="../Images/f767e9d1398a9484509b1623470f6af2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ndAiowj2bnS2B3Cs"/></div></div><figcaption class="le lf et er es lg lh bd b be z dx translated"><strong class="bd kb">橙色</strong>表示<strong class="bd kb">负面情绪</strong>，<strong class="bd kb">深蓝色</strong>表示<strong class="bd kb">正面情绪</strong>，<strong class="bd kb">浅蓝色</strong>表示<strong class="bd kb">中性情绪</strong>。</figcaption></figure><p id="5535" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated"><strong class="ii hj">按航空公司划分的Twitter情绪:</strong>美国航空、联合航空和全美航空有&gt; 60%的负面推文，有大量负面转发。</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="jl jm di jn bf jo"><div class="er es li"><img src="../Images/9dd4b98f75fbb5656f9ce9dd22e4edcf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QCVc5zDSLs9Oz0K9BE7fiA.png"/></div></div></figure><p id="1963" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated"><strong class="ii hj">情绪之间的字数分布:</strong>根据下面的密度曲线和箱线图，我们可以看到负面推文通常比其他情绪更冗长。我们的单因素方差分析测试得出结论，这些情绪之间的字数确实存在差异(p &lt; 0.01)。</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="jl jm di jn bf jo"><div class="er es lj"><img src="../Images/f12cfcac26ef811df3adcdc94bd1fdd1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ep01NvPJPTYhg2K11l7hqw.png"/></div></div></figure><p id="4050" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated"><strong class="ii hj">负面推文热门词:</strong>负面推文的词云表示延迟、hold、bag、hour、call等高频词。</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div class="er es lk"><img src="../Images/5ebb5eeb74e294c478b09bfc9f499f33.png" data-original-src="https://miro.medium.com/v2/resize:fit:970/format:webp/1*JxoDTfg2GyFjSZJwusO2XA.png"/></div></figure><h1 id="fc41" class="jz ka hi bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated"><strong class="ak">接近</strong></h1><p id="d001" class="pw-post-body-paragraph ig ih hi ii b ij kx il im in ky ip iq ir kz it iu iv la ix iy iz lb jb jc jd hb bi translated"><strong class="ii hj">方法1 —情绪分析</strong></p><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="jl jm di jn bf jo"><div class="er es ll"><img src="../Images/bc3138f7b6f244d3db1ae716878fe632.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oPXztCQsbsBljjg-Ru9CQw.png"/></div></div><figcaption class="le lf et er es lg lh bd b be z dx translated"><em class="if"> (**)表示每个算法中的最佳模型</em></figcaption></figure><p id="70c8" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated"><strong class="ii hj"> <em class="je">法</em> </strong></p><p id="c782" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">根据上面显示的模型结果总结，我们选择了带有TFIDF 的<strong class="ii hj">逻辑回归作为预测情绪的最佳模型。下面，我们将讨论这种模型的方法。</strong></p><p id="1ffb" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">由于我们只对推文的内容和每条推文的情绪水平感兴趣，所以我们提取了相应的两列，分别是‘text’和‘airline _ perspective’。下面的截图显示了5个随机的文本样本及其情感水平。</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="jl jm di jn bf jo"><div class="er es jf"><img src="../Images/3f0e9db4d531196026eeed0648648f3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*SZgpndhumfVTo68Z"/></div></div></figure><p id="0fcc" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">1.文本处理</p><p id="834f" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">首先，我们使用正则表达式清除文本中的标签、符号、提及、URL、数字和标点符号。在应用前面的步骤后，文本有一些额外的空白，稍后标记器可以将其拆分为单词。也就是说，我们删除了那些多余的空间。此外，我们确保删除所有单个字符，例如，“it's”可以转换为“it s”，然后我们需要删除“s ”,因为它没有任何意义。对于词干提取，我们注意到，虽然Porter是最常用的词干提取器，也是最温和的词干提取器之一，但有许多单词我们在提取词干后错过了它们的原意，最终降低了准确率。因此，我们决定不为文本清理部分添加词干。</p><p id="f270" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">此外，我们设置了停用词，排除了一些表示否定的词，如“不”、“不”，并更新了一些对预测情感没有意义的词。</p><p id="d473" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">此外，为了将文本分割成单词，我们做了<strong class="ii hj">标记化</strong>，下面给出了例子。</p><pre class="jg jh ji jj fd lm ln lo lp aw lq bi"><span id="59a7" class="lr ka hi ln b fi ls lt l lu lv">def clean_text(txt):<br/>    <br/>    """<br/>    removing all hashtags , punctuations, stop_words  and links, also stemming words <br/>    """<br/>    txt = txt.lower()<br/>    def remove_stopwords(txt):<br/>        return [t for t in txt if t not in stop]<br/>    #txt = re.sub(r"(?&lt;=\w)nt", "not",txt) #change don't to do not cna't to cannot <br/>    txt = re.sub(r"(@\S+)", "", txt)  # remove hashtags<br/>    txt = re.sub(r'\W', ' ', str(txt)) # remove all special characters including apastrophie <br/>    txt = txt.translate(str.maketrans('', '', string.punctuation)) # remove punctuations <br/>    txt = re.sub(r'\s+[a-zA-Z]\s+', ' ', txt)   # remove all single characters (it's -&gt; it s then we need to remove s)<br/>    txt = re.sub(r'\s+', ' ', txt, flags=re.I) # Substituting multiple spaces with single space<br/>    txt = re.sub(r"(http\S+|http)", "", txt) # remove links <br/>#    txt = ' '.join([PorterStemmer().stem(word=word) for word in txt.split(" ") if word not in stop_words ]) # stem &amp; remove stop words<br/>    txt = ''.join([i for i in txt if not i.isdigit()]).strip() # remove digits ()<br/>    return txt</span><span id="6812" class="lr ka hi ln b fi lw lt l lu lv">df['cleaned_text'] = df['text'].apply(clean_text)<br/>re_tok = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')</span><span id="637a" class="lr ka hi ln b fi lw lt l lu lv">def tokenize(s): <br/>    return re_tok.sub(r' \1 ', s).split()</span><span id="8168" class="lr ka hi ln b fi lw lt l lu lv">df['tokenized'] = df['cleaned_text'].apply(lambda row: tokenize(row))<br/>stop = set(stopwords.words('english'))<br/>stop.update(['amp', 'rt', 'cc'])<br/>stop = stop - set(['no', 'not'])</span><span id="4111" class="lr ka hi ln b fi lw lt l lu lv">def remove_stopwords(row):<br/>    return [t for t in row if t not in stop]<br/>df['tokenized'] = df['tokenized'].apply(lambda row: remove_stopwords(row))</span><span id="5ac9" class="lr ka hi ln b fi lw lt l lu lv"><br/>df[['text', 'tokenized']].head()</span></pre><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="jl jm di jn bf jo"><div class="er es jf"><img src="../Images/8ce905a5c0aea9d78de2331cfdb8719e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*kH09P5NQTyXHcHA4"/></div></div></figure><p id="c73b" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">2.文本矢量化</p><p id="8e88" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">然后，我们使用CountVectorizer和TFIDF进行文本矢量化，将文档转换为向量。</p><ol class=""><li id="a39d" class="lx ly hi ii b ij ik in io ir lz iv ma iz mb jd mc md me mf bi translated">TFIDF:对于不使用网格搜索选择的参数，我们使用最大特征2500，并忽略文档频率严格高于0.8且低于7的术语。对于求解器，我们使用牛顿-cg，因为它对未缩放的数据集是鲁棒的，并且对具有l2惩罚的多项式(也称为岭)执行得更好。Ridge包括模型中的所有变量，尽管有些变量被缩小了，但它的计算量比lasso要少。我们选择10作为正则化强度的倒数。</li><li id="0cb5" class="lx ly hi ii b ij mg in mh ir mi iv mj iz mk jd mc md me mf bi translated">count vectorizer:hyper参数在不使用网格搜索的情况下，我们忽略了文档频率严格低于5且n个gram范围内有unigram和bigram的术语。</li><li id="f276" class="lx ly hi ii b ij mg in mh ir mi iv mj iz mk jd mc md me mf bi translated">CV Gridsearch:然后我们尝试了Gridsearch推荐的超级参数，如下所示。<br/> - <strong class="ii hj"> C </strong> : 3 <br/> - <strong class="ii hj">惩罚</strong>:‘L2’<br/>-<strong class="ii hj">max _ df</strong>:0.5(<em class="je">忽略出现在超过50%的文档中的术语</em> ) <br/> - <strong class="ii hj"> min_df </strong> : 1(忽略出现在少于1个文档中的术语)<br/> - <strong class="ii hj"> ngram_range </strong> : (1，2)</li></ol><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="jl jm di jn bf jo"><div class="er es ml"><img src="../Images/4c09b1dc089d172c4394e8800e910734.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*skY1iUv845W84Sbt"/></div></div></figure><p id="d72c" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">然而，结果表明精度低于前两个模型。在查看参数时，我们注意到gridsearch推荐的hyper参数在删除术语方面更加严格。例如，TFIDF忽略出现在少于7个文档中的术语，而gridsearch建议忽略出现在少于1个文档中的术语(min_df)。</p><p id="7da0" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated"><strong class="ii hj"> <em class="je">结果</em> </strong></p><p id="d898" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">在这3个模型中，使用TFIDF的logistic回归的检验准确率最高，为80.3%。</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="jl jm di jn bf jo"><div class="er es mm"><img src="../Images/7c5e077c2037ce253c479986117842af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jvjMnn8ykzLmIMDuSHKubQ.png"/></div></div></figure><p id="d8ec" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">使用逻辑回归分类器，我们能够绘制出最重要的系数，这些系数被认为是对每个情绪水平进行预测的。正如你在下面看到的，对于负面的，“最坏的”，“小时”，“荒谬的”或专门与小时相关的词似乎对预测有很大的贡献。同样，对于积极的情绪，“太好了”、“太棒了”、“谢谢”和与感激相关的词语对情绪预测的贡献很大。</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="jl jm di jn bf jo"><div class="er es mn"><img src="../Images/10422c2fcfea26bd4548a4c8a9536c51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*fA8rXsxEALWs9WrC"/></div></div></figure><p id="7336" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated"><strong class="ii hj"> <em class="je">学习&amp;挑战</em> </strong></p><blockquote class="mo mp mq"><p id="9dc0" class="ig ih je ii b ij ik il im in io ip iq mr is it iu ms iw ix iy mt ja jb jc jd hb bi translated">我们认为TFIDF性能优于CountVectorizer的原因之一是，它可以更有效地捕捉频繁但无意义的单词，因为它可以缩小诸如"<strong class="ii hj"> LOL" </strong>或"<strong class="ii hj"> ASAP" </strong>之类的单词，同时放大与客户体验相关的独特单词。</p></blockquote><p id="3b63" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">在Twitter上执行情感分析的挑战之一是，由于每个Twitter用户对他们的体验有不同的说法，因此有许多俚语、新词、首字母缩写词、缩写词、诅咒或简单的拼写错误的词很难用当前的文本清理包或正则表达式捕获，特别是当数据很大时。下一步，我们想寻找更好的文本清理包，可以减少上述问题。</p><p id="0be6" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated"><strong class="ii hj">方法2 —使用LDA进行主题建模</strong></p><p id="f80d" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">通过方法1，我们能够以相对较高的准确度识别推文的情绪。为了进一步分析，我们想了解人们在负面推文中关注的一般话题或类别。用于主题建模的最流行和最广泛采用的算法之一是LDA(潜在狄利克雷分配)。</p><blockquote class="mo mp mq"><p id="943f" class="ig ih je ii b ij ik il im in io ip iq mr is it iu ms iw ix iy mt ja jb jc jd hb bi translated"><strong class="ii hj">潜在狄利克雷分配(LDA)</strong>—LDA的工作方式是，它假设每个文档都由各种主题的混合组成，每个主题都由各种单词的混合组成。它建立了基于狄利克雷分布的每文档主题模型和每主题单词模型。下图有助于解释算法流程。</p></blockquote><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="jl jm di jn bf jo"><div class="er es mu"><img src="../Images/1c5071272945d87f8b354f90d9a24190.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DViWh_pZOJfyDDTjWmSeQw.png"/></div></div><figcaption class="le lf et er es lg lh bd b be z dx translated"><a class="ae jy" href="https://towardsdatascience.com/light-on-math-machine-learning-intuitive-guide-to-latent-dirichlet-allocation-437c81220158" rel="noopener" target="_blank">https://towards data science . com/light-on-math-machine-learning-intuitive-guide-to-latent-Dirichlet-allocation-437 c 81220158</a></figcaption></figure><p id="fcbd" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">使用我们的数据，我们可以建立一个字典来训练ld a模型。然后，<strong class="ii hj"> LDA </strong> <strong class="ii hj">模型</strong>将输出每个主题中的热门词汇，然后分析师可以将它们归类到主题名称中(是的，它确实需要手动部分，但它仍然工作得很好)。</p><p id="b94b" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated"><strong class="ii hj"> <em class="je">方法</em> </strong></p><p id="b4fa" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">1.文本预处理</p><p id="dd89" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">LDA的第一步也是最重要的一步是数据清理，或者更具体地说，<strong class="ii hj">停用词移除</strong>。这也被认为是LDA建模的主要缺点，因为我们需要清理和挑剔许多没有真正表明主题的单词。例如，在这种情况下，诸如“行李”和“延误”等词表示不同的主题或投诉类别。然而，像“完全”或“芝加哥”这样的词就不是了。</p><p id="08d0" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">我们在文本预处理中采取的步骤如下(如下面的代码所示):</p><ol class=""><li id="c17a" class="lx ly hi ii b ij ik in io ir lz iv ma iz mb jd mc md me mf bi translated">Regex : <em class="je">删除航班号、表情符号、标签、推特用户名、文本标点和符号</em></li><li id="2ce2" class="lx ly hi ii b ij mg in mh ir mi iv mj iz mk jd mc md me mf bi translated">Html解析器+小写</li><li id="7e84" class="lx ly hi ii b ij mg in mh ir mi iv mj iz mk jd mc md me mf bi translated">停用字词扩展(&gt; 500字)，包括:<em class="je">美国城市名称、航空公司名称、日期、时间、星期几</em></li><li id="dfd0" class="lx ly hi ii b ij mg in mh ir mi iv mj iz mk jd mc md me mf bi translated">空间标记:<em class="je">去掉形容词和连词</em></li><li id="58d5" class="lx ly hi ii b ij mg in mh ir mi iv mj iz mk jd mc md me mf bi translated">斯特梅尔+ Lemmatizer</li></ol><pre class="jg jh ji jj fd lm ln lo lp aw lq bi"><span id="3617" class="lr ka hi ln b fi ls lt l lu lv">cities = pd.read_csv("<a class="ae jy" href="https://raw.githubusercontent.com/grammakov/USA-cities-and-states/master/us_cities_states_counties.csv" rel="noopener ugc nofollow" target="_blank">https://raw.githubusercontent.com/grammakov/USA-cities-and-states/master/us_cities_states_counties.csv</a>",sep="|")<br/>cities = cities.iloc[:,:2]<br/>cities.drop_duplicates(keep='first',inplace=True)</span><span id="06aa" class="lr ka hi ln b fi lw lt l lu lv">#preprocess data<br/>def preprocess(text):<br/>    stopwords = set(STOPWORDS)<br/>    stopwords.update(exclude_word_list) <br/>#this list was saved to csv and made available on our Github repo</span><span id="8c00" class="lr ka hi ln b fi lw lt l lu lv">#stopwords.update([i for i in ts])<br/>    # stopwords.update([str(i).lower() for i in cities.City]) #removing City names in US<br/>    r = re.compile(r'(?&lt;=\@)(\w+)') #remove words after tags --&gt; usually twitter account<br/>    ra = re.compile(r'(?&lt;=\#)(\w+)') #remove words after hashtags<br/>    ro = re.compile(r'(flt\d*)') #remove words after flight number<br/>    names = r.findall(text.lower())<br/>    hashtag = ra.findall(text.lower())<br/>    flight = ro.findall(text.lower())<br/>    lmtzr = WordNetLemmatizer()<br/>    def stem_tokens(tokens, lemmatize):<br/>        lemmatized = []<br/>        for item in tokens:<br/>            lemmatized.append(lmtzr.lemmatize(item,'v'))<br/>        return lemmatized<br/>    def deEmojify(inputString):<br/>        return inputString.encode('ascii', 'ignore').decode('ascii')<br/>    <br/>    doc = nlp(text)<br/>    text = deEmojify(text)<br/>    soup = BeautifulSoup(text)<br/>    text = soup.get_text()<br/>    text = "".join([ch.lower() for ch in text if ch not in string.punctuation])<br/>    tokens = nltk.word_tokenize(text)<br/>    tokens = [ch for ch in tokens if len(ch)&gt;4] #remove words with character length below 2<br/>    tokens = [ch for ch in tokens if len(ch)&lt;=15] #remove words with character length above 15 <br/>    lemm = stem_tokens(tokens, lmtzr)<br/>    lemstop = [i for i in lemm if i not in stopwords]<br/>    lemstopcl = [i for i in lemstop if i not in names]<br/>    lemstopcl = [i for i in lemstopcl if i not in hashtag]<br/>    lemstopcl = [i for i in lemstopcl if i not in flight]<br/>    lemstopcl = [i for i in lemstopcl if not i.isdigit()]<br/>    lemstopcl1 = [i for i in lemstopcl if i not in t]<br/>    return lemstopcl</span></pre><p id="44b2" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">2.选择主题的数量(K)</p><p id="08bc" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">一旦我们将单词预处理成标记，我们就可以创建一个字典(或单词包)，其中包含一个单词在训练数据集中出现的次数。使用这个单词包，我们可以训练我们的LDA模型。</p><p id="e436" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">我们还需要确定LDA的主题数量(K )(类似于确定k-means聚类的K)。尽管有许多方法来确定主题的最佳数量，但最常用的方法是使用困惑分数和连贯分数。这个想法是，困惑分数越低，连贯性分数越高，那么“K”就越好。(<a class="ae jy" href="http://qpleple.com/topic-coherence-to-evaluate-topic-models/" rel="noopener ugc nofollow" target="_blank">点击这里，如果你想了解更多关于连贯性或困惑分数</a></p><p id="50a7" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">根据下图，我们确定该数据的最佳“K”为8。因此，我们用它来训练我们的LDA模型。</p><pre class="jg jh ji jj fd lm ln lo lp aw lq bi"><span id="0956" class="lr ka hi ln b fi ls lt l lu lv">def compute_coherence_values(dictionary, corpus, texts, start, stop):<br/>    """<br/>    Compute c_v coherence for various number of topics<br/>    """<br/>    coherence_values = []<br/>    model_list = []<br/>    for num_topics in range(start, stop):<br/>        model = gensim.models.ldamodel.LdaModel(corpus=corpus, <br/>                                              num_topics=num_topics,<br/>                                              id2word=id2word,<br/>                                              random_state=90,<br/>                                              alpha='auto',<br/>                                              eta='auto',<br/>                                              per_word_topics=True)<br/>        model_list.append(model)<br/>        coherencemodel = CoherenceModel(model=model, texts=texts,<br/>                             dictionary=dictionary, coherence='c_v')<br/>        coherence_values.append(coherencemodel.get_coherence())</span><span id="b89e" class="lr ka hi ln b fi lw lt l lu lv">    return model_list, coherence_values</span><span id="0a40" class="lr ka hi ln b fi lw lt l lu lv">start=4<br/>stop=9<br/>model_list, coherence_values = compute_coherence_values(dictionary=id2word, <br/>                                    corpus=corpus,<br/>                                    texts=processed_docs,<br/>                                    start=start, stop=stop)</span></pre><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="jl jm di jn bf jo"><div class="er es mv"><img src="../Images/3997423000f85bac9d13f7db028c81e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Ojo-0CIDfNvygJP0"/></div></div></figure><p id="0ad2" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">3.训练LDA模型</p><p id="c7c3" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">使用8的k，我们得到了-9.34的困惑分数和0.60的一致性分数，考虑到有超过5个主题，这是相当不错的。</p><pre class="jg jh ji jj fd lm ln lo lp aw lq bi"><span id="3f10" class="lr ka hi ln b fi ls lt l lu lv">%%time<br/># Create Dictionary<br/>id2word = gensim.corpora.Dictionary(processed_docs)</span><span id="365b" class="lr ka hi ln b fi lw lt l lu lv"># Create Corpus: Term Document Frequency<br/>corpus = [id2word.doc2bow(text) for text in processed_docs]</span><span id="fd5f" class="lr ka hi ln b fi lw lt l lu lv"># Build LDA model<br/>lda_model1 = gensim.models.ldamodel.LdaModel(corpus=corpus,<br/>                                           id2word=id2word,<br/>                                           num_topics=8, <br/>                                           random_state=123,<br/>                                           update_every=1,<br/>                                           chunksize=10,<br/>                                           passes=10,<br/>                                           alpha='auto',<br/>                                           eta='auto',<br/>                                           iterations=125,<br/>                                           per_word_topics=True)<br/>doc_lda = lda_model1[corpus]</span></pre><p id="fa7d" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">4.LDA结果</p><p id="ef2a" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">我们现在可以打印每个主题中的顶部单词来标识主题名称。</p><pre class="jg jh ji jj fd lm ln lo lp aw lq bi"><span id="d5df" class="lr ka hi ln b fi ls lt l lu lv">from pprint import pprint<br/>pprint(lda_model4.print_topics())</span></pre><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="jl jm di jn bf jo"><div class="er es mw"><img src="../Images/36cb2d87fc9ac1a08e6580ed3c571dee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*G1LBsLBEnk3_XfeW"/></div></div></figure><p id="56b2" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">为了更好地可视化，我们使用gensim 包中的<strong class="ii hj"> pyLDAvis，它将我们的LDA模型的交互结果输出到一个html中，如下所示，其中每个气泡代表一个主题。理想的LDA模型是所有的气泡都相互分离的模型。在这种情况下，我们的模型非常好，因为大气泡(由文档中的更多令牌组成的气泡)彼此相距很远，只有小气泡彼此如此接近。</strong></p><p id="af6a" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">当我们点击每个气泡时，我们可以看到它们包含的标记的百分比，以及其中的单词及其相应的概率得分(即该单词属于该主题的概率)。</p><pre class="jg jh ji jj fd lm ln lo lp aw lq bi"><span id="a923" class="lr ka hi ln b fi ls lt l lu lv">import pyLDAvis<br/>from pyLDAvis import gensim</span><span id="fe97" class="lr ka hi ln b fi lw lt l lu lv">pyLDAvis.enable_notebook()<br/>vis = pyLDAvis.gensim.prepare(lda_model4, corpus, id2word,sort_topics=False)</span><span id="a94d" class="lr ka hi ln b fi lw lt l lu lv">pyLDAvis.save_html(vis, ‘ldaviz.html’) #run this to save your vis as html file<br/>vis</span></pre><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="jl jm di jn bf jo"><div class="er es ld"><img src="../Images/8e1bb2c21dbc7a5b06fb779d279e543d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*iDq8vHPajcaafgPm"/></div></div></figure><p id="f18e" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">基于以上单词分布，我们决定将主题命名如下:</p><ul class=""><li id="ba46" class="lx ly hi ii b ij ik in io ir lz iv ma iz mb jd mx md me mf bi translated">主题1 →延迟和客户服务</li><li id="3cf7" class="lx ly hi ii b ij mg in mh ir mi iv mj iz mk jd mx md me mf bi translated">话题2 →行李问题</li><li id="08a7" class="lx ly hi ii b ij mg in mh ir mi iv mj iz mk jd mx md me mf bi translated">话题3 →改期和退款</li><li id="de8c" class="lx ly hi ii b ij mg in mh ir mi iv mj iz mk jd mx md me mf bi translated">主题4 →电话和在线预订</li><li id="a5e2" class="lx ly hi ii b ij mg in mh ir mi iv mj iz mk jd mx md me mf bi translated">主题5 →预订问题</li><li id="2058" class="lx ly hi ii b ij mg in mh ir mi iv mj iz mk jd mx md me mf bi translated">主题6 →座位偏好</li><li id="908d" class="lx ly hi ii b ij mg in mh ir mi iv mj iz mk jd mx md me mf bi translated">主题7 →额外费用</li><li id="b4f2" class="lx ly hi ii b ij mg in mh ir mi iv mj iz mk jd mx md me mf bi translated">主题8 →客户体验</li></ul><p id="098b" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">为了使结果更具交互性，我们还使用jupyter notebook、ipywidgets和voila在本地主机站点中创建了一个简短的演示。以下是片段。</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="jl jm di jn bf jo"><div class="er es ld"><img src="../Images/d8bf0e9216b0f6217b80fc0efd283f4a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*98kW8mWV8GroB5V5"/></div></div></figure><p id="9e17" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">当我们将LDA模型结果与业务问题联系起来时，我们发现最负面的推文主题是关于延误、客户体验、退款/重新安排和行李。类似于我们在wordcloud上的初步发现。</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="jl jm di jn bf jo"><div class="er es jf"><img src="../Images/6818996aeedcb4bdd18889fe0a611b3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*zysMd6iYPlrDslZh"/></div></div></figure><p id="3242" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">此外，每个航空公司的负面推文中似乎有不同的主题分布。以美联航vs美航为例。与美国航空公司相比，联合航空公司似乎有更多关于行李问题的投诉。</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="jl jm di jn bf jo"><div class="er es my"><img src="../Images/8b478415c138864f7a347017a7a92481.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_gjxKh1tuzU_W1rzfrWBKQ.png"/></div></div></figure><p id="8a0b" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated"><strong class="ii hj"> <em class="je">学习&amp;挑战</em> </strong></p><p id="cda7" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">总的来说，LDA模型是用于主题分析的强大且易于使用的算法，因为实现时间相对较快。然而，它仍然需要并依赖于人工工作，例如彻底移除停用词并基于顶词正确标记主题。也就是说，它需要高度关注细节，并需要一个主题专家来确定包含/删除哪些单词。</p><h1 id="49a7" class="jz ka hi bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated"><strong class="ak">业务影响和建议</strong></h1><p id="ef69" class="pw-post-body-paragraph ig ih hi ii b ij kx il im in ky ip iq ir kz it iu iv la ix iy iz lb jb jc jd hb bi translated">航空业是一个非常传统的行业，一些航空公司的一般商业惯例可以追溯到其成立之初(联合航空公司成立于1931年)。航空公司并不总是试图衡量顾客的反馈和情绪。J.D. Power在1968年启动了一系列调查来收集消费者的反馈，过了好几年航空公司才有了可靠的信息来源来衡量消费者的反馈信息。</p><p id="b9a6" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">为了评估我们通过分析与我们范围内的六家航空公司相关的推文的情绪和主题而得出的结论的有效性，我们将我们的一些结论与来自美国交通部(DOT)空中交通消费者报告(ATCR)的事实进行了比较。这是一份每月发布的报告，包含关于延误、服务投诉和其他航空公司相关数据点的各种统计数据，这些数据点比较了美国各种飞行航空公司。统计数据偶尔也会被汇总，以生成季度和年度数据。</p><blockquote class="mo mp mq"><p id="43fe" class="ig ih je ii b ij ik il im in io ip iq mr is it iu ms iw ix iy mt ja jb jc jd hb bi translated"><strong class="ii hj">几个有趣的事实:</strong><br/>* 2015年全年投诉量增长29.8%<br/>*所有美国国内航班的预定取消率为1.5%<br/>*联合航空公司在17家航空公司中的排名:<br/>*处理不当的行李最少:第11位<br/>*准点率:第15位<br/>*取消最少:第16位<br/>*每位乘客的投诉最少:第17位</p></blockquote><p id="83cc" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">如上图所示，2015年的投诉量有所增加，并且随着行业的发展，投诉量还会继续增加。此外，取消率可能听起来很小，只有1.5%。但考虑到一个每年有950万次国内航班的市场，这意味着全年大约有142，500次航班的乘客受到影响。航空公司需要一种比月度/季度/年度报告更实时地了解消费者情绪的方法。如果航空公司希望真正做到敏捷，并在客户出现需求时满足他们的需求，这种频率是不够的。</p><p id="3d18" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">一些关于联合航空公司表现的有趣排名是，他们在准点表现，最少取消，最少投诉和最少误处理行李方面接近美国国内航空公司的最后一名。从我们的推文数据中，我们看到消费者也对联合航空公司和这些相同的类别抱怨最多。在高水平上，这表明在twitter情绪和主题分析结果与用ATCR汇编的数据之间的关系中存在一些相关性，但不一定是因果关系。</p><blockquote class="mo mp mq"><p id="18db" class="ig ih je ii b ij ik il im in io ip iq mr is it iu ms iw ix iy mt ja jb jc jd hb bi translated">(此外，2015年乘客数量最多的航空公司是美国航空公司，其负面推文比联合航空公司少……)</p></blockquote><p id="b971" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">如果航空公司还没有采取社交媒体和情感/话题分析策略，他们肯定应该这样做。</p><p id="53bf" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">使用我们2015年的Twitter数据，我们观察到，我们的分析见解和美国DOT获得的定量见解之间确实存在一些可观察到的关系，也可能与绩效有关。一个简单的实现方法是使用一个实时引擎来标记与航空公司相关的推文，用RNN之类的东西标记该推文的情绪，然后分析负面推文的主题，转发给特定的客户团队(即Boston Logan的客户服务、LAX的餐饮服务，甚至是客舱装饰团队)，以计划适当的业务行动。</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="jl jm di jn bf jo"><div class="er es jf"><img src="../Images/6f13c12381dec01f500fc86e8d2dda0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Inn_oLCx8GJWF-33"/></div></div></figure><p id="278d" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">社交媒体平台也在加强其作为人们新闻、社交互动、电子商务等的主要来源的地位。航空公司应该利用这一点。进行调查是吸引客户和收集反馈的一种不错的方法，但航空公司应该转移到人们已经表达他们的意见和担忧的空间，并利用这些280个字符的短信立即制定改进计划。</p></div><div class="ab cl jr js gp jt" role="separator"><span class="ju bw bk jv jw jx"/><span class="ju bw bk jv jw jx"/><span class="ju bw bk jv jw"/></div><div class="hb hc hd he hf"><h1 id="cd31" class="jz ka hi bd kb kc mz ke kf kg na ki kj kk nb km kn ko nc kq kr ks nd ku kv kw bi translated"><strong class="ak">参考文献</strong></h1><p id="d82c" class="pw-post-body-paragraph ig ih hi ii b ij kx il im in ky ip iq ir kz it iu iv la ix iy iz lb jb jc jd hb bi translated"><a class="ae jy" href="https://www.kaggle.com/crowdflower/twitter-airline-sentiment" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/crowd flower/Twitter-airline-sensation</a></p><p id="ea42" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated"><a class="ae jy" href="http://qpleple.com/topic-coherence-to-evaluate-topic-models/" rel="noopener ugc nofollow" target="_blank">http://qp ple . com/topic-coherence-to-evaluate-topic-models/</a></p><p id="232a" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated"><a class="ae jy" href="https://www.transportation.gov/individuals/aviation-consumer-protection/air-travel-consumer-reports" rel="noopener ugc nofollow" target="_blank">https://www . transportation . gov/personals/aviation-consumer-protection/air-travel-consumer-reports</a></p><p id="8f4e" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated"><a class="ae jy" rel="noopener" href="/nanonets/topic-modeling-with-lsa-psla-lda-and-lda2vec-555ff65b0b05">https://medium . com/nano nets/topic-modeling-with-LSA-psla-LDA-and-LDA 2 vec-555 ff 65 b 0b 05</a></p><p id="1008" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated"><a class="ae jy" href="http://blog.echen.me/2012/03/20/infinite-mixture-models-with-nonparametric-bayes-and-the-dirichlet-process/" rel="noopener ugc nofollow" target="_blank">http://blog . echen . me/2012/03/20/具有非参数贝叶斯和狄利克雷过程的无限混合模型/ </a></p><p id="c5aa" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated"><a class="ae jy" href="https://slidesgo.com/" rel="noopener ugc nofollow" target="_blank">https://slidesgo.com/</a></p></div></div>    
</body>
</html>