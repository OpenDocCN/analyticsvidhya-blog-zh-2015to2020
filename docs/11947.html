<html>
<head>
<title>Using Python to Find the Cheapest Air Tickets and their Timings</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 Python 查找最便宜的机票及其时间</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/using-python-to-find-the-cheapest-air-tickets-and-their-timings-954c6a233e3d?source=collection_archive---------1-----------------------#2020-12-25">https://medium.com/analytics-vidhya/using-python-to-find-the-cheapest-air-tickets-and-their-timings-954c6a233e3d?source=collection_archive---------1-----------------------#2020-12-25</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="402d" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">这是一个方便的指南，教你如何使用网上报废来找到特定出发时间的最便宜的机票。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/bf89aeb8b4941557a0d91315cfc76cea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*wmpsndWxmF9gZE2p"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">由<a class="ae ju" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的<a class="ae ju" href="https://unsplash.com/@camdicecca?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Cam DiCecca </a>拍摄的照片</figcaption></figure><p id="47a9" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi jv translated"><span class="l jw jx jy bm jz ka kb kc kd di">多年来，ravel 聚合器在创建公共平台方面做得很好，人们可以在这个平台上选择过多的航班和酒店。这为用户和航空公司提供了更大的灵活性，他们现在可以根据自己喜欢的时间预订机票。事实上，这些年来网站的用户界面也变得更加友好，用户可以根据个人喜好进行分类和过滤。</span></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es ke"><img src="../Images/b5fe89fe562d535e5cc8f0a7d9261a51.png" data-original-src="https://miro.medium.com/v2/resize:fit:636/format:webp/1*P1IMXav6O_we793f1Ef1Ig.jpeg"/></div><figcaption class="jq jr et er es js jt bd b be z dx translated">资料来源:www.cxodaily.com</figcaption></figure><p id="210f" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">在我过去几个月对这些网站的研究中，我花了一些时间规划 COVID 后的旅行，我发现大多数网站都缺少一个关键的特征。这些网站通常会在某一天按价格(从低到高)对期权进行排序。一些网站甚至在日期选择面板中显示未来几天按天计算的最便宜的选项。然而，在像新冠肺炎这样的许多州都有夜间宵禁的时期，或者从安全的角度来看，一个主要的问题是，人们希望在优选时间段期间利用最便宜的选择。到目前为止，还没有网站提供查询未来几天特定时间段最便宜航班的选项。这一功能在当今时代变得非常重要，对于想要最终确定旅行路线的客户来说，可能会有很大的好处。因此，在旅游网站提供这种功能之前，我们将尝试使用<em class="kf"> Selenium </em>在<em class="kf"> Python </em>上构建这一功能。</p><h1 id="e605" class="kg kh hi bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated"><strong class="ak">场景</strong></h1><p id="2f92" class="pw-post-body-paragraph ig ih hi ii b ij le il im in lf ip iq ir lg it iu iv lh ix iy iz li jb jc jd hb bi translated">假设一个人想从德里飞往孟买，旅行日期灵活，大约一周，但对出发时间的要求是下午 3 点到 6 点。</p><h1 id="b35d" class="kg kh hi bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated"><strong class="ak">接近</strong></h1><p id="3a51" class="pw-post-body-paragraph ig ih hi ii b ij le il im in lf ip iq ir lg it iu iv lh ix iy iz li jb jc jd hb bi translated"><strong class="ii hj">警告！首先，如果你也计划建立这个工具，请参考各自网站的<em class="kf"> robots.txt </em>并检查所有允许提取的内容。如果网站不允许废弃您需要的东西，请在继续之前给网站管理员发一封邮件。</strong></p><p id="4f26" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">为了我们的分析，我们将选择印度最大的在线旅游聚合商之一，<strong class="ii hj"><em class="kf"/></strong>。<strong class="ii hj"> <em class="kf"> MakeMyTrip </em> </strong>是纳斯达克上市公司，提供包括机票、国内外度假套餐、酒店预订、火车票、汽车票等在线旅游服务。要废弃网站，我们首先导入必要的库:</p><pre class="jf jg jh ji fd lj lk ll lm aw ln bi"><span id="46bb" class="lo kh hi lk b fi lp lq l lr ls">import selenium<br/>from selenium import webdriver as wb<br/>import pandas as pd<br/>import numpy as np<br/>import datetime<br/>import time<br/>from datetime import date<br/>from selenium.webdriver.common.keys import Keys<br/>from selenium.webdriver.support.ui import WebDriverWait<br/>from selenium.webdriver.support import expected_conditions as EC<br/>from selenium.webdriver.common.by import By</span></pre><p id="5207" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">将工作目录设置为保存<em class="kf"> chromedriver </em>和<em class="kf"> chromedriver </em>的路径，如下所示:-</p><pre class="jf jg jh ji fd lj lk ll lm aw ln bi"><span id="b276" class="lo kh hi lk b fi lp lq l lr ls">%cd "PATH WHERE YOUR CHROMEDRIVER IS SAVED"<br/>driver = wb.Chrome("YOUR PATH\\chromedriver.exe")</span></pre><p id="d3b0" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">由于我们想要查看一周的航班价格，我们随机选择了一月的第一周(2021 年 1 月 4 日-10 日)。我们设置了日、月和年变量。</p><pre class="jf jg jh ji fd lj lk ll lm aw ln bi"><span id="46d7" class="lo kh hi lk b fi lp lq l lr ls">month = [1,1,1,1,1,1,1]<br/>month = [str(x).zfill(2) for x in month]<br/>day = [4,5,6,7,8,9,10]<br/>day = [str(x).zfill(2) for x in day]<br/>year = [2021,2021,2021,2021,2021,2021,2021]<br/>year = [str(x).zfill(4) for x in year]</span></pre><p id="bdf7" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">现在，为了能够从网站中提取信息，我们首先需要研究<em class="kf"> url </em>。搜索 2021 年 1 月 4 日从德里到孟买的航班的 url 显示如下</p><pre class="jf jg jh ji fd lj lk ll lm aw ln bi"><span id="30b2" class="lo kh hi lk b fi lp lq l lr ls">https://www.makemytrip.com/flight/search?tripType=O&amp;itinerary=DEL-BOM-04/01/2021&amp;paxType=A-1_C-0_I-0&amp;cabinClass=E&amp;sTime=1608889546521&amp;forwardFlowRequired=true&amp;mpo=&amp;intl=false</span></pre><p id="389a" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">上面的<em class="kf"> url </em>给了我们一个清晰的指示，告诉我们需要在哪里输入上面创建的日、月和年变量。因此，我们将调用该网站如下:-</p><pre class="jf jg jh ji fd lj lk ll lm aw ln bi"><span id="2356" class="lo kh hi lk b fi lp lq l lr ls">for a,b,c in zip(day,month,year):<br/>    driver.get("<a class="ae ju" href="https://www.makemytrip.com/flight/search?tripType=O&amp;itinerary=DEL-BOM-{}/{}/{}&amp;paxType=A-1_C-0_I-0&amp;cabinClass=E&amp;sTime=1597828876664&amp;forwardFlowRequired=true" rel="noopener ugc nofollow" target="_blank">https://www.makemytrip.com/flight/search?tripType=O&amp;itinerary=DEL-BOM-{}/{}/{}&amp;paxType=A-1_C-0_I-0&amp;cabinClass=E&amp;sTime=1597828876664&amp;forwardFlowRequired=true</a>".format(a,b,c))</span></pre><p id="e222" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">在 Instagram 和脸书这样的网站上，我们面临的一个主要挑战(从抓取的角度来看)是无限滚动，也就是说，只有当你向下滚动时，数据才会持续加载。默认情况下，我们的代码只能提取可见的部分，因此存在潜在的数据丢失风险。对于<em class="kf"> Makemytrip </em>，我们面临类似的情况，所有列出的航班都不会加载，直到你向下滚动，这是我们必须在代码中包含的内容。</p><pre class="jf jg jh ji fd lj lk ll lm aw ln bi"><span id="8824" class="lo kh hi lk b fi lp lq l lr ls">lenOfPage = driver.execute_script("window.scrollTo(0, document.body.scrollHeight);var lenOfPage=document.body.scrollHeight;return lenOfPage;")<br/>    match=False<br/>    while(match==False):<br/>        lastCount = lenOfPage<br/>        time.sleep(1)<br/>        lenOfPage = driver.execute_script("window.scrollTo(0, document.body.scrollHeight);var lenOfPage=document.body.scrollHeight;return lenOfPage;")<br/>        if lastCount==lenOfPage:<br/>            match=True</span></pre><p id="58b9" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">现在，我们已经准备好提取我们首选时间段内所有航班的航班名称、价格、来源、目的地、持续时间、出发时间、到达时间和日期，并将信息保存到名为'<em class="kf"> Flight_Prices </em>'的空<em class="kf">数据框</em>。</p><pre class="jf jg jh ji fd lj lk ll lm aw ln bi"><span id="354a" class="lo kh hi lk b fi lp lq l lr ls"># Creating an empty dataframe called 'Flight_Prices'<br/>Flight_Prices = pd.DataFrame()</span><span id="ebb1" class="lo kh hi lk b fi lt lq l lr ls"># Creating a for loop which will iterate through all the required pages of the website<br/>for a,b,c in zip(day,month,year):<br/>    driver.get("<a class="ae ju" href="https://www.makemytrip.com/flight/search?tripType=O&amp;itinerary=DEL-BOM-{}/{}/{}&amp;paxType=A-1_C-0_I-0&amp;cabinClass=E&amp;sTime=1597828876664&amp;forwardFlowRequired=true" rel="noopener ugc nofollow" target="_blank">https://www.makemytrip.com/flight/search?tripType=O&amp;itinerary=DEL-BOM-{}/{}/{}&amp;paxType=A-1_C-0_I-0&amp;cabinClass=E&amp;sTime=1597828876664&amp;forwardFlowRequired=true</a>".format(a,b,c))<br/>    time.sleep(15)<br/>    <br/>    lenOfPage = driver.execute_script("window.scrollTo(0, document.body.scrollHeight);var lenOfPage=document.body.scrollHeight;return lenOfPage;")<br/>    match=False<br/>    while(match==False):<br/>        lastCount = lenOfPage<br/>        time.sleep(1)<br/>        lenOfPage = driver.execute_script("window.scrollTo(0, document.body.scrollHeight);var lenOfPage=document.body.scrollHeight;return lenOfPage;")<br/>        if lastCount==lenOfPage:<br/>            match=True<br/>    <br/>    time.sleep(60)<br/>    # Extracting all the Airline names using xpath<br/>    FlightName_elements = driver.find_elements_by_xpath("//div[<a class="ae ju" href="http://twitter.com/class" rel="noopener ugc nofollow" target="_blank">@class</a>='pull-left airways-info-sect']")<br/>    FlightName_elements = [x.text for x in FlightName_elements]<br/>    FlightName = [x.split('\n')[0] for x in FlightName_elements]<br/>    FlightName = pd.Series(FlightName)<br/>    <br/>    # Extracting all the prices using xpath<br/>    Price_elements = driver.find_elements_by_xpath("//span[<a class="ae ju" href="http://twitter.com/class" rel="noopener ugc nofollow" target="_blank">@class</a>='actual-price']")<br/>    Price = [x.text for x in Price_elements]<br/>    Price = [i for i in Price if i]<br/>    Price = pd.Series(Price)<br/>    <br/>    # Extracting all the Source City details using xpath<br/>    Fromcity_elements = driver.find_elements_by_xpath("//p[<a class="ae ju" href="http://twitter.com/class" rel="noopener ugc nofollow" target="_blank">@class</a>='dept-city']")<br/>    Fromcity = [x.text for x in Fromcity_elements]<br/>    Fromcity = pd.Series(Fromcity)<br/>    <br/>    # Extracting all the Destination City details using xpath<br/>    Tocity_elements = driver.find_elements_by_xpath("//p[<a class="ae ju" href="http://twitter.com/class" rel="noopener ugc nofollow" target="_blank">@class</a>='arrival-city']")<br/>    Tocity = [x.text for x in Tocity_elements]<br/>    Tocity = pd.Series(Tocity)<br/>    <br/>    # Extracting all the Duration details using xpath<br/>    Duration_elements = driver.find_elements_by_xpath("//p[<a class="ae ju" href="http://twitter.com/class" rel="noopener ugc nofollow" target="_blank">@class</a>='fli-duration']")<br/>    Duration = [x.text for x in Duration_elements]<br/>    Duration = pd.Series(Duration)<br/>    <br/>     # Extracting all the Departure time details using xpath<br/>    Deptime_elements = driver.find_elements_by_xpath("//div[<a class="ae ju" href="http://twitter.com/class" rel="noopener ugc nofollow" target="_blank">@class</a>='dept-time']")<br/>    Deptime = [x.text for x in Deptime_elements]<br/>    Deptime = pd.Series(Deptime)<br/>    <br/>     # Extracting all the Arrival Time details using xpath<br/>    Arrtime_elements = driver.find_elements_by_xpath("//p[<a class="ae ju" href="http://twitter.com/class" rel="noopener ugc nofollow" target="_blank">@class</a>='reaching-time append_bottom3']")<br/>    Arrtime = [x.text for x in Arrtime_elements]<br/>    Arrtime = [x.split("+", 1)[0] for x in Arrtime]<br/>    Arrtime = pd.Series(Arrtime)<br/>    <br/>    Date_elements = driver.find_elements_by_xpath("//div[<a class="ae ju" href="http://twitter.com/class" rel="noopener ugc nofollow" target="_blank">@class</a>='item blue_active']")<br/>    Date_elements = [x.text for x in Date_elements]<br/>    x = [x.split(',', 1)[1] for x in Date_elements]<br/>    Date = [i.split('\n', 1)[0] for i in x]<br/>    Date = pd.Series(Date)<br/>            <br/>    # Combining all the lists into a dataframe called 'df'<br/>    df = pd.DataFrame({'Date':Date,"Airline":FlightName,"From City":Fromcity, "To City":Tocity, "Departure Time":Deptime,"Arrival Time":Arrtime,"Flight Duration":Duration,"Price":Price})<br/>    <br/>    # We will append the results obtained from every page into the empty datafram created earlier called 'Flight_Prices'<br/>    Flight_Prices = Flight_Prices.append(df) <br/>        <br/>Flight_Prices[Flight_Prices.Date==""] = np.NaN<br/>Flight_Prices.Date = Flight_Prices.Date.fillna(method='ffill')<br/>Flight_Prices.Price = Flight_Prices.Price.str.replace(",","").str.extract('(\d+)')<br/>Flight_Prices</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es lu"><img src="../Images/c7e348b1b97cdf872fb35cd8c90ba07d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1236/format:webp/1*McghGZIV8b3pA_MuY_9uwQ.png"/></div></figure><p id="42b8" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">我们最终得到一个漂亮的<em class="kf">数据框架</em>，有 788 行飞行选项和各种相关功能。现在，在进入关键步骤之前，我们必须清理一下我们的数据。首先，我们需要确保我们的'<em class="kf"> Price </em>'列是一个数值</p><pre class="jf jg jh ji fd lj lk ll lm aw ln bi"><span id="c9b8" class="lo kh hi lk b fi lp lq l lr ls">Flight_Prices['Price'] = pd.to_numeric(Flight_Prices['Price'])</span></pre><p id="3e90" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">然后，我们筛选出出发时间仅在下午 3 点到 6 点之间的航空公司选项。</p><pre class="jf jg jh ji fd lj lk ll lm aw ln bi"><span id="2f12" class="lo kh hi lk b fi lp lq l lr ls">Flight_Prices = Flight_Prices[(Flight_Prices['Departure Time']&gt;='15:00') &amp; (Flight_Prices['Departure Time']&lt;= '18:00')]</span></pre><p id="0e33" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">最后，我们按日期分组，找到一周中所有日期价格最便宜的航班，并得到想要的结果。</p><pre class="jf jg jh ji fd lj lk ll lm aw ln bi"><span id="8f8f" class="lo kh hi lk b fi lp lq l lr ls">Flight_Prices.loc[Flight_Prices.groupby('Date')['Price'].idxmin()]<br/>Flight_Prices.drop_duplicates('Date')</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es lv"><img src="../Images/4868665947d2c8680b27a39bfb81d51a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1206/format:webp/1*5rCR0ayFcFGba0q_cUrYHw.png"/></div></figure><p id="c781" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">在折线图上画出同样的东西。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es lw"><img src="../Images/2ef63c13eb3446d39988ef187b230e0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:794/format:webp/1*GPVEWrlgU9Xv2RSnazvJvA.png"/></div></figure><p id="6fca" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">这个练习帮助我们做出决定。我们看到 1 月 10 日是我们首选时间段中最便宜的航班。然而，它似乎是一个转机航班，因为飞行时间为 17.5 小时。因此，我们将选择下一个最佳选择，即 1 月 9 日上市。这比一周内所有其他日期最便宜的航班便宜了将近 21%。</p><h1 id="2cf3" class="kg kh hi bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">结论</h1><p id="6062" class="pw-post-body-paragraph ig ih hi ii b ij le il im in lf ip iq ir lg it iu iv lh ix iy iz li jb jc jd hb bi translated">在这个练习中，我们看到了<em class="kf"> Python </em>在开发小型黑客方面确实非常有用，可以帮助日常决策。这个过程可以简单到从相关网站上删除数据，根据我们的需要清理数据，并可视化以实现数据驱动的决策。帖子概述了该过程中使用的主要代码，完整代码可在<a class="ae ju" href="https://github.com/aksbehera/Projects" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p></div></div>    
</body>
</html>