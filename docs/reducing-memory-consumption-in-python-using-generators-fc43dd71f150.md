# 使用生成器减少 Python 中的内存消耗

> 原文：<https://medium.com/analytics-vidhya/reducing-memory-consumption-in-python-using-generators-fc43dd71f150?source=collection_archive---------9----------------------->

![](img/44766dad3cc9814784603c651798ec05.png)

您是否曾经不得不处理一个大型数据集，并在 Python 中遇到可怕的*内存错误*，或者只是需要限制大型数据集的内存消耗？如果答案是肯定的，考虑使用发电机。

生成器提供了一种处理数据的方法，无需先将整个数据源加载到内存中。这在以高效的 pythonic 方式处理非常大的文件时特别有用。

生成器的核心是返回迭代器的函数，这意味着生成器可以循环。然而，与 Python 中的常规迭代器不同，整个数据集不会预先加载到内存中。

## 创建生成器函数

发生器函数围绕着`yield`语句(后面的会有更多的*)。它们被定义为一个普通的函数，只是增加了一个`yield`语句来代替我们熟悉的`return`。*

在下面(*人为*)的例子中，定义了发生器函数`basic_generator`。这将返回一个生成器，一次生成 50，000，000 个整数。

由`basic_generator`返回的生成器被分配给变量`gen`，然后可以像普通迭代器一样对其进行迭代。这里的区别在于，生成器一次生成一个值，而不是像 list 那样预先将所有 50，000，000 个整数加载到内存中。

## 读取大文件

生成器函数最常见的用法可能是在读取大文件时，在 Python 中读取文件时，通常是一次将文件的全部内容读入内存。当处理大文件时，这可能会有问题，要么消耗过多的内存，要么在最坏的情况下消耗所有可用的内存，引发一个`MemoryError`并最终使应用程序崩溃。

*注意:使用 32 位版本的 Python 时，Python 进程只能寻址 2GB 的内存，因此无论有多少可用的物理内存，一旦 Python 消耗了 2GB 的内存，就会引发 MemoryError 错误。*

根据文件的类型和内容，你可能想要逐行读取(文本文件常见的*，或者二进制文件*常见的*)。*

Python 中内置的`open`函数已经一行一行地对文件进行了惰性评估，因此对于一次一行地读取一个大文件，不需要实现一个生成器函数。这可以像下面的例子一样简单地实现。

现在，在需要以 *n* 大小的字节块读取文件的情况下，可以使用下面的生成器函数。这将打开文件并产生等于 *chunk_size* 字节的数据块。

## 序列生成

生成器函数的另一个常见和流行的用途是生成大型或潜在的无限值序列。

## 无限数列

生成器函数是解决生成无限数列问题的理想选择，因为序列生成的状态可以巧妙地封装在一个函数定义中。

## 斐波那契数列

内存受限环境中的斐波那契数列是使用生成器函数求解的另一个很好的选择，因为可以避免将生成的斐波那契数列中的所有值加载到内存中。

## 生成器表达式

如果一个完整的生成器函数对于简单的序列生成器来说过于冗长，那么可以选择使用生成器表达式来创建一个生成器。语法与列表理解非常相似，唯一的区别是生成器表达式需要`( )`圆括号，而列表理解需要`[ ]`括号。

*如果你有兴趣学习列表理解，看看我的帖子* [*这里*](https://www.lachlaneagling.com/python-list-comprehensions-at-a-glance/) *。*

## 在后台

当 python 解释器在函数中遇到`yield`语句时，它知道该函数是一个生成器函数。此时，函数将返回一个特殊的迭代器对象，并将其赋给目标变量。

生成器对象使用内部`f_locals`变量存储状态。此外，该对象有一个`next()`方法，该方法调用并运行生成器函数内的代码，直到 yield 语句，此时返回生成的值，存储当前状态，并暂停函数的执行，直到再次调用`next()`。

下一个方法既可以手动调用，也可以在循环结构中隐式调用。

当生成器的值用尽时，会出现一个`StopIteration`异常，表示生成器已经用尽，无法生成更多的值。这个异常由一个循环结构(比如 for 循环)自动处理，但是，如果在生成器上手动调用 next，这个异常需要被捕获并手动处理。

## 内存和性能指标

当涉及到内存消耗时，生成器提供了最大的好处，这是因为它们提供了[惰性评估](https://en.wikipedia.org/wiki/Lazy_evaluation)，防止所有的值被一次加载到内存中。

在下面的示例中，将生成 50，000 个整数的序列的生成器的字节大小与 50，000 个整数的静态列表进行比较。与静态生成的整数列表消耗 406，488 字节的内存相比，生成器只消耗 112 字节的内存。在这个特殊的例子中，生成器的内存效率比 list 高出约 3600 倍。

然而，这种内存效率的缺点是通过运行时性能观察到的，与静态生成的值列表相比，使用生成器会导致更多的函数调用，从而导致更长的运行时间。下面是使用 [cProfile](https://docs.python.org/3.7/library/profile.html) 对 100，000 以内的整数进行简单的*求和*分析。生成器表达式在 123 毫秒内产生 100，005 个函数调用，而列表理解在 12 毫秒内只需要 5 个函数调用。

*看我在 Python* [*中关于剖析的帖子这里*](https://www.lachlaneagling.com/ghost/#/editor/post/5daf945c2955a95a7370b937) *。*

这是由于生成器表达式调用`next()`来获取序列中的每个值而返回的生成器。

从这些观察中自然得出的结论是，需要仔细考虑系统的需求。如果内存约束将超过性能影响，那么生成器是最合适的解决方案。相反，如果内存消耗没有运行时性能重要，那么使用静态数据源(如列表)更合适。