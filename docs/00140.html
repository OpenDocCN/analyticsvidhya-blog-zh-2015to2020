<html>
<head>
<title>An Introduction to Random Forest using the fastai Library (Machine Learning for Programmers — Part 1)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用fastai库介绍随机森林(程序员的机器学习—第1部分)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/an-introduction-to-random-forest-using-the-fastai-library-machine-learning-for-programmers-part-63cf5c7960b4?source=collection_archive---------0-----------------------#2018-10-08">https://medium.com/analytics-vidhya/an-introduction-to-random-forest-using-the-fastai-library-machine-learning-for-programmers-part-63cf5c7960b4?source=collection_archive---------0-----------------------#2018-10-08</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="e1d9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于任何想要学习机器学习的人来说，编程是一个至关重要的先决条件。当然，有相当多的autoML工具，但大多数仍处于非常初级的阶段，远远超出了个人的预算。数据科学家的最佳点在于将编程与机器学习算法相结合。</p><p id="d590" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Fast.ai由<a class="jd je ge" href="https://medium.com/u/34ab754f8c5e?source=post_page-----63cf5c7960b4--------------------------------" rel="noopener" target="_blank">杰瑞米·霍华德</a>和<a class="jd je ge" href="https://medium.com/u/ee56d0bac1b7?source=post_page-----63cf5c7960b4--------------------------------" rel="noopener" target="_blank">瑞秋·托马斯</a>的惊人搭档带领。所以当他们发布他们的机器学习课程时，我迫不及待地开始了。</p><p id="50f8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我个人喜欢这门课的是自上而下的教学方法。你首先学习如何用Python编写算法，然后转向理论方面。虽然不是唯一的方法，但它肯定有它的优点。</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div class="er es jf"><img src="../Images/11931d825db4adc3a736c44269a392fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/0*UxjzPu76_Nyyp-Z-.jpg"/></div></figure><p id="56cf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在观看这些视频时，我决定以一系列文章的形式为我们这个令人敬畏的社区策划我的学习！因此，在这第一篇文章中，我提供了前两个视频的全面总结(包括代码)，在这两个视频中，杰瑞米·霍华德教我们如何使用fastai库构建随机森林模型，以及如何调整不同的超参数可以显著改变我们模型的准确性。</p><p id="cc51" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jn">你需要有一点Python的经验才能理解代码。</em> <em class="jn">所以，如果你是机器学习的初学者，并且以前没有使用过Python和Jupyter笔记本，我建议你先看看下面两个资源:</em></p><ul class=""><li id="6a82" class="jo jp hi ih b ii ij im in iq jq iu jr iy js jc jt ju jv jw bi translated"><a class="ae jx" href="https://trainings.analyticsvidhya.com/courses/course-v1:AnalyticsVidhya+DS101+2018T2/about" rel="noopener ugc nofollow" target="_blank">数据科学简介</a>(涵盖Python、统计学和预测建模的基础知识)</li><li id="e33c" class="jo jp hi ih b ii jy im jz iq ka iu kb iy kc jc jt ju jv jw bi translated"><a class="ae jx" href="https://www.analyticsvidhya.com/blog/2018/05/starters-guide-jupyter-notebook/" rel="noopener ugc nofollow" target="_blank">Jupyter笔记本初学者指南</a></li></ul><h1 id="6dc9" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">目录</h1><ol class=""><li id="a4c8" class="jo jp hi ih b ii lb im lc iq ld iu le iy lf jc lg ju jv jw bi translated">课程结构和材料</li><li id="2faf" class="jo jp hi ih b ii jy im jz iq ka iu kb iy kc jc lg ju jv jw bi translated">机器学习介绍:第1课<br/> 2.1导入必要的库<br/> 2.2下载数据集<br/> 2.3随机森林介绍<br/> 2.4预处理<br/> 2.5模型建立</li><li id="3511" class="jo jp hi ih b ii jy im jz iq ka iu kb iy kc jc lg ju jv jw bi translated">机器学习简介:第2课<br/> 3.1创建验证集<br/> 3.2创建单个树</li><li id="f378" class="jo jp hi ih b ii jy im jz iq ka iu kb iy kc jc lg ju jv jw bi translated">其他主题</li></ol><h1 id="9535" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">课程结构和材料</h1><p id="619d" class="pw-post-body-paragraph if ig hi ih b ii lb ik il im lc io ip iq lh is it iu li iw ix iy lj ja jb jc hb bi translated">视频讲座可在YouTube上获得，本课程按照以下结构分为12个讲座:</p><ul class=""><li id="7a08" class="jo jp hi ih b ii ij im in iq jq iu jr iy js jc jt ju jv jw bi translated"><a class="ae jx" href="https://youtu.be/CzdWqFTmn0Y" rel="noopener ugc nofollow" target="_blank">第1课—随机森林简介</a></li><li id="513c" class="jo jp hi ih b ii jy im jz iq ka iu kb iy kc jc jt ju jv jw bi translated"><a class="ae jx" href="https://youtu.be/blyXCk4sgEg" rel="noopener ugc nofollow" target="_blank">第2课—随机森林深度潜水</a></li><li id="4369" class="jo jp hi ih b ii jy im jz iq ka iu kb iy kc jc jt ju jv jw bi translated"><a class="ae jx" href="https://youtu.be/YSFG_W8JxBo" rel="noopener ugc nofollow" target="_blank">第3课——性能、验证和模型解释</a></li><li id="2ece" class="jo jp hi ih b ii jy im jz iq ka iu kb iy kc jc jt ju jv jw bi translated"><a class="ae jx" href="https://youtu.be/0v93qHDqq_g" rel="noopener ugc nofollow" target="_blank">第4课—特征重要性，树解释器</a></li><li id="e5e6" class="jo jp hi ih b ii jy im jz iq ka iu kb iy kc jc jt ju jv jw bi translated"><a class="ae jx" href="https://youtu.be/3jl2h9hSRvc" rel="noopener ugc nofollow" target="_blank">第5课——从头开始推断和RF</a></li><li id="e014" class="jo jp hi ih b ii jy im jz iq ka iu kb iy kc jc jt ju jv jw bi translated"><a class="ae jx" href="https://youtu.be/BFIYUvBRTpE" rel="noopener ugc nofollow" target="_blank">第6课—数据产品和实时编码</a></li><li id="1bc5" class="jo jp hi ih b ii jy im jz iq ka iu kb iy kc jc jt ju jv jw bi translated"><a class="ae jx" href="https://youtu.be/O5F9vR2CNYI" rel="noopener ugc nofollow" target="_blank">第7课— RF从零开始和梯度下降</a></li><li id="5cc6" class="jo jp hi ih b ii jy im jz iq ka iu kb iy kc jc jt ju jv jw bi translated"><a class="ae jx" href="https://youtu.be/DzE0eSdy5Hk" rel="noopener ugc nofollow" target="_blank">第8课—梯度下降和逻辑回归</a></li><li id="38e1" class="jo jp hi ih b ii jy im jz iq ka iu kb iy kc jc jt ju jv jw bi translated"><a class="ae jx" href="https://youtu.be/PGC0UxakTvM" rel="noopener ugc nofollow" target="_blank">第9课——正规化、学习率和NLP </a></li><li id="276d" class="jo jp hi ih b ii jy im jz iq ka iu kb iy kc jc jt ju jv jw bi translated"><a class="ae jx" href="https://youtu.be/37sFIak42Sc" rel="noopener ugc nofollow" target="_blank">第10课—更多NLP和柱状数据</a></li><li id="3034" class="jo jp hi ih b ii jy im jz iq ka iu kb iy kc jc jt ju jv jw bi translated"><a class="ae jx" href="https://youtu.be/XJ_waZlJU8g" rel="noopener ugc nofollow" target="_blank">第11课—嵌入</a></li><li id="240c" class="jo jp hi ih b ii jy im jz iq ka iu kb iy kc jc jt ju jv jw bi translated"><a class="ae jx" href="https://youtu.be/5_xFdhfUnvQ" rel="noopener ugc nofollow" target="_blank">第12课——完整的罗斯曼，伦理问题</a></li></ul><p id="6333" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">本课程假设您的计算机上安装了Jupyter笔记本电脑。如果您没有(也不喜欢安装它)，您可以选择以下任何一种(这些都附带象征性的费用):</p><ol class=""><li id="e35d" class="jo jp hi ih b ii ij im in iq jq iu jr iy js jc lg ju jv jw bi translated"><a class="ae jx" href="https://www.crestle.com/" rel="noopener ugc nofollow" target="_blank">冠毛</a></li><li id="e525" class="jo jp hi ih b ii jy im jz iq ka iu kb iy kc jc lg ju jv jw bi translated"><a class="ae jx" href="https://www.paperspace.com/" rel="noopener ugc nofollow" target="_blank">纸张空间</a></li></ol><p id="26f8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">与每个讲座相关的所有笔记本都可以在<a class="ae jx" href="https://github.com/fastai/fastai" rel="noopener ugc nofollow" target="_blank"> fast.ai的GitHub资源库</a>上找到。您可以一次性克隆或下载整个存储库。您可以在<a class="ae jx" href="https://github.com/fastai/fastai#to-install" rel="noopener ugc nofollow" target="_blank"> to-install </a>部分找到完整的安装步骤。</p><h1 id="eaa2" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">机器学习简介:第1课</h1><p id="ab42" class="pw-post-body-paragraph if ig hi ih b ii lb ik il im lc io ip iq lh is it iu li iw ix iy lj ja jb jc hb bi translated">准备好开始了吗？然后查看<a class="ae jx" href="https://github.com/fastai/fastai/blob/master/courses/ml1/lesson1-rf.ipynb" rel="noopener ugc nofollow" target="_blank"> Jupyter笔记本</a>和下面的第一课视频。</p><p id="2f26" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这一讲中，我们将学习如何用Python建立一个随机森林模型。由于本课程采用自上而下的方法，我们将先进行编码，同时了解代码是如何工作的。然后，我们将研究随机森林算法的内部工作原理。</p><figure class="jg jh ji jj fd jk"><div class="bz dy l di"><div class="lk ll l"/></div></figure><p id="d671" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们深入探讨一下这个讲座的内容。</p><h1 id="4620" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">导入必要的库</h1><pre class="jg jh ji jj fd lm ln lo lp aw lq bi"><span id="ba43" class="lr ke hi ln b fi ls lt l lu lv">%load ext_autoreload <br/>%autoreload 2</span></pre><p id="c8ba" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">以上两个命令会在源代码更新时自动修改笔记本。因此，使用<em class="jn">ext _ auto load</em>将自动动态地在您的笔记本中进行更改。</p><pre class="jg jh ji jj fd lm ln lo lp aw lq bi"><span id="7eb9" class="lr ke hi ln b fi ls lt l lu lv">%matplotlib inline</span></pre><p id="35df" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用% <em class="jn"> matplotlib inline </em>，我们可以可视化笔记本内部的情节。</p><pre class="jg jh ji jj fd lm ln lo lp aw lq bi"><span id="0eaf" class="lr ke hi ln b fi ls lt l lu lv">from fastai.imports import*<br/>from fastai.structured import *<br/>from pandas_summary import DataFrameSummary<br/>from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier<br/>from IPython.display import display<br/>from sklearn import metrics</span></pre><p id="b49a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用<em class="jn"> import* </em>将导入fastai库中的所有内容。还导入了其他必要的库来读取数据帧摘要，创建随机森林模型和度量来计算RMSE(评估度量)。</p><h1 id="ec30" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">下载数据集</h1><p id="bdb3" class="pw-post-body-paragraph if ig hi ih b ii lb ik il im lc io ip iq lh is it iu li iw ix iy lj ja jb jc hb bi translated">我们将使用的数据集是“<a class="ae jx" href="https://www.kaggle.com/c/bluebook-for-bulldozers" rel="noopener ugc nofollow" target="_blank">推土机蓝皮书</a>”。本次挑战的问题陈述如下:</p><blockquote class="lw lx ly"><p id="c485" class="if ig jn ih b ii ij ik il im in io ip lz ir is it ma iv iw ix mb iz ja jb jc hb bi translated"><em class="hi">目标是根据用途、设备类型和配置，预测拍卖中特定重型设备的销售价格。数据来源于拍卖结果公告，包括使用和设备配置信息。Fast Iron正在创建一本“推土机蓝皮书”，供客户在拍卖中评估他们的重型设备车队的价值。</em></p></blockquote><figure class="jg jh ji jj fd jk er es paragraph-image"><div class="er es mc"><img src="../Images/6282ec3303cad52dbe32da9b536c64d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*HrGpEaKAh6oYxQj2.jpg"/></div></figure><p id="0761" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">评估指标是RMSLE(均方根对数误差)。如果您以前没有听说过它，请不要担心，我们将在代码演练期间理解并处理它。假设您已经成功下载了数据集，让我们继续编码吧！</p><pre class="jg jh ji jj fd lm ln lo lp aw lq bi"><span id="63f6" class="lr ke hi ln b fi ls lt l lu lv">PATH = “data/bulldozers/”</span></pre><p id="5709" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">该命令用于设置数据集的位置。我们目前将下载的数据集存储在data文件夹内名为<em class="jn">推土机</em>的文件夹中。要检查路径中有哪些文件，您可以键入:</p><pre class="jg jh ji jj fd lm ln lo lp aw lq bi"><span id="30a2" class="lr ke hi ln b fi ls lt l lu lv">!ls data/bulldozers/</span></pre><p id="2dec" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">或者，</p><pre class="jg jh ji jj fd lm ln lo lp aw lq bi"><span id="b1ac" class="lr ke hi ln b fi ls lt l lu lv">!ls {PATH}</span></pre><h1 id="081b" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">阅读文件</h1><p id="2ced" class="pw-post-body-paragraph if ig hi ih b ii lb ik il im lc io ip iq lh is it iu li iw ix iy lj ja jb jc hb bi translated">提供的数据集是. csv格式。这是一个结构化数据集，其中的列代表一系列内容，如ID、日期、州、产品组等。对于处理结构化数据，pandas是最重要的库。当我们之前使用<em class="jn"> import* </em>命令时，我们已经将<em class="jn"> pandas作为pd </em>导入。我们现在将使用pandas的<em class="jn"> read_csv </em>函数来读取数据:</p><pre class="jg jh ji jj fd lm ln lo lp aw lq bi"><span id="934b" class="lr ke hi ln b fi ls lt l lu lv">df_raw = pd.read_csv(f'{PATH}Train.csv', low_memory=False, parse_dates=["saledate"])</span></pre><p id="5c27" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们看看数据的前几行:</p><pre class="jg jh ji jj fd lm ln lo lp aw lq bi"><span id="d825" class="lr ke hi ln b fi ls lt l lu lv">df_raw.head()</span></pre><p id="a4ef" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">由于数据集很大，这个命令没有显示完整的列数据。相反，我们将看到一些没有显示的数据点(如屏幕截图所示):</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="er es md"><img src="../Images/854e2e690c03ddc8b9e6bd04acd832a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*FgyqaGYtFE3zPw0Z.png"/></div></div></figure><p id="a54e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了解决这个问题，我们将定义以下函数，其中我们将<em class="jn">最大行数</em>和<em class="jn">最大列数</em>设置为1000。</p><pre class="jg jh ji jj fd lm ln lo lp aw lq bi"><span id="c18d" class="lr ke hi ln b fi ls lt l lu lv">def display_all(df):<br/>    with pd.option_context("display.max_rows", 1000, display.max_columns", 1000): <br/>        display(df)</span></pre><p id="0d76" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们现在可以使用这个新创建的函数打印数据集的头部。我们进行了转置，使其在视觉上更具吸引力(我们将列名视为索引)。</p><pre class="jg jh ji jj fd lm ln lo lp aw lq bi"><span id="e6fb" class="lr ke hi ln b fi ls lt l lu lv">display_all(df_raw.head().transpose())</span></pre><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="er es mi"><img src="../Images/cf0e0e57693ce908df786787fee41128.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*c-7e3jPfJYjrjs3B.png"/></div></div></figure><p id="9c3c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">请记住，评估指标是RMSLE——它基本上是结果的对数值之间的RMSE。因此，我们将通过取目标变量的对数值来转换它。这就是受欢迎的图书馆<em class="jn">numpy</em>来拯救我们的地方。</p><pre class="jg jh ji jj fd lm ln lo lp aw lq bi"><span id="775a" class="lr ke hi ln b fi ls lt l lu lv">df_raw.SalePrice = np.log(df_raw.SalePrice)</span></pre><h1 id="d759" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">随机森林简介</h1><p id="a1a4" class="pw-post-body-paragraph if ig hi ih b ii lb ik il im lc io ip iq lh is it iu li iw ix iy lj ja jb jc hb bi translated">随机森林模型如何从零开始工作的概念将在本课程的后面部分详细讨论，但这里用杰瑞米·霍华德的话说是一个简短的介绍:</p><ul class=""><li id="479e" class="jo jp hi ih b ii ij im in iq jq iu jr iy js jc jt ju jv jw bi translated">随机森林是一种通用的机器学习技术</li><li id="08d5" class="jo jp hi ih b ii jy im jz iq ka iu kb iy kc jc jt ju jv jw bi translated">它可用于回归(目标是连续变量)或分类(目标是分类变量)问题</li><li id="d001" class="jo jp hi ih b ii jy im jz iq ka iu kb iy kc jc jt ju jv jw bi translated">它还可以处理任何类型的列，如像素值、邮政编码、收入等。</li><li id="503a" class="jo jp hi ih b ii jy im jz iq ka iu kb iy kc jc jt ju jv jw bi translated">一般来说，随机森林不会过度适应(很容易阻止它过度适应)</li><li id="ba5d" class="jo jp hi ih b ii jy im jz iq ka iu kb iy kc jc jt ju jv jw bi translated">通常不需要单独的验证集。即使只有一个数据集，它也能告诉你它的概化程度</li><li id="5c12" class="jo jp hi ih b ii jy im jz iq ka iu kb iy kc jc jt ju jv jw bi translated">它几乎没有(如果有的话)统计假设(它不假设数据是正态分布的，数据是线性的，或者您需要指定交互)</li><li id="1ab3" class="jo jp hi ih b ii jy im jz iq ka iu kb iy kc jc jt ju jv jw bi translated">需要很少的特性工程策略，所以这是一个很好的起点。对于许多不同类型的情况，您不需要记录数据或多次交互</li></ul><p id="64d4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">听起来是个很棒的技术，对吧？</p><p id="bd91" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jn"> RandomForestRegressor </em>和<em class="jn"> RandomForestClassifier </em>函数在Python中分别用于回归和分类问题。由于我们正在处理回归挑战，我们将坚持使用<em class="jn"> RandomForestRegressor </em>。</p><pre class="jg jh ji jj fd lm ln lo lp aw lq bi"><span id="4443" class="lr ke hi ln b fi ls lt l lu lv">m = RandomForestRegressor(n_jobs=-1) m.fit(df_raw.drop('SalePrice', axis=1), df_raw.SalePrice)</span></pre><p id="d209" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jn"> m.fit </em>功能有两个输入:</p><ul class=""><li id="308a" class="jo jp hi ih b ii ij im in iq jq iu jr iy js jc jt ju jv jw bi translated">自变量</li><li id="49e4" class="jo jp hi ih b ii jy im jz iq ka iu kb iy kc jc jt ju jv jw bi translated">因变量(目标变量)</li></ul><p id="51ff" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里的目标变量是<em class="jn"> df_raw。销售价格</em>。自变量是除销售价格之外的所有变量<strong class="ih hj">。</strong>这里，我们使用<em class="jn"> df_raw.drop </em>来删除SalePrice列(axis = 1表示列)。这将引发如下所示的错误:</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="er es mj"><img src="../Images/79bedaf0227dc7beb44a2c473c59a0b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*TzOJ6BzY1cHUFI9v.png"/></div></div></figure><pre class="jg jh ji jj fd lm ln lo lp aw lq bi"><span id="636d" class="lr ke hi ln b fi ls lt l lu lv">ValueError: could not convert string to float: 'Conventional'</span></pre><p id="a0e6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这表明该模型不能处理“常规”值。大多数机器学习模型(包括随机森林)不能直接使用分类列。我们需要先将这些列转换成数字。所以下一步自然是将所有分类列转换成连续变量。</p><h1 id="8162" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">数据预处理</h1><p id="542f" class="pw-post-body-paragraph if ig hi ih b ii lb ik il im lc io ip iq lh is it iu li iw ix iy lj ja jb jc hb bi translated">让我们分别处理每个分类列。首先，考虑日期时间格式的<em class="jn">销售日期</em>列。从日期列中，我们可以提取数字值，例如——年、月、月中的某一天、星期几、假日与否、周末或工作日、下雨了吗？等。</p><p id="6f09" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将利用fastai库中的<em class="jn"> add_datepart </em>函数来为我们创建这些特性。该函数创建以下功能:</p><pre class="jg jh ji jj fd lm ln lo lp aw lq bi"><span id="c070" class="lr ke hi ln b fi ls lt l lu lv">'Year', 'Month', 'Week', 'Day', 'Dayofweek', 'Dayofyear', 'Is_month_end', 'Is_month_start', 'Is_quarter_end', 'Is_quarter_start', 'Is_year_end', 'Is_year_start'</span></pre><p id="060a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们运行函数并检查列:</p><pre class="jg jh ji jj fd lm ln lo lp aw lq bi"><span id="a42f" class="lr ke hi ln b fi ls lt l lu lv">add_datepart(df_raw, 'saledate')<br/>df_raw.columns</span></pre><p id="d9e9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">输出:</p><pre class="jg jh ji jj fd lm ln lo lp aw lq bi"><span id="2ba7" class="lr ke hi ln b fi ls lt l lu lv">Index(['SalesID', 'SalePrice', 'MachineID', 'ModelID', 'datasource', 'auctioneerID', 'YearMade', 'MachineHoursCurrentMeter', 'UsageBand', 'fiModelDesc', 'fiBaseModel', 'fiSecondaryDesc', 'fiModelSeries', 'fiModelDescriptor', 'ProductSize', 'fiProductClassDesc', 'state', 'ProductGroup', 'ProductGroupDesc', 'Drive_System', 'Enclosure', 'Forks', 'Pad_Type', 'Ride_Control', 'Stick', 'Transmission', 'Turbocharged', 'Blade_Extension', 'Blade_Width', 'Enclosure_Type', 'Engine_Horsepower', 'Hydraulics', 'Pushblock', 'Ripper', 'Scarifier', 'Tip_Control', 'Tire_Size', 'Coupler', 'Coupler_System', 'Grouser_Tracks', 'Hydraulics_Flow', 'Track_Type', 'Undercarriage_Pad_Width', 'Stick_Length', 'Thumb', 'Pattern_Changer', 'Grouser_Type', 'Backhoe_Mounting', 'Blade_Type', 'Travel_Controls', 'Differential_Type', 'Steering_Controls', 'saleYear', 'saleMonth', 'saleWeek', 'saleDay', 'saleDayofweek', 'saleDayofyear', 'saleIs_month_end', 'saleIs_month_start', 'saleIs_quarter_end', 'saleIs_quarter_start', 'saleIs_year_end', 'saleIs_year_start', 'saleElapsed'], dtype='object')</span></pre><p id="abe6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下一步是将分类变量转换成数字。为此，我们可以使用fastai的<em class="jn"> train_cats </em>函数:</p><pre class="jg jh ji jj fd lm ln lo lp aw lq bi"><span id="e332" class="lr ke hi ln b fi ls lt l lu lv">train_cats(df_raw)</span></pre><p id="50ff" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在将分类列转换为数字列时，我们必须考虑以下两个问题:</p><ol class=""><li id="35f9" class="jo jp hi ih b ii ij im in iq jq iu jr iy js jc lg ju jv jw bi translated">一些分类变量之间可以有顺序(例如，高&gt;中&gt;低)。我们可以使用<em class="jn">设置类别</em>来设置顺序。</li><li id="9fab" class="jo jp hi ih b ii jy im jz iq ka iu kb iy kc jc lg ju jv jw bi translated">如果一个类别在训练数据中得到一个特定的数字，那么它在测试数据中应该有相同的值。例如，如果训练数据的高值为3，测试数据的高值为2，那么它将有两种不同的含义。我们可以使用<em class="jn"> apply_cats </em>来验证和测试集合，以确保不同集合中的映射是相同的</li></ol><p id="ffb1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">虽然这在我们当前的情况下不会有太大的不同，因为随机森林是在分割数据集上工作的(我们很快就会详细了解随机森林是如何工作的)，但对于其他算法来说，知道这一点仍然是很好的。</p><h1 id="416f" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">缺失值处理</h1><p id="0515" class="pw-post-body-paragraph if ig hi ih b ii lb ik il im lc io ip iq lh is it iu li iw ix iy lj ja jb jc hb bi translated">下一步是查看数据集中缺失值的数量，并了解如何处理它们。这在机器学习竞赛和现实生活的行业问题中都是一个相当普遍的挑战。</p><pre class="jg jh ji jj fd lm ln lo lp aw lq bi"><span id="fbe9" class="lr ke hi ln b fi ls lt l lu lv">display_all(df_raw.isnull().sum().sort_index()/len(df_raw))</span></pre><p id="52ab" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们用<em class="jn">。isnull()。sum() </em>获取缺失值的总数。这除以数据集的长度来确定缺失值的比率。</p><p id="48bf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">数据集现在可以用于创建模型了。数据清理始终是一个乏味且耗时的过程。因此，请确保保存转换后的数据集，以便下次加载数据时，我们不必再次执行上述任务。</p><p id="61ca" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将把它保存为羽化格式，这样可以让我们高效地访问数据:</p><pre class="jg jh ji jj fd lm ln lo lp aw lq bi"><span id="4877" class="lr ke hi ln b fi ls lt l lu lv">#to save<br/>os.makedirs('tmp', exist_ok=True)<br/>df.to_feather('tmp/bulldozers-raw')<br/><br/>#to read<br/>df_raw = pd.read_feather('tmp/bulldozers-raw')</span></pre><p id="c559" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们必须估算缺失值，并将数据存储为从属和独立部分。这是通过使用fastai函数<em class="jn"> proc_df </em>来完成的。该功能执行以下任务:</p><ul class=""><li id="dfd0" class="jo jp hi ih b ii ij im in iq jq iu jr iy js jc jt ju jv jw bi translated">对于连续变量，它检查一列是否有缺失值</li><li id="b9ce" class="jo jp hi ih b ii jy im jz iq ka iu kb iy kc jc jt ju jv jw bi translated">如果该列有缺失值，它会创建另一个名为<em class="jn"> columnname_na </em>的列，其中1表示缺失，0表示没有缺失</li><li id="98ea" class="jo jp hi ih b ii jy im jz iq ka iu kb iy kc jc jt ju jv jw bi translated">同时，缺失的值被替换为列的中值</li><li id="ed3a" class="jo jp hi ih b ii jy im jz iq ka iu kb iy kc jc jt ju jv jw bi translated">对于分类变量，pandas用-1替换缺失值。因此<em class="jn"> proc_df </em>将所有分类变量的值加1。因此，我们用0表示缺失，而所有其他值都以1递增</li></ul><pre class="jg jh ji jj fd lm ln lo lp aw lq bi"><span id="2a6e" class="lr ke hi ln b fi ls lt l lu lv">df, y, nas = proc_df(df_raw, 'SalePrice')</span></pre><h1 id="c927" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">模型结构</h1><p id="cfbc" class="pw-post-body-paragraph if ig hi ih b ii lb ik il im lc io ip iq lh is it iu li iw ix iy lj ja jb jc hb bi translated">我们已经处理了分类列和日期值。我们还处理了缺失的值。现在，我们终于可以启动并构建我们一直在缓慢前进的随机森林模型了。</p><pre class="jg jh ji jj fd lm ln lo lp aw lq bi"><span id="15d6" class="lr ke hi ln b fi ls lt l lu lv">m = RandomForestRegressor(n_jobs=-1) <br/>m.fit(df, y) <br/>m.score(df,y)</span></pre><p id="22ab" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jn"> n_jobs </em>设置为-1，以使用机器上所有可用的内核。这给了我们0.98的分数(r)，非常优秀。这里需要注意的是，我们已经在训练集上训练了模型，并在其上检查了结果。这个模型很有可能在看不见的数据(在我们的例子中是测试集)上表现不好。</p><p id="bf0c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">找出答案的唯一方法是创建一个验证集，并在其上检查模型的性能。因此，让我们创建一个包含12，000个数据点的验证集(训练集将包含其余的数据)。</p><pre class="jg jh ji jj fd lm ln lo lp aw lq bi"><span id="3c5d" class="lr ke hi ln b fi ls lt l lu lv">def split_vals(a,n): <br/>    return a[:n].copy(), a[n:].copy()<br/><br/>n_valid = 12000  # same as Kaggle's test set size<br/>n_trn = len(df)-n_valid<br/>raw_train, raw_valid = split_vals(df_raw, n_trn)<br/>X_train, X_valid = split_vals(df, n_trn)<br/>y_train, y_valid = split_vals(y, n_trn)<br/><br/>X_train.shape, y_train.shape, X_valid.shape</span></pre><p id="7763" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">输出:</p><pre class="jg jh ji jj fd lm ln lo lp aw lq bi"><span id="bc1c" class="lr ke hi ln b fi ls lt l lu lv">((389125, 66), (389125,), (12000, 66))</span></pre><p id="7064" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这里，我们将在新的数据集(原始数据集的样本)上训练模型，并检查训练集和验证集的性能。</p><pre class="jg jh ji jj fd lm ln lo lp aw lq bi"><span id="dd62" class="lr ke hi ln b fi ls lt l lu lv">#define a function to check rmse value<br/>def rmse(x,y): <br/>    return math.sqrt(((x-y)**2).mean())</span></pre><p id="1d27" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了将分数与训练集和测试集进行比较，下面的函数返回两个数据集的RMSE值和分数。</p><pre class="jg jh ji jj fd lm ln lo lp aw lq bi"><span id="c3dc" class="lr ke hi ln b fi ls lt l lu lv">def print_score(m):<br/>    res = [rmse(m.predict(X_train), y_train),<br/>           rmse(m.predict(X_valid), y_valid),<br/>           m.score(X_train, y_train), m.score(X_valid, y_valid)]<br/>    if hasattr(m, 'oob_score_'): res.append(m.oob_score_)<br/>    print(res)</span><span id="44cc" class="lr ke hi ln b fi mk lt l lu lv">m = RandomForestRegressor(n_jobs=-1)<br/>%time m.fit(X_train, y_train)<br/>print_score(m)</span></pre><p id="fd2b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上面代码的结果如下所示。<strong class="ih hj">训练集得分为0.98，验证集得分为0.88 </strong>。有点下降，但该模型总体上仍然表现良好。</p><pre class="jg jh ji jj fd lm ln lo lp aw lq bi"><span id="49b1" class="lr ke hi ln b fi ls lt l lu lv">CPU times: user 1min 3s, sys: 356 ms, total: 1min 3s<br/>Wall time: 8.46 s<br/>[0.09044244804386327, 0.2508166961122146, 0.98290459302099709, 0.88765316048270615]</span></pre><h1 id="3dbd" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">机器学习简介:第2课</h1><p id="f15c" class="pw-post-body-paragraph if ig hi ih b ii lb ik il im lc io ip iq lh is it iu li iw ix iy lj ja jb jc hb bi translated">既然您已经知道如何用Python编写随机森林模型，那么理解它在所有代码下的实际工作方式也同样重要。随机森林经常被引用为黑盒模型，现在是时候消除这种误解了。</p><figure class="jg jh ji jj fd jk"><div class="bz dy l di"><div class="lk ll l"/></div></figure><p id="2cd1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们在第一课中观察到，该模型在训练数据(它以前见过的点)上表现非常好，但在验证集上测试时表现不佳(数据点模型没有经过训练)。让我们首先了解我们是如何创建验证集的，以及为什么它如此重要。</p><h1 id="29b2" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">创建验证集</h1><p id="44f5" class="pw-post-body-paragraph if ig hi ih b ii lb ik il im lc io ip iq lh is it iu li iw ix iy lj ja jb jc hb bi translated">创建一个与测试集非常相似的验证集是机器学习中最重要的任务之一。验证分数代表了我们的模型在真实世界数据或测试数据上的表现。</p><p id="c12e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">请记住，如果涉及到时间组件，那么最近的行应该包含在验证集中。因此，我们的验证集将与测试集大小相同(来自训练数据的最后12，000行)。</p><pre class="jg jh ji jj fd lm ln lo lp aw lq bi"><span id="5a82" class="lr ke hi ln b fi ls lt l lu lv">def split_vals(a,n):<br/>   return a[:n].copy(), a[n:].copy()<br/><br/>n_valid = 12000  <br/>n_trn = len(df)-n_valid<br/>raw_train, raw_valid = split_vals(df_raw, n_trn)<br/>X_train, X_valid = split_vals(df, n_trn)<br/>y_train, y_valid = split_vals(y, n_trn)</span></pre><p id="0007" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从0到(长度— 12000)的数据点存储为训练集(x_train，y_train)。如前所述，使用训练集构建模型，并在训练集和验证集上测量其性能。</p><pre class="jg jh ji jj fd lm ln lo lp aw lq bi"><span id="2805" class="lr ke hi ln b fi ls lt l lu lv">m = RandomForestRegressor(n_jobs=-1)<br/>%time m.fit(X_train, y_train)<br/>print_score(m)</span></pre><p id="cbe0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">结果:</p><pre class="jg jh ji jj fd lm ln lo lp aw lq bi"><span id="e887" class="lr ke hi ln b fi ls lt l lu lv">CPU times: user 1min 3s, sys: 356 ms, total: 1min 3s <br/>Wall time: 8.46 s <br/>[0.09044244804386327, 0.2508166961122146, 0.98290459302099709, 0.88765316048270615]</span></pre><p id="515c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从上面的代码中，我们得到了结果:</p><ul class=""><li id="0338" class="jo jp hi ih b ii ij im in iq jq iu jr iy js jc jt ju jv jw bi translated">训练场上的RMSE</li><li id="55f7" class="jo jp hi ih b ii jy im jz iq ka iu kb iy kc jc jt ju jv jw bi translated">验证集上的RMSE</li><li id="52e8" class="jo jp hi ih b ii jy im jz iq ka iu kb iy kc jc jt ju jv jw bi translated">训练集上的r平方</li><li id="80c7" class="jo jp hi ih b ii jy im jz iq ka iu kb iy kc jc jt ju jv jw bi translated">验证集上的r平方</li></ul><p id="8bb8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">很明显，该模型在训练集上过度拟合。另外，训练需要一分多钟。我们能减少训练时间吗？是的，我们可以！为此，我们将进一步获取原始数据集的子集:</p><pre class="jg jh ji jj fd lm ln lo lp aw lq bi"><span id="e661" class="lr ke hi ln b fi ls lt l lu lv">df_trn, y_trn, nas = proc_df(df, 'SalePrice', subset=30000)<br/>X_train, _ = split_vals(df_trn, 20000)<br/>y_train, _ = split_vals(y_trn, 20000)</span></pre><p id="4d98" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">已经创建了30，000个样本的子集，我们从中抽取20，000个样本用于训练随机森林模型。</p><h1 id="e71c" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">建造一棵树</h1><p id="6cdf" class="pw-post-body-paragraph if ig hi ih b ii lb ik il im lc io ip iq lh is it iu li iw ix iy lj ja jb jc hb bi translated">随机森林是一组称为估计量的树。随机森林模型中的树木数量由参数<em class="jn"> n_estimator </em>定义。我们将首先查看最大深度为3的单棵树(设置<em class="jn">n _估计器</em> = 1)。</p><pre class="jg jh ji jj fd lm ln lo lp aw lq bi"><span id="a551" class="lr ke hi ln b fi ls lt l lu lv">m = RandomForestRegressor(<strong class="ln hj">n_estimators=1</strong>, max_depth=3, bootstrap=<strong class="ln hj">False</strong>, n_jobs=-1)<br/>m.fit(X_train, y_train)<br/>print_score(m)</span></pre><p id="6bf8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">结果:</p><pre class="jg jh ji jj fd lm ln lo lp aw lq bi"><span id="e6ce" class="lr ke hi ln b fi ls lt l lu lv">[0.4965829795739235, 0.5246832258551836, 0.50149617735615859, 0.5083655198087873]</span></pre><p id="e74d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">绘制树:</p><pre class="jg jh ji jj fd lm ln lo lp aw lq bi"><span id="a560" class="lr ke hi ln b fi ls lt l lu lv">draw_tree(m.estimators_[0], df_trn, precision=3)</span></pre><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="er es ml"><img src="../Images/b1b2d80dcd50b5d45119794c42f2007e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*WIDf47NCgQ17Z1ct.png"/></div></div></figure><p id="53f2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">该树是一组二元决策。查看第一个框，第一个分割是基于耦合器系统值:小于/等于0.5或大于0.5。分割后，我们得到耦合器_系统&gt; 0.5的3185行，剩余的16815行具有&lt;0.5. Similarly, next split is on enclosure and Year_made.</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div class="er es mm"><img src="../Images/c24435dac1a86765cfce8ea23871bb19.png" data-original-src="https://miro.medium.com/v2/resize:fit:936/format:webp/0*zGU0QwwOrnY5rE8K.png"/></div></figure><p id="f809" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">For the first box, a model is created using only the average value (10.189). This means that all the rows have a predicted value of 10.189 and the MSE (Mean Squared Error) for these predictions is 0.459. Instead, if we make a split and separate the rows based on coupler_system &lt;0.5, the MSE is reduced to 0.414 for samples satisfying the condition (true) and 0.109 for the remaining samples.</p><p id="fdea" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">So how do we decide which variable to split on? The idea is to split the data into two groups which are as different from each other as possible. This can be done by checking each possible split point for each variable, and then figuring out which one gives the lower MSE. To do this, we can take a weighted average of the two MSE values after the split. The splitting stops when it either reaches the pre-specified <em class="jn">最大_深度</em>值，或者当每个叶节点只有一个值时。</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="er es mn"><img src="../Images/52cd5c7014aaa1af551bdc94c396016f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*A6Af-9wKGrXHF0KC.png"/></div></div></figure><p id="e023" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们有一个基本模型——一棵树，但这不是一个很好的模型。我们需要建立在这个结构上的更复杂的东西。为了创建一个森林，我们将使用一种叫做装袋的统计技术。</p><h1 id="ea35" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">装袋介绍</h1><p id="1645" class="pw-post-body-paragraph if ig hi ih b ii lb ik il im lc io ip iq lh is it iu li iw ix iy lj ja jb jc hb bi translated">在bagging技术中，我们创建多个模型，每个模型给出的预测与其他模型不相关。然后我们对这些模型的预测进行平均。<strong class="ih hj">随机森林是一种装袋技术。</strong></p><p id="4e0d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果创建的所有树彼此相似并给出相似的预测，那么平均这些预测将不会提高模型性能。相反，我们可以在不同的数据子集上创建多个树，这样即使这些树过拟合，它们也会在不同的点集上这样做。<em class="jn">这些样品是用替代品取的。</em></p><p id="6450" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">简而言之，我们创建多个表现不佳的模型，并对它们进行平均，以创建一个良好的模型。</strong>单个模型必须尽可能具有预测性，但放在一起应该是不相关的。我们现在将增加随机森林中估计量的数量，看看结果。</p><pre class="jg jh ji jj fd lm ln lo lp aw lq bi"><span id="612b" class="lr ke hi ln b fi ls lt l lu lv">m = RandomForestRegressor(n_jobs=-1)<br/>m.fit(X_train, y_train)<br/>print_score(m)</span></pre><p id="6520" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果我们不给<em class="jn"> n_estimator </em>参数一个值，默认取为10。我们将从10棵树中的每一棵树得到预测。此外，<em class="jn"> np.stack </em>将用于一个接一个地连接预测。</p><pre class="jg jh ji jj fd lm ln lo lp aw lq bi"><span id="9815" class="lr ke hi ln b fi ls lt l lu lv">preds = np.stack([t.predict(X_valid) for t in m.estimators_])</span><span id="c49c" class="lr ke hi ln b fi mk lt l lu lv">preds.shape</span></pre><p id="5c93" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">预测的维数是(10，12000)。这意味着验证集中的每一行有10个预测。</p><p id="0de7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，为了将我们的模型结果与验证集进行比较，这里是预测行、预测的平均值和来自验证集的实际值。</p><pre class="jg jh ji jj fd lm ln lo lp aw lq bi"><span id="b37a" class="lr ke hi ln b fi ls lt l lu lv">preds[:,0], np.mean(preds[:,0]), y_valid[0]</span></pre><p id="3332" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">实际值是9.17，但我们的预测没有一个接近这个值。对我们所有的预测取平均值，我们得到9.07，这是一个比任何单独的树更好的预测。</p><pre class="jg jh ji jj fd lm ln lo lp aw lq bi"><span id="c28b" class="lr ke hi ln b fi ls lt l lu lv">(array([ 9.21034,  8.9872 , 8.9872 , 8.9872 ,  8.9872 , 9.21034, 8.92266, 9.21034,  9.21034, 8.9872 ]),<br/>9.0700003890739005,<br/>9.1049798563183568)</span></pre><p id="95d3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">尽可能可视化您的模型总是一个好主意。这张图显示了随着树木数量的增加，r值的变化。</p><pre class="jg jh ji jj fd lm ln lo lp aw lq bi"><span id="e72c" class="lr ke hi ln b fi ls lt l lu lv">plt.plot([metrics.r2_score(y_valid, np.mean(preds[:i+1], axis=0)) for i in range(10)]);</span></pre><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="er es mo"><img src="../Images/ecc04c0b7b853d42ad3936a41cb85959.png" data-original-src="https://miro.medium.com/v2/resize:fit:762/format:webp/0*d7UVh1pU3wFu-szX.png"/></div></div></figure><p id="9286" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">正如所料，随着树的数量增加，r变得更好。您可以试验一下<em class="jn"> n_estimator </em>的值，看看r值在每次迭代中是如何变化的。你会注意到，在一定数量的树之后，r值趋于平稳。</p><h1 id="0e74" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">场外(OOB)评分</h1><p id="6126" class="pw-post-body-paragraph if ig hi ih b ii lb ik il im lc io ip iq lh is it iu li iw ix iy lj ja jb jc hb bi translated">为小数据集创建单独的验证集可能是一个潜在的问题，因为这将导致更小的训练集。在这种情况下，我们可以使用没有训练树的数据点(或样本)。</p><p id="b3ef" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为此，我们设置参数<em class="jn"> oob_score </em> =True。</p><pre class="jg jh ji jj fd lm ln lo lp aw lq bi"><span id="995d" class="lr ke hi ln b fi ls lt l lu lv">m = RandomForestRegressor(n_estimators=40, n_jobs=-1, oob_score=True)<br/>m.fit(X_train, y_train)<br/>print_score(m)<br/><br/>[0.10198464613020647, 0.2714485881623037, 0.9786192457999483, 0.86840992079038759, 0.84831537630038534]</span></pre><p id="d868" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jn"> oob_score </em>为0.84，接近验证集。让我们看看其他一些有趣的技术，通过它们我们可以改进我们的模型。</p><h1 id="93ab" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">二次抽样</h1><p id="2fd2" class="pw-post-body-paragraph if ig hi ih b ii lb ik il im lc io ip iq lh is it iu li iw ix iy lj ja jb jc hb bi translated">之前，我们创建了一个30，000行的子集，训练集是从这个子集中随机选择的。作为一种替代方案，我们可以每次创建一个不同的子集，以便在更大部分的数据上训练模型。</p><pre class="jg jh ji jj fd lm ln lo lp aw lq bi"><span id="07a0" class="lr ke hi ln b fi ls lt l lu lv">df_trn, y_trn, nas = proc_df(df_raw, 'SalePrice')<br/>X_train, X_valid = split_vals(df_trn, n_trn)<br/>y_train, y_valid = split_vals(y_trn, n_trn)<br/>set_rf_samples(20000)</span></pre><p id="2e81" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们使用<em class="jn"> set_rf_sample </em>来指定样本大小。让我们检查一下模型的性能是否有所提高。</p><pre class="jg jh ji jj fd lm ln lo lp aw lq bi"><span id="98ce" class="lr ke hi ln b fi ls lt l lu lv">m = RandomForestRegressor(n_estimators=40, n_jobs=-1, oob_score=True)<br/>m.fit(X_train, y_train)<br/>print_score(m)<br/><br/>[0.2317315086850927, 0.26334275954117264, 0.89225792718146846, 0.87615150359885019, 0.88097587673696554]</span></pre><p id="c99d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们得到0.876的验证分数。到目前为止，我们已经研究了一个样本的子集。我们可以在整个数据集上拟合这个模型(但这将需要很长时间来运行，这取决于您的计算资源有多好！).</p><pre class="jg jh ji jj fd lm ln lo lp aw lq bi"><span id="0858" class="lr ke hi ln b fi ls lt l lu lv">reset_rf_samples()<br/>m = RandomForestRegressor(n_estimators=40, n_jobs=-1, oob_score=True)<br/>m.fit(X_train, y_train)<br/>print_score(m)<br/><br/>[0.07843013746508616, 0.23879806957665775, 0.98490742269867626, 0.89816206196980131, 0.90838819297302553]</span></pre><h1 id="3093" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">要试验和调整的其他超参数</h1><h1 id="a280" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">最小样本叶</h1><p id="050f" class="pw-post-body-paragraph if ig hi ih b ii lb ik il im lc io ip iq lh is it iu li iw ix iy lj ja jb jc hb bi translated">这可以作为树的停止标准。当叶节点中的样本数小于指定值时，树停止生长(或分裂)。</p><pre class="jg jh ji jj fd lm ln lo lp aw lq bi"><span id="32d6" class="lr ke hi ln b fi ls lt l lu lv">m = RandomForestRegressor(n_estimators=40, min_samples_leaf=3,n_jobs=-1, oob_score=True)<br/>m.fit(X_train, y_train)<br/>print_score(m)<br/><br/>[0.11595869956476182, 0.23427349924625201, 0.97209195463880227, 0.90198460308551043, 0.90843297242839738]</span></pre><p id="5714" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里，我们将<em class="jn">最小样本叶</em>指定为3。这意味着对于每次分割，节点中的最小样本数应为3。我们看到，验证集的r提高了，测试集的r降低了，这表明模型没有过度拟合训练数据。</p><h1 id="9174" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">最大特征</h1><p id="1fa8" class="pw-post-body-paragraph if ig hi ih b ii lb ik il im lc io ip iq lh is it iu li iw ix iy lj ja jb jc hb bi translated">随机森林的另一个重要参数是<em class="jn"> max_features </em>。我们之前已经讨论过，各个树必须尽可能不相关。同样，随机森林使用行的子集来训练每棵树。此外，我们还可以使用列(特性)的子集，而不是使用所有的特性。这可以通过调整<em class="jn">最大特征</em>参数来实现。</p><pre class="jg jh ji jj fd lm ln lo lp aw lq bi"><span id="9eee" class="lr ke hi ln b fi ls lt l lu lv">m = RandomForestRegressor(n_estimators=40, min_samples_leaf=3, max_features=0.5, n_jobs=-1, oob_score=True) <br/>m.fit(X_train, y_train)<br/>print_score(m)<br/><br/>[0.11926975747908228, 0.22869111042050522, 0.97026995966445684, 0.9066000722129437, 0.91144914977164715]</span></pre><p id="1a1a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">设置<em class="jn"> max_features </em>稍微提高了验证分数。这里<em class="jn"> max_features </em>被设置为0.5，这意味着每次分割使用50%的特征。请记住，这个参数也可以采用log2或sqrt这样的值。</p><h1 id="14bb" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">其他主题</h1><h1 id="28a9" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">Jupyter笔记本中的提示和技巧</h1><p id="4a6c" class="pw-post-body-paragraph if ig hi ih b ii lb ik il im lc io ip iq lh is it iu li iw ix iy lj ja jb jc hb bi translated">杰瑞米·霍华德提到了一些导航Jupyter笔记本的技巧和窍门，新手会觉得很有用。以下是一些亮点:</p><ul class=""><li id="c9df" class="jo jp hi ih b ii ij im in iq jq iu jr iy js jc jt ju jv jw bi translated">要找出函数位于哪个库中，只需键入函数名并运行单元格(shift-enter):</li></ul><pre class="jg jh ji jj fd lm ln lo lp aw lq bi"><span id="eef0" class="lr ke hi ln b fi ls lt l lu lv">display</span></pre><figure class="jg jh ji jj fd jk er es paragraph-image"><div class="ab fe cl mp"><img src="../Images/31573030d1a65a61fbd5e375cc6c1f55.png" data-original-src="https://miro.medium.com/v2/format:webp/1*b31hiO4ynbDLRrXWEFF4aQ.png"/></div></figure><ul class=""><li id="d51c" class="jo jp hi ih b ii ij im in iq jq iu jr iy js jc jt ju jv jw bi translated">若要查看文档，请在函数前使用问号:</li></ul><pre class="jg jh ji jj fd lm ln lo lp aw lq bi"><span id="9e8c" class="lr ke hi ln b fi ls lt l lu lv">?display</span></pre><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="er es mq"><img src="../Images/98cb4a112f59a2554338e5d2c8e30a5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*tBlW6kbeIyrJs5FL.png"/></div></div></figure><ul class=""><li id="b300" class="jo jp hi ih b ii ij im in iq jq iu jr iy js jc jt ju jv jw bi translated">若要查看函数的源代码，请在函数名前使用双问号:</li></ul><pre class="jg jh ji jj fd lm ln lo lp aw lq bi"><span id="1b74" class="lr ke hi ln b fi ls lt l lu lv">??display</span></pre><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="er es mr"><img src="../Images/77122aa60f07037e7ac3000ca3446410.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*NBB46Ds54FODMd90.png"/></div></div></figure><h1 id="aed8" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">维度的诅咒</h1><p id="39e0" class="pw-post-body-paragraph if ig hi ih b ii lb ik il im lc io ip iq lh is it iu li iw ix iy lj ja jb jc hb bi translated">维度的诅咒是我们拥有的维度越多，空间边缘上的点就越多。所以如果列数越多，就会产生越来越多的空白空间。从理论上讲，这意味着点与点之间的距离意义不大。这不应该是真的，因为这些点彼此之间的距离仍然不同。即使它们在边上，我们仍然可以确定它们彼此之间有多远。</p><h1 id="d3fd" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">连续、分类、顺序变量</h1><ul class=""><li id="1773" class="jo jp hi ih b ii lb im lc iq ld iu le iy lf jc jt ju jv jw bi translated">连续变量是具有整数值或浮点值的变量。例如，年龄、距离、体重、收入等</li><li id="74ea" class="jo jp hi ih b ii jy im jz iq ka iu kb iy kc jc jt ju jv jw bi translated">分类变量通常是代表名称或标签的字符串或值。例如，性别、州、邮政编码、级别等</li><li id="85dc" class="jo jp hi ih b ii jy im jz iq ka iu kb iy kc jc jt ju jv jw bi translated">序数变量是那些在它们之间有顺序的分类变量。例如，等级(I、II、III)或备注(差、好、优秀)有一个顺序。</li></ul><h1 id="801f" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">过度拟合和欠拟合</h1><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><div class="er es ms"><img src="../Images/65a07b33e285f154ac11eb62e5e66cf1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*1OvL9bgIZR5VLqJt.png"/></div></div></figure><ul class=""><li id="a5f3" class="jo jp hi ih b ii ij im in iq jq iu jr iy js jc jt ju jv jw bi translated">欠拟合:在训练数据和测试数据上表现不佳的模型。这个模型不能很好地概括。(左图)</li><li id="21db" class="jo jp hi ih b ii jy im jz iq ka iu kb iy kc jc jt ju jv jw bi translated">过度拟合:在训练数据上表现非常好，但在测试数据上没有表现出类似的高性能的模型。(右图)</li></ul><h1 id="14f3" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">均方根对数误差</h1><p id="1023" class="pw-post-body-paragraph if ig hi ih b ii lb ik il im lc io ip iq lh is it iu li iw ix iy lj ja jb jc hb bi translated">我们的数据集的评估指标是RMSLE。这个公式是</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div class="er es mt"><img src="../Images/f79181b35ecf3be3f442ea51bf63bc74.png" data-original-src="https://miro.medium.com/v2/resize:fit:778/format:webp/0*_HTtFrP3eK-u5LYu.png"/></div></figure><p id="5e17" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们首先取对数值的平方差的平均值。我们对所得结果求平方根。这相当于计算这些值的对数的均方根误差(rmse)。</p><h1 id="ba94" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">r平方</h1><p id="e21c" class="pw-post-body-paragraph if ig hi ih b ii lb ik il im lc io ip iq lh is it iu li iw ix iy lj ja jb jc hb bi translated">以下是R平方的数学公式:</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div class="er es mu"><img src="../Images/2337e03e8345675c19e3ab2da4bf0f7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*_aHhpovoeCXNr0Fz.png"/></div></figure><ul class=""><li id="4827" class="jo jp hi ih b ii ij im in iq jq iu jr iy js jc jt ju jv jw bi translated">SSregression是(实际值-预测值)的平方和</li><li id="079b" class="jo jp hi ih b ii jy im jz iq ka iu kb iy kc jc jt ju jv jw bi translated">SStotal是(实际值-平均值)的平方和</li></ul><p id="31c3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">R平方的值可以是小于1的任何值。如果r平方为负，说明你的模型比预测均值差。</p><h1 id="0b83" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">极度随机化树</h1><p id="ea89" class="pw-post-body-paragraph if ig hi ih b ii lb ik il im lc io ip iq lh is it iu li iw ix iy lj ja jb jc hb bi translated">在scikit-learn中，我们有另一个算法<em class="jn"> ExtraTreeClassifier </em>，它是一个极度随机化的树模型。与随机森林不同，它不是为每个变量尝试每个分裂点，而是为几个变量随机尝试几个分裂点。</p><h1 id="32ab" class="kd ke hi bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">结束注释</h1><p id="ef9b" class="pw-post-body-paragraph if ig hi ih b ii lb ik il im lc io ip iq lh is it iu li iw ix iy lj ja jb jc hb bi translated">这篇文章对fast.ai的机器学习课程的前两个视频进行了非常全面的总结。在第一课中，我们学习了在推土机数据集上编码一个简单的随机森林模型。随机森林(和大多数ml算法)不能处理分类变量。在随机森林实现过程中，我们遇到了类似的问题，我们看到了如何使用数据集中的日期列和其他分类列来创建模型。</p><p id="c50e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在第二个视频中，介绍了创建验证集的概念。然后，我们使用这个验证集来检查模型的性能，并调整一些基本的超参数来改进模型。这个视频中我最喜欢的部分是绘制和可视化我们建造的树。我相信通过这些视频你会学到很多东西。我将很快发布另一篇文章，介绍课程的下两个视频。</p><p id="315f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jn">更新:</em> </strong>这是该系列的第二部分(涵盖第3、4、5课)</p><p id="b01e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae jx" href="https://www.analyticsvidhya.com/blog/2018/10/interpret-random-forest-model-machine-learning-programmers/" rel="noopener ugc nofollow" target="_blank">使用fastai库解释随机森林模型的直观指南(程序员的机器学习—第2部分)</a></p></div><div class="ab cl mv mw gp mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="hb hc hd he hf"><p id="eced" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jn">原载于2018年10月8日</em><a class="ae jx" href="https://www.analyticsvidhya.com/blog/2018/10/comprehensive-overview-machine-learning-part-1/" rel="noopener ugc nofollow" target="_blank"><em class="jn">www.analyticsvidhya.com</em></a><em class="jn">。</em></p></div></div>    
</body>
</html>