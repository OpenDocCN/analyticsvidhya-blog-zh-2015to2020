<html>
<head>
<title>Decision Tree for Regression — The Recipe</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">回归决策树——秘诀</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/decision-tree-for-regression-the-recipe-74f7628b8a0?source=collection_archive---------11-----------------------#2020-06-03">https://medium.com/analytics-vidhya/decision-tree-for-regression-the-recipe-74f7628b8a0?source=collection_archive---------11-----------------------#2020-06-03</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="24a9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">回归是指当因变量连续时，确定因变量和自变量之间的潜在关系。可以使用许多模型来预测连续变量。使用的一些模型是线性回归、决策树、k-最近邻等。</p><p id="4a21" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">决策树模型本质上是非参数的，即它使用无限的参数来学习数据。它有一棵树的结构。随机森林算法是决策树的改进版本。决策树基本上将数据集分割成许多子集。</p><p id="fdcb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">就像切蛋糕一样……</em></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/6b7cb6ba6d48f9370bea8355db597d00.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o0w9mI8ysfm00ysCBfQTbg.jpeg"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">供图:<a class="ae ju" href="https://alltimelists.com/youve-been-cutting-the-cake-all-wrong/" rel="noopener ugc nofollow" target="_blank">https://all time lists . com/you ve-be-cut-the-cake-all-wrong/</a></figcaption></figure><p id="a412" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">决策树的结构</strong></p><p id="6e24" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">通常，数据集被分支或切割的节点被称为<strong class="ih hj">决策节点</strong>。分支停止的节点称为<strong class="ih hj">叶节点。</strong>数据集第一次被切割的节点称为<strong class="ih hj">根节点。</strong>从另一个角度来看，数据是根据不同的条件分组的。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es jv"><img src="../Images/28e5c72e1ca5c418fcbd524b0ce164ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1190/format:webp/1*QVPffJUHDDXYLcT6z0PbxQ.jpeg"/></div><figcaption class="jq jr et er es js jt bd b be z dx translated">黄色节点-决策节点，绿色节点-叶节点，以蓝色突出显示的节点-根节点</figcaption></figure><p id="8b24" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">决策树的学习方面指的是识别在数据集的哪里进行这些切割。</p><p id="6d5c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我写了一行代码，但它是如何工作的？？？？？</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es jw"><img src="../Images/880b2d7f0ec6e8edfd4c97f3ae866677.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qPZ45Zc3oljWP4mBpsxE5Q.jpeg"/></div></div></figure><p id="fd8a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们用一个例子来讨论。</p><p id="a43c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">假设我们正在解决一个问题，预测我们应该添加到一道菜里的辣椒粉的克数<em class="jd">(因变量)</em>，给定要考虑的自变量有</p><p id="5e65" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">I .烹饪类型(印度、中国、泰国)，</p><p id="12ec" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">二。菜里有新鲜辣椒(0-否，1-是)，</p><p id="110c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">三。这道菜是为孩子们做的吗？(0-否，1-是)，</p><p id="7b7f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">四。菜肴的基本配料(米饭、面条、蔬菜)，</p><p id="3f19" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">动词 （verb的缩写）准备的菜肴的数量(以克为单位)。</p><p id="ce03" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">可能还有更多的因素需要考虑，但我们仅限于这五个。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es jx"><img src="../Images/5fc1af459a5ce3e539a588d8edb43062.png" data-original-src="https://miro.medium.com/v2/resize:fit:1038/format:webp/1*ehPUWKsn1wJwjLfpdsbuRw.jpeg"/></div><figcaption class="jq jr et er es js jt bd b be z dx translated">我们的数据集</figcaption></figure><p id="661a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">其他例子也可以用来解释，但是如果你不把它和你熟悉的事物联系起来，那还有什么好激动的。</p><p id="945a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">(请读者注意，数据集是为了解释的目的而创建的，可能与实际值不匹配)</em></p><p id="cd83" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">通过找到度量(称为“标准”)减少最大的独立变量和阈值，树开始生长。</p><p id="f5dc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">步骤顺序:</strong></p><ol class=""><li id="42ab" class="jy jz hi ih b ii ij im in iq ka iu kb iy kc jc kd ke kf kg bi translated">计算训练数据中因变量的‘MSE’(均方误差)。这里的“均方误差”解释了平均值的分布(如方差)。<em class="jd">(计算MSE是因为在代码中，criterion =‘MSE’)</em></li></ol><p id="f99c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们数据中的“y”值:26，15，25，30，10，24，13，8，14，27</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es kh"><img src="../Images/2f1d71171c6723024623826c821de9b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:984/format:webp/1*tDjnI5_m8b-Ai6KT9SNRHQ.jpeg"/></div></figure><p id="5884" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.接下来，模型通过尝试将每个独立变量和每个可能的阈值作为条件来分割数据集，并在分割数据后计算MSE。</p><p id="5670" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jd">数据上有哪些可能的拆分？</em>T3】</strong></p><p id="02ad" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">例如，我们试图根据新鲜辣椒的存在来分割数据，</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es ki"><img src="../Images/15bd5885d6ff8a72ec24f382fc35a9b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:834/format:webp/1*lkJhDbcsIYBfUQhWTnxsUw.jpeg"/></div><figcaption class="jq jr et er es js jt bd b be z dx translated">数据——在分开不同的辣椒后</figcaption></figure><p id="f7e4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在“辣椒的存在”上分割后计算数据的MSE:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es kj"><img src="../Images/226cc168a89f7c525bd8d7ace23beb0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EGqvchToV7UbhXK5882W5g.jpeg"/></div></figure><p id="502f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">MSE减少= 57.36–57.33 = 0.03</p><p id="6971" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">类似地，让我们试着在变量“这道菜是给孩子们做的吗？”上分割数据</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es kk"><img src="../Images/1f0a7b277a5f7c67ee6c5a96e60423d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:862/format:webp/1*mumRa5BedGkF6cW-V96yAw.jpeg"/></div></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es kl"><img src="../Images/b1819191b6fa157e6137d16ed8c67df3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1108/format:webp/1*NTP42AGY5Y4mDZS1jbQxqw.jpeg"/></div></figure><p id="34bf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">MSE减少= 57.36–57.302 = 0.058</p><p id="b43f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">同样，数据也可以按菜系划分，例如，如果菜系类型为“泰式”等。，并计算MSE的相应减少。</p><p id="7e0a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jd">连续变量的情况下会发生什么？？？？？</em> </strong></p><p id="2816" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">“准备菜肴的数量”是我们数据集中的一个变量。</p><p id="b6b8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">将连续变量的不同值作为阈值来计算MSE的减少。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es ki"><img src="../Images/2a906c97783370a7240d1ab2c5a814f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:834/format:webp/1*nLxXhUMRfmW1LuKj_zl79w.jpeg"/></div></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es km"><img src="../Images/ed97352c98944f62463545d043a072ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1192/format:webp/1*OC_Bw0ponMf5KEg4kQFOxA.jpeg"/></div></figure><p id="27c6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">MSE减少= 57.36–19.3 = 38.06</p><p id="0784" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于连续变量的不同阈值，重复该过程。</p><p id="23f7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"><em class="jd">“MSE减少”值告诉我们特定变量的数据分割是否有效。</em> </strong> <em class="jd">用同样的方法，对每一个单一变量都计算出MSE的减少量。</em></p><p id="3b07" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">3.给出MSE的最大减少的变量因此被选择作为分裂的根节点。<em class="jd">(在代码中我们提到splitter='best ')。</em></p><p id="1468" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">在我们的示例中，变量“准备的菜肴数量”及其阈值1115被选为根节点，因为它导致MSE的最大减少。</em></p><p id="3be9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">因此，用于分割数据的第一个条件是“准备的菜肴数量”&lt; =1115。</strong></p><p id="6401" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">4.为了使树增长，从根产生的节点可以被进一步分割。我们有2个从根<em class="jd">分支的节点(一个由端盘数量≤1115的数据组成，另一个由端盘数量&gt; 1115的数据组成)</em>。</p><p id="2c47" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这两个节点中哪一个分支更远？基于我们指定的超参数来回答。</p><p id="3cec" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">超参数'最小杂质分离'，'最小样本叶'，'最小样本分离'和'最小杂质减少'帮助我们决定一个节点是否将分支。一旦选择了可以分支的节点，重复相同的过程，以便找到导致mse最大减少的变量和阈值(所选节点中的值的<em class="jd"> mse)。</em></p><p id="6899" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">重复该过程，直到达到树的最大深度或最大叶节点数。当不可能进一步分裂时，生长也停止。下图是我们训练集的决策树模型。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es kn"><img src="../Images/f05091c644368b9bc67fcce5f2e566d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XpdykxomKgdJPHEhNcoD_Q.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">我们数据集的决策树模型</figcaption></figure><p id="4ab1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">表现:</strong></p><p id="4938" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">模型中的每个块/节点为我们提供了4个方面的见解，</p><p id="27c1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">1.该节点中存在的训练数据的样本数(样本)</p><p id="e073" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.该节点中点的平均值(值)</p><p id="76f6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">3.该节点中值的MSE(熵)</p><p id="f75c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">4.进一步拆分节点所基于变量和阈值。</p><p id="1bfd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">请注意，所有叶节点仅给出洞察1、2和3，因为它们不会再次分支。</p><p id="38ae" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以在最终模型中看到10个叶节点，因为我们的数据中有10个因变量的唯一值。一般来说，完全长大的树不是首选。这样的树会一直生长，直到每个叶节点中只有一个唯一的值。</p><p id="aa9b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">(该死…如果训练数据很大，那会导致一棵大树)</em>。</p><p id="b2a5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这也将导致另一个问题，称为模型对我们的训练数据的过度拟合。因此，调整超参数至关重要。有关超参数的更多详细信息，请参考</p><p id="3bff" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae ju" href="https://scikitlearn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html#sklearn.tree.DecisionTreeRegressor" rel="noopener ugc nofollow" target="_blank">T3】https://scikit learn . org/stable/modules/generated/sk learn . tree . decisiontreeregressor . html # sk learn . tree . decisiontreeregressorT5】</a></p><p id="791a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">模型建立。接下来呢？？？</strong></p><p id="1c75" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在预测看不见的数据点的过程中，模型使用看不见的数据的独立变量值，并在基于定型数据开发的条件下检查它们。在某一点上，看不见的数据点落在其中一个节点下，并且最终预测作为该节点中训练点的平均值给出。该模型只是返回我们看不见的数据所属的节点的“价值”洞察力。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es ko"><img src="../Images/d4644eada70021515f0ee1a1125ae4c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6tbvYJq__8kgws3Fd_CMPg.png"/></div></div></figure><p id="4f7f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">假设我们需要预测具有以下属性的一道菜的辣椒粉数量:[泰国，有辣椒，不是为孩子做的，基本成分:大米，850克最终菜]，数据点通过红色显示的路径，并在一个节点中结束(除此之外，不检查任何条件)。该节点<em class="jd">(该节点中训练数据点的平均辣椒粉)</em> = 10，因此，该看不见的数据点的辣椒粉的预测量= 10克。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es kp"><img src="../Images/65eb0412cc7e7f534132b875a208410d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*POx5rRoBxLIjXYweKHYTHw.jpeg"/></div><figcaption class="jq jr et er es js jt bd b be z dx translated">供图:<a class="ae ju" href="https://www.barnorama.com/20-hilarious-surprised-cats-photos/" rel="noopener ugc nofollow" target="_blank">https://www . barnorama . com/20-爆笑-惊讶-猫-照片/ </a></figcaption></figure><p id="a475" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">好吧…等等…什么？？平均分？？？k近邻算法就是这么预测的。是..K-NN取k个“最近点”并返回它们的平均值作为预测值。决策树回归器以同样的方式工作，但是为了知道哪些点需要平均，它使用了分裂技术。</p><p id="ce00" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">快乐学习！！！！！！！</strong></p><p id="0bd2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">参考资料:</p><p id="b0d8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">[1]<a class="ae ju" href="https://saedsayad.com/decision_tree_reg.htm" rel="noopener ugc nofollow" target="_blank">https://saedsayad.com/decision_tree_reg.htm</a></p><p id="c949" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">[2]<a class="ae ju" href="https://scikit-learn.org/stable/modules/tree.html" rel="noopener ugc nofollow" target="_blank">https://scikit-learn.org/stable/modules/tree.html</a></p></div></div>    
</body>
</html>