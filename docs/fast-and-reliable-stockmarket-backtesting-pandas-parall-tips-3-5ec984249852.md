# 快速可靠的股票市场回溯测试。熊猫平行小贴士#3

> 原文：<https://medium.com/analytics-vidhya/fast-and-reliable-stockmarket-backtesting-pandas-parall-tips-3-5ec984249852?source=collection_archive---------10----------------------->

![](img/bf446513e04aad7e6a41fe55708fe7f5.png)

在前两个技巧中，我展示了如何获取数据集中每个交易日的 n 大动量股票列表。主要目标是实现简洁明了的代码，首先使计算更可靠，然后更快。

但是怎么真的快呢？使用前一篇文章中给出的代码输出该表大约需要 42 秒:它获得 6600 个具有 20 年价格历史的报价机(1800 万行)作为输入，并返回包含 3 只表现最好的股票的表(15.5 万行)。

问题是:“我们能否在不牺牲可靠性的情况下减少时间？”
答案是:“是的，使用并行处理。”

这里的第一点是了解我们是否可以用必须分成几个块的数据进行独立计算。我们来分析一下:

*   首先，我们获取单个股票的价格历史，并计算其每天的第 n 个动量；
*   然后我们把每一天的动量分类；
*   并在特定日期保留 3 只(5，10，n)表现最好的股票。

显然，第一次计算可以并行进行，根据不同的报价机列表将价格数据分成几个子集。例如，我有 6600 家公司的价格历史记录，而我的电脑有 12 个处理器，所以我可以将整个数据集分成 12 个块，这样每个块都包含 550 家公司的完整价格历史记录。获得个股动量后，算法将 12 个表重组为一个更大的表，然后我们可以排序并保存。

这些功能如下:

*   “动量”函数总是计算当前数据集的第 n 个动量；
*   “split_prices”函数将总共 6600 个报价机数据集分成 12 个较小的数据集；
*   “parallel_momentum”函数将 18M 行价格历史数据、动量值(我们愿意计算)、PC 内核数量作为输入，运行“n_cores”并行计算，并返回(几乎)相同的 18M 行数据集，但每个日期都有动量。

最后，我们需要做的就是将获得的动量从最好到最差排序，并从每个日期中选出表现最好的 3 个。代码如下:

正如我们所看到的，以这种方式完成的并行计算可以让我们节省大约 25%的计算时间:在输出相同的情况下，计算时间从 42 秒减少到 32 秒。

但是如果我们测量代码不同部分的执行时间，我们会发现最长的是那些对 Pandas 数据帧进行操作的部分。例如，在函数" split_prices "中有这样的操作:

```
prices[prices['Ticker'].isin(cur_tickers)]
```

在这一部分中，该算法获取报价器列表，并告诉 Pandas 查看所有行的 1800 万行数据，并在“报价器”列中返回包含这些报价器的数据。这是一个相当长的操作。因此，让我们用一个新的函数“split_prices_fast”替换函数“split_prices”:

使用这种拆分数据的方法运行并行计算，可以为我们带来 7 秒钟的额外计算加速:

因此，现在我们的并行算法比最初的算法快了近 1.7 倍。

但是完美的极限是零时间运行代码，所以肯定有可以改进的地方。至于“split_prices_fast”功能:没有评论是为了给你一个机会一步一步地拆解它自己在做什么。