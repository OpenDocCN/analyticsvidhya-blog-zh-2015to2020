<html>
<head>
<title>Face mask detection using AI (model creation)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用人工智能(模型创建)的人脸面具检测</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/face-mask-detection-using-ai-model-creation-67f43dd2c3db?source=collection_archive---------15-----------------------#2020-07-29">https://medium.com/analytics-vidhya/face-mask-detection-using-ai-model-creation-67f43dd2c3db?source=collection_archive---------15-----------------------#2020-07-29</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex if ig ih ii"><div class="bz dy l di"><div class="ij ik l"/></div></figure><p id="efb5" class="pw-post-body-paragraph il im hi in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji hb bi translated">引用自<a class="ae jj" href="https://www.pyimagesearch.com/faqs/single-faq/how-do-i-reference-or-cite-one-of-your-blog-posts-books-or-courses" rel="noopener ugc nofollow" target="_blank">https://www . pyimagesearch . com/FAQ/single-FAQ/how-do-I-reference-or-cite-one-of-your-blog-posts-books-or-courses</a></p><h1 id="e4d3" class="jk jl hi bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated"><strong class="ak"> 1。简介</strong></h1><p id="7f5f" class="pw-post-body-paragraph il im hi in b io ki iq ir is kj iu iv iw kk iy iz ja kl jc jd je km jg jh ji hb bi translated">随着新冠肺炎确诊病例的持续上升，使用口罩已经成为这些天每个人都应该采取的最重要的安全措施之一。戴口罩会在很大程度上有助于防止病毒传播。疾控中心建议每个人在公共场合外出时戴上布口罩。</p><figure class="ko kp kq kr fd ii er es paragraph-image"><div class="er es kn"><img src="../Images/5482d3e42770495cbbcf5a6a5d44f904.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cu1nBwbFAQ8oZipjPwHPHA.png"/></div></figure><p id="d766" class="pw-post-body-paragraph il im hi in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji hb bi translated">很快，面具将成为我们生活的一部分。公共场所、办公室等。会强制戴口罩。很难人工检查进入公共场所或办公室的每个人是否戴着面具。为了解决这个问题，我们正在创建一个深度学习模型，它可以检测没有戴面具进入的人。</p><h1 id="ad3f" class="jk jl hi bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated"><strong class="ak"> 2。数据集</strong></h1><p id="14f4" class="pw-post-body-paragraph il im hi in b io ki iq ir is kj iu iv iw kk iy iz ja kl jc jd je km jg jh ji hb bi translated">为了创建一个人脸面具分类模型，我们需要两种类型的图像-有面具和没有面具的脸。为此，我们可以找到许多数据集。下面给出了其中的一些。</p><ol class=""><li id="ab92" class="ku kv hi in b io ip is it iw kw ja kx je ky ji kz la lb lc bi translated">https://www.kaggle.com/andrewmvd/face-mask-detection?选择=图像</li><li id="d5fb" class="ku kv hi in b io ld is le iw lf ja lg je lh ji kz la lb lc bi translated"><a class="ae jj" href="https://arxiv.org/abs/2003.09093" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2003.09093</a></li></ol><figure class="ko kp kq kr fd ii er es paragraph-image"><div class="er es li"><img src="../Images/3f267a9f0be72312cbc7d52238ab91e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1030/format:webp/1*OhgliySQaUptNv8FNDQf-g.png"/></div><figcaption class="lj lk et er es ll lm bd b be z dx translated">带遮罩的数据集图像</figcaption></figure><figure class="ko kp kq kr fd ii er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es ln"><img src="../Images/ad137626f4ed11898cd916ebe2cbd65b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1102/format:webp/1*LtqKuRLCaz9inqYWjLNLhg.png"/></div></div><figcaption class="lj lk et er es ll lm bd b be z dx translated">我们的数据集图像没有遮罩</figcaption></figure><h1 id="550c" class="jk jl hi bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated"><strong class="ak"> 3。导入必要的库</strong></h1><p id="7e60" class="pw-post-body-paragraph il im hi in b io ki iq ir is kj iu iv iw kk iy iz ja kl jc jd je km jg jh ji hb bi translated">现在让我们导入我们想要的库。我们可以使用keras，tensorflow，matplotlib，umpy等..</p><pre class="ko kp kq kr fd ls lt lu lv aw lw bi"><span id="1002" class="lx jl hi lt b fi ly lz l ma mb"># import the necessary packages<br/>from tensorflow.keras.preprocessing.image import ImageDataGenerator<br/>from tensorflow.keras.applications import MobileNetV2<br/>from tensorflow.keras.layers import AveragePooling2D<br/>from tensorflow.keras.layers import Dropout<br/>from tensorflow.keras.layers import Flatten<br/>from tensorflow.keras.layers import Dense<br/>from tensorflow.keras.layers import Input<br/>from tensorflow.keras.models import Model<br/>from tensorflow.keras.optimizers import Adam<br/>from tensorflow.keras.applications.mobilenet_v2 import preprocess_input<br/>from tensorflow.keras.preprocessing.image import img_to_array<br/>from tensorflow.keras.preprocessing.image import load_img<br/>from tensorflow.keras.utils import to_categorical<br/>from sklearn.preprocessing import LabelBinarizer<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.metrics import classification_report<br/>from imutils import paths<br/>import matplotlib.pyplot as plt<br/>import numpy as np<br/>import os</span></pre><h1 id="383e" class="jk jl hi bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated"><strong class="ak"> 4。获取数据集</strong></h1><p id="9b0e" class="pw-post-body-paragraph il im hi in b io ki iq ir is kj iu iv iw kk iy iz ja kl jc jd je km jg jh ji hb bi translated">下载上面提到的数据集并提供目录，这样我们就可以在我们的程序中使用它们。主要有两类一类带口罩，一类不带口罩。我们需要首先将图像转换成数组。每个图像被转换成统一的尺寸224、224。这些数组中的每一个都存储为数据(列表),标签存储在标签(列表)下</p><pre class="ko kp kq kr fd ls lt lu lv aw lw bi"><span id="5e23" class="lx jl hi lt b fi ly lz l ma mb">DIRECTORY = r"C:\Users\jerry\project works ML\article to publish\face mask detetcion\dataset"<br/>CATEGORIES = ["with_mask", "without_mask"]</span><span id="7eaf" class="lx jl hi lt b fi mc lz l ma mb"># grab the list of images in our dataset directory, then initialize<br/># the list of data (i.e., images) and class images<br/>print("[INFO] loading images...")</span><span id="7ba1" class="lx jl hi lt b fi mc lz l ma mb">data = []<br/>labels = []</span><span id="4725" class="lx jl hi lt b fi mc lz l ma mb">for category in CATEGORIES:<br/>    path = os.path.join(DIRECTORY, category)<br/>    for img in os.listdir(path):<br/>     img_path = os.path.join(path, img)<br/>     image = load_img(img_path, target_size=(224, 224))<br/>     image = img_to_array(image)<br/>     image = preprocess_input(image)</span><span id="db64" class="lx jl hi lt b fi mc lz l ma mb">data.append(image)<br/>     labels.append(category)</span></pre><h1 id="52b6" class="jk jl hi bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated"><strong class="ak"> 5。对标签执行一键编码</strong></h1><p id="3a9f" class="pw-post-body-paragraph il im hi in b io ki iq ir is kj iu iv iw kk iy iz ja kl jc jd je km jg jh ji hb bi translated">正如我们在上面看到的，标签是字符串格式的，我们需要将其转换为整数格式，因为我们的模型不接受字符串格式。为此，我们使用一个热编码器(例如，如果我们有两个标签YES和NO，它可以转换为0和1)。</p><pre class="ko kp kq kr fd ls lt lu lv aw lw bi"><span id="5144" class="lx jl hi lt b fi ly lz l ma mb"># perform one-hot encoding on the labels<br/>lb = LabelBinarizer()<br/>labels = lb.fit_transform(labels)<br/>labels = to_categorical(labels)</span><span id="5ebd" class="lx jl hi lt b fi mc lz l ma mb">data = np.array(data, dtype="float32")<br/>labels = np.array(labels)</span></pre><h1 id="8335" class="jk jl hi bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated"><strong class="ak"> 6。列车试运行</strong></h1><p id="1dbc" class="pw-post-body-paragraph il im hi in b io ki iq ir is kj iu iv iw kk iy iz ja kl jc jd je km jg jh ji hb bi translated">现在我们需要分割数据集，这样我们就可以有一个新的数据集来测试我们的模型性能。这里，我们将80%的数据用于训练目的，另外20%用于测试目的。</p><pre class="ko kp kq kr fd ls lt lu lv aw lw bi"><span id="5813" class="lx jl hi lt b fi ly lz l ma mb">(trainX, testX, trainY, testY) = train_test_split(data, labels,<br/> test_size=0.20, stratify=labels, random_state=5)</span></pre><p id="fa3a" class="pw-post-body-paragraph il im hi in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji hb bi translated">我们还使用“图像数据生成器”。图像数据生成器是keras提供的一个功能，用来增加我们必须训练的数据数量。在许多情况下，数据很少被训练。随着数据量的增加，准确度也随之提高。它通过添加各种属性，如翻转、旋转等，从一个图像创建许多图像..代码中给出了许多可以更改的属性。大部分都设置为默认。</p><pre class="ko kp kq kr fd ls lt lu lv aw lw bi"><span id="3e14" class="lx jl hi lt b fi ly lz l ma mb"># construct the training image generator for data augmentation<br/>aug = ImageDataGenerator(<br/> rotation_range=20,<br/> zoom_range=0.15,<br/> width_shift_range=0.2,<br/> height_shift_range=0.2,<br/> shear_range=0.15,<br/> horizontal_flip=True,<br/> fill_mode="nearest")</span></pre><h1 id="8657" class="jk jl hi bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">7 .<strong class="ak">。模型创建</strong></h1><p id="f71d" class="pw-post-body-paragraph il im hi in b io ki iq ir is kj iu iv iw kk iy iz ja kl jc jd je km jg jh ji hb bi translated">有一些预先训练好的图像模型，所以当我们使用“imagenet”时，这些权重将被初始化，这将给出一个更好的结果。输入张量是通过的图像的形状。</p><p id="ab36" class="pw-post-body-paragraph il im hi in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji hb bi translated">我们还初始化初始学习率、训练的时期数和批量大小。</p><blockquote class="md me mf"><p id="daf3" class="il im mg in b io ip iq ir is it iu iv mh ix iy iz mi jb jc jd mj jf jg jh ji hb bi translated">我们<em class="hi">把我们的输出模型作为密集的(2，activation="softmax ")。2是因为我们有两个带面具和不带面具的班级。输出层中使用的激活函数是softmax(二元分类)。</em></p></blockquote><pre class="ko kp kq kr fd ls lt lu lv aw lw bi"><span id="801e" class="lx jl hi lt b fi ly lz l ma mb"># initialize the initial learning rate, number of epochs to train for,<br/># and batch size<br/>INIT_LR = 1e-4<br/>EPOCHS = 20<br/>BS = 32</span><span id="6452" class="lx jl hi lt b fi mc lz l ma mb"><br/># load the MobileNetV2 network, ensuring the head FC layer sets are<br/># left off<br/>baseModel = MobileNetV2(weights="imagenet", include_top=False,<br/> input_tensor=Input(shape=(224, 224, 3)))</span><span id="39e8" class="lx jl hi lt b fi mc lz l ma mb"># construct the head of the model that will be placed on top of the<br/># the base model<br/>headModel = baseModel.output<br/>headModel = AveragePooling2D(pool_size=(7, 7))(headModel)<br/>headModel = Flatten(name="flatten")(headModel)<br/>headModel = Dense(128, activation="relu")(headModel)<br/>headModel = Dropout(0.5)(headModel)<br/>headModel = Dense(2, activation="softmax")(headModel)</span><span id="bfdc" class="lx jl hi lt b fi mc lz l ma mb"># place the head FC model on top of the base model (this will become<br/># the actual model we will train)<br/>model = Model(inputs=baseModel.input, outputs=headModel)</span><span id="e9f1" class="lx jl hi lt b fi mc lz l ma mb"># loop over all layers in the base model and freeze them so they will<br/># *not* be updated during the first training process<br/>for layer in baseModel.layers:<br/> layer.trainable = False</span><span id="ba3b" class="lx jl hi lt b fi mc lz l ma mb"># compile our model<br/>print("[INFO] compiling model...")<br/>opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)<br/>model.compile(loss="binary_crossentropy", optimizer=opt,<br/> metrics=["accuracy"])</span><span id="c42f" class="lx jl hi lt b fi mc lz l ma mb"># train the head of the network<br/>print("[INFO] training head...")<br/>H = model.fit(<br/> aug.flow(trainX, trainY, batch_size=BS),<br/> steps_per_epoch=len(trainX) // BS,<br/> validation_data=(testX, testY),<br/> validation_steps=len(testX) // BS,<br/> epochs=EPOCHS)</span><span id="3d21" class="lx jl hi lt b fi mc lz l ma mb"># make predictions on the testing set<br/>print("[INFO] evaluating network...")<br/>predIdxs = model.predict(testX, batch_size=BS)</span><span id="804a" class="lx jl hi lt b fi mc lz l ma mb"># for each image in the testing set we need to find the index of the<br/># label with corresponding largest predicted probability<br/>predIdxs = np.argmax(predIdxs, axis=1)</span><span id="4b84" class="lx jl hi lt b fi mc lz l ma mb"># show a nicely formatted classification report<br/>print(classification_report(testY.argmax(axis=1), predIdxs,<br/> target_names=lb.classes_))</span><span id="1a80" class="lx jl hi lt b fi mc lz l ma mb"># serialize the model to disk<br/>print("[INFO] saving mask detector model...")<br/>model.save("mask_detector.model", save_format="h5")</span></pre><p id="ee65" class="pw-post-body-paragraph il im hi in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji hb bi translated">最后将我们的模型保存为mask_detector.model，以h5格式保存。我们将在以后使用这个模型。</p><h1 id="9d05" class="jk jl hi bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated"><strong class="ak"> 8。训练损失和准确性</strong></h1><p id="316f" class="pw-post-body-paragraph il im hi in b io ki iq ir is kj iu iv iw kk iy iz ja kl jc jd je km jg jh ji hb bi translated">我们使用matplotlib来绘制训练损失、val_loss、train_acc、val_accuracy。</p><pre class="ko kp kq kr fd ls lt lu lv aw lw bi"><span id="0cee" class="lx jl hi lt b fi ly lz l ma mb"># plot the training loss and accuracy<br/>N = EPOCHS<br/>plt.style.use("ggplot")<br/>plt.figure()<br/>plt.plot(np.arange(0, N), H.history["loss"], label="train_loss")<br/>plt.plot(np.arange(0, N), H.history["val_loss"], label="val_loss")<br/>plt.plot(np.arange(0, N), H.history["accuracy"], label="train_acc")<br/>plt.plot(np.arange(0, N), H.history["val_accuracy"], label="val_acc")<br/>plt.title("Training Loss and Accuracy")<br/>plt.xlabel("Epoch #")<br/>plt.ylabel("Loss/Accuracy")<br/>plt.legend(loc="lower left")<br/>plt.savefig("plot.png")</span></pre><figure class="ko kp kq kr fd ii er es paragraph-image"><div class="er es mk"><img src="../Images/5c02eedd4b946ecaba71b269789758fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*UCvTQD3152uxpinPJKvO0g.png"/></div></figure><h1 id="b797" class="jk jl hi bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated"><strong class="ak"> 9。结论</strong></h1><p id="b0d8" class="pw-post-body-paragraph il im hi in b io ki iq ir is kj iu iv iw kk iy iz ja kl jc jd je km jg jh ji hb bi translated">在这篇文章中，我们学习了如何建立一个面具检测模型。现在我们可以在实时应用程序中使用这个模型。在这里，我们使用OpenCV在我们的网络摄像头中实现该模型，该项目可以与嵌入式系统集成，应用于学校、机场、火车站、办公室和公共场所，以确保遵守公共安全准则。</p><p id="3305" class="pw-post-body-paragraph il im hi in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji hb bi translated">实现这个模型的程序是<a class="ae jj" rel="noopener" href="/@jerryjohn1995/face-mask-detection-system-using-artificial-intelligence-52afd27b0a4e">这里是</a>。</p><p id="dc01" class="pw-post-body-paragraph il im hi in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji hb bi translated">因为<strong class="in hj">没有</strong>是完美的，如果任何人发现任何错误或建议，请随时在下面评论。</p><p id="f527" class="pw-post-body-paragraph il im hi in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji hb bi translated">电子邮件Id:jerryjohn1995@gmail.com</p><p id="1202" class="pw-post-body-paragraph il im hi in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji hb bi translated">insta gram:https://www.instagram.com/jerry_john_7/?hl=en<a class="ae jj" href="https://www.instagram.com/jerry_john_7/?hl=en" rel="noopener ugc nofollow" target="_blank"/></p><p id="a06f" class="pw-post-body-paragraph il im hi in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji hb bi translated">LinkedIn:linkedin.com/in/jerryjohn1995</p><p id="35cb" class="pw-post-body-paragraph il im hi in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji hb bi translated">脸书:<a class="ae jj" href="https://www.facebook.com/jerry.john.583234/" rel="noopener ugc nofollow" target="_blank">https://www.facebook.com/jerry.john.583234/</a></p></div></div>    
</body>
</html>