<html>
<head>
<title>Installation guide of TensorRT for YOLOv3</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">yolo v3 tensort安装指南</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/installation-guide-of-tensorrt-for-yolov3-58a89eb984f?source=collection_archive---------6-----------------------#2019-12-05">https://medium.com/analytics-vidhya/installation-guide-of-tensorrt-for-yolov3-58a89eb984f?source=collection_archive---------6-----------------------#2019-12-05</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/defabe3a2c352c698ffcc19c1212bb13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1074/format:webp/1*4-PvNFH9_i9XxazYmn4cGA.png"/></div></figure><p id="ce67" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">免责声明:</strong>这是我使用TensorRT，将yolov3权重转换为TensorRT文件的体验。本文包括TensorRT(5.0)某个版本的步骤和面临的错误，因此使用其他版本的过程可能会有所不同。</p></div><div class="ab cl jk jl gp jm" role="separator"><span class="jn bw bk jo jp jq"/><span class="jn bw bk jo jp jq"/><span class="jn bw bk jo jp"/></div><div class="hb hc hd he hf"><p id="0980" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">既然您在这里，我希望可以安全地假设您已经使用Yolov3构建了一个很棒的对象检测模型，并希望将其投入生产。</p><p id="6c1d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在，您希望让您的模型更好地用于推理——也许尝试减少延迟并增加吞吐量。如果您使用嵌入式计算板，例如Nvidia Jetson板，这一步就变得至关重要。</p><p id="1d42" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">NVIDIA TensorRT是一个很好的选择。从他们的<a class="ae jr" href="https://developer.nvidia.com/tensorrt" rel="noopener ugc nofollow" target="_blank">网站</a>，</p><blockquote class="js jt ju"><p id="f92b" class="im in jv io b ip iq ir is it iu iv iw jw iy iz ja jx jc jd je jy jg jh ji jj hb bi translated">NVIDIA TensorRT是一个高性能深度学习推理平台。它包括一个深度学习推理优化器和运行时，为深度学习推理应用程序提供低延迟和高吞吐量。在推理过程中，基于TensorRT的应用程序的执行速度比纯CPU平台快40倍。</p></blockquote><p id="0f6a" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">许多描述TensorRT及其优点的文章已经存在，所以我想在这里分享安装和程序，因为我花了很多时间才弄明白，所以我希望这篇文章可以帮助别人。</p><p id="9006" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这些是我的系统的规格:</p><ul class=""><li id="4d99" class="jz ka hi io b ip iq it iu ix kb jb kc jf kd jj ke kf kg kh bi translated">GPU: GTX 1080</li><li id="104a" class="jz ka hi io b ip ki it kj ix kk jb kl jf km jj ke kf kg kh bi translated">TensorRT版本:5.0</li><li id="0275" class="jz ka hi io b ip ki it kj ix kk jb kl jf km jj ke kf kg kh bi translated">CUDA: 9.0</li><li id="05e5" class="jz ka hi io b ip ki it kj ix kk jb kl jf km jj ke kf kg kh bi translated">Ubuntu 16.04</li></ul></div><div class="ab cl jk jl gp jm" role="separator"><span class="jn bw bk jo jp jq"/><span class="jn bw bk jo jp jq"/><span class="jn bw bk jo jp"/></div><div class="hb hc hd he hf"><p id="2d9d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">让我们开始吧。</p><p id="bbf8" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我们的目标是将<em class="jv"> yolov3.weights </em>转换为<em class="jv"> yolov3.trt </em>。我们将通过将其分解为以下内容来实现:</p><blockquote class="kn"><p id="790e" class="ko kp hi bd kq kr ks kt ku kv kw jj dx translated">yolov 3 . weights-&gt; yolo . onnx-&gt; yolov 3 . TRT</p></blockquote><p id="39c7" class="pw-post-body-paragraph im in hi io b ip kx ir is it ky iv iw ix kz iz ja jb la jd je jf lb jh ji jj hb bi translated">因此，我们的步骤将遵循相同的流程:</p><ul class=""><li id="bc43" class="jz ka hi io b ip iq it iu ix kb jb kc jf kd jj ke kf kg kh bi translated">TensorRT装置</li><li id="3174" class="jz ka hi io b ip ki it kj ix kk jb kl jf km jj ke kf kg kh bi translated">Yolov3至Onnx转换</li><li id="fdcf" class="jz ka hi io b ip ki it kj ix kk jb kl jf km jj ke kf kg kh bi translated">onnx-tensorrt安装和转换</li></ul></div><div class="ab cl jk jl gp jm" role="separator"><span class="jn bw bk jo jp jq"/><span class="jn bw bk jo jp jq"/><span class="jn bw bk jo jp"/></div><div class="hb hc hd he hf"><h1 id="e1cf" class="lc ld hi bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated"><strong class="ak">tensort安装</strong></h1><ol class=""><li id="01cb" class="jz ka hi io b ip ma it mb ix mc jb md jf me jj mf kf kg kh bi translated">从这个<a class="ae jr" href="https://developer.nvidia.com/nvidia-tensorrt-5x-download" rel="noopener ugc nofollow" target="_blank">链接</a>下载TensorRT tar文件版本5.0.2.6。您需要成为NVIDIA开发者计划的成员。登录后，同意他们的条款并在<strong class="io hj"> TensorRT 5.0 GA </strong>中选择合适版本的tar包。</li><li id="ba81" class="jz ka hi io b ip ki it kj ix kk jb kl jf km jj mf kf kg kh bi translated">遵循此<a class="ae jr" href="https://developer.download.nvidia.com/compute/machine-learning/tensorrt/docs/5.0/GA_5.0.2.6/TensorRT-Installation-Guide.pdf" rel="noopener ugc nofollow" target="_blank"> pdf </a>中的tar文件说明。</li><li id="16ac" class="jz ka hi io b ip ki it kj ix kk jb kl jf km jj mf kf kg kh bi translated"><strong class="io hj">重要</strong>:提供该命令中<em class="jv">tensort-5 . 0 . 2 . 6</em>的绝对路径</li></ol><pre class="mg mh mi mj fd mk ml mm mn aw mo bi"><span id="2008" class="mp ld hi ml b fi mq mr l ms mt">$export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/path/to/folder/TensorRT-5.0.2.6/lib</span></pre><p id="8f58" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">4.安装后，转到<em class="jv">TensorRT-5 . 0 . 2 . 6/sample</em>并运行</p><pre class="mg mh mi mj fd mk ml mm mn aw mo bi"><span id="e18f" class="mp ld hi ml b fi mq mr l ms mt">$make -j8</span></pre><p id="5be7" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">5.上述命令将在<em class="jv"> TensorRT-5.0.2.6/bin </em>文件夹中创建一些文件。</p><p id="319c" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">6.在命令下运行。</p><pre class="mg mh mi mj fd mk ml mm mn aw mo bi"><span id="5b02" class="mp ld hi ml b fi mq mr l ms mt">$./sample_mnist</span></pre><p id="ecd9" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">7.您的输出应该如下所示:</p><pre class="mg mh mi mj fd mk ml mm mn aw mo bi"><span id="af16" class="mp ld hi ml b fi mq mr l ms mt">[I] Building and running a GPU inference engine for MNIST<br/>[I] Input:<br/>@@@@@@@@@@@@@@@@@@@@@@@@@@@@<br/>@@@@@@@@@@@@@@@@@@@@@@@@@@@@<br/>@@@@@@@@@@@@@@@@@@@@@@@@@@@@<br/>@@@@@@@@@@@@@@@@@@@@@@@@@@@@<br/>@@@@@@@@#-:.-=@@@@@@@@@@@@@@<br/>@@@@@%=     . *@@@@@@@@@@@@@<br/>@@@@% .:+%%%  *@@@@@@@@@@@@@<br/>@@@@+=#@@@@@# @@@@@@@@@@@@@@<br/>@@@@@@@@@@@%  @@@@@@@@@@@@@@<br/>@@@@@@@@@@@: *@@@@@@@@@@@@@@<br/>@@@@@@@@@@- .@@@@@@@@@@@@@@@<br/>@@@@@@@@@:  #@@@@@@@@@@@@@@@<br/>@@@@@@@@:   +*%#@@@@@@@@@@@@<br/>@@@@@@@%         :+*@@@@@@@@<br/>@@@@@@@@#*+--.::     +@@@@@@<br/>@@@@@@@@@@@@@@@@#=:.  +@@@@@<br/>@@@@@@@@@@@@@@@@@@@@  .@@@@@<br/>@@@@@@@@@@@@@@@@@@@@#. #@@@@<br/>@@@@@@@@@@@@@@@@@@@@#  @@@@@<br/>@@@@@@@@@%@@@@@@@@@@- +@@@@@<br/>@@@@@@@@#-@@@@@@@@*. =@@@@@@<br/>@@@@@@@@ .+%%%%+=.  =@@@@@@@<br/>@@@@@@@@           =@@@@@@@@<br/>@@@@@@@@*=:   :--*@@@@@@@@@@<br/>@@@@@@@@@@@@@@@@@@@@@@@@@@@@<br/>@@@@@@@@@@@@@@@@@@@@@@@@@@@@<br/>@@@@@@@@@@@@@@@@@@@@@@@@@@@@<br/>@@@@@@@@@@@@@@@@@@@@@@@@@@@@<br/><br/>[I] Output:<br/>0:<br/>1:<br/>2:<br/>3: **********<br/>4:<br/>5:<br/>6:<br/>7:<br/>8:<br/>9:</span></pre><p id="7a5d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">8.在终端上，运行python3，然后尝试:</p><pre class="mg mh mi mj fd mk ml mm mn aw mo bi"><span id="6f75" class="mp ld hi ml b fi mq mr l ms mt">import tensorrt</span></pre><p id="8b95" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">如果它没有给出错误，那么tensorrt安装完成。</p><blockquote class="js jt ju"><p id="aeda" class="im in jv io b ip iq ir is it iu iv iw jw iy iz ja jx jc jd je jy jg jh ji jj hb bi translated"><strong class="io hj">可能出现的问题</strong>(以后可能会出现几次):</p><p id="fc6e" class="im in jv io b ip iq ir is it iu iv iw jw iy iz ja jx jc jd je jy jg jh ji jj hb bi translated">ImportError: libnvinfer.so.5:无法打开共享对象文件:没有这样的文件或目录</p><p id="be0c" class="im in jv io b ip iq ir is it iu iv iw jw iy iz ja jx jc jd je jy jg jh ji jj hb bi translated"><strong class="io hj">解决方案:</strong></p><p id="b03a" class="im in jv io b ip iq ir is it iu iv iw jw iy iz ja jx jc jd je jy jg jh ji jj hb bi translated">$ export LD _ LIBRARY _ PATH = $ LD _ LIBRARY _ PATH:/home/PATH/to/folder/TensorRT-5 . 0 . 2 . 6/lib</p></blockquote><p id="bd27" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">希望TensorRT安装成功并正常工作。</p></div><div class="ab cl jk jl gp jm" role="separator"><span class="jn bw bk jo jp jq"/><span class="jn bw bk jo jp jq"/><span class="jn bw bk jo jp"/></div><div class="hb hc hd he hf"><h1 id="319d" class="lc ld hi bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated">Yolov3至Onnx转换</h1><ol class=""><li id="e1ec" class="jz ka hi io b ip ma it mb ix mc jb md jf me jj mf kf kg kh bi translated">转到文件夹:<em class="jv">TensorRT-5 . 0 . 2 . 6/samples/python/yolo v3 _ onnx</em></li><li id="debb" class="jz ka hi io b ip ki it kj ix kk jb kl jf km jj mf kf kg kh bi translated">在python2和3上都安装onnx==1.2.2。(否则用onnx==1.4.1尝试)</li><li id="59bd" class="jz ka hi io b ip ki it kj ix kk jb kl jf km jj mf kf kg kh bi translated">使用python2运行</li></ol><pre class="mg mh mi mj fd mk ml mm mn aw mo bi"><span id="0b74" class="mp ld hi ml b fi mq mr l ms mt">$python yolov3_to_onnx.py</span></pre><p id="b5b0" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">它将下载<em class="jv"> yolov3.weights </em>并在成功运行后输出<em class="jv"> yolov3.onnx </em>。您可以根据自己的需要修改<em class="jv"> yolov3_to_onnx.py </em>文件。</p></div><div class="ab cl jk jl gp jm" role="separator"><span class="jn bw bk jo jp jq"/><span class="jn bw bk jo jp jq"/><span class="jn bw bk jo jp"/></div><div class="hb hc hd he hf"><h1 id="db23" class="lc ld hi bd le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz bi translated"><strong class="ak"> Onnx到TensorRT的安装和转换</strong></h1><ul class=""><li id="2d80" class="jz ka hi io b ip ma it mb ix mc jb md jf me jj ke kf kg kh bi translated">我在onnx-tensorrt转换时遇到了protobuf问题，文件在<em class="jv">tensor rt-5 . 0 . 2 . 6/samples/python/yolo v3 _ onnx中给出。</em></li><li id="bc12" class="jz ka hi io b ip ki it kj ix kk jb kl jf km jj ke kf kg kh bi translated">所以我选择了另一种方式，尝试了这个存储库。对于我的TensorRT版本，我使用的是v5.0 branch。</li><li id="c937" class="jz ka hi io b ip ki it kj ix kk jb kl jf km jj ke kf kg kh bi translated">我主要是按照他们<a class="ae jr" href="https://github.com/onnx/onnx-tensorrt/tree/v5.0" rel="noopener ugc nofollow" target="_blank"> github </a>和<a class="ae jr" href="https://devtalk.nvidia.com/default/topic/1060735/jetson-nano/how-to-install-onnx-tensorrt-and-how-to-solve-can-not-find-quot-dirver_types-h-quot-error/" rel="noopener ugc nofollow" target="_blank">这里</a>的指示。</li></ul><pre class="mg mh mi mj fd mk ml mm mn aw mo bi"><span id="c239" class="mp ld hi ml b fi mq mr l ms mt">$ git clone — recursive <a class="ae jr" href="https://github.com/onnx/onnx-tensorrt.git" rel="noopener ugc nofollow" target="_blank">https://github.com/onnx/onnx-tensorrt.gi</a>t<br/>$ cd onnx-tensorrt<br/>$ git checkout v5.0<br/>$ mkdir build<br/>$ cd build<br/>$ cmake .. -DCUDA_INCLUDE_DIRS=/usr/local/cuda/include -DTENSORRT_ROOT=/home/agnext/Documents/TensorRT-5.0.2.6 -DGPU_ARCHS="61"</span></pre><blockquote class="js jt ju"><p id="3c32" class="im in jv io b ip iq ir is it iu iv iw jw iy iz ja jx jc jd je jy jg jh ji jj hb bi translated"><strong class="io hj">可能的问题:</strong> onnx不包含CMakeLists.txt文件</p><p id="55d4" class="im in jv io b ip iq ir is it iu iv iw jw iy iz ja jx jc jd je jy jg jh ji jj hb bi translated"><strong class="io hj">解决:</strong>T24】https://github.com/NVIDIA/TensorRT/issues/17</p><p id="2fb4" class="im in jv io b ip iq ir is it iu iv iw jw iy iz ja jx jc jd je jy jg jh ji jj hb bi translated"><strong class="io hj">可能的问题</strong>:找不到Protobuf编译器</p><p id="47a2" class="im in jv io b ip iq ir is it iu iv iw jw iy iz ja jx jc jd je jy jg jh ji jj hb bi translated"><strong class="io hj">解决方案:</strong> sudo apt-get安装protobuf-compiler</p></blockquote><p id="eb72" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">继续执行以下命令:</p><pre class="mg mh mi mj fd mk ml mm mn aw mo bi"><span id="1d39" class="mp ld hi ml b fi mq mr l ms mt">$ make -j8<br/>$ sudo make install<br/>$ cd ..<br/>$ sudo python3 setup.py install</span></pre><blockquote class="js jt ju"><p id="4a12" class="im in jv io b ip iq ir is it iu iv iw jw iy iz ja jx jc jd je jy jg jh ji jj hb bi translated"><strong class="io hj">可能的问题</strong>:无法执行“swig”:没有这样的文件或目录</p><p id="7017" class="im in jv io b ip iq ir is it iu iv iw jw iy iz ja jx jc jd je jy jg jh ji jj hb bi translated"><a class="ae jr" href="https://github.com/certbot/certbot/issues/34#issuecomment-63769817" rel="noopener ugc nofollow" target="_blank"> <strong class="io hj">解决方案</strong> </a> : sudo apt-get安装swig</p><p id="d491" class="im in jv io b ip iq ir is it iu iv iw jw iy iz ja jx jc jd je jy jg jh ji jj hb bi translated"><strong class="io hj">可能的问题:</strong> NvOnnxParser.h:26:21:致命错误:NvInfer.h:没有这样的文件或目录</p><p id="c89b" class="im in jv io b ip iq ir is it iu iv iw jw iy iz ja jx jc jd je jy jg jh ji jj hb bi translated"><a class="ae jr" href="https://github.com/onnx/onnx-tensorrt/issues/59" rel="noopener ugc nofollow" target="_blank"> <strong class="io hj">解</strong> </a> <strong class="io hj"> : </strong></p><p id="191c" class="im in jv io b ip iq ir is it iu iv iw jw iy iz ja jx jc jd je jy jg jh ji jj hb bi translated">1.在TensorRTx.x.x.x/include中找到NvInfer.h</p><p id="c581" class="im in jv io b ip iq ir is it iu iv iw jw iy iz ja jx jc jd je jy jg jh ji jj hb bi translated">2.在onnx-tensorrt中，在setup.py内部，</p><p id="b809" class="im in jv io b ip iq ir is it iu iv iw jw iy iz ja jx jc jd je jy jg jh ji jj hb bi translated">INC _ DIRS =["/path/to/file/TensorRT-5 . 0 . 2 . 6/include "]</p><p id="901c" class="im in jv io b ip iq ir is it iu iv iw jw iy iz ja jx jc jd je jy jg jh ji jj hb bi translated"><strong class="io hj">问题:</strong> x86_64-linux-gnu-g++:错误:build/libnvonnxparser.so:没有这样的文件或目录</p><p id="dfa1" class="im in jv io b ip iq ir is it iu iv iw jw iy iz ja jx jc jd je jy jg jh ji jj hb bi translated"><strong class="io hj">解决:</strong> <a class="ae jr" href="https://github.com/onnx/onnx-tensorrt/issues/126#issuecomment-537892082" rel="noopener ugc nofollow" target="_blank">链接</a></p><p id="3f41" class="im in jv io b ip iq ir is it iu iv iw jw iy iz ja jx jc jd je jy jg jh ji jj hb bi translated">对<em class="hi">libnvonnxparser _ runtime . so</em>做同样的事情</p></blockquote><ul class=""><li id="fbd1" class="jz ka hi io b ip iq it iu ix kb jb kc jf kd jj ke kf kg kh bi translated">运行这个来检查安装是否顺利。</li></ul><pre class="mg mh mi mj fd mk ml mm mn aw mo bi"><span id="6441" class="mp ld hi ml b fi mq mr l ms mt">$ onnx2trt -h</span></pre><ul class=""><li id="3bb7" class="jz ka hi io b ip iq it iu ix kb jb kc jf kd jj ke kf kg kh bi translated">最后，将onnx文件转换为tensorrt。</li></ul><pre class="mg mh mi mj fd mk ml mm mn aw mo bi"><span id="8e08" class="mp ld hi ml b fi mq mr l ms mt">$ onnx2trt yolov3.onnx -o yolov3.trt</span></pre><p id="3380" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">你会在文件夹中看到一个文件<em class="jv"> yolov3.trt。</em></p></div><div class="ab cl jk jl gp jm" role="separator"><span class="jn bw bk jo jp jq"/><span class="jn bw bk jo jp jq"/><span class="jn bw bk jo jp"/></div><div class="hb hc hd he hf"><p id="54a1" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我希望我能节省你的一些时间。感谢阅读。</p><p id="6121" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi">:)</p></div></div>    
</body>
</html>