<html>
<head>
<title>K-means Clustering — Everything you need to know</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">k-均值聚类—您需要知道的一切</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/k-means-clustering-everything-you-need-to-know-175dd01766d5?source=collection_archive---------10-----------------------#2020-01-26">https://medium.com/analytics-vidhya/k-means-clustering-everything-you-need-to-know-175dd01766d5?source=collection_archive---------10-----------------------#2020-01-26</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="c4fd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当我学习K-means聚类时，我必须通过几个博客和视频来收集我想知道的关于K-means聚类的所有信息。本教程只是试图在一个博客中包含从各种来源学到的所有概念。</p><h1 id="f11a" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">能够满足</h1><ol class=""><li id="e8c1" class="kj kk hi ih b ii kl im km iq kn iu ko iy kp jc kq kr ks kt bi translated"><a class="ae ku" href="#5ac5" rel="noopener ugc nofollow">什么是K均值聚类？</a></li><li id="3132" class="kj kk hi ih b ii kv im kw iq kx iu ky iy kz jc kq kr ks kt bi translated"><a class="ae ku" href="#0729" rel="noopener ugc nofollow">我们的目标？</a></li><li id="eb1f" class="kj kk hi ih b ii kv im kw iq kx iu ky iy kz jc kq kr ks kt bi translated">这个算法是如何工作的？</li><li id="e69f" class="kj kk hi ih b ii kv im kw iq kx iu ky iy kz jc kq kr ks kt bi translated"><a class="ae ku" href="http://@aebc" rel="noopener ugc nofollow" target="_blank">如何随机初始化质心？</a> <br/> <a class="ae ku" href="#2df0" rel="noopener ugc nofollow"> *随机初始化</a> <br/> <a class="ae ku" href="#6cdd" rel="noopener ugc nofollow"> * K-means ++ </a></li><li id="5245" class="kj kk hi ih b ii kv im kw iq kx iu ky iy kz jc kq kr ks kt bi translated"><a class="ae ku" href="#2ce7" rel="noopener ugc nofollow">如何优化？</a></li><li id="4f70" class="kj kk hi ih b ii kv im kw iq kx iu ky iy kz jc kq kr ks kt bi translated"><a class="ae ku" href="#e39f" rel="noopener ugc nofollow">聚类的评价指标？</a></li><li id="d0a8" class="kj kk hi ih b ii kv im kw iq kx iu ky iy kz jc kq kr ks kt bi translated"><a class="ae ku" href="#9f9c" rel="noopener ugc nofollow">聚类的停止标准？</a></li><li id="23b5" class="kj kk hi ih b ii kv im kw iq kx iu ky iy kz jc kq kr ks kt bi translated"><a class="ae ku" href="#f6a0" rel="noopener ugc nofollow">K均值的假设</a></li><li id="1e04" class="kj kk hi ih b ii kv im kw iq kx iu ky iy kz jc kq kr ks kt bi translated"><a class="ae ku" href="#d62a" rel="noopener ugc nofollow">K-means的挑战</a></li><li id="a67b" class="kj kk hi ih b ii kv im kw iq kx iu ky iy kz jc kq kr ks kt bi translated"><a class="ae ku" href="#26fc" rel="noopener ugc nofollow">需要处理的数据问题？</a></li><li id="1fee" class="kj kk hi ih b ii kv im kw iq kx iu ky iy kz jc kq kr ks kt bi translated"><a class="ae ku" href="#8f14" rel="noopener ugc nofollow">K均值的应用</a></li><li id="6cd8" class="kj kk hi ih b ii kv im kw iq kx iu ky iy kz jc kq kr ks kt bi translated"><a class="ae ku" href="#4c5d" rel="noopener ugc nofollow">参考文献</a></li></ol><h1 id="3628" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated"><strong class="ak">什么是K均值聚类？</strong></h1><p id="5ac5" class="pw-post-body-paragraph if ig hi ih b ii kl ik il im km io ip iq la is it iu lb iw ix iy lc ja jb jc hb bi translated">这是一种算法，可以帮助我们将相似的数据点分组在一起。这是一个划分问题，所以如果我们有m个数据点，那么我们需要将它们划分成K个簇</p><h1 id="bdb9" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated"><strong class="ak">我们的目标？</strong></h1><p id="0729" class="pw-post-body-paragraph if ig hi ih b ii kl ik il im km io ip iq la is it iu lb iw ix iy lc ja jb jc hb bi translated">我们希望优化我们的算法，以便— <br/> 1。我们希望聚类中的数据点尽可能相似<br/> 2。尽可能保持集群(不相似或不同)</p><h1 id="3051" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated"><strong class="ak">这个算法是怎么工作的？</strong></h1><figure class="le lf lg lh fd li er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es ld"><img src="../Images/24f8829caa3e0ad636db5bd3a3c12ac3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G60MbAnouFWfAF8Vht6Ypg.jpeg"/></div></div></figure><p id="c158" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">输入- <br/> 1。</strong>训练集:x1，x2……，xm <br/> 2。数据集需要的聚类数:K</p><p id="f877" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">伪算法- </strong></p><figure class="le lf lg lh fd li er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es lp"><img src="../Images/f68202b5f6b06653706524da92ca900c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ov7GEb8GoC42Kn6JfS3nrA.jpeg"/></div></div><figcaption class="lq lr et er es ls lt bd b be z dx translated">K-means算法(Andrew NG的课程)</figcaption></figure><h1 id="0150" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated"><strong class="ak">如何随机初始化质心？</strong></h1><p id="aebc" class="pw-post-body-paragraph if ig hi ih b ii kl ik il im km io ip iq la is it iu lb iw ix iy lc ja jb jc hb bi translated">在上述算法中，K均值的两个最重要的考虑因素是—</p><ol class=""><li id="3929" class="kj kk hi ih b ii ij im in iq lu iu lv iy lw jc kq kr ks kt bi translated">如何确定质心的数量？</li><li id="e6fa" class="kj kk hi ih b ii kv im kw iq kx iu ky iy kz jc kq kr ks kt bi translated">如何初始化质心？</li></ol><p id="aa67" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本教程的后面部分，我们将研究如何选择集群数量。</p><ul class=""><li id="2df0" class="kj kk hi ih b ii ij im in iq lu iu lv iy lw jc lx kr ks kt bi translated"><strong class="ih hj">随机初始化- </strong></li></ul><ol class=""><li id="7e54" class="kj kk hi ih b ii ij im in iq lu iu lv iy lw jc kq kr ks kt bi translated">我们可以从我们的训练集中随机选取K个数据点，并初始化这些数据点的质心。</li><li id="4652" class="kj kk hi ih b ii kv im kw iq kx iu ky iy kz jc kq kr ks kt bi translated">随机初始化的问题——每次我们运行我们的算法，我们的初始质心将是不同的。所以K-means可以基于质心的初始化得到不同的解。<strong class="ih hj">(局部最优)</strong></li></ol><ul class=""><li id="6cdd" class="kj kk hi ih b ii ij im in iq lu iu lv iy lw jc lx kr ks kt bi translated"><strong class="ih hj"> K-means ++ </strong></li></ul><p id="e4fb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们在这里只选择了一个随机质心，而不是随机选择所有质心进行初始化。</p><ol class=""><li id="6db8" class="kj kk hi ih b ii ij im in iq lu iu lv iy lw jc kq kr ks kt bi translated">随机选取1个数据点作为初始质心。</li><li id="e505" class="kj kk hi ih b ii kv im kw iq kx iu ky iy kz jc kq kr ks kt bi translated">现在计算每个数据点与质心的距离。</li><li id="862c" class="kj kk hi ih b ii kv im kw iq kx iu ky iy kz jc kq kr ks kt bi translated">下一个质心=距离当前质心最远的距离的平方。</li></ol><figure class="le lf lg lh fd li er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es ly"><img src="../Images/c84213dbe3d240318ecb54d1d271dfaf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T4ZTlTUDPAjPvsODHxon1w.jpeg"/></div></div></figure><blockquote class="lz"><p id="fb15" class="ma mb hi bd mc md me mf mg mh mi jc dx translated">K-means ++比随机初始化开销大</p></blockquote><h1 id="8981" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo mj jq jr js mk ju jv jw ml jy jz ka bi translated"><strong class="ak">如何避免局部最优？还是为了更好的局部最优而优化？</strong></h1><p id="2ce7" class="pw-post-body-paragraph if ig hi ih b ii kl ik il im km io ip iq la is it iu lb iw ix iy lc ja jb jc hb bi translated">在实现K-means算法时，很有可能会陷入局部最优。所以我们的目标是找到最佳的局部最优解。</p><p id="f030" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">多次随机初始化:</strong></p><p id="7e30" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果K = = = small(2–10)<br/><strong class="ih hj">Algo:</strong>，则使用此方法</p><figure class="le lf lg lh fd li er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es mm"><img src="../Images/a7155332f3cc8f27ad480a423a15f224.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OqUPdc5lPDMOTgX7_leGvQ.jpeg"/></div></div><figcaption class="lq lr et er es ls lt bd b be z dx translated">选择给出最低成本函数的质心。</figcaption></figure><h1 id="95b9" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">聚类的评估指标-</h1><blockquote class="mn mo mp"><p id="e39f" class="if ig mq ih b ii ij ik il im in io ip mr ir is it ms iv iw ix mt iz ja jb jc hb bi translated"><strong class="ih hj">惯性——试图形成紧密的集群</strong></p></blockquote><p id="f466" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">它计算聚类中所有点离质心的距离。<br/> <strong class="ih hj"> <em class="mq">惯性越低越好</em> </strong></p><figure class="le lf lg lh fd li er es paragraph-image"><div class="er es mu"><img src="../Images/e68277f28ad4c05eebb5ade56201efaa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1086/format:webp/1*QV2eyVVX3IaQIEsrvJbjEg.jpeg"/></div><figcaption class="lq lr et er es ls lt bd b be z dx translated">分析-Vidhya</figcaption></figure><blockquote class="mn mo mp"><p id="c794" class="if ig mq ih b ii ij ik il im in io ip mr ir is it ms iv iw ix mt iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="hi">邓恩指数</em> </strong> <em class="hi"> —聚类之间的相异度</em></p></blockquote><p id="8f37" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">考虑聚类之间的距离，以便聚类尽可能互不相同。<br/> <strong class="ih hj"> <em class="mq">邓恩指数越高，聚类越好。</em> </strong></p><figure class="le lf lg lh fd li er es paragraph-image"><div class="er es mv"><img src="../Images/2c6461228b272b875cd2858befa078e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1236/format:webp/1*U-tcp_09pfM7kvyhH8L_Zg.jpeg"/></div><figcaption class="lq lr et er es ls lt bd b be z dx translated">分析-Vidhya</figcaption></figure><h1 id="69ab" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated"><strong class="ak">K表示的停止标准</strong></h1><p id="9f9c" class="pw-post-body-paragraph if ig hi ih b ii kl ik il im km io ip iq la is it iu lb iw ix iy lc ja jb jc hb bi translated">1.已达到最大迭代次数。<br/> 2。新形成的星团的质心变化不大。<br/> 3。点保持在同一簇中。</p><h1 id="f6a0" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated"><strong class="ak">K均值的假设</strong></h1><ol class=""><li id="f206" class="kj kk hi ih b ii kl im km iq kn iu ko iy kp jc kq kr ks kt bi translated"><strong class="ih hj">限于球形团簇<br/> </strong>如果你想知道K-means将要形成的团簇，只需想象一个类似球形的形状。当K-means计算距质心的距离时，它形成一个球形。因此，它不能群集复杂的几何形状。<br/> <strong class="ih hj"> <em class="mq">解——内核方法<br/> </em> </strong> <em class="mq">变换到更高维的表示，使数据线性可分。<br/> </em> <strong class="ih hj"> <em class="mq">从sklearn.cluster导入SphericalClustering </em> </strong></li><li id="2b26" class="kj kk hi ih b ii kv im kw iq kx iu ky iy kz jc kq kr ks kt bi translated"><strong class="ih hj">簇的大小<br/> </strong>该算法仅考虑距离，因此不考虑具有不同大小或密度的簇。<em class="mq">它假设一个聚类内的特征具有相等的方差。</em></li></ol><h1 id="d62a" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated"><strong class="ak">K-means的挑战</strong></h1><ol class=""><li id="3e1b" class="kj kk hi ih b ii kl im km iq kn iu ko iy kp jc kq kr ks kt bi translated"><strong class="ih hj">局部最优— <br/> </strong>聚类数增加局部最优。因此，我们的集群依赖于质心初始化</li><li id="270e" class="kj kk hi ih b ii kv im kw iq kx iu ky iy kz jc kq kr ks kt bi translated"><strong class="ih hj"> K- <br/> </strong>无法从数据中学习聚类数。</li><li id="70c0" class="kj kk hi ih b ii kv im kw iq kx iu ky iy kz jc kq kr ks kt bi translated"><strong class="ih hj">缓慢— <br/> </strong>随着我们数据集规模的增大，算法变得缓慢。对于K的每次迭代，它必须访问数据集中的每个点。<br/> <strong class="ih hj"> <em class="mq">解决方案—小批量K表示</em> </strong></li><li id="9202" class="kj kk hi ih b ii kv im kw iq kx iu ky iy kz jc kq kr ks kt bi translated"><strong class="ih hj">聚类均匀数据— <em class="mq"> <br/> </em> </strong>即使数据集中没有逻辑聚类，该算法也能聚类均匀数据。</li><li id="8237" class="kj kk hi ih b ii kv im kw iq kx iu ky iy kz jc kq kr ks kt bi translated"><strong class="ih hj">给予较大的聚类更多的权重</strong></li></ol><h1 id="26fc" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">应用K-means需要处理的数据问题</h1><ol class=""><li id="879c" class="kj kk hi ih b ii kl im km iq kn iu ko iy kp jc kq kr ks kt bi translated"><strong class="ih hj"> <em class="mq">异常值— </em> </strong> <em class="mq">由于我们使用的是基于距离的方法，K-means对异常值很敏感。</em></li><li id="36a2" class="kj kk hi ih b ii kv im kw iq kx iu ky iy kz jc kq kr ks kt bi translated"><strong class="ih hj"> <em class="mq">分类数据— </em> </strong> <em class="mq"> K表示不能处理分类数据。这可以通过三种方式来解决。</em>将分类变量转换为数值— →缩放数据— &gt;应用K均值<br/> 2。用汉明距离代替欧几里德距离。[如果两个分类值相同，使距离==0否则1] <br/> 3。计算模式。</li><li id="cb4a" class="kj kk hi ih b ii kv im kw iq kx iu ky iy kz jc kq kr ks kt bi translated"><strong class="ih hj">降维— </strong> <em class="mq">如果数据是高维的，降低我们数据的维度是很好的</em></li><li id="8711" class="kj kk hi ih b ii kv im kw iq kx iu ky iy kz jc kq kr ks kt bi translated"><strong class="ih hj">缺失值</strong> — <em class="mq">这些应该被处理。</em></li><li id="54da" class="kj kk hi ih b ii kv im kw iq kx iu ky iy kz jc kq kr ks kt bi translated"><strong class="ih hj">多线性</strong> — <em class="mq">不会受到严重影响，因为它会计算距离。但是，如果我们删除一些基于共线性的要素，我们可能会使一些样本更接近。</em></li></ol><figure class="le lf lg lh fd li er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es mw"><img src="../Images/a702349bbcd28f8670e1cc64b76f35c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NHB8UFbUU1RHdVUJv--s6A.jpeg"/></div></div></figure><h1 id="8f14" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated"><strong class="ak">K-means的应用</strong></h1><ol class=""><li id="4f99" class="kj kk hi ih b ii kl im km iq kn iu ko iy kp jc kq kr ks kt bi translated"><strong class="ih hj">数据或图像压缩—</strong><em class="mq">1字节256色可寻址。对于每个像素，我们有3个字节用于</em> <strong class="ih hj"> <em class="mq"> RGB。</em> </strong> <em class="mq">现在如果我们想减少颜色的数量，我们可以使用K-means来确定使用哪些颜色。我们可以将每个像素视为一个数据点。<br/>实现—</em><a class="ae ku" href="https://jakevdp.github.io/PythonDataScienceHandbook/05.11-k-means.html" rel="noopener ugc nofollow" target="_blank">https://jakevdp . github . io/python datascience handbook/05.11-k-means . html</a></li><li id="28c4" class="kj kk hi ih b ii kv im kw iq kx iu ky iy kz jc kq kr ks kt bi translated"><strong class="ih hj">异常值检测— </strong></li></ol><blockquote class="mn mo mp"><p id="c10e" class="if ig mq ih b ii ij ik il im in io ip mr ir is it ms iv iw ix mt iz ja jb jc hb bi translated">基于距离的方法—</p></blockquote><p id="5b45" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="mq">找出数据的阈值— →如果距离&gt;阈值:标记为异常值— →移除异常值</em></p><blockquote class="mn mo mp"><p id="c287" class="if ig mq ih b ii ij ik il im in io ip mr ir is it ms iv iw ix mt iz ja jb jc hb bi translated">基于集群的方法-</p></blockquote><p id="ebee" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="mq">找出最小聚类— - &gt;将最小聚类中的点视为离群点。</em></p><h1 id="4c5d" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated"><strong class="ak">参考文献- </strong></h1><ol class=""><li id="e1ba" class="kj kk hi ih b ii kl im km iq kn iu ko iy kp jc kq kr ks kt bi translated"><a class="ae ku" href="https://jakevdp.github.io/PythonDataScienceHandbook/05.11-k-means.html" rel="noopener ugc nofollow" target="_blank">https://jakevdp . github . io/python datascience handbook/05.11-k-means . html</a></li><li id="9725" class="kj kk hi ih b ii kv im kw iq kx iu ky iy kz jc kq kr ks kt bi translated"><a class="ae ku" href="https://scikit-learn.org/stable/modules/clustering.html#k-means" rel="noopener ugc nofollow" target="_blank">https://sci kit-learn . org/stable/modules/clustering . html # k-means</a></li></ol></div></div>    
</body>
</html>