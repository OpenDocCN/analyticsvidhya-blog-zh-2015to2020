<html>
<head>
<title/>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1/>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/linear-regression-6eebfb69d9be?source=collection_archive---------22-----------------------#2020-05-01">https://medium.com/analytics-vidhya/linear-regression-6eebfb69d9be?source=collection_archive---------22-----------------------#2020-05-01</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><figure class="hh hi ez fb hj hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es hg"><img src="../Images/45a65525551b42dd6a23d8403c5d2c9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0sWryJmme7H2bZR-Eoi8QA.jpeg"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">来源:未知</figcaption></figure></div><div class="ab cl hv hw gp hx" role="separator"><span class="hy bw bk hz ia ib"/><span class="hy bw bk hz ia ib"/><span class="hy bw bk hz ia"/></div><div class="hb hc hd he hf"><h1 id="52b9" class="ic id ie bd if ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja bi translated"><strong class="ak">数据科学:线性回归</strong></h1><h1 id="19f9" class="ic id ie bd if ig jb ii ij ik jc im in io jd iq ir is je iu iv iw jf iy iz ja bi translated"><strong class="ak">简介:</strong></h1><p id="7a23" class="pw-post-body-paragraph jg jh ie ji b jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">线性回归通常是第一个机器学习算法。这是一个简单的模型，但每个人都需要掌握它，因为它为其他机器学习算法奠定了基础。</p><p id="e73d" class="pw-post-body-paragraph jg jh ie ji b jj ke jl jm jn kf jp jq jr kg jt ju jv kh jx jy jz ki kb kc kd hb bi translated">为了理解线性回归，让我们首先理解什么是回归。</p><p id="c566" class="pw-post-body-paragraph jg jh ie ji b jj ke jl jm jn kf jp jq jr kg jt ju jv kh jx jy jz ki kb kc kd hb bi translated">基本上是用统计方法来寻找变量/特征之间的关系。它们用于预测连续值。</p><h1 id="6fc4" class="ic id ie bd if ig jb ii ij ik jc im in io jd iq ir is je iu iv iw jf iy iz ja bi translated"><strong class="ak">直觉:</strong></h1><p id="8c6b" class="pw-post-body-paragraph jg jh ie ji b jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">线性回归是有监督的机器学习算法。它使用一条<strong class="ji kj">最佳拟合直线</strong>(也称为回归线)在<strong class="ji kj">因变量(Y) </strong>和一个或多个<strong class="ji kj">自变量(X) </strong>之间建立关系。</p><p id="6068" class="pw-post-body-paragraph jg jh ie ji b jj ke jl jm jn kf jp jq jr kg jt ju jv kh jx jy jz ki kb kc kd hb bi translated"><strong class="ji kj">因变量</strong>:我们想要预测其值的变量，也称为目标变量。</p><p id="2ecc" class="pw-post-body-paragraph jg jh ie ji b jj ke jl jm jn kf jp jq jr kg jt ju jv kh jx jy jz ki kb kc kd hb bi translated"><strong class="ji kj">自变量</strong>:用于预测数值的变量</p><figure class="kl km kn ko fd hk er es paragraph-image"><div class="er es kk"><img src="../Images/d8870f485a6fc3fdc56967e937eaf677.png" data-original-src="https://miro.medium.com/v2/resize:fit:1030/format:webp/1*7QUfETfH0AVqdLsaFpr-PQ.png"/></div></figure><p id="4794" class="pw-post-body-paragraph jg jh ie ji b jj ke jl jm jn kf jp jq jr kg jt ju jv kh jx jy jz ki kb kc kd hb bi translated">其中:</p><p id="a980" class="pw-post-body-paragraph jg jh ie ji b jj ke jl jm jn kf jp jq jr kg jt ju jv kh jx jy jz ki kb kc kd hb bi translated"><strong class="ji kj">面积(sft中)</strong>:自变量</p><p id="c6d9" class="pw-post-body-paragraph jg jh ie ji b jj ke jl jm jn kf jp jq jr kg jt ju jv kh jx jy jz ki kb kc kd hb bi translated"><strong class="ji kj">价格</strong>:因变量</p><p id="5ac1" class="pw-post-body-paragraph jg jh ie ji b jj ke jl jm jn kf jp jq jr kg jt ju jv kh jx jy jz ki kb kc kd hb bi translated">在二维空间中，我们创建一条线来找出两个变量之间的关系。</p><p id="7818" class="pw-post-body-paragraph jg jh ie ji b jj ke jl jm jn kf jp jq jr kg jt ju jv kh jx jy jz ki kb kc kd hb bi translated"><strong class="ji kj">直线方程:</strong></p><p id="a547" class="pw-post-body-paragraph jg jh ie ji b jj ke jl jm jn kf jp jq jr kg jt ju jv kh jx jy jz ki kb kc kd hb bi translated">y= m*x + c</p><p id="3b16" class="pw-post-body-paragraph jg jh ie ji b jj ke jl jm jn kf jp jq jr kg jt ju jv kh jx jy jz ki kb kc kd hb bi translated">其中:</p><p id="eefe" class="pw-post-body-paragraph jg jh ie ji b jj ke jl jm jn kf jp jq jr kg jt ju jv kh jx jy jz ki kb kc kd hb bi translated">y =因变量</p><p id="1246" class="pw-post-body-paragraph jg jh ie ji b jj ke jl jm jn kf jp jq jr kg jt ju jv kh jx jy jz ki kb kc kd hb bi translated">x =独立变量</p><p id="0d67" class="pw-post-body-paragraph jg jh ie ji b jj ke jl jm jn kf jp jq jr kg jt ju jv kh jx jy jz ki kb kc kd hb bi translated">m =斜率，表示在x值的单位变化范围内，y的变化量。</p><p id="7b5d" class="pw-post-body-paragraph jg jh ie ji b jj ke jl jm jn kf jp jq jr kg jt ju jv kh jx jy jz ki kb kc kd hb bi translated">c =截距或偏差，表示数据不是从零开始。</p><p id="bdda" class="pw-post-body-paragraph jg jh ie ji b jj ke jl jm jn kf jp jq jr kg jt ju jv kh jx jy jz ki kb kc kd hb bi translated">我们的目标是找到可用于预测相关值的最佳拟合线(这里表示为y)。</p><p id="2529" class="pw-post-body-paragraph jg jh ie ji b jj ke jl jm jn kf jp jq jr kg jt ju jv kh jx jy jz ki kb kc kd hb bi translated">但是二维空间中可以有多条线，那么哪条线是最佳拟合线呢？</p><p id="d771" class="pw-post-body-paragraph jg jh ie ji b jj ke jl jm jn kf jp jq jr kg jt ju jv kh jx jy jz ki kb kc kd hb bi translated">为了理解这一点，我们应该理解<strong class="ji kj">残差平方和/误差平方和(RSS/SSE)。</strong></p><p id="40e5" class="pw-post-body-paragraph jg jh ie ji b jj ke jl jm jn kf jp jq jr kg jt ju jv kh jx jy jz ki kb kc kd hb bi translated"><strong class="ji kj">残差平方和</strong>(也称为预测的误差平方和)是实际数据点和预测数据点之间的差值。</p><p id="9940" class="pw-post-body-paragraph jg jh ie ji b jj ke jl jm jn kf jp jq jr kg jt ju jv kh jx jy jz ki kb kc kd hb bi translated">SSE方程:</p><figure class="kl km kn ko fd hk er es paragraph-image"><div class="er es kp"><img src="../Images/b7b6e8b6ee1673a3d073bced742448c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*09Ut5taPm9CjWUf1NNCnFA.png"/></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">来源:未知</figcaption></figure><p id="39da" class="pw-post-body-paragraph jg jh ie ji b jj ke jl jm jn kf jp jq jr kg jt ju jv kh jx jy jz ki kb kc kd hb bi translated">在哪里</p><p id="d312" class="pw-post-body-paragraph jg jh ie ji b jj ke jl jm jn kf jp jq jr kg jt ju jv kh jx jy jz ki kb kc kd hb bi translated">yi=观察者数据点</p><p id="9023" class="pw-post-body-paragraph jg jh ie ji b jj ke jl jm jn kf jp jq jr kg jt ju jv kh jx jy jz ki kb kc kd hb bi translated">回归线估计的ŷi:实际值。</p><p id="8b4b" class="pw-post-body-paragraph jg jh ie ji b jj ke jl jm jn kf jp jq jr kg jt ju jv kh jx jy jz ki kb kc kd hb bi translated">使用SSE/RSS等式，将创建多行，如下所示。</p><figure class="kl km kn ko fd hk er es paragraph-image"><div class="er es kq"><img src="../Images/1af3fd7c145ec12093616cb5621e9990.png" data-original-src="https://miro.medium.com/v2/resize:fit:1358/format:webp/1*0vtrXC7uHRAtSHjL9sRWdA.png"/></div></figure><p id="82a8" class="pw-post-body-paragraph jg jh ie ji b jj ke jl jm jn kf jp jq jr kg jt ju jv kh jx jy jz ki kb kc kd hb bi translated">将具有最小RSS/SSE值的线被选为二维空间中回归的最佳拟合线。基本上，应该考虑覆盖大部分点并具有最小RSS/SSE值的那条线。</p><p id="241e" class="pw-post-body-paragraph jg jh ie ji b jj ke jl jm jn kf jp jq jr kg jt ju jv kh jx jy jz ki kb kc kd hb bi translated">这里</p><p id="9412" class="pw-post-body-paragraph jg jh ie ji b jj ke jl jm jn kf jp jq jr kg jt ju jv kh jx jy jz ki kb kc kd hb bi translated">蓝点:实际数据点，红线:预测数据点</p><figure class="kl km kn ko fd hk er es paragraph-image"><div class="er es kr"><img src="../Images/248c392927d7629bc926d67088e629c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/format:webp/1*76WoErSgOKOalmxVH5iY4w.png"/></div></figure><p id="4e41" class="pw-post-body-paragraph jg jh ie ji b jj ke jl jm jn kf jp jq jr kg jt ju jv kh jx jy jz ki kb kc kd hb bi translated">需要注意的是，为了便于演示，我们只取了两个变量/特征。</p><p id="b101" class="pw-post-body-paragraph jg jh ie ji b jj ke jl jm jn kf jp jq jr kg jt ju jv kh jx jy jz ki kb kc kd hb bi translated">在两个变量的情况下:我们可以画一条线</p><p id="0e92" class="pw-post-body-paragraph jg jh ie ji b jj ke jl jm jn kf jp jq jr kg jt ju jv kh jx jy jz ki kb kc kd hb bi translated">3个变量:可以画平面</p><p id="1717" class="pw-post-body-paragraph jg jh ie ji b jj ke jl jm jn kf jp jq jr kg jt ju jv kh jx jy jz ki kb kc kd hb bi translated">4个变量:可以画超平面</p><p id="5f17" class="pw-post-body-paragraph jg jh ie ji b jj ke jl jm jn kf jp jq jr kg jt ju jv kh jx jy jz ki kb kc kd hb bi translated">具有N维的类似独立特征，创建了相对的N维空间(因为很难显示更高维，所以我以2维为例)</p><p id="eb7b" class="pw-post-body-paragraph jg jh ie ji b jj ke jl jm jn kf jp jq jr kg jt ju jv kh jx jy jz ki kb kc kd hb bi translated">上面的方程也可以写成如下形式</p><p id="6526" class="pw-post-body-paragraph jg jh ie ji b jj ke jl jm jn kf jp jq jr kg jt ju jv kh jx jy jz ki kb kc kd hb bi translated">Y=Wo+W1*X1</p><p id="a2e7" class="pw-post-body-paragraph jg jh ie ji b jj ke jl jm jn kf jp jq jr kg jt ju jv kh jx jy jz ki kb kc kd hb bi translated">让我们将Y值代入RSS/SSE等式:</p><figure class="kl km kn ko fd hk er es paragraph-image"><div class="er es ks"><img src="../Images/390881af6f3792aad0f4191134b652de.png" data-original-src="https://miro.medium.com/v2/resize:fit:430/format:webp/1*pYvme6O-PnaLQCJICWi79w.png"/></div></figure><p id="e1d8" class="pw-post-body-paragraph jg jh ie ji b jj ke jl jm jn kf jp jq jr kg jt ju jv kh jx jy jz ki kb kc kd hb bi translated">RSS(Wo，W1)=(y1-[Wo+W1 * X1])+(y2-[Wo+W1 * X2])…………+(易-[Wo+W1*Xi])</p><p id="f819" class="pw-post-body-paragraph jg jh ie ji b jj ke jl jm jn kf jp jq jr kg jt ju jv kh jx jy jz ki kb kc kd hb bi translated">最后，独立变量的所有值连同它们的权重(截距和斜率值)被传递到该方程，并且具有最小残差平方和的线被选择为最佳拟合线。</p><p id="2ce1" class="pw-post-body-paragraph jg jh ie ji b jj ke jl jm jn kf jp jq jr kg jt ju jv kh jx jy jz ki kb kc kd hb bi translated">为了更新权重，我们使用<strong class="ji kj">成本函数(也称为上面讨论的平方误差函数)</strong>和<strong class="ji kj">梯度下降</strong>，我们将在后面的主题中讨论。给你一瞥。</p><p id="2914" class="pw-post-body-paragraph jg jh ie ji b jj ke jl jm jn kf jp jq jr kg jt ju jv kh jx jy jz ki kb kc kd hb bi translated">成本函数基本上告诉我们，对于给定的m(Wi)和c(Wo)值，我们的模型在进行预测方面有多好。</p><p id="3ce5" class="pw-post-body-paragraph jg jh ie ji b jj ke jl jm jn kf jp jq jr kg jt ju jv kh jx jy jz ki kb kc kd hb bi translated">成本函数表示为j。</p><figure class="kl km kn ko fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es kt"><img src="../Images/0efbf9bdb6e6f0370199534394044f12.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*j0jcfZkZBjdzG2o9Ot9-OQ.png"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">图片:奥雷利</figcaption></figure><p id="1090" class="pw-post-body-paragraph jg jh ie ji b jj ke jl jm jn kf jp jq jr kg jt ju jv kh jx jy jz ki kb kc kd hb bi translated">我们的目标是最小化成本函数。为此，我们需要找到产生最低y值m(或w1)的值</p><p id="84ea" class="pw-post-body-paragraph jg jh ie ji b jj ke jl jm jn kf jp jq jr kg jt ju jv kh jx jy jz ki kb kc kd hb bi translated">梯度下降可用于最小化成本函数。梯度下降算法有助于作出这一决定与导数的使用。</p><p id="cc32" class="pw-post-body-paragraph jg jh ie ji b jj ke jl jm jn kf jp jq jr kg jt ju jv kh jx jy jz ki kb kc kd hb bi translated">使用梯度下降，我们将能够找到我们的成本函数最小的m(斜率)和b(截距)的那些值。请浏览下面的文章，深入了解梯度下降的细节。</p><div class="hh hi ez fb hj ku"><a rel="noopener follow" target="_blank" href="/datadriveninvestor/an-overview-of-gradient-descent-algorithms-e373443afa7f"><div class="kv ab dw"><div class="kw ab kx cl cj ky"><h2 class="bd kj fi z dy kz ea eb la ed ef lb bi translated">梯度下降算法综述</h2><div class="lc l"><h3 class="bd b fi z dy kz ea eb la ed ef dx translated">概述:</h3></div><div class="ld l"><p class="bd b fp z dy kz ea eb la ed ef dx translated">medium.com</p></div></div><div class="le l"><div class="lf l lg lh li le lj hp ku"/></div></div></a></div><p id="ff21" class="pw-post-body-paragraph jg jh ie ji b jj ke jl jm jn kf jp jq jr kg jt ju jv kh jx jy jz ki kb kc kd hb bi translated"><strong class="ji kj">制作线性回归模型前需要考虑的最佳实践:</strong></p><ol class=""><li id="3194" class="lk ll ie ji b jj ke jn kf jr lm jv ln jz lo kd lp lq lr ls bi translated">由于它使用距离(主要是欧几里德距离)作为度量来查找实际值和预测值，因此在将数据用于模型训练之前必须进行标准化/规范化。<strong class="ji kj">标准化</strong>(通常更好，因为它考虑了异常值)将数据转换为标准正态分布或z分布，其中平均值为0，标准差为1。基本上它会使数据单元更少。</li></ol><p id="1d3c" class="pw-post-body-paragraph jg jh ie ji b jj ke jl jm jn kf jp jq jr kg jt ju jv kh jx jy jz ki kb kc kd hb bi translated">z分数用于执行标准化。</p><figure class="kl km kn ko fd hk er es paragraph-image"><div class="er es lt"><img src="../Images/279bcda7073e944d6ad75b518abb2d80.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/1*CJwT8E7uMUjmc4Uf5-HExw.gif"/></div></figure><p id="39ff" class="pw-post-body-paragraph jg jh ie ji b jj ke jl jm jn kf jp jq jr kg jt ju jv kh jx jy jz ki kb kc kd hb bi translated">其中，<strong class="ji kj">规范化</strong>的目标是将数据集中数值列的值更改为一个通用范围，而不扭曲值范围的差异。</p><figure class="kl km kn ko fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lu"><img src="../Images/773c07395838221ecea89d1aa91a5161.png" data-original-src="https://miro.medium.com/v2/resize:fit:656/format:webp/1*0P0HEQWV1Yo4yCtYPkwBXw.png"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">图片:数据鲨鱼</figcaption></figure></div><div class="ab cl hv hw gp hx" role="separator"><span class="hy bw bk hz ia ib"/><span class="hy bw bk hz ia ib"/><span class="hy bw bk hz ia"/></div><div class="hb hc hd he hf"><p id="61d6" class="pw-post-body-paragraph jg jh ie ji b jj ke jl jm jn kf jp jq jr kg jt ju jv kh jx jy jz ki kb kc kd hb bi translated">2.移除线性回归的异常值。您可以使用五个数字汇总或使用箱线图或散点图来检查异常值。</p><p id="3f82" class="pw-post-body-paragraph jg jh ie ji b jj ke jl jm jn kf jp jq jr kg jt ju jv kh jx jy jz ki kb kc kd hb bi translated">3.移除相关要素(相互关联的要素，一个要素的增加会增加或减少其他要素)。</p><p id="fb13" class="pw-post-body-paragraph jg jh ie ji b jj ke jl jm jn kf jp jq jr kg jt ju jv kh jx jy jz ki kb kc kd hb bi translated"><strong class="ji kj">模型拟合度和精度:</strong></p><ol class=""><li id="24bc" class="lk ll ie ji b jj ke jn kf jr lm jv ln jz lo kd lp lq lr ls bi translated">当训练和测试数据在准确性上存在巨大差异时，就会发生过拟合。应进行预处理和特征工程，以消除过拟合并获得良好的模型精度。</li><li id="33bb" class="lk ll ie ji b jj lv jn lw jr lx jv ly jz lz kd lp lq lr ls bi translated">在线性回归中，模型精度由R平方的值决定。统计学上，R平方是数据与拟合回归线接近程度的度量。这也被称为决定系数。</li></ol><p id="0445" class="pw-post-body-paragraph jg jh ie ji b jj ke jl jm jn kf jp jq jr kg jt ju jv kh jx jy jz ki kb kc kd hb bi translated">r平方=解释偏差/总偏差</p><p id="4704" class="pw-post-body-paragraph jg jh ie ji b jj ke jl jm jn kf jp jq jr kg jt ju jv kh jx jy jz ki kb kc kd hb bi translated">r平方值始终介于0和100%之间:</p><ul class=""><li id="dd7a" class="lk ll ie ji b jj ke jn kf jr lm jv ln jz lo kd ma lq lr ls bi translated">0%表示该模型不能解释响应数据在其平均值附近的任何可变性。</li><li id="298d" class="lk ll ie ji b jj lv jn lw jr lx jv ly jz lz kd ma lq lr ls bi translated">100%表示模型解释了响应数据围绕其平均值的所有可变性。</li></ul><p id="ed7a" class="pw-post-body-paragraph jg jh ie ji b jj ke jl jm jn kf jp jq jr kg jt ju jv kh jx jy jz ki kb kc kd hb bi translated">一般来说，R平方越高，模型就越符合您的数据。</p><p id="563f" class="pw-post-body-paragraph jg jh ie ji b jj ke jl jm jn kf jp jq jr kg jt ju jv kh jx jy jz ki kb kc kd hb bi translated"><strong class="ji kj">结论</strong>:线性回归是预测连续值的基本模型之一。在创建任何线性回归模型之前，必须进行数据预处理和特征工程，以获得良好的准确性。</p><p id="ec15" class="pw-post-body-paragraph jg jh ie ji b jj ke jl jm jn kf jp jq jr kg jt ju jv kh jx jy jz ki kb kc kd hb bi translated">如果你喜欢我的文章，请点击<strong class="ji kj">鼓掌</strong>(最多50次)，这将激励我写更多。</p><p id="df8d" class="pw-post-body-paragraph jg jh ie ji b jj ke jl jm jn kf jp jq jr kg jt ju jv kh jx jy jz ki kb kc kd hb bi translated">想要连接:</p><p id="a136" class="pw-post-body-paragraph jg jh ie ji b jj ke jl jm jn kf jp jq jr kg jt ju jv kh jx jy jz ki kb kc kd hb bi translated">联系方式:【https://www.linkedin.com/in/anjani-kumar-9b969a39/ T4】</p><p id="163a" class="pw-post-body-paragraph jg jh ie ji b jj ke jl jm jn kf jp jq jr kg jt ju jv kh jx jy jz ki kb kc kd hb bi translated">如果你喜欢我在Medium上的帖子，并希望我继续做这项工作，请考虑在<a class="ae mb" href="https://www.patreon.com/anjanikumar" rel="noopener ugc nofollow" target="_blank"> <strong class="ji kj"> patreon </strong> </a>上支持我</p></div></div>    
</body>
</html>