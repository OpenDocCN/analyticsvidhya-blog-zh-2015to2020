<html>
<head>
<title>Timeseries forecasting using LSTM</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">利用LSTM进行时间序列预测</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/timeseries-forecasting-using-lstm-57640c57e105?source=collection_archive---------6-----------------------#2020-12-17">https://medium.com/analytics-vidhya/timeseries-forecasting-using-lstm-57640c57e105?source=collection_archive---------6-----------------------#2020-12-17</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="ad27" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">LSTM(长短期记忆网络)是RNN(递归神经网络)的变体，能够学习长期依赖性，特别是在序列预测问题中。</p></div><div class="ab cl jd je gp jf" role="separator"><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji"/></div><div class="hb hc hd he hf"><p id="b747" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这里，我将使用LSTM来演示我们如何使用这种技术来做一些时间序列预测。</p><figure class="jl jm jn jo fd jp er es paragraph-image"><div class="er es jk"><img src="../Images/e58dfea3249dbcd8147d064b7ccef9b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/0*ehRDmIwHCPPTq8K6.gif"/></div><figcaption class="js jt et er es ju jv bd b be z dx translated"><a class="ae jw" href="https://giphy.com/gifs/3o7abKJnlA3n2YqHe0/html5" rel="noopener ugc nofollow" target="_blank">图像来源</a></figcaption></figure><p id="4bfa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">数据</strong>:<a class="ae jw" href="https://www.kaggle.com/uciml/electric-power-consumption-data-set" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/UC IML/electric-power-consumption-Data-set</a></p><figure class="jl jm jn jo fd jp er es paragraph-image"><div role="button" tabindex="0" class="jy jz di ka bf kb"><div class="er es jx"><img src="../Images/b4e5b0494266f9f29ea9f804ffa4e6ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*13BfxWGg4Rrs03kVVM1FwA.png"/></div></div><figcaption class="js jt et er es ju jv bd b be z dx translated">data.head()输出</figcaption></figure><p id="df3d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">数据预处理:</strong></p><pre class="jl jm jn jo fd kc kd ke kf aw kg bi"><span id="154d" class="kh ki hi kd b fi kj kk l kl km">#Derive a column as Date from Date and Time <br/>data.loc[:,<strong class="kd hj">'Date'</strong>] = pd.to_datetime(data.Date.astype(str)+<strong class="kd hj">' '</strong>+data.Time.astype(str))</span><span id="389c" class="kh ki hi kd b fi kn kk l kl km">#Drop the column time<br/>data.drop([<strong class="kd hj">"Time"</strong>],inplace=<strong class="kd hj">True</strong>,axis =1)</span><span id="9e92" class="kh ki hi kd b fi kn kk l kl km">#Set the Date column as index<br/>data.set_index([<strong class="kd hj">"Date"</strong>],inplace=<strong class="kd hj">True</strong>)</span><span id="2616" class="kh ki hi kd b fi kn kk l kl km">#change the series to dataframe<br/>data = data[[<strong class="kd hj">"Global_active_power"</strong>]]</span><span id="74c7" class="kh ki hi kd b fi kn kk l kl km">#check if there is any unwanted characters in the column<br/>print (data[pd.to_numeric(data['Global_active_power'], errors='coerce').isnull()]["Global_active_power"].unique())</span><span id="2d42" class="kh ki hi kd b fi kn kk l kl km">#remove the character (in this case it is '?')<br/>data["Global_active_power"] = data["Global_active_power"].apply(lambda x: float(x) if "?" not in x else None)</span></pre><p id="9214" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">数据每分钟都可用，因此我们可以按天、月或小时对数据进行重新采样。我将选择按小时重新采样，否则按月会减少数据点的数量。使用日的预测没有给出任何有趣的预测结果，所以我选择小时而不是日来对数据集进行重采样。</p><pre class="jl jm jn jo fd kc kd ke kf aw kg bi"><span id="b104" class="kh ki hi kd b fi kj kk l kl km">data_sampled_hr=data[<strong class="kd hj">"Global_active_power"</strong>].resample(<strong class="kd hj">'H'</strong>).mean().iloc[1: , ]<br/>data_sampled_hr = pd.DataFrame(data_sampled_hr)</span></pre><figure class="jl jm jn jo fd jp er es paragraph-image"><div class="er es ko"><img src="../Images/2ff187b4e582349577ec35fae006a21e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1332/format:webp/1*5dsPlceyJBKbWYELl_py6A.png"/></div><figcaption class="js jt et er es ju jv bd b be z dx translated">data_sampled_hr.head()</figcaption></figure><pre class="jl jm jn jo fd kc kd ke kf aw kg bi"><span id="ebe8" class="kh ki hi kd b fi kj kk l kl km">#Let's fill the nans with 0 and visualiza the data<br/>data_sampled_hr = data_sampled_hr.fillna(0)</span></pre><figure class="jl jm jn jo fd jp er es paragraph-image"><div role="button" tabindex="0" class="jy jz di ka bf kb"><div class="er es kp"><img src="../Images/793d8b747062af12cf35b129e4f7d072.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OxYF327s2rQ8ExyGKn2LKA.png"/></div></div></figure><p id="4639" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">可视化无助于理解是否有任何季节性或趋势。所以，让我们用季节分解来分解时间序列。</p><pre class="jl jm jn jo fd kc kd ke kf aw kg bi"><span id="1421" class="kh ki hi kd b fi kj kk l kl km"><strong class="kd hj">from </strong>statsmodels.tsa.seasonal <strong class="kd hj">import </strong>seasonal_decompose <br/>results = seasonal_decompose(data_sampled_hr)<br/>results.seasonal[:1000].plot(figsize = (12,8));</span></pre><figure class="jl jm jn jo fd jp er es paragraph-image"><div role="button" tabindex="0" class="jy jz di ka bf kb"><div class="er es kq"><img src="../Images/8ec69c2176b7d971834d382e2d1f5944.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z5Ge9wTFU6STA_kT4eNcQA.png"/></div></div></figure><p id="cac9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们做一些ACF来看看时间序列如何与其过去的值相关联</p><pre class="jl jm jn jo fd kc kd ke kf aw kg bi"><span id="d1f2" class="kh ki hi kd b fi kj kk l kl km"><strong class="kd hj">from </strong>statsmodels.graphics.tsaplots <strong class="kd hj">import </strong>plot_acf<br/>plot_acf(data_sampled_hr)<br/>plt.show();</span></pre><figure class="jl jm jn jo fd jp er es paragraph-image"><div role="button" tabindex="0" class="jy jz di ka bf kb"><div class="er es kr"><img src="../Images/63c9af08bb62b3c304867b792abe316a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4GD8khkhFeyB0eDJii_MsQ.png"/></div></div></figure><p id="0de4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这就有意思了！看看相关性如何在一天的最初几个小时很高，然后在一天的晚些时候再次上升。肯定是有趋势的。</p><p id="21b5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">模型建立和评估:</strong></p><p id="c539" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们看看LSTM模型能否做出一些预测或了解数据的总体趋势。</p><p id="876f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于预测，我们可以做的是使用48小时(2天)的时间窗口来预测未来。让我们来设计训练和测试数据。</p><pre class="jl jm jn jo fd kc kd ke kf aw kg bi"><span id="b103" class="kh ki hi kd b fi kj kk l kl km">train = data_sampled_hr[:-48]<br/>test = data_sampled_hr[-48:] # last 48 hours is my test data</span></pre><p id="29f5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们需要我们的数据被缩放，这对任何深度学习模型都是必不可少的。</p><pre class="jl jm jn jo fd kc kd ke kf aw kg bi"><span id="a0e6" class="kh ki hi kd b fi kj kk l kl km"><strong class="kd hj">from </strong>sklearn.preprocessing <strong class="kd hj">import </strong>MinMaxScaler<br/><br/>scaler = MinMaxScaler()<br/>scaler.fit(train)</span><span id="2fcb" class="kh ki hi kd b fi kn kk l kl km">scaled_train = scaler.transform(train)<br/>scaled_test = scaler.transform(test)</span></pre><p id="c2d9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们将使用Keras库中的时间序列生成器来设计训练数据和标签，这意味着生成器将从一开始就使用48个数据点，并将第49个数据点映射为标签，然后接下来的48个数据点将第一个和第50个数据点映射为标签，依此类推。</p><pre class="jl jm jn jo fd kc kd ke kf aw kg bi"><span id="6f69" class="kh ki hi kd b fi kj kk l kl km"><em class="ks">#Time series generator<br/></em><strong class="kd hj">from </strong>keras.preprocessing.sequence <strong class="kd hj">import </strong>TimeseriesGenerator<br/><em class="ks">#define generator </em></span><span id="b240" class="kh ki hi kd b fi kn kk l kl km"><em class="ks">#I have used batch_size as 10 so that it's faster, one can use 1 as well<br/></em>n_input = 48<br/>n_features = 1</span><span id="af82" class="kh ki hi kd b fi kn kk l kl km">generator = TimeseriesGenerator(scaled_train,scaled_train,length = n_input, batch_size = 10)</span><span id="6a8f" class="kh ki hi kd b fi kn kk l kl km">#Note: both the parameters of TimeseriesGenerator are scaled_train #because to generate the data and the label it will use scaled_train</span></pre><p id="fb99" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在让我们定义模型，</p><pre class="jl jm jn jo fd kc kd ke kf aw kg bi"><span id="4b63" class="kh ki hi kd b fi kj kk l kl km"><strong class="kd hj">from </strong>keras.models <strong class="kd hj">import </strong>Sequential<br/><strong class="kd hj">from </strong>keras.layers <strong class="kd hj">import </strong>Dense<br/><strong class="kd hj">from </strong>keras.layers <strong class="kd hj">import </strong>LSTM<br/><br/><em class="ks"># define model<br/><br/></em>model = Sequential()<br/>model.add(LSTM(200,activation= <strong class="kd hj">"relu" </strong>, input_shape = (n_input , n_features)))<br/>model.add(Dense(1))<br/>model.compile(optimizer = <strong class="kd hj">"adam" </strong>, loss=<strong class="kd hj">"mse"</strong>)</span></pre><figure class="jl jm jn jo fd jp er es paragraph-image"><div role="button" tabindex="0" class="jy jz di ka bf kb"><div class="er es kt"><img src="../Images/87f66f4ce0fceed5129f22bcfc268e98.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U9I_e_-VD1eQ-ATfusUQpA.png"/></div></div><figcaption class="js jt et er es ju jv bd b be z dx translated">模型.摘要()</figcaption></figure><figure class="jl jm jn jo fd jp er es paragraph-image"><div role="button" tabindex="0" class="jy jz di ka bf kb"><div class="er es ku"><img src="../Images/8eea87752aae7b9a140fd8779b305bb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7779_cM3xD6nIF6hKoTRvQ.png"/></div></div></figure><pre class="jl jm jn jo fd kc kd ke kf aw kg bi"><span id="1896" class="kh ki hi kd b fi kj kk l kl km">model.fit_generator(generator , epochs=5)</span></pre><p id="24ff" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">请注意我是如何使用epoch作为5的，我们可以使用更多的epoch来查看模型的执行情况。</p><p id="43b3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了了解损失随时代的变化，我们可以快速绘制一个图表:</p><figure class="jl jm jn jo fd jp er es paragraph-image"><div role="button" tabindex="0" class="jy jz di ka bf kb"><div class="er es kv"><img src="../Images/3081fc524c6ffb1bf52d12498912cb68.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FAGrJ0zBd3civj4kK_DaRA.png"/></div></div></figure><pre class="jl jm jn jo fd kc kd ke kf aw kg bi"><span id="70ee" class="kh ki hi kd b fi kj kk l kl km">loss_per_epoch = model.history.history[<strong class="kd hj">"loss"</strong>]<br/>plt.plot(range(len(loss_per_epoch)), loss_per_epoch);</span></pre><p id="e2a5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，让我们看看它在测试数据上的表现。</p><pre class="jl jm jn jo fd kc kd ke kf aw kg bi"><span id="a36d" class="kh ki hi kd b fi kj kk l kl km">first_eval_batch = scaled_train[-48:]<br/>first_eval_batch = first_eval_batch.reshape((1, n_input, n_features))<br/>test_predictions = []<br/><br/>first_eval_batch = scaled_train[-n_input:]<br/>current_batch = first_eval_batch.reshape((1, n_input, n_features))<br/><br/><strong class="kd hj">for </strong>i <strong class="kd hj">in </strong>range(len(test)):</span><span id="1a7f" class="kh ki hi kd b fi kn kk l kl km">    # 2d to 1d conversion<br/>    current_pred = model.predict(current_batch)[0]</span><span id="1da9" class="kh ki hi kd b fi kn kk l kl km">    #store the prediction<br/>    test_predictions.append(current_pred)</span><span id="fb6f" class="kh ki hi kd b fi kn kk l kl km">    #update batch to now include prediction and drop first value<br/>    current_batch = np.append(current_batch[:, 1:, :], [[current_pred]], axis=1)<br/><br/>test_predictions = scaler.inverse_transform(test_predictions)<br/>test[<strong class="kd hj">"pred"</strong>] = test_predictions</span></pre><figure class="jl jm jn jo fd jp er es paragraph-image"><div role="button" tabindex="0" class="jy jz di ka bf kb"><div class="er es kw"><img src="../Images/e1f8992646c2a40b65a0b195b5581e26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_BbdEWPjSMGQ3qO-SlMUrw.png"/></div></div><figcaption class="js jt et er es ju jv bd b be z dx translated">test.head()</figcaption></figure><p id="9354" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">绘制预测图:</strong></p><figure class="jl jm jn jo fd jp er es paragraph-image"><div role="button" tabindex="0" class="jy jz di ka bf kb"><div class="er es kx"><img src="../Images/fa047f2ca280f9cd34ef8afa08f8a2ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ijge-cNbpe6_580aPJJbxQ.png"/></div></div><figcaption class="js jt et er es ju jv bd b be z dx translated">test.plot(figsize = (12，8))；</figcaption></figure><p id="5b50" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">虽然预测并不完全完美，但您可以看到模型是如何选择趋势的。</p><p id="1344" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们现在可以改变<strong class="ih hj">的历元数</strong>，<strong class="ih hj">改变时间窗口</strong>，意思是用96小时或24小时代替48小时，看看模型是否能够做出准确的预测。我们还可以执行一些其他重采样模式来试验数据集。</p><p id="477b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后，代替一个LSTM层，我们也可以使用多个层来做进一步的实验。</p></div><div class="ab cl jd je gp jf" role="separator"><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji"/></div><div class="hb hc hd he hf"><p id="4c58" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是一个小小的努力，展示了我们如何轻松地使用LTSM模型来预测时间序列。我希望这是有帮助的，如果你注意到任何需要改进的地方，请随时留言。感谢您阅读文章！！！</p></div></div>    
</body>
</html>