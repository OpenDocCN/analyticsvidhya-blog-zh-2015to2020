<html>
<head>
<title>Lyric Mood Identifier</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">歌词语气标识符</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/lyric-mood-identifier-c8e94a49c73?source=collection_archive---------20-----------------------#2020-05-11">https://medium.com/analytics-vidhya/lyric-mood-identifier-c8e94a49c73?source=collection_archive---------20-----------------------#2020-05-11</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="adc9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一个NLP分类案例，关于使用R语言根据歌词(英语)识别歌曲的积极或消极情绪。</p><p id="fed7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">音乐不仅能够影响你的心情。据格罗宁根大学的研究人员称，听特别快乐或悲伤的音乐甚至可以改变我们感知世界的方式。在这个现代世界，我们有能力轻松选择我们想听的音乐。一些音乐播放器平台，如Spotify，因其音乐推荐系统而闻名。其中他们基于他们的客户历史或流派偏好单独推荐音乐。这将是一个新的想法，如果音乐可以通过它的歌词来欣赏，并将根据歌词的情绪获得推荐。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/e5e3d9c56e8ccef6204840eea3569c3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B5EqLD0H_7iRu9zR09pQPw.jpeg"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">调高音量</figcaption></figure><h1 id="6c60" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">背景</h1><p id="4292" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">这个项目是基于这个<a class="ae kx" href="https://www.kaggle.com/edenbd/150k-lyrics-labeled-with-spotify-valence" rel="noopener ugc nofollow" target="_blank"> Kaggle数据集</a>。该数据集包含使用Spotify API收集的150k歌词及其价值。配价是一个从0.0到1.0的量度，用来描述音轨所传达的音乐积极性。高价曲目听起来更积极(例如，快乐、愉快、欣快)，而低价曲目听起来更消极(例如，悲伤、沮丧、愤怒)。我们在这篇文章中的任务是<strong class="ih hj">执行受监督的自然语言处理情感分析来衡量一首歌曲的积极程度。</strong>这种分析可以用于Spotify公司自身改进其基于歌词(词)的音乐推荐系统。</p><p id="29a9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">局限性:语言既广泛又复杂。NLP也因其高计算值而闻名。所以在这个分析中，我将只使用英文歌词，并且只对45k首歌曲进行数据采样。</p><p id="23a7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">注:</strong>所有库和代码都是用Rstudio软件作为R编程语言IDE处理的。</p><p id="2e1c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用的库:</p><pre class="jf jg jh ji fd ky kz la lb aw lc bi"><span id="240d" class="ld jv hi kz b fi le lf l lg lh"># You can load the package into your workspace using the `library()` function<br/>library(dplyr)<br/>library(tidytext)<br/>library(textclean)<br/>library(tm)<br/>library(SnowballC)<br/>library(stringr)<br/>library(rsample)<br/>library(cld2)<br/>library(caret)<br/>library(e1071)<br/>library(tidymodels)</span></pre><p id="f4d2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">正如我之前所说，数据集包含150k的歌词和一些变量。这是关于数据集的一瞥</p><pre class="jf jg jh ji fd ky kz la lb aw lc bi"><span id="b13e" class="ld jv hi kz b fi le lf l lg lh">Observations: 158,353<br/>Variables: 5<br/>$ X      &lt;int&gt; 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 2...<br/>$ artist &lt;fct&gt; Elijah Blake, Elijah Blake, Elijah Blake, Elijah Blake, Elijah Blake, Elijah Blake, Eli...<br/>$ seq    &lt;fct&gt; "No, no\nI ain't ever trapped out the bando\nBut oh Lord, don't get me wrong\nI know a ...<br/>$ song   &lt;fct&gt; Everyday, Live Till We Die, The Otherside, Pinot, Shadows &amp; Diamonds, Uno, Girlfriend (...<br/>$ label  &lt;dbl&gt; 0.6260, 0.6300, 0.2400, 0.5360, 0.3710, 0.3210, 0.6010, 0.3330, 0.5060, 0.1790, 0.2090,...</span></pre><h1 id="af42" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">数据争论</h1><p id="49f5" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">这里我给你看一个歌词的例子。</p><pre class="jf jg jh ji fd ky kz la lb aw lc bi"><span id="82bd" class="ld jv hi kz b fi le lf l lg lh">head(dat$seq,1)</span><span id="b613" class="ld jv hi kz b fi li lf l lg lh">&gt; [1] No, no\nI ain't ever trapped out the bando\nBut oh Lord, don't get me wrong\nI know a couple niggas that do\nI'm from a place where everybody knows your name\nThey say I gotta watch my attitude\nWhen they see money, man they all start actin' strange\nSo fuck with the ones that fuck with you\nThey can never say I'm brand new\n\nIt's everyday, everyday\nEveryday, everyday, everyday\nEveryday, everyday\nEveryday, everyday\nI've been talkin' my shit, nigga that's regular\nI've been lovin' 'em thick, life is spectacular\nI spend like I'ma die rich, nigga I'm flexin', yeah\nEveryday, that's everyday\nThat's everyday\nThat's everyday\nThat's everyday, everyday\n\nI see all of these wanna-be hot R&amp;B singers\nI swear you all sound the same\nThey start from the bottom, so far from the motto\nYou niggas'll never be Drake\nShout out to OVO\nMost of them prolly don't know me though\nI stay in the cut, I don't fuck with no\nBody but I D, that's a pun on No I.D\nWhen nobody know my name\nRunnin' for my dream wasn't hard to do\nYou break bread, I swear they all pull out a plate\nEat with the ones who starved with you\nIf I'm winnin' then my crew can't lose\n\nIt's everyday, everyday\nEveryday, everyday, everyday\nEveryday, everyday\nEveryday, everyday\nI've been talkin' my shit, nigga that's regular\nI've been lovin' 'em thick, life is spectacular\nI spend like I'ma die rich, nigga I'm flexin', yeah\nEveryday, that's everyday\nThat's everyday\nThat's everyday\nThat's everyday, everyday\n\nI heard since you got money\nYou changed, you're actin' funny\nThat's why I gets on my lonely\nYou be lovin' when change is a hobby\nWho do you dress when you ain't got nobody?\n\nIt's everyday, everyday\nEveryday, everyday, everyday\nEveryday, everyday\nEveryday, everyday\nI've been talkin' my shit, nigga that's regular\nI've been lovin' 'em thick, life is spectacular\nI spend like I'ma die rich, nigga I'm flexin', yeah\nEveryday, that's everyday\nThat's everyday\nThat's everyday\nThat's everyday, everyday<br/>135645 Levels: ''Do you want... to have... a tasty... mushroom?' ...</span></pre><p id="2d46" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">歌词存储在seq列中。正如你所看到的，在建模之前需要做很多处理。我们首先可以做的最简单的事情是删除“\n”作为它的新换行符。目标列(标签)仍为数字格式。正如我之前所说，较高的价值(标签)意味着歌曲被认为是积极的情绪，而较低的价值意味着消极的情绪。我将把化合价转换成二进制值，标记为“正”和“负”，中间值为0.5。我还想过滤英语歌词，以执行自然语言处理更容易。我将使用“cld2”包中的函数来检测歌词语言。</p><pre class="jf jg jh ji fd ky kz la lb aw lc bi"><span id="0ee0" class="ld jv hi kz b fi le lf l lg lh">dat$seq &lt;- str_replace_all(as.character(dat$seq), "\n"," ")<br/># valence with &gt; 0.5 will labelled as potiive, &lt; 0.5 negative<br/>dat$mood &lt;- ifelse(dat$label &gt; 0.5, "positive","negative")<br/>dat$lang &lt;- cld2::detect_language(dat$seq)<br/># filter the data to english lyric only<br/>dat &lt;- dat[dat$lang == "en",]</span></pre><p id="6651" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们看看我们的数据是如何变化的</p><pre class="jf jg jh ji fd ky kz la lb aw lc bi"><span id="8a9d" class="ld jv hi kz b fi le lf l lg lh">head(dat$seq,1)</span><span id="8de9" class="ld jv hi kz b fi li lf l lg lh">&gt; [1] "Who keeps on trusting you When you been cheating Spending your nights on the town? Who keeps on saying That she still wants you When you're through runnin' around? Who keeps on lovin' you When you been lyin' Sayin' things that ain't what they seem?  Well, God does But I don't  God will But I won't And that's the difference Between God and me  God does, but I don't God will, but I won't And that's the difference Between God and me   So, who says she'll forgive you Says that she'll miss you And dream of your sweet memory? Well God does But I don't God will  But I won't And that's the difference Between God and me  God does, but I don't God will, but I won't And that's the difference  Between God and me  God does, but I don't God will, but I won't And that's the difference Between God and me"</span></pre><p id="8814" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这只是我们将为文本清理做的许多步骤之一。由于我的机器限制，我只用45k的歌曲进行分析。这些歌曲是从随机抽样中选出的。</p><p id="49af" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在文本清理过程中，我更熟悉的是<em class="jd"> tm </em>和<em class="jd"> stringr </em>包但我也想学习<em class="jd"> textclean </em>(来自<em class="jd"> tidytext </em>)魔法。在建模之前，我将使用这两个包来清理我的文本数据。下面是我们在文本清理过程中要做的事情的代码，解释写在代码内的hash (#)中:</p><pre class="jf jg jh ji fd ky kz la lb aw lc bi"><span id="29ad" class="ld jv hi kz b fi le lf l lg lh">dat &lt;- dat %&gt;%<br/>  mutate(text_clean = seq %&gt;%  # select seq column<br/>           str_to_lower() %&gt;%  # convert all the string to low alphabet<br/>           replace_contraction() %&gt;% # replace contraction to their multi-word forms<br/>           replace_internet_slang() %&gt;% # replace internet slang to normal words<br/>           replace_word_elongation() %&gt;% # reolace informal writing with known semantic replacements<br/>           replace_number(remove = T) %&gt;% # remove number<br/>           replace_date(replacement = "") %&gt;% # remove date<br/>           str_remove_all(pattern = "[[:punct:]]") %&gt;% # remove punctuation<br/>           str_squish() %&gt;% # reduces repeated whitespace inside a string.<br/>           str_trim() # removes whitespace from start and end of string<br/>         )</span></pre><p id="e2c9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上面的代码中发生了很多事情，但是我们只需要一段代码就可以做到。我还会将文本数据转换成语料库，并使用<em class="jd"> tm </em>包进行标记化。之后，我将只选择出现在850首歌曲中的词。这个限制是概括我们模型中使用的单词所必需的。</p><pre class="jf jg jh ji fd ky kz la lb aw lc bi"><span id="1c04" class="ld jv hi kz b fi le lf l lg lh">corp &lt;- VCorpus(VectorSource(dat$text_clean))</span><span id="45cd" class="ld jv hi kz b fi li lf l lg lh">corp_dtm &lt;- corp %&gt;% <br/>  # use pre-build english stopwords<br/>  tm_map(removeWords, stopwords("en")) %&gt;%<br/>  tm_map(stemDocument) %&gt;%<br/>  # convert corpus to document term matrix<br/>  DocumentTermMatrix()<br/></span><span id="d4e6" class="ld jv hi kz b fi li lf l lg lh"># Find term frequency that appear in at least 850 lyrics<br/>freq_term &lt;- findFreqTerms(corp_dtm, 850)<br/># 815 words are selected<br/>dat.dtm &lt;- corp_dtm[,freq_term]</span></pre><h1 id="75f6" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">建模</h1><h2 id="def3" class="ld jv hi bd jw lj lk ll ka lm ln lo ke iq lp lq ki iu lr ls km iy lt lu kq lv bi translated">朴素贝叶斯</h2><p id="901f" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">使用NB建模需要在训练数据中进行特殊处理。列代表单词，每行代表一首歌曲。NB不需要每个词的确切数量，只需要知道这些词是否出现在歌曲中。因此，我们将每个单元格中的值转换为包含1或0。1表示该特定单词出现在歌曲中，0表示不存在。</p><pre class="jf jg jh ji fd ky kz la lb aw lc bi"><span id="bf6f" class="ld jv hi kz b fi le lf l lg lh"># split the data. 75% for train data, and 25% for test data<br/>set.seed(1502)<br/>index &lt;- sample(1:nrow(dat.dtm), 0.75*nrow(dat.dtm))</span><span id="9b8d" class="ld jv hi kz b fi li lf l lg lh">train_x &lt;- dat.dtm[index,]<br/>test_x &lt;- dat.dtm[-index,]<br/># subset label/target variable<br/>train_label &lt;- dat[index,"mood"]<br/>test_label &lt;- dat[-index,"mood"]</span></pre><p id="3066" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用伯努利转换器将0以上的任何值转换为1，0保持为0。我们将构建一个自定义函数来实现这一点，然后将该函数应用于训练和测试数据。</p><pre class="jf jg jh ji fd ky kz la lb aw lc bi"><span id="2176" class="ld jv hi kz b fi le lf l lg lh"># build bernoulli converter function<br/>bernoulli_conv &lt;- function(x){<br/>  x &lt;- as.factor(as.numeric(x&gt;0))<br/>}</span><span id="3ae1" class="ld jv hi kz b fi li lf l lg lh"># apply bernoulli_conv funtion to train and test data<br/>train_x &lt;- apply(train_x,2,bernoulli_conv)<br/>test_x &lt;- apply(test_x,2,bernoulli_conv)</span></pre><p id="5618" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">单元格中的0表示歌曲没有特定的单词。这也意味着相应的类别-特征组合出现的概率为0。它将破坏NB算法，该算法使用贝叶斯规则计算给定独立预测变量的分类类变量的条件a-后验概率。我们可以指定拉普拉斯=1来启用加一平滑。</p><p id="b9a8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后，我们将构建朴素贝叶斯模型，进行预测(测试数据)，并为以后的评估创建混淆矩阵</p><pre class="jf jg jh ji fd ky kz la lb aw lc bi"><span id="c959" class="ld jv hi kz b fi le lf l lg lh"># train the model<br/>mod.nb &lt;- naiveBayes(train_x, as.factor(train_label), laplace = 1)<br/># predict to test data<br/>pred.nb &lt;- predict(mod.nb, test_x,<br/>                   type = "class")</span><span id="49e2" class="ld jv hi kz b fi li lf l lg lh"># build dataframe for prediction result<br/>pred.nb.x &lt;- cbind(data.frame(pred.nb),test_label)%&gt;%<br/>  setNames(c("pred","actual"))</span><span id="b263" class="ld jv hi kz b fi li lf l lg lh"># create confusion matrix <br/>cf.nb &lt;- confusionMatrix(data = pred.nb.x$pred,<br/>                         reference = pred.nb.x$actual,<br/>                         positive = "positive")</span></pre><p id="dc1e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">结果如下:</p><pre class="jf jg jh ji fd ky kz la lb aw lc bi"><span id="443f" class="ld jv hi kz b fi le lf l lg lh">cf.nb</span><span id="e9a0" class="ld jv hi kz b fi li lf l lg lh">&gt; Confusion Matrix and Statistics</span><span id="82ce" class="ld jv hi kz b fi li lf l lg lh">Reference<br/>Prediction negative positive<br/>  negative     4363     2733<br/>  positive     1464     2690<br/>                                               <br/>               Accuracy : 0.6269               <br/>                 95% CI : (0.6179, 0.6359)     <br/>    No Information Rate : 0.518                <br/>    P-Value [Acc &gt; NIR] : &lt; 0.00000000000000022<br/>                                               <br/>                  Kappa : 0.2468               <br/>                                               <br/> Mcnemar's Test P-Value : &lt; 0.00000000000000022<br/>                                               <br/>            Sensitivity : 0.4960               <br/>            Specificity : 0.7488               <br/>         Pos Pred Value : 0.6476               <br/>         Neg Pred Value : 0.6149               <br/>             Prevalence : 0.4820               <br/>         Detection Rate : 0.2391               <br/>   Detection Prevalence : 0.3692               <br/>      Balanced Accuracy : 0.6224               <br/>                                               <br/>       'Positive' Class : positive</span></pre><h2 id="4106" class="ld jv hi bd jw lj lk ll ka lm ln lo ke iq lp lq ki iu lr ls km iy lt lu kq lv bi translated">决策图表</h2><p id="74e6" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">接下来，我们将使用不同的算法构建另一个模型。我们将使用决策树、MARS和随机森林。所有建模过程(除了朴素贝叶斯)都在使用<em class="jd"> parsnip </em>包(嵌入在<em class="jd"> tidymodel </em>包中)。但在此之前，我们需要用清理后的数据制作一个数据框。令牌值不会像朴素贝叶斯那样转换为1或0。它会保持原样。和之前一样，我们也将数据分成75%和25%的比例进行训练和测试。</p><pre class="jf jg jh ji fd ky kz la lb aw lc bi"><span id="c73a" class="ld jv hi kz b fi le lf l lg lh">dat.clean &lt;- as.data.frame(as.matrix(dat.dtm), stringsAsFactors = F)<br/># we have 800+ variable in words form. i change the label name from `mood` to labelY to avoid overwriting column names<br/>new.dat &lt;- cbind(dat.clean, data.frame(labelY = dat$mood))</span><span id="83b8" class="ld jv hi kz b fi li lf l lg lh"># splitting dataset<br/>set.seed(1502)<br/>splitter &lt;- initial_split(new.dat, prop = 0.75, strata = "labelY")<br/>train &lt;- training(splitter)<br/>test &lt;- testing(splitter)</span></pre><p id="7fa6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后，我们来建立决策树模型，做预测(对数据进行测试)，创建一个混淆矩阵，供后期评估。</p><pre class="jf jg jh ji fd ky kz la lb aw lc bi"><span id="0dfd" class="ld jv hi kz b fi le lf l lg lh"># Train the model<br/>mod.dt &lt;- decision_tree(mode = "classification") %&gt;%<br/>  set_engine("rpart") %&gt;% fit(labelY~., data = train)</span><span id="3776" class="ld jv hi kz b fi li lf l lg lh">pred.dt &lt;- predict(mod.dt, test, <br/>                   type = "class")</span><span id="63b9" class="ld jv hi kz b fi li lf l lg lh"># build dataframe for prediction result<br/>pred.dt.x &lt;- as.data.frame(cbind(pred.dt, test$labelY)) %&gt;%<br/>  setNames(c("pred","actual"))</span><span id="da77" class="ld jv hi kz b fi li lf l lg lh"># create confusion matrix<br/>cf.dt &lt;- confusionMatrix(data = pred.dt.x$pred,<br/>                         reference = pred.dt.x$actual,<br/>                         positive = "positive")</span></pre><p id="818b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是决策树模型的结果:</p><pre class="jf jg jh ji fd ky kz la lb aw lc bi"><span id="1988" class="ld jv hi kz b fi le lf l lg lh">cf.dt</span><span id="fc50" class="ld jv hi kz b fi li lf l lg lh">&gt; Confusion Matrix and Statistics</span><span id="84ea" class="ld jv hi kz b fi li lf l lg lh">Reference<br/>Prediction negative positive<br/>  negative     3671     2404<br/>  positive     2188     2986<br/>                                              <br/>               Accuracy : 0.5918              <br/>                 95% CI : (0.5826, 0.6009)    <br/>    No Information Rate : 0.5208              <br/>    P-Value [Acc &gt; NIR] : &lt; 0.0000000000000002<br/>                                              <br/>                  Kappa : 0.1808              <br/>                                              <br/> Mcnemar's Test P-Value : 0.00151             <br/>                                              <br/>            Sensitivity : 0.5540              <br/>            Specificity : 0.6266              <br/>         Pos Pred Value : 0.5771              <br/>         Neg Pred Value : 0.6043              <br/>             Prevalence : 0.4792              <br/>         Detection Rate : 0.2654              <br/>   Detection Prevalence : 0.4600              <br/>      Balanced Accuracy : 0.5903              <br/>                                              <br/>       'Positive' Class : positive</span></pre><h2 id="dbc5" class="ld jv hi bd jw lj lk ll ka lm ln lo ke iq lp lq ki iu lr ls km iy lt lu kq lv bi translated">火星</h2><p id="c415" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">接下来，我们使用MARS算法建立第三个模型</p><pre class="jf jg jh ji fd ky kz la lb aw lc bi"><span id="262d" class="ld jv hi kz b fi le lf l lg lh"># train mars model<br/>mod.mars &lt;- mars(mode = "classification") %&gt;%<br/>  set_engine("earth") %&gt;% fit(labelY~., data = train)</span><span id="c9ca" class="ld jv hi kz b fi li lf l lg lh">pred.mars &lt;- predict(mod.mars, test, <br/>                   type = "class")</span><span id="1f8e" class="ld jv hi kz b fi li lf l lg lh"># build dataframe for prediction result<br/>pred.mars.x &lt;- as.data.frame(cbind(pred.mars, test$labelY)) %&gt;%<br/>  setNames(c("pred","actual"))</span><span id="0e2b" class="ld jv hi kz b fi li lf l lg lh"># create confusion matrix<br/>cf.mars &lt;- confusionMatrix(data = pred.mars.x$pred,<br/>                         reference = pred.mars.x$actual,<br/>                         positive = "positive")</span></pre><p id="252e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是火星模型的结果:</p><pre class="jf jg jh ji fd ky kz la lb aw lc bi"><span id="8a5d" class="ld jv hi kz b fi le lf l lg lh">cf.mars</span><span id="c7ff" class="ld jv hi kz b fi li lf l lg lh">&gt; Confusion Matrix and Statistics</span><span id="6215" class="ld jv hi kz b fi li lf l lg lh">Reference<br/>Prediction negative positive<br/>  negative     4403     2880<br/>  positive     1456     2510<br/>                                               <br/>               Accuracy : 0.6145               <br/>                 95% CI : (0.6055, 0.6236)     <br/>    No Information Rate : 0.5208               <br/>    P-Value [Acc &gt; NIR] : &lt; 0.00000000000000022<br/>                                               <br/>                  Kappa : 0.2195               <br/>                                               <br/> Mcnemar's Test P-Value : &lt; 0.00000000000000022<br/>                                               <br/>            Sensitivity : 0.4657               <br/>            Specificity : 0.7515               <br/>         Pos Pred Value : 0.6329               <br/>         Neg Pred Value : 0.6046               <br/>             Prevalence : 0.4792               <br/>         Detection Rate : 0.2231               <br/>   Detection Prevalence : 0.3526               <br/>      Balanced Accuracy : 0.6086               <br/>                                               <br/>       'Positive' Class : positive</span></pre><h2 id="7dbc" class="ld jv hi bd jw lj lk ll ka lm ln lo ke iq lp lq ki iu lr ls km iy lt lu kq lv bi translated">随机森林</h2><p id="1d6a" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">我最喜欢的算法之一，也是最讨厌的(RAM killer af)。这个又爱又恨的模型需要对列名进行特殊处理。像<em class="jd">这样的列名break，for，next，if </em>被认为是特殊字符，因此在构建随机森林和模型调优时会出现错误。</p><pre class="jf jg jh ji fd ky kz la lb aw lc bi"><span id="db69" class="ld jv hi kz b fi le lf l lg lh">## i store the train and test data to new variabel so the old one remain reproducible<br/>train_tune &lt;- train<br/>test_tune &lt;- test</span><span id="1fb2" class="ld jv hi kz b fi li lf l lg lh">colnames(train_tune) &lt;- make.names(colnames(train_tune))<br/>colnames(test_tune) &lt;- make.names(colnames(test_tune))</span><span id="367b" class="ld jv hi kz b fi li lf l lg lh"># build 5 folds cross validation for tuning evaluationn<br/>set.seed(1502)<br/>folds &lt;- vfold_cv(train_tune, 3)</span></pre><p id="1a40" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在我们更改了列名(改为:更改特殊字符)之后，我们将像以前一样构建模型。</p><pre class="jf jg jh ji fd ky kz la lb aw lc bi"><span id="40f6" class="ld jv hi kz b fi le lf l lg lh"># Train Random Forest model<br/>mod.rf &lt;- rand_forest(trees = 500, mtry = 5, mode = "classification") %&gt;%<br/>  set_engine("ranger") %&gt;% fit(labelY~., data = train_tune)</span><span id="bd7a" class="ld jv hi kz b fi li lf l lg lh">pred.rf &lt;- predict(mod.rf, test_tune, <br/>                   type = "class")</span><span id="966b" class="ld jv hi kz b fi li lf l lg lh"># build dataframe for prediction result<br/>pred.rf.x &lt;- as.data.frame(cbind(pred.rf, test_tune$labelY)) %&gt;%<br/>  setNames(c("pred","actual"))</span><span id="31fe" class="ld jv hi kz b fi li lf l lg lh"># create confusion matrix<br/>cf.rf &lt;- confusionMatrix(data = pred.rf.x$pred,<br/>                         reference = pred.rf.x$actual,<br/>                         positive = "positive")</span></pre><p id="dd81" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是随机森林模型的结果:</p><pre class="jf jg jh ji fd ky kz la lb aw lc bi"><span id="40dd" class="ld jv hi kz b fi le lf l lg lh">cf.rf</span><span id="2a25" class="ld jv hi kz b fi li lf l lg lh">&gt; Confusion Matrix and Statistics</span><span id="5a86" class="ld jv hi kz b fi li lf l lg lh">Reference<br/>Prediction negative positive<br/>  negative     4140     2019<br/>  positive     1719     3371<br/>                                               <br/>               Accuracy : 0.6677               <br/>                 95% CI : (0.6589, 0.6764)     <br/>    No Information Rate : 0.5208               <br/>    P-Value [Acc &gt; NIR] : &lt; 0.00000000000000022<br/>                                               <br/>                  Kappa : 0.3328               <br/>                                               <br/> Mcnemar's Test P-Value : 0.000001006          <br/>                                               <br/>            Sensitivity : 0.6254               <br/>            Specificity : 0.7066               <br/>         Pos Pred Value : 0.6623               <br/>         Neg Pred Value : 0.6722               <br/>             Prevalence : 0.4792               <br/>         Detection Rate : 0.2997               <br/>   Detection Prevalence : 0.4525               <br/>      Balanced Accuracy : 0.6660               <br/>                                               <br/>       'Positive' Class : positive</span></pre><p id="1f3c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从上面所有的混淆矩阵可以看出，随机森林模型的准确率最高。遗憾的是，我对结果不满意。最高准确率只有66.75%。我将尝试为随机森林模型做模型调整，希望我们能得到一个更好的结果。</p><h1 id="fa46" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">随机森林的模型调整</h1><p id="2bce" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">在随机森林中，我们可以做一些参数调整，如<em class="jd">树</em>和<em class="jd">树参数</em>。这一次，我们将对树的数量进行网格调整，并根据给定的数量进行排序。我们将用3 k倍交叉验证进行4次网格搜索。</p><pre class="jf jg jh ji fd ky kz la lb aw lc bi"><span id="fa14" class="ld jv hi kz b fi le lf l lg lh"># specify the grid for both parameter<br/>rf.grid &lt;- expand.grid(trees = c(450,500,550,600), mtry = 3:6)</span><span id="47fe" class="ld jv hi kz b fi li lf l lg lh">rf.setup &lt;- rand_forest(trees = tune(), mtry = tune()) %&gt;%<br/>  set_engine("ranger") %&gt;%<br/>  set_mode("classification")</span><span id="20f2" class="ld jv hi kz b fi li lf l lg lh"># this tuning takes a very lot of time. if you do this in your PC, please be patient and make sure your machine have at least 8gb of RAM <br/>rf.tune &lt;- tune_grid(labelY~., model = rf.setup, resamples = folds, grid = rf.grid, metrics = metric_set(accuracy, sens, spec))</span></pre><p id="3097" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">调谐需要很多时间。调优后，我知道最佳结果的参数是<em class="jd">树</em> = 6和<em class="jd">树</em> = 550。然后，我们将使用这些参数重建模型，进行预测(测试数据)，并为以后的评估创建混淆矩阵。</p><pre class="jf jg jh ji fd ky kz la lb aw lc bi"><span id="8713" class="ld jv hi kz b fi le lf l lg lh"># specify best parameter<br/>best.rfX &lt;- rf.tune %&gt;% select_best("accuracy", maximize = F)</span><span id="2e87" class="ld jv hi kz b fi li lf l lg lh">#rebuild the model<br/>mod.rf.2X &lt;- rf.setup %&gt;% finalize_model(parameters = best.rfX)<br/>mod.rf.2.new &lt;- mod.rf.2X %&gt;% fit(labelY~., data = train_tune)</span><span id="0fcd" class="ld jv hi kz b fi li lf l lg lh"># predict new model to test data<br/>pred.rf.2 &lt;- predict(mod.rf.2.x, test_tune, <br/>                   type = "class")</span><span id="d412" class="ld jv hi kz b fi li lf l lg lh"># build dataframe for prediction result<br/>pred.rf.2.x &lt;- as.data.frame(cbind(pred.rf.2, test_tune$labelY)) %&gt;%<br/>  setNames(c("pred","actual"))</span><span id="221b" class="ld jv hi kz b fi li lf l lg lh"># create confusion matrix<br/>cf.rf.2 &lt;- confusionMatrix(data = pred.rf.2.x$pred,<br/>                         reference = pred.rf.2.x$actual,<br/>                         positive = "positive")</span></pre><p id="9068" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从精确度66.7到66.9，我们的改进很小</p><p id="a5cb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我想还不错</p><h1 id="501f" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">模型评估和结论</h1><p id="8e61" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">让我们结合所有的混淆矩阵，使评估更容易</p><pre class="jf jg jh ji fd ky kz la lb aw lc bi"><span id="67a7" class="ld jv hi kz b fi le lf l lg lh">df.nb &lt;- data.frame(t(as.matrix(cf.nb, what = "classes")))<br/>df.nb &lt;- cbind(df.nb, data.frame(t(as.matrix(cf.nb,what = "overall"))))</span><span id="9de3" class="ld jv hi kz b fi li lf l lg lh">df.dt &lt;- data.frame(t(as.matrix(cf.dt, what = "classes")))<br/>df.dt &lt;- cbind(df.dt, data.frame(t(as.matrix(cf.dt,what = "overall"))))</span><span id="9ca8" class="ld jv hi kz b fi li lf l lg lh">df.mars &lt;- data.frame(t(as.matrix(cf.mars, what = "classes")))<br/>df.mars &lt;- cbind(df.mars, data.frame(t(as.matrix(cf.mars,what = "overall"))))</span><span id="82ff" class="ld jv hi kz b fi li lf l lg lh">df.rf &lt;- data.frame(t(as.matrix(cf.rf, what = "classes")))<br/>df.rf &lt;- cbind(df.rf, data.frame(t(as.matrix(cf.rf,what = "overall"))))</span><span id="4ae5" class="ld jv hi kz b fi li lf l lg lh">df.rf.2 &lt;- data.frame(t(as.matrix(cf.rf.2, what = "classes")))<br/>df.rf.2 &lt;- cbind(df.rf.2, data.frame(t(as.matrix(cf.rf.2,what = "overall"))))</span><span id="006a" class="ld jv hi kz b fi li lf l lg lh">all.eval &lt;- rbind(Naive_Bayes = df.nb, <br/>                  Decision_Tree = df.dt,<br/>                  Mars = df.mars,<br/>                  Random_Forest = df.rf,<br/>                  Random_Forest_tuned = df.rf.2) %&gt;%<br/>  select("Accuracy","Sensitivity","Specificity","Precision","F1") %&gt;% data.frame()</span></pre><p id="9f5a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面是结果截图:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lw"><img src="../Images/56a47f2e5e190c88349ca8ad86b9761b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7CYQnJQMARuOSTSKCE4OGg.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">图1:所有模型的度量结果</figcaption></figure><p id="a3f6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">由于在这种情况下没有紧迫性，我们将选择准确性作为解决这种情况的高优先级指标。如果用户不喜欢推荐的歌曲，他们可以很容易地删除或跳过，这不会影响我们的运营成本。悲伤歌曲播放列表中的积极歌曲不会伤害任何人，但如果我们试图避免它，它会更好。</p><p id="694e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从上表可以看出，<em class="jd">随机森林调优的</em>模型精度最高。如果我们尝试另一种分类模型，总是有可能获得更高的准确性(或其他指标)。我们以后会这么做的。因此，总之，<strong class="ih hj">我们将使用<em class="jd">随机森林</em>模型根据歌词来预测歌曲的情绪。</strong></p></div><div class="ab cl lx ly gp lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="hb hc hd he hf"><h1 id="d776" class="ju jv hi bd jw jx me jz ka kb mf kd ke kf mg kh ki kj mh kl km kn mi kp kq kr bi translated">预测新的给定歌词</h1><blockquote class="mj mk ml"><p id="4f45" class="if ig jd ih b ii ij ik il im in io ip mm ir is it mn iv iw ix mo iz ja jb jc hb bi translated">如果我有一句歌词不在数据集中，我可以用这个算法来预测它的情绪吗？</p></blockquote><h2 id="5493" class="ld jv hi bd jw lj lk ll ka lm ln lo ke iq lp lq ki iu lr ls km iy lt lu kq lv bi translated">是的，你可以</h2><p id="e144" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">我们只涵盖大约45k首歌曲。全世界有成千上万的歌曲，如果我们不能预测歌词的情绪，那真是太遗憾了。因此，在这里，我们将尝试构建一个函数来将一个普通的新歌词文本放入我们的模型中。在我们预测他们的情绪之前，数据会被自动清理。</p><p id="b075" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这里，我将使用《海贼王》OST开场3中一首名为“hikari e”(to the light)的歌曲作为样本。这首歌原本是日本的，但我翻译它来配合我们现有的模式。</p><pre class="jf jg jh ji fd ky kz la lb aw lc bi"><span id="8314" class="ld jv hi kz b fi le lf l lg lh"># new text lyric<br/>text &lt;- "I've just now begun to search, over the splashing waves<br/>For the everlasting world<br/>With this overflowing passion in my chest, I will go anywhere<br/>Seeking the light yet unseen.</span><span id="4a38" class="ld jv hi kz b fi li lf l lg lh">When  the summer sun shakes my heart's sail<br/>That's the signal to open the door to a new world<br/>Swaying on the waves, supassing my despair<br/>Aiming for the other side of the horizon.</span><span id="eae1" class="ld jv hi kz b fi li lf l lg lh">I've just now begun to search, over the splashing waves,<br/>For the everlasting world<br/>With this overflowing passion in my chest, I will go anywhere,<br/>Seeking the light yet unseen.</span><span id="93bd" class="ld jv hi kz b fi li lf l lg lh">A current of repetitious days and mundane clouds<br/>I see reflected in you a future you can't possibly know<br/>Even if I avoid pain by not changing<br/>That leaves me without dreams or even hope -- so let's go!.</span><span id="6d7f" class="ld jv hi kz b fi li lf l lg lh">Why am I searching?  What is it I want?<br/>The answer is surely somewhere ahead<br/>My heart will go on to the moving world<br/>Hiding my yet unseen strength.</span><span id="83af" class="ld jv hi kz b fi li lf l lg lh">Why am I searching?  What is it I want?<br/>Where is the yet unseen treasure?<br/>With this overflowing passion in my chest, how far can I go?<br/>I don't know, but</span><span id="2e7c" class="ld jv hi kz b fi li lf l lg lh">I've just now begun to search, over the splashing waves,<br/>For the everlasting world<br/>With this overflowing passion in my chest, I will go anywhere,<br/>Seeking the light yet unseen</span><span id="aef3" class="ld jv hi kz b fi li lf l lg lh">To the other side"</span></pre><p id="8a2c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">首先，我们需要把歌词转换成数据帧，就像我们以前的算法一样。我将使用<em class="jd">随机森林</em>模型来预测这首歌词，因为这是我们最好的模型。接下来，我们将构建自动清理歌词并将其转换为所需形状的函数。它只是将所有的清理步骤合并到一个函数中，并构建新的数据帧作为输出。它还将单词作为预测变量与训练数据中所需的列名(本例中为单词)进行匹配。</p><pre class="jf jg jh ji fd ky kz la lb aw lc bi"><span id="80ae" class="ld jv hi kz b fi le lf l lg lh">textcleaner &lt;- function(x){<br/>  x &lt;- as.character(x)<br/>  <br/>  x &lt;- x %&gt;%<br/>    str_to_lower() %&gt;%<br/>    replace_contraction() %&gt;%<br/>    replace_internet_slang() %&gt;%<br/>    replace_word_elongation() %&gt;%<br/>    replace_number(remove = T) %&gt;%<br/>    replace_date(replacement = "") %&gt;%<br/>    str_remove_all(pattern = "[[:punct:]]") %&gt;%<br/>    str_squish() %&gt;%<br/>    str_trim()<br/>  <br/>  xdtm &lt;- VCorpus(VectorSource(x)) %&gt;%<br/>    tm_map(removeWords, stopwords("en")) %&gt;%<br/>    tm_map(stemDocument) %&gt;% <br/>    DocumentTermMatrix(control = list(<br/>      dictionary = names(train_tune)<br/>    ))<br/>  <br/>  dfx &lt;- as.data.frame(as.matrix(xdtm), stringAsFactors=F)<br/>    <br/>}</span></pre><p id="dd4e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">之后，我们将应用该函数对歌词进行采样，并使用<em class="jd">随机森林</em>模型预测歌曲的情绪。</p><pre class="jf jg jh ji fd ky kz la lb aw lc bi"><span id="6901" class="ld jv hi kz b fi le lf l lg lh"># apply textcleaner function to sample text<br/>samptext &lt;- textcleaner(text)</span><span id="b7e1" class="ld jv hi kz b fi li lf l lg lh">predict(mod.rf.2.x,samptext)</span><span id="1e05" class="ld jv hi kz b fi li lf l lg lh">&gt; <br/>.pred_class<br/>&lt;fctr&gt;<br/>negative</span></pre><p id="4748" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">随机森林</em>模型预测歌词是一首消极情绪的歌曲。如果你听到真正的歌曲，它实际上是一首充满精神、活力和积极情绪的音乐，但我从来不知道歌词到底在说什么。</p><h2 id="c308" class="ld jv hi bd jw lj lk ll ka lm ln lo ke iq lp lq ki iu lr ls km iy lt lu kq lv bi translated">谢谢大家！</h2><p id="d845" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">想讨论请留言评论。我也接受所有的批评，这样我就能不断学习。</p><h1 id="cb96" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">参考</h1><ul class=""><li id="9dfb" class="mp mq hi ih b ii ks im kt iq mr iu ms iy mt jc mu mv mw mx bi translated"><a class="ae kx" href="https://github.com/western11/Lyric-Mood-Identifier" rel="noopener ugc nofollow" target="_blank">该项目的Github库</a></li><li id="f984" class="mp mq hi ih b ii my im mz iq na iu nb iy nc jc mu mv mw mx bi translated"><a class="ae kx" href="https://rpubs.com/jojoecp/612656" rel="noopener ugc nofollow" target="_blank"> Rpubs文档</a></li><li id="a09e" class="mp mq hi ih b ii my im mz iq na iu nb iy nc jc mu mv mw mx bi translated"><a class="ae kx" href="https://www.kaggle.com/joecristian/brief-lyric-s-mood-identifier" rel="noopener ugc nofollow" target="_blank"> Kaggle数据集和内核</a></li><li id="d606" class="mp mq hi ih b ii my im mz iq na iu nb iy nc jc mu mv mw mx bi translated"><a class="ae kx" href="https://algorit.ma/" rel="noopener ugc nofollow" target="_blank"> Algoritma </a>:我工作和学习数据科学的地方</li></ul></div></div>    
</body>
</html>