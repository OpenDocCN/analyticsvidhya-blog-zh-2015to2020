<html>
<head>
<title>Web Scraping using Selenium, BeautifulSoup</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用硒的网刮，美丽的Soup</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/web-scraping-using-selenium-beautifulsoup-a0bd87762a2c?source=collection_archive---------16-----------------------#2020-04-07">https://medium.com/analytics-vidhya/web-scraping-using-selenium-beautifulsoup-a0bd87762a2c?source=collection_archive---------16-----------------------#2020-04-07</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/f9eb136a1bf2c56656b7c0373770233e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*y2KgllBfjhytbugd"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">由<a class="ae iu" href="https://unsplash.com/@marvelous?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Marvin Meyer </a>在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="9603" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">作为一名数据科学家，收集数据是工作的一部分。</p><p id="dc70" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">有几种方法可以获得数据。如果你能从<a class="ae iu" href="https://www.kaggle.com/" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>得到一个数据集，那太好了！然而，有时数据并不是你想要的。数据可能在网站上，而你想要得到网站上的信息——介绍网络搜集！</p><p id="1bdc" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">Web抓取是从HTML页面获取内容的过程。我们正在使用的工具是<strong class="ix hj"> Selenium </strong>，它将打开一个浏览器并模拟javascript事件，例如点击事件、延迟加载等。</p><p id="2811" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">设置</strong></p><ol class=""><li id="ecfc" class="jt ju hi ix b iy iz jc jd jg jv jk jw jo jx js jy jz ka kb bi translated"><strong class="ix hj">安装硒</strong></li></ol><p id="0f86" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><code class="du kc kd ke kf b">pip3 install selenium</code></p><p id="ae27" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">或者</p><p id="6870" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><code class="du kc kd ke kf b">conda install selenium</code>在Jupyter笔记本上</p><p id="ee36" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">2.<strong class="ix hj">下载网络驱动</strong></p><p id="932c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">根据您想要使用的浏览器，您可以下载合适的web驱动程序。在本教程中，我将使用Chrome。因此，我下载了<a class="ae iu" href="https://chromedriver.chromium.org/" rel="noopener ugc nofollow" target="_blank"> chrome网络驱动。</a></p><p id="f03d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">3.<strong class="ix hj">从硒库进口</strong></p><pre class="kg kh ki kj fd kk kf kl km aw kn bi"><span id="e635" class="ko kp hi kf b fi kq kr l ks kt">from selenium import webdriver<br/>from selenium.webdriver.common.keys import Keys<br/>from selenium.webdriver.chrome.options import Options<br/>from selenium.webdriver.support.ui import WebDriverWait as wait<br/>from selenium.common.exceptions import TimeoutException</span></pre><p id="b190" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">4.<strong class="ix hj">设置驱动程序以打开浏览器</strong></p><p id="cfb2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在这个例子中，我将从一个流行的葡萄酒评论网站Vivino上抓取。</p><pre class="kg kh ki kj fd kk kf kl km aw kn bi"><span id="f9b7" class="ko kp hi kf b fi kq kr l ks kt">url = '<a class="ae iu" href="https://www.vivino.com/explore?e=eJwdyjkKgDAURdHdvFKMQ_k6dyBWIvKNMQSMShIcdq_Y3NNcH1hmNbzbqHJ4uVnl0A-7FvpLg4MKduEpwZkkK_aJQZLbbBzlNEGswc7ZRI0r9cM3_xSI1PICdrAezQ==" rel="noopener ugc nofollow" target="_blank">https://www.vivino.com/explore?e=eJwdyjkKgDAURdHdvFKMQ_k6dyBWIvKNMQSMShIcdq_Y3NNcH1hmNbzbqHJ4uVnl0A-7FvpLg4MKduEpwZkkK_aJQZLbbBzlNEGswc7ZRI0r9cM3_xSI1PICdrAezQ==</a>'</span><span id="4d77" class="ko kp hi kf b fi ku kr l ks kt">path = r'path of where the driver is located'<br/>driver = webdriver.Chrome(executable_path = path)<br/>driver.get(url)</span></pre><p id="b204" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">运行该程序将打开一个使用web驱动程序的浏览器。现在，您可以通过查看页面上的HTML来收集数据。</p><figure class="kg kh ki kj fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kv"><img src="../Images/9cd22105053e08ba54a855f8f91a67ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lxKkT4Q1FkWpLKTvvs4Eig.png"/></div></div></figure><figure class="kg kh ki kj fd ij er es paragraph-image"><div class="er es kw"><img src="../Images/6108066fd557ff0d393ebc9ddd27f6a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1318/format:webp/1*k7Fat9RwbsV7U9o8VdE1PA.png"/></div></figure><p id="19a6" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">美丽的风景</strong></p><p id="da12" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">BeautifulSoup是一个解析HTML数据的Python库。</p><pre class="kg kh ki kj fd kk kf kl km aw kn bi"><span id="1a47" class="ko kp hi kf b fi kq kr l ks kt">import copy<br/>from bs4 import BeautifulSoup</span><span id="2f84" class="ko kp hi kf b fi ku kr l ks kt">html = BeautifulSoup(driver.page_source, 'lxml')<br/>div = html.find("div", {"class": "explorerPage__results--3wqLw"})<br/>rows = html.find_all("div", {"class": "explorerCard__explorerCard--3Q7_0"})</span><span id="c2ba" class="ko kp hi kf b fi ku kr l ks kt">all_rows = []</span><span id="0083" class="ko kp hi kf b fi ku kr l ks kt"># Let's store each row as a dictionary <br/>empty_row = {<br/>    "title": None, "location": None, "price": 0.0, "type": None, "ratings": None, "num_ratings": None, "reviews": None, "url": None<br/>}</span><span id="617e" class="ko kp hi kf b fi ku kr l ks kt">for row in rows:<br/>    new_row = copy.copy(empty_row)<br/>    # A list of all the entries in the row.<br/>    new_row['title'] = row.find("span", {"class": "vintageTitle__wine--U7t9G"}).text<br/>    location = row.find("div", {"class": "vintageLocation__vintageLocation--1DF0p"})<br/>    new_row['location'] = location.findChildren()[-1].text<br/>    price_button = row.find("button", {"class": "addToCartButton__addToCartButton--qZv9F"})<br/>    if price_button:<br/>        new_row['price'] = (float(price_button.find("span").text.replace("$", "")))<br/>    new_row['type'] = 'Rosé'<br/>    new_row['ratings'] = row.find("div", {"class": "vivinoRatingWide__averageValue--1zL_5"}).text<br/>    new_row['num_ratings'] = int(row.find("div", {"class": "vivinoRatingWide__basedOn--s6y0t"}).text.split()[0])<br/>    review_div = row.find("div", {"class": "review__note--2b2DB"})<br/>    if review_div:<br/>        new_row['reviews'] = review_div.text<br/>    clean_div = row.find("div", {"class": "cleanWineCard__cleanWineCard--tzKxV cleanWineCard__row--CBPRR"})<br/>    if clean_div:<br/>        new_row['url'] = '<a class="ae iu" href="https://www.vivino.com'" rel="noopener ugc nofollow" target="_blank">https://www.vivino.com'</a> + clean_div.find("a")['href']<br/>    all_rows.append(new_row)</span></pre><p id="2714" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">以下是结果子集的示例:</p><pre class="kg kh ki kj fd kk kf kl km aw kn bi"><span id="5d4c" class="ko kp hi kf b fi kq kr l ks kt">[{'title': 'Estate Pinot Noir 2016',<br/>  'location': 'Willamette Valley',<br/>  'price': 38.95,<br/>  'type': 'Rosé',<br/>  'ratings': '4.6',<br/>  'num_ratings': 37,<br/>  'reviews': None,<br/>  'url': 'https://www.vivino.com/shea-wine-cellars-estate-pinot-noir/w/12513?year=2016&amp;price_id=20572438'},<br/> {'title': 'Petite Sirah 2016',<br/>  'location': 'Paso Robles',<br/>  'price': 39.95,<br/>  'type': 'Rosé',<br/>  'ratings': '4.6',<br/>  'num_ratings': 25,<br/>  'reviews': '“So smooth and a little brighter than I was expecting, but nonetheless wonderful.  Not overpowering and pretty much made for food.”',<br/>  'url': 'https://www.vivino.com/aaron-petite-sirah/w/1207985?year=2016&amp;price_id=20183451'},<br/> {'title': 'Las Alturas Vineyard Pinot Noir 2014',<br/>  'location': 'Santa Lucia Highlands',<br/>  'price': 36.99,<br/>  'type': 'Rosé',<br/>  'ratings': '4.5',<br/>  'num_ratings': 4516,<br/>  'reviews': '“Very very good. Almost like an Orrin swift take on Pinot. Intense sweet fruit. Quite dark for a Pinot and absolutely delicious ”',<br/>  'url': 'https://www.vivino.com/belle-glos-las-alturas-vineyard-pinot-noir/w/15239?year=2014&amp;price_id=20092711'},<br/> {'title': 'Clio 2017',<br/>  'location': 'Jumilla',<br/>  'price': 36.85,<br/>  'type': 'Rosé',<br/>  'ratings': '4.5',<br/>  'num_ratings': 569,<br/>  'reviews': '“A savory Spanish blend of 70% Monastrell and 30% Cab that’s spectacular!\nIntoxicating nose of blueberry, forest floor, plum and menthol. Flavor packed mouth of ripe berries, cherry pie, black licorice, and juicy plum.\nSmooth tannins for a youngster with a delicate brambly finish after a 30 minute decant.\nPairs great with Manchego cheese.\nA 4.3 rating from me but this will be special for years to come.\nEs el mejor mis amigos!!!”',<br/>  'url': 'https://www.vivino.com/el-nido-clio/w/1219218?year=2017&amp;price_id=20240187'},<br/> {'title': 'Cabernet Sauvignon 2018',<br/>  'location': 'Paso Robles',<br/>  'price': 39.89,<br/>  'type': 'Rosé',<br/>  'ratings': '4.5',<br/>  'num_ratings': 539,<br/>  'reviews': None,<br/>  'url': 'https://www.vivino.com/austin-hope-cabernet-sauvignon-paso-robles/w/5866389?year=2018&amp;price_id=20557366'},<br/> {'title': 'Las Alturas Vineyard Pinot Noir 2018',<br/>  'location': 'Santa Lucia Highlands',<br/>  'price': 34.99,<br/>  'type': 'Rosé',<br/>  'ratings': '4.5',<br/>  'num_ratings': 444,<br/>  'reviews': None,<br/>  'url': 'https://www.vivino.com/belle-glos-las-alturas-vineyard-pinot-noir/w/15239?year=2018&amp;price_id=20711583'},<br/> {'title': 'Dairyman Vineyard Pinot Noir 2018',<br/>  'location': 'Russian River Valley',<br/>  'price': 34.99,<br/>  'type': 'Rosé',<br/>  'ratings': '4.5',<br/>  'num_ratings': 203,<br/>  'reviews': None,<br/>  'url': 'https://www.vivino.com/belle-glos-dairyman-vineyard-pinot-noir/w/1561411?year=2018&amp;price_id=20468469'},<br/> {'title': "Zinfandel (Michael's Estate Vineyard) 2017",<br/>  'location': 'Paso Robles',<br/>  'price': 29.99,<br/>  'type': 'Rosé',<br/>  'ratings': '4.5',<br/>  'num_ratings': 39,<br/>  'reviews': None,<br/>  'url': 'https://www.vivino.com/adelaida-cellars-zinfandel-michael-s-estate-vineyard/w/2601471?year=2017&amp;price_id=20646768'}]</span></pre><p id="75f7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们试着分解一下:</p><pre class="kg kh ki kj fd kk kf kl km aw kn bi"><span id="523e" class="ko kp hi kf b fi kq kr l ks kt">import copy<br/>from bs4 import BeautifulSoup</span></pre><ul class=""><li id="4539" class="jt ju hi ix b iy iz jc jd jg jv jk jw jo jx js kx jz ka kb bi translated">我正在导入图书馆副本和BeautifulSoup</li></ul><pre class="kg kh ki kj fd kk kf kl km aw kn bi"><span id="8852" class="ko kp hi kf b fi kq kr l ks kt">html = BeautifulSoup(driver.page_source, 'lxml')</span></pre><ul class=""><li id="5e98" class="jt ju hi ix b iy iz jc jd jg jv jk jw jo jx js kx jz ka kb bi translated">这里我将页面源代码转换成一个html字符串</li></ul><pre class="kg kh ki kj fd kk kf kl km aw kn bi"><span id="9a9a" class="ko kp hi kf b fi kq kr l ks kt">div = html.find("div", {"class": "explorerPage__results--3wqLw"})<br/>rows = html.find_all("div", {"class": "explorerCard__explorerCard--3Q7_0"})</span></pre><ul class=""><li id="fa3a" class="jt ju hi ix b iy iz jc jd jg jv jk jw jo jx js kx jz ka kb bi translated">我从html中抓取div并保存到变量中。</li></ul><pre class="kg kh ki kj fd kk kf kl km aw kn bi"><span id="01f6" class="ko kp hi kf b fi kq kr l ks kt">rows = html.find_all("div", {"class": "explorerCard__explorerCard--3Q7_0"})</span></pre><p id="820b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在这个代码片段中，我查找所有具有类“explorer card _ _ explorer card—3q 7 _ 0”的div，并将其保存到一个变量行中。它将返回一个所有div的列表，这些div的类别为` explorer card _ _ explorer card—3q 7 _ 0 '</p><pre class="kg kh ki kj fd kk kf kl km aw kn bi"><span id="bfd5" class="ko kp hi kf b fi kq kr l ks kt">all_rows = []</span><span id="c906" class="ko kp hi kf b fi ku kr l ks kt"># Let's store each row as a dictionary <br/>empty_row = {<br/>    "title": None, "location": None, "price": 0.0, "type": None, "ratings": None, "num_ratings": None, "reviews": None, "url": None, "vintage": ""<br/>}</span></pre><ul class=""><li id="3796" class="jt ju hi ix b iy iz jc jd jg jv jk jw jo jx js kx jz ka kb bi translated">初始化一个空列表<code class="du kc kd ke kf b">all_rows</code>和一个空字典<code class="du kc kd ke kf b">empty_row</code>，引用字符串作为关键字，值为None。</li></ul><pre class="kg kh ki kj fd kk kf kl km aw kn bi"><span id="b753" class="ko kp hi kf b fi kq kr l ks kt">for row in rows:<br/>    new_row = copy.copy(empty_row)<br/>    # A list of all the entries in the row.<br/>    new_row['title'] = row.find("span", {"class": "vintageTitle__wine--U7t9G"}).text<br/>    location = row.find("div", {"class": "vintageLocation__vintageLocation--1DF0p"})<br/>    new_row['location'] = location.findChildren()[-1].text<br/>    price_button = row.find("button", {"class": "addToCartButton__addToCartButton--qZv9F"})<br/>    if price_button:<br/>        new_row['price'] = (float(price_button.find("span").text.replace("$", "")))<br/>    new_row['type'] = 'Rosé'<br/>    new_row['ratings'] = row.find("div", {"class": "vivinoRatingWide__averageValue--1zL_5"}).text<br/>    new_row['num_ratings'] = int(row.find("div", {"class": "vivinoRatingWide__basedOn--s6y0t"}).text.split()[0])<br/>    review_div = row.find("div", {"class": "review__note--2b2DB"})<br/>    if review_div:<br/>        new_row['reviews'] = review_div.text<br/>    clean_div = row.find("div", {"class": "cleanWineCard__cleanWineCard--tzKxV cleanWineCard__row--CBPRR"})<br/>    if clean_div:<br/>        new_row['url'] = '<a class="ae iu" href="https://www.vivino.com'" rel="noopener ugc nofollow" target="_blank">https://www.vivino.com'</a> + clean_div.find("a")['href']<br/>    all_rows.append(new_row)</span></pre><p id="0370" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在这个代码片段中，我们正在遍历rows变量(list)。对于每次迭代，我们将创建一个空字典的副本。对于代码片段的其余部分，我们寻找各自的div，获取文本并将其保存到字典的键值中。然后我们将它添加到我们的主列表<code class="du kc kd ke kf b">all_rows</code>。</p><p id="753c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">以下是代码组合:</p><pre class="kg kh ki kj fd kk kf kl km aw kn bi"><span id="38d4" class="ko kp hi kf b fi kq kr l ks kt">conda install selenium<br/>from selenium import webdriver<br/>from selenium.webdriver.common.keys import Keys<br/>from selenium.webdriver.chrome.options import Options<br/>from selenium.webdriver.support.ui import WebDriverWait as wait<br/>from selenium.common.exceptions import TimeoutException</span><span id="199c" class="ko kp hi kf b fi ku kr l ks kt">url = '<a class="ae iu" href="https://www.vivino.com/explore?e=eJwdyjkKgDAURdHdvFKMQ_k6dyBWIvKNMQSMShIcdq_Y3NNcH1hmNbzbqHJ4uVnl0A-7FvpLg4MKduEpwZkkK_aJQZLbbBzlNEGswc7ZRI0r9cM3_xSI1PICdrAezQ=='" rel="noopener ugc nofollow" target="_blank">https://www.vivino.com/explore?e=eJwdyjkKgDAURdHdvFKMQ_k6dyBWIvKNMQSMShIcdq_Y3NNcH1hmNbzbqHJ4uVnl0A-7FvpLg4MKduEpwZkkK_aJQZLbbBzlNEGswc7ZRI0r9cM3_xSI1PICdrAezQ=='</a><br/>path = r'/Users/#{user}/Desktop/chromedriver' (where the driver is located)<br/>driver = webdriver.Chrome(executable_path = path)<br/>driver.get(url)</span><span id="590e" class="ko kp hi kf b fi ku kr l ks kt">import copy<br/>from bs4 import BeautifulSoup<br/>html = BeautifulSoup(driver.page_source, 'lxml')<br/>div = html.find("div", {"class": "explorerPage__results--3wqLw"})<br/>rows = html.find_all("div", {"class": "explorerCard__explorerCard--3Q7_0"})<br/>all_rows = []<br/># Let's store each row as a dictionary <br/>empty_row = {<br/>    "title": None, "location": None, "price": 0.0, "type": None, "ratings": None, "num_ratings": None, "reviews": None, "url": None<br/>}<br/>for row in rows:<br/>    new_row = copy.copy(empty_row)<br/>    # A list of all the entries in the row.<br/>    new_row['title'] = row.find("span", {"class": "vintageTitle__wine--U7t9G"}).text<br/>    location = row.find("div", {"class": "vintageLocation__vintageLocation--1DF0p"})<br/>    new_row['location'] = location.findChildren()[-1].text<br/>    price_button = row.find("button", {"class": "addToCartButton__addToCartButton--qZv9F"})<br/>    if price_button:<br/>        new_row['price'] = (float(price_button.find("span").text.replace("$", "")))<br/>    new_row['type'] = 'Rosé'<br/>    new_row['ratings'] = row.find("div", {"class": "vivinoRatingWide__averageValue--1zL_5"}).text<br/>    new_row['num_ratings'] = int(row.find("div", {"class": "vivinoRatingWide__basedOn--s6y0t"}).text.split()[0])<br/>    review_div = row.find("div", {"class": "review__note--2b2DB"})<br/>    if review_div:<br/>        new_row['reviews'] = review_div.text<br/>    clean_div = row.find("div", {"class": "cleanWineCard__cleanWineCard--tzKxV cleanWineCard__row--CBPRR"})<br/>    if clean_div:<br/>        new_row['url'] = '<a class="ae iu" href="https://www.vivino.com'" rel="noopener ugc nofollow" target="_blank">https://www.vivino.com'</a> + clean_div.find("a")['href']<br/>    all_rows.append(new_row)</span></pre><p id="300e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">注:</strong></p><p id="dde9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">大多数网站都警惕机器人抓取他们的网站内容，所以在使用Selenium时要小心。如果你不小心，你的IP地址将被禁止。</p><p id="44e2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这就对了。你可以用Selenium来清理一个网站！</p></div></div>    
</body>
</html>