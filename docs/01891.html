<html>
<head>
<title>Get Started with spark based machine learning in Azure Synapse Analytics — Regression modelling.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">开始使用Azure Synapse Analytics中基于spark的机器学习—回归建模。</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/get-started-with-spark-based-machine-learning-in-synapse-analytics-regression-modelling-90e7dda1748e?source=collection_archive---------18-----------------------#2019-11-19">https://medium.com/analytics-vidhya/get-started-with-spark-based-machine-learning-in-synapse-analytics-regression-modelling-90e7dda1748e?source=collection_archive---------18-----------------------#2019-11-19</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="b0b9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">统一的分析工具，可摄取、计算或处理数据、存储数据、高级分析或机器学习，并在一个工具中显示所有内容。端到端数据分析平台专为扩展和易用性而构建。</p></div><div class="ab cl jd je gp jf" role="separator"><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji"/></div><div class="hb hc hd he hf"><figure class="jl jm jn jo fd jp er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es jk"><img src="../Images/00a8f1423e0bc94e41365dc3ac024ff2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9cdu8zoiIE5X3wttguHYrA.jpeg"/></div></div></figure><h1 id="ccff" class="jw jx hi bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">Synapse高级分析</h1><p id="36f1" class="pw-post-body-paragraph if ig hi ih b ii ku ik il im kv io ip iq kw is it iu kx iw ix iy ky ja jb jc hb bi translated">Synapse能够运行基于spark的代码，从而实现数据工程或特征工程以及机器学习。本文描述了如何在synapse中使用spark训练机器学习模型。</p><h1 id="57ae" class="jw jx hi bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">先决条件</h1><p id="9da2" class="pw-post-body-paragraph if ig hi ih b ii ku ik il im kv io ip iq kw is it iu kx iw ix iy ky ja jb jc hb bi translated">将上述培训文件上传到blob存储或ADLS Gen2。或者您可以使用synapse orchestrate特性将数据移动到Blob中。</p><p id="af4d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下载样本数据集。<a class="ae kz" href="https://dewsa.blob.core.windows.net/taxidata/train.csv" rel="noopener ugc nofollow" target="_blank">https://dewsa.blob.core.windows.net/taxidata/train.csv</a></p><pre class="jl jm jn jo fd la lb lc ld aw le bi"><span id="2b09" class="lf jx hi lb b fi lg lh l li lj">For my testing i was able to move the blob storage train.csv into ADLS gen2 filesystem. I did that for just to show how to move data inside synapse analytics.</span></pre><p id="51b3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">首先，让我们连接到数据存储以获取数据</p><p id="2ac8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是为了让spark版本运行起来。</p><pre class="jl jm jn jo fd la lb lc ld aw le bi"><span id="17a4" class="lf jx hi lb b fi lg lh l li lj">%%pyspark <br/>import pyspark <br/>print(print(pyspark.__version__))</span></pre><p id="3dde" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在让我们配置blob存储以获取数据:</p><pre class="jl jm jn jo fd la lb lc ld aw le bi"><span id="c1c7" class="lf jx hi lb b fi lg lh l li lj">spark.conf.set( "fs.azure.account.key.waginput.blob.core.windows.net", "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx")</span></pre><p id="813c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">将csv文件读入数据帧</p><pre class="jl jm jn jo fd la lb lc ld aw le bi"><span id="c71c" class="lf jx hi lb b fi lg lh l li lj">val df = spark.read.option("header","true").option("inferSchema","true").csv("wasbs://incoming@waginput.blob.core.windows.net/train.csv")</span></pre><p id="a3e3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">打印模式:</p><pre class="jl jm jn jo fd la lb lc ld aw le bi"><span id="5916" class="lf jx hi lb b fi lg lh l li lj">df.printSchema</span></pre><p id="3f08" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为机器学习建模设置功能列表:</p><pre class="jl jm jn jo fd la lb lc ld aw le bi"><span id="35b2" class="lf jx hi lb b fi lg lh l li lj">import org.apache.spark.ml.feature.VectorAssembler <br/>import org.apache.spark.ml.linalg.Vectors </span><span id="de58" class="lf jx hi lb b fi lk lh l li lj">val featureCols=Array("fare_amount","pickup_longitude","pickup_latitude","dropoff_longitude","dropoff_latitude","passenger_count") </span><span id="0b2c" class="lf jx hi lb b fi lk lh l li lj">val assembler: org.apache.spark.ml.feature.VectorAssembler= new VectorAssembler().setInputCols(featureCols).setOutputCol("features") </span><span id="27e8" class="lf jx hi lb b fi lk lh l li lj">val assembledDF = assembler.setHandleInvalid("skip").transform(df) </span><span id="b7c4" class="lf jx hi lb b fi lk lh l li lj">val assembledFinalDF = assembledDF.select("fare_amount","features")</span></pre><p id="f655" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">标准化数据帧:</p><pre class="jl jm jn jo fd la lb lc ld aw le bi"><span id="7495" class="lf jx hi lb b fi lg lh l li lj">import org.apache.spark.ml.feature.Normalizer <br/>val normalizedDF = new Normalizer().setInputCol("features").setOutputCol("normalizedFeatures").transform(assembledFinalDF)</span></pre><p id="a523" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">删除数据框中缺失的数据点:</p><pre class="jl jm jn jo fd la lb lc ld aw le bi"><span id="b48f" class="lf jx hi lb b fi lg lh l li lj">val normalizedDF1 = normalizedDF.na.drop()</span></pre><p id="1e04" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在分割数据集用于训练和测试。70%用于培训，30%用于测试</p><pre class="jl jm jn jo fd la lb lc ld aw le bi"><span id="8cbb" class="lf jx hi lb b fi lg lh l li lj">val Array(trainingDS, testDS) = normalizedDF1.randomSplit(Array(0.7, 0.3))</span></pre><p id="223a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">构建线性回归模型并执行它:</p><pre class="jl jm jn jo fd la lb lc ld aw le bi"><span id="9338" class="lf jx hi lb b fi lg lh l li lj">import org.apache.spark.ml.regression.LinearRegression</span><span id="4777" class="lf jx hi lb b fi lk lh l li lj">// Create a LinearRegression instance. This instance is an Estimator. <br/>val lr = new LinearRegression().setLabelCol("fare_amount").setMaxIter(100)</span><span id="8399" class="lf jx hi lb b fi lk lh l li lj">// Print out the parameters, documentation, and any default values. println(s"Linear Regression parameters:\n ${lr.explainParams()}\n") </span><span id="c415" class="lf jx hi lb b fi lk lh l li lj">// Learn a Linear Regression model. This uses the parameters stored in lr.<br/>val lrModel = lr.fit(trainingDS)</span><span id="78a4" class="lf jx hi lb b fi lk lh l li lj">// Make predictions on test data using the Transformer.transform() method.<br/>// LinearRegression.transform will only use the 'features' column. val lrPredictions = lrModel.transform(testDS)</span></pre><p id="bae9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">用测试数据测试模型:</p><pre class="jl jm jn jo fd la lb lc ld aw le bi"><span id="33ee" class="lf jx hi lb b fi lg lh l li lj">import org.apache.spark.sql.functions._ <br/>import org.apache.spark.sql.types._ <br/>println("\nPredictions : " ) </span><span id="a4be" class="lf jx hi lb b fi lk lh l li lj">lrPredictions.select($"fare_amount".cast(IntegerType),$"prediction".cast(IntegerType)).orderBy(abs($"prediction"-$"fare_amount")).distinct.show(15)</span></pre><p id="cd21" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在是评估模型的时候了:</p><pre class="jl jm jn jo fd la lb lc ld aw le bi"><span id="2e16" class="lf jx hi lb b fi lg lh l li lj">import org.apache.spark.ml.evaluation.RegressionEvaluator </span><span id="067d" class="lf jx hi lb b fi lk lh l li lj">val evaluator_r2 = new RegressionEvaluator().setPredictionCol("prediction").setLabelCol("fare_amount").setMetricName("r2") </span><span id="fdb1" class="lf jx hi lb b fi lk lh l li lj">//As the name implies, isLargerBetter returns if a larger value is better or smaller for evaluation. <br/>val isLargerBetter : Boolean = evaluator_r2.isLargerBetter </span><span id="3e5e" class="lf jx hi lb b fi lk lh l li lj">println("Coefficient of determination = " + evaluator_r2.evaluate(lrPredictions))</span></pre><p id="147f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">评估上述模型输出:</p><pre class="jl jm jn jo fd la lb lc ld aw le bi"><span id="34ed" class="lf jx hi lb b fi lg lh l li lj">//Evaluate the results. Calculate Root Mean Square Error val evaluator_rmse = new RegressionEvaluator().setPredictionCol("prediction").setLabelCol("fare_amount").setMetricName("rmse") </span><span id="2240" class="lf jx hi lb b fi lk lh l li lj">//As the name implies, isLargerBetter returns if a larger value is better for evaluation. <br/>val isLargerBetter1 : Boolean = evaluator_rmse.isLargerBetter </span><span id="ffae" class="lf jx hi lb b fi lk lh l li lj">println("Root Mean Square Error = " + evaluator_rmse.evaluate(lrPredictions))</span></pre><p id="ac88" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">模型已成功构建并执行。接下来是创建推理代码，并为生产构建推理过程</p></div><div class="ab cl jd je gp jf" role="separator"><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji"/></div><div class="hb hc hd he hf"><p id="97ba" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="ll">最初发表于</em><a class="ae kz" href="https://github.com/balakreshnan/synapseAnalytics/blob/master/SparkMLLinearReg.md" rel="noopener ugc nofollow" target="_blank">T5【https://github.com】</a><em class="ll">。</em></p></div></div>    
</body>
</html>