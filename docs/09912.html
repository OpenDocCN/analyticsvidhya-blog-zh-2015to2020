<html>
<head>
<title>Building A Text Analysis Web App With Medium Claps Prediction</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">构建一个具有中等评分预测的文本分析Web应用程序</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/building-a-text-analysis-web-app-with-medium-claps-prediction-2ce2d59153ef?source=collection_archive---------5-----------------------#2020-09-26">https://medium.com/analytics-vidhya/building-a-text-analysis-web-app-with-medium-claps-prediction-2ce2d59153ef?source=collection_archive---------5-----------------------#2020-09-26</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/a4d7854b24b265aaf069a3ac9af562ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v319BoxlFVS6lqTMS8L3mg.png"/></div></div></figure><figure class="iq ir is it fd ij"><div class="bz dy l di"><div class="iu iv l"/></div></figure><p id="c2ea" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated"><em class="ju">数据，数据，到处都是但没有一滴信息在眼前！</em></p><p id="1a5c" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated"><em class="ju">(…向柯勒律治道歉)</em></p><p id="ffd8" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated"><strong class="iy hj">与数字数据不同，你通常可以将数字数据归结为一些汇总统计数据，从中提取一些真知灼见，而文本数据则有点难以快速处理。</strong></p><p id="a35d" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">为了看看数据科学/ ML技术是否能帮助我提高写作水平，我构建了一个简单的基于Python Flask的web应用程序，它可以快速分析网页，以获得基于高级文本分析指标的快速见解。</p><p id="728e" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated"><strong class="iy hj">该应用程序会返回统计数据，如字数、句子数等，还会返回自然语言处理功能，如情感分析得分和可读性得分。利用其他人建立的预先训练好的模型，我还加入了预测作者性格类型的代码。该应用还具有“鼓掌预测器”功能，通过两种方法来估计预期的鼓掌次数——简单的线性回归预测模型(警告，准确性相当差)和使用文档嵌入矢量化的分类器(Doc2Vec) </strong></p><p id="4a69" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated"><strong class="iy hj">我已经在网上发布了代码，所以请随时给我留下一些反馈或复制我的回购并改进它(例如，构建您自己的自定义数据集并重新训练模型等)</strong></p><p id="8eb2" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated"><strong class="iy hj"> App演示网站:</strong><a class="ae jv" href="http://34.126.106.75:5000/" rel="noopener ugc nofollow" target="_blank">http://34.126.106.75:5000</a></p><p id="b338" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated"><em class="ju">2022年9月更新:自从我写这篇文章以来，已经有大约2年了，我已经决定关闭应用程序演示网站，因为低流量不值得在谷歌云上托管它的每月成本——如果我在下面得到足够多的评论，我可能会重新考虑；)</em></p><figure class="iq ir is it fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es jw"><img src="../Images/4b27339f1b03bfde9331a34a6eb5b9b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x6ZM-uw7a1CrkScXavaHWw.png"/></div></div><figcaption class="jx jy et er es jz ka bd b be z dx translated">网络应用位于:<a class="ae jv" href="http://34.126.113.131:5000/" rel="noopener ugc nofollow" target="_blank">http://34.126.113.131:5000</a></figcaption></figure><p id="2a46" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">你为什么要做这个？</p><p id="f8e8" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">几个月来，我一直在Medium.com上撰写与数据科学相关的主题，并努力思考如何最好地改进我的文章，提高我的鼓掌数/浏览量。所以我开始考虑是否可以使用ML或数据科学技术来帮助我写得更好。</p><p id="3115" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">有人工智能驱动的解决方案，如语法上的<a class="ae jv" href="https://www.grammarly.com/" rel="noopener ugc nofollow" target="_blank"/>(人工智能驱动的写作助手)。然而，我想我会从一个更小的目标开始，制作一个简单的web应用程序，它可以处理文本并返回一些关键指标。</p><p id="77b8" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">这篇文章介绍了我采取的步骤以及我的一些主要收获。我在下面放了一些代码片段，但完整的脚本可以在这里找到:</p><div class="kb kc ez fb kd ke"><a href="https://github.com/ZhijingEu/Text_Analyzer_FlaskWebApp" rel="noopener  ugc nofollow" target="_blank"><div class="kf ab dw"><div class="kg ab kh cl cj ki"><h2 class="bd hj fi z dy kj ea eb kk ed ef hh bi translated">ZhijingEu/Text _ Analyzer _ FlaskWebApp</h2><div class="kl l"><h3 class="bd b fi z dy kj ea eb kk ed ef dx translated">在GitHub上创建一个帐号，为ZhijingEu/Text _ Analyzer _ FlaskWebApp开发做贡献。</h3></div><div class="km l"><p class="bd b fp z dy kj ea eb kk ed ef dx translated">github.com</p></div></div><div class="kn l"><div class="ko l kp kq kr kn ks io ke"/></div></div></a></div><h1 id="ea4d" class="kt ku hi bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated"><strong class="ak">概要</strong></h1><p id="0e44" class="pw-post-body-paragraph iw ix hi iy b iz lr jb jc jd ls jf jg jh lt jj jk jl lu jn jo jp lv jr js jt hb bi translated"><a class="ae jv" href="#b711" rel="noopener ugc nofollow"> <strong class="iy hj"> 1。提取&amp;清理原始数据</strong>T3】</a></p><p id="a3e6" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated"><a class="ae jv" href="#a0c7" rel="noopener ugc nofollow">2<strong class="iy hj">。处理HTML/文本数据以提取关键指标</strong> </a></p><p id="63ad" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated"><a class="ae jv" href="#3b2b" rel="noopener ugc nofollow"> <strong class="iy hj"> 3。建立预测模型</strong> </a></p><p id="b108" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated"><a class="ae jv" href="#abf1" rel="noopener ugc nofollow"> <strong class="iy hj"> 3.1 .性格分析预测—迈尔斯·布里格斯类型指标</strong> </a></p><p id="de12" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated"><a class="ae jv" href="#20fd" rel="noopener ugc nofollow"> <strong class="iy hj"> 3.2 .性格分析预测—大五特质</strong> </a></p><p id="a1e5" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated"><a class="ae jv" href="#e48a" rel="noopener ugc nofollow"> <strong class="iy hj"> 3.3 .鼓掌计数估算器</strong> </a></p><p id="21db" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated"><a class="ae jv" href="#67f1" rel="noopener ugc nofollow"> <strong class="iy hj"> 3.3.1探索性数据分析</strong> </a></p><p id="8b2d" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated"><a class="ae jv" href="#2268" rel="noopener ugc nofollow"> <strong class="iy hj"> 3.3.2“简单”线性回归估计量</strong> </a></p><p id="30e2" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated"><a class="ae jv" href="#aff8" rel="noopener ugc nofollow"> <strong class="iy hj"> 3.3.3文档嵌入基础分类器</strong> </a></p><p id="002c" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated"><a class="ae jv" href="#8679" rel="noopener ugc nofollow"> <strong class="iy hj"> 4。将代码转换成一个简单的Flask App </strong> </a></p><p id="7758" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated"><a class="ae jv" href="#4855" rel="noopener ugc nofollow"> <strong class="iy hj"> 5。</strong>结论</a></p><h2 id="b711" class="lw ku hi bd kv lx ly lz kz ma mb mc ld jh md me lh jl mf mg ll jp mh mi lp mj bi translated">1.提取和清理数据</h2><figure class="iq ir is it fd ij er es paragraph-image"><div class="er es mk"><img src="../Images/5393331182d17cad37547c2ce3b6a61d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1202/format:webp/1*uQD2MwxXPEJDJ-MOtHSTNg.png"/></div><figcaption class="jx jy et er es jz ka bd b be z dx translated">来源:<a class="ae jv" href="https://www.alamy.com/stock-photo/paint-scraper.html" rel="noopener ugc nofollow" target="_blank">阿拉米</a></figcaption></figure><p id="484b" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">这相当简单，因为我使用Python的<a class="ae jv" href="https://requests.readthedocs.io/en/master" rel="noopener ugc nofollow" target="_blank"> Requests </a>库进行大部分的网络抓取</p><pre class="iq ir is it fd ml mm mn mo aw mp bi"><span id="a0de" class="lw ku hi mm b fi mq mr l ms mt">from bs4 import BeautifulSoup<br/>import urllib.request<br/>from urllib.request import Request, urlopen</span><span id="202f" class="lw ku hi mm b fi mu mr l ms mt">class ArticleExtract():</span><span id="7b81" class="lw ku hi mm b fi mu mr l ms mt">def __init__(self,url,text_input=False):<br/>        self.url = url<br/>        self.text_input= text_input # To allow for text input too</span><span id="7b1a" class="lw ku hi mm b fi mu mr l ms mt">#Set get_html and cleaned_text as properties as these get re-used by other functions</span><span id="5d06" class="lw ku hi mm b fi mu mr l ms mt"><a class="ae jv" href="http://twitter.com/property" rel="noopener ugc nofollow" target="_blank">@property</a><br/>def get_html(self):<br/>        user_agent_list = ['Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_5) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/13.1.1 Safari/605.1.15','Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:77.0) Gecko/20100101 Firefox/77.0','Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36','Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:77.0) Gecko/20100101 Firefox/77.0','Mozilla/5.0 (Windows NT 10.0; Win64;x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36',]</span><span id="65d9" class="lw ku hi mm b fi mu mr l ms mt">          if self.text_input==False:<br/>            for i in range(1,4):<br/>                #Pick a random user agent<br/>                user_agent = random.choice(user_agent_list)<br/>                #Set the headers <br/>                headers = {'User-Agent': user_agent}</span><span id="6392" class="lw ku hi mm b fi mu mr l ms mt">          req = Request(self.url, headers=headers)</span><span id="967f" class="lw ku hi mm b fi mu mr l ms mt">          self._get_html = urlopen(req).read()</span><span id="bf70" class="lw ku hi mm b fi mu mr l ms mt">          if self.text_input==True:<br/>                self._get_html = self.url<br/>                <br/>          return self._get_html<br/>...</span></pre><p id="ffb7" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">我首先创建了一个类，它接受文本或URL作为输入，并有一整套方法来处理数据和存储输出。(然而这个类对象最终变得臃肿，所以我不得不将其重构为Flask应用程序中的一组函数——稍后会详细介绍)</p><p id="e5d2" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">原始HTML中有各种各样的HTML标签。有很多方法可以移除这些标签，但是我用了漂亮的汤，它有一个有用的get_text函数和一个解析器，可以识别和去除标签</p><figure class="iq ir is it fd ij er es paragraph-image"><div class="er es mv"><img src="../Images/480728e0b941aeda71e3d4201204dc26.png" data-original-src="https://miro.medium.com/v2/resize:fit:596/format:webp/1*EuJ7e8XqDpKbtW0lYEzd2A.png"/></div><figcaption class="jx jy et er es jz ka bd b be z dx translated">图片来源:约翰·坦尼尔——在《爱丽丝梦游仙境》中，素甲鱼向爱丽丝讲述他美丽的汤的场景。</figcaption></figure><pre class="iq ir is it fd ml mm mn mo aw mp bi"><span id="a537" class="lw ku hi mm b fi mq mr l ms mt">class ArticleExtract():</span><span id="9fc9" class="lw ku hi mm b fi mu mr l ms mt">...</span><span id="7615" class="lw ku hi mm b fi mu mr l ms mt">def cleaned_text(htmlinput):<br/>    cleaned_text=BeautifulSoup(htmlinput, "html.parser").get_text("  ").replace("\r", " ").replace("\t", " ").replace("\n", " ").replace(u'\xa0', u' ')<br/>    return cleaned_text</span><span id="4b49" class="lw ku hi mm b fi mu mr l ms mt">...</span></pre><h2 id="a0c7" class="lw ku hi bd kv lx ly lz kz ma mb mc ld jh md me lh jl mf mg ll jp mh mi lp mj bi translated"><strong class="ak"> 2。处理数据</strong></h2><p id="70cc" class="pw-post-body-paragraph iw ix hi iy b iz lr jb jc jd ls jf jg jh lt jj jk jl lu jn jo jp lv jr js jt hb bi translated">我尝试从这两个商业网站复制功能，并以此为指导选择生成哪些文本分析指标</p><p id="d3ba" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated"><a class="ae jv" href="https://readable.com/" rel="noopener ugc nofollow" target="_blank">https://readable.com</a></p><p id="2283" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">https://seoscout.com/tools/keyword-analyzer<a class="ae jv" href="https://seoscout.com/tools/keyword-analyzer" rel="noopener ugc nofollow" target="_blank"/></p><p id="d667" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">然而，我也包括一些网页元数据，如出版日期，图像和嵌入式视频计数等</p><p id="f409" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">繁重的工作由<a class="ae jv" href="https://www.nltk.org/" rel="noopener ugc nofollow" target="_blank"> NLTK库</a>完成，它是我用于基本标记化步骤的主要工具，为许多其他后续函数提供信息。</p><div class="kb kc ez fb kd ke"><a href="https://www.guru99.com/tokenize-words-sentences-nltk.html" rel="noopener  ugc nofollow" target="_blank"><div class="kf ab dw"><div class="kg ab kh cl cj ki"><h2 class="bd hj fi z dy kj ea eb kk ed ef hh bi translated">用NLTK标记单词和句子</h2><div class="kl l"><h3 class="bd b fi z dy kj ea eb kk ed ef dx translated">什么是标记化？标记化是将大量文本分割成较小部分的过程，称为…</h3></div><div class="km l"><p class="bd b fp z dy kj ea eb kk ed ef dx translated">www.guru99.com</p></div></div><div class="kn l"><div class="mw l kp kq kr kn ks io ke"/></div></div></a></div><p id="c8aa" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">标记化是将文本分割成更小的块，如句子或单词，以满足许多其他文本指标。</p><pre class="iq ir is it fd ml mm mn mo aw mp bi"><span id="5c89" class="lw ku hi mm b fi mq mr l ms mt">class ArticleExtract():</span><span id="14bd" class="lw ku hi mm b fi mu mr l ms mt">...<a class="ae jv" href="http://twitter.com/property" rel="noopener ugc nofollow" target="_blank"><br/>@property</a><br/>def tokens_alpha(self):<br/>        raw = BeautifulSoup(self.get_html, 'html.parser').get_text(strip=True)<br/>        words = nltk.word_tokenize(raw)<br/>        self._tokens_alpha= [word for word in words if word.isalpha()] # or use option of := if word.isalnum()<br/>        return self._tokens_alpha<br/>...</span></pre><p id="59bd" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">值得一提的还有我用于情感分析的TextBlob库。</p><div class="kb kc ez fb kd ke"><a href="https://towardsdatascience.com/my-absolute-go-to-for-sentiment-analysis-textblob-3ac3a11d524" rel="noopener follow" target="_blank"><div class="kf ab dw"><div class="kg ab kh cl cj ki"><h2 class="bd hj fi z dy kj ea eb kk ed ef hh bi translated">我对情感分析的绝对依赖——text blob。</h2><div class="kl l"><h3 class="bd b fi z dy kj ea eb kk ed ef dx translated">使用文本块的情感分析。</h3></div><div class="km l"><p class="bd b fp z dy kj ea eb kk ed ef dx translated">towardsdatascience.com</p></div></div><div class="kn l"><div class="mx l kp kq kr kn ks io ke"/></div></div></a></div><p id="40bd" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">情感分析使用关键词分析来确定极性(陈述的消极或积极程度)和主观性(相对于基于中性事实的陈述，例如我认为…，你应该…，等等)。极性得分是一个浮动值，对于消极陈述在-100%范围内，对于积极陈述在+100%范围内。主观性评分有一个范围，0.0%非常客观，100%非常主观。</p><pre class="iq ir is it fd ml mm mn mo aw mp bi"><span id="e48d" class="lw ku hi mm b fi mq mr l ms mt">class ArticleExtract():</span><span id="1f59" class="lw ku hi mm b fi mu mr l ms mt">...<br/>def sentiment(self):<br/>        blob = TextBlob(self.cleaned_text)<br/>        split_text=blob.sentences<br/>        <br/>        df=pd.DataFrame((''.join(split_text[i]) for i in   <br/>        range(len(split_text))),columns=['Sentences'])<br/>        <br/>        df[["TextBlob_Polarity","TextBlob_Subjectivity"]]=<br/>        pd.DataFrame((split_text[i].sentiment for i in <br/>        range(len(split_text))))</span><span id="9bb0" class="lw ku hi mm b fi mu mr l ms mt">        df=df[df['Sentences'].map(len) &gt; 15] #Remove all short <br/>        sentences<br/>        #Avoid counting any sentences with Polarity 0 or    <br/>        Subjectivity 0 <br/>        <br/>        TextBlob_Overall_Polarity=df[df["TextBlob_Polarity"] != 0]<br/>        ['TextBlob_Polarity'].median()<br/>        <br/>        TextBlob_Overall_Subjectivity=df[df["TextBlob_Subjectivity"] <br/>        != 0]['TextBlob_Subjectivity'].median()<br/>        <br/>        return <br/>             TextBlob_Overall_Polarity,TextBlob_Overall_Subjectivity<br/>...</span></pre><p id="3175" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">对于可读性分析，有一系列令人眼花缭乱的不同方法，要么将文本与现有的“硬”单词列表进行比较，要么计算音节/句子/单词的长度。</p><div class="kb kc ez fb kd ke"><a href="https://en.wikipedia.org/wiki/Readability" rel="noopener  ugc nofollow" target="_blank"><div class="kf ab dw"><div class="kg ab kh cl cj ki"><h2 class="bd hj fi z dy kj ea eb kk ed ef hh bi translated">可读性</h2><div class="kl l"><h3 class="bd b fi z dy kj ea eb kk ed ef dx translated">可读性是指读者理解书面文本的难易程度。在自然语言中，文本的可读性…</h3></div><div class="km l"><p class="bd b fp z dy kj ea eb kk ed ef dx translated">en.wikipedia.org</p></div></div><div class="kn l"><div class="my l kp kq kr kn ks io ke"/></div></div></a></div><p id="5ba7" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">为了简单起见，我最终选定了一个叫做<a class="ae jv" href="https://readable.com/blog/the-flesch-reading-ease-and-flesch-kincaid-grade-level" rel="noopener ugc nofollow" target="_blank">Flesch Reading easy Score</a>的单一指标，我使用一个叫做<a class="ae jv" href="https://pypi.org/project/textstat" rel="noopener ugc nofollow" target="_blank"> Textstat </a>的库来估算这个指标</p><p id="e92b" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">它是使用一个公式计算的，该公式考虑了平均句子长度和每个单词的平均音节数，分数越高，文本越容易阅读(例如，&gt; 90 =非常容易，&lt; 30 =非常混乱)</p><pre class="iq ir is it fd ml mm mn mo aw mp bi"><span id="6549" class="lw ku hi mm b fi mq mr l ms mt">class ArticleExtract():</span><span id="946a" class="lw ku hi mm b fi mu mr l ms mt">...<br/>def FS_ReadingEaseScore(self):<br/>        <br/>       FS_GradeScore=textstat.flesch_reading_ease(self.cleaned_text)<br/>        return FS_GradeScore<br/>...</span></pre><p id="b4aa" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">在最初的两个步骤中，我遇到的一个问题是我得到的数据的准确性。我最终创建了一个函数来逐句查看结果，我发现我的原始数据没有被适当地“清洗”</p><p id="53d2" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated"><strong class="iy hj"> <em class="ju">第一课:</em> </strong> <em class="ju"> </em> <strong class="iy hj"> <em class="ju">做</em> </strong> <em class="ju"> </em> <strong class="iy hj"> <em class="ju">不要低估适当清理html文本的重要性</em> </strong>。比如我最初用BeautifulSoup.get_text()清理HTML标签<a class="ae jv" href="https://stackoverflow.com/questions/16767405/beautifulsoup-concatenating-words" rel="noopener ugc nofollow" target="_blank">而不是。get _ text(" "</a>)。因此我得到了这样的废话:—</p><pre class="iq ir is it fd ml mm mn mo aw mp bi"><span id="9438" class="lw ku hi mm b fi mq mr l ms mt">BeautifulSoup('&lt;span&gt;this is a&lt;/span&gt;cat').text<br/>Output : u'this is acat</span></pre><p id="65ca" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">这意味着我总是无意中把单词连接在一起，之后所有依赖于“清理文本”的东西都是错误的——例如，它增加了句子长度，使可读性分数更差，混淆了情感分析等。其他区域是像含有“-”或“-”字符的句子或表格/列表，这取决于它们在html中的设置，可能会以乱码结束，并增加句子数量。</p><h2 id="3b2b" class="lw ku hi bd kv lx ly lz kz ma mb mc ld jh md me lh jl mf mg ll jp mh mi lp mj bi translated">3.构建预测模型</h2><h2 id="82c3" class="lw ku hi bd kv lx ly lz kz ma mb mc ld jh md me lh jl mf mg ll jp mh mi lp mj bi translated">人格分析</h2><figure class="iq ir is it fd ij er es paragraph-image"><div class="er es mz"><img src="../Images/e88614d70278fc8f12b6388285799b71.png" data-original-src="https://miro.medium.com/v2/resize:fit:1012/format:webp/1*fSRSPklKgRAVgXtaBxdJWQ.png"/></div><figcaption class="jx jy et er es jz ka bd b be z dx translated"><a class="ae jv" href="https://www.123rf.com/stock-photo/personality.html?sti=n77f19hiwbf8wti7ho|" rel="noopener ugc nofollow" target="_blank">来源:123RF库存照片</a></figcaption></figure><p id="bf6a" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">虽然严格来说，性格分析本身并不是文本分析的一部分，但我认为这将是该应用程序的一个有趣的补充。我最初想开发自己的模型，但这比我预期的要多一点，所以我从一些作者发布在网上的作品改编而来。</p><h2 id="abf1" class="lw ku hi bd kv lx ly lz kz ma mb mc ld jh md me lh jl mf mg ll jp mh mi lp mj bi translated"><strong class="ak"> 3.1 Myers Briggs型指示器</strong></h2><p id="cbd3" class="pw-post-body-paragraph iw ix hi iy b iz lr jb jc jd ls jf jg jh lt jj jk jl lu jn jo jp lv jr js jt hb bi translated">Myers-Briggs Type Indicator(MBTI)试图解释人们如何感知世界和做出决定，并将人们分为四类:内向或外向、感知或直觉、思考或感觉、判断或感知。从每个类别中抽取一个字母，产生一个四个字母的测试结果，如“INFJ”或“ENFP”。</p><p id="9baa" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">我对下面文章中的代码进行了逆向工程，并将他们预先训练好的模型(这是一个逻辑回归模型)加载到我的应用程序中。</p><div class="kb kc ez fb kd ke"><a href="https://towardsdatascience.com/text-analytics-what-does-your-linkedin-profile-summary-say-about-your-personality-f80df46875d1" rel="noopener follow" target="_blank"><div class="kf ab dw"><div class="kg ab kh cl cj ki"><h2 class="bd hj fi z dy kj ea eb kk ed ef hh bi translated">文本分析:关于你的个性，你的LinkedIn个人资料摘要说明了什么？</h2><div class="kl l"><h3 class="bd b fi z dy kj ea eb kk ed ef dx translated">使用自然语言处理技术来预测你的性格。</h3></div><div class="km l"><p class="bd b fp z dy kj ea eb kk ed ef dx translated">towardsdatascience.com</p></div></div><div class="kn l"><div class="na l kp kq kr kn ks io ke"/></div></div></a></div><p id="fe44" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">这篇文章本身值得一读，因为他们的整个项目用几个主要咨询公司的网络搜索LinkedIn个人资料来测试模型，以检查在那里工作的人是否有模式。</p><h2 id="20fd" class="lw ku hi bd kv lx ly lz kz ma mb mc ld jh md me lh jl mf mg ll jp mh mi lp mj bi translated">3.2大五人格分析</h2><p id="cdc9" class="pw-post-body-paragraph iw ix hi iy b iz lr jb jc jd ls jf jg jh lt jj jk jl lu jn jo jp lv jr js jt hb bi translated">同样，另一种流行的性格分析方法是<a class="ae jv" href="https://en.wikipedia.org/wiki/Big_Five_personality_traits" rel="noopener ugc nofollow" target="_blank">五大特质</a>模型(有时也称为O.C.E.A.N模型)，它是五种主要性格特征的组合:</p><ul class=""><li id="ce76" class="nb nc hi iy b iz ja jd je jh nd jl ne jp nf jt ng nh ni nj bi translated">对经验持开放态度(创新/好奇与一致/谨慎)</li><li id="13d3" class="nb nc hi iy b iz nk jd nl jh nm jl nn jp no jt ng nh ni nj bi translated">责任心(高效/有条理与奢侈/粗心)</li><li id="7efb" class="nb nc hi iy b iz nk jd nl jh nm jl nn jp no jt ng nh ni nj bi translated">外向性(外向/精力充沛对孤独/保守)</li><li id="7a53" class="nb nc hi iy b iz nk jd nl jh nm jl nn jp no jt ng nh ni nj bi translated">宜人性(友好/富有同情心与挑战性/冷酷无情)</li><li id="5c38" class="nb nc hi iy b iz nk jd nl jh nm jl nn jp no jt ng nh ni nj bi translated">神经质(敏感/紧张与坚韧/自信)</li></ul><p id="e324" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">我使用了来自该项目资源库的预训练模型(它是随机森林回归器和随机森林分类器的组合):</p><div class="kb kc ez fb kd ke"><a href="https://github.com/jcl132/personality-prediction-from-text" rel="noopener  ugc nofollow" target="_blank"><div class="kf ab dw"><div class="kg ab kh cl cj ki"><h2 class="bd hj fi z dy kj ea eb kk ed ef hh bi translated">JCL 132/从文本预测个性</h2><div class="kl l"><h3 class="bd b fi z dy kj ea eb kk ed ef dx translated">该项目旨在使用各种机器学习模型从文本样本中预测大5人格特征。一个…</h3></div><div class="km l"><p class="bd b fp z dy kj ea eb kk ed ef dx translated">github.com</p></div></div><div class="kn l"><div class="np l kp kq kr kn ks io ke"/></div></div></a></div><p id="5596" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">在我的应用程序中，我只使用他们预先训练好的模型进行预测。然而，整个项目的范围令人印象深刻，因为它集成了Python、Django和Node JS，后者可以抓取你的FB数据，将其存储在数据库实例(可以是你自己的私有实例)上，并在定制的web应用程序上显示所有结果，该应用程序可以将你朋友的所有个性特征与你自己的进行比较。</p><p id="9a1a" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">因此，对于这一部分，我的主要收获是:-</p><p id="b9ff" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated"><strong class="iy hj"> <em class="ju">第二课:在适当的情况下，利用他人的作品</em> </strong> <em class="ju">(假设它是公开的，并且你给了原作者应有的荣誉；-) </em>我在之前的一篇文章中已经谈到了这个主题<a class="ae jv" rel="noopener" href="/analytics-vidhya/building-an-amateur-machine-learning-web-app-what-i-learnt-d6a89bddb025#0e41">，但它值得重复——如果您可以定义您需要什么，并意识到价格与性能/支持级别/文档之间的潜在权衡——很可能已经有一个服务或一些开源项目已经有了解决方案。</a></p><h2 id="e48a" class="lw ku hi bd kv lx ly lz kz ma mb mc ld jh md me lh jl mf mg ll jp mh mi lp mj bi translated"><strong class="ak"> 3.3。鼓掌预测</strong></h2><p id="a2f6" class="pw-post-body-paragraph iw ix hi iy b iz lr jb jc jd ls jf jg jh lt jj jk jl lu jn jo jp lv jr js jt hb bi translated">对于clap预测，我可以采取类似的“复制并适应”方法，因为有相当多的关于这个主题的好文章<a class="ae jv" rel="noopener" href="/analytics-vidhya/how-to-maximize-claps-on-your-medium-articles-ce427cf327ff">【1】</a><a class="ae jv" href="https://www.kaggle.com/c/how-good-is-your-medium-article" rel="noopener ugc nofollow" target="_blank">【2】</a><a class="ae jv" rel="noopener" href="/dataseries/building-a-data-science-model-to-predict-a-successful-medium-article-f2458c30a14f">【3】</a>和<a class="ae jv" rel="noopener" href="/free-code-camp/how-to-predict-likes-and-shares-based-on-your-articles-title-using-machine-learning-47f98f0612ea">【4】</a>。然而，这个挑战非常有趣，我想亲自尝试一下。</p><figure class="iq ir is it fd ij er es paragraph-image"><div class="er es nq"><img src="../Images/27ec9e80a1cd9f9f3a84abccafa2433e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1258/format:webp/1*gSfYiALT6Ky2Id29EXz9rg.png"/></div><figcaption class="jx jy et er es jz ka bd b be z dx translated"><a class="ae jv" href="https://www.dreamstime.com/illustration/clap-hands-cartoon.html" rel="noopener ugc nofollow" target="_blank">来源:Dreamstime股票照片</a></figcaption></figure><h2 id="67f1" class="lw ku hi bd kv lx ly lz kz ma mb mc ld jh md me lh jl mf mg ll jp mh mi lp mj bi translated">探索性数据分析</h2><p id="ac41" class="pw-post-body-paragraph iw ix hi iy b iz lr jb jc jd ls jf jg jh lt jj jk jl lu jn jo jp lv jr js jt hb bi translated">为了跟进，在repo中使用<a class="ae jv" href="https://github.com/ZhijingEu/Text_Analyzer_FlaskWebApp/blob/master/02_Exploratory_Data_Analysis.ipynb" rel="noopener ugc nofollow" target="_blank">exploratorydataanalysis . ipynb</a>文件。</p><p id="809b" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">我使用在步骤2中构建的脚本从<a class="ae jv" href="https://towardsdatascience.com" rel="noopener" target="_blank">的首页获取了大约200篇文章，分别是《走向数据科学</a>和<a class="ae jv" href="https://medium.com/analytics-vidhya" rel="noopener">分析Vidhya </a>。这篇文章的URL-s和Clap计数是使用<a class="ae jv" href="https://www.parsehub.com" rel="noopener ugc nofollow" target="_blank"> Parsehub </a>(我在以前的文章中介绍过的一个漂亮的工具<a class="ae jv" rel="noopener" href="/analytics-vidhya/building-an-amateur-machine-learning-web-app-what-i-learnt-d6a89bddb025#dede">)(<em class="ju">我知道我本来可以在Python中完成这项工作，但是在花了几个小时摆弄Beautiful Soup之后，我放弃了</em></a><a class="ae jv" href="https://selenium-python.readthedocs.io/" rel="noopener ugc nofollow" target="_blank"><em class="ju">Selenium</em></a><em class="ju">库——分页很难，好吗？</em>)</p><p id="e559" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">我知道200作为一个数据集是很小的，但我想从一个小的“精选”数据集开始，这样我可以对模型的行为有更好的感觉。不幸的是，我后来发现大多数头版特色文章都是最近发表的(结果鼓掌次数通常只有三位数，因为文章还没有时间“成熟”)，所以我实际上最终得到了一个有点不平衡的数据集。我还偷偷看了一些“精选”的2018/ 2019年末文章，以了解年龄和鼓掌数量的变化。(不过，请注意，这种过度呈现新文章的问题将会回来，并在@ss中咬我一口，稍后您将会看到)</p><figure class="iq ir is it fd ij er es paragraph-image"><div class="er es nr"><img src="../Images/2423c2383f36aaafdce6e0c25a005ade.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*4U0NiqQhUie8p3xjCmisPQ.png"/></div></figure><p id="4dcb" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">大多数文章都属于鼓掌次数少的类别，只有少数文章(大部分是老文章)鼓掌次数多。</p><figure class="iq ir is it fd ij er es paragraph-image"><div class="er es ns"><img src="../Images/e17839a08a244307fd5c7f98e2f8f40d.png" data-original-src="https://miro.medium.com/v2/resize:fit:760/format:webp/1*ajb9W5yyq7MxGL3OlG_z_g.png"/></div><figcaption class="jx jy et er es jz ka bd b be z dx translated">在200篇文章中，超过3/4的文章的点击率低于5000次…</figcaption></figure><p id="b501" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">鉴于鼓掌数量中的这种“幂律”类型行为，我创建了一个Log鼓掌计数指标，因为我认为这是一个更好的衡量标准。我最初运行了一个简单的Pearson相关来理解各种指标，并查看是否有一个模式或与Log Clap计数的任何强相关。结果是不确定的，因为显示强相关性的唯一指标是:-</p><ul class=""><li id="2faf" class="nb nc hi iy b iz ja jd je jh nd jl ne jp nf jt ng nh ni nj bi translated">年龄(从发表日期开始)——这确实有道理，因为旧文章往往有更多的观点，但这是一个不完整的画面，因为显然肯定有其他因素在起作用，如果不是所有的旧文章都有高掌声</li></ul><figure class="iq ir is it fd ij er es paragraph-image"><div class="er es nt"><img src="../Images/fe04c93a5b38b4e0ee10d46f19a14a0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:764/format:webp/1*cFXW839zu0Nso4uHFybDPw.png"/></div><figcaption class="jx jy et er es jz ka bd b be z dx translated">相关性:0.534</figcaption></figure><ul class=""><li id="bb64" class="nb nc hi iy b iz ja jd je jh nd jl ne jp nf jt ng nh ni nj bi translated">句子数量和单词数量——这是反直觉的，因为它似乎表明句子越多，文章越长，掌声就越多？</li></ul><figure class="iq ir is it fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nu"><img src="../Images/747e89fd30c3634682d19a086c3d793e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0Uh7K3BQx9LLM8gd_7oHBg.png"/></div></div></figure><p id="04f9" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">我就不说其他图表了，但令我惊讶的是，像极性或主观性、可读性分数和大多数个性分数的绝对值都小于0.20。</p><p id="b0bb" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">为了帮助我以不同的方式查看数据，并更好地可视化一些可能扭曲相关性的异常值，我还为Hi-Med-Lo clap计数制作了并排的盒图(有些随意地选择为H : &gt; 5k (37篇文章)，M : 5k-0.5k (58篇文章)，L : &lt; 0.5k Claps (105 Articles) ) against the total 200 articles</p><figure class="iq ir is it fd ij er es paragraph-image"><div class="er es nv"><img src="../Images/2d41e35959fc27bb548b52b603889e32.png" data-original-src="https://miro.medium.com/v2/resize:fit:826/format:webp/1*xo340QKlU4l3LyoU-Csomw.png"/></div></figure><p id="7a74" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">Using this box-plot type view, there does seem to be a weak relationship where Hi Clap articles tend to have a slightly higher FS Grade Score . This makes sense as a lower score means the text is harder to read. (Either that or my data or data processing was bad)</p><p id="50ed" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">While there was no discernable pattern between the Hi/Mid/Lo Clap articles by predicted MBTI personality types, it was interesting to see that the logistic regression model used for the MTBI classifier seems to think most of the total 200 articles were written by #-#-T-J type authors.</p><figure class="iq ir is it fd ij er es paragraph-image"><div class="er es nw"><img src="../Images/b1e05c25751427e459abde102f46e6c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:806/format:webp/1*b0_k_Nf50pNqWlxaM9Q9mA.png"/></div><figcaption class="jx jy et er es jz ka bd b be z dx translated">INTJ-s make up ~40% of all articles</figcaption></figure><p id="9600" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">There is more detail in the IPYNB notebook on the Github repo if you are interested but nothing of note.</p><p id="3092" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">At this point, if I were doing this seriously , I would have probably stopped and went back to re-examine the accuracy of the data processing steps and/or expand the size of the data-set. However since the “clap prediction" was ultimately only an add on feature to my main goal of building a simple text analysis app, I just went ahead with what I had.</p><h2 id="2268" class="lw ku hi bd kv lx ly lz kz ma mb mc ld jh md me lh jl mf mg ll jp mh mi lp mj bi translated">3.3.2 Clap Prediction Via A Linear Regression Model</h2><p id="a421" class="pw-post-body-paragraph iw ix hi iy b iz lr jb jc jd ls jf jg jh lt jj jk jl lu jn jo jp lv jr js jt hb bi translated">I used a very plain vanilla approach that in hindsight probably does not capture the actual relationships very well but I ran a number of linear regression approaches out of the SciKit learn toolkit with a hand-crafted set of features where I more or less just dropped the entire MTBI and Big5 Personality metrics (as most of these had low correlations anyway)</p><pre class="iq ir is it fd ml mm mn mo aw mp bi"><span id="8e18" class="lw ku hi mm b fi mq mr l ms mt">df = pd.read_excel('Dataset.xlsx')<br/>df['log_claps']=np.log(df.claps)</span><span id="a611" class="lw ku hi mm b fi mu mr l ms mt">#Regression Variables were "hand-picked" to exclude non numerical and both MTBI and Big5 OCEAN characteristics</span><span id="25ed" class="lw ku hi mm b fi mu mr l ms mt">column_for_regression=["Age_19Sep20","sentence_count","title_word_count","average_word_count_per_sentence","text_word_count","vocab_count_excl_commonwords","imgs_per_1000words","FS_GradeScore","vids_per_1000words","polarity","subjectivity"]</span><span id="3868" class="lw ku hi mm b fi mu mr l ms mt">X=df.loc[:, df.columns.intersection(column_for_regression)]<br/>y = df['log_claps']<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)</span><span id="209d" class="lw ku hi mm b fi mu mr l ms mt">lasso_alphas = 10**np.linspace(-5,0,1000)<br/>lasso_cv = LassoCV(alphas = lasso_alphas, cv=5)<br/>lasso_cv.fit(X_train, y_train)<br/>lasso_cv.alpha_<br/>lasso = Lasso(alpha=lasso_cv.alpha_)<br/>lasso.fit(X_train, y_train)<br/>predicted_claps_lasso = lasso.predict(X_test)<br/>lasso_mse = mean_squared_error(y_test, predicted_claps_lasso)<br/>r_sq = lasso.score(X_test, y_test)</span><span id="d764" class="lw ku hi mm b fi mu mr l ms mt">print("Lasso Regression")<br/>print("")<br/>print('coefficient of determination:', round(r_sq,3))<br/>print("")<br/>print('intercept:', lasso.intercept_)<br/>print("")<br/>print('slope:', lasso.coef_)<br/>print("")<br/>print('Mean Sq Error in Log Claps',lasso_mse)<br/>print("")<br/>print('Mean Sq Error in Claps',np.exp(lasso_mse))</span></pre><p id="35ec" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">Lasso Regression seemed to do better than the Ridge Regression and the basic un-regularised Linear Regression.</p><figure class="iq ir is it fd ij er es paragraph-image"><div class="er es nx"><img src="../Images/54cd62144eae099a2130b86fa07e8e22.png" data-original-src="https://miro.medium.com/v2/resize:fit:1246/format:webp/1*hF6xdTiYaD2itnmastza0g.png"/></div></figure><p id="76ee" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">So how well does it perform ? As you may expect — Not so great… :(</p><figure class="iq ir is it fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ny"><img src="../Images/1c916f21c74a989e8dd8529a30fae2aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nXXNdOaJy-ObpZEnzehL0w.png"/></div></div><figcaption class="jx jy et er es jz ka bd b be z dx translated">The straight-line is if Predicted = Actual (Note the scales are a bit misleading) so the further the dot is from the straight line, the worse the error</figcaption></figure><p id="2233" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">The errors are “blown up” because the regression is against Log Claps. The model seems to work okay for articles that were in actual fact less than 2,000 Claps but anything beyond that seems to fall over.</p><p id="0f50" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">Therefore my advice would be to apply this clap prediction for new-ish articles (6–9 mths old from publish date) — which coincidentally matches up with the majority of the training data-set anyway. (<em class="ju">几率是多少？！*讥讽* </em>)</p><h2 id="aff8" class="lw ku hi bd kv lx ly lz kz ma mb mc ld jh md me lh jl mf mg ll jp mh mi lp mj bi translated">3.3.2通过“分类”模型进行的Clap预测</h2><p id="5f78" class="pw-post-body-paragraph iw ix hi iy b iz lr jb jc jd ls jf jg jh lt jj jk jl lu jn jo jp lv jr js jt hb bi translated">在另一种方法中，我忽略了所有的文本度量，只关注(清理过的)文本的内容。要跟进使用repo中的<a class="ae jv" href="https://github.com/ZhijingEu/Text_Analyzer_FlaskWebApp/blob/master/03_Training_A_Doc2Vec_Model.ipynb" rel="noopener ugc nofollow" target="_blank">Training _ A _ doc 2 vec _ model . ipynb</a>文件。</p><p id="0518" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">有一种在自然语言处理中经常使用的技术叫做单词嵌入，其中你“矢量化”一个单词。我的解释可能过于简单，但它是通过一种算法来猜测给定周围单词(即上下文)的单词，并将该信息编码成多维向量来实现的。</p><p id="6829" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">这样做，您可以将同一语料库中分析的任何单词用数字表示为一个等长向量，然后找到该单词与任何其他单词之间的“距离”。因此，你可以做一些非常酷的事情，比如添加国王和女人的向量，并得出一个与王后的向量非常匹配的向量。</p><div class="kb kc ez fb kd ke"><a href="https://towardsdatascience.com/introduction-to-word-embedding-and-word2vec-652d0c2060fa" rel="noopener follow" target="_blank"><div class="kf ab dw"><div class="kg ab kh cl cj ki"><h2 class="bd hj fi z dy kj ea eb kk ed ef hh bi translated">单词嵌入和Word2Vec简介</h2><div class="kl l"><h3 class="bd b fi z dy kj ea eb kk ed ef dx translated">单词嵌入是最流行的文档词汇表示之一。它能够捕捉…的上下文</h3></div><div class="km l"><p class="bd b fp z dy kj ea eb kk ed ef dx translated">towardsdatascience.com</p></div></div><div class="kn l"><div class="nz l kp kq kr kn ks io ke"/></div></div></a></div><p id="d1bd" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">有一个等价的文档级嵌入过程，称为Doc2Vec，它扩展了这一思想，可以将整个文档转换为一个向量。</p><div class="kb kc ez fb kd ke"><a rel="noopener follow" target="_blank" href="/@ermolushka/text-clusterization-using-python-and-doc2vec-8c499668fa61"><div class="kf ab dw"><div class="kg ab kh cl cj ki"><h2 class="bd hj fi z dy kj ea eb kk ed ef hh bi translated">使用Python和Doc2vec的文本集群化</h2><div class="kl l"><h3 class="bd b fi z dy kj ea eb kk ed ef dx translated">假设您有一堆来自用户的文本文档，您想从中获得一些见解。对于…</h3></div><div class="km l"><p class="bd b fp z dy kj ea eb kk ed ef dx translated">medium.com</p></div></div><div class="kn l"><div class="oa l kp kq kr kn ks io ke"/></div></div></a></div><p id="6352" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">因此，我在这里的一般方法是使用200篇文章的文本来训练Doc2Vec模型，然后找到从高到低鼓掌计数文章的“平均”向量。隐含的假设是，语义内容中有一些东西可以区分hi-med-lo clap文章。</p><p id="7e1f" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">使用这些类别的平均代表向量，我可以将每一篇文章与这些类别进行比较，通过距离度量来“预测”它属于哪个类别(即文章与平均类别向量的相似程度)</p><p id="772e" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">方法如下，使用<a class="ae jv" href="https://github.com/RaRe-Technologies/gensim/#documentation" rel="noopener ugc nofollow" target="_blank"> gensim </a>库</p><pre class="iq ir is it fd ml mm mn mo aw mp bi"><span id="59ae" class="lw ku hi mm b fi mq mr l ms mt">import pandas as pd</span><span id="f396" class="lw ku hi mm b fi mu mr l ms mt">import numpy as np<br/>from numpy import save<br/>from numpy import load</span><span id="0fa9" class="lw ku hi mm b fi mu mr l ms mt">from scipy import spatial</span><span id="0030" class="lw ku hi mm b fi mu mr l ms mt">import gensim<br/>from nltk.corpus import stopwords<br/>from collections import namedtuple<br/>from gensim.models import doc2vec<br/>from gensim.models.doc2vec import Doc2Vec<br/>from gensim.models.doc2vec import Doc2Vec, TaggedDocument<br/>from nltk.tokenize import word_tokenize</span><span id="06cc" class="lw ku hi mm b fi mu mr l ms mt">data_source = pd.read_excel('Dataset.xlsx')<br/>data_source.drop(data_source.columns.difference(['ID','title','popularity_level','raw_text']), 1, inplace=True)</span><span id="b01a" class="lw ku hi mm b fi mu mr l ms mt">data = data_source["raw_text"]<br/>tagged_data = [TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) for i, _d in enumerate(data)]</span><span id="4d5a" class="lw ku hi mm b fi mu mr l ms mt">#Code adapted from <a class="ae jv" rel="noopener" href="/@mishra.thedeepak/doc2vec-simple-implementation-example-df2afbbfbad5">https://medium.com/@mishra.thedeepak/doc2vec-simple-implementation-example-df2afbbfbad5</a></span><span id="d435" class="lw ku hi mm b fi mu mr l ms mt">max_epochs = 100<br/>vec_size = 300<br/>alpha = 0.025</span><span id="0b46" class="lw ku hi mm b fi mu mr l ms mt">Doc2VecModel = Doc2Vec(vector_size=vec_size,<br/>                alpha=alpha, <br/>                min_alpha=0.00025,<br/>                min_count=1,<br/>                dm =1)<br/>  <br/>Doc2VecModel.build_vocab(tagged_data)</span><span id="412a" class="lw ku hi mm b fi mu mr l ms mt">for epoch in range(max_epochs):<br/>    print('iteration {0}'.format(epoch))<br/>    Doc2VecModel.train(tagged_data,<br/>                total_examples=Doc2VecModel.corpus_count,<br/>                epochs=Doc2VecModel.iter)<br/>    # decrease the learning rate<br/>    Doc2VecModel.alpha -= 0.0002<br/>    # fix the learning rate, no decay<br/>    Doc2VecModel.min_alpha = model.alpha<br/>    <br/>Doc2VecModel.save("Doc2Vec.model")</span></pre><p id="a153" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">使用Doc2Vec中可以找到模型中最相似文章的相似性函数，它产生了一个非常准确的匹配——我不确定它是否挑出了一种独特的写作风格，但当我给它输入我的一篇文章时，它从其他199篇文章中挑出了我写的所有文章。</p><figure class="iq ir is it fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ob"><img src="../Images/0b4189c21cdae4c88974879ce8f6933d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-3KPLpBVGOae32A0dG5YYg.png"/></div></div></figure><p id="fa37" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">与之前线性回归方法中的H M L不同，我对VH到VL进行了更精细的分类，具体如下VH，&gt; 10000次鼓掌(21篇文章)；h，5000–10000次鼓掌(15篇文章)；m，1000–5000次鼓掌(29篇文章)；100-1000次鼓掌(82篇文章)；VL，&lt; 100拍手(53篇文章)。</p><p id="42c6" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">由于文档向量有300维长，你无法直观地看到它，所以使用TSNE(一种降维方法)处理数据时，我绘制了所有文章，并通过鼓掌计数类对它们进行了颜色编码。</p><figure class="iq ir is it fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es oc"><img src="../Images/fdb7dc7cec5479debe4859c02fc02980.png" data-original-src="https://miro.medium.com/v2/resize:fit:1378/format:webp/1*E-C_DQwuJIYBQir7W3wlQg.png"/></div></div><figcaption class="jx jy et er es jz ka bd b be z dx translated">TSNE的200篇文献向量</figcaption></figure><p id="acfe" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">基于TSNE图，确实出现了一种模式，其中低clap文章远离“中心”(参考浅蓝色和紫色点)。这么说可能有点夸张，但绿色和深蓝色确实更接近中间。同样，问题是分类不平衡(低点击量的文章比高点击量的文章多)</p><p id="af57" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">无论如何，布丁的好坏取决于吃的东西，那么分类器的效果如何呢？令人惊讶的是……80%的准确率相当不错！</p><figure class="iq ir is it fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es od"><img src="../Images/d0bbde34d31884aafa3feef5bd2436b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZPvg7C2gKmrxzEtk5VtfdQ.png"/></div></div><figcaption class="jx jy et er es jz ka bd b be z dx translated">结果示例—预测基于文章与哪个类别最相似…</figcaption></figure><figure class="iq ir is it fd ij er es paragraph-image"><div class="er es oe"><img src="../Images/373c7bf0239a6299ce2ccfba04a71aff.png" data-original-src="https://miro.medium.com/v2/resize:fit:822/format:webp/1*dRdhjeSAJcb_3POEZU_MVQ.png"/></div><figcaption class="jx jy et er es jz ka bd b be z dx translated">160/200篇文章被准确预测！</figcaption></figure><p id="90f8" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated"><strong class="iy hj">第三课:ML技术(模型选择、超参数调整等)只是成功的模型应用的一部分——最终更重要的是训练数据的质量。</strong>这包括关于完整性(它是否代表您试图预测/理解的内容——请注意，我在文章年龄和鼓掌计数方面存在类别不平衡问题)、一致性/正确性(在我的情况下，我怀疑预处理步骤可能仍然有问题)和上下文的所有内容——即理解如何应用ML模型来提供关于可接受的错误级别的一些指导。</p><h1 id="8679" class="kt ku hi bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated"><strong class="ak"> 4。将代码转换成一个简单的Flask App </strong></h1><p id="6954" class="pw-post-body-paragraph iw ix hi iy b iz lr jb jc jd ls jf jg jh lt jj jk jl lu jn jo jp lv jr js jt hb bi translated">我最初期望将我的代码翻译成Flask应用程序会相对简单，因为我有意识地决定不包括通常的web应用程序功能(例如，没有视图计数器，没有登录管理，没有反馈/评论部分)。我很快发现不是:(</p><p id="42f5" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">我的根本问题是我最初的代码是如何编写的。我创建了这些庞大的类，它们充满了方法，存储了大量数据。我这样做是为了方便抓取网页和构建参考数据集。即ArticleExtract类的设置方式，我只给了它一个URL，它就完成了所有其他的工作。</p><p id="9a44" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">这很有效，因为我在web抓取期间没有优化速度，并且仍然处于数据分析的探索阶段，在用特定的URL实例化一个类对象之后，我有选择地使用其他方法来调用特定的度量或绘图图表或其他东西。(也就是说，我没有一次运行所有的方法，我的网络抓取(我让它运行了一整夜)只针对高级页面级别的指标——而不是详细的逐句分析或clap预测)</p><p id="6792" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">然而，将所有这些代码剪切粘贴到Flask应用程序中会使事情变得极其缓慢。Flask的工作方式是为每个页面创建视图，这些视图根据各个页面发送的HTTP请求工作——本质上是使每个视图成为一个独立的功能。由于默认情况下Flask <strong class="iy hj">不允许你跨视图</strong><a class="ae jv" href="https://stackoverflow.com/questions/27611216/how-to-pass-a-variable-between-flask-pages" rel="noopener ugc nofollow" target="_blank">【1】</a>共享数据，这也意味着对于每个页面，我必须为相同的URL创建一个全新的“本地”版本的ArticleExtract对象，并且每次都重新运行。</p><figure class="iq ir is it fd ij er es paragraph-image"><div class="er es of"><img src="../Images/1a04c9db2283dc40d47b5566730c757e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1034/format:webp/1*NjyxelIIDZLwf_ejENuhgQ.png"/></div><figcaption class="jx jy et er es jz ka bd b be z dx translated">呃…你今天想要那份分析报告吗？<a class="ae jv" href="https://www.123rf.com/stock-photo/tortoise_slow.html?sti=oc6ksj7zt3wp1ehnpq|" rel="noopener ugc nofollow" target="_blank">来源:123RF库存照片</a></figcaption></figure><p id="a43f" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">Flask有一个会话特性，但是可以存储“cookies ”,但是这仅限于400kb，而且大多数文档都建议使用数据库解决方案来跨不同页面“持久化”数据。</p><p id="b2b6" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">我最终将ArticleExtract对象分解成独立的函数，并创建了一个“container”类来存储不同页面视图共享的关键数据，以加快处理速度。</p><p id="a4e3" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated"><strong class="iy hj">第4课:当开发需要部署的代码时——提前计划，从处理时间和内存效率的角度考虑代码的性能</strong>。为了使故障排除更容易，将代码“模块化”成可管理的块，而不是编写紧密耦合的整体代码块，这也是一个很好的实践(也就是说，代码流中包含的依赖项/引用越多，进行任何编辑时整个代码失败的可能性就越大)</p><h1 id="4855" class="kt ku hi bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">5.结论</h1><p id="95cf" class="pw-post-body-paragraph iw ix hi iy b iz lr jb jc jd ls jf jg jh lt jj jk jl lu jn jo jp lv jr js jt hb bi translated">我希望这对希望构建类似应用程序的任何人或者开始使用Python进行文本分析的任何人都有用。</p><p id="315d" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">总而言之，作为一名数据科学爱好者和n00b开发人员，我的主要收获是:</p><ul class=""><li id="4f24" class="nb nc hi iy b iz ja jd je jh nd jl ne jp nf jt ng nh ni nj bi translated"><strong class="iy hj">在进行任何文本辩论时，不要低估对原始html数据进行适当清洗的重要性！</strong></li><li id="9ea0" class="nb nc hi iy b iz nk jd nl jh nm jl nn jp no jt ng nh ni nj bi translated"><strong class="iy hj">在适当的情况下，利用他人的工作</strong></li><li id="1198" class="nb nc hi iy b iz nk jd nl jh nm jl nn jp no jt ng nh ni nj bi translated"><strong class="iy hj">ML技术只是成功模型应用的一部分——最终关键是训练数据质量</strong></li><li id="df93" class="nb nc hi iy b iz nk jd nl jh nm jl nn jp no jt ng nh ni nj bi translated"><strong class="iy hj">提前计划——考虑运行代码所需的内存和处理时间的效率</strong></li></ul><p id="c0f4" class="pw-post-body-paragraph iw ix hi iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">我仍然致力于在线部署该应用程序，因此这可能是未来帖子的主题，但现在，欢迎您克隆我的回购并亲自尝试。</p></div></div>    
</body>
</html>