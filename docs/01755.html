<html>
<head>
<title>How to apply preprocessing steps in a pipeline only to specific features</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何将管线中的预处理步骤仅应用于特定特征</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/how-to-apply-preprocessing-steps-in-a-pipeline-only-to-specific-features-4e91fe45dfb8?source=collection_archive---------4-----------------------#2019-11-12">https://medium.com/analytics-vidhya/how-to-apply-preprocessing-steps-in-a-pipeline-only-to-specific-features-4e91fe45dfb8?source=collection_archive---------4-----------------------#2019-11-12</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/dc00f59439b83933db6d1a5919b931be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-C95_o87H0ZU5162i2Abxg.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">图片由Pixabay的Michael Gaida提供</figcaption></figure><p id="6070" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">情况:您有一个标准化和自动化预处理的管道。您的数据集包含至少两种不同数据类型的特征，需要不同的预处理步骤。例如，分类特征可能需要转换为虚拟变量，但连续特征可能需要标准化。从0.20版本开始，sci-kit learn已经为您提供了相关内容！函数<a class="ae js" href="https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html" rel="noopener ugc nofollow" target="_blank"> ColumnTransformer </a>允许您创建特定于列的管道步骤！在这篇文章中，我将向您展示如何使用这个函数，并谈一谈使用管道进行预处理的好处。我们开始吧！</p><p id="85f4" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">首先，加载必要的库:</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="14e3" class="kc kd hi jy b fi ke kf l kg kh">import pandas as pd<br/>from sklearn.compose import ColumnTransformer<br/>from sklearn.impute import SimpleImputer<br/>from sklearn.linear_model import LogisticRegression<br/>from sklearn.metrics import classification_report<br/>from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold<br/>from sklearn.pipeline import Pipeline<br/>from sklearn.preprocessing import OneHotEncoder, StandardScaler</span></pre><p id="ee02" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">我们将使用泰坦尼克号的数据集。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="3733" class="kc kd hi jy b fi ke kf l kg kh">titanic = pd.read_csv('./titanic.csv')<br/><br/>titanic.head()</span></pre><figure class="jt ju jv jw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ki"><img src="../Images/285fe109b5c8e28aaa1cdfc639ee477a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VylN3F0WpFkDw8Zc1D0XNA.png"/></div></div></figure><h1 id="6462" class="kj kd hi bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf bi translated">使用管道进行预处理的优势</h1><p id="7bb9" class="pw-post-body-paragraph iu iv hi iw b ix lg iz ja jb lh jd je jf li jh ji jj lj jl jm jn lk jp jq jr hb bi translated">我们希望根据现有数据预测是否有乘客幸存。在我们训练我们的模型之前，必须做一些预处理。为什么要在我们的机器学习管道中包含预处理？事先做好一切，比如说熊猫，不是更容易吗？</p><p id="5c6b" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">首先，它很方便，并且使预处理步骤及其顺序显式、透明和可复制。但是还有三个更实质性的原因:</p><p id="9652" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">1)它允许在超参数调优中包括预处理步骤(我将在另一篇文章中回到这个问题)。</p><p id="2875" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">2)它使您避免了使用任何测试数据进行模型训练或模型决策(例如，分类器参数)的错误，也称为<em class="ll">数据泄漏</em>。例如，当您使用缩放器或输入缺失值时，这个陷阱就潜伏着。避免这种情况对于获得有效的模型性能估计是至关重要的。管道中声明的预处理步骤保证只基于训练数据(或交叉验证中的训练折叠)来执行。</p><p id="374b" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">3)它保证您的数据总是以相同的方式进行预处理。这很重要，例如，如果分类特征在测试集中有一个不在训练集中出现的类别。我举个例子:假设你的训练数据包含一个特征<code class="du lm ln lo jy b">review_status</code>，这个特征表示一个交易是否已经被审核过。它可能包含以下两个类别:</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="5e1d" class="kc kd hi jy b fi ke kf l kg kh">review_status = ['not reviewed', 'reviewed']</span></pre><p id="7c86" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">但是，在您的测试数据中，还有一个类别<code class="du lm ln lo jy b">'externally reviewed'</code>，它没有出现在训练集中。现在如果你使用<code class="du lm ln lo jy b">pandas.get_dummies()</code>，你会遇到两个问题:</p><p id="1e95" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">1)如果通过观察获得新的数据，使用<code class="du lm ln lo jy b">pandas.get_dummies()</code>根本没有意义。</p><p id="c553" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">2)与训练集相比，您最终在测试集中多了一个特征/列。但是您的模型是在训练集上训练的，不知道此列。反之亦然，如果类别在测试集中缺失，那么您的模型就需要多一个特性。<code class="du lm ln lo jy b">OneHotEncoder()</code>作为所有流水线步骤，首先在训练集上调用<code class="du lm ln lo jy b">.fit()</code>方法，然后调用<code class="du lm ln lo jy b">.transform()</code>方法，但在测试集上只调用<code class="du lm ln lo jy b">.transform()</code>。因此，这些类别仅来自训练集中的唯一类别！您可以通过设置<code class="du lm ln lo jy b">handle_unknown</code>参数明确声明如果遇到未知类别会发生什么:<code class="du lm ln lo jy b">handle_unknown = 'error'</code>在遇到未知类别时抛出一个错误，而<code class="du lm ln lo jy b">handle_unknown = 'ignore'</code>使转换器忽略该类别。因此，一旦适合，<code class="du lm ln lo jy b">OneHotEncoder()</code>每次应用于新数据时都会产生相同的输出。这对于我们的模型来说很容易消化。</p><h1 id="a88a" class="kj kd hi bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf bi translated">创建列转换器</h1><p id="8a5d" class="pw-post-body-paragraph iu iv hi iw b ix lg iz ja jb lh jd je jf li jh ji jj lj jl jm jn lk jp jq jr hb bi translated">好了，现在让我们创建一个预处理管道。我们希望为分类特征创建虚拟变量，并对连续特征进行标准化。出于这个目的，我们把所有东西都放在一个<code class="du lm ln lo jy b">ColumnTransformer</code>里。我们从分类开始:首先，我们需要命名这个步骤:<code class="du lm ln lo jy b">'onehot'</code>。然后我们需要指定变压器，这里是<code class="du lm ln lo jy b">OneHotEncoder()</code>。最后，我们需要指出哪些列应该被转换，这里通过给出列名<code class="du lm ln lo jy b">['pclass', 'sex', 'embarked']</code>来完成，但是其他形式(例如，索引)也可以。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="0f61" class="kc kd hi jy b fi ke kf l kg kh">('onehot', OneHotEncoder(), ['pclass', 'sex', 'embarked'])</span></pre><p id="1000" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><code class="du lm ln lo jy b">StandardScaler()</code>也是如此。由于我们的特征中有一些缺失值，我们也可以实现一个估算器。幸运是，sci-kit learn为我们提供了一个简单的估算工具。最后，我们需要告诉<code class="du lm ln lo jy b">ColumnTransformer</code>在<code class="du lm ln lo jy b">remainder</code>中没有被选择进行转换的特征发生了什么。你可以选择把它们留在<code class="du lm ln lo jy b">remainder = 'passthrough'</code>中，像我一样，把它们丢弃在<code class="du lm ln lo jy b">remainder = 'drop'</code>中，或者把它们交给另一个评估者。这里是完成的<code class="du lm ln lo jy b">ColumnTransformer</code>:</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="6ea3" class="kc kd hi jy b fi ke kf l kg kh">preprocessor = ColumnTransformer(<br/>    [<br/>        ('imputer', SimpleImputer(strategy = 'constant', <br/>          fill_value = 'missing'), ['pclass', 'sex', 'embarked']),<br/>        ('onehot', OneHotEncoder(), ['pclass', 'sex', 'embarked']),<br/>        ('imputer', SimpleImputer(strategy = 'median'), <br/>          ['age', 'sibsp', 'parch', 'fare']),<br/>        ('scaler', StandardScaler(), ['age', 'sibsp', 'parch',<br/>          'fare'])<br/>    ],<br/>    remainder = 'drop'<br/>)</span></pre><p id="8221" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">这段代码看起来有点难看。我更喜欢将这些行分成两个子转换器，一个用于分类特征，一个用于数字特征。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="8272" class="kc kd hi jy b fi ke kf l kg kh"># transformer for categorical features<br/>categorical_features = ['pclass', 'sex', 'embarked']<br/>categorical_transformer = Pipeline(<br/>    [<br/>        ('imputer_cat', SimpleImputer(strategy = 'constant',<br/>          fill_value = 'missing')),<br/>        ('onehot', OneHotEncoder(handle_unknown = 'ignore'))<br/>    ]<br/>)</span></pre><p id="8962" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">现在，数字特征的步骤是:</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="3786" class="kc kd hi jy b fi ke kf l kg kh"># transformer for numerical features<br/>numeric_features = ['age', 'sibsp', 'parch', 'fare']<br/>numeric_transformer = Pipeline(<br/>    [<br/>        ('imputer_num', SimpleImputer(strategy = 'median')),<br/>        ('scaler', StandardScaler())<br/>    ]<br/>)</span></pre><p id="58b0" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">我们再次将它们组合在一个<code class="du lm ln lo jy b">ColumnTransformer</code>中。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="d18d" class="kc kd hi jy b fi ke kf l kg kh">preprocessor = ColumnTransformer(<br/>    [<br/>        ('categoricals', categorical_transformer, <br/>          categorical_features),<br/>        ('numericals', numeric_transformer, numeric_features)<br/>    ],<br/>    remainder = 'drop'<br/>)</span></pre><p id="44cc" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">接下来，我们创建机器学习管道，并作为一个步骤包括列转换器。可能会缩短代码，但我发现这种表达方式更清晰。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="e4b8" class="kc kd hi jy b fi ke kf l kg kh">pipeline = Pipeline(<br/>    [<br/>        ('preprocessing', preprocessor),<br/>        ('clf', LogisticRegression())<br/>    ]<br/>)</span></pre><p id="3a22" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">现在我们已经设置了所有的预处理步骤，我们可以继续进行超参数调整和模型性能评估。我在这里将候选参数作为字典传递。因为我们稍后将为<code class="du lm ln lo jy b">GridSearchCV()</code>提供一个管道，所以我们需要指出一个参数属于哪个步骤。在我们的管道步骤<code class="du lm ln lo jy b">('clf', LogisticRegression())</code>中添加“clf__”就可以实现这个目的。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="de2e" class="kc kd hi jy b fi ke kf l kg kh">params = {<br/>    'clf__solver': ['liblinear'],<br/>    'clf__penalty': ['l1', 'l2'],<br/>    'clf__C': [0.01, 0.1, 1, 10, 100],<br/>    'clf__random_state': [42]<br/>}</span></pre><p id="835e" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">我们仍然需要定义一个交叉验证策略。我选<code class="du lm ln lo jy b">RepeatedStratifiedKFold()</code>和<em class="ll"> k </em> =5。这意味着分层的5重交叉验证重复两次，在两次重复之间对观察结果进行洗牌。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="c38c" class="kc kd hi jy b fi ke kf l kg kh">rskf = RepeatedStratifiedKFold(n_splits = 5, n_repeats = 2, random_state = 42)</span></pre><p id="acf1" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">接下来，我们通过填写上面的步骤并选择一个评分标准来创建<code class="du lm ln lo jy b">GridSearchCV()</code>对象:</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="8f1a" class="kc kd hi jy b fi ke kf l kg kh">cv = GridSearchCV(<br/>  pipeline, <br/>  params, <br/>  cv = rskf, <br/>  scoring = ['f1', 'accuracy'], <br/>  refit = 'f1', <br/>  n_jobs = -1<br/>  )</span></pre><p id="4277" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">将数据分为要素(X)和目标(y):</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="3e12" class="kc kd hi jy b fi ke kf l kg kh">X = titanic.drop('survived', axis = 1)<br/>y = titanic.survived</span></pre><p id="fdb0" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">最后，执行和评估！</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="f1fc" class="kc kd hi jy b fi ke kf l kg kh">cv.fit(X, y)</span><span id="632f" class="kc kd hi jy b fi lp kf l kg kh">print(f'Best F1-score: {cv.best_score_:.3f}\n')<br/>print(f'Best parameter set: {cv.best_params_}\n')<br/>print(f'Scores: {classification_report(y, cv.predict(X))}')</span></pre><p id="be94" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">让我们来看看结果:</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="1184" class="kc kd hi jy b fi ke kf l kg kh">Best F1-score: 0.712<br/><br/>Best parameter set: {'clf__C': 10, 'clf__penalty': 'l1', 'clf__random_state': 42, 'clf__solver': 'liblinear'}<br/><br/>Scores:               precision    recall  f1-score   support<br/><br/>           0       0.82      0.85      0.83       809<br/>           1       0.74      0.69      0.72       500<br/><br/>    accuracy                           0.79      1309<br/>   macro avg       0.78      0.77      0.77      1309<br/>weighted avg       0.79      0.79      0.79      1309</span></pre><p id="a290" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">我们的最佳结果，F1值为0.712，是在正则化强度的倒数(<em class="ll"> C </em>)为10和L1罚的情况下实现的。</p><p id="07f0" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在下面的一个文件中找到完整的代码。编码快乐！</p><p id="0175" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">这篇文章也发表在我的博客<a class="ae js" href="https://moritzkoerber.github.io/python/tutorial/2019/10/11/blogpost/" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><figure class="jt ju jv jw fd ij"><div class="bz dy l di"><div class="lq lr l"/></div></figure></div></div>    
</body>
</html>