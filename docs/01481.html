<html>
<head>
<title>Handwritten Digit classification full analysis of network Architecture(Le-Net-1)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">手写数字分类网络结构全分析(Le-Net-1)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/handwritten-digit-classification-full-analysis-of-network-architecture-le-net1-cf852183c263?source=collection_archive---------9-----------------------#2019-10-25">https://medium.com/analytics-vidhya/handwritten-digit-classification-full-analysis-of-network-architecture-le-net1-cf852183c263?source=collection_archive---------9-----------------------#2019-10-25</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/994350f9cab0c087947f391c7895bffa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*U6cI0gH1he3O3daH"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><a class="ae iu" href="https://unsplash.com/@popnzebra?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Pop &amp;斑马</a>在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</figcaption></figure><p id="965a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在了解手写数字分类之前，先看这个问题的应用。</p><p id="5313" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">应用手写数字分类</strong></p><ul class=""><li id="dc59" class="jt ju hi ix b iy iz jc jd jg jv jk jw jo jx js jy jz ka kb bi translated">识别车辆的牌照。</li><li id="dbb8" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">处理手工填写的表格中的数字条目。</li><li id="60a5" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">处理银行支票号码，金额，日期。</li><li id="65ac" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">从纸张或图像中识别数字。</li></ul><p id="2952" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在手写数字分类问题中，图像被直接输入到学习网络中，而不是图像的固定特征向量，然后使用反向传播来学习特征向量。</p><p id="b440" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为了设计一个可以概括问题的网络，我们需要充分考虑网络的架构。解决任何独特的问题或改善网络的<strong class="ix hj">架构。</strong>例如，如果现有网络过度拟合或花费更多时间进行训练，那么您可以考虑重新设计网络，使自由参数最小化。</p><p id="9329" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">为什么要手写数字分类？</strong></p><ul class=""><li id="9a5e" class="jt ju hi ix b iy iz jc jd jg jv jk jw jo jx js jy jz ka kb bi translated">简单的问题</li><li id="f814" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">它只包含黑色和白色像素</li><li id="96c3" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">数字可以与背景分开</li></ul><p id="9049" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">网络的输入是归一化图像。</p><p id="769d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在形状识别中，我们结合局部特征来检测目标。我们也可以使用局部特征来检测字符，但是这些局部特征是由学习网络决定的。</p><p id="8f51" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">手写数字的问题</strong></p><ul class=""><li id="73e7" class="jt ju hi ix b iy iz jc jd jg jv jk jw jo jx js jy jz ka kb bi translated">每个人都有不同的书写风格，因此手写数字的大小、宽度和方向可能因人而异。</li></ul><p id="4805" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">数字可能位于不同的位置，网络如何处理:</strong></p><ul class=""><li id="da82" class="jt ju hi ix b iy iz jc jd jg jv jk jw jo jx js jy jz ka kb bi translated">用局部感受野扫描图像，并将状态存储在神经元中。比如在图像上滑动内核大小并执行卷积，然后执行挤压函数并存储输出。每个输出的集合被称为特征图，它代表下一层。</li><li id="3a92" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">局部感受野对于每个特征图共享相同的权重。这种技术被称为权重共享，这种技术的好处是减少了自由参数的数量。</li><li id="d87a" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">拥有不同的特征图将从图像中提取不同的特征，这在后续步骤中可能需要。</li><li id="d188" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">局部感受野和卷积特征映射的思想可以应用于后续的隐藏层，以提取特征。</li><li id="4d31" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">在较高位置提取的特征受位置变化的影响较小。</li></ul><p id="e939" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">网络整体流量数据:</strong></p><ul class=""><li id="78ce" class="jt ju hi ix b iy iz jc jd jg jv jk jw jo jx js jy jz ka kb bi translated">第一隐藏层提取一些特征图，随后是下一隐藏层，其执行局部平均、子采样、降低特征图的分辨率，然后再次进行一些特征提取、再次平均、降低。最终输出层与最后一个隐藏层相连。</li></ul><h1 id="90d5" class="kh ki hi bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">网络体系结构</h1><p id="ddb2" class="pw-post-body-paragraph iv iw hi ix b iy lf ja jb jc lg je jf jg lh ji jj jk li jm jn jo lj jq jr js hb bi translated">28×28输入图像&gt;<br/>四个24×24特征映射卷积层(5×5大小)&gt; <br/>平均池层(2×2大小)&gt; <br/>八个12×12特征映射卷积层(5×5大小)&gt; <br/>平均池层(2×2大小)&gt; <br/>直接完全连接到输出</p><h1 id="74e2" class="kh ki hi bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">Lenet-1的实施</h1><p id="d28e" class="pw-post-body-paragraph iv iw hi ix b iy lf ja jb jc lg je jf jg lh ji jj jk li jm jn jo lj jq jr js hb bi translated"><strong class="ix hj">必要进口</strong></p><pre class="lk ll lm ln fd lo lp lq lr aw ls bi"><span id="8380" class="lt ki hi lp b fi lu lv l lw lx">import torch<br/>import torchvision<br/>from torchvision import transforms, datasets<br/>import torch.nn as nn<br/>import torch.nn.functional as F<br/>import torch.optim as optim<br/>import numpy as np</span></pre><p id="e8dc" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">下载训练和测试数据集。</strong></p><ul class=""><li id="d999" class="jt ju hi ix b iy iz jc jd jg jv jk jw jo jx js jy jz ka kb bi translated"><strong class="ix hj">改造。ToTensor(): </strong>将图像转换成Torch张量。</li></ul><pre class="lk ll lm ln fd lo lp lq lr aw ls bi"><span id="d6d2" class="lt ki hi lp b fi lu lv l lw lx">train = datasets.MNIST("", train = True, download = True,<br/>                      transform = transforms.Compose([<br/>                          transforms.ToTensor()<br/>                      ]))<br/>test = datasets.MNIST("", train = False, download = True, <br/>                     transform = transforms.Compose([<br/>                         transforms.ToTensor()<br/>                     ]))</span></pre><p id="742d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">加载数据，设置批量大小并混洗数据。</strong></p><pre class="lk ll lm ln fd lo lp lq lr aw ls bi"><span id="9833" class="lt ki hi lp b fi lu lv l lw lx">trainset = torch.utils.data.DataLoader(train, batch_size = 8, shuffle = True)<br/>testset = torch.utils.data.DataLoader(test, batch_size = 8, shuffle = True)</span></pre><p id="cca1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> LeNet-1网络:</strong></p><pre class="lk ll lm ln fd lo lp lq lr aw ls bi"><span id="d9fb" class="lt ki hi lp b fi lu lv l lw lx">class Net(nn.Module):<br/>    <br/>    def __init__(self):<br/>        super(Net, self).__init__()<br/>        # first layer<br/>        self.conv1 = nn.Conv2d(in_channels=1, out_channels=4, kernel_size = 5)<br/>        # third layer<br/>        self.conv2 = nn.Conv2d(in_channels = 4, out_channels=12, kernel_size=5)<br/>        #output layer<br/>        self.fc_out = nn.Linear(in_features=192, out_features=10)<br/>        <br/>        <br/>    def forward(self, x):<br/>        # applying activation on convolution result<br/>        x = F.relu(self.conv1(x))<br/>        # applying averging, Second layer<br/>        x = F.avg_pool2d(x,kernel_size=2)<br/>        x = F.relu(self.conv2(x))<br/>        x = F.avg_pool2d(x, kernel_size=2)<br/>        s = self.get_dimension_size(x)<br/>        x = self.fc_out(x.view(-1, s))<br/>        <br/>        return F.log_softmax(x, dim = 1)<br/>    <br/>    def get_dimension_size(self, x):<br/>        size = x.size()[1:]<br/>        num_features = 1<br/>        for s in size:<br/>            num_features *= s<br/>        return num_features</span></pre><p id="f50d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">训练模型</strong></p><pre class="lk ll lm ln fd lo lp lq lr aw ls bi"><span id="7a45" class="lt ki hi lp b fi lu lv l lw lx">device = torch.device("cuda" if torch.cuda.is_available() else "cpu")<br/>print(device)       <br/>net = Net().to(device)<br/>print(net)</span><span id="99f3" class="lt ki hi lp b fi ly lv l lw lx">optimizer = optim.Adam(net.parameters(), lr = 0.001)<br/>EPOCHS = 20<br/>loss_list = []<br/>for epoch in range(EPOCHS):<br/>    correct = 0<br/>    total = 0<br/>    for data in trainset:<br/>        X, y = data<br/>        net.zero_grad()<br/>        X, y = X.to(device), y.to(device)<br/>        output = net.forward(X)<br/>        loss = F.nll_loss(output, y)<br/>        loss.backward()<br/>        optimizer.step()<br/>        torch.cuda.empty_cache()<br/>    loss_list.append(np.sum(loss.item()))</span></pre><p id="0d3b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">定义评价函数</strong></p><pre class="lk ll lm ln fd lo lp lq lr aw ls bi"><span id="6591" class="lt ki hi lp b fi lu lv l lw lx">def evaluation(dataloader):<br/>    total, correct = 0, 0<br/>    #keeping the network in evaluation mode <br/>    net.eval()<br/>    for data in dataloader:<br/>        inputs, labels = data<br/>        #moving the inputs and labels to gpu<br/>        inputs, labels = inputs.to(device), labels.to(device)<br/>        outputs = net.forward(inputs)<br/>        _, pred = torch.max(outputs.data, 1)<br/>        total += labels.size(0)<br/>        correct += (pred == labels).sum().item()<br/>        return 100 * correct / total</span></pre><p id="5914" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">#保存训练好的模型</strong></p><pre class="lk ll lm ln fd lo lp lq lr aw ls bi"><span id="d285" class="lt ki hi lp b fi lu lv l lw lx">torch.save(net.state_dict(), 'digit_model.pth')</span></pre><p id="2d44" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">不断学习，勇于创新。</strong></p><div class="lz ma ez fb mb mc"><a rel="noopener follow" target="_blank" href="/@sh.tsang/paper-brief-review-of-lenet-1-lenet-4-lenet-5-boosted-lenet-4-image-classification-1f5f809dbf17"><div class="md ab dw"><div class="me ab mf cl cj mg"><h2 class="bd hj fi z dy mh ea eb mi ed ef hh bi translated">综述:LeNet-1、LeNet-4、LeNet-5、Boosted LeNet-4(图像分类)</h2><div class="mj l"><h3 class="bd b fi z dy mh ea eb mi ed ef dx translated">已经有大量的文献对LeNet这一经典的图像分类方法进行了深入的研究</h3></div><div class="mk l"><p class="bd b fp z dy mh ea eb mi ed ef dx translated">medium.com</p></div></div><div class="ml l"><div class="mm l mn mo mp ml mq io mc"/></div></div></a></div><figure class="lk ll lm ln fd ij"><div class="bz dy l di"><div class="mr ms l"/></div></figure></div></div>    
</body>
</html>