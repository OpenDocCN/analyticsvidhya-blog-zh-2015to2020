<html>
<head>
<title>Introduction to TensorFlow Lite</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">TensorFlow Lite简介</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/introduction-to-tensorflow-lite-66c19d757b8c?source=collection_archive---------11-----------------------#2020-10-21">https://medium.com/analytics-vidhya/introduction-to-tensorflow-lite-66c19d757b8c?source=collection_archive---------11-----------------------#2020-10-21</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="e1db" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本笔记本中，我们将回顾TF Lite的基础知识。这本笔记本的首要目标是描述两件事:<br/> 1。如何将TensorFlow模型转换成TF Lite <br/> 2。如何从TF Lite模型中提取模型架构和权重</p><h1 id="7537" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">介绍</h1><p id="dcae" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">TensorFlow Lite是一套帮助开发人员在移动、嵌入式和物联网设备上运行TensorFlow模型的工具。它支持设备上的机器学习推理，具有低延迟和小二进制大小。它由两个主要部分组成。</p><p id="c302" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们来看看使用TensorFlow Lite的整体工作流程。</p><h1 id="58b4" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">开发工作流程</h1><p id="ca5d" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">使用TensorFlow Lite的工作流程包括以下步骤:</p><ol class=""><li id="80bc" class="kg kh hi ih b ii ij im in iq ki iu kj iy kk jc kl km kn ko bi translated"><strong class="ih hj">挑模特</strong></li></ol><p id="1171" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">带上你自己的TensorFlow模型，在网上找一个模型，或者用一个预先训练好的模型来加入或者重新训练。</p><p id="6fe6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.<strong class="ih hj">转换型号</strong></p><p id="6bc3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果您正在使用自定义模型，请使用TensorFlow Lite转换器和几行Python将其转换为TensorFlow Lite格式。</p><p id="c51e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">3.<strong class="ih hj">部署到您的设备上</strong></p><p id="7de8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用TensorFlow Lite解释器和多种语言的API在设备上运行您的模型。</p><p id="3ea2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">4.<strong class="ih hj">优化您的模型</strong></p><p id="b0c3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用谷歌的<a class="ae kp" href="https://www.tensorflow.org/lite/performance/model_optimization" rel="noopener ugc nofollow" target="_blank">模型优化工具包</a>来减少你的模型的大小，提高它的效率，同时对准确性的影响最小。</p><h1 id="551e" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">张量流Lite转换器</h1><p id="cfb1" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">让我们用第一个主要组件来回答第二个要点。为了将TensorFlow模型转换为TFLITE，我们使用了<a class="ae kp" href="https://www.tensorflow.org/lite/convert/index" rel="noopener ugc nofollow" target="_blank"> TensorFlow Lite转换器</a>。这将引入优化来提高二进制文件的大小和性能。TF Lite转换器将创建TensorFlow Lite模型(由<em class="kq">标识的优化的FlatBuffer格式)。tflite </em>文件扩展名)。</p><figure class="ks kt ku kv fd kw er es paragraph-image"><div class="er es kr"><img src="../Images/a4d64ea39c622e124b0d038b8bd8597f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1308/format:webp/1*7EHdaW_C5dfFbEPGxzynmA.png"/></div><figcaption class="kz la et er es lb lc bd b be z dx translated"><a class="ae kp" href="https://www.tensorflow.org/lite/images/convert/convert.png" rel="noopener ugc nofollow" target="_blank"> TF Lite转换过程</a></figcaption></figure><h2 id="3726" class="ld je hi bd jf le lf lg jj lh li lj jn iq lk ll jr iu lm ln jv iy lo lp jz lq bi translated">过程</h2><p id="a3c3" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">推荐使用Google的<a class="ae kp" href="https://www.tensorflow.org/lite/convert/index#python_api" rel="noopener ugc nofollow" target="_blank"> Python API </a>与转换器交互。假设你在TensorFlow中训练了一个模型。您可以通过将它保存为一个<em class="kq"> SavedModel </em>或一个单独的HDF5文件</p><pre class="ks kt ku kv fd lr ls lt lu aw lv bi"><span id="75c3" class="ld je hi ls b fi lw lx l ly lz"><em class="kq"># </em>You should save it as a SavedModel by specifying <em class="kq">save_format=‘tf’<br/>tf.keras.Model.save(filepath, save_format=None)</em></span></pre><p id="9b06" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在您已经有了一个SavedModel，您可以如下转换它:</p><pre class="ks kt ku kv fd lr ls lt lu aw lv bi"><span id="e3bd" class="ld je hi ls b fi lw lx l ly lz">import tensorflow as tf<br/># Convert the model<br/>converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir) # path to the SavedModel directory<br/>tflite_model = converter.convert()</span><span id="c6a7" class="ld je hi ls b fi ma lx l ly lz"># Save the model.<br/>with open(‘model.tflite’, ‘wb’) as f:<br/> f.write(tflite_model)</span></pre><p id="4853" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">你可以从_saved_model()  <a class="ae kp" href="https://www.tensorflow.org/api_docs/python/tf/compat/v1/lite/TFLiteConverter#from_saved_model" rel="noopener ugc nofollow" target="_blank">这里</a>找到更多关于<em class="kq">的详情。</em></p><h1 id="60d1" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">TensorFlow Lite解释器</h1><p id="3045" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">现在，让我们进入第二个主要组件。一旦我们有了<em class="kq">。tflite </em>模型，我们需要用它对edge 进行<em class="kq">推理。这意味着我们将在手机、嵌入式Linux设备或微控制器上执行它，以获得对输入数据的预测。为了进行推断，我们需要使用<a class="ae kp" href="https://www.tensorflow.org/lite/guide/inference" rel="noopener ugc nofollow" target="_blank"> TensorFlow Lite解释器</a>。为了精简和快速，它使用了<em class="kq">静态图排序</em>。您可以在此找到有关支持设备<a class="ae kp" href="https://www.tensorflow.org/lite/guide/inference#supported_platforms" rel="noopener ugc nofollow" target="_blank">的详细信息。</a></em></p><h2 id="cdf9" class="ld je hi bd jf le lf lg jj lh li lj jn iq lk ll jr iu lm ln jv iy lo lp jz lq bi translated">推理过程</h2><p id="c96b" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated"><strong class="ih hj"> 1。加载模型</strong></p><p id="bd1e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">您必须加载<em class="kq">。tflite </em>模型放入内存，其中包含模型的执行图。</p><p id="eed0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 2。转换数据</strong></p><p id="924a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">模型的原始输入数据通常与模型预期的输入数据格式不匹配。例如，您可能需要调整图像大小或更改图像格式以与模型兼容。</p><p id="4e46" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 3。运行推理</strong></p><p id="8af1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这一步包括使用TensorFlow Lite API来执行模型。它包括几个步骤，如构建解释器和分配张量，如下面几节所述。</p><p id="a272" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 4。解释输出</strong></p><p id="376e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当您从模型推断中获得结果时，您必须以一种有意义的方式解释张量，这种方式在您的应用程序中是有用的。</p><p id="659c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">例如，模型可能只返回概率列表。将概率映射到相关类别并呈现给最终用户取决于您。</p></div><div class="ab cl mb mc gp md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="hb hc hd he hf"><p id="8d47" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面是一些运行TF Lite模型进行推理的示例Python代码。</p><pre class="ks kt ku kv fd lr ls lt lu aw lv bi"><span id="9e7e" class="ld je hi ls b fi lw lx l ly lz">import numpy as np<br/>import tensorflow as tf</span><span id="471c" class="ld je hi ls b fi ma lx l ly lz"># Load the TFLite model and allocate tensors.<br/>interpreter = tf.lite.Interpreter(model_path="converted_model.tflite")<br/>interpreter.allocate_tensors()</span><span id="57c9" class="ld je hi ls b fi ma lx l ly lz"># Get input and output tensors.<br/>input_details = interpreter.get_input_details()<br/>output_details = interpreter.get_output_details()</span><span id="2f7c" class="ld je hi ls b fi ma lx l ly lz"># Test the model on random input data.<br/>input_shape = input_details[0]['shape']<br/>input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)<br/>interpreter.set_tensor(input_details[0]['index'], input_data)</span><span id="09c3" class="ld je hi ls b fi ma lx l ly lz">interpreter.invoke()</span><span id="c658" class="ld je hi ls b fi ma lx l ly lz"># The function `get_tensor()` returns a copy of the tensor data.<br/># Use `tensor()` in order to get a pointer to the tensor.<br/>output_data = interpreter.get_tensor(output_details[0]['index'])<br/>print(output_data)</span></pre><h1 id="29e9" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">从TF Lite模型中提取模型架构和权重</h1><p id="47ce" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">有几种方法可以从<em class="kq">中提取信息。tflite </em>文件。让我们检查他们。</p><h2 id="7a06" class="ld je hi bd jf le lf lg jj lh li lj jn iq lk ll jr iu lm ln jv iy lo lp jz lq bi translated">形象化</h2><p id="bebb" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated"><a class="ae kp" href="https://github.com/lutzroeder/netron" rel="noopener ugc nofollow" target="_blank"> Netron </a>是可视化TensorFlow Lite模型的最简单方法。</p><p id="1c97" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果Netron无法打开您的TensorFlow Lite模型，您可以尝试TensorFlow资源库中的<a class="ae kp" href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/tools/visualize.py" rel="noopener ugc nofollow" target="_blank"> visualize.py </a>脚本<br/>您可以按照以下步骤使用它:<br/> 1 .克隆TensorFlow存储库<br/> 2。安装<a class="ae kp" href="https://docs.bazel.build/versions/master/install.html" rel="noopener ugc nofollow" target="_blank">座</a>座<br/> 3。使用bazel运行visualize.py脚本:</p><pre class="ks kt ku kv fd lr ls lt lu aw lv bi"><span id="200b" class="ld je hi ls b fi lw lx l ly lz">bazel run //tensorflow/lite/tools:visualize model.tflite visualized_model.html</span></pre><h1 id="262e" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">参考</h1><ul class=""><li id="3752" class="kg kh hi ih b ii kb im kc iq mi iu mj iy mk jc ml km kn ko bi translated"><a class="ae kp" href="https://www.tensorflow.org/lite/guide" rel="noopener ugc nofollow" target="_blank"> TensorFlow Lite指南</a></li></ul></div></div>    
</body>
</html>