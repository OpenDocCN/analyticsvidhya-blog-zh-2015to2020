<html>
<head>
<title>Gensim LDA Topic Modeling for Article Discovery</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于文章发现的Gensim LDA主题建模</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/gensim-lda-topic-modeling-for-article-discovery-9707237e4f0d?source=collection_archive---------11-----------------------#2020-12-27">https://medium.com/analytics-vidhya/gensim-lda-topic-modeling-for-article-discovery-9707237e4f0d?source=collection_archive---------11-----------------------#2020-12-27</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="6557" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated"><strong class="ak">利用机器学习创建新冠肺炎研究工具</strong></h2></div><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es iw"><img src="../Images/10c9a13f74324ac5c7b6c500f007e38e.png" data-original-src="https://miro.medium.com/v2/resize:fit:988/format:webp/1*VTHd8nB_PBsDtd2hd87ybg.png"/></div><figcaption class="je jf et er es jg jh bd b be z dx translated">LDA模型的板符号(【https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation】T2</figcaption></figure></div><div class="ab cl jj jk go jl" role="separator"><span class="jm bw bk jn jo jp"/><span class="jm bw bk jn jo jp"/><span class="jm bw bk jn jo"/></div><div class="ha hb hc hd he"><h1 id="46ac" class="jq jr hh bd js jt ju jv jw jx jy jz ka in kb io kc iq kd ir ke it kf iu kg kh bi translated"><strong class="ak">目录:</strong></h1><ol class=""><li id="9c9a" class="ki kj hh kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">项目概述</li><li id="5e07" class="ki kj hh kk b kl la kn lb kp lc kr ld kt le kv kw kx ky kz bi translated">进口</li><li id="7659" class="ki kj hh kk b kl la kn lb kp lc kr ld kt le kv kw kx ky kz bi translated">文本清理方法</li><li id="47ab" class="ki kj hh kk b kl la kn lb kp lc kr ld kt le kv kw kx ky kz bi translated">创建熊猫数据框</li><li id="1468" class="ki kj hh kk b kl la kn lb kp lc kr ld kt le kv kw kx ky kz bi translated">训练LDA模型</li><li id="64a0" class="ki kj hh kk b kl la kn lb kp lc kr ld kt le kv kw kx ky kz bi translated">创建提示语料库</li><li id="66bb" class="ki kj hh kk b kl la kn lb kp lc kr ld kt le kv kw kx ky kz bi translated">计算主题分布</li><li id="266a" class="ki kj hh kk b kl la kn lb kp lc kr ld kt le kv kw kx ky kz bi translated">检索相关文章</li><li id="22b3" class="ki kj hh kk b kl la kn lb kp lc kr ld kt le kv kw kx ky kz bi translated">确认</li><li id="0e41" class="ki kj hh kk b kl la kn lb kp lc kr ld kt le kv kw kx ky kz bi translated">后续步骤和有用的链接</li></ol></div><div class="ab cl jj jk go jl" role="separator"><span class="jm bw bk jn jo jp"/><span class="jm bw bk jn jo jp"/><span class="jm bw bk jn jo"/></div><div class="ha hb hc hd he"><h1 id="6463" class="jq jr hh bd js jt ju jv jw jx jy jz ka in kb io kc iq kd ir ke it kf iu kg kh bi translated"><strong class="ak">项目概述:</strong></h1><p id="dd46" class="pw-post-body-paragraph lf lg hh kk b kl km ii lh kn ko il li kp lj lk ll kr lm ln lo kt lp lq lr kv ha bi translated">这个项目的目的是使用LDA主题建模来查找与提示相关的科学期刊文章。我在Kaggle提供的笔记本上对此进行了编码，并使用了同样由kaggle提供的数千篇科学期刊文章的数据集。本教程结束时，你将能够输入一段信息，并检索类似性质的文章。</p></div><div class="ab cl jj jk go jl" role="separator"><span class="jm bw bk jn jo jp"/><span class="jm bw bk jn jo jp"/><span class="jm bw bk jn jo"/></div><div class="ha hb hc hd he"><h1 id="1d82" class="jq jr hh bd js jt ju jv jw jx jy jz ka in kb io kc iq kd ir ke it kf iu kg kh bi translated"><strong class="ak">进口:</strong></h1><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es ls"><img src="../Images/a42c9652897cb7d3b1d8af6eebd492d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NNdCBjs--eKfHd9UGBETcw.png"/></div></div></figure><p id="403e" class="pw-post-body-paragraph lf lg hh kk b kl lx ii lh kn ly il li kp lz lk ll kr ma ln lo kt mb lq lr kv ha bi translated">这些都是我在项目中使用的导入。大多数是不言自明的——其他的将在出现时讨论。</p></div><div class="ab cl jj jk go jl" role="separator"><span class="jm bw bk jn jo jp"/><span class="jm bw bk jn jo jp"/><span class="jm bw bk jn jo"/></div><div class="ha hb hc hd he"><h1 id="c355" class="jq jr hh bd js jt ju jv jw jx jy jz ka in kb io kc iq kd ir ke it kf iu kg kh bi translated"><strong class="ak">文本清理方法:</strong></h1><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es mc"><img src="../Images/065139b8a2a35bc1c4bc5a1fea3dcde4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cF50mpTY6UWXpVULaWKvFA.png"/></div></div></figure><p id="d700" class="pw-post-body-paragraph lf lg hh kk b kl lx ii lh kn ly il li kp lz lk ll kr ma ln lo kt mb lq lr kv ha bi translated">作为人，我们自动解析屏幕上的单词，不让不同的上下文影响我们对它们的理解。清理分析出不必要的噪音，如发音、数字和符号，这样就只剩下单词了。</p><p id="4481" class="pw-post-body-paragraph lf lg hh kk b kl lx ii lh kn ly il li kp lz lk ll kr ma ln lo kt mb lq lr kv ha bi translated">使用re python库，我们可以使用正则表达式在字符串中找到不需要的模式并删除它们。检查<a class="ae ji" href="https://regex101.com/" rel="noopener ugc nofollow" target="_blank">https://regex101.com</a>来测试你自己的。</p></div><div class="ab cl jj jk go jl" role="separator"><span class="jm bw bk jn jo jp"/><span class="jm bw bk jn jo jp"/><span class="jm bw bk jn jo"/></div><div class="ha hb hc hd he"><h1 id="6555" class="jq jr hh bd js jt ju jv jw jx jy jz ka in kb io kc iq kd ir ke it kf iu kg kh bi translated"><strong class="ak">创建熊猫数据框:</strong></h1><p id="a42c" class="pw-post-body-paragraph lf lg hh kk b kl km ii lh kn ko il li kp lj lk ll kr lm ln lo kt lp lq lr kv ha bi translated">Pandas库提供了一个易于使用的直观数据结构。我们所要做的就是填充一个字典对象并调用pd。DataFrame()。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es md"><img src="../Images/0e84c9dea7c49da8c3e0b7f1cb106955.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sFPVXJ-qVynGk7DyubiwAg.png"/></div></div><figcaption class="je jf et er es jg jh bd b be z dx translated">收集所有文件路径</figcaption></figure><p id="677a" class="pw-post-body-paragraph lf lg hh kk b kl lx ii lh kn ly il li kp lz lk ll kr ma ln lo kt mb lq lr kv ha bi translated">Kaggle将JSON格式的文章存储在子目录中，访问它们最简单的方法是添加每篇文章的完整文件路径。json文件添加到一个列表中，并重复调用json_load(filepath)。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es me"><img src="../Images/8f6897abeee9bbb7eca5907edcc2aa47.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u2H7YxmOGRW_FaqQPvrc-w.png"/></div></div></figure><p id="8634" class="pw-post-body-paragraph lf lg hh kk b kl lx ii lh kn ly il li kp lz lk ll kr ma ln lo kt mb lq lr kv ha bi translated">这段代码中有很多内容，但实际上并不复杂。我们只是从json文件中检索数据，然后对其进行清理、词干化和标记化，然后将数据添加到字典中。</p><p id="5080" class="pw-post-body-paragraph lf lg hh kk b kl lx ii lh kn ly il li kp lz lk ll kr ma ln lo kt mb lq lr kv ha bi translated">词干分析字符串并删除结尾，这样剩下的就是单词的词干。于是“跑得快的人比跑得慢的人跑得快”这句话就变成了“跑得快比跑得快跑得慢”。这很有帮助，因为作为人，我们理解跑步者、跑步和跑步之间的语义联系——但是对于ML算法，我们必须使这种联系更加明显。</p><p id="e66d" class="pw-post-body-paragraph lf lg hh kk b kl lx ii lh kn ly il li kp lz lk ll kr ma ln lo kt mb lq lr kv ha bi translated">标记化使每个单独的单词都有自己的标记，这种格式使得统计单词的频率和创建词典变得容易。</p><p id="5333" class="pw-post-body-paragraph lf lg hh kk b kl lx ii lh kn ly il li kp lz lk ll kr ma ln lo kt mb lq lr kv ha bi translated">最后，我们删除所有包含在停用词数组中的标记。停用词是非常常见的词，它们对模型几乎没有任何有意义的贡献。Gensim提供了一个最常用的列表，只需导入即可使用。</p><p id="0c14" class="pw-post-body-paragraph lf lg hh kk b kl lx ii lh kn ly il li kp lz lk ll kr ma ln lo kt mb lq lr kv ha bi translated">到了这一步，我们所有可读的科学文章都变成了一堆不协调的单词。</p></div><div class="ab cl jj jk go jl" role="separator"><span class="jm bw bk jn jo jp"/><span class="jm bw bk jn jo jp"/><span class="jm bw bk jn jo"/></div><div class="ha hb hc hd he"><h1 id="9b79" class="jq jr hh bd js jt ju jv jw jx jy jz ka in kb io kc iq kd ir ke it kf iu kg kh bi translated"><strong class="ak">训练LDA模型:</strong></h1><p id="fa68" class="pw-post-body-paragraph lf lg hh kk b kl km ii lh kn ko il li kp lj lk ll kr lm ln lo kt lp lq lr kv ha bi translated">为了训练LDA，我们需要4样东西:id2单词字典、语料库、主题数量和通过次数。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es mf"><img src="../Images/6716b729893430376f17130253c238de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3XFBXibsRr_w18rZS6KlXw.png"/></div></div></figure><p id="bff6" class="pw-post-body-paragraph lf lg hh kk b kl lx ii lh kn ly il li kp lz lk ll kr ma ln lo kt mb lq lr kv ha bi translated">Id2单词字典:这个字典为输入的文本集合中的每个不同的单词分配一个id。</p><p id="cf5e" class="pw-post-body-paragraph lf lg hh kk b kl lx ii lh kn ly il li kp lz lk ll kr ma ln lo kt mb lq lr kv ha bi translated">语料库:语料库是模型将被训练的每个文档的字典中每个单词的频率。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es mg"><img src="../Images/1595031da44772b9460570cc166154f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UtKzX6mOgdlm1PfPEKq4kQ.png"/></div></div></figure><p id="3d8f" class="pw-post-body-paragraph lf lg hh kk b kl lx ii lh kn ly il li kp lz lk ll kr ma ln lo kt mb lq lr kv ha bi translated">主题数量:主题数量是模型应该将单词分成的概率聚类的数量。对于这种模式，我们将使用150个稍微多一点的主题。</p><p id="1da3" class="pw-post-body-paragraph lf lg hh kk b kl lx ii lh kn ly il li kp lz lk ll kr ma ln lo kt mb lq lr kv ha bi translated">通过次数:训练模型将通过整个语料库更新概率的次数。</p></div><div class="ab cl jj jk go jl" role="separator"><span class="jm bw bk jn jo jp"/><span class="jm bw bk jn jo jp"/><span class="jm bw bk jn jo"/></div><div class="ha hb hc hd he"><h1 id="d00f" class="jq jr hh bd js jt ju jv jw jx jy jz ka in kb io kc iq kd ir ke it kf iu kg kh bi translated"><strong class="ak">创建提示语料库:</strong></h1><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es mh"><img src="../Images/d3087a42c440da998962b191fa2aa304.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_XVqoe66pmFau_pGO84Tzw.png"/></div></div></figure><p id="76dd" class="pw-post-body-paragraph lf lg hh kk b kl lx ii lh kn ly il li kp lz lk ll kr ma ln lo kt mb lq lr kv ha bi translated">每个提示都有一个子目录，里面全是相关的文章，所以我们可以写一个方法来收集和组合它们的标题。然后，我们可以将它与原始提示连接起来，创建一个最终的语料库，我们可以在查找其他相关文章时使用它作为比较。</p><p id="bdbf" class="pw-post-body-paragraph lf lg hh kk b kl lx ii lh kn ly il li kp lz lk ll kr ma ln lo kt mb lq lr kv ha bi translated">然后，我们必须清理，阻止和标记字符串。</p></div><div class="ab cl jj jk go jl" role="separator"><span class="jm bw bk jn jo jp"/><span class="jm bw bk jn jo jp"/><span class="jm bw bk jn jo"/></div><div class="ha hb hc hd he"><h1 id="fc4a" class="jq jr hh bd js jt ju jv jw jx jy jz ka in kb io kc iq kd ir ke it kf iu kg kh bi translated"><strong class="ak">计算主题分布:</strong></h1><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es mi"><img src="../Images/99662cc2eb08e9ce0b1ad046cface7fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oaVUG7EDeqq9DgAh7pcWOQ.png"/></div></div></figure><p id="8155" class="pw-post-body-paragraph lf lg hh kk b kl lx ii lh kn ly il li kp lz lk ll kr ma ln lo kt mb lq lr kv ha bi translated">首先，我们创建helper方法，该方法返回给定文章的主题分布。然后我们在每篇文章上调用它，并将结果保存到一个列表中，我们可以将该列表附加到数据框中。</p><p id="7340" class="pw-post-body-paragraph lf lg hh kk b kl lx ii lh kn ly il li kp lz lk ll kr ma ln lo kt mb lq lr kv ha bi translated">到底什么是话题？在这种特定情况下，主题是单词的概率分布。对于相似的主题，相关的单词将具有更高的概率。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es mj"><img src="../Images/cd0f6edd27cd4cd792a248af720cbc54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2aJH8LrgQX88XiywCWK_cQ.png"/></div></div></figure><p id="ee4a" class="pw-post-body-paragraph lf lg hh kk b kl lx ii lh kn ly il li kp lz lk ll kr ma ln lo kt mb lq lr kv ha bi translated">这些并不是完整的主题分布，因为它们没有涵盖所有150个主题。所以我们用另一个辅助方法create_full_vectors重复这个过程，它创建全概率向量。</p></div><div class="ab cl jj jk go jl" role="separator"><span class="jm bw bk jn jo jp"/><span class="jm bw bk jn jo jp"/><span class="jm bw bk jn jo"/></div><div class="ha hb hc hd he"><h1 id="1df3" class="jq jr hh bd js jt ju jv jw jx jy jz ka in kb io kc iq kd ir ke it kf iu kg kh bi translated"><strong class="ak">检索相关文章:</strong></h1><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es mk"><img src="../Images/50ee4b700376aff76e892c4683cc8919.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yVxOQW4fNH-m-6CiAK3gtQ.png"/></div></div></figure><p id="a5b4" class="pw-post-body-paragraph lf lg hh kk b kl lx ii lh kn ly il li kp lz lk ll kr ma ln lo kt mb lq lr kv ha bi translated">为了比较文章，我们将使用辣库提供的jensen-shannon距离。文章之间的距离越小，它们的相关性就越强。</p></div><div class="ab cl jj jk go jl" role="separator"><span class="jm bw bk jn jo jp"/><span class="jm bw bk jn jo jp"/><span class="jm bw bk jn jo"/></div><div class="ha hb hc hd he"><h1 id="fadc" class="jq jr hh bd js jt ju jv jw jx jy jz ka in kb io kc iq kd ir ke it kf iu kg kh bi translated"><strong class="ak">验证:</strong></h1><p id="f6d4" class="pw-post-body-paragraph lf lg hh kk b kl km ii lh kn ko il li kp lj lk ll kr lm ln lo kt lp lq lr kv ha bi translated">检查结果，并查看顶部文档与提示的相关程度。对于我们的模型，我们只使用了随机的2000篇文章，所以我们可能会错过一些文章。</p></div><div class="ab cl jj jk go jl" role="separator"><span class="jm bw bk jn jo jp"/><span class="jm bw bk jn jo jp"/><span class="jm bw bk jn jo"/></div><div class="ha hb hc hd he"><h1 id="5c78" class="jq jr hh bd js jt ju jv jw jx jy jz ka in kb io kc iq kd ir ke it kf iu kg kh bi translated"><strong class="ak">下一步:</strong></h1><p id="d0fe" class="pw-post-body-paragraph lf lg hh kk b kl km ii lh kn ko il li kp lj lk ll kr lm ln lo kt lp lq lr kv ha bi translated">这个模型可以通过几种不同的方式来改进性能。</p><ul class=""><li id="a8f3" class="ki kj hh kk b kl lx kn ly kp ml kr mm kt mn kv mo kx ky kz bi translated">执行一些EDA和一些更具体的停用词被过滤掉。你可以通过绘制一个单词在文档中至少出现x次的直方图来做到这一点。如果一个单词在大约80%的文档中出现了至少x次，那么删除它可能是安全的。</li><li id="6fa2" class="ki kj hh kk b kl la kn lb kp lc kr ld kt le kv mo kx ky kz bi translated">测试不同数量的训练主题。我们做了150个——但是看看100个和50个主题的效果如何。</li><li id="bf15" class="ki kj hh kk b kl la kn lb kp lc kr ld kt le kv mo kx ky kz bi translated">对超过2000个文档进行训练和测试，这会给你一个更精确的模型，也会给你一个可以容纳更多相关文章的更大的文档库。</li><li id="923e" class="ki kj hh kk b kl la kn lb kp lc kr ld kt le kv mo kx ky kz bi translated">尝试用不同的形式输入文章。也许简短的特定关键字加载查询会比大量随机相关信息更好？</li><li id="ade3" class="ki kj hh kk b kl la kn lb kp lc kr ld kt le kv mo kx ky kz bi translated">二元模型和三元模型——除了为每个唯一的单词创建一个字典条目之外，还要为每个唯一的单词对和每个唯一的3个单词对创建一个字典条目。你可以从每一个文档中获得更多的信息——但是要注意训练时间。</li></ul></div><div class="ab cl jj jk go jl" role="separator"><span class="jm bw bk jn jo jp"/><span class="jm bw bk jn jo jp"/><span class="jm bw bk jn jo"/></div><div class="ha hb hc hd he"><h1 id="175d" class="jq jr hh bd js jt ju jv jw jx jy jz ka in kb io kc iq kd ir ke it kf iu kg kh bi translated"><strong class="ak">有用链接:</strong></h1><p id="2c22" class="pw-post-body-paragraph lf lg hh kk b kl km ii lh kn ko il li kp lj lk ll kr lm ln lo kt lp lq lr kv ha bi translated"><strong class="kk hi"> LDA教程</strong>——【https://www.youtube.com/watch?v=3mHy4OSyRf0】T4</p><p id="fce4" class="pw-post-body-paragraph lf lg hh kk b kl lx ii lh kn ly il li kp lz lk ll kr ma ln lo kt mb lq lr kv ha bi translated"><strong class="kk hi">Genism Docs</strong>——<a class="ae ji" href="https://gensim.readthedocs.io/en/latest/index.html" rel="noopener ugc nofollow" target="_blank">https://gensim.readthedocs.io/en/latest/index.html</a></p><p id="2c85" class="pw-post-body-paragraph lf lg hh kk b kl lx ii lh kn ly il li kp lz lk ll kr ma ln lo kt mb lq lr kv ha bi translated"><strong class="kk hi"> Kaggle数据</strong>—<a class="ae ji" href="https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/Allen-institute-for-ai/CORD-19-research-challenge</a></p></div></div>    
</body>
</html>