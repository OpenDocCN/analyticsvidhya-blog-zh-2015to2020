<html>
<head>
<title>Linear Regression using PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用PyTorch进行线性回归</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/linear-regression-using-pytorch-b12d694732ae?source=collection_archive---------23-----------------------#2020-06-18">https://medium.com/analytics-vidhya/linear-regression-using-pytorch-b12d694732ae?source=collection_archive---------23-----------------------#2020-06-18</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="54f8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一个变量的数学线性方程可以定义如下。</p><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="fbae" class="jm jn hi ji b fi jo jp l jq jr">y = mx+c</span></pre><p id="0d4f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了将它与现实世界的例子联系起来，让我们假设一家小公司想要根据一个月的平均温度来预测该月所需的25升饮用水瓶的数量。他们想要建立瓶子数量和月平均温度之间的模式[为了简单起见，我们假设员工数量是固定的]。该公司希望使用他们的历史数据来建立模型，以帮助他们实现这一目标。</p><p id="4b17" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">数据集的例子。</p><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="c648" class="jm jn hi ji b fi jo jp l jq jr">Month's Avg Temperature   Number of Bottles consumed in month<br/>35                                  4<br/>37                                  8</span></pre><p id="9bc5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们试着把它和方程式联系起来。</p><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="1ef4" class="jm jn hi ji b fi jo jp l jq jr">Temperature is x  and y is bottles </span><span id="2337" class="jm jn hi ji b fi js jp l jq jr">now we have to find m and c. so that when we put x in below equation it should help with prediction of number of bottles</span><span id="53c2" class="jm jn hi ji b fi js jp l jq jr">y = mx+c</span></pre><p id="d4d0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本文中，我将重点介绍使用Pytorch的实现。数学细节请参考我以前的帖子。<a class="ae jt" href="https://www.linkedin.com/pulse/linear-regression-from-scratch-java-nirmal-singh/" rel="noopener ugc nofollow" target="_blank">https://www . LinkedIn . com/feed/update/urn:李:activity:66486111139209003008/</a>或<a class="ae jt" rel="noopener" href="/@nirmal1067/linear-regression-from-scratch-in-java-dc7aead2ba04">https://medium . com/@ nirmal 1067/linear-regression-从零开始-in-java-dc7aead2ba04 </a></p><p id="25b7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">先决条件:PyTorch环境设置必须存在。</strong></p><p id="08a0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用下面的代码片段创建输入张量X，实际输出Y。这里E代表使输出非线性的误差</p><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="2c59" class="jm jn hi ji b fi jo jp l jq jr">X = torch.linspace(0,50,50).reshape(-1,1)<br/>torch.manual_seed(50)<br/>E = torch.randint(-8,9,(50,1),dtype=torch.float)<br/>Y = 5*X + 8 + E</span></pre><p id="ae3c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面是线性回归的代码。复制代码时缩进变得混乱。</p><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="7b82" class="jm jn hi ji b fi jo jp l jq jr">class LinearRegressionModel(nn.Module):<br/>    <br/>    #optimizer<br/>    <br/>    def __init__(self,in_Feature=1,out_Feature=1,learningRate=0.001):<br/>        super().__init__()<br/>        self.linear= nn.Linear(in_Feature,out_Feature)<br/>        self.optimizer = torch.optim.SGD(self.parameters(), lr = 0.001)<br/>        self.criterion = nn.MSELoss()<br/>    <br/>    def predict(self,inputs):<br/>        predict = self.linear(inputs)<br/>        return predict<br/>    <br/>    def printClassValues(self):<br/>        for name, param in self.named_parameters():<br/>            print(name, '\t', param.item())<br/>        <br/>    def trainModel(self,X,y,epochs=50):<br/>        #epochs = 100<br/>        losses = []</span><span id="cafa" class="jm jn hi ji b fi js jp l jq jr">for i in range(epochs):<br/>            i+=1<br/>            y_pred = self.predict(X)<br/>            loss = self.criterion(y_pred, y)<br/>            losses.append(loss)<br/>            print(f'epoch: {i:2}  loss: {loss.item():10.8f}  weight: {self.linear.weight.item():10.8f}  \<br/>            bias: {self.linear.bias.item():10.8f}') <br/>            self.optimizer.zero_grad()<br/>            loss.backward()<br/>            self.optimizer.step()</span></pre><p id="6641" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了测试下面的代码使用。这将用默认的偏差和权重初始化你的模型。</p><p id="249a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">LG model = LinearRegressionModel(1，1) <br/> lgModel.printClassValues()</p><p id="9976" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面一行代码将训练你的模型。</p><p id="1fa5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">lgModel.trainModel(X，Y)</p><p id="f173" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">训练时，你要留意体重和偏见是如何变化的。以下是我的模型的训练日志。</p><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="d836" class="jm jn hi ji b fi jo jp l jq jr">epoch:  1  loss: 24908.03906250  weight: -0.24355280              bias: 0.74757409<br/>epoch:  2  loss: 11715.38183594  weight: 8.90680599              bias: 1.02333665<br/>epoch:  3  loss: 5522.17285156  weight: 2.63715982              bias: 0.84102964<br/>epoch:  4  loss: 2614.80932617  weight: 6.93266582              bias: 0.97256958<br/>epoch:  5  loss: 1249.96154785  weight: 3.98936534              bias: 0.88907117<br/>epoch:  6  loss: 609.23602295  weight: 6.00579691              bias: 0.95290476<br/>epoch:  7  loss: 308.44332886  weight: 4.62402439              bias: 0.91578913<br/>epoch:  8  loss: 167.23051453  weight: 5.57056141              bias: 0.94783634<br/>epoch:  9  loss: 100.93089294  weight: 4.92183685              bias: 0.93249261<br/>epoch: 10  loss: 69.79891968  weight: 5.36611938              bias: 0.94961578<br/>epoch: 11  loss: 55.17618179  weight: 5.06151915              bias: 0.94449055<br/>epoch: 12  loss: 48.30352783  weight: 5.27002287              bias: 0.95460564<br/>epoch: 13  loss: 45.06904221  weight: 5.12696838              bias: 0.95427531<br/>epoch: 14  loss: 43.54253006  weight: 5.22478771              bias: 0.96109837<br/>epoch: 15  loss: 42.81778717  weight: 5.15756941              bias: 0.96301681<br/>epoch: 16  loss: 42.46943665  weight: 5.20342922              bias: 0.96829230<br/>epoch: 17  loss: 42.29781723  weight: 5.17181253              bias: 0.97126424<br/>epoch: 18  loss: 42.20915604  weight: 5.19327927              bias: 0.97581106<br/>epoch: 19  loss: 42.15945053  weight: 5.17837572              bias: 0.97927547<br/>epoch: 20  loss: 42.12804413  weight: 5.18839121              bias: 0.98347813<br/>epoch: 21  loss: 42.10523224  weight: 5.18133450              bias: 0.98717159<br/>epoch: 22  loss: 42.08646393  weight: 5.18597412              bias: 0.99121052<br/>epoch: 23  loss: 42.06961060  weight: 5.18260002              bias: 0.99500942<br/>epoch: 24  loss: 42.05364609  weight: 5.18471670              bias: 0.99896938<br/>epoch: 25  loss: 42.03814316  weight: 5.18307209              bias: 1.00281560<br/>epoch: 26  loss: 42.02280426  weight: 5.18400383              bias: 1.00673640<br/>epoch: 27  loss: 42.00761795  weight: 5.18317080              bias: 1.01060271<br/>epoch: 28  loss: 41.99245834  weight: 5.18354702              bias: 1.01450300<br/>epoch: 29  loss: 41.97735596  weight: 5.18309498              bias: 1.01837671<br/>epoch: 30  loss: 41.96227264  weight: 5.18321037              bias: 1.02226520<br/>epoch: 31  loss: 41.94721603  weight: 5.18293667              bias: 1.02614009<br/>epoch: 32  loss: 41.93214798  weight: 5.18293047              bias: 1.03002095<br/>epoch: 33  loss: 41.91712952  weight: 5.18274069              bias: 1.03389442<br/>epoch: 34  loss: 41.90211487  weight: 5.18267632              bias: 1.03776956<br/>epoch: 35  loss: 41.88711548  weight: 5.18252659              bias: 1.04164016<br/>epoch: 36  loss: 41.87213898  weight: 5.18243551              bias: 1.04551053<br/>epoch: 37  loss: 41.85715485  weight: 5.18230391              bias: 1.04937768<br/>epoch: 38  loss: 41.84220123  weight: 5.18220091              bias: 1.05324376<br/>epoch: 39  loss: 41.82727432  weight: 5.18207836              bias: 1.05710721<br/>epoch: 40  loss: 41.81235123  weight: 5.18196821              bias: 1.06096911<br/>epoch: 41  loss: 41.79744339  weight: 5.18185043              bias: 1.06482875<br/>epoch: 42  loss: 41.78254318  weight: 5.18173838              bias: 1.06868660<br/>epoch: 43  loss: 41.76766968  weight: 5.18162251              bias: 1.07254231<br/>epoch: 44  loss: 41.75281525  weight: 5.18150854              bias: 1.07639611<br/>epoch: 45  loss: 41.73797607  weight: 5.18139362              bias: 1.08024788<br/>epoch: 46  loss: 41.72313309  weight: 5.18127966              bias: 1.08409774<br/>epoch: 47  loss: 41.70832825  weight: 5.18116522              bias: 1.08794558<br/>epoch: 48  loss: 41.69353104  weight: 5.18105078              bias: 1.09179139<br/>epoch: 49  loss: 41.67874527  weight: 5.18093681              bias: 1.09563529<br/>epoch: 50  loss: 41.66396332  weight: 5.18082237              bias: 1.09947717</span></pre><p id="76ba" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一旦模型被训练，使用下面代码片段生成输出预测输出“O ”,并使用matplotlib进行图形比较</p><p id="5f0e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">o = X * LG model . linear . weight+LG model . linear . bias<br/>PLT . scatter(X . detach()。numpy()，y . numpy())<br/>PLT . plot(x . detach()。numpy()，O.detach()。numpy()，' r ')</p><p id="5dab" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面是我的模型的图表。</p><figure class="jd je jf jg fd jv er es paragraph-image"><div role="button" tabindex="0" class="jw jx di jy bf jz"><div class="er es ju"><img src="../Images/477e429be99c4e3a76997c8f6a0edad9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_Q3AU_Pn5QJ2LGsskUST4Q.png"/></div></div></figure></div></div>    
</body>
</html>