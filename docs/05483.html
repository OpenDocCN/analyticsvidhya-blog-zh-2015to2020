<html>
<head>
<title>Topics in Computer Vision — The YOLO Algorithm</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">计算机视觉专题——YOLO算法</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/topics-in-computer-vision-the-yolo-algorithm-4f04e3bc1e14?source=collection_archive---------28-----------------------#2020-04-22">https://medium.com/analytics-vidhya/topics-in-computer-vision-the-yolo-algorithm-4f04e3bc1e14?source=collection_archive---------28-----------------------#2020-04-22</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="118f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">你只看一次</strong>或“<strong class="ih hj"> YOLO </strong>”是一种物体检测算法的名字，在<em class="jd"> Redmon </em> <em class="jd">等人</em>2016年的一篇研究论文中受到洗礼。YOLO实现了用于自动驾驶汽车等尖端技术的实时物体检测。让我们看看是什么让这个算法如此受欢迎，并浏览一下它的工作概况。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/3c9e0268028bce2d35dba46b91ab1e14.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BHHGXu9UX69B6e30yvtrHg.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">对象检测示例</figcaption></figure><h1 id="3ea9" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">背景</h1><h2 id="f23c" class="ks jv hi bd jw kt ku kv ka kw kx ky ke iq kz la ki iu lb lc km iy ld le kq lf bi translated">实时的重要性</h2><p id="9c9f" class="pw-post-body-paragraph if ig hi ih b ii lg ik il im lh io ip iq li is it iu lj iw ix iy lk ja jb jc hb bi translated">人类可以看到图像，并立即识别其中的对象、它们的位置和相对位置。这使我们能够用很少的意识思考来完成复杂的任务，比如开车。因此，训练汽车自动驾驶需要相似的反应能力和准确性。在其最基本的形式中，这种系统必须能够剖析道路的实时视频，检测各种类型的物体，并在继续决定路径之前学习它们的真实世界位置，所有这些都是实时的。</p><h2 id="1b47" class="ks jv hi bd jw kt ku kv ka kw kx ky ke iq kz la ki iu lb lc km iy ld le kq lf bi translated">在YOLO之前</h2><p id="3d17" class="pw-post-body-paragraph if ig hi ih b ii lg ik il im lh io ip iq li is it iu lj iw ix iy lk ja jb jc hb bi translated">先前的检测系统使用在测试图像的不同切片上评估的分类器。例如，可变形零件模型(<strong class="ih hj"> DPM </strong>)涉及在图像中均匀间隔的位置上滑动窗口，并在这些零件上运行分类器。<strong class="ih hj"> R-CNN </strong>(基于区域的卷积神经网络)，另一个模型，运行分割算法将图像分成斑点，然后对这些斑点运行分类器。但是<strong class="ih hj">低速</strong>和<strong class="ih hj">难以优化</strong>困扰着这样的前YOLO系统。</p><h1 id="2967" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">YOLO算法</h1><h2 id="2aee" class="ks jv hi bd jw kt ku kv ka kw kx ky ke iq kz la ki iu lb lc km iy ld le kq lf bi translated">工作</h2><p id="a530" class="pw-post-body-paragraph if ig hi ih b ii lg ik il im lh io ip iq li is it iu lj iw ix iy lk ja jb jc hb bi translated">YOLO将物体检测重新定义为一个回归问题。它将单个卷积神经网络(CNN)应用于整个图像，将图像划分为网格，并预测每个网格的类别概率和边界框。例如，取一个100×100的图像。我们把它分成网格，比如说7x7。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es ll"><img src="../Images/11dfe53a5d7646a9794094a5837defa1.png" data-original-src="https://miro.medium.com/v2/resize:fit:568/format:webp/1*2VgyMcgYAtidMnYekiqh3g.jpeg"/></div></figure><p id="8aec" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于每个网格，网络预测一个边界框和对应于每个类别(汽车、行人、交通灯等)的概率。).</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es lm"><img src="../Images/1a6e37fb63674749435d3bbc3a0cc0d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:536/format:webp/1*Kd6HXiHUfMqWtDL0ev12CA.png"/></div></figure><p id="642e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">每个边界框可以用四个描述符来描述:</p><ol class=""><li id="ba26" class="ln lo hi ih b ii ij im in iq lp iu lq iy lr jc ls lt lu lv bi translated">边界框的中心</li><li id="9ac4" class="ln lo hi ih b ii lw im lx iq ly iu lz iy ma jc ls lt lu lv bi translated">高度</li><li id="2e4f" class="ln lo hi ih b ii lw im lx iq ly iu lz iy ma jc ls lt lu lv bi translated">宽度</li><li id="9c38" class="ln lo hi ih b ii lw im lx iq ly iu lz iy ma jc ls lt lu lv bi translated">映射到对象所属类的值</li></ol><p id="ddf2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">此外，该算法还预测了包围盒中存在物体的概率。如果对象的中心落入网格单元，则该网格单元负责检测该对象。每个网格中会有多个边界框。在训练时，我们只希望每个对象有一个边界框。因此，我们指定一个框负责基于哪个框与地面真实框具有最高重叠来预测对象。</p><p id="f329" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后，我们在每个类的对象上应用一个名为“<strong class="ih hj">非最大抑制</strong>的方法来过滤掉“置信度”小于阈值的边界框。这给了我们对图像的预测。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es mb"><img src="../Images/1545424160e64dfa6063cb036a235ecc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fomUp3CB6iWRPKQt2hX6xQ.png"/></div></div></figure><h1 id="4723" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">重要</h1><p id="7002" class="pw-post-body-paragraph if ig hi ih b ii lg ik il im lh io ip iq li is it iu lj iw ix iy lk ja jb jc hb bi translated">YOLO是<strong class="ih hj">速度极快的</strong>。由于检测问题被构造为回归问题，因此不需要复杂的流水线。比'<strong class="ih hj"> R-CNN </strong>快<strong class="ih hj"> 1000x </strong>以上，比'<strong class="ih hj"> Fast R-CNN </strong>快<strong class="ih hj"> 100x </strong>以上。它能够处理小于25毫秒延迟的实时视频流。它还实现了比现有实时系统两倍多的精度。同样重要的是，YOLO正在沿着'<strong class="ih hj">端到端深度学习的路线</strong>实践。</p></div></div>    
</body>
</html>