<html>
<head>
<title>BEBLID: Why local feature descriptors are still important in 2020?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">BEBLID:为什么局部特征描述符在2020年仍然重要？</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/beblid-why-feature-descriptors-are-still-important-in-2020-10f0526886f?source=collection_archive---------6-----------------------#2020-05-06">https://medium.com/analytics-vidhya/beblid-why-feature-descriptors-are-still-important-in-2020-10f0526886f?source=collection_archive---------6-----------------------#2020-05-06</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="77d3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最近，我们发表了一篇论文，介绍了一种新的局部图像特征描述符，称为<strong class="ih hj">be blid:Boosted Efficient Binary Local Image Descriptor。</strong>我们提供了它的源代码:【https://github.com/iago-suarez/BEBLID】T2这篇文章是对它的非正式介绍，我希望能让你对它感兴趣。</p><div class="je jf ez fb jg jh"><a href="https://github.com/iago-suarez/BEBLID" rel="noopener  ugc nofollow" target="_blank"><div class="ji ab dw"><div class="jj ab jk cl cj jl"><h2 class="bd hj fi z dy jm ea eb jn ed ef hh bi translated">埃古-苏亚雷斯/贝布利德</h2><div class="jo l"><h3 class="bd b fi z dy jm ea eb jn ed ef dx translated">这个库包含BEBLID本地图像描述符的源代码，该代码依赖于OpenCV 4。</h3></div><div class="jp l"><p class="bd b fp z dy jm ea eb jn ed ef dx translated">github.com</p></div></div><div class="jq l"><div class="jr l js jt ju jq jv jw jh"/></div></div></a></div><p id="0046" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果说最近在计算机视觉领域发生了一场革命，那毫无疑问就是深度学习。卷积神经元网络(CNN)是自动学习非常丰富的图像特征的惊人工具。它们功能强大，可端到端训练，代表非常抽象的知识，但它们有一个主要缺点:它们速度慢！如果你经常尝试把这种网络植入你的手机，你可能会看到你的手机开始燃烧，电池耗尽。这就是为什么高效视觉在今天仍然有意义。</p><p id="a4fe" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果可能的话，这在一个特殊情况下变得更加重要:3D视觉。大多数三维视觉技术，如同步定位和映射(SLAM)，运动结构(SfM)或实时自定位，都依赖于快速特征匹配来反映某些场景模型的特征和摄像机当前看到的特征。</p><figure class="jy jz ka kb fd kc er es paragraph-image"><div role="button" tabindex="0" class="kd ke di kf bf kg"><div class="er es jx"><img src="../Images/589db58652d7ddecb3e3de83524b76b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UEXYWMnmzJWLge1MUAFnyA.png"/></div></div><figcaption class="ki kj et er es kk kl bd b be z dx translated">图片取自ORB-SLAM2演示:【https://www.youtube.com/watch?v=j2ZNuBCr4SA T4】</figcaption></figure><p id="d2a9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">正是在这种情况下，低级功能仍然扮演着重要的角色。但是什么是地方特色呢？嗯，只是一个容易识别的区域:一个斑点，一个角落，一个片段…如果你想要一个很棒的介绍，我推荐OpenCV的教程。重点是，我们通常希望我们的方法以这样一种方式记忆这些角，以便下次它看到它们时，它说:嘿，我想我们以前见过！这就是BEBLID所做的。</p><p id="b29b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">BEBLID使用一串0和1(二进制字符串)描述了图像的一小部分，这样，下次我们用另一种照明或从不同的角度检测图像的同一部分时，两个二进制字符串将非常相似。二进制字符串就像图像指纹。</p><p id="2b9d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">与其他类似的描述符(如ORB、LATCH或BinBoost)相比，BEBLID更快、更准确地描述了斑点和角落，描述一幅图像不到2毫秒。详见文中的<a class="ae jd" href="https://www.researchgate.net/publication/340686020_BEBLID_Boosted_Efficient_Binary_Local_Image_Descriptor" rel="noopener ugc nofollow" target="_blank">。在这里，我将向您展示一个如何使用它的示例:</a></p><figure class="jy jz ka kb fd kc"><div class="bz dy l di"><div class="km kn l"/></div></figure><p id="b891" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">该示例使用OpenCV 4.1.0。基本上，它导入BEBLID描述符，你可以在这里找到<a class="ae jd" href="https://github.com/iago-suarez/BEBLID/blob/master/BEBLID.h" rel="noopener ugc nofollow" target="_blank"/>，检测ORB关键点，使用BEBLID进行描述，与OpenCV BFMatcher进行匹配，并打印两幅图像之间的匹配特征。在BEBLID演示中有完整的代码<a class="ae jd" href="https://github.com/iago-suarez/BEBLID/blob/master/demo.cpp" rel="noopener ugc nofollow" target="_blank">。</a></p><figure class="jy jz ka kb fd kc er es paragraph-image"><div role="button" tabindex="0" class="kd ke di kf bf kg"><div class="er es ko"><img src="../Images/2d8a7dedb3209917ca83163586d13a22.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yIbjNEMW69fZZg7rWWv0Tw.jpeg"/></div></div></figure><p id="8fdf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们计划做一个pull请求，在OpenCV中包含描述符，所以在不久的将来，我们将提供Python和Java演示。现在，很抱歉，它只是C++。</p><p id="7fda" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">总而言之:</p><ul class=""><li id="75ea" class="kp kq hi ih b ii ij im in iq kr iu ks iy kt jc ku kv kw kx bi translated">BEBLID是一个非常有效的二值兴趣点描述符。</li><li id="e9f3" class="kp kq hi ih b ii ky im kz iq la iu lb iy lc jc ku kv kw kx bi translated">它在智能手机CPU中不到2毫秒的时间内提取每幅图像的2000个描述符。如果你像我一样正在做增强现实，这是很棒的。</li><li id="ea35" class="kp kq hi ih b ii ky im kz iq la iu lb iy lc jc ku kv kw kx bi translated">它和ORB一样快，有比BinBoost更好的地图，并且在HPatches bechmark中接近筛选。</li></ul></div></div>    
</body>
</html>