<html>
<head>
<title>A Quick Guide to Loss Functions</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">损失函数快速指南</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/a-quick-guide-to-loss-functions-60d78547fecb?source=collection_archive---------13-----------------------#2019-10-11">https://medium.com/analytics-vidhya/a-quick-guide-to-loss-functions-60d78547fecb?source=collection_archive---------13-----------------------#2019-10-11</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/21dec81b1af363bb47475ab7133ca61e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*VlPgDUvOiW8JWUkf"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">卢克·切瑟在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><p id="4e69" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我想通过这个博客分享的议程是，在机器学习中，在我们训练过程的每一次迭代中，我们都会比较我们的预测和实际输出。该比较产生误差值，并且该误差是我们在使用优化策略梯度下降的学习过程中最小化的。</p><p id="359a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们实际计算误差值的方法是使用<strong class="ix hj"> <em class="jt">损失函数</em> </strong>。它量化了当正确的输出是<strong class="ix hj"> Y(相关值)</strong>时，如果我们使用当前的模型对<strong class="ix hj"> X(独立值)</strong>进行预测，我们会错得有多离谱。我们的主要目标是尽可能地将其降至零。</p><p id="7f3e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">在机器学习的背景下，我们将损失函数大致分为两种类型:</strong></p><ol class=""><li id="f9a2" class="ju jv hi ix b iy iz jc jd jg jw jk jx jo jy js jz ka kb kc bi translated">分类损失</li><li id="7641" class="ju jv hi ix b iy kd jc ke jg kf jk kg jo kh js jz ka kb kc bi translated">回归损失</li></ol><h2 id="38d8" class="ki kj hi bd kk kl km kn ko kp kq kr ks jg kt ku kv jk kw kx ky jo kz la lb lc bi translated"><strong class="ak"> <em class="ld"> 1 —分类损失:</em> </strong></h2><p id="3eeb" class="pw-post-body-paragraph iv iw hi ix b iy le ja jb jc lf je jf jg lg ji jj jk lh jm jn jo li jq jr js hb bi translated">它有两种类型:<strong class="ix hj">交叉熵</strong>和<strong class="ix hj">铰链损失。</strong></p><ul class=""><li id="a567" class="ju jv hi ix b iy iz jc jd jg jw jk jx jo jy js lj ka kb kc bi translated"><strong class="ix hj">交叉熵损失</strong> —也称为对数损失。它由所有预测概率/输出的负值之和乘以(实际输出)来确定，因为有许多as类，这将给出我们的误差。</li></ul><figure class="ll lm ln lo fd ij er es paragraph-image"><div class="er es lk"><img src="../Images/5ce279153891dd515fedc9f5263948d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1096/format:webp/1*PDtIfRHpMfbbXbhj26I-OA.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">交叉熵损失函数</figcaption></figure><p id="2bea" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这里，<strong class="ix hj"><em class="jt"/></strong>为实际输出，<strong class="ix hj"> <em class="jt"> p(yi) </em> </strong>为第<em class="jt"/><strong class="ix hj">第</strong>个位置的预测输出概率，N为训练样本数</p><ul class=""><li id="d449" class="ju jv hi ix b iy iz jc jd jg jw jk jx jo jy js lj ka kb kc bi translated"><strong class="ix hj">铰链损失— </strong>通常在<strong class="ix hj"> SVM(支持向量机)中用于分类的另一种损失函数，</strong>它不仅在预测不正确时而且在预测不可信时惩罚预测。它惩罚了那些真正意义上的预测。但是自信正确的预测不会受到任何惩罚。</li></ul><figure class="ll lm ln lo fd ij er es paragraph-image"><div class="er es lp"><img src="../Images/bbef3e53d9eeaf4458aef5b95c6c5d45.png" data-original-src="https://miro.medium.com/v2/resize:fit:1186/format:webp/1*VWWSpFBYc-ZVi2FuJeGTjA.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">铰链损失函数</figcaption></figure><p id="6caa" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">其中<strong class="ix hj"> <em class="jt">【易】</em></strong>为实际输出<strong class="ix hj"><em class="jt">【hθ(Xi)</em></strong>为我们在<strong class="ix hj"> <em class="jt">与</em> </strong>训练示例的假设/预测输出概率。</p><p id="38f4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">因此，由此我们可以形式化我们的标签可以是1或-1，因此当符号匹配并且<strong class="ix hj"> <em class="jt"> hθ(xi) </em> </strong>大于或等于1时，损耗为零。</p><p id="0205" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">与交叉熵损失相比，铰链损失更容易计算。用梯度下降训练更快，因为大部分时间梯度为零。所以，我们不需要更新权重。如果我们想以较低的精度进行实时预测，总是依赖于铰链损失超过交叉熵损失。但是如果精度比速度重要，那么我们应该总是用交叉熵损失。</p><h2 id="59f9" class="ki kj hi bd kk kl km kn ko kp kq kr ks jg kt ku kv jk kw kx ky jo kz la lb lc bi translated"><strong class="ak"> <em class="ld"> 2。回归损失— </em> </strong></h2><p id="eb48" class="pw-post-body-paragraph iv iw hi ix b iy le ja jb jc lf je jf jg lg ji jj jk lh jm jn jo li jq jr js hb bi translated"><em class="jt">它有三种类型</em> <strong class="ix hj"> <em class="jt">均方、绝对</em> </strong> <em class="jt">和</em> <strong class="ix hj"> <em class="jt">胡贝尔损失。</em>T15】</strong></p><ul class=""><li id="fc5e" class="ju jv hi ix b iy iz jc jd jg jw jk jx jo jy js lj ka kb kc bi translated"><strong class="ix hj">均方损失或L2损失</strong> —它计算或测量模型预测与正确值的平均偏差量。</li></ul><figure class="ll lm ln lo fd ij er es paragraph-image"><div class="er es lq"><img src="../Images/3ae63d7234e6ab5adb6ad918805b0984.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/1*D-7K2fUG8Ev3iA_81svXjw.gif"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">均方误差损失函数</figcaption></figure><p id="3248" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这里<strong class="ix hj"><em class="jt"/></strong>为实际输出，<strong class="ix hj"> <em class="jt"> p(yi) </em> </strong>为第<em class="jt"> i </em> <strong class="ix hj"> th </strong>位置的预测输出概率，<strong class="ix hj"> n </strong>为训练样本数。</p><p id="f234" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">因此，在MSE中，我们可以计算预测输出和实际输出之间的差异，求平方，我们将对每个训练示例或数据点进行计算，将它们相加，然后除以训练示例的总数。平方的原因是让我们的结果是二次的，所以当我们绘图时，它将只有一个全局最小值。因此，使用像梯度下降这样的优化策略，我们不会陷入局部最小值，这将最终帮助我们找到理想的参数值来优化目标函数。</p><figure class="ll lm ln lo fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lr"><img src="../Images/34139f1c5374bd086a432b5f850f30da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T9xxgTtdwFAM9twa44Ojhw.jpeg"/></div></div></figure><ul class=""><li id="da51" class="ju jv hi ix b iy iz jc jd jg jw jk jx jo jy js lj ka kb kc bi translated"><strong class="ix hj">平均绝对误差或L1损失</strong> —它计算一组预测中误差的平均大小，而不考虑它们的方向。我们对预测输出和实际输出之间的绝对差异的测试样本取平均值，其中所有个体差异具有相同的权重。在平方误差中，我们通过平方它们来惩罚较大的偏差，这使得异常值更大。因此，平方后，平均绝对误差比均方误差对异常值更稳健。MAE( <strong class="ix hj">平均绝对误差)</strong>给数据分配相等的权重，而MSE <strong class="ix hj">(均方误差)</strong>强调极端值<strong class="ix hj">。</strong></li></ul><figure class="ll lm ln lo fd ij er es paragraph-image"><div class="er es ls"><img src="../Images/19f74a5b43823cc200943d182a1446b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:630/1*J8U9GIMXu44w1P93qKK6Sw.gif"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">平均绝对损失函数</figcaption></figure><ul class=""><li id="27d6" class="ju jv hi ix b iy iz jc jd jg jw jk jx jo jy js lj ka kb kc bi translated">胡贝尔 <strong class="ix hj">损失</strong>——这是一个与梅非常相似的损失。与MSE相比，它对异常值也不太敏感。对大值是二次的，对小值是线性的。</li></ul><figure class="ll lm ln lo fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lt"><img src="../Images/eae512438dfcf58cce9d157b236f7cd3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4JTKDrvNbAGyTZuvjTxgBQ.png"/></div></div></figure><p id="21ff" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">所以，根据你的问题是回归问题还是分类问题，我们可以使用几个损失函数，然后，我们可以选择一个损失函数来优化精度或速度。所以，希望你喜欢看我的博客。如果您有任何疑问，请在下面评论。在那之前，学习、理解、实施和重复。</p><p id="e750" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> <em class="jt">演员表—你管视频(Siraj Raval，损失函数讲解)</em> </strong></p></div></div>    
</body>
</html>