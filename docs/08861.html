<html>
<head>
<title>Master KMeans clustering basics</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">掌握 KMeans 聚类基础知识</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/kmeans-clustering-basics-96fb7c4279ef?source=collection_archive---------18-----------------------#2020-08-16">https://medium.com/analytics-vidhya/kmeans-clustering-basics-96fb7c4279ef?source=collection_archive---------18-----------------------#2020-08-16</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="e596" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">什么是集群？</h2></div><p id="b7c0" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">聚类是机器学习中无监督算法的一部分。与线性回归、逻辑回归等监督算法不同，聚类处理未标记的数据或没有目标变量的数据。</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es jt"><img src="../Images/aea5dd49efac77c8282320e38213b57c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*20T9VdgKrHpFF1j8gGdmBQ.png"/></div></div></figure><blockquote class="kf kg kh"><p id="3623" class="ix iy ki iz b ja jb ij jc jd je im jf kj jh ji jj kk jl jm jn kl jp jq jr js hb bi translated">聚类的任务是对相似的数据点进行分组。</p></blockquote><h2 id="2f06" class="km kn hi bd ko kp kq kr ks kt ku kv kw jg kx ky kz jk la lb lc jo ld le lf lg bi translated">聚类的类型:</h2><p id="85d8" class="pw-post-body-paragraph ix iy hi iz b ja lh ij jc jd li im jf jg lj ji jj jk lk jm jn jo ll jq jr js hb bi translated">聚类属于数据挖掘主题，并且在该领域中有许多研究正在进行，并且存在许多聚类算法。</p><p id="0787" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">以下是聚类算法的主要类型。</p><ol class=""><li id="1fbc" class="lm ln hi iz b ja jb jd je jg lo jk lp jo lq js lr ls lt lu bi translated"><em class="ki">K-表示</em></li><li id="9ddf" class="lm ln hi iz b ja lv jd lw jg lx jk ly jo lz js lr ls lt lu bi translated"><em class="ki">层次聚类</em></li><li id="d902" class="lm ln hi iz b ja lv jd lw jg lx jk ly jo lz js lr ls lt lu bi translated"><em class="ki"> DBSCAN </em></li></ol><h2 id="0ee4" class="km kn hi bd ko kp kq kr ks kt ku kv kw jg kx ky kz jk la lb lc jo ld le lf lg bi translated">聚类的应用:</h2><p id="fa7c" class="pw-post-body-paragraph ix iy hi iz b ja lh ij jc jd li im jf jg lj ji jj jk lk jm jn jo ll jq jr js hb bi translated">以下是集群的一些应用</p><ol class=""><li id="9d78" class="lm ln hi iz b ja jb jd je jg lo jk lp jo lq js lr ls lt lu bi translated">客户细分:这是销售和营销领域中最重要的集群用例之一。这里的目的是根据一些相似性对人员或客户进行分组，以便他们可以为不同组中的人员提出不同的行动项目。一个例子是，亚马逊根据不同人的购买模式提供不同的优惠。</li><li id="647b" class="lm ln hi iz b ja lv jd lw jg lx jk ly jo lz js lr ls lt lu bi translated">图像分割:聚类用于图像分割，将相似的图像像素组合在一起。图像中不同对象的像素被分组在一起。</li></ol><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es ma"><img src="../Images/671b918df9a1cf5b3511a9d02a575526.png" data-original-src="https://miro.medium.com/v2/resize:fit:1224/format:webp/1*40GXv2WP4FJeTWuYe9nygg.png"/></div></figure><p id="f4cd" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">3.预处理步骤:有监督的机器学习算法比无监督的算法更健壮，更容易解释，但是除非你已经标记了数据，否则你不能使用有监督的算法。在这种情况下，聚类被用作预处理步骤，其中聚类被用于将未标记的数据分组，然后将标记分配给它，然后该数据可以用于监督算法。</p><h2 id="6ce5" class="km kn hi bd ko kp kq kr ks kt ku kv kw jg kx ky kz jk la lb lc jo ld le lf lg bi translated">k-表示:</h2><p id="2343" class="pw-post-body-paragraph ix iy hi iz b ja lh ij jc jd li im jf jg lj ji jj jk lk jm jn jo ll jq jr js hb bi translated">K- means 也叫劳氏算法。</p><p id="ff02" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">K-中的步骤表示:</p><ol class=""><li id="b2fe" class="lm ln hi iz b ja jb jd je jg lo jk lp jo lq js lr ls lt lu bi translated">随机初始化 k 形心。</li><li id="3d01" class="lm ln hi iz b ja lv jd lw jg lx jk ly jo lz js lr ls lt lu bi translated">将每个点指定给其最近的质心。</li><li id="dd57" class="lm ln hi iz b ja lv jd lw jg lx jk ly jo lz js lr ls lt lu bi translated">重新计算所有 k 个质心</li><li id="3b6c" class="lm ln hi iz b ja lv jd lw jg lx jk ly jo lz js lr ls lt lu bi translated">重复步骤 2 和 3，直到质心不变。</li></ol><blockquote class="kf kg kh"><p id="6251" class="ix iy ki iz b ja jb ij jc jd je im jf kj jh ji jj kk jl jm jn kl jp jq jr js hb bi translated">质心是群集中心的一个点。</p></blockquote><h2 id="5b22" class="km kn hi bd ko kp kq kr ks kt ku kv kw jg kx ky kz jk la lb lc jo ld le lf lg bi translated">距离函数:</h2><p id="bf09" class="pw-post-body-paragraph ix iy hi iz b ja lh ij jc jd li im jf jg lj ji jj jk lk jm jn jo ll jq jr js hb bi translated">在第二步，每个点被指定为最近的质心，现在明显的问题是模型如何找出最近的质心？</p><p id="366b" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">有许多方法可以计算数据点和质心之间的距离，一些距离函数如下:</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es mb"><img src="../Images/b4af0cd3f30769f110802c7013062172.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5m9v4dQ0vd2u651AWeS32Q.png"/></div></div></figure><ul class=""><li id="ab59" class="lm ln hi iz b ja jb jd je jg lo jk lp jo lq js mc ls lt lu bi translated"><strong class="iz hj">类内距离:</strong>同一类内点之间的距离。</li><li id="1506" class="lm ln hi iz b ja lv jd lw jg lx jk ly jo lz js mc ls lt lu bi translated"><strong class="iz hj">簇间距离:</strong>不同簇内点之间的距离</li></ul><h2 id="052c" class="km kn hi bd ko kp kq kr ks kt ku kv kw jg kx ky kz jk la lb lc jo ld le lf lg bi translated"><strong class="ak">如何挑选最佳 K？</strong></h2><p id="ec00" class="pw-post-body-paragraph ix iy hi iz b ja lh ij jc jd li im jf jg lj ji jj jk lk jm jn jo ll jq jr js hb bi translated">K 是 K 均值算法中的超参数，我们必须在模型开始训练之前提供它。</p><ul class=""><li id="d0a8" class="lm ln hi iz b ja jb jd je jg lo jk lp jo lq js mc ls lt lu bi translated"><strong class="iz hj">惯性</strong>:这是每个数据点与其最近质心之间的均方距离。</li></ul><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es md"><img src="../Images/90e9c6b13a111ba7592235c62f6dbed1.png" data-original-src="https://miro.medium.com/v2/resize:fit:562/format:webp/1*mjchzt1ip5QKutjL5dqyZA.png"/></div></figure><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es me"><img src="../Images/6c79c9aa4ef9114bf455706f61b0551e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*Oy-NCf-tE4D8oWSBODP4qw.png"/></div></figure><p id="47b3" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">使用不同的 K 值运行模型，并检查惯量值，惯量值越小，K 值越大。</p><ul class=""><li id="fc17" class="lm ln hi iz b ja jb jd je jg lo jk lp jo lq js mc ls lt lu bi translated"><strong class="iz hj">轮廓尺寸</strong>:</li></ul><figure class="ju jv jw jx fd jy er es paragraph-image"><div class="er es mf"><img src="../Images/d1be17b9ac559385fdc88271d9f4332c.png" data-original-src="https://miro.medium.com/v2/resize:fit:484/format:webp/1*JWxhcs7M_KKEaNfhWJt05A.png"/></div></figure><p id="7527" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">b:簇间距离。<br/> a:类内距离。</p><ul class=""><li id="692b" class="lm ln hi iz b ja jb jd je jg lo jk lp jo lq js mc ls lt lu bi translated">1≤s≤1:<strong class="iz hj">剪影得分越高，聚类越好。</strong></li></ul><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es mg"><img src="../Images/49d0543658c260afca1e10015f52e991.png" data-original-src="https://miro.medium.com/v2/resize:fit:764/format:webp/1*ZEHJ_SRIXeg1aKdSRuYFCg.png"/></div></div></figure><h2 id="1816" class="km kn hi bd ko kp kq kr ks kt ku kv kw jg kx ky kz jk la lb lc jo ld le lf lg bi translated">如何初始化 K？</h2><p id="dc57" class="pw-post-body-paragraph ix iy hi iz b ja lh ij jc jd li im jf jg lj ji jj jk lk jm jn jo ll jq jr js hb bi translated">我们已经看到了如何使用惯性或轮廓分数来选择 K 的最佳值。一旦我们选定了 K 的最佳值，接下来的问题就是如何初始化它？</p><ol class=""><li id="ae9f" class="lm ln hi iz b ja jb jd je jg lo jk lp jo lq js lr ls lt lu bi translated"><strong class="iz hj">随机初始化:</strong>在这种情况下，每个数据点有相等的概率被选为质心。</li><li id="8cb0" class="lm ln hi iz b ja lv jd lw jg lx jk ly jo lz js lr ls lt lu bi translated"><strong class="iz hj"> K-means++ </strong>:在这种情况下，从给定的数据点中随机选择第一个质心，并根据其与其他质心的距离选择下一个质心。数据点离质心的距离越高，被选为下一个质心的概率就越高。</li></ol><h2 id="3c0d" class="km kn hi bd ko kp kq kr ks kt ku kv kw jg kx ky kz jk la lb lc jo ld le lf lg bi translated">K 均值的局限性:</h2><ol class=""><li id="3c90" class="lm ln hi iz b ja lh jd li jg mh jk mi jo mj js lr ls lt lu bi translated">如果原始数据中的自然聚类大小不同，效果就不太好。</li></ol><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es mk"><img src="../Images/5bec18346a696348a370f8027b5406c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xJPNDSt34PKm-8L0uy_uDw.png"/></div></div></figure><p id="cdca" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">2.如果原始数据中的自然聚类具有不同的密度，那么它就不会工作得很好。</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es ml"><img src="../Images/bee25555de6a20c885c07c1deb19e8ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DN6XHTdXdGmP3r6Tu0VGng.png"/></div></div></figure><p id="8cd1" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">3.如果原始数据中的自然聚类是非球形的，则效果不太好。</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es mm"><img src="../Images/3241aa8ead075bb6a5778d3811a88d68.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A7NwXOy20Z3i4K5t_GZW5Q.png"/></div></div></figure><h1 id="754a" class="mn kn hi bd ko mo mp mq ks mr ms mt kw io mu ip kz ir mv is lc iu mw iv lf mx bi translated">分层聚类:</h1><p id="26b0" class="pw-post-body-paragraph ix iy hi iz b ja lh ij jc jd li im jf jg lj ji jj jk lk jm jn jo ll jq jr js hb bi translated">K-means 算法的一个主要问题是，我们必须在训练开始之前向模型提供 K 的值。为了克服这个问题，使用了分层聚类。</p></div><div class="ab cl my mz gp na" role="separator"><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd"/></div><div class="hb hc hd he hf"><h2 id="b048" class="km kn hi bd ko kp kq kr ks kt ku kv kw jg kx ky kz jk la lb lc jo ld le lf lg bi translated">K 模式和 K 原型:</h2><p id="3a6a" class="pw-post-body-paragraph ix iy hi iz b ja lh ij jc jd li im jf jg lj ji jj jk lk jm jn jo ll jq jr js hb bi translated">K-means 算法仅适用于数值数据。如果你只有分类数据，那么使用<strong class="iz hj"> K 模式</strong>算法。如果你有分类数据和数字数据，那么使用<strong class="iz hj"> k-prototype </strong>算法。</p><p id="188e" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">感谢您的宝贵时间。如果你觉得这很有用，请点赞并评论。</p><p id="3358" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="ki">快乐阅读！</em></p></div></div>    
</body>
</html>