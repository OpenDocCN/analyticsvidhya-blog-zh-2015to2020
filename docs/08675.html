<html>
<head>
<title>Image classification with PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">PyTorch图像分类</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/image-classification-with-pytorch-184e76c2cf3b?source=collection_archive---------11-----------------------#2020-08-08">https://medium.com/analytics-vidhya/image-classification-with-pytorch-184e76c2cf3b?source=collection_archive---------11-----------------------#2020-08-08</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="fe63" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jd"> CIFAR 10数据集使用逻辑回归</em> </strong></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es je"><img src="../Images/7970287dacc1ac4709a0d231fac4ff71.png" data-original-src="https://miro.medium.com/v2/resize:fit:1060/format:webp/1*AViqXPM44_eMKs1hZnptJg.png"/></div><figcaption class="jm jn et er es jo jp bd b be z dx translated">CIFAR-10数据集(来源:【https://www.cs.toronto.edu/~kriz/cifar.html】T4)</figcaption></figure><p id="89b8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在我之前的帖子中，我们已经讨论过了</p><ol class=""><li id="9cda" class="jr js hi ih b ii ij im in iq jt iu ju iy jv jc jw jx jy jz bi translated"><a class="ae jq" rel="noopener" href="/analytics-vidhya/deep-learning-artificial-neural-network-ann-13b54c3f370f?source=your_stories_page---------------------------">深度学习——人工神经网络</a></li><li id="5cdc" class="jr js hi ih b ii ka im kb iq kc iu kd iy ke jc jw jx jy jz bi translated"><a class="ae jq" rel="noopener" href="/@arun.purakkatt/tensors-basics-of-pytorch-programming-5de82ea45ebf?source=your_stories_page---------------------------">张量pytorch编程基础</a></li><li id="ddc6" class="jr js hi ih b ii ka im kb iq kc iu kd iy ke jc jw jx jy jz bi translated"><a class="ae jq" rel="noopener" href="/analytics-vidhya/linear-regression-with-pytorch-147fed55f138">使用PyTorch进行线性回归</a></li></ol><p id="ee45" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">让我们尝试用逻辑回归来解决</em><a class="ae jq" href="https://www.cs.toronto.edu/~kriz/cifar.html" rel="noopener ugc nofollow" target="_blank"><em class="jd">CIFAR-10</em></a><em class="jd">数据集的图像分类。</em></p></div><div class="ab cl kf kg gp kh" role="separator"><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk"/></div><div class="hb hc hd he hf"><p id="aab5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jd">第一步:导入必要的库&amp;浏览数据集</em> </strong></p><p id="af22" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们正在进口必要的图书馆熊猫，numpy，matplotlib，火炬，火炬视觉。使用基本EDA，我们可以推断CIFAR-10数据集包含10类图像，训练数据集大小为50000个图像，测试数据集大小为10000个图像。每个图像的大小为[3 x 32 x 32 ]。其表示3通道RGB，32×32像素大小。</p><pre class="jf jg jh ji fd km kn ko kp aw kq bi"><span id="f698" class="kr ks hi kn b fi kt ku l kv kw"><em class="jd">#Explore CIFAR Data set</em><br/>dataset = CIFAR10(root='data/', download=True, transform=ToTensor())<br/>test_dataset = CIFAR10(root='data/', train=False, transform=ToTensor())</span><span id="519c" class="kr ks hi kn b fi kx ku l kv kw"><em class="jd">#size of training data</em><br/>dataset_size = len(dataset)<br/>dataset_size</span><span id="a3f2" class="kr ks hi kn b fi kx ku l kv kw"><em class="jd">#size of test data</em><br/>test_dataset_size = len(test_dataset)<br/>test_dataset_size</span><span id="68a8" class="kr ks hi kn b fi kx ku l kv kw"><em class="jd">#number of classes in the data set</em><br/>classes = dataset.classes<br/>classes</span></pre><p id="f9f3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">可视化样本图像和样本图像的尺寸。</p><pre class="jf jg jh ji fd km kn ko kp aw kq bi"><span id="b0db" class="kr ks hi kn b fi kt ku l kv kw"><em class="jd">#Let us understand the size of one image</em><br/>img, label = dataset[0]<br/>img_shape = img.shape<br/>img_shape</span><span id="33e2" class="kr ks hi kn b fi kx ku l kv kw"><em class="jd">#Let us look at a sample image</em><br/>img, label = dataset[0]<br/>plt.imshow(img.permute((1, 2, 0)))<br/>print('Label (numeric):', label)<br/>print('Label (textual):', classes[label])</span></pre><p id="81f1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因为这是一个3通道RGB图像，Pytorch期望通道作为第一维，而matplotlib期望作为图像的最后一维。给你。使用置换tesnor方法将通道移动到最后一个维度</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es ky"><img src="../Images/6dee8334d26c1b61f6aeffe4843eda93.png" data-original-src="https://miro.medium.com/v2/resize:fit:502/format:webp/0*bBP5w1D79q8uiEU7.png"/></div><figcaption class="jm jn et er es jo jp bd b be z dx translated">标签(数字):6 <br/>标签(文本):青蛙</figcaption></figure><p id="a13a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jd">第二步:为训练准备数据</em> </strong></p><p id="47c2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们使用训练集，验证集，测试集。我们为什么需要它们？</p><p id="0e6c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">训练集:用于训练我们的模型，计算损失和调整权重验证集:评估具有超参数的模型，并在训练期间选择最佳模型。我们使用10%的训练数据作为验证集测试数据集:用于比较不同的模型并报告最终的准确性。</p><p id="bef0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们使用pytorch中的random_split来创建train_ds和val_ds。设置torch.manual_seed(43)用于再现结果。</p><pre class="jf jg jh ji fd km kn ko kp aw kq bi"><span id="09fd" class="kr ks hi kn b fi kt ku l kv kw">#validation set size 5000 ie 10% <br/>torch.manual_seed(43)<br/>val_size = 5000<br/>train_size = len(dataset) - val_size</span><span id="16b2" class="kr ks hi kn b fi kx ku l kv kw">#creating training &amp; validation set using random_split<br/>train_ds, val_ds = random_split(dataset, [train_size, val_size])<br/>len(train_ds), len(val_ds)</span></pre><p id="e006" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们使用的数据加载器与上一个示例中使用的一样，批量大小为128。为了可视化我们的数据，我们使用torch vision的make_grid辅助函数。</p><pre class="jf jg jh ji fd km kn ko kp aw kq bi"><span id="bb52" class="kr ks hi kn b fi kt ku l kv kw">#Creating data loader to load data in batches<br/>batch_size=128</span><span id="2d94" class="kr ks hi kn b fi kx ku l kv kw">train_loader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)<br/>val_loader = DataLoader(val_ds, batch_size*2, num_workers=4, pin_memory=True)<br/>test_loader = DataLoader(test_dataset, batch_size*2, num_workers=4, pin_memory=True)</span><span id="0a88" class="kr ks hi kn b fi kx ku l kv kw">#visualize data using make_grid helper function from torch vision<br/>for images, _ in train_loader:<br/>    print('images.shape:', images.shape)<br/>    plt.figure(figsize=(16,8))<br/>    plt.axis('off')<br/>    plt.imshow(make_grid(images, nrow=16).permute((1, 2, 0)))<br/>    break</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es kz"><img src="../Images/64549b7c81efe91dd940a7a63b08c7c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y-b5O99ofcDiX982erosOg.png"/></div></div><figcaption class="jm jn et er es jo jp bd b be z dx translated">图像。形状:火炬。尺寸([128，3，32，32])</figcaption></figure><p id="953b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jd">第三步:创建基础模型类&amp;在GPU上训练</em> </strong></p><p id="10a3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们正在创建一个从nn.module继承的ImageClassificationBase类，它不包含模型体系结构，即__init__ &amp; __forward__方法。</p><pre class="jf jg jh ji fd km kn ko kp aw kq bi"><span id="7be8" class="kr ks hi kn b fi kt ku l kv kw">class ImageClassificationBase(nn.Module):<br/>    def training_step(self, batch):<br/>        images, labels = batch <br/>        out = self(images)                  # Generate predictions<br/>        loss = F.cross_entropy(out, labels) # Calculate loss<br/>        return loss<br/>    <br/>    def validation_step(self, batch):<br/>        images, labels = batch <br/>        out = self(images)                    # Generate predictions<br/>        loss = F.cross_entropy(out, labels)   # Calculate loss<br/>        acc = accuracy(out, labels)           # Calculate accuracy<br/>        return {'val_loss': loss, 'val_acc': acc}<br/>        <br/>    def validation_epoch_end(self, outputs):<br/>        batch_losses = [x['val_loss'] for x in outputs]<br/>        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses<br/>        batch_accs = [x['val_acc'] for x in outputs]<br/>        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies<br/>        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}<br/>    <br/>    def epoch_end(self, epoch, result):<br/>        print("Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}".format(epoch, result['val_loss'], result['val_acc']))</span></pre><p id="5a33" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">我们都听说过，要训练深度学习模型，CPU是不够的，但我们需要GPU。如何在GPU上训练我们的模型？</em></p><p id="0d3d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们正在检查设备可用性，它会根据您的系统设置显示GPU/CPU。我们正在创建辅助函数to_device来将张量移动到所选的设备。将数据移动到设备的devicedataloader()类。我们将需要帮助函数来绘制损失和准确性。</p><pre class="jf jg jh ji fd km kn ko kp aw kq bi"><span id="1eee" class="kr ks hi kn b fi kt ku l kv kw">device = get_default_device()<br/>device</span><span id="f339" class="kr ks hi kn b fi kx ku l kv kw">def to_device(data, device):<br/>    """Move tensor(s) to chosen device"""<br/>    if isinstance(data, (list,tuple)):<br/>        return [to_device(x, device) for x in data]<br/>    return data.to(device, non_blocking=True)</span><span id="c8d2" class="kr ks hi kn b fi kx ku l kv kw">class DeviceDataLoader():<br/>    """Wrap a dataloader to move data to a device"""<br/>    def __init__(self, dl, device):<br/>        self.dl = dl<br/>        self.device = device<br/>        <br/>    def __iter__(self):<br/>        """Yield a batch of data after moving it to device"""<br/>        for b in self.dl: <br/>            yield to_device(b, self.device)</span><span id="fbae" class="kr ks hi kn b fi kx ku l kv kw">def __len__(self):<br/>        """Number of batches"""<br/>        return len(self.dl)</span></pre><p id="7adb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">将数据加载器移动到适当的设备。</p><pre class="jf jg jh ji fd km kn ko kp aw kq bi"><span id="ae89" class="kr ks hi kn b fi kt ku l kv kw">train_loader = DeviceDataLoader(train_loader, device)<br/>val_loader = DeviceDataLoader(val_loader, device)<br/>test_loader = DeviceDataLoader(test_loader, device)</span></pre><p id="7c29" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jd">第三步:训练模式</em> </strong></p><p id="b647" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">与线性回归相似，不同之处在于我们也有验证阶段。输入尺寸为3x32x32，输出尺寸为10。我们使用了两个隐藏层。神经网络架构将看起来像2048 x 1650 x 512 x 138 x 10。图像被展平成矢量，应用图层和激活函数，最后使用输出图层得到预测。Relu在这里用作激活函数。</p><pre class="jf jg jh ji fd km kn ko kp aw kq bi"><span id="e185" class="kr ks hi kn b fi kt ku l kv kw"><strong class="kn hj">class</strong> <strong class="kn hj">CIFAR10Model</strong>(ImageClassificationBase):<br/>    <strong class="kn hj">def</strong> __init__(self):<br/>        super().__init__()<br/>        self.linear1 = nn.Linear(input_size, 1650)<br/>        <em class="jd"># hidden layers</em><br/>        self.linear2 = nn.Linear(1650, 512)<br/>        self.linear3 = nn.Linear(512, 138)<br/>        <em class="jd"># output layer</em><br/>        self.linear4 = nn.Linear(138, output_size)<br/>        <br/>    <strong class="kn hj">def</strong> forward(self, xb):<br/>        <em class="jd"># Flatten images into vectors</em><br/>        out = xb.view(xb.size(0), -1)<br/>        <em class="jd"># Apply layers &amp; activation functions</em><br/>        out = self.linear1(out)<br/>        <em class="jd"># Apply activation function</em><br/>        out = F.relu(out)<br/>        <em class="jd"># Get intermediate outputs using hidden layer 2</em><br/>        out = self.linear2(out)<br/>        <em class="jd"># Apply activation function</em><br/>        out = F.relu(out)<br/>        <em class="jd"># Get predictions using output layer</em><br/>        out = self.linear3(out)<br/>        <em class="jd"># Apply activation function</em><br/>        out = F.relu(out)<br/>        <em class="jd"># Get predictions using output layer</em><br/>        out = self.linear4(out)<br/>        <em class="jd"># Apply activation function</em><br/>        out = F.relu(out)<br/>        <strong class="kn hj">return</strong> out</span></pre><p id="b3c7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">利用拟合函数训练模型，减少损失，提高精度。在这里，我们正在尝试不同的学习速度和时期。在学习率为0.001和周期数为25的情况下，我们获得了最佳精度。</p><pre class="jf jg jh ji fd km kn ko kp aw kq bi"><span id="8a2b" class="kr ks hi kn b fi kt ku l kv kw">history += fit(10, 0.05, model, train_loader, val_loader)<br/>history += fit(8, 0.005, model, train_loader, val_loader)<br/>history += fit(7, 0.01, model, train_loader, val_loader)<br/>history += fit(4, 0.001, model, train_loader, val_loader)<br/>history += fit(10, 0.0001, model, train_loader, val_loader)</span><span id="b454" class="kr ks hi kn b fi kx ku l kv kw">#since 0.001 gives best accuracy, will go with that<br/>history += fit(25, 0.001, model, train_loader, val_loader)</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es le"><img src="../Images/5359f28792c17f9acbd71b95472fbccd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1394/format:webp/1*mJYfm2oQe4CAKelay4Ueiw.png"/></div><figcaption class="jm jn et er es jo jp bd b be z dx translated">精度和损失与时代的数量</figcaption></figure><p id="c90d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jd">第四步:记录结果&amp;保存模型</em> </strong></p><p id="b494" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以用下面的代码保存这个模型，它可以用来预测。</p><pre class="jf jg jh ji fd km kn ko kp aw kq bi"><span id="5c68" class="kr ks hi kn b fi kt ku l kv kw">evaluate(model, test_loader)<br/>arch =  '4 layers (1650,512,138,10)'<br/>lrs = [0.5,0.01,0.05,0.001,0.1]<br/>epochs = [5,7,8,10,4, 25]</span><span id="5856" class="kr ks hi kn b fi kx ku l kv kw">test_acc =  0.54<br/>test_loss = 1.30</span><span id="7caf" class="kr ks hi kn b fi kx ku l kv kw">torch.save(model.state_dict(), 'cifar10-feedforward.pth')</span></pre></div><div class="ab cl kf kg gp kh" role="separator"><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk kl"/><span class="ki bw bk kj kk"/></div><div class="hb hc hd he hf"><p id="7fa2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">请在笔记本<a class="ae jq" href="https://github.com/Arun-purakkatt/Deep_Learning_Pytorch" rel="noopener ugc nofollow" target="_blank"> <em class="jd"> Github </em> </a>上查看完整代码，在<em class="jd"> </em> <a class="ae jq" href="https://www.linkedin.com/in/arun-purakkatt-mba-m-tech-31429367/" rel="noopener ugc nofollow" target="_blank"> <em class="jd">上保持连接，在</em> </a>中保持链接。</p><p id="2968" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jd">演职员表&amp;参考文献:</em> </strong></p><ol class=""><li id="36ad" class="jr js hi ih b ii ij im in iq jt iu ju iy jv jc jw jx jy jz bi translated"><a class="ae jq" href="https://jovian.ml/aakashns/03-logistic-regression" rel="noopener ugc nofollow" target="_blank">https://jovian.ml/aakashns/03-logistic-regression</a></li><li id="ef20" class="jr js hi ih b ii ka im kb iq kc iu kd iy ke jc jw jx jy jz bi translated"><a class="ae jq" href="https://www.deeplearningwizard.com/deep_learning/practical_pytorch/pytorch_linear_regression/" rel="noopener ugc nofollow" target="_blank">https://www . deep learning wizard . com/deep _ learning/practical _ py torch/py torch _ linear _ regression/</a></li><li id="ae84" class="jr js hi ih b ii ka im kb iq kc iu kd iy ke jc jw jx jy jz bi translated"><a class="ae jq" href="https://pytorch.org/docs/stable/tensors.html" rel="noopener ugc nofollow" target="_blank">https://pytorch.org/docs/stable/tensors.html</a></li></ol></div></div>    
</body>
</html>