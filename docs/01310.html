<html>
<head>
<title>Completing Historical Temperature records with LSTM in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在Python中使用LSTM完成历史温度记录</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/completing-historical-temperature-records-with-lstm-in-python-f505b10289e7?source=collection_archive---------6-----------------------#2019-10-14">https://medium.com/analytics-vidhya/completing-historical-temperature-records-with-lstm-in-python-f505b10289e7?source=collection_archive---------6-----------------------#2019-10-14</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="1d60" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">基于公共数据集，我们完成了智利Azapa气象站的历史媒体每日温度记录。</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/9b072dc92c307ee54d5458af0541e80d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*AC9dUPLB9KwtxBtM"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">照片由<a class="ae jn" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的<a class="ae jn" href="https://unsplash.com/@sharadmbhat?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Sharad Bhat </a>拍摄</figcaption></figure><h2 id="8382" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">背景</h2><p id="b22e" class="pw-post-body-paragraph km kn hi ko b kp kq ij kr ks kt im ku jz kv kw kx kd ky kz la kh lb lc ld le hb bi translated">本文的目标是探索LSTM网络来预测智利阿扎帕气象站1977-1980年间缺失的温度记录值。</p><p id="cf5b" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">该数据集是从拉丁美洲气候评估和数据集(LACA)发布的数据中获得的，通过查阅以下网站获得6个最近气象站的单个TXT文件:【http://lacad.ciifen.org/ES/<a class="ae jn" href="http://lacad.ciifen.org/ES/." rel="noopener ugc nofollow" target="_blank"/></p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es lk"><img src="../Images/89b34a8d34559ebdbfca67870b8fb341.png" data-original-src="https://miro.medium.com/v2/resize:fit:1126/format:webp/1*2GZbJFXtrAUcJO6uKKFh-Q.png"/></div></figure><p id="c5ef" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">阿扎帕气象站(596)被选为目标。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ll"><img src="../Images/e89b8e8136fbc027478fefbf5240d06d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1128/format:webp/1*R6oNUntIweNU6cybUKbdZg.png"/></div></figure><h2 id="7d30" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">正在准备数据集</h2><p id="623c" class="pw-post-body-paragraph km kn hi ko b kp kq ij kr ks kt im ku jz kv kw kx kd ky kz la kh lb lc ld le hb bi translated">我们从六个单独的TXT文件开始，保存为CSV格式。每个CSV工作站如下所示:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es lm"><img src="../Images/538e2fd5b60b3d0d99fd32635b030b70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1080/format:webp/1*FEkojMC0kWPVSTMi2OMPIg.png"/></div></figure><p id="ebdb" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">每个记录包含源标识、日期、TG(十分之一摄氏度的温度，是我们的目标数据)和质量数据来源(其中Q_TG=0是原始数据，Q_TG=9是空值)。</p><p id="6e12" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">我们生成一个唯一的数据帧，合并六个数据文件，仅保留每个文件的TG列(温度等级),并以日期作为索引:</p><pre class="iy iz ja jb fd ln lo lp lq aw lr bi"><span id="3095" class="jo jp hi lo b fi ls lt l lu lv"># Importing and joining CSV in single dataframe <br/>import pandas as pd</span><span id="a7e5" class="jo jp hi lo b fi lw lt l lu lv">#importing first file as data_553 <br/>data_553 = pd.read_csv("./LACA_blended_custom/TG_STAID000553.csv",names=['SOUID','DATE','TG553','Q_TG'],<br/>                        header=0,parse_dates=['DATE'],index_col=['DATE'],usecols=['DATE','TG553'])</span><span id="3c2c" class="jo jp hi lo b fi lw lt l lu lv">#process for adding following files<br/>def anexo(merge,newset):<br/>    col_name = 'TG'+newset<br/>    data_new = pd.read_csv(<br/>               "./LACA_blended_custom/TG_STAID000"+newset+".csv",<br/>               names=['SOUID','DATE',col_name,'Q_TG'],<br/>               header=0,parse_dates=['DATE'],<br/>               index_col=['DATE'],usecols=['DATE',col_name])<br/>    <br/>    merge_n=pd.merge(merge,data_new, how='inner', left_index=True, right_index=True)<br/>    return merge_n</span><span id="329b" class="jo jp hi lo b fi lw lt l lu lv">#adding the other files<br/>merge = anexo(data_553,'585')<br/>merge = anexo(merge,'588')<br/>merge = anexo(merge,'595')<br/>merge = anexo(merge,'596')<br/>merge = anexo(merge,'597')</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es lx"><img src="../Images/67b066c44ac77f4166aef8b1df13518f.png" data-original-src="https://miro.medium.com/v2/resize:fit:798/format:webp/1*N0EmLYO3-NHYyAvdoydfJg.png"/></div></figure><h2 id="53dd" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">数据预览和特征工程</h2><p id="5d51" class="pw-post-body-paragraph km kn hi ko b kp kq ij kr ks kt im ku jz kv kw kx kd ky kz la kh lb lc ld le hb bi translated">首先，我们必须将TG=-9999的寄存器指定为null，并将它们可视化</p><pre class="iy iz ja jb fd ln lo lp lq aw lr bi"><span id="c1a0" class="jo jp hi lo b fi ls lt l lu lv">import matplotlib.pyplot as plt<br/>import seaborn as sns<br/></span><span id="ab43" class="jo jp hi lo b fi lw lt l lu lv">#Replace with None cols with -9999<br/>cols = ['TG553','TG588','TG585','TG595','TG596','TG597']<br/>for col in cols:<br/>    merge[col] = merge[col].apply(lambda x: None if x == -9999 else x)</span><span id="d9e0" class="jo jp hi lo b fi lw lt l lu lv">#missing value counts in each of these columns<br/>Isnull = merge.isnull().sum()/len(merge)*100<br/>Isnull = Isnull[Isnull&gt;0]<br/>Isnull.sort_values(inplace=True, ascending=False)<br/>Isnull = Isnull.to_frame()<br/>Isnull.columns = ['Nulls']<br/>Isnull.index.names = ['Stations']<br/>Isnull['Stations'] = Isnull.index</span><span id="cef5" class="jo jp hi lo b fi lw lt l lu lv">#plot Missing values<br/>plt.figure(figsize=(13, 5))<br/>sns.set(style='darkgrid',color_codes=True,)<br/>sns.barplot(x='Stations', y='Nulls', data=Isnull)<br/>plt.xticks(rotation = 90)<br/>plt.show()</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ly"><img src="../Images/ed986b7844b0496c6ef992bc9a9cb304.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GQOpXGzA4TBt2J4ClL1H5Q.png"/></div></div></figure><p id="c860" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">可视化热图中的空数据</p><pre class="iy iz ja jb fd ln lo lp lq aw lr bi"><span id="25db" class="jo jp hi lo b fi ls lt l lu lv">plt.figure(figsize=(12, 6))<br/>sns.heatmap(merge.isnull())<br/>plt.show()</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lz"><img src="../Images/0e64864b7ebb8ee5f66c77e96f0be1b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LDZ6SR8_zyyKJUyeUKaOfA.png"/></div></div></figure><p id="6fb0" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">我们可以观察到，在1976年10月至1984年12月期间，信息(黑色背景)非常紧凑</p><p id="6880" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">删除整个数据集中的空记录我们得到了1477条记录的最终集合，在1976年12月28日和1984年11月21日之间</p><pre class="iy iz ja jb fd ln lo lp lq aw lr bi"><span id="f0c3" class="jo jp hi lo b fi ls lt l lu lv">anual = merge.groupby(merge.index.year)<br/>serie = anual.size()</span><span id="ca2e" class="jo jp hi lo b fi lw lt l lu lv">plt.figure(figsize=(13, 5))<br/>sns.set(style='whitegrid')<br/>sns.barplot(x=serie.index, y=serie)<br/>plt.xticks(rotation = 90)<br/>plt.show()</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ma"><img src="../Images/5cb0a9e0eea8be4f7ddeed0c29a09cb4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L5lr7H6Ma1gTgcWA-ZQoWg.png"/></div></div></figure></div><div class="ab cl mb mc gp md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="hb hc hd he hf"><h2 id="51da" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">使用LSTM网络预测缺失数据记录</h2><p id="5a29" class="pw-post-body-paragraph km kn hi ko b kp kq ij kr ks kt im ku jz kv kw kx kd ky kz la kh lb lc ld le hb bi translated">首先，让我们使用MinMaxScaler缩放数据。我喜欢在专题工作结束时使用我的Jupiter笔记本中的数据集副本，然后我可以在不影响最终数据集的情况下采用不同的方法来实现目标。</p><p id="6771" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">在这种情况下，变量有相似的值，那么缩放可能是不必要的，但我喜欢使用低的和相似的值，这总是可能的。</p><pre class="iy iz ja jb fd ln lo lp lq aw lr bi"><span id="7a4c" class="jo jp hi lo b fi ls lt l lu lv">from sklearn.preprocessing import MinMaxScaler<br/>dataset = merge.copy()</span><span id="a206" class="jo jp hi lo b fi lw lt l lu lv">dataset.reset_index(inplace=True, drop=True)</span><span id="728d" class="jo jp hi lo b fi lw lt l lu lv">scaler = MinMaxScaler()<br/>reshape  = ['TG553','TG588','TG585','TG595','TG596','TG597']<br/>dataset[reshape] = scaler.fit_transform(dataset[reshape])</span></pre><p id="ecde" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">我们必须在训练和测试中分割数据集以保持连续的形状</p><pre class="iy iz ja jb fd ln lo lp lq aw lr bi"><span id="82c3" class="jo jp hi lo b fi ls lt l lu lv">rate = 0.75  <br/>tst_train_len = int(len(dataset)*rate)<br/>tst_test_len = len(dataset) - tst_train<br/>train, test = dataset.loc[0:tst_train_len,:],<br/>              dataset.loc[tst_train_len:len(dataset),:]</span></pre><p id="dfc2" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">当使用LSTM时，我们必须编程一个回看窗口功能。在这个函数中，我们接收dataframe或serie对象，并返回X和Y numpy对象。</p><p id="d5b2" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">如果我们定义回顾大小为3，我们需要前3个记录作为X来获得第一个目标y。在一个简单的例子中，如果我们有这个X=[a，b，c，d，e，f]并且回顾=3，我们将获得:</p><p id="5434" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">a、b、c -&gt; d</p><p id="7ae3" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">b、c、d -&gt; e</p><p id="f0de" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">c、d、e -&gt; f</p><p id="dd2b" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">然后我们丢失了一些数据，我们有6个数据记录，只有3个标签。</p><pre class="iy iz ja jb fd ln lo lp lq aw lr bi"><span id="0d28" class="jo jp hi lo b fi ls lt l lu lv">def create_dataset(dataset, look_back=1):<br/>    dataX, dataY = [], []<br/>    for i in range(len(dataset)-look_back-1):<br/>        a = np.array(dataset.loc[i:(i+look_back), :])        <br/>        dataX.append(a)<br/>        dataY.append(np.array(dataset.loc[i + look_back, :]))<br/>    return np.array(dataX), np.array(dataY)</span></pre><p id="a2cf" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">然后，我们将该函数应用于训练和测试数据，在第一次试验中，我们使用look_back=3</p><pre class="iy iz ja jb fd ln lo lp lq aw lr bi"><span id="0748" class="jo jp hi lo b fi ls lt l lu lv">from keras.models import Sequential<br/>from keras.layers import Dense, LSTM<br/>from keras.callbacks import ModelCheckpoint</span><span id="2d47" class="jo jp hi lo b fi lw lt l lu lv">look_back = 3</span><span id="f103" class="jo jp hi lo b fi lw lt l lu lv">trainX, trainY = create_dataset(train,look_back)<br/>testX, testY = create_dataset(test,look_back)</span></pre><p id="4913" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">我们准备开始我们的LSTM神经网络。在第一次试验中，我们配置四个感知器，批量=1，训练10个时期。看起来不错，然后我们尝试50个纪元。</p><pre class="iy iz ja jb fd ln lo lp lq aw lr bi"><span id="2298" class="jo jp hi lo b fi ls lt l lu lv">from keras.models import Sequential<br/>from keras.layers import Dense, LSTM</span><span id="c3aa" class="jo jp hi lo b fi lw lt l lu lv">cnt_perc = 4<br/>cnt_epoch = 50<br/>bz = 1</span><span id="e697" class="jo jp hi lo b fi lw lt l lu lv">model = Sequential()<br/>model.add(LSTM(cnt_perc, input_shape=(look_back+1,6)))<br/>model.add(Dense(6))<br/>model.summary()<br/>model.compile(loss='mean_squared_error', optimizer='adam')</span><span id="bd6d" class="jo jp hi lo b fi lw lt l lu lv">model.fit(trainX, trainY, epochs=cnt_epoch, batch_size=bz)</span><span id="1d50" class="jo jp hi lo b fi lw lt l lu lv">trainPredict = scaler.inverse_transform(model.predict(trainX))</span><span id="2c59" class="jo jp hi lo b fi lw lt l lu lv">testPredict = scaler.inverse_transform(model.predict(testX))</span></pre><p id="3e83" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">为了评估分数，我们必须关注回看窗口，在这个python示例中，我们评估第4列中的准确性:Azapa站(TG596)</p><pre class="iy iz ja jb fd ln lo lp lq aw lr bi"><span id="ce04" class="jo jp hi lo b fi ls lt l lu lv">from sklearn.metrics import mean_squared_error<br/>import math</span><span id="0c45" class="jo jp hi lo b fi lw lt l lu lv">trainScore = math.sqrt(mean_squared_error(original[look_back:(len(trainX)+look_back),4], trainPredict[:,4]))<br/>print('Train: %.2f RMSE' % (trainScore))</span><span id="3bd6" class="jo jp hi lo b fi lw lt l lu lv">testScore = math.sqrt(mean_squared_error(original[len(trainX)+(look_back*2)+1:,4], testPredict[:,4]))<br/>print('Test: %.2f RMSE' % (testScore))</span></pre><p id="9b88" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">获得准确度(日平均值的0.471度是初始尝试的合理准确度):</p><p id="f9f9" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">火车:6.56 RMSE，测试:4.71 RMSE</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mi"><img src="../Images/611459358fb03f1512b0f6bcfc75b3a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1108/format:webp/1*5DY_LBbaLmK6DF6HjxKZoA.png"/></div></figure><h2 id="6f51" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">让LSTM接近精确</h2><p id="f1e3" class="pw-post-body-paragraph km kn hi ko b kp kq ij kr ks kt im ku jz kv kw kx kd ky kz la kh lb lc ld le hb bi translated">我们可以试着改变一些参数。回顾窗口、批量大小、更多训练时期和网络结构。</p><p id="a151" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">在做了一些测试后，有六个感知器模型运行得更好:</p><pre class="iy iz ja jb fd ln lo lp lq aw lr bi"><span id="b39f" class="jo jp hi lo b fi ls lt l lu lv"># Grafico<br/>plt.figure(figsize=(13, 5))<br/>plt.plot(original[4:1107,4])<br/>plt.plot(trainPredict[:,4])<br/>#plt.plot(testPredict[:,4])<br/>plt.show()</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mj"><img src="../Images/e07491163f4cee1cf602ceb992d3439a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8rz5Q9Pm0snZa6VUvnALTA.png"/></div></div></figure><p id="b6d6" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">最终分数:训练:0.80 RMSE，测试:0.55 RMSE</p><h1 id="1fb2" class="mk jp hi bd jq ml mm mn ju mo mp mq jy io mr ip kc ir ms is kg iu mt iv kk mu bi translated">摘要</h1><p id="d5df" class="pw-post-body-paragraph km kn hi ko b kp kq ij kr ks kt im ku jz kv kw kx kd ky kz la kh lb lc ld le hb bi translated">在这种情况下，LSTM是获得精确预测值的绝佳工具。我们必须小心数据集索引和用于生成和评估X，Y训练和测试的例程。</p><p id="1dae" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">我希望这篇文章对你有用，这是我在这里的第一份工作，如果有什么可以做得更好的，我将非常感谢您的评论和报告。</p><p id="24fa" class="pw-post-body-paragraph km kn hi ko b kp lf ij kr ks lg im ku jz lh kw kx kd li kz la kh lj lc ld le hb bi translated">您可以在我的Github中访问完整的Jupyter笔记本和数据集:<a class="ae jn" href="https://github.com/gnaya73/medium" rel="noopener ugc nofollow" target="_blank">https://github.com/gnaya73/medium</a></p></div></div>    
</body>
</html>