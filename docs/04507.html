<html>
<head>
<title>Identifying Brain Tumor from MRI images using FastAI and metrics tracking using Neptune AI</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用FastAI从MRI图像中识别脑肿瘤和用Neptune AI进行度量跟踪</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/identifying-brain-tumor-from-mri-images-using-fastai-and-metrics-tracking-using-neptune-ai-71fbc56febba?source=collection_archive---------12-----------------------#2020-03-22">https://medium.com/analytics-vidhya/identifying-brain-tumor-from-mri-images-using-fastai-and-metrics-tracking-using-neptune-ai-71fbc56febba?source=collection_archive---------12-----------------------#2020-03-22</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><figure class="hh hi ez fb hj hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es hg"><img src="../Images/96493371f7d0b78972ad11370dd7456f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FPLKD-_U46CgEOd8otEpnQ.jpeg"/></div></div></figure><div class=""/><h1 id="0c79" class="iq ir ht bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">目标</h1><p id="a6f4" class="pw-post-body-paragraph jo jp ht jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">本文的目的是探索使用FastAI的动态UNet架构从MRI图像中识别脑肿瘤，并在Neptune AI logger中记录各种损失参数，以对模型基超参数调整之间的性能进行比较分析。本文将详细探讨所使用的动态UNet架构和经典UNet架构的架构，还将探讨如何使用Neptune AI轻松、有序地跟踪各种损失矩阵，并在超参数调整后轻松比较各种模型性能。</p><h1 id="dcc7" class="iq ir ht bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">模型描述</h1><figure class="kn ko kp kq fd hk er es paragraph-image"><div class="er es km"><img src="../Images/cba5d12745054582478ce7b7575710db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1224/0*szouyTngxwK7IX5l"/></div></figure><p id="1b0f" class="pw-post-body-paragraph jo jp ht jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated"><em class="kw"> UNet:解释经典模型架构</em></p><p id="79ab" class="pw-post-body-paragraph jo jp ht jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">U-Net由Olaf Ronneberger、Philipp Fischer、Thomas Brox于2015年在论文《U-Net:生物医学图像分割的卷积网络》中创建。它是FCN的改进和发展:埃文·谢尔哈默，乔纳森·朗，特雷弗·达雷尔(2014)。“语义分割的全卷积网络”。</p><p id="dae7" class="pw-post-body-paragraph jo jp ht jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">在生物医学图像任务中，不仅需要识别具有特定疾病的图像，还需要识别疑似疾病的区域。经典卷积神经网络将其任务集中在图像分类上，其中输入是图像，输出是一个标签，但是UNet能够识别可能患病的区域，它能够通过对每个像素进行分类来定位和区分边界，因此输入和输出共享相同的大小。</p><p id="035e" class="pw-post-body-paragraph jo jp ht jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">模型的名字来自于它的“U”形结构。左边部分称为收缩路径，由一般卷积过程构成；右边部分是扩展路径，它由转置的2d卷积层构成，基本上用作上采样过程。</p><p id="ce8d" class="pw-post-body-paragraph jo jp ht jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated"><em class="kw">收缩路径</em>:遵循以下流程</p><p id="101e" class="pw-post-body-paragraph jo jp ht jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">卷积_第1层-&gt;卷积_第2层-&gt;最大池-&gt;丢弃(可选)</p><figure class="kn ko kp kq fd hk er es paragraph-image"><div class="er es kx"><img src="../Images/a139b96db4f42e5f657ed6bf7757a036.png" data-original-src="https://miro.medium.com/v2/resize:fit:424/0*WV4C5bEEbzXWQjE1"/></div></figure><p id="3efc" class="pw-post-body-paragraph jo jp ht jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">每个过程构成两个卷积层，通道数从1 → 64变化，因为卷积过程会增加图像的深度。向下的红色箭头是最大池化过程，它将图像大小减半。</p><figure class="kn ko kp kq fd hk er es paragraph-image"><div class="er es ky"><img src="../Images/e3e7bd02865caf3f75e3c5b3f4d64ebb.png" data-original-src="https://miro.medium.com/v2/resize:fit:768/0*UDNzHFDOrUHEogLN"/></div></figure><p id="c543" class="pw-post-body-paragraph jo jp ht jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">上述过程重复3次。</p><figure class="kn ko kp kq fd hk er es paragraph-image"><div class="er es kz"><img src="../Images/4cdad8dc271de5b0cfa609ace7a93167.png" data-original-src="https://miro.medium.com/v2/resize:fit:624/0*ksZ-SjQfL_TN5UfS"/></div></figure><p id="0a28" class="pw-post-body-paragraph jo jp ht jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">最后，在最底层构建第2层卷积层，但没有最大池。这时的图像已经调整到28x28x1024。</p><p id="1a22" class="pw-post-body-paragraph jo jp ht jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated"><em class="kw">广阔的道路:</em></p><p id="17fb" class="pw-post-body-paragraph jo jp ht jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">在此过程中，图像将被放大到其原始大小。它遵循以下过程:</p><figure class="kn ko kp kq fd hk er es paragraph-image"><div class="er es la"><img src="../Images/37f843b5cab8b1fd9b63461e887c47fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1140/0*cxpiF1TQCWUWqy8i"/></div></figure><p id="05e4" class="pw-post-body-paragraph jo jp ht jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">卷积_ 2d _转置-&gt;连接-&gt;卷积_层1 -&gt;卷积_层2</p><p id="49aa" class="pw-post-body-paragraph jo jp ht jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">转置卷积是一种上采样技术，它通过填充原始图像，然后进行卷积运算来扩展图像的大小。在转置卷积之后，图像从28×28×1024→56×56×512被放大，然后，该图像与来自收缩路径的相应图像连接在一起，并且一起形成大小为56×56×1024的图像。这样做是为了组合来自先前层的信息，以便获得更精确的预测。</p><figure class="kn ko kp kq fd hk er es paragraph-image"><div class="er es km"><img src="../Images/9da072585b6b8d05dcb1fc9233e55dce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1224/0*ySgz8lyfOv83v2KT"/></div></figure><p id="61b4" class="pw-post-body-paragraph jo jp ht jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">最后一步是对图像进行整形，以满足预测要求，因此最后一层卷积层具有1个大小为1×1的滤波器。</p><p id="079b" class="pw-post-body-paragraph jo jp ht jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">** <em class="kw">要详细了解转置卷积请查看这篇令人惊叹的文章:</em><a class="ae lb" rel="noopener" href="/activating-robotic-minds/up-sampling-with-transposed-convolution-9ae4f2df52d0">https://medium . com/activating-robotic-minds/up-sampling-with-Transposed-convolution-9 AE 4 F2 df 52d 0</a></p><p id="df49" class="pw-post-body-paragraph jo jp ht jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated"><em class="kw">动态UNet架构</em></p><p id="1d3b" class="pw-post-body-paragraph jo jp ht jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">与经典UNet架构相比，动态UNet架构依赖于编码器-解码器结构。在我们的实现中，U-Net将位于编码器(可以是预训练的模型)之上，最终输出为n_classes。在初始化期间，它通过在模型中传递一个虚拟输入，使用钩子来确定中间特征尺寸，并自动创建向上的路径。因此，解码器部分(扩展路径)是基于编码器架构自动创建的。</p><p id="bf0f" class="pw-post-body-paragraph jo jp ht jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated"><em class="kw">动态UNet实现</em></p><p id="db10" class="pw-post-body-paragraph jo jp ht jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">1.模型实例化:在我们的实现中，编码器基本上是一个预训练的ResNet34模型:</p><pre class="kn ko kp kq fd lc ld le lf aw lg bi"><span id="8683" class="lh ir ht ld b fi li lj l lk ll">learn = unet_learner(data, models.resnet34, metrics=dice, wd=1e-1, path='/kaggle/working')</span></pre><p id="4614" class="pw-post-body-paragraph jo jp ht jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">上面的代码创建了一个DynamicUNet类的“learn”对象，编码器是一个预训练的resnet34模型。此外，对于评估度量，我们使用DICE (Dice系数是2 *重叠面积除以两幅图像中的像素总数)。“wd”基本上是一个重量衰减参数，或者更普遍地称为L2正则化。这是减少过拟合的经典方法，包括将模型所有权重的平方和加到损失函数中。</p><p id="d8b0" class="pw-post-body-paragraph jo jp ht jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">2.找到最佳学习率:为了找到最佳学习率，我们从学习率范围测试开始。我们将使用FastAI的内置方法lr_find()。</p><pre class="kn ko kp kq fd lc ld le lf aw lg bi"><span id="85f8" class="lh ir ht ld b fi li lj l lk ll">learn.lr_find()</span></pre><p id="61d5" class="pw-post-body-paragraph jo jp ht jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">这是受论文“超级收敛:使用大学习率快速训练神经网络”的启发链接:<a class="ae lb" href="https://arxiv.org/pdf/1708.07120.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1708.07120.pdf</a></p><figure class="kn ko kp kq fd hk er es paragraph-image"><div class="er es lm"><img src="../Images/b6cb95ee4cd4a595f737d962ca616933.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/0*fjI2MbCrqPeQspSr"/></div></figure><p id="8c7f" class="pw-post-body-paragraph jo jp ht jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">学习率(LR)范围测试的输出可以如下所示。观想给了我们损失和学习速度的概念。</p><p id="9f10" class="pw-post-body-paragraph jo jp ht jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">3.训练模型:我们将使用Leslie Smith的1cycle policy训练网络(链接到论文:<a class="ae lb" href="https://arxiv.org/pdf/1803.09820.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1803.09820.pdf</a>)。</p><p id="ff09" class="pw-post-body-paragraph jo jp ht jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">为了使用这种方法，我们需要从上述方法中找到最佳学习率。在这种情况下，2e-03到8e-03范围内的东西可以作为好的价值。因此，运行5个时期的fit_cycle，并且学习速率(lr) = 5e-03，我们得到以下结果:</p><pre class="kn ko kp kq fd lc ld le lf aw lg bi"><span id="4b91" class="lh ir ht ld b fi li lj l lk ll">learn.fit_one_cycle(5, 5e-3)<br/>learn.recorder.plot()</span></pre><figure class="kn ko kp kq fd hk er es paragraph-image"><div class="er es ln"><img src="../Images/f88d1c231984d93b017bd23b25ca1e9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:850/0*J0CPvbhQ9tsCpRXH"/></div></figure><figure class="kn ko kp kq fd hk er es paragraph-image"><div class="er es lo"><img src="../Images/03aa55b47bb0f7cca2930f8bdfd8d89e.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/0*0J8YIii8gG9mLg44"/></div></figure><h1 id="4b2c" class="iq ir ht bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">使用海王星人工智能记录器运行实验和度量跟踪</h1><p id="2a87" class="pw-post-body-paragraph jo jp ht jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">Neptune是一个实验跟踪中心，为数据科学项目带来组织和协作。基本上它记录了整个实验过程。这非常有帮助，因为它有助于运行几个具有不同参数调整的实验，并比较模型的性能。</p><p id="bdfc" class="pw-post-body-paragraph jo jp ht jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">让我们看看如何为下面的项目设置一个Neptune监视器</p><p id="ddaf" class="pw-post-body-paragraph jo jp ht jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">1.安装所需的包:Neptune工具需要以下包</p><pre class="kn ko kp kq fd lc ld le lf aw lg bi"><span id="9c47" class="lh ir ht ld b fi li lj l lk ll">!pip install neptune-contrib<br/>!pip install neptune-contrib[monitoring]</span></pre><p id="fd11" class="pw-post-body-paragraph jo jp ht jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">2.设置Neptune监视器并创建一个实验:下面的代码创建了一个Neptune实验，它可以在模型训练期间记录各种度量</p><pre class="kn ko kp kq fd lc ld le lf aw lg bi"><span id="ee27" class="lh ir ht ld b fi li lj l lk ll">import neptune<br/>from neptunecontrib.monitoring.fastai import NeptuneMonitor</span><span id="9768" class="lh ir ht ld b fi lp lj l lk ll">neptune.init('aninda/sandbox',<br/>             api_token=secret_value_0)</span><span id="5a52" class="lh ir ht ld b fi lp lj l lk ll">with neptune.create_experiment(name='FastAI_MRI_segmentation',params={'lr': 1e-2}):<br/>    neptune.append_tag('First_logger')<br/>    learn.callbacks.append(NeptuneMonitor())<br/>    <br/>    learn.fit_one_cycle(20, slice(2e-3))</span></pre><p id="0cea" class="pw-post-body-paragraph jo jp ht jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">由于这段代码是用Kaggle编写的，因此也分享了一种创建API令牌来保持API密钥秘密的方法:</p><pre class="kn ko kp kq fd lc ld le lf aw lg bi"><span id="eee0" class="lh ir ht ld b fi li lj l lk ll">from kaggle_secrets import UserSecretsClient<br/>user_secrets = UserSecretsClient()<br/>secret_value_0 = user_secrets.get_secret("api_token_neptune")</span></pre><p id="8615" class="pw-post-body-paragraph jo jp ht jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">3.在海王星人工智能中可视化记录的实验</p><p id="8860" class="pw-post-body-paragraph jo jp ht jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">Neptune AI提供了一个强大的UI来可视化所有的实验，并带有交互式图表来比较这些实验。</p><figure class="kn ko kp kq fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lq"><img src="../Images/7e7067217a1dbfe6cb6c8e1364be977f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*9g8-YEZcYBG3e-6Q"/></div></div></figure><p id="fb27" class="pw-post-body-paragraph jo jp ht jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">比较不同实验中各种损失指标的结果:</p><figure class="kn ko kp kq fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lq"><img src="../Images/c24ca6132408a48f8efcbffd1935e59a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Ti7yqzTpRj1Fg1fO"/></div></div></figure><figure class="kn ko kp kq fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lr"><img src="../Images/1e49622cdf8be5c00003123a55fa0896.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*fvPzo5NRXB3x1rFW"/></div></div></figure><p id="e2ee" class="pw-post-body-paragraph jo jp ht jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">这些强大的工具有助于确定模型的正确参数，并加快数据科学项目的实验阶段。</p><h1 id="8bd7" class="iq ir ht bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">保存模型并可视化预测结果</h1><p id="245a" class="pw-post-body-paragraph jo jp ht jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">使用以下代码保存训练好的模型:</p><pre class="kn ko kp kq fd lc ld le lf aw lg bi"><span id="5b1c" class="lh ir ht ld b fi li lj l lk ll">def save_and_show(name):<br/>    saved_to = learn.save(name, return_path=True)<br/>    print('Saved to', saved_to, 'Note: this will be lost unless we commit the kernel')<br/>    learn.load(name) # free memory etc<br/>    <br/>    learn.show_results(rows=8, figsize=(32, 32))</span></pre><p id="0d81" class="pw-post-body-paragraph jo jp ht jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">调用方法</p><pre class="kn ko kp kq fd lc ld le lf aw lg bi"><span id="1ae4" class="lh ir ht ld b fi li lj l lk ll">save_and_show('stage-1')</span></pre><p id="ae45" class="pw-post-body-paragraph jo jp ht jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">结果(实际情况与预测情况):</p><figure class="kn ko kp kq fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es ls"><img src="../Images/f9f99db67be48f29a944c450b7ee8ce0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*msUq42jxWHKFu-ke"/></div></div></figure><p id="1892" class="pw-post-body-paragraph jo jp ht jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">由此可见，该模型在识别肿瘤感染区域方面表现得相当好。</p><h1 id="054f" class="iq ir ht bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">链接到代码库</h1><p id="b184" class="pw-post-body-paragraph jo jp ht jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated"><em class="kw">Github:</em>T4【https://Github . com/conformist 101/brain MRI _ Scan _ FastAI _ segmentation</p><p id="241f" class="pw-post-body-paragraph jo jp ht jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">Kaggle内核:<a class="ae lb" href="https://www.kaggle.com/anindabhattacharjee/fastai-mri-segmentation-with-neptuneai-logging" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/anindabhattacharjee/fastai-MRI-segmentation-with-Neptune ai-logging</a></p><p id="58b7" class="pw-post-body-paragraph jo jp ht jq b jr kr jt ju jv ks jx jy jz kt kb kc kd ku kf kg kh kv kj kk kl hb bi translated">数据集:<a class="ae lb" href="https://www.kaggle.com/mateuszbuda/lgg-mri-segmentation" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/mateuszbuda/lgg-mri-segmentation</a>(作者:<a class="ae lb" href="https://www.kaggle.com/mateuszbuda" rel="noopener ugc nofollow" target="_blank">马特乌斯·布达</a>)</p></div></div>    
</body>
</html>