<html>
<head>
<title>Pytorch or Tensorflow, Dynamic vs Static computation graph</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Pytorch或Tensorflow，动态与静态计算图</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/dynamic-vs-static-computation-graph-2579d1934ecf?source=collection_archive---------0-----------------------#2019-03-10">https://medium.com/analytics-vidhya/dynamic-vs-static-computation-graph-2579d1934ecf?source=collection_archive---------0-----------------------#2019-03-10</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="2e7e" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">动态和静态计算图的区别</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/e333de734588392af464ae7e364978de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*8K6N64f8Y52ZuYPl"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">萨法尔·萨法罗夫在<a class="ae jn" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="5d47" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">使用静态计算图(如Tensor Flow、CNTK)的框架和使用动态计算图(如Pytorch和DyNet)的框架之间的主要区别在于，后者的工作方式如下，为每个训练样本从头开始构建不同的计算图，然后向前和向后传播，换句话说，用户可以自由地为每个输入样本使用不同的网络，但这当然会增加一些开销，但不要担心像DyNet这样的框架有一个优化的C++后端和轻量级的图形表示。实验表明，DyNet的速度比静态声明工具包更快或相当，而静态图框架只需定义一次图，然后优化图编译器就可以生成优化图，然后所有训练样本都可以输入到该图中。一方面，一旦编译完成，大型图可以在CPU或GPU上高效运行<br/>，这使得它非常适合具有固定结构的大型图，其中只有输入在实例之间发生变化。然而，编译步骤本身可能是昂贵的，并且它使得界面使用起来更加麻烦</p><p id="446e" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">现在让我们详细了解一下两种范式之间的差异。</p></div><div class="ab cl kk kl gp km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="hb hc hd he hf"><h2 id="ac93" class="kr ks hi bd kt ku kv kw kx ky kz la lb jx lc ld le kb lf lg lh kf li lj lk ll bi translated">静态声明</h2><p id="37d1" class="pw-post-body-paragraph jo jp hi jq b jr lm ij jt ju ln im jw jx lo jz ka kb lp kd ke kf lq kh ki kj hb bi translated">静态声明遵循两个步骤:</p><blockquote class="lr ls lt"><p id="23a1" class="jo jp lu jq b jr js ij jt ju jv im jw lv jy jz ka lw kc kd ke lx kg kh ki kj hb bi translated">计算架构的定义</p></blockquote><p id="92c8" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">在这个步骤中，用户定义他希望继续进行的图形的形状，例如取一个16*16的图像，并且把这个图像传递到10个卷积层，用这个确定的函数计算损失并且预测一个确定图像的类别。</p><blockquote class="lr ls lt"><p id="25eb" class="jo jp lu jq b jr js ij jt ju jv im jw lv jy jz ka lw kc kd ke lx kg kh ki kj hb bi translated">计算的执行</p></blockquote><p id="06b2" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">在计算发生的这一步，用户重复地将数据传递给16x16矩阵，库执行先前声明的计算图。然后可以在测试时使用预测，或者在训练时可以计算损失并反向传播</p><p id="daf8" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">优势</p><p id="b8a7" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">一个显而易见的事情是，图形一旦定义，就可以尽可能快地多次使用，因为实际上我们不会创建任何新的东西，所以这在大型数据集上非常有用，并且在训练和测试速度方面非常有用。第二，静态计算图可以用于跨计算设备池调度计算，因此可以共享计算成本。</p><p id="6346" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">不足之处</p><ul class=""><li id="d10c" class="ly lz hi jq b jr js ju jv jx ma kb mb kf mc kj md me mf mg bi translated"><em class="lu">不同的输入大小可能是一个问题，例如，如果您的输入不限于16*16，那么定义相同计算的单一结构将会更加困难。</em></li><li id="5ac1" class="ly lz hi jq b jr mh ju mi jx mj kb mk kf ml kj md me mf mg bi translated">可变结构的输入/输出:更复杂的情况是每个输入不仅有不同的大小，而且有不同的结构，例如你的数据可能有图像、文本和结构化的表格。</li></ul><p id="90ff" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">然而，如果我们可以在声明时声明一个具有未指定大小的输入的图，并让该图处理输入，因为TensorFlow提供了动态rnn操作，我们就可以避免这些困难。因此，虽然原则上可以用静态声明来处理可变架构，但在实践中仍然存在一些困难:</p><p id="6589" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">计算图实现的复杂性:</p><p id="0446" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">为了支持动态执行，计算图必须能够处理更复杂的数据类型(例如，可变大小的张量和结构化数据)，并且像流控制原语这样的操作必须作为操作可用。这增加了计算图形式和实现的复杂性，并减少了优化的机会。</p><p id="ee51" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">调试难度:</p><p id="98cf" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">虽然静态分析允许在声明期间识别一些错误，但是许多逻辑错误必须等到执行时才被发现(特别是当许多变量在声明时未被指定时)，这必然远离导致它们的声明代码。根本原因的位置和观察到的崩溃的位置的分离使得调试变得困难。</p><h2 id="82d4" class="kr ks hi bd kt ku kv kw kx ky kz la lb jx lc ld le kb lf lg lh kf li lj lk ll bi translated">动态声明</h2><p id="8480" class="pw-post-body-paragraph jo jp hi jq b jr lm ij jt ju ln im jw jx lo jz ka kb lp kd ke kf lq kh ki kj hb bi translated">这仅执行一步技术，因此回想一下我们的16*16图像的示例，加载该图像，然后将其传递到2个卷积层，然后计算训练阶段的损失，或者计算测试情况下的预测概率，为每个训练实例创建图表，因此它应该是轻量级的。</p><h2 id="854e" class="kr ks hi bd kt ku kv kw kx ky kz la lb jx lc ld le kb lf lg lh kf li lj lk ll bi translated">信用</h2><ul class=""><li id="5590" class="ly lz hi jq b jr lm ju ln jx mm kb mn kf mo kj md me mf mg bi translated"><a class="ae jn" href="https://arxiv.org/abs/1701.03980" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1701.03980</a>。</li><li id="8ece" class="ly lz hi jq b jr mh ju mi jx mj kb mk kf ml kj md me mf mg bi translated">Yoav Goldberg自然语言处理中的神经网络方法-Morgan &amp; Claypool (2017)图书。</li></ul></div></div>    
</body>
</html>