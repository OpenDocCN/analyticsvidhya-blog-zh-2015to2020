<html>
<head>
<title>Introduction of Reinforcement Learning- Q &amp; A</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">强化学习简介-问答</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/introduction-of-reinforcement-learning-q-a-a702cea3e428?source=collection_archive---------31-----------------------#2020-07-12">https://medium.com/analytics-vidhya/introduction-of-reinforcement-learning-q-a-a702cea3e428?source=collection_archive---------31-----------------------#2020-07-12</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><blockquote class="if ig ih"><p id="317b" class="ii ij ik il b im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg hb bi translated"><em class="hi">“</em>运用得当，正强化:学习无比强大。”</p></blockquote><figure class="ji jj jk jl fd jm er es paragraph-image"><div role="button" tabindex="0" class="jn jo di jp bf jq"><div class="er es jh"><img src="../Images/d7285a71e6e617812ad07e06e023165e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*xYdMIism4Wn9cTh_"/></div></div><figcaption class="jt ju et er es jv jw bd b be z dx translated">由<a class="ae jx" href="https://unsplash.com/@jamesponddotco?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">詹姆斯·庞德</a>在<a class="ae jx" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="5928" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jy iv iw ix jz iz ja jb ka jd je jf jg hb bi translated">强化学习是一种机器学习技术，其中代理通过最大化为实现既定目标而采取的行动的累积回报，使用试错法从环境中学习。</p><figure class="ji jj jk jl fd jm er es paragraph-image"><div role="button" tabindex="0" class="jn jo di jp bf jq"><div class="er es kb"><img src="../Images/dbeb1dfc3cfac8bb9e3f0d1ea068d9a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*NVodh9bJCsy97cjS.png"/></div></div><figcaption class="jt ju et er es jv jw bd b be z dx translated">图片:-维基百科</figcaption></figure><p id="b59a" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jy iv iw ix jz iz ja jb ka jd je jf jg hb bi translated">让我们试着理解上图中的强化学习(RL ),一个代理人会在给定的环境中采取一些行动，结果是，如果代理人采取的行动是正确的，他会得到奖励，如果代理人采取的行动是错误的，他会得到惩罚。这与婴儿如何学习走路是一个简单的类比。首先，他们把错误的脚放在前面，摔倒(惩罚)，然后把右脚放在前面(得到父母喜欢的奖励)，接着，把右脚放在前面，婴儿开始走和跑。这与RL问题非常相似，最初它对环境一无所知，但最终它开始采取行动，并在行动过程中获得奖励或惩罚。</p><p id="2b22" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jy iv iw ix jz iz ja jb ka jd je jf jg hb bi translated"><strong class="il hj">强化学习与监督学习有何不同？</strong></p><p id="1cfb" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jy iv iw ix jz iz ja jb ka jd je jf jg hb bi translated">在监督学习中，有明确定义的标记输出来识别给定的特征，并且机器试图在特征和输出之间创建等式。在RL中没有提供这样的标记输出，代理将采取行动，然后将使用奖励或惩罚来了解该行动有多好。</p><p id="40f2" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jy iv iw ix jz iz ja jb ka jd je jf jg hb bi translated"><strong class="il hj">强化学习和无监督学习有区别吗？</strong></p><p id="a865" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jy iv iw ix jz iz ja jb ka jd je jf jg hb bi translated">是的，在无监督学习中，机器试图找到数据点之间的相似性，并且不存在机器想要实现的这种指定目标，不像RL机器有指定的目标，它为实现该目标采取行动并获得奖励或惩罚。以婴儿走路为例，婴儿的目标是走路。</p><p id="f01a" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jy iv iw ix jz iz ja jb ka jd je jf jg hb bi translated"><strong class="il hj">什么是强化学习中的agent？</strong></p><p id="63c7" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jy iv iw ix jz iz ja jb ka jd je jf jg hb bi translated">RL中的代理通过最大化累积奖励和最小化惩罚来从环境中学习。代理从环境中接收观察和奖励，并对环境采取行动。</p><figure class="ji jj jk jl fd jm er es paragraph-image"><div class="er es kc"><img src="../Images/c1b771c7f6b0a94321e99dcd2c545938.png" data-original-src="https://miro.medium.com/v2/resize:fit:956/format:webp/0*DElNd6AGnPHBiNp8.png"/></div></figure><p id="c08f" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jy iv iw ix jz iz ja jb ka jd je jf jg hb bi translated"><strong class="il hj">强化学习中的环境是什么？</strong></p><p id="1686" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jy iv iw ix jz iz ja jb ka jd je jf jg hb bi translated">环境是代理根据给定策略采取行动的地方。就像对婴儿来说，环境应该是游乐场，家..等等，汽车的环境就是汽车可以行驶的道路和高速公路。通常有两种类型的环境。确定性和概率性。</p><p id="ea83" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jy iv iw ix jz iz ja jb ka jd je jf jg hb bi translated">在<strong class="il hj">确定性环境</strong>中——你的环境不会因为采取行动而改变，它将是相同的。意味着确定性环境的结果示例将像国际象棋游戏移动，tic tok游戏移动</p><p id="9aeb" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jy iv iw ix jz iz ja jb ka jd je jf jg hb bi translated">在<strong class="il hj">随机(概率)环境</strong> —我们无法确定电流的输出，因为它在采取每个行动后都在不断变化。这是一个真实的生活场景，我们无法确定接下来会发生什么。随机环境的例子——环境变化非常快的自动驾驶汽车。</p><p id="2db5" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jy iv iw ix jz iz ja jb ka jd je jf jg hb bi translated"><strong class="il hj">什么是强化学习中的探索和利用？</strong></p><p id="6e6f" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jy iv iw ix jz iz ja jb ka jd je jf jg hb bi translated">探索意味着主体将探索所有可能的行动，以获得应该采取的最优行动，从而获得最大的回报。就计算而言，这是非常昂贵的，因为探索所有可能需要大量的计算能力。</p><p id="ad54" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jy iv iw ix jz iz ja jb ka jd je jf jg hb bi translated">剥削意味着代理人将只采取某些行动来获得回报。在这种情况下，代理人不采取必要的行动来探索其他行动，以找到达到目标的最佳行动。</p><p id="c165" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jy iv iw ix jz iz ja jb ka jd je jf jg hb bi translated">在训练代理时，我们必须在探索和利用之间取得适当的平衡，以便代理也能探索和不利用某些动作。平衡开发和探索是强化学习中的关键挑战之一，在监督和非监督学习的纯形式中根本不会出现这个问题。</p><p id="e679" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jy iv iw ix jz iz ja jb ka jd je jf jg hb bi translated"><strong class="il hj">强化学习的算法有哪些？</strong></p><ol class=""><li id="a913" class="kd ke hi il b im in iq ir jy kf jz kg ka kh jg ki kj kk kl bi translated">MDP(马尔可夫决策过程)</li><li id="f12e" class="kd ke hi il b im km iq kn jy ko jz kp ka kq jg ki kj kk kl bi translated">动态规划</li><li id="a961" class="kd ke hi il b im km iq kn jy ko jz kp ka kq jg ki kj kk kl bi translated">蒙特卡洛过程</li><li id="b92e" class="kd ke hi il b im km iq kn jy ko jz kp ka kq jg ki kj kk kl bi translated">q学习</li><li id="c34d" class="kd ke hi il b im km iq kn jy ko jz kp ka kq jg ki kj kk kl bi translated">时差</li><li id="98e8" class="kd ke hi il b im km iq kn jy ko jz kp ka kq jg ki kj kk kl bi translated">双Q学习(DQL)</li><li id="b4bc" class="kd ke hi il b im km iq kn jy ko jz kp ka kq jg ki kj kk kl bi translated">州行动奖励州行动</li></ol><p id="a2fd" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jy iv iw ix jz iz ja jb ka jd je jf jg hb bi translated"><strong class="il hj">强化学习有哪些应用？</strong></p><p id="84e5" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jy iv iw ix jz iz ja jb ka jd je jf jg hb bi translated">自主机器人——RL在机器人领域有着巨大的用途。当机器人在真实环境中接受训练时，机器人会学习并因采取的每一个行动而获得奖励。它为复杂且难以设计的行为设计提供了框架和工具集。</p><p id="3b0e" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jy iv iw ix jz iz ja jb ka jd je jf jg hb bi translated">电脑游戏——现在大多数游戏都是在RL上开发的，并且在本质上变得具有适应性。机器在玩游戏的同时也在学习，当机器学习时，它提供了不同的挑战</p><p id="598d" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jy iv iw ix jz iz ja jb ka jd je jf jg hb bi translated">个性化推荐——以前的新闻推荐工作面临着几个挑战，包括新闻动态的快速变化、用户容易厌倦以及点击率不能反映用户的保留率。深度强化学习可以用来解决这个问题。</p></div><div class="ab cl kr ks gp kt" role="separator"><span class="ku bw bk kv kw kx"/><span class="ku bw bk kv kw kx"/><span class="ku bw bk kv kw"/></div><div class="hb hc hd he hf"><p id="d132" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jy iv iw ix jz iz ja jb ka jd je jf jg hb bi translated">感谢阅读。做评论，让我知道你是否需要任何详细的博客/任何算法/方法。</p><p id="588c" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jy iv iw ix jz iz ja jb ka jd je jf jg hb bi translated">祝你过得愉快。</p></div></div>    
</body>
</html>