<html>
<head>
<title>Computer Vision Techniques: Implementing Mask-R CNN on Malaria Cells Data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">计算机视觉技术:在疟疾细胞数据上实现Mask-R CNN</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/computer-vision-techniques-implementing-mask-r-cnn-on-malaria-cells-data-e03b9fbeb6be?source=collection_archive---------2-----------------------#2019-11-13">https://medium.com/analytics-vidhya/computer-vision-techniques-implementing-mask-r-cnn-on-malaria-cells-data-e03b9fbeb6be?source=collection_archive---------2-----------------------#2019-11-13</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/c65a48b0d1557fb3915ec19562f9a56d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1118/format:webp/1*mLqAyXo0EQQc7gWv5DhMFw.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">基于Mask-R CNN的疟疾细胞检测</figcaption></figure><blockquote class="iq ir is"><p id="2669" class="it iu iv iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">当今世界，计算机视觉是人工智能中最强大、最复杂的领域。随着我们的深入，我们将体验计算机视觉的各种应用和技术。</p></blockquote><p id="0158" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">计算机视觉是试图复制人眼复杂性的计算机科学领域。它使计算机能够检测图像和视频中的对象。由于深度学习和各种CNN和R-CNN技术，这在今天成为可能。</p><p id="cedc" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">有5种主要的计算机视觉技术:</p><ol class=""><li id="8c64" class="jv jw hi iw b ix iy jb jc js jx jt jy ju jz jr ka kb kc kd bi translated">图像分类</li><li id="f516" class="jv jw hi iw b ix ke jb kf js kg jt kh ju ki jr ka kb kc kd bi translated">带定位的图像分类</li><li id="9042" class="jv jw hi iw b ix ke jb kf js kg jt kh ju ki jr ka kb kc kd bi translated">目标检测</li><li id="01dc" class="jv jw hi iw b ix ke jb kf js kg jt kh ju ki jr ka kb kc kd bi translated">图像分割:语义分割</li><li id="d5ce" class="jv jw hi iw b ix ke jb kf js kg jt kh ju ki jr ka kb kc kd bi translated">图像分割:实例分割</li></ol><h1 id="40a8" class="kj kk hi bd kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg bi translated">1.图像分类</h1><p id="0a98" class="pw-post-body-paragraph it iu hi iw b ix lh iz ja jb li jd je js lj jh ji jt lk jl jm ju ll jp jq jr hb bi translated">在图像分类问题中，各种图像中的每一幅图像都属于一个类别。我们需要定义图像的标签，并预测图像的类别。</p><p id="d5c7" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">让我们公式化一个问题:</p><ul class=""><li id="23c6" class="jv jw hi iw b ix iy jb jc js jx jt jy ju jz jr lm kb kc kd bi translated">假设我们有一个MNIST数据集，其中有N幅图像，这些图像被分类到10个标签中的任何一个标签中:0，1，2，3，4，5，6，7，8，9是我们的输入数据。</li><li id="fc23" class="jv jw hi iw b ix ke jb kf js kg jt kh ju ki jr lm kb kc kd bi translated">然后，我们使用该输入或训练数据集来训练分类器以学习该模型。</li><li id="19a9" class="jv jw hi iw b ix ke jb kf js kg jt kh ju ki jr lm kb kc kd bi translated">最后，我们将评估我们的模型，要求它预测一组新图像的标签。然后，我们可以将真实标签与分类器给出的图像的预测标签进行比较。</li></ul><p id="d5b5" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">这里，我们可以使用多标签分类器或CNN(卷积神经网络)来训练我们的分类器。</p><figure class="lo lp lq lr fd ij er es paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="er es ln"><img src="../Images/af3adb7d19d92df7559a2b4d1c5816da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hkOaiCAaNf_LqtBB6HflkA.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">使用CNN预测的MNIST图像(红色数字显示预测值)</figcaption></figure><p id="d95f" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">在上图中，我们使用CNN训练了MNIST数据，并预测了一些图像的标签。</p><p id="a9c9" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated"><strong class="iw hj">输出:图像分类的输出是类别标签或类别id。</strong></p><p id="3cd8" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated"><strong class="iw hj">问题:</strong>如果我们想定位物体的位置呢？</p><h1 id="171b" class="kj kk hi bd kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg bi translated">2.带定位的图像分类</h1><p id="0256" class="pw-post-body-paragraph it iu hi iw b ix lh iz ja jb li jd je js lj jh ji jt lk jl jm ju ll jp jq jr hb bi translated">比方说，我们有狗和猫的图像，我们用CNN对它们进行分类，如果我们想知道它们在图像中的位置呢？</p><p id="f2c4" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">这是更具挑战性的图像分类版本。</p><p id="1b37" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">输出:输出是类别标签+由边界框给出的图像中对象的位置。边界框是围绕对象的矩形或正方形框。</p><figure class="lo lp lq lr fd ij er es paragraph-image"><div class="er es lw"><img src="../Images/f0fb602d49208a00bd916babf5d24e9b.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/1*Hf9r7xFBEUdkJ2DMYU4EEA.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">图片显示了疟疾细胞图像中细胞的边界框</figcaption></figure><figure class="lo lp lq lr fd ij er es paragraph-image"><div class="er es lx"><img src="../Images/dceeeff6315d67d8d0dbfb906f3d379c.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*6CfYAmzhO5FlrM-EUUO-aQ.jpeg"/></div><figcaption class="im in et er es io ip bd b be z dx translated">图像分类与带定位的图像分类的区别(来源:互联网)</figcaption></figure><p id="3eef" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated"><strong class="iw hj">问:</strong>如果一张图片中有不同类型的物体会怎么样？</p><h1 id="855d" class="kj kk hi bd kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg bi translated">3.目标检测</h1><p id="b8a3" class="pw-post-body-paragraph it iu hi iw b ix lh iz ja jb li jd je js lj jh ji jt lk jl jm ju ll jp jq jr hb bi translated">在具有定位的图像分类中，每个图像可以具有多个具有相同类别标签的对象，但是如果图像具有具有不同类别标签的不同对象，则识别它们的类别标签和包围盒属于对象检测。</p><figure class="lo lp lq lr fd ij er es paragraph-image"><div class="er es ly"><img src="../Images/c44f5c62772fa0705fc31f0a42daf7f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1102/format:webp/1*DDmJNbaB02R0w8IFPqMEEg.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">3种计算机视觉技术的区别(来源:互联网)</figcaption></figure><p id="69c1" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">输出:它给出了图像中每个对象的类别标签和边界框。</p><figure class="lo lp lq lr fd ij er es paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="er es lz"><img src="../Images/8c3d8b05c15519d40d993bb95b7aa4a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1zPZ8GnV3LFIvbyj6O7qkg.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">疟疾细胞图像上的目标检测(给出图像中每个细胞的类别标签和包围盒)。在这张图片中，一些细胞是红细胞，一些是环状的。</figcaption></figure><p id="b888" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">可以使用四种算法来完成对象检测:</p><ol class=""><li id="8205" class="jv jw hi iw b ix iy jb jc js jx jt jy ju jz jr ka kb kc kd bi translated"><strong class="iw hj"> CNN-卷积神经网络</strong>像我们的眼睛一样检测边缘，从而定义物体的边界。是的，我们可以使用CNN来检测图像中的对象。CNN进行目标检测的步骤是:</li></ol><ul class=""><li id="7f16" class="jv jw hi iw b ix iy jb jc js jx jt jy ju jz jr lm kb kc kd bi translated">首先，我们将一幅图像作为输入。</li><li id="23f6" class="jv jw hi iw b ix ke jb kf js kg jt kh ju ki jr lm kb kc kd bi translated">然后，使用滑动窗口技术将图像划分成各种区域，就像将100* 100像素的图像划分成各种10* 10像素的区域一样。</li><li id="3210" class="jv jw hi iw b ix ke jb kf js kg jt kh ju ki jr lm kb kc kd bi translated">我们将把每个区域看作独立的图像。</li><li id="852d" class="jv jw hi iw b ix ke jb kf js kg jt kh ju ki jr lm kb kc kd bi translated">把每个地区传给CNN，把他们分成各种类别。</li><li id="85d5" class="jv jw hi iw b ix ke jb kf js kg jt kh ju ki jr lm kb kc kd bi translated">一旦我们得到了每个区域对应的类别，我们就可以将每个区域合并，得到含有检测目标的原始图像。</li></ul><p id="750a" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">CNN的问题是，我们需要将CNN应用于大量的位置和规模，这在计算上非常昂贵！</p><p id="fb20" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated"><strong class="iw hj"> 2。R-CNN(基于区域的CNN)</strong>-R-CNN算法不是在大量区域上工作，而是在图像中提出一堆盒子，并检查这些盒子中是否包含任何对象。r-CNN<strong class="iw hj">T5【使用<strong class="iw hj">选择性搜索</strong>从图像中提取这些方框，这些方框被称为<strong class="iw hj"> ROI(感兴趣区域)。<br/> </strong>我们来了解一下<strong class="iw hj">选择性搜索</strong>:一张图像基本上有四个区域:变化的尺度、颜色、纹理、包围。选择性搜索识别图像中的这些模式，并在此基础上提出各种区域。</strong></p><p id="740e" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated"><strong class="iw hj">选择性搜索</strong>中的步骤:<br/>拍摄图像- &gt;初始分割- &gt;组合相似的片段(基于颜色、纹理或大小相似性以及形状兼容性)- &gt; ROI(感兴趣区域)</p><figure class="lo lp lq lr fd ij er es paragraph-image"><div class="er es ma"><img src="../Images/2461f12a860e7f1e4d225dc7de3c46b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1198/format:webp/1*uFC7egnj62VdwVZy0cZttw.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">美国有线电视新闻网(来源:互联网)</figcaption></figure><p id="26b2" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">在<strong class="iw hj"> R-CNN </strong>中检测物体的步骤如下:</p><ol class=""><li id="996f" class="jv jw hi iw b ix iy jb jc js jx jt jy ju jz jr ka kb kc kd bi translated">R-CNN利用选择性搜索来创建大约2000个感兴趣区域。</li><li id="c45d" class="jv jw hi iw b ix ke jb kf js kg jt kh ju ki jr ka kb kc kd bi translated">这些区域被扭曲成固定大小的图像或被重新整形，以便它们可以匹配CNN输入的大小，并单独馈入CNN网络。CNN为每个区域提取特征。</li><li id="48a3" class="jv jw hi iw b ix ke jb kf js kg jt kh ju ki jr ka kb kc kd bi translated">提取每个区域的特征，然后用SVM对目标和背景进行分类。每堂课，我们训练一个二进制SVM。</li><li id="8b99" class="jv jw hi iw b ix ke jb kf js kg jt kh ju ki jr ka kb kc kd bi translated">最后，提取的每个区域的特征还遵循线性回归模型来为图像中每个识别的对象生成更紧密的包围盒。</li></ol><p id="9c44" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">较少但更高质量的ROI使得R-CNN比滑动窗口CNN更快更准确。</p><p id="b4d1" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">美国有线电视新闻网的问题:</p><p id="f0fe" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">训练R-CNN模型既昂贵又缓慢，因为:</p><ul class=""><li id="5be8" class="jv jw hi iw b ix iy jb jc js jx jt jy ju jz jr lm kb kc kd bi translated">基于选择性搜索为每幅图像提取2000个区域</li><li id="688f" class="jv jw hi iw b ix ke jb kf js kg jt kh ju ki jr lm kb kc kd bi translated">使用CNN提取每个图像区域的特征。假设我们有N个图像，那么CNN特征的数量将是N * 2,000</li><li id="038e" class="jv jw hi iw b ix ke jb kf js kg jt kh ju ki jr lm kb kc kd bi translated">使用R-CNN训练对象检测的3个模型(CNN、SVM和回归器)使其速度慢且计算量大。</li></ul><p id="9c79" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated"><strong class="iw hj"> 3。快速R-CNN <br/> </strong>解决R-CNN问题的方法是快速R-CNN。在R-CNN中，我们为每张图片使用了大约2000个CNN。但是，在快速R-CNN中，单个CNN用于每幅图像，并且一次获得所有特征，因此减少了计算时间。</p><figure class="lo lp lq lr fd ij er es paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="er es mb"><img src="../Images/2d86ccd6b0d0161e1f5dda6764d26684.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GqU49LTS-iiS47e8S3R8tQ.png"/></div></div></figure><p id="8fcf" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">在<strong class="iw hj">快速R-CNN </strong>探测物体的步骤如下:</p><ol class=""><li id="a310" class="jv jw hi iw b ix iy jb jc js jx jt jy ju jz jr ka kb kc kd bi translated">首先，我们使用一个<strong class="iw hj">特征提取器</strong>(一个CNN)来提取整幅图像的特征。</li><li id="21c1" class="jv jw hi iw b ix ke jb kf js kg jt kh ju ki jr ka kb kc kd bi translated">同时，我们还使用外部区域提议方法，如选择性搜索，来创建<strong class="iw hj">ROI</strong>。</li><li id="73bf" class="jv jw hi iw b ix ke jb kf js kg jt kh ju ki jr ka kb kc kd bi translated">然后，我们将感兴趣区域和相应的特征图结合起来，形成用于对象检测的面片。</li><li id="0672" class="jv jw hi iw b ix ke jb kf js kg jt kh ju ki jr ka kb kc kd bi translated">我们根据FC层的输入，使用<strong class="iw hj"> ROI pooling </strong>将补丁打包/整形为固定大小，并将其提供给完全连接的层。</li><li id="1ce6" class="jv jw hi iw b ix ke jb kf js kg jt kh ju ki jr ka kb kc kd bi translated">在全连接网络的顶部使用softmax层来预测类别。除了softmax图层之外，线性回归图层也被并行用于输出预测类的边界框坐标。</li></ol><p id="48b6" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">通过不重复特征提取，快速R-CNN大大减少了处理时间。</p><p id="55ab" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated"><strong class="iw hj">快速R-CNN的问题:</strong>快速R-CNN仍然使用区域提议法来寻找ROI，这使得它非常耗时。</p><p id="2625" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated"><strong class="iw hj"> 4。更快的R-CNN <br/> </strong>更快的R-CNN是Fast R-CNN的修改版。它们之间的主要区别在于，快速RCNN使用选择性搜索来生成感兴趣区域，而快速RCNN使用“<strong class="iw hj">区域提议网络</strong>”(RPN)。</p><p id="b40f" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">RPN以图像特征图作为输入，生成感兴趣区域。</p><figure class="lo lp lq lr fd ij er es paragraph-image"><div class="er es mc"><img src="../Images/07f7b4d66e90aee6a26a8f5c6cffb0bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1216/format:webp/1*FEQicDIERgVZY22fk0M8xw.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">更快的R-CNN</figcaption></figure><p id="e53c" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">步骤如下<strong class="iw hj">更快的R-CNN </strong>检测物体</p><ol class=""><li id="f037" class="jv jw hi iw b ix iy jb jc js jx jt jy ju jz jr ka kb kc kd bi translated">首先，我们使用一个<strong class="iw hj">特征提取器</strong>(一个CNN)来提取整幅图像的特征。</li><li id="6aaa" class="jv jw hi iw b ix ke jb kf js kg jt kh ju ki jr ka kb kc kd bi translated"><strong class="iw hj">区域建议网络</strong>应用于这些特征地图。这将返回对象建议，即ROI及其客观性分数。</li><li id="3218" class="jv jw hi iw b ix ke jb kf js kg jt kh ju ki jr ka kb kc kd bi translated">然后ROI和相应的特征图都通过<strong class="iw hj">ROI合并层。</strong>我们根据FC层的输入将提案包装/整形为固定大小，并将其提供给完全连接的层。</li><li id="c1f4" class="jv jw hi iw b ix ke jb kf js kg jt kh ju ki jr ka kb kc kd bi translated">在全连接网络的顶部使用softmax层来预测类别。与softmax图层一起，线性回归图层也用于并行输出预测类的边界框坐标。</li></ol><p id="86e6" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated"><strong class="iw hj"> RPN </strong>在CNN生成的特征图上使用滑动窗口，在每个窗口，它生成比如说，<em class="iv"> k </em>不同形状和大小的锚框(固定边界框)。对于每个锚盒，RPN预测两件事:</p><ul class=""><li id="ae5b" class="jv jw hi iw b ix iy jb jc js jx jt jy ju jz jr lm kb kc kd bi translated">第一个是锚是对象的概率(不考虑对象属于哪个类)。</li><li id="88f4" class="jv jw hi iw b ix ke jb kf js kg jt kh ju ki jr lm kb kc kd bi translated">第二个是边界框回归器，用于调整锚点以更好地适应对象。</li></ul><p id="659e" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated"><strong class="iw hj">问题</strong>:物体的实际形状呢？</p><h1 id="86cc" class="kj kk hi bd kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg bi translated">4.图像分割:语义分割</h1><p id="534c" class="pw-post-body-paragraph it iu hi iw b ix lh iz ja jb li jd je js lj jh ji jt lk jl jm ju ll jp jq jr hb bi translated">对象检测告诉我们每个对象的类别标签和边界框。但是，它没有告诉我们每个物体的实际形状。</p><p id="09e3" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">因此，这里图像分割进入图片。</p><p id="1763" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">图像分割为每个对象创建了一个像素级的遮罩，从而为我们提供了对象的精确形状。</p><p id="cbd5" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated"><strong class="iw hj">问题</strong>:我们哪里需要图像分割？</p><p id="315d" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated"><strong class="iw hj">回答</strong>:下面是图像分割的一些应用:</p><ol class=""><li id="410a" class="jv jw hi iw b ix iy jb jc js jx jt jy ju jz jr ka kb kc kd bi translated">疟疾或癌症检测细胞:在医学界，正确检测图像中的细胞可以告诉我们有关疾病的信息。</li><li id="80a2" class="jv jw hi iw b ix ke jb kf js kg jt kh ju ki jr ka kb kc kd bi translated">自动驾驶汽车:要驾驶汽车，我们需要了解我们前方或侧面物体的实际形状。因为自动驾驶汽车也需要它。</li><li id="b92c" class="jv jw hi iw b ix ke jb kf js kg jt kh ju ki jr ka kb kc kd bi translated">从卫星系统定位物体。</li></ol><p id="0cd6" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">图像分割有两种类型:</p><p id="9573" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated"><strong class="iw hj">一、语义分割:</strong>图像中的每个像素都属于一个特定的类别——汽车、建筑物、窗户等。并且属于特定类别的所有像素都被分配了单一颜色。例如，它将图像像背景一样分割成1类，将图像中的汽车分割成1类，将图像中的人分割成1类。所以，这里总共有3个类，用3种颜色的3个蒙版分割图片。</p><figure class="lo lp lq lr fd ij er es paragraph-image"><div class="er es md"><img src="../Images/959878fca64470d5f20b847fbc6f7052.png" data-original-src="https://miro.medium.com/v2/resize:fit:1156/format:webp/1*cs8jXP35FnBvUzhxT3yqRA.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">语义分割与实例分割(图片来自互联网)</figcaption></figure><p id="9486" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">有一些实现语义分段的架构，如FCN(全卷积网络)、编码器-解码器架构(例如U-Net架构)等。</p><p id="b2cc" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">问:如果想分别检测同一个类/类型的每个对象呢？</p><p id="924a" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated"><strong class="iw hj">二。实例分割:</strong>它分别对每个对象进行分割。</p><h1 id="008c" class="kj kk hi bd kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg bi translated">5.图像分割:实例分割</h1><p id="d38a" class="pw-post-body-paragraph it iu hi iw b ix lh iz ja jb li jd je js lj jh ji jt lk jl jm ju ll jp jq jr hb bi translated">在实例分段中，同一类的不同实例被单独分段。比如，在上面的图片中，同一个类(动物)的不同实例被赋予了不同的标签。<br/>许多对象的边界框相互重叠。所以面具有助于检测物体的确切形状。<br/> <strong class="iw hj">用于实例分割的算法之一是Mask R-CNN。</strong></p><h2 id="b091" class="me kk hi bd kl mf mg mh kp mi mj mk kt js ml mm kx jt mn mo lb ju mp mq lf mr bi translated">屏蔽R-CNN:</h2><p id="4479" class="pw-post-body-paragraph it iu hi iw b ix lh iz ja jb li jd je js lj jh ji jt lk jl jm ju ll jp jq jr hb bi translated">屏蔽R-CNN基本上是建立在更快的R-CNN之上的。这是一个像素级的图像分割。</p><figure class="lo lp lq lr fd ij er es paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="er es ms"><img src="../Images/29ca8093ff980701f4c7301a7cfc8baf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LskT_JGTVkw162xeRJ8cFg.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">面具R-CNN(来源:互联网)</figcaption></figure><p id="e3a9" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">在<strong class="iw hj">屏蔽R-CNN </strong>中检测物体的步骤</p><ol class=""><li id="422e" class="jv jw hi iw b ix iy jb jc js jx jt jy ju jz jr ka kb kc kd bi translated">首先，我们使用一个<strong class="iw hj">特征提取器</strong>(一个CNN)来提取整幅图像的特征。</li><li id="1ebf" class="jv jw hi iw b ix ke jb kf js kg jt kh ju ki jr ka kb kc kd bi translated"><strong class="iw hj">区域建议网络</strong>应用于这些特征地图。这将返回对象建议，即ROI及其客观性分数。</li><li id="163a" class="jv jw hi iw b ix ke jb kf js kg jt kh ju ki jr ka kb kc kd bi translated">然后ROI和相应的特征图都通过<strong class="iw hj">ROI Align层。在Mask R-CNN中，使用ROI Align </strong>层代替ROI Pooling。RoI Align层旨在修复由RoI池中的量化导致的位置错位。感兴趣的区域被准确地从原始图像映射到特征图上，而不用舍入到整数。</li><li id="a6eb" class="jv jw hi iw b ix ke jb kf js kg jt kh ju ki jr ka kb kc kd bi translated">在全连接网络的顶部使用softmax层来预测类别。与softmax图层一起，线性回归图层也用于并行输出预测类的边界框坐标。</li><li id="451f" class="jv jw hi iw b ix ke jb kf js kg jt kh ju ki jr ka kb kc kd bi translated">ROI对准层的输出也单独进入卷积层以预测掩模。</li></ol><h2 id="0bfb" class="me kk hi bd kl mf mg mh kp mi mj mk kt js ml mm kx jt mn mo lb ju mp mq lf mr bi translated">掩模R-CNN中的损失函数:</h2><p id="6ce1" class="pw-post-body-paragraph it iu hi iw b ix lh iz ja jb li jd je js lj jh ji jt lk jl jm ju ll jp jq jr hb bi translated">掩模R-CNN中的损失包括由于RPN(区域建议网络)造成的损失和由于分类、定位和分割掩模造成的损失。</p><p id="b02a" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">1.损失(RPN)= RPN_Class损失+ RPN_BBox损失</p><p id="f82e" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">2.损失(掩码R-CNN)=损失(类别标签预测)+损失(边界框预测)+损失(掩码预测)</p><h2 id="ccbf" class="me kk hi bd kl mf mg mh kp mi mj mk kt js ml mm kx jt mn mo lb ju mp mq lf mr bi translated">总损耗=损耗(RPN) +损耗(屏蔽R-CNN)</h2><p id="6315" class="pw-post-body-paragraph it iu hi iw b ix lh iz ja jb li jd je js lj jh ji jt lk jl jm ju ll jp jq jr hb bi translated">因此，我们的优化问题是最小化总损失</p><h1 id="4821" class="kj kk hi bd kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg bi translated">在疟疾数据单元上实现Mask R-CNN</h1><p id="3b57" class="pw-post-body-paragraph it iu hi iw b ix lh iz ja jb li jd je js lj jh ji jt lk jl jm ju ll jp jq jr hb bi translated">我已经从kaggle获取了疟疾数据细胞的数据。链接描述如下:<br/>数据来源:<a class="ae mt" href="https://www.kaggle.com/kmader/malaria-bounding-boxes" rel="noopener ugc nofollow" target="_blank"><strong class="iw hj">https://www.kaggle.com/kmader/malaria-bounding-boxes</strong></a></p><p id="df13" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">在这个数据中是图像(。png或者。jpg格式)。有2组图像，包括1208个训练图像和120个测试图像。</p><p id="7eaf" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated"><strong class="iw hj">标签:</strong>数据由两类未感染细胞(红细胞和白细胞)和四类感染细胞(配子体、环、滋养体和裂殖体)组成。数据显示未感染的红细胞与未感染的白细胞和感染的细胞之间存在严重的不平衡，后者占所有细胞的95%以上。</p><p id="d671" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">JSON文件中的每个单元都有一个类标签和一组边界框坐标。<br/>我有一个使用Mask-RCNN(掩模区域卷积神经网络)的训练模型。<br/>我从下面的链接学会了Mask-RCNN。这是一个训练袋鼠对象检测数据集。一些代码片段摘自下面的参考链接。# Ref:<a class="ae mt" href="https://machinelearningmastery.com/how-to-train-an-object-detection-model-with-keras/" rel="noopener ugc nofollow" target="_blank">https://machine learning mastery . com/how-to-train-a-object-detection-model-with-keras/</a></p><p id="745e" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">Mask_RCNN给出3个输出:<br/> 1。Class_ids <br/> 2。对象/单元边界框<br/> 3。对象/单元格的遮罩</p><p id="3047" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated"><strong class="iw hj">本案例研究分为5个步骤:<br/> </strong> 1 .为Keras <br/> 2安装面罩R-CNN。为目标探测准备数据集<br/> 3。用于疟疾细胞检测的训练掩模R-CNN模型<br/> 4。评测Mask R-CNN型号<br/> 5。检测新照片中的单元格</p><h2 id="11cd" class="me kk hi bd kl mf mg mh kp mi mj mk kt js ml mm kx jt mn mo lb ju mp mq lf mr bi translated">1.安装屏蔽R-CNN</h2><p id="787c" class="pw-post-body-paragraph it iu hi iw b ix lh iz ja jb li jd je js lj jh ji jt lk jl jm ju ll jp jq jr hb bi translated">一、从<a class="ae mt" href="https://github.com/matterport/Mask_RCNN" rel="noopener ugc nofollow" target="_blank"><em class="iv"/></a>克隆或下载库</p><p id="47f8" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">二。打开cmd。转到Mask_RCNN目录，运行安装脚本:<br/><em class="iv">CD Mask _ RCNN<br/>python setup . py install<br/>我们会得到安装成功的消息。</em></p><p id="bbe1" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">三。如何检查Mask RCNN是否安装成功:<br/> <em class="iv">运行命令:&gt; pip show mask-rcnn <br/>输出:名称:mask-rcnn <br/>版本:2.1 <br/>摘要:Mask R-CNN用于对象检测和实例分割<br/>主页:</em><a class="ae mt" href="https://github.com/matterport/Mask_RCNN" rel="noopener ugc nofollow" target="_blank"><em class="iv">https://github.com/matterport/Mask_RCNN</em></a><em class="iv"><br/>作者:Matterport <br/>作者邮箱:</em><a class="ae mt" href="mailto:waleed.abdulla@gmail.com" rel="noopener ugc nofollow" target="_blank"><em class="iv">waleed.abdulla@gmail.com</em></a></p><p id="5975" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">我们现在可以使用这个库了。</p><h2 id="ef52" class="me kk hi bd kl mf mg mh kp mi mj mk kt js ml mm kx jt mn mo lb ju mp mq lf mr bi translated">2.为目标检测准备数据集</h2><p id="fbd3" class="pw-post-body-paragraph it iu hi iw b ix lh iz ja jb li jd je js lj jh ji jt lk jl jm ju ll jp jq jr hb bi translated">样本图像:</p><figure class="lo lp lq lr fd ij er es paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="er es mu"><img src="../Images/1f5f4ddbee0082e5422ad84730d84d25.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OsNfJhnCn0MlmC_-EEV_xg.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">疟疾包围盒数据集的图像</figcaption></figure><p id="dbdc" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">示例training.json文件:</p><figure class="lo lp lq lr fd ij er es paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="er es mv"><img src="../Images/83548740f98264f32e51b7b702a6ef3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B0RCWxCIvMHuZLeecRTSqQ.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">示例json文件</figcaption></figure><p id="0aa8" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">这里，图像具有r * c个像素，r和c的最小和最大值定义边界框顶点。</p><p id="dfb1" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">为了创建数据集，我们需要为每个图像的每个边界框提取具有相应类别的最小值、最大值、r值和c值。并为每个图像分配一个image_id。</p><figure class="lo lp lq lr fd ij er es paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="er es mw"><img src="../Images/0dca21b4982350a97b74bfc46eedea4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yZA9Qg_zZus5r3YFIJMnbw.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">创建的数据帧的前5个条目</figcaption></figure><p id="df50" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">写出掩码RCNN的不同函数</p><figure class="lo lp lq lr fd ij er es paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="er es mx"><img src="../Images/579e1726bea85d3718f569db189bb2e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JHZnwmWZ3kJcuK4CNb0m2g.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">代码片段</figcaption></figure><p id="8f13" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">然后准备训练和测试数据集:</p><figure class="lo lp lq lr fd ij er es paragraph-image"><div class="er es my"><img src="../Images/ac26c52fb12377f358b805cc07b2e5a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1124/format:webp/1*fG1C-7BFPw1dJVsi4gQ17g.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">准备训练和测试数据集的代码段</figcaption></figure><p id="46ba" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">让我们测试一下图像加载、遮罩和装箱在not？</p><figure class="lo lp lq lr fd ij er es paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="er es mz"><img src="../Images/3749797213de11cad8f073e665f0c849.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IiYlgJyk9CEmhwT-gb6wnQ.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">使用类标签测试图像加载、遮罩和边界框的代码片段</figcaption></figure><p id="609d" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">上面代码的输出:</p><figure class="lo lp lq lr fd ij er es paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="er es lz"><img src="../Images/6ecbf92f18aa1fc068870ca3dcbf2ddb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ulhLl0qPwOd-Z1LFOaPK_g.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">image_id 15的输出显示</figcaption></figure><p id="3f03" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">图像的可视化显示了遮罩、虚线框格式的边界框和类id。</p><h2 id="92db" class="me kk hi bd kl mf mg mh kp mi mj mk kt js ml mm kx jt mn mo lb ju mp mq lf mr bi translated">3.用于疟疾细胞检测训练掩模R-CNN模型</h2><p id="9e2e" class="pw-post-body-paragraph it iu hi iw b ix lh iz ja jb li jd je js lj jh ji jt lk jl jm ju ll jp jq jr hb bi translated">(一)。第一步是定义用于训练模型的配置:<br/>我们定义了MalariaConfig类，它扩展了mrcnn.config.Config类。</p><figure class="lo lp lq lr fd ij er es paragraph-image"><div class="er es na"><img src="../Images/3f598fcdf92cc8591f33bf4537ac3047.png" data-original-src="https://miro.medium.com/v2/resize:fit:1148/format:webp/1*t6BzEsvcYYu1zFdl_EEipQ.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">马拉里亚配置类</figcaption></figure><p id="6dde" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">㈡。训练模型<br/>现在，我们将使用预定义的权重来训练模型。第一步是下载预适配面罩R-CNN模型的模型文件(架构和权重)。<br/>将模型权重从Mask R-CNN的matterplot github目录下载到您当前工作目录下的一个名为“<em class="iv"> mask_rcnn_coco.h5 </em>的文件中。</p><p id="bceb" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">现在，通过创建一个<em class="iv"> mrcnn.model.MaskRCNN </em>类的实例来定义模型，并通过将“<em class="iv">模式</em>参数设置为“<em class="iv">训练</em>并使用我们上面定义的配置来指定模型将用于训练。</p><p id="ee62" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">加载我们下载的weight mask_rcnn_coco.h5。</p><p id="652a" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">现在训练模型。(代码片段如下所示)</p><figure class="lo lp lq lr fd ij er es paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="er es nb"><img src="../Images/801882e45b28a146f2e0b20905423258.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RpBINBMPSJcu5rWKIOcdBg.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">训练掩模R-CNN模型</figcaption></figure><p id="d8c4" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">训练模型大约需要2-3个小时。我用的是GPU(NVIDIA GeForce GTX 1080，Max-Q设计)。</p><p id="9eff" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">每个时代结束时都会创建一个模型。由于损耗随着每个时段而减少，因此我们将使用时段5文件<strong class="iw hj">mask _ rcnn _ malaria _ CFG _ 0005 . H5</strong>来评估模型性能。</p><h2 id="f0e6" class="me kk hi bd kl mf mg mh kp mi mj mk kt js ml mm kx jt mn mo lb ju mp mq lf mr bi translated">4.评估掩模R-CNN模型</h2><p id="89de" class="pw-post-body-paragraph it iu hi iw b ix lh iz ja jb li jd je js lj jh ji jt lk jl jm ju ll jp jq jr hb bi translated">第一步是为评估模型定义一个新的配置。参见下面的代码。</p><figure class="lo lp lq lr fd ij er es paragraph-image"><div class="er es nc"><img src="../Images/d4432f76b22fa32d1cef23b5138a31db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1352/format:webp/1*0-UW3Tdb7MC8X9bHYhodAw.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">预测配置代码</figcaption></figure><p id="1884" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">接下来，我们可以用config_pred定义模型，并将'<em class="iv">模式</em>'参数设置为'<em class="iv">推理</em>，而不是'<em class="iv">训练</em>'。<br/>接下来，我们可以从当前工作目录中保存的模型文件'<em class="iv">mask _ rcnn _ malaria _ CFG _ 0005 . H5</em>'中加载权重。</p><figure class="lo lp lq lr fd ij er es paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="er es nd"><img src="../Images/f38dcf82352a93a55fbfbdafa50cc361.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*85zFYc44hqtUjKZehM9nYA.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">模型评估代码</figcaption></figure><p id="8c44" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">plot_actual_vs_predicted是为绘制实际图像和预测图像而定义的函数。下图是伪代码片段。</p><figure class="lo lp lq lr fd ij er es paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="er es ne"><img src="../Images/aee43dece4d5ee0eb59cb6d33be6561d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*72zc5uH0FShfTvTLfUPjPw.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">实际图像与预测图像的绘图代码</figcaption></figure><p id="1d60" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">通常使用mAP和IOU来评估用于对象识别任务的模型的性能。</p><p id="2c6f" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">我们预测边界框，这样我们就可以确定预测边界框和实际边界框的重叠程度。这可以通过将重叠面积除以两个边界框的总面积，或者将交集除以并集来计算，称为“<em class="iv">交集除以并集</em>”或IoU。完美的边界框预测将具有为1的IoU。<br/>如果IoU大于0.5，例如它们重叠50%或更多，则假定边界框的预测是肯定的，这是标准的。</p><p id="479e" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">精度是指正确预测的边界框(IoU &gt; 0.5)占图像中预测的所有边界框的百分比。Recall是图像中所有对象中正确预测的边界框(IoU &gt; 0.5)的百分比。随着我们做出更多的预测，召回率会增加，但是精确度会下降或者变得不稳定，因为我们开始做出假阳性预测。对于每个数量的预测，召回(<em class="iv"> x </em>)可以相对于精确度(<em class="iv"> y </em>)来绘制，以创建曲线或直线。我们可以最大化这条线上每个点的值，并计算每个召回值的精确度或AP的平均值。<br/>数据集中所有图像的平均精度(AP)的平均值或均值称为平均精度，或mAP。</p><p id="c273" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">mask-rcnn库提供了一个<em class="iv"> mrcnn.utils.compute_ap </em>来计算给定图像的ap和其他指标。这些AP分数可以跨数据集收集，并且计算平均值以给出模型在检测数据集中的对象方面有多好的想法。</p><figure class="lo lp lq lr fd ij er es paragraph-image"><div class="er es nf"><img src="../Images/6d9124a4bfa6ad9cd8260bfee0e2a896.png" data-original-src="https://miro.medium.com/v2/resize:fit:1080/format:webp/1*EU2eXBzDOdcHkgKBP0d0uQ.png"/></div></figure><figure class="lo lp lq lr fd ij er es paragraph-image"><div class="er es ng"><img src="../Images/56f8a3f63e6a600fbd143ffa22f40feb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1138/format:webp/1*EEl78aEfIzI2fumiFNv2ww.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">预测红细胞和营养体</figcaption></figure><p id="01bf" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">从上面的实际和预测图像我们可以看到实际图像的大部分细胞是预测的。在此示例图像中，预测了红细胞和滋养层。</p><p id="263f" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated"><strong class="iw hj">对模型进行评估后，我们得到:</strong> <br/>训练数据的mAP评估为0.830 <br/>测试数据的mAP评估为0.806</p><h2 id="0738" class="me kk hi bd kl mf mg mh kp mi mj mk kt js ml mm kx jt mn mo lb ju mp mq lf mr bi translated">5.检测新照片中的单元格</h2><p id="4615" class="pw-post-body-paragraph it iu hi iw b ix lh iz ja jb li jd je js lj jh ji jt lk jl jm ju ll jp jq jr hb bi translated">我从网上下载了一些疟疾细胞图像，并在这些图像上运行模型。这些图像不是训练和测试数据集的一部分。</p><p id="64ef" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">结果如下:</p><figure class="lo lp lq lr fd ij er es paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="er es nh"><img src="../Images/26dd0f4235d033d82c43dbfdfbf23a03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*stnJmKpsjdTeiPmbUwU_-Q.jpeg"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">实际图像1</figcaption></figure><figure class="lo lp lq lr fd ij er es paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="er es ni"><img src="../Images/6610489f777ef5e4c7dbd783295f92f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FOWu7wLIF_Z344VX39SCfw.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">预测图像1</figcaption></figure><p id="26ea" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">在上面的新图像中，预测了1个营养橄榄石(红色掩膜),得分为0.7443。</p><figure class="lo lp lq lr fd ij er es paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="er es nj"><img src="../Images/fc662044fb331356c71c430ba66a7620.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m8l6XEdEnMtlxsaU0duP2A.jpeg"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">实际图像2</figcaption></figure><figure class="lo lp lq lr fd ij er es paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="er es nk"><img src="../Images/d15f182ef6c0013ef76ef622266f72f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_O0_FQ0SvIVH_GKZhhhVKQ.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">预测图像2</figcaption></figure><p id="e171" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">在上面的新图像中，预测了1颗营养橄榄石(红色掩膜),得分为0.723。</p><p id="e602" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">在上面预测的图像中，显示了图像中许多单元的边界框和遮罩。并且许多红细胞和滋养体被正确地检测和预测。</p><h2 id="48e8" class="me kk hi bd kl mf mg mh kp mi mj mk kt js ml mm kx jt mn mo lb ju mp mq lf mr bi translated">密码</h2><p id="a27b" class="pw-post-body-paragraph it iu hi iw b ix lh iz ja jb li jd je js lj jh ji jt lk jl jm ju ll jp jq jr hb bi translated">关于代码，请查看我的Github简介</p><div class="nl nm ez fb nn no"><a href="https://github.com/nidhibansal1902/Malaria-cells-detection-case-study-Mask-R-CNN" rel="noopener  ugc nofollow" target="_blank"><div class="np ab dw"><div class="nq ab nr cl cj ns"><h2 class="bd hj fi z dy nt ea eb nu ed ef hh bi translated">nidhibansal 1902/疟疾细胞-检测-案例研究-Mask-R-CNN</h2><div class="nv l"><h3 class="bd b fi z dy nt ea eb nu ed ef dx translated">它是基于计算机视觉的。使用Mask-RCNN疟疾细胞检测-包围盒实现对象检测…</h3></div><div class="nw l"><p class="bd b fp z dy nt ea eb nu ed ef dx translated">github.com</p></div></div><div class="nx l"><div class="ny l nz oa ob nx oc ik no"/></div></div></a></div><h1 id="f118" class="kj kk hi bd kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg bi translated">结论</h1><p id="0312" class="pw-post-body-paragraph it iu hi iw b ix lh iz ja jb li jd je js lj jh ji jt lk jl jm ju ll jp jq jr hb bi translated">在这篇博客中，我们讨论了各种计算机视觉技术。</p><p id="28b0" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">详细讨论了Mask R-CNN，并将其应用于疟疾数据单元。<br/>对红细胞和寄生虫感染细胞的细胞识别效果较好。</p><h2 id="1567" class="me kk hi bd kl mf mg mh kp mi mj mk kt js ml mm kx jt mn mo lb ju mp mq lf mr bi translated">改进的范围</h2><ol class=""><li id="2b27" class="jv jw hi iw b ix lh jb li js od jt oe ju of jr ka kb kc kd bi translated">掩模形状可以改进到单元的精确尺寸。</li><li id="07b0" class="jv jw hi iw b ix ke jb kf js kg jt kh ju ki jr ka kb kc kd bi translated">所实现的模型没有检测到所有被感染的细胞。它需要一些改进。</li></ol></div><div class="ab cl og oh gp oi" role="separator"><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol om"/><span class="oj bw bk ok ol"/></div><div class="hb hc hd he hf"><p id="da3b" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">如果你觉得我的文章有用，给它一个👏并帮助他人找到它。记住，你最多可以 <strong class="iw hj"> <em class="iv">拍50次</em> </strong> <em class="iv">(按下👏图标更长)。这是一个很好的反馈方式！</em></p></div></div>    
</body>
</html>