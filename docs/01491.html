<html>
<head>
<title>RandomForest Classifier Vs Multinomial Naive Bayes for a multi-output Natural Language classification problem</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">多输出自然语言分类问题中随机森林分类器与多项式朴素贝叶斯的比较</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/randomforest-classifier-vs-multinomial-naive-bayes-for-a-multi-output-natural-language-2426381a5217?source=collection_archive---------6-----------------------#2019-10-26">https://medium.com/analytics-vidhya/randomforest-classifier-vs-multinomial-naive-bayes-for-a-multi-output-natural-language-2426381a5217?source=collection_archive---------6-----------------------#2019-10-26</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/a52642e8e5d1a0334ae02f071eb82969.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ERxiPfSvLqEtamUkETAmSg.png"/></div></div></figure><h1 id="2f65" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">简介:</h1><p id="031e" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">自然语言处理(NLP)是当今最令人兴奋的人工智能(AI)技术之一，广泛应用于各行各业。文本识别和分类问题在数据科学家中很流行。科学家经常发现很难选择正确的机器学习模型来用于文本分类问题。</p><p id="9423" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">因此，这篇文章试图比较两种流行的机器学习技术在多输出文本分类问题中的性能:<strong class="jq hj"><em class="kr"/></strong>随机森林分类器和<strong class="jq hj"> <em class="kr">多项朴素贝叶斯</em> </strong>分类器。这两个模型分别应用于灾难期间接收的消息的多输出分类，目的是预测消息可能属于的类别。</p><p id="5236" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">使用的数据集来自<em class="kr">‘图8’</em>，包括两个。csv文件:一个<em class="kr"> 'message.csv' </em>文件和一个<em class="kr"> 'categories.csv' </em>文件。<em class="kr"> 'message.csv' </em>数据包含列:<em class="kr"> message </em>(灾难期间收到的原始消息)<em class="kr"> message_id </em>、<em class="kr">流派</em>(无论是社交媒体、新闻还是直接文本消息)，而<em class="kr"> 'categories.csv' </em>包含<em class="kr"> message_id </em>以及消息所属的不同类别。部分类别包括:<em class="kr">医疗相关</em>、<em class="kr">搜救、</em> <em class="kr">请求帮助</em>、<em class="kr">军事</em>等。，有36个可能的类别。这两个数据集经过<a class="ae ks" href="https://github.com/cjayidoko/DisasterResponsePipeline/blob/master/ETL%20Pipeline%20Preparation.ipynb" rel="noopener ugc nofollow" target="_blank">清理和预处理</a>以获得用于模型准备和构建的数据框架。</p><figure class="ku kv kw kx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kt"><img src="../Images/f3ccfc890bb6f004659fc75b66895d3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WtQjC2PYHjB8_tUggodBrA.png"/></div></div></figure><figure class="ku kv kw kx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ky"><img src="../Images/15797fc76a395e18be6c3aadd9ebdff1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HUIQeiZImJXn6xeXJTyysQ.png"/></div></div><figcaption class="kz la et er es lb lc bd b be z dx translated"><strong class="bd is">消息类别分布</strong></figcaption></figure><h1 id="fd5f" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated"><strong class="ak">特色工程:</strong></h1><p id="b87a" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">作为模型构建的一部分，必须对收到的每一条信息进行处理，并从中提取重要的特征。编写了一个函数<a class="ae ks" href="https://github.com/cjayidoko/DisasterResponsePipeline/blob/master/train_classifier1.py" rel="noopener ugc nofollow" target="_blank"> tokenize </a>，它将对任何给定的句子应用所有必要的文本处理技术。这些技术包括:</p><p id="bcd0" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated"><strong class="jq hj">规范化:</strong>——基本上是把所有字母都转换成小写字母，同时去掉标点符号。<br/> <br/> <strong class="jq hj">记号化:</strong> —将每个文档/行/句子分解成记号或单词，并返回所有记号的列表<br/> <br/> <strong class="jq hj">【词汇化:</strong> —将动词带到它们各自的动词根并去除空格，最后<br/> <br/> <strong class="jq hj">去除停用词:</strong> —包括去除在记号化文档中找到的称为停用词的单词包中包含的所有不必要的单词。因此，tokenize函数为每条消息返回一个经过所有处理阶段的单词列表。此外，使用以下技术提取重要特征:</p><p id="9a0d" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated"><strong class="jq hj"> <em class="kr">计数矢量器:</em> </strong> —它将为所有单词创建一个矩阵，并为单词<br/> <br/> <strong class="jq hj"> <em class="kr">的单次出现分配1，为未出现分配0，术语频率—逆术语频率(TFIDF)转换器:</em> </strong> —它将返回每个单词的归一化/转换形式，包括术语频率乘以逆文档频率。</p><p id="1a23" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">在特征提取阶段结束时，自变量(消息)处于矩阵形式。而因变量是数据集中所有36个类别的1和0的矩阵，两者都已准备好进行一些建模。</p><figure class="ku kv kw kx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ld"><img src="../Images/e847866152ae44ac51c129368bd00925.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bcgXpoYDuusXNoqYrLJSbQ.png"/></div></div><figcaption class="kz la et er es lb lc bd b be z dx translated"><strong class="bd is">使用seaborn热图的类别相似度</strong></figcaption></figure><h1 id="9a92" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated"><strong class="ak">模型构建:</strong></h1><p id="a8d4" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">为了训练用于文本分类的机器学习模型，设计了一种流水线，该流水线将应用上述所有需要的变换以及每个估计器的多输出分类。因为目标是比较两种机器学习技术的性能，所以估计器被单独应用于模型:“模型1”- <strong class="jq hj">随机森林</strong>分类器和‘模型2’——<strong class="jq hj">多项式NB </strong>。</p><pre class="ku kv kw kx fd le lf lg lh aw li bi"><span id="1254" class="lj ir hi lf b fi lk ll l lm ln">#estimator = RandomForestClassifier()<br/> estimator = MultinomialNB()<br/> pipeline = Pipeline([<br/> 	(‘transformer’, Pipeline([<br/> 		(‘vect’, CountVectorizer(tokenizer = tokenize)),<br/> 		(‘tfidf’, TfidfTransformer())<br/> 	])),<br/> 	(‘clf’, MultiOutputClassifier(estimator))<br/> ])</span></pre><p id="b6c3" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">建立了网格搜索，该网格搜索将通过所提供的所有不同参数来运行机器学习管道，以找到每个模型的最佳性能参数，之后将其用于训练模型。看一看所使用的参数和网格搜索，以及每种方法中选出的最佳表现。</p><pre class="ku kv kw kx fd le lf lg lh aw li bi"><span id="2c91" class="lj ir hi lf b fi lk ll l lm ln">parameters = { <br/> 	‘transformer__vect__max_features’: [5000, 3000, 1000],<br/> 	‘transformer__vect__ngram_range’: ((1,1),(1,2)),<br/> 	‘transformer__tfidf__use_idf’: (True, False)<br/> 	}<br/> #Using RandomForestClassifier:<br/> model1 = GridSearchCV(pipeline, param_grid = parameters)<br/> model1.fit(X_train,Y_train)<br/> <br/> #Using Multinomial Naive Bayes:<br/> model2 = GridSearchCV(pipeline, param_grid = parameters)<br/> model2.fit(X_train,Y_train)`</span></pre><p id="1acd" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated"><em class="kr">其中‘X _ train’和‘Y _ train’分别是自变量和因变量的训练数据集(给定数据集的80%)。参数包括</em><strong class="jq hj"><em class="kr">【max-features】</em></strong><em class="kr">，这是对</em> <strong class="jq hj"> <em class="kr">计数矢量器</em> </strong> <em class="kr">、</em> <strong class="jq hj"> <em class="kr">、【n-gram range】</em></strong><em class="kr">是用于决定如何将单词组合并一起分析的范围，以及</em><strong class="jq hj"><em class="kr">【use-IDF】</em></strong><em class="kr">用于</em></p><p id="4154" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated"><strong class="jq hj">最佳表现:</strong></p><pre class="ku kv kw kx fd le lf lg lh aw li bi"><span id="7044" class="lj ir hi lf b fi lk ll l lm ln">model1.best_params_ <br/> 		{‘transformer__tfidf__use_idf’: False,<br/> 		‘transformer__vect__max_features’: 1000,<br/> 		‘transformer__vect__ngram_range’: (1, 2)}<br/>model2.best_params_ <br/> 		{‘transformer__tfidf__use_idf’: False,<br/> 		‘transformer__vect__max_features’: 1000,<br/> 		‘transformer__vect__ngram_range’: (1, 1)}</span></pre><h1 id="e639" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">结果:</h1><p id="f709" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">结果显示用于<strong class="jq hj"> <em class="kr"> RandomForest </em> </strong>分类器的最佳参数包括:<strong class="jq hj"><em class="kr">use _ IDF</em></strong>as<strong class="jq hj">False</strong>这意味着仅使用<strong class="jq hj"> <em class="kr"> tf-idf </em> </strong>矢量器中的术语频率，并且将仅取决于文档中给定单词的密度，而不会消除过多使用该单词的影响， <strong class="jq hj"> <em class="kr"> max_features </em> </strong>为<strong class="jq hj"> 1000 </strong>是测试的<strong class="jq hj"> <em class="kr"> max_features </em> </strong>参数中最小的一个数，<strong class="jq hj"> <em class="kr"> n_gram range </em> </strong>为<strong class="jq hj"> 1-2 </strong>，会优先选择最多两个字的组合。 <strong class="jq hj"> <em class="kr">多项式</em> </strong>返回的最佳参数与<strong class="jq hj"> <em class="kr"> RandomForest </em> </strong>相同，只是单字计数的<strong class="jq hj"> <em class="kr"> n_gram range </em> </strong>不同。<br/>进一步地，模型被用于对测试数据进行预测，并且两个模型的性能指标被比较。编写了一个<a class="ae ks" href="https://github.com/cjayidoko/DisasterResponsePipeline/blob/master/train_classifier1.py" rel="noopener ugc nofollow" target="_blank"> evaluate_model </a>函数，该函数将接受<em class="kr">data frame、y_pred </em>、<em class="kr"> y_test </em>和<em class="kr">列标签</em>，并返回一个重要得分指标的数据帧，例如给定类别的<em class="kr">f1-得分</em>、<em class="kr">准确度</em>、<em class="kr">精度</em>和<em class="kr">召回</em>。在评分标准中，<em class="kr"> precision </em>似乎是在这种情况下选择两个模型中最佳性能的最佳标准。这在很大程度上是基于这样一个事实，即它衡量的是一个模型只检测相关实例(这里是1)的能力。此外，由于precision是真阳性与真阳性预测和假阳性预测之和的度量，使用它将有助于最大限度地减少假阳性，从而最大限度地减少对灾难类别的错误预测。下面显示了precision所示的两个模型的性能对比图。</p><figure class="ku kv kw kx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lo"><img src="../Images/c4e5cffad4a440b9c5563580c766ac8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Wfyvftzq8oZWm_yyiZa-cA.png"/></div></div><figcaption class="kz la et er es lb lc bd b be z dx translated"><strong class="bd is">车型性能对比</strong></figcaption></figure><h1 id="1e6f" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">讨论:</h1><p id="cc9d" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">性能图表明<strong class="jq hj"> <em class="kr"> RandomForest </em> </strong>分类器对于像这样的多输出分类问题中的大部分类别会表现得更好。这是假设默认的10棵树。<a class="ae ks" href="https://www.researchgate.net/post/How_to_determine_the_number_of_trees_to_be_generated_in_Random_Forest_algorithm" rel="noopener ugc nofollow" target="_blank">如果增加树的数量可以带来更好的性能</a>，那么相信进一步的网格搜索可能会产生针对该问题的<strong class="jq hj"> <em class="kr"> RandomForest </em> </strong>分类器的更高性能。此外，<strong class="jq hj"> <em class="kr">朴素贝叶斯</em> </strong>模型似乎对于具有更多训练数据大小的类别表现得更好，例如:“与援助相关的”、“直接报告”、“水”、“与医疗相关的”。</p><p id="9717" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">模型的应用也为建立机器学习模型提供了不同的思路。虽然对于具有较大训练数据大小的类别，精度值显得较低，但是可以看出，模型似乎更准确地预测了这些类别。例如，对诸如“<em class="kr">我们的房子正遭到枪击，我们听到炸弹落下的声音”</em>的文本的预测将准确地返回<strong class="jq hj">军事</strong>作为类别，而文本“<em class="kr">随着事情的发展，我们的房子将被夷为平地，火不会在此停止”</em>将不会返回<strong class="jq hj">火</strong>作为适当的类别。查看<a class="ae ks" href="https://github.com/cjayidoko/DisasterResponsePipeline/blob/master/ML%20Pipeline%20Preparation.ipynb" rel="noopener ugc nofollow" target="_blank">笔记本</a>了解更多相关信息。</p><h1 id="5a0e" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated"><strong class="ak">结论和建议:</strong></h1><p id="5dc5" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">这篇文章已经能够展示在文本的多输出分类中利用<strong class="jq hj"> <em class="kr"> RandomForest </em> </strong>分类器和<strong class="jq hj"> <em class="kr">朴素贝叶斯</em> </strong>分类器的测试案例。结果可以总结如下:</p><p id="90f4" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">1.在机器学习模型中使用网格搜索总是有助于选择最佳参数。然而，这可能很耗时。这种搜索显示:a .在<em class="kr"> 1000 </em>、<em class="kr"> 3000 </em>和<em class="kr"> 5000 </em>和<br/>中选择<em class="kr"> 1000 </em>作为<strong class="jq hj">、<em class="kr">计数矢量器</em>、<br/>中的<em class="kr">max _ feature</em>b .在<strong class="jq hj">、<em class="kr"> Tfidf-transformer </em>、</strong> <br/>中最好不要使用逆文档频率</strong></p><p id="2ac6" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">2.<strong class="jq hj"> <em class="kr"> RandomForest </em> </strong>分类器在可用训练数据较少的情况下会在多输出分类中给出更好的性能，而<strong class="jq hj"> <em class="kr">多项朴素贝叶斯</em> </strong>在测试样本量较大的情况下会表现得更好。</p><p id="3b5f" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">3.训练数据越大，机器学习模型在识别类别时就越准确，但并不转化为性能度量值的增加。</p><p id="11e0" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">进一步的工作将比较两个模型的<em class="kr">召回</em>和<em class="kr">f1-得分</em>，以查看相关预测数量和所有相关预测之间的权衡是否能够提供关于模型性能的进一步见解。此外，在RandomForest分类器上进行网格搜索将有助于选择性能最佳的特征。</p><p id="1cc5" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">要了解更多关于这项工作和用机器学习模型构建的web应用程序的信息，请查看GitHub知识库<a class="ae ks" href="https://github.com/cjayidoko/DisasterResponsePipeline" rel="noopener ugc nofollow" target="_blank">这里</a></p><p id="6142" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated"><strong class="jq hj">关于作者:</strong></p><p id="21cc" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">Chijioke Idoko拥有物理学学士学位和地球物理学硕士学位。在本文发表时，他正在完成Udacity的数据科学纳米学位。他在计算建模方面拥有丰富的经验，并在科学期刊上发表过同行评审的论文。</p><p id="62ad" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">在LinkedIn上联系他<a class="ae ks" href="https://www.linkedin.com/in/chijioke-idoko-b14135a4/" rel="noopener ugc nofollow" target="_blank">这里</a></p></div></div>    
</body>
</html>