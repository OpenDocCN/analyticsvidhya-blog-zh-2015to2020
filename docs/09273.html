<html>
<head>
<title>Common Loss functions in machine learning for a Regression model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">回归模型机器学习中的常见损失函数</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/common-loss-functions-in-machine-learning-for-a-regression-model-27d2bbda9c93?source=collection_archive---------5-----------------------#2020-08-31">https://medium.com/analytics-vidhya/common-loss-functions-in-machine-learning-for-a-regression-model-27d2bbda9c93?source=collection_archive---------5-----------------------#2020-08-31</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/547ddcb41f96c695cc73cc51cc4d72b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uv6vbKh0fjNtAD98Hbn9OQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">凯文·Ku在<a class="ae iu" href="https://unsplash.com/s/photos/coding?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><blockquote class="iv"><p id="7224" class="iw ix hi bd iy iz ja jb jc jd je jf dx translated">为任何算法找到正确的损失函数是至关重要的，因为损失函数的不准确选择将导致错误的解决方案，并可能成为优化机器学习模型的麻烦制造者。</p></blockquote></div><div class="ab cl jg jh gp ji" role="separator"><span class="jj bw bk jk jl jm"/><span class="jj bw bk jk jl jm"/><span class="jj bw bk jk jl"/></div><div class="hb hc hd he hf"><p id="de6b" class="pw-post-body-paragraph jn jo hi jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj jf hb bi translated">机器学习是人工智能的先驱子集，机器使用可用的数据集进行自我学习。对于任何机器学习模型的优化，必须选择可接受的损失函数。一个<strong class="jp hj">损失函数</strong>描述了模型在训练数据集上的表现。损失函数表达了被训练模型的预测和实际问题实例之间的差异。如果预测结果和实际结果之间的偏差太大，那么损失函数将具有非常高的值。逐渐地，在一些优化函数的帮助下，损失函数学习减少预测中的误差。在本文中，我们将介绍几种损失函数及其在机器/深度学习领域的应用。</p><p id="16fb" class="pw-post-body-paragraph jn jo hi jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj jf hb bi translated">不存在适用于所有机器学习模型的普适损失函数。根据问题陈述和模型的类型，需要从可用的集合中选择合适的损失函数。不同的参数，如机器学习算法的类型、所提供的数据集中异常值的百分比程度、计算导数的容易程度等。在选择损失函数中发挥作用。</p><p id="dfc5" class="pw-post-body-paragraph jn jo hi jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj jf hb bi translated">损失函数主要分为两大类<strong class="jp hj">回归损失</strong>和<strong class="jp hj">分类损失</strong>。在本文中，将只讨论回归损失，分类损失将在另一篇文章中发表。(注:回归函数通常预测一个值/数量，而分类函数预测一个标签/类别)</p><h2 id="00dd" class="kk kl hi bd km kn ko kp kq kr ks kt ku jy kv kw kx kc ky kz la kg lb lc ld le bi translated">回归损失:</h2><p id="e89b" class="pw-post-body-paragraph jn jo hi jp b jq lf js jt ju lg jw jx jy lh ka kb kc li ke kf kg lj ki kj jf hb bi translated"><strong class="jp hj"> 1。误差总和(SE) </strong></p><p id="995b" class="pw-post-body-paragraph jn jo hi jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj jf hb bi translated">这是一个基本的损失函数，只需在每次迭代中将预测值和实际值之间的所有误差差相加即可计算出来。数学表示如下:</p><figure class="ll lm ln lo fd ij er es paragraph-image"><div class="er es lk"><img src="../Images/76da92d85ad93b2f11d29a550bd69772.png" data-original-src="https://miro.medium.com/v2/resize:fit:268/format:webp/1*wYzf6lblfXyJ83e_SLp4HA.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">误差总和</figcaption></figure><p id="ca7b" class="pw-post-body-paragraph jn jo hi jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj jf hb bi translated">其中ŷ代表预测值，y代表实际值。</p><p id="eb13" class="pw-post-body-paragraph jn jo hi jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj jf hb bi translated">误差和(SE)不是一个有效的函数，因为预测结果与实际结果的偏差可能是正的，也可能是负的。因此，误差总和(se)值可能小于与期望实际结果的实际总偏差。</p><p id="3e05" class="pw-post-body-paragraph jn jo hi jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj jf hb bi translated"><strong class="jp hj"> 2。绝对误差之和(SAE) </strong></p><p id="ce27" class="pw-post-body-paragraph jn jo hi jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj jf hb bi translated">绝对误差之和(SAE)是每次迭代中预测值和实际值之间所有误差差的绝对值的总和。下面显示了数学表示:</p><figure class="ll lm ln lo fd ij er es paragraph-image"><div class="er es lp"><img src="../Images/5a99719246eedda568ba93a82610f4c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:292/format:webp/1*8ujZUeIK44AzHhMOw-KNcQ.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">绝对误差之和</figcaption></figure><p id="6665" class="pw-post-body-paragraph jn jo hi jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj jf hb bi translated">其中ŷ代表预测值，y代表实际值。</p><p id="58eb" class="pw-post-body-paragraph jn jo hi jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj jf hb bi translated">这里，在绝对误差总和(SAE)中，产生的误差将显示总偏差，预测结果与期望的实际结果有偏差，因为正方向和负方向的偏差不会对彼此的值有任何影响，因此它们各自的值不会减小。</p><p id="2a75" class="pw-post-body-paragraph jn jo hi jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj jf hb bi translated"><strong class="jp hj"> 3。误差平方和(SSE) </strong></p><p id="640f" class="pw-post-body-paragraph jn jo hi jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj jf hb bi translated">误差平方和(SSE)是误差平方的总和，它是从数据的实际期望值预测的偏差。它是数据和估计模型之间差异的度量。较小的SSE表明模型与数据紧密吻合。该函数如下所示:</p><figure class="ll lm ln lo fd ij er es paragraph-image"><div class="er es lq"><img src="../Images/c67e734278e0755949cf7e40a8969092.png" data-original-src="https://miro.medium.com/v2/resize:fit:452/format:webp/1*NZ7PoZjg_hzzEehedDxEAA.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">误差平方和</figcaption></figure><p id="c4c6" class="pw-post-body-paragraph jn jo hi jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj jf hb bi translated">预测结果与实际结果的微小偏差将对误差值产生平方影响。这个函数给出非负值，并且可以在所有点上求导。</p><p id="f0d9" class="pw-post-body-paragraph jn jo hi jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj jf hb bi translated"><strong class="jp hj"> 4。平均绝对误差(MAE) / L1损耗</strong></p><p id="11cb" class="pw-post-body-paragraph jn jo hi jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj jf hb bi translated">平均绝对误差(MAE) / L1损失被测量为预测和实际结果之间的绝对差之和的平均值。这将计算差值的大小。</p><figure class="ll lm ln lo fd ij er es paragraph-image"><div class="er es lr"><img src="../Images/53f9e0d26d87d7209c3d365469c9718a.png" data-original-src="https://miro.medium.com/v2/resize:fit:576/format:webp/1*GSVC0jMNP8p1JAn-0jijjg.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">绝对平均误差</figcaption></figure><p id="1db2" class="pw-post-body-paragraph jn jo hi jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj jf hb bi translated">误差的方向/符号对MAE计算没有影响。无论差异是正还是负。MAE对异常值更鲁棒，但是它需要更复杂的工具来计算梯度。</p><p id="714b" class="pw-post-body-paragraph jn jo hi jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj jf hb bi translated"><strong class="jp hj"> 5。均方误差(MSE) / L2损耗</strong></p><p id="cae7" class="pw-post-body-paragraph jn jo hi jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj jf hb bi translated">均方误差(MSE) / L2损失通过取预测值和实际值之间的平方差的和的平均值来计算。MSE给出了误差的平均大小，与它们的方向无关。</p><figure class="ll lm ln lo fd ij er es paragraph-image"><div class="er es ls"><img src="../Images/f46954d9a2bef40f32369f0ba00ba2a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:506/format:webp/1*4EjHKA45lpoFaNTAHT1h8w.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">均方误差</figcaption></figure><p id="1fb7" class="pw-post-body-paragraph jn jo hi jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj jf hb bi translated">当预测值和实际值相差很小时，MSE值会发生很大的变化。由于平方，根据预测值和实际值之间的差异，它对模型的惩罚很重。用MSE计算梯度更容易。</p><p id="8db5" class="pw-post-body-paragraph jn jo hi jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj jf hb bi translated"><strong class="jp hj"> 6。均方根误差(RMSE) </strong></p><p id="12f8" class="pw-post-body-paragraph jn jo hi jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj jf hb bi translated"><strong class="jp hj">均方根误差</strong> ( <strong class="jp hj"> RMSE </strong>)是最常用的误差函数。它是模型预测值和实际期望值之间的差异。RMSE可以通过取上述<strong class="jp hj">均方误差(MSE) / L2损耗的平方根来计算。</strong>每个误差对RMSE的影响与误差平方的大小成正比。它<strong class="jp hj"> </strong>表示预测模型值和实际值之间偏差的第二个采样时刻的平方根。</p><figure class="ll lm ln lo fd ij er es paragraph-image"><div class="er es lt"><img src="../Images/b4a8260138e24753da8aa6962d610abc.png" data-original-src="https://miro.medium.com/v2/resize:fit:462/format:webp/0*m_KPLJZYJqZ0RSds.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">均方根误差</figcaption></figure><p id="324d" class="pw-post-body-paragraph jn jo hi jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj jf hb bi translated">更大的误差对RMSE的影响更大。这些偏差被称为误差。RMSE用于将不同时间的预测中的误差大小聚合到一个度量中。RMSE描述了模型的准确性，并有助于比较不同模型对特定数据集的预测误差。</p><p id="8140" class="pw-post-body-paragraph jn jo hi jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj jf hb bi translated">模型预测偏差符号对RMSE值没有影响，它总是非负的。RMSE的零值表明模型是100%准确的，但在实践中，这种情况从未发生过。对于模型优化，在实践中尽可能降低RMSE值。</p><p id="2bfc" class="pw-post-body-paragraph jn jo hi jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj jf hb bi translated">7.<strong class="jp hj">平均偏差误差(MBE) </strong></p><p id="938a" class="pw-post-body-paragraph jn jo hi jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj jf hb bi translated">平均偏差误差不经常作为损失函数用于任何机器模型。MBE主要用于计算机器学习模型中的平均偏差。虽然它在实践中不太准确，但它可以确定模型是有正偏差还是负偏差。</p><figure class="ll lm ln lo fd ij er es paragraph-image"><div class="er es lu"><img src="../Images/ec08e667ef3e3f8de3bbaa830b411091.png" data-original-src="https://miro.medium.com/v2/resize:fit:414/format:webp/1*CRUb2CrMkwg9aYh9Qel0uQ.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">平均偏差误差</figcaption></figure><p id="635d" class="pw-post-body-paragraph jn jo hi jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj jf hb bi translated">它有助于优化模型。它有助于决定是否需要考虑模型偏差的任何步骤。MBE的输出是预测中的平均偏差。MBE与MSE相同，唯一的区别是它不像MSE那样采用绝对值。MBE的正值表示价值被高估，负值表示价值被低估。</p><p id="656f" class="pw-post-body-paragraph jn jo hi jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj jf hb bi translated"><strong class="jp hj"> 8。胡贝尔损失</strong></p><p id="a7a4" class="pw-post-body-paragraph jn jo hi jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj jf hb bi translated">在统计学中，Huber损失可能是稳健回归中使用的损失函数，与平方误差损失相比，它对数据中的异常值不太敏感。有时还会使用分类的变体。Huber损耗结合了MSE和MAE的最简单特性。对于较小的误差，它是二次的，否则就是线性的(对于它的梯度也是如此)。它通过它的delta参数来识别。数学上定义如下:</p><figure class="ll lm ln lo fd ij er es paragraph-image"><div class="er es lv"><img src="../Images/d20c7ee8ba9569a55ee1bb3ddfbd0a70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1038/format:webp/1*uWggqE9iO2_8HM2TPd39AQ.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">胡伯损失</figcaption></figure><p id="8327" class="pw-post-body-paragraph jn jo hi jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj jf hb bi translated">也可以用0来区分。它是一个绝对误差，当误差很小时，它变成二次误差。超参数𝛿(δ)决定了误差必须有多小才能使其为二次误差。𝛿(德尔塔)也可以调整。当𝛿近似为零时，胡伯损失接近MAE，当𝛿近似为无穷大时，胡伯损失接近MSE(大数。)</p><h1 id="2846" class="lw kl hi bd km lx ly lz kq ma mb mc ku md me mf kx mg mh mi la mj mk ml ld mm bi translated">参考</h1><ol class=""><li id="0b61" class="mn mo hi jp b jq lf ju lg jy mp kc mq kg mr jf ms mt mu mv bi translated">AgriMetSoft (2019)。在线计算器。发售地点:【https://agrimetsoft.com/calculators/Mean%20Bias%20Error T4】</li><li id="1e5a" class="mn mo hi jp b jq mw ju mx jy my kc mz kg na jf ms mt mu mv bi translated"><a class="ae iu" rel="noopener" href="/@phuctrt/loss-functions-why-what-where-or-when-189815343d3f">https://medium . com/@ phu ctrt/loss-functions-why-what-where-when-189815343 d3f</a></li><li id="43cd" class="mn mo hi jp b jq mw ju mx jy my kc mz kg na jf ms mt mu mv bi translated"><a class="ae iu" href="https://towardsdatascience.com/common-loss-functions-in-machine-learning-46af0ffc4d23#:~:text=Broadly%2C%20loss%20functions%20can%20be,Regression%20losses%20and%20Classification%20losses." rel="noopener" target="_blank">https://towards data science . com/common-loss-functions-in-machine-learning-46 af 0 ffc 4d 23 #:~:text = Broadly % 2C % 20 loss % 20 functions % 20 can % 20 be，Regression % 20losses %和% 20Classification % 20losses。</a></li><li id="cbb0" class="mn mo hi jp b jq mw ju mx jy my kc mz kg na jf ms mt mu mv bi translated"><a class="ae iu" href="https://towardsdatascience.com/common-loss-functions-in-machine-learning-46af0ffc4d23" rel="noopener" target="_blank">https://towards data science . com/common-loss-functions-in-machine-learning-46 af 0 ffc 4d 23</a></li></ol><h1 id="8728" class="lw kl hi bd km lx ly lz kq ma mb mc ku md me mf kx mg mh mi la mj mk ml ld mm bi translated">注意</h1><p id="f5b5" class="pw-post-body-paragraph jn jo hi jp b jq lf js jt ju lg jw jx jy lh ka kb kc li ke kf kg lj ki kj jf hb bi translated">此外，如果你是机器学习的初学者，并且热衷于了解更多，那么你可以搜索GitHub帐户<strong class="jp hj"> sushantkumar-estech </strong>或者可以使用链接<a class="ae iu" href="https://github.com/sushantkumar-estech" rel="noopener ugc nofollow" target="_blank">https://github.com/sushantkumar-estech</a>来了解有趣的项目</p><p id="9bcc" class="pw-post-body-paragraph jn jo hi jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj jf hb bi translated">从你的练习愿望中选择任何项目，如果有任何问题，你可以写信给我。我很乐意帮忙。</p><p id="dc85" class="pw-post-body-paragraph jn jo hi jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj jf hb bi translated">享受阅读，快乐学习！！</p></div></div>    
</body>
</html>