<html>
<head>
<title>Artificial Neural Network(ANN) with Keras simplified, Use Case : if student pass the exam ?(Code part only)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">人工神经网络(ANN)与Keras简化，用例:如果学生通过考试？(仅代码部分)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/artificial-neural-network-ann-with-keras-simplified-use-case-if-student-pass-the-exam-code-949ddb2a9c91?source=collection_archive---------3-----------------------#2020-02-29">https://medium.com/analytics-vidhya/artificial-neural-network-ann-with-keras-simplified-use-case-if-student-pass-the-exam-code-949ddb2a9c91?source=collection_archive---------3-----------------------#2020-02-29</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/7722dd59d473d2cbb7b82dcd7f69d286.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*99gDbFIkyrAtlpnnMy0VHA.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">图片作者:<a class="ae iu" href="https://pixabay.com/users/Monoar-2240009/?utm_source=link-attribution&amp;amp;utm_medium=referral&amp;amp;utm_campaign=image&amp;amp;utm_content=1486278" rel="noopener ugc nofollow" target="_blank">单阿尔·拉赫曼·罗尼，皮查拜</a></figcaption></figure><p id="ed10" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">先决条件:<a class="ae iu" href="https://jupyter.org/" rel="noopener ugc nofollow" target="_blank"> Jupyter notebook </a>或<a class="ae iu" href="https://colab.research.google.com/notebooks/intro.ipynb" rel="noopener ugc nofollow" target="_blank"> Google Colab </a>或其他支持python的工具，现在我们有很多这样的工具。</p><h1 id="04f0" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">在战斗之前</h1><p id="9932" class="pw-post-body-paragraph iv iw hi ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated"><strong class="ix hj">数据集:</strong></p><figure class="kx ky kz la fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kw"><img src="../Images/bf87b64bebaeb74f31979afb2e23a023.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6yM2113wPI3lXQnS0nAYmg.png"/></div></div></figure><p id="bbf4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">大多数栏目都是不言自明的，其简单的学生数据涵盖了德里的三所学校:Kendriya Vidyalaya、Govt小学和Navodaya Vidyalaya</p><p id="5bc8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">PS: Vidyalaya在印地语中是学校的意思，其假想数据仅供参考😊</p><p id="16de" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">问题陈述:</strong></p><p id="db2b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">基于之前的记录，创建一个基于深度学习的预测器，它将帮助我们确定该学生今年是否有可能不及格，这样教师就可以将更多的注意力放在该学生群体上。</p><p id="2231" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">预读</strong></p><p id="4bb8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">ANN理论:<a class="ae iu" href="https://towardsdatascience.com/applied-deep-learning-part-1-artificial-neural-networks-d7834f67a4f6" rel="noopener" target="_blank">https://towards data science . com/applied-deep-learning-part-1-artificial-neural-networks-d 7834 f 67 a4f 6</a></p><p id="caf3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">克拉斯理论:<a class="ae iu" href="https://keras.io/" rel="noopener ugc nofollow" target="_blank">https://keras.io/</a></p><h2 id="31f6" class="lb ju hi bd jv lc ld le jz lf lg lh kd jg li lj kh jk lk ll kl jo lm ln kp lo bi translated">准备马匹</h2><p id="7be6" class="pw-post-body-paragraph iv iw hi ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">对于本文档中提到的任何库，都可以在您的机器/工具上获得，例如</p><pre class="kx ky kz la fd lp lq lr ls aw lt bi"><span id="c736" class="lb ju hi lq b fi lu lv l lw lx">Notebook<br/>! pip install keras </span><span id="c157" class="lb ju hi lq b fi ly lv l lw lx">Annaconda<br/>conda install -c conda-forge tensorflow</span></pre><h1 id="4da0" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">战役</h1><p id="6184" class="pw-post-body-paragraph iv iw hi ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated"><strong class="ix hj">特征预处理</strong></p><p id="38b4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">输入变量(X)和输出变量(y)，类似于</p><p id="99d2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> y = f(X) </strong></p><pre class="kx ky kz la fd lp lq lr ls aw lt bi"><span id="cf44" class="lb ju hi lq b fi lu lv l lw lx">X=df_all_student.iloc[:, 2:12]<br/>y=df_all_student.iloc[:, 12]</span></pre><p id="e8a5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们都知道所有的机器学习/深度学习(ML/DL)都是针对数字数据的，但“学校”和“性别”是文本数据，所以我们需要将文本数据编码为数字，我们知道sklearn会为我们完成这项工作</p><figure class="kx ky kz la fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lz"><img src="../Images/0e9b39976e364e65b02d9bd615808853.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XsplfNVGio-MerVvxPzTQA.png"/></div></div></figure><p id="c7fa" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">你可以看到“学校”和“性别”现在都是数字，但我们陷入了新的问题。基于数值，如果我们有一些不真实的顺序或层次，这很容易混淆我们的模型。这里的“OneHotEncoder”将帮助我们将一列拆分为多列。数字由1和0代替，这取决于哪一列有什么值。</p><p id="1ccc" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">正如您在构造函数中看到的，我们指定哪一列必须是热编码的，在本例中为[1]。</p><figure class="kx ky kz la fd ij er es paragraph-image"><div class="er es ma"><img src="../Images/e10bfa0e5512748f53e7a9277a8c53d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1304/format:webp/1*vQ5o_XwGPOSsZno0yt4u0A.png"/></div></figure><p id="12f4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在我们可能会陷入“虚拟变量陷阱”,即独立变量是多重共线的——两个或更多变量高度相关。解决方案:只需删除一个变量，如</p><p id="e5fa" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><code class="du mb mc md lq b">X = X[:, 1:]</code></p><p id="99c5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，所有数据都已设置好，因此我们可以拆分训练和测试数据集</p><pre class="kx ky kz la fd lp lq lr ls aw lt bi"><span id="55dc" class="lb ju hi lq b fi lu lv l lw lx">from sklearn.model_selection import train_test_split<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)</span></pre><p id="9435" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">80%训练，20 %测试，提及random_state意味着每次训练和测试数据都相同，如果不提及random_state，则下一次运行将不是确定性的或不同的。</p><p id="4aa9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在正常的ML生命周期中，我们将数据标准化或规范化，因此大多数数据都在相同的范围内</p><pre class="kx ky kz la fd lp lq lr ls aw lt bi"><span id="1958" class="lb ju hi lq b fi lu lv l lw lx">from sklearn.preprocessing import StandardScaler<br/>sc = StandardScaler()<br/>X_train = sc.fit_transform(X_train)<br/>X_test = sc.transform(X_test)</span></pre><p id="b0b0" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">安在行动</strong></p><p id="56dd" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这是一件艺术的事情，你需要创建第一个人工神经网络模式/图形，然后超调。没有公式，大多数事情都是反复试验。我们只有一些建议，其余的一切都是艺术。</p><p id="0092" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">初始化基本的Keras顺序模型(每一层的输出都是我们实现的下一层的输入)</p><pre class="kx ky kz la fd lp lq lr ls aw lt bi"><span id="8017" class="lb ju hi lq b fi lu lv l lw lx">import keras<br/>from keras.models import Sequential <br/>cf = Sequential()</span></pre><p id="0950" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">添加第一个输入层和第一个隐藏层</strong></p><pre class="kx ky kz la fd lp lq lr ls aw lt bi"><span id="1fa3" class="lb ju hi lq b fi lu lv l lw lx">from keras.layers import Dense</span><span id="3744" class="lb ju hi lq b fi ly lv l lw lx">cf.add(Dense(units = 6, kernel_initializer = ‘uniform’, activation = ‘relu’, input_dim = 11))</span></pre><p id="ea80" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">密集:</strong>以顺序模式完全连接层，实现方程<code class="du mb mc md lq b">output = activation(dot(input, kernel) + bias)</code></p><p id="c989" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这意味着我们取输入张量和稠密层中的任何权重核矩阵之间的点积。</p><p id="578e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">参数:</strong></p><p id="3e3e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">单位:表示该层的输出大小，通常输入层节点数(自变量数)的平均值为11，输出层节点数的平均值为1，我们取6作为平均值。</p><p id="b66f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">Kernel_initializer :初始化器参数告诉Keras如何初始化我们的层、权重矩阵和偏置向量的值</p><p id="da58" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">激活:</strong>用于密集层的元素激活函数。阅读更多关于整流线性单元(ReLU)的信息</p><p id="b681" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> Input_dim: </strong>仅用于第一层，输入自变量的数量。仅用于第一个隐藏层</p><p id="d5b5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">偏差:</strong>如果我们要提前实施</p><p id="2dde" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">辍学</strong></p><p id="0075" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为了避免过度拟合，dropout是一种在训练期间忽略随机选择的神经元的技术</p><pre class="kx ky kz la fd lp lq lr ls aw lt bi"><span id="63cb" class="lb ju hi lq b fi lu lv l lw lx">cf.add(Dropout(rate = 0.1))</span></pre><p id="2e05" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这里我们随机丢弃了10%的神经元</p><p id="b16c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">中间层和最后一层</strong></p><pre class="kx ky kz la fd lp lq lr ls aw lt bi"><span id="c5e8" class="lb ju hi lq b fi lu lv l lw lx">cf.add(Dense(units = 6, kernel_initializer = ‘uniform’, activation = ‘relu’))<br/>cf.add(Dropout(rate = 0.1))<br/>cf.add(Dense(units = 1, kernel_initializer = ‘uniform’, activation = ‘sigmoid’))</span></pre><p id="654f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">最后一层激活功能与前一层不同。这里通常使用“sigmoid”表示布尔型，使用“softmax”表示多类。</p><p id="d585" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">形象化</strong></p><pre class="kx ky kz la fd lp lq lr ls aw lt bi"><span id="a060" class="lb ju hi lq b fi lu lv l lw lx">from ann_visualizer.visualize import ann_viz;<br/>ann_viz(network, title="");</span></pre><p id="8770" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">pdf将像这样打开</p><figure class="kx ky kz la fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es me"><img src="../Images/b1df5c3c80cadb93fb30e33d45a7f419.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kRsyJAJZ_nK_eRulbfWleA.png"/></div></div></figure><p id="9c57" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">编译</strong></p><pre class="kx ky kz la fd lp lq lr ls aw lt bi"><span id="dadf" class="lb ju hi lq b fi lu lv l lw lx">cf.compile(optimizer = ‘adam’, loss = ‘binary_crossentropy’, metrics = [‘accuracy’])</span></pre><p id="a23a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">您需要配置学习过程</p><ul class=""><li id="eedb" class="mf mg hi ix b iy iz jc jd jg mh jk mi jo mj js mk ml mm mn bi translated"><strong class="ix hj">优化器</strong>:更新权重参数以最小化损失函数..</li><li id="9eed" class="mf mg hi ix b iy mo jc mp jg mq jk mr jo ms js mk ml mm mn bi translated"><strong class="ix hj">损失函数</strong>:作为地形的向导，告诉<strong class="ix hj">优化器</strong>它是否在向正确的方向移动，以到达谷底，即全局最小值。</li><li id="334b" class="mf mg hi ix b iy mo jc mp jg mq jk mr jo ms js mk ml mm mn bi translated"><strong class="ix hj">度量</strong>:度量函数类似于损失，除了在训练模型时不使用评估度量的结果。</li></ul><p id="9131" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">Keras为每个参数提供了多个现有选项，也有人可以覆盖它</p><p id="7740" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">配合</strong></p><pre class="kx ky kz la fd lp lq lr ls aw lt bi"><span id="c59c" class="lb ju hi lq b fi lu lv l lw lx">cf.fit(X_train, y_train, batch_size = 10, epochs = 100)</span></pre><p id="8da0" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">基于分类器的实际训练，</p><p id="f9f6" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">批量:与样本相关的超参数</p><p id="1ef7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">时期:与迭代相关的超参数</p><p id="7f16" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">更多详情:<a class="ae iu" href="https://keras.io/models/sequential/" rel="noopener ugc nofollow" target="_blank">https://keras.io/models/sequential/</a></p><p id="5c6c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">你会得到这种类型的结果，这个数据集不是真实的，所以得到这个精度😁😁</p><pre class="kx ky kz la fd lp lq lr ls aw lt bi"><span id="604b" class="lb ju hi lq b fi lu lv l lw lx">Epoch 99/100<br/>8000/8000 [==============================] - 2s 221us/step - loss: 0.6898 - accuracy: 0.5375<br/>Epoch 100/100<br/>8000/8000 [==============================] - 2s 225us/step - loss: 0.6900 - accuracy: 0.5381</span></pre><p id="8638" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">测试结果预测</strong></p><pre class="kx ky kz la fd lp lq lr ls aw lt bi"><span id="a8cf" class="lb ju hi lq b fi lu lv l lw lx">y_prediction =cf.predict(X_test)</span></pre><p id="9204" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">您可以像这样获得任何特定的学生预测cf.predict(X_test[0:1，:])或传递相同的形状和规范化数组来获得新的学生预测。</p><h1 id="0207" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">交互效度分析</h1><p id="6b6e" class="pw-post-body-paragraph iv iw hi ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated"><strong class="ix hj"> k </strong> - <strong class="ix hj">叠交</strong> - <strong class="ix hj">验证</strong></p><p id="ccb2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们的模型测试和训练数据可能有偏差，因此交叉验证技术用于更好的模型性能测量。在K-fold中，是指数据集被随机分成'<strong class="ix hj"> k </strong>'个组。其中一组用作测试集，其余的用作训练集。</p><pre class="kx ky kz la fd lp lq lr ls aw lt bi"><span id="0d96" class="lb ju hi lq b fi lu lv l lw lx">from keras.wrappers.scikit_learn import KerasClassifier<br/>from sklearn.model_selection import cross_val_score<br/>def kera_classifier():<br/> cf = Sequential()<br/> cf.add(Dense(units = 6, kernel_initializer = ‘uniform’, activation = ‘relu’, input_dim = 11))<br/> cf.add(Dense(units = 6, kernel_initializer = ‘uniform’, activation = ‘relu’))<br/> cf.add(Dense(units = 1, kernel_initializer = ‘uniform’, activation = ‘sigmoid’))<br/> cf.compile(optimizer = ‘adam’, loss = ‘binary_crossentropy’, metrics = [‘accuracy’])<br/> return cf<br/>cf = KerasClassifier(build_fn = kera_classifier, batch_size = 10, epochs = 100)<br/>accuracies = cross_val_score(estimator = cf, X = X_train, y = y_train, cv = 10, n_jobs = -1)<br/>mean = accuracies.mean()<br/>variance = accuracies.std()</span></pre><p id="bba6" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">相同的代码，但是使用了sklearn来使用它的功能进行k倍验证</p><p id="bcfd" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">网格搜索交叉验证</strong></p><p id="8fd1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">使用它，您可以自动进行超调，就像您将提供多个优化器、时期、批量大小组合，它将自动从它们中创建所有排列，运行它们中的每一个，并最终向您显示最终的最佳参数，您可以将它用于您的最终生产项目。这将减少大量人工时间，以及机器学习中的自动化</p><pre class="kx ky kz la fd lp lq lr ls aw lt bi"><span id="959e" class="lb ju hi lq b fi lu lv l lw lx">from keras.wrappers.scikit_learn import KerasClassifier<br/>from sklearn.model_selection import GridSearchCV<br/>def kera_classifier(optimizer):<br/> cf = Sequential()<br/> cf.add(Dense(units = 6, kernel_initializer = ‘uniform’, activation = ‘relu’, input_dim = 11))<br/> cf.add(Dense(units = 6, kernel_initializer = ‘uniform’, activation = ‘relu’))<br/> cf.add(Dense(units = 1, kernel_initializer = ‘uniform’, activation = ‘sigmoid’))<br/> cf.compile(optimizer = optimizer, loss = ‘binary_crossentropy’, metrics = [‘accuracy’])<br/> return cf<br/>cf = KerasClassifier(build_fn = kera_classifier)<br/>parameters = {‘batch_size’: [10, 15],<br/> ‘epochs’: [10, 50],<br/> ‘optimizer’: [‘adam’, ‘rmsprop’]}<br/>gv_search = GridSearchCV(estimator = cf,<br/> param_grid = parameters,<br/> scoring = ‘accuracy’,<br/> cv = 10)<br/>gv_search = gv_search.fit(X_train, y_train)<br/>best_param = gv_search.best_params_<br/>best_acc = gv_search.best_score_</span></pre><p id="12be" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">完整的解决方案可从以下网址获得:<a class="ae iu" href="https://github.com/jaiswalvineet/Artificial-Neural-Network-ANN-with-Keras-simplified/upload" rel="noopener ugc nofollow" target="_blank">https://github . com/jaiswalvinet/Artificial-Neural-Network-ANN-with-Keras-simplified/upload</a></p><p id="b6cd" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，我们可以托管模型，并发现学生是否有可能不及格，然后我们就知道下一步该怎么做了…</p><p id="0b09" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="mt">我尽量做到准确，但是如果您发现任何问题，请告诉我。</em></p><p id="905d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">享受学习！！！</p></div></div>    
</body>
</html>