<html>
<head>
<title>Demystifying LSTM Weights and Bias Dimensions.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">揭开LSTM权重和偏差维度的神秘面纱。</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/demystifying-lstm-weights-and-biases-dimensions-c47dbd39b30a?source=collection_archive---------1-----------------------#2020-03-04">https://medium.com/analytics-vidhya/demystifying-lstm-weights-and-biases-dimensions-c47dbd39b30a?source=collection_archive---------1-----------------------#2020-03-04</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/2fd00e7d3453e4afe4c6aa16edab839a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*-5nnkN5ak0afJi1C"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">沃洛季米尔·赫里先科在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure></div><div class="ab cl iv iw gp ix" role="separator"><span class="iy bw bk iz ja jb"/><span class="iy bw bk iz ja jb"/><span class="iy bw bk iz ja"/></div><div class="hb hc hd he hf"><p id="58d0" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">LSTM(长短期记忆)是递归神经网络结构(RNNs)的变体。LSTM解决了反向传播过程中梯度消失和爆炸的问题。这是通过使用存储单元来实现的。在本帖中，我们将讨论LSTM单元的重量和偏差尺寸。了解LSTM，可以参考这里的<a class="ae iu" rel="noopener" href="/mlreview/understanding-lstm-and-its-diagrams-37e2f46f1714">这里的</a>或者<a class="ae iu" href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/" rel="noopener ugc nofollow" target="_blank">这里的</a>。</p><h1 id="03b1" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">LSTM建筑</h1><figure class="kz la lb lc fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ky"><img src="../Images/b575969453ffe180666693052838f77e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ON1CokEAHaIryJTIyWgbKw.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">图1: LSTM细胞</figcaption></figure><p id="a6af" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">在LSTM图中，我们可以看到我们有8个不同的权重参数(4个与隐藏状态(单元状态)相关，4个与输入向量相关)。我们还有4个不同的偏置参数。为了更好地理解这一点，我们可以使用下面的等式，并更好地理解LSTM单元中的操作。</p><figure class="kz la lb lc fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ld"><img src="../Images/88d8fd03e242698d0fc67ad31d9eb9a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y-RI3y90IZpOUMnkCBrQxQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">图2: LSTM方程</figcaption></figure><p id="f645" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">在这里，借助上面的等式，我们可以清楚地看到总共有4个偏差和8个权重。我们举个例子。</p><pre class="kz la lb lc fd le lf lg lh aw li bi"><span id="20cd" class="lj kb hi lf b fi lk ll l lm ln">Seq_len of the input sentence (S)= 12<br/>embedding dimension (E)= 30<br/>No of LSTM cells (hidden units) (H)= 10<br/>Batch_size (B) = 1</span></pre><p id="faab" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">输入(x)将是批量大小*嵌入尺寸= B*D <br/>先前的隐藏状态将是批量大小*隐藏单元= B*H</p><pre class="kz la lb lc fd le lf lg lh aw li bi"><span id="8144" class="lj kb hi lf b fi lk ll l lm ln">Equation 1: forget gate = [(1*10).(10*10)+(1*30).(30*10) + (1*10)]<br/>= (1*10) = (B*H)</span><span id="c57e" class="lj kb hi lf b fi lo ll l lm ln">Equation 2: update gate = [(1*10).(10*10)+(1*30).(30*10) + (1*10)]<br/>= (1*10) = (B*H)</span><span id="e1b3" class="lj kb hi lf b fi lo ll l lm ln">Equation 3: candidate memory=[(1*10).(10*10)+(1*30).(30*10)+(1*10)]<br/>= (1*10) = (B*H)</span><span id="97f2" class="lj kb hi lf b fi lo ll l lm ln">Equation 4: output gate =[(1*10).(10*10)+(1*30).(30*10) + (1*10)]<br/>= (1*10) = (B*H)</span></pre><p id="0012" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">由于所有权重遵循相同的结构，因此可以将这些权重组合在一起，然后乘以各自的输出。与隐藏状态相关联的权重被称为核权重，与输入相关联的权重被称为递归核权重。</p><p id="9787" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated"><strong class="je hj">注:</strong> <br/> 1。因为LSTM按顺序处理数据。它将一次接收一个字，并且同一个LSTM单元将接收下一个后续字。LSTM细胞的数量并不意味着LSTM多次重复。这意味着它可以展开到序列长度。在实际的LSTM细胞中，同一个细胞将一个接一个地接收所有的字。<br/> 2。序列长度对权重和偏差维度没有任何影响。从上面的计算中可以清楚的看到。<br/> 3。权重是通过权重的转置来相乘的，但是为了简化，这里我重新安排了权重和输入。</p><p id="920e" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">为了查看所有的权重和偏差维度，我已经将它们放在一个表格中，并根据等式相应地命名它们。</p><figure class="kz la lb lc fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lp"><img src="../Images/74e9368bfb22829e0e4b6c836ff92928.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9D4jR_ClROAv-awpm41iCQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">图3:LSTM每个参数的尺寸</figcaption></figure><h2 id="78f1" class="lj kb hi bd kc lq lr ls kg lt lu lv kk jn lw lx ko jr ly lz ks jv ma mb kw mc bi translated">请比较Tensorflow实现</h2><p id="ed4e" class="pw-post-body-paragraph jc jd hi je b jf md jh ji jj me jl jm jn mf jp jq jr mg jt ju jv mh jx jy jz hb bi translated">在下面的代码片段中，我实现了两个LSTM层。第一个我们已经讨论过了，下面的结果只适用于第一个LSTM层。你可以用第二层LSTM来验证你的理解。家庭作业:P</p><figure class="kz la lb lc fd ij"><div class="bz dy l di"><div class="mi mj l"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">图Tensorflow中LSTM的代码片段</figcaption></figure><figure class="kz la lb lc fd ij er es paragraph-image"><div class="er es mk"><img src="../Images/c8aa0489b6ce16a67f8372b15f7ab4e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1310/format:webp/1*0TIkG-sqkwief295vJ-lqw.png"/></div></figure><figure class="kz la lb lc fd ij er es paragraph-image"><div class="er es ml"><img src="../Images/b416501a8648e06acf1c11435211d4bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:694/format:webp/1*xK4n1Ec5aoop81MfG_nM_g.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">图5:代码片段的输出</figcaption></figure><p id="41d3" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">在这里，我们可以清楚地看到，每个权重和偏差都有相同的维度。所以，现在我们也可以很容易地联系到计算LSTM晶胞中参数个数的公式，即</p><p id="5d6b" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated"><strong class="je hj">参数个数= 4×[<em class="mm">h</em>(<em class="mm">h</em>+e)+<em class="mm">h</em>]= 4(10(10+30)+10)= 1640。<br/> </strong>其中h = LSTM隐藏单元的数量<br/>，e =输入的嵌入维数</p><h2 id="b86b" class="lj kb hi bd kc lq lr ls kg lt lu lv kk jn lw lx ko jr ly lz ks jv ma mb kw mc bi translated">参考资料:</h2><div class="mn mo ez fb mp mq"><a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/" rel="noopener  ugc nofollow" target="_blank"><div class="mr ab dw"><div class="ms ab mt cl cj mu"><h2 class="bd hj fi z dy mv ea eb mw ed ef hh bi translated">了解LSTM网络</h2><div class="mx l"><h3 class="bd b fi z dy mv ea eb mw ed ef dx translated">2015年8月27日发布人类不是每秒钟都从零开始思考。当你读这篇文章时，你…</h3></div><div class="my l"><p class="bd b fp z dy mv ea eb mw ed ef dx translated">colah.github.io</p></div></div></div></a></div><div class="mn mo ez fb mp mq"><a rel="noopener follow" target="_blank" href="/mlreview/understanding-lstm-and-its-diagrams-37e2f46f1714"><div class="mr ab dw"><div class="ms ab mt cl cj mu"><h2 class="bd hj fi z dy mv ea eb mw ed ef hh bi translated">理解LSTM及其图表</h2><div class="mx l"><h3 class="bd b fi z dy mv ea eb mw ed ef dx translated">我只想重申这里所说的:</h3></div><div class="my l"><p class="bd b fp z dy mv ea eb mw ed ef dx translated">medium.com</p></div></div><div class="mz l"><div class="na l nb nc nd mz ne io mq"/></div></div></a></div><p id="3a62" class="pw-post-body-paragraph jc jd hi je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">我希望你喜欢这篇短文。跟着我上<a class="ae iu" href="https://github.com/gskdhiman" rel="noopener ugc nofollow" target="_blank"> GitHub </a>和<a class="ae iu" href="https://www.kaggle.com/gskdhiman" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>。请随时到gskdhiman@gmail.com找我。非常欢迎对这篇文章的任何改进提出建议。</p></div></div>    
</body>
</html>