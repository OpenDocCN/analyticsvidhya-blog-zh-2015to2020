<html>
<head>
<title>A Practical Introduction to K-Nearest Neighbors Algorithm for Regression (with Python code)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">回归的K-最近邻算法实用介绍(带Python代码)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/a-practical-introduction-to-k-nearest-neighbors-algorithm-for-regression-with-python-code-a81223eb6ad?source=collection_archive---------3-----------------------#2018-08-22">https://medium.com/analytics-vidhya/a-practical-introduction-to-k-nearest-neighbors-algorithm-for-regression-with-python-code-a81223eb6ad?source=collection_archive---------3-----------------------#2018-08-22</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="8349" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在我遇到的所有机器学习算法中，KNN无疑是最容易上手的。尽管它很简单，但它被证明在某些任务中非常有效(正如您将在本文中看到的)。</p><p id="8228" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">甚至更好？分类和回归问题都可以用！然而，它更常用于分类问题。我很少在任何回归任务中看到KNN的实现。我在这里的目的是说明并强调当目标变量本质上是连续的时，KNN是如何同样有效的。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/57c0676cf11a22ec6019257d640bd839.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*e6M8pWwFZ_FF9Fz6.png"/></div></div></figure><p id="86af" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本文中，我们将首先了解KNN算法背后的直觉，看看计算点之间距离的不同方法，然后最终在Big Mart销售数据集上用Python实现该算法。我们走吧！</p><h1 id="ab80" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">目录</h1><ol class=""><li id="55d1" class="kn ko hi ih b ii kp im kq iq kr iu ks iy kt jc ku kv kw kx bi translated">一个简单的例子来理解KNN背后的直觉</li><li id="7661" class="kn ko hi ih b ii ky im kz iq la iu lb iy lc jc ku kv kw kx bi translated">KNN算法是如何工作的？</li><li id="c5db" class="kn ko hi ih b ii ky im kz iq la iu lb iy lc jc ku kv kw kx bi translated">计算两点间距离的方法</li><li id="3813" class="kn ko hi ih b ii ky im kz iq la iu lb iy lc jc ku kv kw kx bi translated">k因子怎么选？</li><li id="c987" class="kn ko hi ih b ii ky im kz iq la iu lb iy lc jc ku kv kw kx bi translated">处理数据集</li><li id="90b6" class="kn ko hi ih b ii ky im kz iq la iu lb iy lc jc ku kv kw kx bi translated">额外资源</li></ol><h1 id="d641" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">1.一个简单的例子来理解KNN背后的直觉</h1><p id="9ce5" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq ld is it iu le iw ix iy lf ja jb jc hb bi translated">让我们从一个简单的例子开始。考虑下表—它包含10个人的身高、年龄和体重(目标)值。如你所见，ID11的重量值丢失了。我们需要根据身高和年龄来预测这个人的体重。</p><p id="006c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="lg">注:本表数据不代表实际值。这仅仅是作为一个例子来解释这个概念。</em></p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lh"><img src="../Images/580df52800b56d1313ae4f0782468b5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*i-kfTeRIkqSc2E4p.png"/></div></div></figure><p id="67b6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了更清楚地理解这一点，下面是上表中身高与年龄的关系图:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es li"><img src="../Images/16615869a2047731ae5bf232271b0cd8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1284/format:webp/0*hT4QzGmkC0IAK37a.png"/></div></figure><p id="89d9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在上图中，y轴代表人的身高(以英尺为单位)，x轴代表年龄(以岁为单位)。这些点根据ID值进行编号。黄点(ID 11)是我们的测试点。</p><p id="1948" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果我让你根据剧情来确定ID11的重量，你会怎么回答？你可能会说，因为ID11的<strong class="ih hj">更靠近点5和1的</strong>，所以它的重量必须与这些ID相似，可能在72-77千克之间(表中ID1和ID5的重量)。这实际上是有道理的，但是你认为算法如何预测这些值呢？我们将在本文中找到答案。</p><h1 id="ef19" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">2.KNN算法是如何工作的？</h1><p id="a94d" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq ld is it iu le iw ix iy lf ja jb jc hb bi translated">正如我们在上面看到的，KNN可以用于分类和回归问题。该算法使用“<strong class="ih hj">特征相似度</strong>来预测任何新数据点的值。这意味着根据新点与训练集中的点的相似程度为其赋值。从我们的示例中，我们知道ID11的身高和年龄与ID1和ID5相似，因此体重也大致相同。</p><p id="5531" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果这是一个分类问题，我们会把模式作为最终的预测。在这种情况下，我们有两个权重值— 72和77。任何猜测最终值将如何计算？取这些值的平均值作为最终预测值。</p><p id="d48e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面是该算法的逐步解释:</p><ol class=""><li id="ddd3" class="kn ko hi ih b ii ij im in iq lj iu lk iy ll jc ku kv kw kx bi translated">首先，计算新点和每个训练点之间的距离。</li></ol><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lm"><img src="../Images/9f315ac47d26538d15a59a761adcb54a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1288/format:webp/0*Dxu4yRBk6lhjsMYA.png"/></div></figure><p id="bad5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.选择最近的k个数据点(基于距离)。在本例中，如果k值为3，将选择点1、5、6。在本文的后面，我们将进一步探讨选择正确的k值的方法。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ln"><img src="../Images/a7f7b4aa8c6a8d7f66377e6ba50805f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/0*5tPCdlvBfOoTU8Ed.png"/></div></figure><p id="dac5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">3.这些数据点的平均值是新点的最终预测值。在这里，我们的重量为ID11 = (77+72+60)/3 = 69.66千克。</p><p id="2093" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在接下来的几节中，我们将详细讨论这三个步骤。</p><h1 id="3bce" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">3.计算两点间距离的方法</h1><p id="5752" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq ld is it iu le iw ix iy lf ja jb jc hb bi translated"><strong class="ih hj">第一步</strong>是计算新点和每个训练点之间的距离。计算这种距离有各种方法，其中最常见的方法是欧几里德距离、曼哈顿距离(用于连续)和汉明距离(用于分类)。</p><ol class=""><li id="791d" class="kn ko hi ih b ii ij im in iq lj iu lk iy ll jc ku kv kw kx bi translated"><strong class="ih hj">欧几里德距离:</strong>欧几里德距离的计算方法是新点(x)和现有点(y)的平方差之和的平方根。</li><li id="361f" class="kn ko hi ih b ii ky im kz iq la iu lb iy lc jc ku kv kw kx bi translated"><strong class="ih hj">曼哈顿距离</strong>:这是使用绝对差之和的真实向量之间的距离。</li></ol><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lo"><img src="../Images/28f488ac2fe0ee0fdb68f8473bc6ac2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*wOwi97zXhzMiAivU.png"/></div></figure><p id="1c1e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 3。汉明距离</strong>:用于分类变量。如果预测值(x)和实际值(y)相同，距离D将等于0。否则D=1。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lp"><img src="../Images/821ab22705beea9c530994319c4455da.png" data-original-src="https://miro.medium.com/v2/resize:fit:432/format:webp/0*Pul2DpSRLvtV5nCe.png"/></div></figure><p id="6c20" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一旦一个新的观察距离我们的训练集中的点的距离已经被测量，下一步是挑选最近的点。要考虑的点数由k值确定。</p><h1 id="cbe6" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">4.k因子怎么选？</h1><p id="2f69" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq ld is it iu le iw ix iy lf ja jb jc hb bi translated"><strong class="ih hj">第二步</strong>是选择k值。这决定了我们在为任何新观察值赋值时要查看的相邻要素的数量。</p><p id="f6bd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在我们的例子中，对于k = 3的值，最接近的点是ID1、ID5和ID6。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ln"><img src="../Images/d041be98296c0bef97b392c8190fda59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/0*GAXme4tIUHNKsZaU.png"/></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lq"><img src="../Images/36fc508fe9bbb09de252333fcd1a8a3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:672/format:webp/0*pbqyIWzSJXTYr_F1.png"/></div></figure><p id="54f7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">ID11的重量预测为:</p><pre class="je jf jg jh fd lr ls lt lu aw lv bi"><span id="776d" class="lw jq hi ls b fi lx ly l lz ma">ID11 = (77+72+60)/3 </span><span id="615c" class="lw jq hi ls b fi mb ly l lz ma">ID11 = 69.66 kg</span></pre><p id="4b64" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于k=5的值，最接近的点将是ID1、ID4、ID5、ID6、ID10。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mc"><img src="../Images/e385c73571c839f3d39c5786a71212af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1334/format:webp/0*68UH2idXm1fdFCyt.png"/></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es md"><img src="../Images/cd97c4c4e76713d07eb7358a1fc04802.png" data-original-src="https://miro.medium.com/v2/resize:fit:694/format:webp/0*PAcwRcKFhK752hJx.png"/></div></figure><p id="9cb6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对ID11的预测是:</p><pre class="je jf jg jh fd lr ls lt lu aw lv bi"><span id="556c" class="lw jq hi ls b fi lx ly l lz ma">ID 11 =  (77+59+72+60+58)/5  </span><span id="31fe" class="lw jq hi ls b fi mb ly l lz ma">ID 11 = 65.2 kg</span></pre><p id="effb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们注意到，基于k值，最终结果往往会发生变化。那怎么才能算出k的最优值呢？让我们基于我们的训练和验证集的误差计算来决定它(毕竟，最小化误差是我们的最终目标！).</p><p id="4a3a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">看看下面不同k值的训练误差和验证误差的图表。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es me"><img src="../Images/928c0cb89cee88560c403a5af2a5a7fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*yXWagQwH6odA8bbN.png"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mf"><img src="../Images/2eb378d7fa8b15329b11f33197c76808.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*FXt__XphYpZZ_bHo.png"/></div></div></figure><p id="8136" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于非常低的k值(假设k=1)，模型过拟合训练数据，这导致验证集的错误率很高。另一方面，对于较高的k值，模型在训练集和验证集上都表现不佳。如果你仔细观察，验证误差曲线在k = 9时达到最小值。这个k值是模型的最佳值(它将因不同的数据集而异)。这条曲线被称为“<strong class="ih hj">肘形曲线</strong>”(因为它的形状像肘)，通常用于确定k值。</p><p id="6fc1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">您还可以使用网格搜索技术来查找最佳k值。我们将在下一节中实现这一点。</p><h1 id="951e" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">5.处理数据集(Python代码)</h1><p id="741d" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq ld is it iu le iw ix iy lf ja jb jc hb bi translated">到目前为止，您必须对算法有一个清晰的理解。如果你对此有任何问题，请在下面的评论区留言，我很乐意回答。我们现在将继续在数据集上实现该算法。我已经使用了Big Mart销售数据集来展示这个实现，你可以从<a class="ae mg" href="https://datahack.analyticsvidhya.com/contest/practice-problem-big-mart-sales-iii/" rel="noopener ugc nofollow" target="_blank">这个链接</a>下载。</p><p id="53c0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 1。读取文件</strong></p><pre class="je jf jg jh fd lr ls lt lu aw lv bi"><span id="78a7" class="lw jq hi ls b fi lx ly l lz ma">import pandas as pd <br/>df = pd.read_csv('train.csv') <br/>df.head()</span></pre><p id="d533" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 2。估算缺失值</strong></p><pre class="je jf jg jh fd lr ls lt lu aw lv bi"><span id="9580" class="lw jq hi ls b fi lx ly l lz ma">df.isnull().sum() <br/>#missing values in Item_weight and Outlet_size needs to be imputed</span><span id="1903" class="lw jq hi ls b fi mb ly l lz ma">mean = df['Item_Weight'].mean() #imputing item_weight with mean df['Item_Weight'].fillna(mean, inplace =True) <br/>mode = df['Outlet_Size'].mode() #imputing outlet size with mode <br/>df['Outlet_Size'].fillna(mode[0], inplace =True)</span></pre><p id="4b33" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 3。处理分类变量并删除id列</strong></p><pre class="je jf jg jh fd lr ls lt lu aw lv bi"><span id="5bc1" class="lw jq hi ls b fi lx ly l lz ma">df.drop(['Item_Identifier', 'Outlet_Identifier'], axis=1, inplace=True) </span><span id="e031" class="lw jq hi ls b fi mb ly l lz ma">df = pd.get_dummies(df)</span></pre><p id="b7c9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 4。创建训练和测试集</strong></p><pre class="je jf jg jh fd lr ls lt lu aw lv bi"><span id="b0ed" class="lw jq hi ls b fi lx ly l lz ma">from sklearn.model_selection import train_test_split <br/>train , test = train_test_split(df, test_size = 0.3) </span><span id="dcaa" class="lw jq hi ls b fi mb ly l lz ma">x_train = train.drop('Item_Outlet_Sales', axis=1) <br/>y_train = train['Item_Outlet_Sales'] </span><span id="51ba" class="lw jq hi ls b fi mb ly l lz ma">x_test = test.drop('Item_Outlet_Sales', axis = 1) <br/>y_test = test['Item_Outlet_Sales']</span></pre><p id="45d7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 5。预处理——缩放特征</strong></p><pre class="je jf jg jh fd lr ls lt lu aw lv bi"><span id="12c8" class="lw jq hi ls b fi lx ly l lz ma">from sklearn.preprocessing import MinMaxScaler<br/>scaler = MinMaxScaler(feature_range=(0, 1))<br/><br/>x_train_scaled = scaler.fit_transform(x_train)<br/>x_train = pd.DataFrame(x_train_scaled)<br/><br/>x_test_scaled = scaler.fit_transform(x_test)<br/>x_test = pd.DataFrame(x_test_scaled)</span></pre><p id="8e3c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 6。让我们看看不同k值的错误率</strong></p><pre class="je jf jg jh fd lr ls lt lu aw lv bi"><span id="35c3" class="lw jq hi ls b fi lx ly l lz ma">#import required packages<br/>from sklearn import neighbors<br/>from sklearn.metrics import mean_squared_error <br/>from math import sqrt<br/>import matplotlib.pyplot as plt<br/>%matplotlib inline</span><span id="2bcb" class="lw jq hi ls b fi mb ly l lz ma">rmse_val = [] #to store rmse values for different k<br/>for K in range(20):<br/>    K = K+1<br/>    model = neighbors.KNeighborsRegressor(n_neighbors = K)<br/><br/>    model.fit(x_train, y_train)  #fit the model<br/>    pred=model.predict(x_test) #make prediction on test set<br/>    error = sqrt(mean_squared_error(y_test,pred)) #calculate rmse<br/>    rmse_val.append(error) #store rmse values<br/>    print('RMSE value for k= ' , K , 'is:', error)</span></pre><p id="2813" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">输出:</p><pre class="je jf jg jh fd lr ls lt lu aw lv bi"><span id="5045" class="lw jq hi ls b fi lx ly l lz ma">RMSE value for k = 1 is: 1579.8352322344945<br/>RMSE value for k = 2 is: 1362.7748806138618<br/>RMSE value for k = 3 is: 1278.868577489459<br/>RMSE value for k = 4 is: 1249.338516122638<br/>RMSE value for k = 5 is: 1235.4514224035129<br/>RMSE value for k = 6 is: 1233.2711649472913<br/>RMSE value for k = 7 is: 1219.0633086651026<br/>RMSE value for k = 8 is: 1222.244674933665<br/>RMSE value for k = 9 is: 1219.5895059285074<br/>RMSE value for k = 10 is: 1225.106137547365<br/>RMSE value for k = 11 is: 1229.540283771085<br/>RMSE value for k = 12 is: 1239.1504407152086<br/>RMSE value for k = 13 is: 1242.3726040709887<br/>RMSE value for k = 14 is: 1251.505810196545<br/>RMSE value for k = 15 is: 1253.190119191363<br/>RMSE value for k = 16 is: 1258.802262564038<br/>RMSE value for k = 17 is: 1260.884931441893<br/>RMSE value for k = 18 is: 1265.5133661294733<br/>RMSE value for k = 19 is: 1269.619416217394<br/>RMSE value for k = 20 is: 1272.10881411344</span><span id="bd75" class="lw jq hi ls b fi mb ly l lz ma">#plotting the rmse values against k values <br/>curve = pd.DataFrame(rmse_val) #elbow curve <br/>curve.plot()</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mh"><img src="../Images/f38a72d38d753c69bda1ecadbe058f4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:770/format:webp/0*jStuzaP-51IsLdBM.png"/></div></figure><p id="c0e9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">正如我们所讨论的，当我们取k=1时，我们得到一个非常高的RMSE值。随着k值的增加，RMSE值减小。在k= 7时，RMSE大约为1219.06，并且随着k值的进一步增加而迅速上升。我们可以有把握地说，在这种情况下，k=7将给出最佳结果。</p><p id="6c3f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这些是使用我们的训练数据集的预测。现在让我们预测测试数据集的值并提交。</p><p id="4be3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 7。测试数据集上的预测</strong></p><pre class="je jf jg jh fd lr ls lt lu aw lv bi"><span id="40da" class="lw jq hi ls b fi lx ly l lz ma">#reading test and submission files<br/>test = pd.read_csv('test.csv')<br/>submission = pd.read_csv('SampleSubmission.csv')<br/>submission['Item_Identifier'] = test['Item_Identifier']<br/>submission['Outlet_Identifier'] = test['Outlet_Identifier']<br/><br/>#preprocessing test dataset<br/>test.drop(['Item_Identifier', 'Outlet_Identifier'], axis=1, inplace=True)<br/>test['Item_Weight'].fillna(mean, inplace =True)<br/>test = pd.get_dummies(test)<br/>test_scaled = scaler.fit_transform(test)<br/>test = pd.DataFrame(test_scaled)<br/><br/>#predicting on the test set and creating submission file<br/>predict = model.predict(test)<br/>submission['Item_Outlet_Sales'] = predict<br/>submission.to_csv('submit_file.csv',index=False)</span></pre><p id="5271" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">提交这份文件时，我得到了一个RMSE。18960 . 688688868617</p><p id="ac65" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">8。实现GridsearchCV </p><p id="0a31" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了确定k值，每次绘制肘形曲线都是一个繁琐而乏味的过程。您可以简单地使用gridsearch来查找最佳值。</p><pre class="je jf jg jh fd lr ls lt lu aw lv bi"><span id="a344" class="lw jq hi ls b fi lx ly l lz ma">from sklearn.model_selection import GridSearchCV<br/>params = {'n_neighbors':[2,3,4,5,6,7,8,9]}<br/><br/>knn = neighbors.KNeighborsRegressor()<br/><br/>model = GridSearchCV(knn, params, cv=5)<br/>model.fit(x_train,y_train)<br/>model.best_params_</span></pre><p id="6ea3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">输出:</p><pre class="je jf jg jh fd lr ls lt lu aw lv bi"><span id="5343" class="lw jq hi ls b fi lx ly l lz ma">{'n_neighbors': 7}</span></pre><h1 id="e6dc" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">6.结尾注释和附加资源</h1><p id="7316" class="pw-post-body-paragraph if ig hi ih b ii kp ik il im kq io ip iq ld is it iu le iw ix iy lf ja jb jc hb bi translated">在本文中，我们介绍了KNN算法的工作原理及其在Python中的实现。这是最基本的，但也是最有效的机器学习技术之一。对于KNN在R中的实现，可以通读这篇文章:<a class="ae mg" href="https://www.analyticsvidhya.com/blog/2015/08/learning-concept-knn-algorithms-programming/" rel="noopener ugc nofollow" target="_blank">使用R的kNN算法</a>。</p><p id="dfc0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本文中，我们直接从<em class="lg"> sklearn </em>库中使用了KNN模型。你也可以从零开始实现KNN(我推荐这个！)，也就是本文所涉及的:<a class="ae mg" href="https://www.analyticsvidhya.com/blog/2018/03/introduction-k-neighbours-algorithm-clustering/" rel="noopener ugc nofollow" target="_blank"> KNN简体</a>。</p><p id="4268" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你认为你很了解KNN，并且对这种技术有很好的掌握，那么在这个MCQ的测验中测试你的技能:<a class="ae mg" href="https://www.analyticsvidhya.com/blog/2017/09/30-questions-test-k-nearest-neighbors-algorithm/" rel="noopener ugc nofollow" target="_blank">关于kNN算法的30个问题</a>。祝你好运！</p></div><div class="ab cl mi mj gp mk" role="separator"><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn"/></div><div class="hb hc hd he hf"><p id="de68" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="lg">原载于2018年8月22日</em><a class="ae mg" href="https://www.analyticsvidhya.com/blog/2018/08/k-nearest-neighbor-introduction-regression-python/" rel="noopener ugc nofollow" target="_blank"><em class="lg">www.analyticsvidhya.com</em></a><em class="lg">。</em></p></div></div>    
</body>
</html>