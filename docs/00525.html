<html>
<head>
<title>Training Your Models on Cloud TPUs in 4 Easy Steps on Google Colab</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在Google Colab上通过4个简单的步骤在云TPU上训练您的模型</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/tpu-training-made-easy-with-colab-3b73b920878f?source=collection_archive---------0-----------------------#2019-07-22">https://medium.com/analytics-vidhya/tpu-training-made-easy-with-colab-3b73b920878f?source=collection_archive---------0-----------------------#2019-07-22</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="2fb8" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">我在TPU上训练了一个神经机器翻译(NMT)模型，现在感觉自己像个向导…</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/a5142c793d95420185f5884e61f40c4a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2hZsom9OR2luUM1nGnOQQg.png"/></div></div></figure><p id="318c" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">你有一个普通的旧TensorFlow模型，计算量太大，无法在你的标准工作笔记本电脑上训练。我明白了。我也经历过，老实说，看到我的笔记本电脑在试图训练一个模型后连续两次崩溃是很痛苦的。</p><p id="c59b" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">在本文中，我将分解如何使用Google Colab在云中的TPU上训练任何模型的步骤。在这之后，相信我，你再也不想碰你那笨重的CPU了。</p><p id="d3a4" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jl hj"><em class="kf">TL；博士:</em> </strong> <em class="kf">这篇文章向你展示了在TPU上训练任何张量流模型是多么容易，只需对你的代码做很少的修改。</em></p></div><div class="ab cl kg kh gp ki" role="separator"><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl"/></div><div class="hb hc hd he hf"><h2 id="2399" class="kn ko hi bd kp kq kr ks kt ku kv kw kx js ky kz la jw lb lc ld ka le lf lg lh bi translated">什么是TPU？</h2><p id="f720" class="pw-post-body-paragraph jj jk hi jl b jm li ij jo jp lj im jr js lk ju jv jw ll jy jz ka lm kc kd ke hb bi translated">张量处理单元(TPU)是一个加速器——由谷歌大脑硬件工程师定制——专门训练深度和计算昂贵的ML模型。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ln"><img src="../Images/720f4736be23ef39b7dd1162f2f004ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VJYpM4RHoJIO0ZoMR9zn1Q.png"/></div></div><figcaption class="lo lp et er es lq lr bd b be z dx translated">这就是TPU的样子。它有4个巨大的散热器，位于一个电路板的顶部，上面有一些非常先进和强大的电路。</figcaption></figure><p id="120b" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">让我们来透视一下，让你知道TPU有多棒多强大。标准MacBook Pro英特尔CPU每个时钟周期可以执行一些操作。一个标准的现成GPU每个周期可以执行数万次运算。最先进的TPU每周期可以执行数十万次运算(有时高达128K OPS)。</p><p id="b87c" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">为了理解规模，想象一下用这些设备打印一本书。CPU可以逐字符打印。一个GPU一次可以打印几个字。TPU吗？嗯，它可以一次打印一整页。这是我们现在拥有的惊人的速度和力量；向谷歌大声疾呼，让每个人都能获得高性能的硬件。</p><p id="ac93" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">如果你对TPU的内部运作以及是什么让它如此神奇感兴趣，去看看谷歌云博客的文章，在那里他们讨论了从硬件到软件的一切 <a class="ae ls" href="https://cloud.google.com/blog/products/gcp/an-in-depth-look-at-googles-first-tensor-processing-unit-tpu" rel="noopener ugc nofollow" target="_blank"> <em class="kf">这里</em> </a> <em class="kf">。您可以找到关于机制、硬件规格、优点、限制、约束等更多信息，以帮助您完成项目！</em></p></div><div class="ab cl kg kh gp ki" role="separator"><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl"/></div><div class="hb hc hd he hf"><h2 id="1507" class="kn ko hi bd kp kq kr ks kt ku kv kw kx js ky kz la jw lb lc ld ka le lf lg lh bi translated">预处理MNIST</h2><p id="bda2" class="pw-post-body-paragraph jj jk hi jl b jm li ij jo jp lj im jr js lk ju jv jw ll jy jz ka lm kc kd ke hb bi translated">为了这个教程，我将运行一个快速简单的MNIST模型。请注意，这个模型可以是您想要的任何形式。为了更好地帮助您可视化正在发生的事情，我选择了“老MNIST”(再次，您选择的数据集)。</p><p id="41cc" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">让我们首先从提取和预处理数据集开始。这应该不是什么大问题:</p><pre class="iy iz ja jb fd lt lu lv lw aw lx bi"><span id="738c" class="kn ko hi lu b fi ly lz l ma mb">import tensorflow as tf<br/>from tensorflow.keras.datasets import mnist<br/>from tensorflow.keras.utils import to_categorical</span><span id="3c15" class="kn ko hi lu b fi mc lz l ma mb"># This can be any dataset<br/>(x_train, y_train), (x_test, y_test) = mnist.load_data()<br/>x_train = x_train.reshape([x_train.shape[0], 784])<br/>x_test = x_test.reshape([x_test.shape[0], 784])<br/>x_train = x_train / 255<br/>x_test = x_test / 255</span><span id="514b" class="kn ko hi lu b fi mc lz l ma mb">y_train = to_categorical(y_train, 10)<br/>y_test = to_categorical(y_test, 10)</span><span id="d091" class="kn ko hi lu b fi mc lz l ma mb">print (x_train.shape, y_train.shape)<br/>print (x_test.shape, y_test.shape)</span><span id="0ba1" class="kn ko hi lu b fi mc lz l ma mb"># &gt;&gt; (60000, 784), (60000, 10)<br/># &gt;&gt; (10000, 784), (10000, 10)</span></pre><p id="95d3" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">我已经尽力让这个教程尽可能的全面，这样你就可以以深不可测的速度训练你的模型，感觉自己站在世界之巅。我们将采取4个步骤在TPU上训练我们的模型:</p><ol class=""><li id="ca6b" class="md me hi jl b jm jn jp jq js mf jw mg ka mh ke mi mj mk ml bi translated">连接到可用的TPU实例</li><li id="8e04" class="md me hi jl b jm mm jp mn js mo jw mp ka mq ke mi mj mk ml bi translated">初始化分布式训练策略</li><li id="11b3" class="md me hi jl b jm mm jp mn js mo jw mp ka mq ke mi mj mk ml bi translated">在上述策略下构建我们的模型</li><li id="95f9" class="md me hi jl b jm mm jp mn js mo jw mp ka mq ke mi mj mk ml bi translated">训练模型，感觉自己像个<em class="kf">巫师</em></li></ol><p id="3877" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">让我们开始吧！</p><p id="3ec0" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jl hj"> <em class="kf">注意:</em> </strong> <em class="kf">使用</em> <code class="du mr ms mt lu b">tf.data</code> <em class="kf">随意预处理您的数据集，或者如果您喜欢的话，将它们转换成</em><code class="du mr ms mt lu b">TFRecords</code><em class="kf"/>。<em class="kf">这些步骤不是必需的，但是在处理超大型数据集的情况下，这些步骤可能对处理内存不足的实例很有用。</em></p></div><div class="ab cl kg kh gp ki" role="separator"><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl"/></div><div class="hb hc hd he hf"><h2 id="eacb" class="kn ko hi bd kp kq kr ks kt ku kv kw kx js ky kz la jw lb lc ld ka le lf lg lh bi translated">连接到TPU</h2><p id="5c83" class="pw-post-body-paragraph jj jk hi jl b jm li ij jo jp lj im jr js lk ju jv jw ll jy jz ka lm kc kd ke hb bi translated">当我在Colab上摆弄TPUs时，连接一个是最乏味的。花了几个小时在网上搜索和浏览教程，但我最终还是完成了。</p><p id="fafd" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">我们首先需要将本地运行的Colab笔记本连接到TPU运行时。要更改运行时间，只需点击导航栏中的<code class="du mr ms mt lu b">Runtime</code>选项卡。将显示一个下拉菜单，您可以从中选择<code class="du mr ms mt lu b">Change runtime type</code>选项。将弹出一个窗口，您可以从下拉选择器中选择<code class="du mr ms mt lu b">TPU</code>选项。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mu"><img src="../Images/5a04a45480b495cd2f5b9fd85e3e5d64.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RX7jY-e5kML4UlQsKj4Xrg.png"/></div></div><figcaption class="lo lp et er es lq lr bd b be z dx translated">弹出窗口看起来像这样。将运行时从CPU切换到TPU。</figcaption></figure><p id="7175" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">为了连接到TPU实例，我们需要创建一个<code class="du mr ms mt lu b">TPUClusterResolver</code>，它接收可用的设备并为我们提供一个:</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mv mw l"/></div></figure><p id="17e7" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">这应该将我们当前的Colab会话连接到一个可用的TPU实例。让我们继续初始化策略，最后调用TPU。</p><p id="a04a" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jl hj"> <em class="kf">注意:</em> </strong> <em class="kf">如果您在多次尝试并重新运行后仍无法连接到TPU实例，您可以将运行时类型改为</em> <code class="du mr ms mt lu b">GPU</code> <em class="kf">。代码仍然可以有效地编译和运行。</em></p></div><div class="ab cl kg kh gp ki" role="separator"><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl"/></div><div class="hb hc hd he hf"><h2 id="cb44" class="kn ko hi bd kp kq kr ks kt ku kv kw kx js ky kz la jw lb lc ld ka le lf lg lh bi translated">初始化分布式训练策略</h2><p id="5b5a" class="pw-post-body-paragraph jj jk hi jl b jm li ij jo jp lj im jr js lk ju jv jw ll jy jz ka lm kc kd ke hb bi translated">现在，我们已经更改了运行时，并获得了可用TPU的列表，我们需要通过创建分布式训练策略来调用TPU，这是一个围绕模型的包装器，使其与多核训练兼容。</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mv mw l"/></div></figure><p id="5444" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><code class="du mr ms mt lu b">resolver</code>让我们可以访问TPU，这样我们最终可以在其上构建一个并行分布的管道。这是一个必要的步骤，因为TPU是一个分布式训练处理器，不像传统的CPU那样是单核的。用这种策略方法，跳上TPU非常简单！它应该会给您一个可用实例的列表:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mx"><img src="../Images/19edf58dd316626a8f5b8519e2079dc9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kDrZo5Za6od6nz78N5wHoA.png"/></div></div><figcaption class="lo lp et er es lq lr bd b be z dx translated">我们有8台设备可供使用</figcaption></figure></div><div class="ab cl kg kh gp ki" role="separator"><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl"/></div><div class="hb hc hd he hf"><h2 id="08e4" class="kn ko hi bd kp kq kr ks kt ku kv kw kx js ky kz la jw lb lc ld ka le lf lg lh bi translated">在分布式培训策略下构建我们的模型</h2><p id="b3c2" class="pw-post-body-paragraph jj jk hi jl b jm li ij jo jp lj im jr js lk ju jv jw ll jy jz ka lm kc kd ke hb bi translated">现在有了培训策略，我们可以继续使用该策略构建我们的模型，如下所示:</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mv mw l"/></div></figure><p id="8404" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">这看起来像很多行话，但它所做的只是采用一个常规的<code class="du mr ms mt lu b">tf.keras</code>模型(通常在CPU上运行),将其放在TPU上，并自动将其分布到所有可用的TPU内核上。</p></div><div class="ab cl kg kh gp ki" role="separator"><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl"/></div><div class="hb hc hd he hf"><h2 id="9a47" class="kn ko hi bd kp kq kr ks kt ku kv kw kx js ky kz la jw lb lc ld ka le lf lg lh bi translated">训练我们的模型</h2><p id="53e2" class="pw-post-body-paragraph jj jk hi jl b jm li ij jo jp lj im jr js lk ju jv jw ll jy jz ka lm kc kd ke hb bi translated">这是这个过程中令人兴奋的部分。我们终于可以在云TPU上免费训练模型了。我们手中有这么多权力，让我们好好利用它，在MNIST上训练(我知道…非常反气候)。</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="mv mw l"/></div></figure><p id="be60" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">确保实例的数量能被<code class="du mr ms mt lu b">steps_per_epoch</code>参数整除，以便在<br/>训练期间使用所有的实例。例如，我们的训练集中有60000个实例。60000 <br/>可以被50整除，这意味着我们所有的实例都被输入到模型中，没有任何<em class="kf">剩余</em>。如果您点击run，它应该会在一段时间后在TPU实例上开始训练:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es my"><img src="../Images/c708ea3d36e108dc8271bf8f74461d1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pWA1XiQMdZzs2mx6OUjuOw.png"/></div></div><figcaption class="lo lp et er es lq lr bd b be z dx translated">这是我在Colab上建立的神经机器翻译模型的TPU训练周期。</figcaption></figure></div><div class="ab cl kg kh gp ki" role="separator"><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl"/></div><div class="hb hc hd he hf"><h2 id="745c" class="kn ko hi bd kp kq kr ks kt ku kv kw kx js ky kz la jw lb lc ld ka le lf lg lh bi translated">最后一次围捕</h2><p id="355b" class="pw-post-body-paragraph jj jk hi jl b jm li ij jo jp lj im jr js lk ju jv jw ll jy jz ka lm kc kd ke hb bi translated">这样，训练应该很快就会开始。Colab将启动一个TPU，并在上面上传模型架构。您很快就会在终端输出中看到经典的Keras进度条样式布局。恭喜你。你刚刚成功地使用了TPU。</p><p id="df37" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">回想起来，我一直认为在TPU上训练模型是只有ML奇才——那些有多年经验和技能的人——才能处理的事情。TPU训练一直是我无法掌握的一件大事，仅仅是因为它的大肆宣传(使它看起来很难使用)。在我最疯狂的梦想中，我从来没有想到它会像在我已有的模型中添加不到10行代码那样简单。</p><p id="8240" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">看完这篇文章，我想让你知道，任何人都可以在加速硬件上训练，不管经验如何。这只是谷歌人工智能在大众中普及机器学习和人工智能的许多步骤之一。</p></div><div class="ab cl kg kh gp ki" role="separator"><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl"/></div><div class="hb hc hd he hf"><h2 id="c6f8" class="kn ko hi bd kp kq kr ks kt ku kv kw kx js ky kz la jw lb lc ld ka le lf lg lh bi translated">关于TPU培训的一些观察</h2><p id="1513" class="pw-post-body-paragraph jj jk hi jl b jm li ij jo jp lj im jr js lk ju jv jw ll jy jz ka lm kc kd ke hb bi translated">我为TensorFlow文档编写的神经机器翻译模型花了我不到一分钟的时间在TPU上进行训练。我很惊讶，因为同一个模型花了4个多小时在一个CPU上训练(这可能解释了为什么我的笔记本电脑崩溃并两次耗尽内存)。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mz"><img src="../Images/4d32dc4e7f88d221ab43db00d7903377.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0BuX1_tYwUZEqzBp72Uq4Q.png"/></div></div><figcaption class="lo lp et er es lq lr bd b be z dx translated">我的NMT模特在TPU上训练得非常好！指标显示训练很顺利，我一路上没有遇到任何障碍。</figcaption></figure><p id="c0da" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">我的模型达到了非常高的精确度——比我在CPU上训练时达到的精确度还要高。说到质量培训，云TPU的性能和速度是首屈一指的！</p><p id="f34a" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jl hj"> <em class="kf">注:</em> </strong> <em class="kf">你可以在这里找到我的代号</em><a class="ae ls" href="https://colab.research.google.com/drive/1o0nSHlhW2i6mrbeU-lUajw8fpSo1dbMr" rel="noopener ugc nofollow" target="_blank"><em class="kf"/></a><em class="kf">。玩得开心！</em></p></div><div class="ab cl kg kh gp ki" role="separator"><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl"/></div><div class="hb hc hd he hf"><h2 id="4e35" class="kn ko hi bd kp kq kr ks kt ku kv kw kx js ky kz la jw lb lc ld ka le lf lg lh bi translated">简单地</h2><p id="df9d" class="pw-post-body-paragraph jj jk hi jl b jm li ij jo jp lj im jr js lk ju jv jw ll jy jz ka lm kc kd ke hb bi translated">当谷歌推出新的机器学习玩具时，它总是带着礼物来，我们可以修补和玩耍。TPU处理器无疑是ML社区的福音，因为它在人工智能的民主化中发挥了重要作用——它让每个人都有机会使用加速硬件，无论其人口结构如何。有了TPUs，研究和实验达到了前所未有的高度，人们现在以前所未有的方式参与机器学习！</p><p id="5b32" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">我希望这篇文章能够帮助您以更加高效和优雅的方式训练您的模型。如果你对TPU的使用有任何疑问，或者想就技术和ML进行一般性的交谈，请随时在评论中提出，或者在<a class="ae ls" href="https://twitter.com/rishabh16_" rel="noopener ugc nofollow" target="_blank"> Twitter </a>或<a class="ae ls" href="https://www.linkedin.com/in/rishabhanand16/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上联系我。我一般一天内回复。</p><p id="bbb3" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">在那之前，我会在下一个里抓住你！</p><p id="8e80" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">里沙卜·阿南德的文章</p></div><div class="ab cl kg kh gp ki" role="separator"><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl"/></div><div class="hb hc hd he hf"><h2 id="5707" class="kn ko hi bd kp kq kr ks kt ku kv kw kx js ky kz la jw lb lc ld ka le lf lg lh bi translated">某种程度上的行动号召</h2><p id="f640" class="pw-post-body-paragraph jj jk hi jl b jm li ij jo jp lj im jr js lk ju jv jw ll jy jz ka lm kc kd ke hb bi translated">有兴趣阅读最新和最伟大的技术，并接触机器学习、数据科学和技术领域的最新进展吗？一定要抓住我的其他文章或给我一个关注！您的反馈和持续的支持意义重大，并鼓励我继续为您的学习撰写高质量的内容！</p><div class="nc nd ez fb ne nf"><a href="https://towardsdatascience.com/quantum-computing-with-colorful-diagrams-8f7861cfb6da" rel="noopener follow" target="_blank"><div class="ng ab dw"><div class="nh ab ni cl cj nj"><h2 class="bd hj fi z dy nk ea eb nl ed ef hh bi translated">量子计算速成班使用非常丰富多彩的图表</h2><div class="nm l"><h3 class="bd b fi z dy nk ea eb nl ed ef dx translated">几乎所有你需要知道的关于量子计算的东西都用非常直观的图画来解释…</h3></div><div class="nn l"><p class="bd b fp z dy nk ea eb nl ed ef dx translated">towardsdatascience.com</p></div></div><div class="no l"><div class="np l nq nr ns no nt jh nf"/></div></div></a></div><div class="nc nd ez fb ne nf"><a rel="noopener follow" target="_blank" href="/sigmoid/https-medium-com-rishabh-anand-on-the-origin-of-genetic-algorithms-fc927d2e11e0"><div class="ng ab dw"><div class="nh ab ni cl cj nj"><h2 class="bd hj fi z dy nk ea eb nl ed ef hh bi translated">遗传算法综合指南(以及如何编码)</h2><div class="nm l"><h3 class="bd b fi z dy nk ea eb nl ed ef dx translated">遗传算法的起源</h3></div><div class="nn l"><p class="bd b fp z dy nk ea eb nl ed ef dx translated">medium.com</p></div></div><div class="no l"><div class="nu l nq nr ns no nt jh nf"/></div></div></a></div><div class="nc nd ez fb ne nf"><a href="https://hackernoon.com/catgan-cat-face-generation-using-gans-f44663586d6b?source=---------8------------------" rel="noopener  ugc nofollow" target="_blank"><div class="ng ab dw"><div class="nh ab ni cl cj nj"><h2 class="bd hj fi z dy nk ea eb nl ed ef hh bi translated">CatGAN:使用GANs生成猫脸— By</h2><div class="nm l"><h3 class="bd b fi z dy nk ea eb nl ed ef dx translated">我们可以看到在第100和第200个纪元时猫脸的模糊轮廓，这表明发电机已经接近…</h3></div><div class="nn l"><p class="bd b fp z dy nk ea eb nl ed ef dx translated">hackernoon.com</p></div></div><div class="no l"><div class="nv l nq nr ns no nt jh nf"/></div></div></a></div><div class="nc nd ez fb ne nf"><a href="https://towardsdatascience.com/making-a-replier-and-follow-bot-for-twitter-using-node-js-23e0ba8e4e4f" rel="noopener follow" target="_blank"><div class="ng ab dw"><div class="nh ab ni cl cj nj"><h2 class="bd hj fi z dy nk ea eb nl ed ef hh bi translated">使用Node.js制作回复器并关注Twitter的Bot</h2><div class="nm l"><h3 class="bd b fi z dy nk ea eb nl ed ef dx translated">如何“明智地”花时间做这个了不起的东西。</h3></div><div class="nn l"><p class="bd b fp z dy nk ea eb nl ed ef dx translated">towardsdatascience.com</p></div></div><div class="no l"><div class="nw l nq nr ns no nt jh nf"/></div></div></a></div><div class="nc nd ez fb ne nf"><a href="https://hackernoon.com/introducing-tensorflow-js-3f31d70f5904?source=---------9------------------" rel="noopener  ugc nofollow" target="_blank"><div class="ng ab dw"><div class="nh ab ni cl cj nj"><h2 class="bd hj fi z dy nk ea eb nl ed ef hh bi translated">TensorFlow.js简介🎉—由</h2><div class="nm l"><h3 class="bd b fi z dy nk ea eb nl ed ef dx translated">TensorFlow.js潜力很大。而不是将javascript文件链接到运行在云上的python文件…</h3></div><div class="nn l"><p class="bd b fp z dy nk ea eb nl ed ef dx translated">hackernoon.com</p></div></div><div class="no l"><div class="nx l nq nr ns no nt jh nf"/></div></div></a></div><div class="nc nd ez fb ne nf"><a href="https://towardsdatascience.com/tensorflow-or-tensorno-c9c6c6c2f992" rel="noopener follow" target="_blank"><div class="ng ab dw"><div class="nh ab ni cl cj nj"><h2 class="bd hj fi z dy nk ea eb nl ed ef hh bi translated">TensorFlow还是TensorNo？</h2><div class="nm l"><h3 class="bd b fi z dy nk ea eb nl ed ef dx translated">TensorFlow机器学习初学者指南。</h3></div><div class="nn l"><p class="bd b fp z dy nk ea eb nl ed ef dx translated">towardsdatascience.com</p></div></div><div class="no l"><div class="ny l nq nr ns no nt jh nf"/></div></div></a></div></div></div>    
</body>
</html>