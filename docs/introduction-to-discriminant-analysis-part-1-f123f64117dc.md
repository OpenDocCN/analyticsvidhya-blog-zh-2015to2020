# 判别分析导论(一)

> 原文：<https://medium.com/analytics-vidhya/introduction-to-discriminant-analysis-part-1-f123f64117dc?source=collection_archive---------0----------------------->

![](img/fff82df17cb6d5e9aca01b836f8af1a7.png)

这看起来像是这个男人在歧视蓝色的鱼。会不会是人类在保护小鱼不被大鱼吃掉？

> *我们的思维越清晰，我们关注的焦点越清晰，我们就越有力量！*

花点时间分析一下这两句话:

总的来说，我认为一个人在健康的时候会表现得更好。从各个角度来看，做任何需要保持健康的事情都是很重要的。

当一个人身体健康时，他/她会表现得更好，无论是生理上还是心理上。通过引导不同/不同形式的能量到每一个方面，在两个方面都工作是很重要的。

你能发现这两者有什么不同吗？

在第二句中，健康的两个方面和所需的重点之间有明显的区别。

当以负面方式使用所获得的差异时，歧视是不好的。否则，在辨别、区分和分配适当焦点的能力的帮助下，可以完成惊人的事情，以实现不同的目标。

# 判别分析导论

判别式分析，是单词 discrimination 的一个松散派生，是一个广泛用于对结果进行等级分类的概念。换句话说，它有助于确定一组变量在预测类别成员资格时是否有效

例如，我可能希望根据学生在期末考试前的各种课堂测试中的分数来预测他在考试中是“通过”还是“失败”。

同样，我可能希望根据客户的工资、每月支出和其他银行负债等来预测他是否会支付每月的抵押贷款。

在上述两种情况下，我的努力都是为了预测一个本质上明确的反应。影响反应或在决定反应中起重要作用的因素称为自变量。

当我阅读各种关于多种分类技术的书籍时，我发现判别分析是一种非常强大的分类工具。另一种这样的技术是逻辑回归，它被发现使用得更广泛。我想揭示判别分析的微妙之处，它有时胜过逻辑回归，尤其是当响应变量超过 2 个水平时。该主题广泛涵盖以下领域:

**一、什么是判别分析？**

**二。判别分析和 Manova 是什么关系？**

**三。用一个简单的例子说明**

# **一、什么是判别分析？**

![](img/02b9556d6e44004e79b073018eff3b51.png)

来源:https://www.flickr.com/photos/15609463@N03/14898932531

判别式，顾名思义，是一种分析业务问题的方法，目的是将响应变量区分或判别到其不同的类别中。

通常，当我们已经有预定义的反应类别/种类，并且我们想要建立一个模型来帮助清楚地预测类别时，如果有任何新的观察进入方程，就使用判别分析。

但是，如果我们有一个尚未定义响应类别的数据集，则聚类先于判别式来创建最能定义群体行为的各种输出类别。在建立聚类之后，许多统计学家/分析师通常使用判别或逻辑模型作为预测技术来对任何新的观察结果进行分类。

可以使用判别模型的一些相关实际例子如下

1.  当我们想预测一个银行贷款的申请人是否可能违约时。
2.  根据各种健康指标预测心脏病发作的可能性。
3.  根据各种性能指标预测发动机/机器的稳定性水平-“良好”、“需要检查”或“需要维修/更换”。

根据等式，响应变量和独立变量之间的预期关系可以通过下面的等式来解释

d=v1*X1+v2*X2+…+vn*Xn+a

其中 d 是判别函数，v 是判别系数，X 是被调查者对该变量的得分。常数(错误)。我们总是得到 n-1 个判别方程，其中 n 是因变量所具有的组/成员数。对于 Iris 数据集，我们得到两个方程，因为我们有三类因变量，即物种。

![](img/8e6561dac90753489cfd3ceca9d6af2b.png)

LDA(线性判别分析)确定组平均值，并为每个个体计算属于不同组的概率。然后，该个人被分配到具有最高概率分数的组。参见左边的例子。

与逻辑回归相比，LDA 更适合于在结果变量包含两个以上类别的情况下预测观察值的类别。此外，对于多类分类问题，它比逻辑回归更稳定。LDA 假设预测值呈正态分布(高斯分布),并且不同类别具有特定类别的均值和相等的方差/协方差。如果违反这些假设，逻辑回归将优于 LDA。

二次判别分析(QDA)是 LDA 的扩展，它比前者稍微灵活一点，因为它不假设方差/协方差相等。换句话说，对于 QDA，每个类别的协方差矩阵可以不同。当你有一个小的训练集时，LDA 往往比 QDA 更好。相比之下，如果训练集非常大，因此分类器的方差不是主要问题，或者如果 K 个类的公共协方差矩阵的假设明显不成立，则推荐使用 QDA。

# **二。判别式与方差分析的关系**

当我们有一个分类响应变量和一组本质上连续的独立变量时，通常使用判别式。

在使用判别分析之前的测试是对同一组变量使用 Manova，但是在反转方程之后，即，用于判别的响应(=因变量)和独立变量分别变成了用于 Manova 的独立变量和响应变量。如果 Manova 输出显示分类变量的均值显著不同，从而拒绝假设影响反应的因素之间没有差异(均值)的无效假设，只有这样判别分析才能很好地区分和分类反应变量(在判别模型中)。如果马诺娃不拒绝零假设，判别分析将是徒劳的。所以在很多方面，判别式依赖于马诺娃，有时被称为马诺娃的逆。在接下来的几节中，我们将通过几个例子更详细地了解这一点。

**三世。举例说明**

## 如下图所示，有几个相关变量

![](img/2c87e9f24acca44eda6984a092891274.png)

类黄酮和非类黄酮与 OD280.OD315 相关。脯氨酸和酒精也有相当程度的相关性

下面显示了上述代码的一些单变量图

![](img/46e6d6cfdace1e7172f8a31463fbabf1.png)![](img/e4d905badcc94eb69ef21cc016729e08.png)

```
**#Bivariate Analyis with facets**
a=ggplot(wine, aes(x=Alcohol, y=MalicAcid,col="red", alpha=0.5))
a+geom_point()+facet_grid(Class~.)+guides(colour=FALSE, alpha=FALSE)
```

![](img/56d0ada62944c32bc2deed6b76a0c7f4.png)

> 如下图所示，cor 系数为 0.09，没有真正的相关性

```
cor(wine$Alcohol,wine$MalicAcid)
```

![](img/fe2fa178d30d395384176b7d3c3010c1.png)![](img/c7f3ef324ce7dda3b94bad677bbc7dbe.png)

如左边的散点图所示，没有真正的相关性。从右边的条形图中可以看出，酒精平均值明显分离

方差分析检验:使用方差分析来检验假设，即结果水平的平均值不同，这实质上意味着可能存在差异，并且独立变量有助于差异。

```
summary(M)*Df Pillai approx F num Df den Df    Pr(>F)    
Y           1 0.8651   64.661     12    121 < 2.2e-16 ***
Residuals 132                                            
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1*
```

> *pValue 和 Fstatistic 表明零假设被拒绝，即所有独立变量的组合(即除类别外的所有变量)对 3 种葡萄酒类型有不同的含义。*

个别重要的变量可以通过
summary.aov(M)找到。

使用 Discriminer 库中的 discpower 函数也可以找到重要的变量。

100%的准确率好得让人难以置信。可能会有过度拟合。然而，这是一个小数据集的热身。接下来是真正的交易！

# **结论**

在 20 世纪 30 年代，三个不同的人——英国的费希尔、美国的霍特林和印度的马哈拉诺比斯——试图通过三种不同的方法解决同一个问题。后来，他们的方法被结合在一起，形成了我们今天所说的判别分析。

在这个博客中，我们学习了什么是线性判别分析，以及它在一个简单数据集上的应用。在下一篇博客中，我们将考虑一个更复杂的现实问题，看看 LDA 的应用。此外，后续博客将涵盖线性判别分析变体的应用、判别模型所有版本的比较和最佳选择，以及复杂非线性模型(包括集成建模)的应用。