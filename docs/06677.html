<html>
<head>
<title>Improving instance segmentation using Path Aggregation Network</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">利用路径聚合网络改进实例分割</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/improving-instance-segmentation-using-path-aggregation-network-a89588f3d630?source=collection_archive---------3-----------------------#2020-05-30">https://medium.com/analytics-vidhya/improving-instance-segmentation-using-path-aggregation-network-a89588f3d630?source=collection_archive---------3-----------------------#2020-05-30</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/a1378c7ee9f48a2a248ee991cac882eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FicdpZPCVYIxp7vFskZrCw.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">(来源:<a class="ae iu" href="https://aev-autonomous-driving-dataset.s3.eu-central-1.amazonaws.com/a2d2-preview.tar" rel="noopener ugc nofollow" target="_blank">https://AEV-autonomous-driving-dataset . S3 . eu-central-1 . Amazon AWS . com/a2 D2-preview . tar</a>)</figcaption></figure><p id="64f3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">实例分割是一项复杂的计算机视觉任务，涉及识别图像中不同的对象实例并绘制它们的像素级掩模。任何用于实例分割的方法除了识别属于那些实例的每个像素之外，还需要(隐式或显式地)检测、分类和定位图像中的各种对象实例。</p><p id="b4f4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">每当需要实例分割时，Mask-RCNN通常会出现在列表中。它在实例分割任务上提供了良好的结果，并优于包括COCO 2016挑战赛获胜者在内的众多模型。除此之外，它在GitHub上有许多很好的实现，这使它成为一个很好的候选对象。</p><figure class="ju jv jw jx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es jt"><img src="../Images/4fccbdd1ee7803022617c7c9337b2b9b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*k6ESAvIJ64yjDNa5ZsWCrg.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">(来源:【https://imgflip.com/memetemplate/184072400/Im-still-worthy T2】)</figcaption></figure></div><div class="ab cl jy jz gp ka" role="separator"><span class="kb bw bk kc kd ke"/><span class="kb bw bk kc kd ke"/><span class="kb bw bk kc kd"/></div><div class="hb hc hd he hf"><p id="2dac" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">导致Mask-RCNN产生良好分割结果的一些主要亮点包括:</p><ul class=""><li id="b09e" class="kf kg hi ix b iy iz jc jd jg kh jk ki jo kj js kk kl km kn bi translated"><strong class="ix hj"> FPN </strong>提供短信息传播路径</li><li id="2106" class="kf kg hi ix b iy ko jc kp jg kq jk kr jo ks js kk kl km kn bi translated">用<strong class="ix hj"> ROIAlign </strong>替换<strong class="ix hj"> ROIPool </strong></li><li id="c092" class="kf kg hi ix b iy ko jc kp jg kq jk kr jo ks js kk kl km kn bi translated">增加一个<strong class="ix hj">独立分支</strong>用于预测掩码</li></ul><p id="e72e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">然而，在本文中，我将讨论<strong class="ix hj">路径聚合网络</strong>——Mask-RCNN的扩展，它对其前身进行了一些改进。<strong class="ix hj"> PANet </strong>试图进一步增强Mask-RCNN的功能，建议通过以下方式改进上述功能:</p><ul class=""><li id="7a2e" class="kf kg hi ix b iy iz jc jd jg kh jk ki jo kj js kk kl km kn bi translated">添加一个<strong class="ix hj">自底向上</strong> <strong class="ix hj">路径</strong>来扩充FPN中自顶向下的路径</li><li id="c307" class="kf kg hi ix b iy ko jc kp jg kq jk kr jo ks js kk kl km kn bi translated">使用<strong class="ix hj">自适应特征池</strong>从所有级别获取信息</li><li id="1720" class="kf kg hi ix b iy ko jc kp jg kq jk kr jo ks js kk kl km kn bi translated">用微小的<strong class="ix hj">全连接层</strong>增加掩模预测</li></ul><h1 id="527e" class="kt ku hi bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">1.自底向上路径增强</h1><figure class="ju jv jw jx fd ij er es paragraph-image"><div class="er es lr"><img src="../Images/f3029637425ca1c2a045f64655169eb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1038/format:webp/1*wIK9CIal9v2UwHmBfHy-Wg.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">图一。PANet中使用的主干插图。(a)用于MASK-RCNN的FPN骨架。(b)自下而上的路径增强</figcaption></figure><p id="4a2b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">随着图像通过网络，连续层<strong class="ix hj">中特征的<strong class="ix hj">复杂度</strong>增加</strong>，从描绘边缘和纹理等低级特征到编码眼睛和鼻子等整个对象部分。然而，特征图<strong class="ix hj">的<strong class="ix hj">空间分辨率</strong>降低</strong>，这是由于图1(a)的左侧部分<strong class="ix hj">所示的各种交错卷积和汇集层。</strong>这导致空间信息的丢失，从而使这些高级特征不适合预测像素级掩模。</p><p id="b1ce" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">Mask-RCNN中使用的特征金字塔网络采用自上而下的路径来将来自高级层的语义丰富的特征与位于较低层的较高分辨率特征图中的精确定位信息相结合。它使用上采样层与来自原始主干中的特征图的横向连接相结合，以产生保留空间信息的语义丰富的特征。</p><p id="6e7b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">除了FPN使用的自上而下的路径之外，PANet还提出了一个自下而上的路径(图1)。Mask-RCNN使用来自更高层的特征(例如图1(a)中的P₅)来产生大物体的掩模。然而，空间信息从低层传播到高层的路径(图1(a)中的红线)相当长，可能由100层以上的层组成。为此，PANet使用了一条较短的路径，从低层到高层有清晰的横向连接。这导致了一个<em class="ls">’</em><strong class="ix hj"><em class="ls">快捷方式</em></strong><em class="ls">’</em>连接(由图1中的绿线描绘)，其由从原始主干中的低层到新的高层(例如N₅)的少于10层组成，从而允许信息容易流动。</p><h2 id="6e4d" class="lt ku hi bd kv lu lv lw kz lx ly lz ld jg ma mb lh jk mc md ll jo me mf lp mg bi translated"><strong class="ak">增强的自下而上结构:</strong></h2><figure class="ju jv jw jx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mh"><img src="../Images/aaf23a45ed8d81f589b05e8519671b80.png" data-original-src="https://miro.medium.com/v2/resize:fit:648/format:webp/1*SGkuM7iOUBukxYx7o3s1Lg.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">图二。自底向上路径增强的构建块。</figcaption></figure><p id="9563" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">主干网络被分成不同的阶段，每个阶段包含产生具有相同空间大小的特征地图的层。例如，图1中的P2和N2属于同一阶段，即2。(P用于表示从FPN生成的特征地图，N用于表示从自下而上路径生成的特征地图)。属于自下而上路径中的第I阶段的特征图是使用先前特征图的3×3步长(2x)卷积，继之以来自FCN的相同阶段特征图的逐元素相加来生成的。对结果执行另一个3×3卷积以产生最终特征。</p><h1 id="cfe0" class="kt ku hi bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated"><strong class="ak"> 2。自适应特征池</strong></h1><p id="b825" class="pw-post-body-paragraph iv iw hi ix b iy mi ja jb jc mj je jf jg mk ji jj jk ml jm jn jo mm jq jr js hb bi translated">以前，Mask-RCNN使用单个阶段(P2、P3、P4或P5)的特征进行预测。如果感兴趣区域很大，则使用更高级的特征图(如P4或P5)通过ROI Align池提取特征。尽管简单有效，但它仍然可能产生非最佳结果。例如，具有10个像素差异的两个建议可以被分配到不同的级别，而事实上这两个建议非常相似。</p><p id="fbd4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">此外，高级特征捕获更丰富的上下文信息。允许小型提案使用这些功能对网络有益。</p><p id="9b8c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">考虑到这一点，PANet融合了所有阶段{N2、N3、N4、N5 }的特征，并让网络决定使用哪些特征。</p><figure class="ju jv jw jx fd ij er es paragraph-image"><div class="er es mn"><img src="../Images/42c6370eb47e7fa53b2da1a583da26cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:632/format:webp/1*CB9CxOBCCLCgygP4WAroDg.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">图3。自适应特征池</figcaption></figure><p id="2be2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">它执行ROI对准以从每个特征图中提取对象的特征。这些对齐的特征地图被允许独立地通过一个参数层。接下来是融合操作，以使网络能够适应特征。测试了三种不同类型的融合操作，其中基于元素的最大值操作产生了最好的结果。</p><h1 id="f808" class="kt ku hi bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated"><strong class="ak"> 3。全连接融合</strong></h1><p id="30f6" class="pw-post-body-paragraph iv iw hi ix b iy mi ja jb jc mj je jf jg mk ji jj jk ml jm jn jo mm jq jr js hb bi translated">掩膜RCNN使用小型全卷积网络(FCN)从汇集的特征中预测掩膜。使用卷积层代替完全连接的层，除了减少参数数量之外，还保留了空间结构。然而，这种方法中的一个问题是，由于参数对于所有空间位置是共享的，因此网络在进行预测时不学习使用像素的位置。例如，道路通常出现在图像的底部，天空出现在图像的顶部。</p><p id="74c7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">另一方面，完全连接的层是<strong class="ix hj"> <em class="ls">位置敏感的</em> </strong>，因为在输入中有对应于不同位置的不同参数。所以它们有能力适应不同的空间位置。此外，使用来自该提议的整个特征地图的信息来进行每个位置的预测。</p><p id="1ea8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">PANet使用来自这两层的信息，在做出决策时为网络提供更加多样化的视图。</p><figure class="ju jv jw jx fd ij er es paragraph-image"><div class="er es mo"><img src="../Images/94d2d70d9084fa741d7dd56a1abb9ddf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1026/format:webp/1*Mx3Em1l2ZQZO98appQSkWg.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">图4。具有全连接融合的掩模预测分支。</figcaption></figure><p id="76d7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为此，PANet使用了conv 3层的功能，如上图4所示。在进入全连接层之前，这些信号经过两个3×3卷积层。第二卷积层用于将信道数量缩减一半，以减少计算开销。此外，完全连接的层仅预测描绘前景和背景的二元遮罩。图1中需要注意的另一个有趣的事情是使用了仅1个完全连接的 (fc)层。这可确保要素的隐藏空间结构保持完整。来自全连接层的预测被整形为与来自卷积分支的预测相同的形状，然后被添加到来自FCN的每个类别的掩码<br/>中，以产生最终输出。</p></div><div class="ab cl jy jz gp ka" role="separator"><span class="kb bw bk kc kd ke"/><span class="kb bw bk kc kd ke"/><span class="kb bw bk kc kd"/></div><div class="hb hc hd he hf"><h1 id="8586" class="kt ku hi bd kv kw mp ky kz la mq lc ld le mr lg lh li ms lk ll lm mt lo lp lq bi translated">结果</h1><figure class="ju jv jw jx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mu"><img src="../Images/e78d62e6d59d83105580502bfb7876ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cJYdgyGg60HIpKuyJLVAZQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">表1。COCO 2016实例分割挑战赛冠军PANet与COCO test-dev子集上Mask R-CNN在Mask AP方面的比较，其中后两者为基线。</figcaption></figure><p id="08ad" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">从表1中可以看出，PANet与<strong class="ix hj"> ResNet-50 </strong>在多尺度图像上训练并在单尺度图像上测试已经超过了Mask R-CNN和2016年的Champion，后者使用了更大的模型集合和测试技巧。并且，在没有大批量训练的情况下，获得了2017年COCO实例分割挑战赛，物体检测任务排名第二。</p><figure class="ju jv jw jx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mv"><img src="../Images/af99c7eff623744339a2d68be4960419.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*devv4rCGlYmmJnUISw6E_g.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">表二。关于Cityscapes val子集的结果，表示为AP [val]，以及关于city scape测试子集的结果，表示为AP。</figcaption></figure><p id="068d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">即使在Cityscapes数据集上，PANet也始终优于Mask-RCNN。在COCO上预先训练，该模型能够比具有相同设置的Mask R-CNN高出4.4个点。</p><h1 id="2505" class="kt ku hi bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq bi translated">参考</h1><ul class=""><li id="8a9a" class="kf kg hi ix b iy mi jc mj jg mw jk mx jo my js kk kl km kn bi translated"><a class="ae iu" href="http://openaccess.thecvf.com/content_iccv_2017/html/He_Mask_R-CNN_ICCV_2017_paper.html" rel="noopener ugc nofollow" target="_blank"> <strong class="ix hj">面具RCNN </strong> </a> <strong class="ix hj">，</strong> ICCV 2017</li><li id="3510" class="kf kg hi ix b iy ko jc kp jg kq jk kr jo ks js kk kl km kn bi translated"><a class="ae iu" href="http://openaccess.thecvf.com/content_cvpr_2017/html/Lin_Feature_Pyramid_Networks_CVPR_2017_paper.html" rel="noopener ugc nofollow" target="_blank"> <strong class="ix hj"> FPN: </strong>用于物体检测的特征金字塔网络</a> <strong class="ix hj">，</strong> CVPR 2017</li><li id="0a5a" class="kf kg hi ix b iy ko jc kp jg kq jk kr jo ks js kk kl km kn bi translated"><a class="ae iu" href="http://openaccess.thecvf.com/content_cvpr_2018/html/Liu_Path_Aggregation_Network_CVPR_2018_paper.html" rel="noopener ugc nofollow" target="_blank"> <strong class="ix hj"> PANet: </strong>路径聚合网络实例分割</a>，CVPR 2018</li></ul><blockquote class="mz na nb"><p id="a74a" class="iv iw ls ix b iy iz ja jb jc jd je jf nc jh ji jj nd jl jm jn ne jp jq jr js hb bi translated">(如果未明确提及来源，所有图片均来自PANet论文)</p></blockquote></div></div>    
</body>
</html>