<html>
<head>
<title>Key Phrase Extraction &amp; Applause Prediction of medium articles</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">媒体文章的关键词抽取和掌声预测</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/key-phrase-extraction-applause-prediction-7b397c7ad76d?source=collection_archive---------14-----------------------#2020-12-19">https://medium.com/analytics-vidhya/key-phrase-extraction-applause-prediction-7b397c7ad76d?source=collection_archive---------14-----------------------#2020-12-19</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/b37dbdd2daad2d4b7013a808ddb96856.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AjztIkWlUQ92hXiYyxilEg.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">*自动ML工具，用于对媒体在线文章的原始数据文件执行ML技术</figcaption></figure><blockquote class="iu"><p id="1dd2" class="iv iw hi bd ix iy iz ja jb jc jd je dx translated"><em class="jf">机器学习最佳项目奖获得者</em>@ IIITD 2019–2020</p></blockquote><blockquote class="jg jh ji"><p id="80c7" class="jj jk jl jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg je hb bi translated"><strong class="jm hj"> <em class="hi">摘要</em></strong><em class="hi">——随着互联网上内容可用性的增加，很难引起注意。对于博客作者来说，获得一些关于他们作品的反馈以确信他们文章的影响力已经成为最重要的事情。我们正在训练一个机器学习模型来学习流行的文章风格，以使用各种单词嵌入的向量空间表示的形式，以及它们基于点击和标签的流行度。</em></p></blockquote><ol class=""><li id="7b49" class="kh ki hi jm b jn kj jr kk kl km kn ko kp kq je kr ks kt ku bi translated"><strong class="jm hj">动机</strong></li></ol><figure class="kw kx ky kz fd ij er es paragraph-image"><div class="er es kv"><img src="../Images/3d3ddf39f7f7383596b52f3e20f469fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:616/format:webp/1*-nB0dibfzwbzORBmHnG43w.png"/></div></figure><p id="9c65" class="pw-post-body-paragraph jj jk hi jm b jn kj jp jq jr kk jt ju kl la jx jy kn lb kb kc kp lc kf kg je hb bi translated">当今世界充满了在线内容，每天都有更多的内容产生。媒体是传播几乎所有社会领域的信息和知识的顶级平台之一。它被大量用于发布计算机科学领域的内容和文章，如ML、AI、数据工程等。在互联网上越来越受欢迎。</p><p id="4cb3" class="pw-post-body-paragraph jj jk hi jm b jn kj jp jq jr kk jt ju kl la jx jy kn lb kb kc kp lc kf kg je hb bi translated"><strong class="jm hj"> 2。简介</strong></p><p id="254d" class="pw-post-body-paragraph jj jk hi jm b jn kj jp jq jr kk jt ju kl la jx jy kn lb kb kc kp lc kf kg je hb bi ld translated">一篇文章的写作和获得人气是一项艰巨的任务。对于不太知道如何获得人气的新作者来说，问题来了。我们把直觉发展成了做一篇有趣的、有意思的媒介文章。我们不是纯粹依赖猜测理论，而是希望使用数据科学和机器学习来测试我们的理论。作为一名数据科学家，我们一直对创造力和自动化充满好奇。此外，我们相信我们的文章和在这个模型上的努力结合了科学的两个方面来预测最佳媒体文章。我们介绍我们的工作，像Medium这样的工作平台有自己的指标来评估内容，让读者鼓掌以示赞赏。此外，这些平台提供了添加一些最能提供内容主题的关键词的功能。</p><figure class="kw kx ky kz fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lm"><img src="../Images/070c50092884692384d8dbf212d36257.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3MFyCSbLCfcuE-UqbFlnHQ.jpeg"/></div></div></figure><p id="1adb" class="pw-post-body-paragraph jj jk hi jm b jn kj jp jq jr kk jt ju kl la jx jy kn lb kb kc kp lc kf kg je hb bi translated">现在，它成为一个必要的作家获得一些援助的最佳可能的关键短语，使文章排名上升，并初步流行的新文章。我们在这个项目中的目标是在媒体上训练一个模型。</p><p id="c38d" class="pw-post-body-paragraph jj jk hi jm b jn kj jp jq jr kk jt ju kl la jx jy kn lb kb kc kp lc kf kg je hb bi translated"><strong class="jm hj"> 3。文献调查</strong></p><p id="2794" class="pw-post-body-paragraph jj jk hi jm b jn kj jp jq jr kk jt ju kl la jx jy kn lb kb kc kp lc kf kg je hb bi translated">关键短语提取是一个很大的领域，已经有很多人致力于此。我们有许多预先训练好的模型，如Bert和pke rake等。这有助于提取关键短语。尽管我们在文本分类方面有了很多的进步，但是只有一小部分研究人员探索了整个文章性能问题。pke是一个基于python的开源关键短语提取工具包。它提供了一个端到端的关键短语提取管道，其中的每个组件都可以很容易地修改或扩展，以开发新的模型。pke还允许对最先进的关键短语提取模型进行简单的基准测试，并附带在SemEval-2010数据集上训练的监督模型。[1], [2].Sahrawat等人[8]使用伯特和bi-lstm等神经网络模型从学术文章中提取关键短语，作为使用BiLSTM-CRF解决的序列标注任务，其中输入文本中的单词使用深度上下文化嵌入来表示。</p><p id="1124" class="pw-post-body-paragraph jj jk hi jm b jn kj jp jq jr kk jt ju kl la jx jy kn lb kb kc kp lc kf kg je hb bi translated"><strong class="jm hj"> 4。使用的数据集</strong></p><figure class="kw kx ky kz fd ij er es paragraph-image"><div class="er es ln"><img src="../Images/ec66e408f84270bdd915646ecff10d2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:544/format:webp/1*8naUXZx6ajJhgETCDDE2sw.png"/></div></figure><p id="3fed" class="pw-post-body-paragraph jj jk hi jm b jn kj jp jq jr kk jt ju kl la jx jy kn lb kb kc kp lc kf kg je hb bi translated">我们用于这个项目的数据集正在被废弃，使用的是官方Medium网站上JSON字符串形式的硒。到目前为止，我们有超过2574篇不同受欢迎程度的文章。我们正在收集更多的数据，但是因为注释验证需要时间，所以我们将在最后的演示中总结这一点。为了进行预处理，我们删除了所有非ASCII字符和空格或特殊字符。然后我们把数字转换成它们的英语等价物。随后是拼写纠正和引理。</p><p id="5ee1" class="pw-post-body-paragraph jj jk hi jm b jn kj jp jq jr kk jt ju kl la jx jy kn lb kb kc kp lc kf kg je hb bi translated">我们的数据有很多新的文章没有掌声，所以我们删除这些，以避免误导。最后进行doc2vec嵌入，得到一个数字文档向量。</p><p id="1274" class="pw-post-body-paragraph jj jk hi jm b jn kj jp jq jr kk jt ju kl la jx jy kn lb kb kc kp lc kf kg je hb bi translated"><strong class="jm hj"> 5 .数据刮取</strong></p><p id="29f8" class="pw-post-body-paragraph jj jk hi jm b jn kj jp jq jr kk jt ju kl la jx jy kn lb kb kc kp lc kf kg je hb bi translated">网络抓取也称为“爬行”或“蜘蛛爬行”，是一种从在线来源(通常是网站)自动收集数据的技术。虽然网络抓取是一种在相对短的时间内获取大量数据的简单方法，但它会给源所在的服务器增加压力。我们废弃了使用硒的培养基的数据。数据挖掘或收集数据是数据科学生命周期中非常原始的一步。根据业务需求，可能需要从SAP服务器、日志、数据库、API、在线存储库或web等来源收集数据。像Selenium这样的网页抓取工具可以在相对较短的时间内抓取大量数据，如文本和图像。</p><p id="3e82" class="pw-post-body-paragraph jj jk hi jm b jn kj jp jq jr kk jt ju kl la jx jy kn lb kb kc kp lc kf kg je hb bi translated">Selenium是一个开源的基于网络的自动化工具。硒主要用于工业测试，但也可用于刮网。我们会使用Chrome浏览器，但是你可以在任何浏览器上尝试，几乎是一样的。[5]我们通过以下步骤报废了:</p><ul class=""><li id="5e73" class="kh ki hi jm b jn kj jr kk kl km kn ko kp kq je lo ks kt ku bi translated">搜索带有给定标签集的文章的URL，只捕获与领域相关的文章。</li><li id="f6b0" class="kh ki hi jm b jn lp jr lq kl lr kn ls kp lt je lo ks kt ku bi translated">从每个网页中删除有用的数据。</li><li id="194e" class="kh ki hi jm b jn lp jr lq kl lr kn ls kp lt je lo ks kt ku bi translated">将抓取的文章数据保存在json对象中。</li></ul><p id="7094" class="pw-post-body-paragraph jj jk hi jm b jn kj jp jq jr kk jt ju kl la jx jy kn lb kb kc kp lc kf kg je hb bi translated"><strong class="jm hj"> 6 .预处理</strong></p><p id="f447" class="pw-post-body-paragraph jj jk hi jm b jn kj jp jq jr kk jt ju kl la jx jy kn lb kb kc kp lc kf kg je hb bi translated">自然语言预处理的步骤是将每个句子转换成等价的处理过的单词表示[1]、[2]、[7]、[8]。</p><p id="871a" class="pw-post-body-paragraph jj jk hi jm b jn kj jp jq jr kk jt ju kl la jx jy kn lb kb kc kp lc kf kg je hb bi translated">用于处理每个单词的技术有:</p><ol class=""><li id="7e57" class="kh ki hi jm b jn kj jr kk kl km kn ko kp kq je kr ks kt ku bi translated">标点去除:<em class="jl">'。",?~!&lt; @#$% &amp; *) </em></li><li id="b504" class="kh ki hi jm b jn lp jr lq kl lr kn ls kp lt je kr ks kt ku bi translated">空格删除:<em class="jl"> \n \t \a </em></li><li id="5f48" class="kh ki hi jm b jn lp jr lq kl lr kn ls kp lt je kr ks kt ku bi translated">非Ascii字符:<em class="jl">非键盘，表情符号</em></li><li id="445c" class="kh ki hi jm b jn lp jr lq kl lr kn ls kp lt je kr ks kt ku bi translated">标记化:<em class="jl">'你好'，'世界'</em></li><li id="7a10" class="kh ki hi jm b jn lp jr lq kl lr kn ls kp lt je kr ks kt ku bi translated">数字转换:<em class="jl"> 1 </em>到<em class="jl">‘一’</em></li><li id="c495" class="kh ki hi jm b jn lp jr lq kl lr kn ls kp lt je kr ks kt ku bi translated">停用词移除:<em class="jl">是，是，是</em></li><li id="4bc5" class="kh ki hi jm b jn lp jr lq kl lr kn ls kp lt je kr ks kt ku bi translated">拼写更正:<em class="jl"> thro，teling，forgt </em></li><li id="5001" class="kh ki hi jm b jn lp jr lq kl lr kn ls kp lt je kr ks kt ku bi translated">分词:<em class="jl"> haveto，whynot </em></li><li id="c88a" class="kh ki hi jm b jn lp jr lq kl lr kn ls kp lt je kr ks kt ku bi translated">词汇化:<em class="jl">老鼠</em>到<em class="jl">老鼠</em></li><li id="8503" class="kh ki hi jm b jn lp jr lq kl lr kn ls kp lt je kr ks kt ku bi translated">扩展缩写:<em class="jl">我已经，不会</em></li><li id="bd53" class="kh ki hi jm b jn lp jr lq kl lr kn ls kp lt je kr ks kt ku bi translated">缩放:<em class="jl">【1，90，99】</em>到<em class="jl">【0.1，0.9，0.99】</em></li></ol><p id="c8fa" class="pw-post-body-paragraph jj jk hi jm b jn kj jp jq jr kk jt ju kl la jx jy kn lb kb kc kp lc kf kg je hb bi translated">文本数据不适合输入到ML模型中，所以我们使用Glove和doc2vec，结合通过text_to_sequence方法从<em class="jl">Keras</em>tokenizer获得的序列。</p><p id="64a0" class="pw-post-body-paragraph jj jk hi jm b jn kj jp jq jr kk jt ju kl la jx jy kn lb kb kc kp lc kf kg je hb bi translated"><strong class="jm hj"> 8。特征提取</strong></p><figure class="kw kx ky kz fd ij er es paragraph-image"><div class="er es lu"><img src="../Images/ca45cc10330262833486f3d255d56e39.png" data-original-src="https://miro.medium.com/v2/resize:fit:574/format:webp/1*EWehL7fHJ9DyzhnHOeSEhA.png"/></div></figure><p id="cddb" class="pw-post-body-paragraph jj jk hi jm b jn kj jp jq jr kk jt ju kl la jx jy kn lb kb kc kp lc kf kg je hb bi translated">概括了问题的长度后，我们剩下的是包含大量相关信息(或多或少)的长向量。由于长度与vocab的大小成正比，正如<em class="jl"> Zip定律</em>【10】，【11】中提到的，所以只提取感兴趣的特征是至关重要的。我们尝试了PCA和LDA特征提取[12]。单词嵌入也有帮助，最终得到23个顶级特征应用ML算法。多于或少于23个特征会导致我们模型的性能降低。这就是为什么我们只捕捉与这组功能最相关的信息。降维还有助于可视化顶层数据组件，以便更好地理解，如图3所示。为了从博客文章的文本数据中提取特征，我们使用了doc2vec，它能够为相应的文档(一篇完整的文章)生成一个向量。我们使用RFE和chi2，最终根据特性的重要性对其进行排序。</p><p id="03a8" class="pw-post-body-paragraph jj jk hi jm b jn kj jp jq jr kk jt ju kl la jx jy kn lb kb kc kp lc kf kg je hb bi translated"><strong class="jm hj"> 9。推荐型号</strong></p><p id="98fd" class="pw-post-body-paragraph jj jk hi jm b jn kj jp jq jr kk jt ju kl la jx jy kn lb kb kc kp lc kf kg je hb bi translated">我们尝试了几种方法和组合来得出最终的结论。但是，所有的预处理步骤都是相同的。对于回归任务和关键字预测任务，预处理是不同的。</p><p id="a37f" class="pw-post-body-paragraph jj jk hi jm b jn kj jp jq jr kk jt ju kl la jx jy kn lb kb kc kp lc kf kg je hb bi translated"><strong class="jm hj"> 9.1掌声预测</strong></p><p id="cd43" class="pw-post-body-paragraph jj jk hi jm b jn kj jp jq jr kk jt ju kl la jx jy kn lb kb kc kp lc kf kg je hb bi translated">我们已经使用线性回归对数据进行了回归，我们还建议使用KNN在向量空间中找到与我们的测试文档最接近的相似数据点。回归给出了MSE，即我们计算了预测结果与实际地面真实结果的偏差。这是为了得到每个文档的鼓掌系数。我们得到的初始MSE大约是13000，这在使用Doc2vec作为特性时是很大的。使用KNN回归，我们将能够将MSE进一步降低到大约4000，精确度为37%。为此，我们有大约2345篇中型文章。</p><p id="ff73" class="pw-post-body-paragraph jj jk hi jm b jn kj jp jq jr kk jt ju kl la jx jy kn lb kb kc kp lc kf kg je hb bi translated">我们稍微修改了我们的任务，从对掌声的回归到流行度分数预测，因为我们无法进一步降低mse。</p><figure class="kw kx ky kz fd ij er es paragraph-image"><div class="er es lv"><img src="../Images/31ac1e45cb8c9d9719c140e0b377026f.png" data-original-src="https://miro.medium.com/v2/resize:fit:376/format:webp/1*Fumq7aBEyPwsxDkqtZeldA.png"/></div></figure><p id="9629" class="pw-post-body-paragraph jj jk hi jm b jn kj jp jq jr kk jt ju kl la jx jy kn lb kb kc kp lc kf kg je hb bi translated">我们试图删除更多的数据。因此，最终的数据集大小现在是7421篇文章。我们更新了1-5范围内的标签值，其中1表示最不受欢迎，5表示最受欢迎。分数分配是在掌声计数的帮助下完成的。因此，这就变成了一个有五个类别的多标签分类任务，其中我们能够得到48%的准确率。对于流行、不流行和流行的二元分类任务，其中我们为低于50的一些掌声分配了不流行的标签，否则我们能够获得94%的准确度。</p><ul class=""><li id="bc20" class="kh ki hi jm b jn kj jr kk kl km kn ko kp kq je lo ks kt ku bi translated">在使用线性回归和knn的掌声预测中，我们能够减少大约4000 mse的损失。</li><li id="230c" class="kh ki hi jm b jn lp jr lq kl lr kn ls kp lt je lo ks kt ku bi translated">这仍然是巨大的！对吗？因此，我们稍微修改了任务，以获得给定文章的流行度分数预测。我们将掌声分为五个等级(1-5)。</li><li id="1890" class="kh ki hi jm b jn lp jr lq kl lr kn ls kp lt je lo ks kt ku bi translated">然后，我们进一步尝试通过仅分配两个标签0和1来分别表示流行或不流行。</li></ul><p id="f26c" class="pw-post-body-paragraph jj jk hi jm b jn kj jp jq jr kk jt ju kl la jx jy kn lb kb kc kp lc kf kg je hb bi translated"><strong class="jm hj"> 9.2关键短语提取</strong></p><figure class="kw kx ky kz fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lw"><img src="../Images/c505d8b3020befee31434e24320cd53f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o5AtjJdXygL0VcmPeIZc9Q.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">生物标记方案</figcaption></figure><p id="8eda" class="pw-post-body-paragraph jj jk hi jm b jn kj jp jq jr kk jt ju kl la jx jy kn lb kb kc kp lc kf kg je hb bi translated">9.2.1深度学习模型</p><p id="18b6" class="pw-post-body-paragraph jj jk hi jm b jn kj jp jq jr kk jt ju kl la jx jy kn lb kb kc kp lc kf kg je hb bi translated">深度学习已经被证明可以解决很多难题。我们已经计划使用像RoBERTa这样的深度学习模型来获得优化的结果，用于我们对文章受欢迎与否的模型最终预测。我们计划使用生物标签来表示每个文档，以便提取关键短语。这是一种常见的格式，类似的自然语言处理任务，如NER。然后使用深度神经网络来预测作为标签的生物标签。</p><figure class="kw kx ky kz fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lx"><img src="../Images/4a28a4a81c5d046f920bd7ba8a3b1519.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UYB5yOF75m5dH_NPLPVj0g.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">深度学习模型(最佳)</figcaption></figure><p id="e130" class="pw-post-body-paragraph jj jk hi jm b jn kj jp jq jr kk jt ju kl la jx jy kn lb kb kc kp lc kf kg je hb bi translated"><strong class="jm hj"> 10。性能提升</strong></p><p id="4646" class="pw-post-body-paragraph jj jk hi jm b jn kj jp jq jr kk jt ju kl la jx jy kn lb kb kc kp lc kf kg je hb bi translated"><em class="jl">是什么提高了我们的绩效，为什么？</em></p><ol class=""><li id="0a4f" class="kh ki hi jm b jn kj jr kk kl km kn ko kp kq je kr ks kt ku bi translated">TfIdf:性能优于doc2vec，因为它捕获了次线性关系。</li><li id="c42b" class="kh ki hi jm b jn lp jr lq kl lr kn ls kp lt je kr ks kt ku bi translated">停用词:在我们的例子中，停用词毫无价值，因为它们在每个文档中都经常出现，只是误导了分类。</li><li id="16c8" class="kh ki hi jm b jn lp jr lq kl lr kn ls kp lt je kr ks kt ku bi translated">降维是有效的:我们的向量表示有很多特征，将这些特征输入模型会增加时间并隐藏重要信息。</li><li id="798d" class="kh ki hi jm b jn lp jr lq kl lr kn ls kp lt je kr ks kt ku bi translated">添加特性:选中的单词嵌入为我们提供了23个足够的特性。添加或删除功能会降低性能，因为相关信息会受到损害。</li><li id="8003" class="kh ki hi jm b jn lp jr lq kl lr kn ls kp lt je kr ks kt ku bi translated">缩放特征有助于获得更好的准确性，尤其是在svm的情况下。</li><li id="ac92" class="kh ki hi jm b jn lp jr lq kl lr kn ls kp lt je kr ks kt ku bi translated">Smote: Smote有助于解决数据不平衡问题。这反过来有助于提高性能。</li><li id="6e13" class="kh ki hi jm b jn lp jr lq kl lr kn ls kp lt je kr ks kt ku bi translated">转换任务:将掌声预测的任务转换为1-5的分数分类。因为分类模型能够获得比回归模型的最佳拟合线更好的决策边界。</li></ol><figure class="kw kx ky kz fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ly"><img src="../Images/9013848ae19b36ce807a881ecd3a0947.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TTiPSMY4BHaqPi34FOB6yw.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">模型架构和背景故事</figcaption></figure><p id="44a0" class="pw-post-body-paragraph jj jk hi jm b jn kj jp jq jr kk jt ju kl la jx jy kn lb kb kc kp lc kf kg je hb bi translated"><em class="jl">什么没有奏效，为什么？</em></p><ol class=""><li id="ac85" class="kh ki hi jm b jn kj jr kk kl km kn ko kp kq je kr ks kt ku bi translated">拼写纠正:大多数问题没有任何拼写错误。假设用户知道该语言。</li><li id="6c68" class="kh ki hi jm b jn lp jr lq kl lr kn ls kp lt je kr ks kt ku bi translated">缩放:问题的矢量表示已经被缩放。进一步扩展不再有帮助。</li><li id="315d" class="kh ki hi jm b jn lp jr lq kl lr kn ls kp lt je kr ks kt ku bi translated">所有嵌入:嵌入通常捕获大部分信息。组合gensim嵌入并不能解决问题。</li><li id="d6a0" class="kh ki hi jm b jn lp jr lq kl lr kn ls kp lt je kr ks kt ku bi translated">添加特性:选中的单词嵌入为我们提供了23个足够的特性。添加或删除功能会降低性能，因为相关信息会受到损害。</li><li id="5233" class="kh ki hi jm b jn lp jr lq kl lr kn ls kp lt je kr ks kt ku bi translated">减少向量大小:它改善了训练时间，但代价是降低了性能。</li><li id="3c21" class="kh ki hi jm b jn lp jr lq kl lr kn ls kp lt je kr ks kt ku bi translated">增加时期:增加doc2vec训练的时期不能给出任何更好的特性。</li><li id="000a" class="kh ki hi jm b jn lp jr lq kl lr kn ls kp lt je kr ks kt ku bi translated">变化回归:将简单回归改为lasso，ridge aur elastic未能提供更好的性能。</li><li id="65d3" class="kh ki hi jm b jn lp jr lq kl lr kn ls kp lt je kr ks kt ku bi translated">超参数调优:由于数据本身是有偏差的，所以超参数未能在很大程度上提高性能。</li></ol><p id="9b02" class="pw-post-body-paragraph jj jk hi jm b jn kj jp jq jr kk jt ju kl la jx jy kn lb kb kc kp lc kf kg je hb bi translated"><strong class="jm hj"> 11。结果</strong></p><p id="5937" class="pw-post-body-paragraph jj jk hi jm b jn kj jp jq jr kk jt ju kl la jx jy kn lb kb kc kp lc kf kg je hb bi translated">对于回归任务，我们使用线性回归来绘制线性决策边界，并估计新文章的掌声。此外，我们建议在文档相似性方面使用knn，以在多维向量空间中找到与新文档最近的k个文档，并取这些文档片段的平均值。优化超参数显示了很大的改进。我们正在为这两个任务规划特定于任务的微调。</p><p id="b19c" class="pw-post-body-paragraph jj jk hi jm b jn kj jp jq jr kk jt ju kl la jx jy kn lb kb kc kp lc kf kg je hb bi translated"><strong class="jm hj"> 11.1掌声预测</strong></p><figure class="kw kx ky kz fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lz"><img src="../Images/a9dc60f4ca47595e832c7d35ed0699f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*46xSibCcBBLu6dEthfzBdA.png"/></div></div></figure><p id="33fd" class="pw-post-body-paragraph jj jk hi jm b jn kj jp jq jr kk jt ju kl la jx jy kn lb kb kc kp lc kf kg je hb bi translated">这些结果是在模型经过严格的特定于任务的微调后获得的。内核、激活、深度、平滑参数、迭代次数、过拟合和欠拟合正则化子是几个例子。</p><figure class="kw kx ky kz fd ij er es paragraph-image"><div class="er es ma"><img src="../Images/9833e0e025adb6be4c35bc98815b3048.png" data-original-src="https://miro.medium.com/v2/resize:fit:808/format:webp/1*2JqtwKrKyeK6FgAOQDAlvw.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">掌声预测表演</figcaption></figure><ul class=""><li id="549d" class="kh ki hi jm b jn kj jr kk kl km kn ko kp kq je lo ks kt ku bi translated">在文章中加入作者、阅读时间、图片数量等特征后，我们能够减少mse。</li><li id="73a3" class="kh ki hi jm b jn lp jr lq kl lr kn ls kp lt je lo ks kt ku bi translated">在多类任务中，我们将能够获得0.48的精度。</li><li id="d5ba" class="kh ki hi jm b jn lp jr lq kl lr kn ls kp lt je lo ks kt ku bi translated">在流行度任务中，我们得到的最终最佳准确率是0.94。</li><li id="3af3" class="kh ki hi jm b jn lp jr lq kl lr kn ls kp lt je lo ks kt ku bi translated">损失和准确性线性地依赖于数据量。</li><li id="2e24" class="kh ki hi jm b jn lp jr lq kl lr kn ls kp lt je lo ks kt ku bi translated">拥有多种方法使我们的应用能够接触到更广泛的受众，因为并不是每个人都希望获得更详细的结果。</li></ul><p id="b0a7" class="pw-post-body-paragraph jj jk hi jm b jn kj jp jq jr kk jt ju kl la jx jy kn lb kb kc kp lc kf kg je hb bi translated"><strong class="jm hj"> 11.2关键短语提取</strong></p><figure class="kw kx ky kz fd ij er es paragraph-image"><div class="er es mb"><img src="../Images/83808327c66ff0de9b3409802d355cc6.png" data-original-src="https://miro.medium.com/v2/resize:fit:852/format:webp/1*uh-tawS0hMXh2XNbG1OpdA.png"/></div></figure><p id="109b" class="pw-post-body-paragraph jj jk hi jm b jn kj jp jq jr kk jt ju kl la jx jy kn lb kb kc kp lc kf kg je hb bi translated">对于关键短语抽取任务，我们初始化了主题级关键短语抽取模型，并使用spacy进行预处理。关键短语候选选择作为名词和形容词的序列出现(即`(名词|形容词)* `)。然后使用随机游走算法进行候选加权。最后，提取N个最佳关键短语，即得分最高的候选短语作为(关键短语，得分)元组。</p><figure class="kw kx ky kz fd ij er es paragraph-image"><div class="er es mc"><img src="../Images/6c5fe15916f9d3ebb41ca42af2fb5864.png" data-original-src="https://miro.medium.com/v2/resize:fit:608/format:webp/1*FZZkX2Z-yGBOcKTbqrgfmA.png"/></div></figure><p id="aefa" class="pw-post-body-paragraph jj jk hi jm b jn kj jp jq jr kk jt ju kl la jx jy kn lb kb kc kp lc kf kg je hb bi translated">深度学习有它自己的好处。它有时可能过拟合，但严格的微调给了我们有希望的结果。对于关键短语提取，在tfidf嵌入上训练的双向LSTM产生了有希望的结果。这项任务非常不平衡，因此我们报告了基于f1分数的指标。</p><p id="9b74" class="pw-post-body-paragraph jj jk hi jm b jn kj jp jq jr kk jt ju kl la jx jy kn lb kb kc kp lc kf kg je hb bi translated">12。用户界面</p><p id="d61c" class="pw-post-body-paragraph jj jk hi jm b jn kj jp jq jr kk jt ju kl la jx jy kn lb kb kc kp lc kf kg je hb bi translated">我们制作了一个基于HTML、python、flask和JQuery的交互式web应用程序，使用ajax API调用从性能最佳的模型集合中检索top k文档。它有两种操作模式，即文本和音频(7)。</p><figure class="kw kx ky kz fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es md"><img src="../Images/e37ba97578c17efde74c9ecfa3925eeb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*MBEiXa-JlSfEYYqs"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">音频和文本输入/输出的用户界面</figcaption></figure><p id="8c62" class="pw-post-body-paragraph jj jk hi jm b jn kj jp jq jr kk jt ju kl la jx jy kn lb kb kc kp lc kf kg je hb bi translated">文本:从键盘输入</p><figure class="kw kx ky kz fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es me"><img src="../Images/70d693a148073809149ac65964979bbb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*n-uuG3zTZ51Fg42C.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">音频接口的代码片段</figcaption></figure><ul class=""><li id="1cab" class="kh ki hi jm b jn kj jr kk kl km kn ko kp kq je lo ks kt ku bi translated">音频:通过默认麦克风和扬声器与web应用程序进行语音交互。用户可以在web应用程序屏幕中看到前5个结果，并允许应用程序将k个结果存储在“temp.txt”文件中以供以后参考。图6和图7分别显示了为查询“我们在板球中的表现”和“罗纳尔多”创建的web应用程序的用户界面。</li><li id="a9cb" class="kh ki hi jm b jn lp jr lq kl lr kn ls kp lt je lo ks kt ku bi translated">TTS是一个很好的工具来改善你的用户体验的影响，这可以通过以下步骤整合到你的界面中。</li></ul><p id="575f" class="pw-post-body-paragraph jj jk hi jm b jn kj jp jq jr kk jt ju kl la jx jy kn lb kb kc kp lc kf kg je hb bi translated">15。结论</p><p id="2d77" class="pw-post-body-paragraph jj jk hi jm b jn kj jp jq jr kk jt ju kl la jx jy kn lb kb kc kp lc kf kg je hb bi translated">我们的目标是为初露头角的研究人员提供端到端的解决方案，让他们写出成功的文章。该系统将接受文本形式的输入，并根据当前趋势给出作者是否达标。深度学习有它自己的好处。它有时可能过拟合，但严格的微调给了我们有希望的结果。对于关键短语提取，在tfidf嵌入上训练的双向LSTM产生了有希望的结果。这项任务非常不平衡，因此我们报告了基于f1分数的指标。</p><p id="3547" class="pw-post-body-paragraph jj jk hi jm b jn kj jp jq jr kk jt ju kl la jx jy kn lb kb kc kp lc kf kg je hb bi translated"><strong class="jm hj"> 14。未来工作</strong></p><p id="5760" class="pw-post-body-paragraph jj jk hi jm b jn kj jp jq jr kk jt ju kl la jx jy kn lb kb kc kp lc kf kg je hb bi translated">这项任务的关键问题是数据不是线性可分的，它有很多重叠。因此，如果我们去寻找一般的文章，而不是特定领域的媒体博客，这将是更有益的。另一个问题是，数据集高度偏向于claps 0，1，因为具有良好claps计数的文章非常少。我们最初建议用KNN来预测拍手的次数，但是在超参数调整和特征工程之后，我们仍然没有得到任何更好的mse。在掌声回归中，我们计划加入其他具有更大权重的特征，如出版日期、作者姓名等。我们将考虑使用深度学习模型来捕捉嵌入的上下文的上下文化单词嵌入。</p><h1 id="93b0" class="mf mg hi bd mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc bi translated"><strong class="ak"> 15。作者投稿</strong></h1><p id="b5a8" class="pw-post-body-paragraph jj jk hi jm b jn nd jp jq jr ne jt ju kl nf jx jy kn ng kb kc kp nh kf kg je hb bi translated">克里希纳·亚达夫(MT19039) [ <a class="ae ni" href="https://www.linkedin.com/in/krishna1432/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a></p><ol class=""><li id="1084" class="kh ki hi jm b jn kj jr kk kl km kn ko kp kq je kr ks kt ku bi translated">数据清理和预处理</li><li id="3c6f" class="kh ki hi jm b jn lp jr lq kl lr kn ls kp lt je kr ks kt ku bi translated">数据注释</li><li id="826a" class="kh ki hi jm b jn lp jr lq kl lr kn ls kp lt je kr ks kt ku bi translated">数据分析和可视化</li><li id="1e93" class="kh ki hi jm b jn lp jr lq kl lr kn ls kp lt je kr ks kt ku bi translated">关键短语提取</li><li id="0d9b" class="kh ki hi jm b jn lp jr lq kl lr kn ls kp lt je kr ks kt ku bi translated">基线结果</li><li id="d1ef" class="kh ki hi jm b jn lp jr lq kl lr kn ls kp lt je kr ks kt ku bi translated">深度学习模型</li><li id="cc0a" class="kh ki hi jm b jn lp jr lq kl lr kn ls kp lt je kr ks kt ku bi translated">分析和结论</li></ol><p id="69a7" class="pw-post-body-paragraph jj jk hi jm b jn kj jp jq jr kk jt ju kl la jx jy kn lb kb kc kp lc kf kg je hb bi translated">拉克希亚·乔杜里(MT19067) [ <a class="ae ni" href="https://www.linkedin.com/in/lakshya-choudhary-7b160612a/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a> ]</p><ol class=""><li id="dec2" class="kh ki hi jm b jn kj jr kk kl km kn ko kp kq je kr ks kt ku bi translated">数据爬虫</li><li id="bbaf" class="kh ki hi jm b jn lp jr lq kl lr kn ls kp lt je kr ks kt ku bi translated">数据注释</li><li id="87d4" class="kh ki hi jm b jn lp jr lq kl lr kn ls kp lt je kr ks kt ku bi translated">特征选择</li><li id="3398" class="kh ki hi jm b jn lp jr lq kl lr kn ls kp lt je kr ks kt ku bi translated">左后KNN |参数调谐</li><li id="7359" class="kh ki hi jm b jn lp jr lq kl lr kn ls kp lt je kr ks kt ku bi translated">基线结果</li><li id="4df8" class="kh ki hi jm b jn lp jr lq kl lr kn ls kp lt je kr ks kt ku bi translated">微调的ML模型</li><li id="acc9" class="kh ki hi jm b jn lp jr lq kl lr kn ls kp lt je kr ks kt ku bi translated">分析和结论</li></ol><h1 id="d41a" class="mf mg hi bd mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc bi translated">参考</h1><p id="a059" class="pw-post-body-paragraph jj jk hi jm b jn nd jp jq jr ne jt ju kl nf jx jy kn ng kb kc kp nh kf kg je hb bi translated">[1]<a class="ae ni" href="https://github.com/boudinfl/pke." rel="noopener ugc nofollow" target="_blank">https://github.com/boudinfl/pke.</a></p><p id="c9fe" class="pw-post-body-paragraph jj jk hi jm b jn kj jp jq jr kk jt ju kl la jx jy kn lb kb kc kp lc kf kg je hb bi translated">[2]<a class="ae ni" href="https://arxiv.org/abs/1810.04805." rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1810.04805.</a></p><p id="d131" class="pw-post-body-paragraph jj jk hi jm b jn kj jp jq jr kk jt ju kl la jx jy kn lb kb kc kp lc kf kg je hb bi translated">[3] Z. Liu，X. Lv，K. Liu，S. Shi，《与其他文本分类方法的比较研究》，<em class="jl">第二届教育技术与计算机科学国际研讨会，2010 </em>，2010年，第1卷，第219–222页，doi: 10.1109/ETCS.2010.248</p><p id="6b25" class="pw-post-body-paragraph jj jk hi jm b jn kj jp jq jr kk jt ju kl la jx jy kn lb kb kc kp lc kf kg je hb bi translated">[4]https://monkeylearn.com/keyword-extraction/.<a class="ae ni" href="https://monkeylearn.com/keyword-extraction/." rel="noopener ugc nofollow" target="_blank"/></p><p id="e214" class="pw-post-body-paragraph jj jk hi jm b jn kj jp jq jr kk jt ju kl la jx jy kn lb kb kc kp lc kf kg je hb bi translated">[5]<a class="ae ni" href="https://www.analyticsvidhya.com/blog/2020/08/web-scraping-selenium-with-python/." rel="noopener ugc nofollow" target="_blank">https://www . analyticsvidhya . com/blog/2020/08/we B- scraping-selenium-with-python/。</a></p><p id="4799" class="pw-post-body-paragraph jj jk hi jm b jn kj jp jq jr kk jt ju kl la jx jy kn lb kb kc kp lc kf kg je hb bi translated">[6] M. S. Phyu和K. T. Nwet，“缅甸文本分类的联合深度学习模型研究”，载于<em class="jl"> 2020年IEEE计算机应用会议，ICCA 2020 </em>，2020年2月，doi:10.1109/icca 49400 . 2020 . 9022809</p><p id="7c36" class="pw-post-body-paragraph jj jk hi jm b jn kj jp jq jr kk jt ju kl la jx jy kn lb kb kc kp lc kf kg je hb bi translated">[7]毕，梁，唐，杨，“软件体系结构中文本分析技术的系统映射研究”，<em class="jl">。Softw。</em>，第144卷，8月号，2018年第533–558页，doi: 10.1016/j.jss.2018.07.055。</p><p id="29e7" class="pw-post-body-paragraph jj jk hi jm b jn kj jp jq jr kk jt ju kl la jx jy kn lb kb kc kp lc kf kg je hb bi translated">[8] Sahrawat D .等人(2020)使用语境化嵌入将关键短语提取作为序列标记。载于:Jose J .等人编的《信息检索进展》。ECIR 2020。计算机科学讲义，第12036卷。斯普林格，查姆。<a class="ae ni" href="https://doi.org/10.1007/978-3-030-45442-5_41." rel="noopener ugc nofollow" target="_blank">https://doi.org/10.1007/978-3-030-45442-5_41.</a></p><p id="6bac" class="pw-post-body-paragraph jj jk hi jm b jn kj jp jq jr kk jt ju kl la jx jy kn lb kb kc kp lc kf kg je hb bi translated">[9]<a class="ae ni" href="https://towardsdatascience.com/extracting-keyphrases-from-text-rake-and-gensim-in-python-eefd0fad582f." rel="noopener" target="_blank">https://towardsdatascience . com/extracting-key phrases-from-text-rake-and-gensim-in-python-eefd 0 fad 582 f。</a></p><p id="1557" class="pw-post-body-paragraph jj jk hi jm b jn kj jp jq jr kk jt ju kl la jx jy kn lb kb kc kp lc kf kg je hb bi translated">[10] S. T. Piantadosi，《自然语言中的Zipf词频定律:评论与未来方向》，<em class="jl"> Psychon。公牛。修订版</em>，第21卷，第5期，第1112–1130页，2014年10月，doi:10.3758/s 13423–014–0585–6。</p><p id="9b1e" class="pw-post-body-paragraph jj jk hi jm b jn kj jp jq jr kk jt ju kl la jx jy kn lb kb kc kp lc kf kg je hb bi translated">[11] L. Adamic，B. H.-声门计量法和undefined 2002，“齐夫定律和互联网。”访问时间:2020年5月13日。【在线】。可用:<a class="ae ni" href="http://www.ram-verlag.de." rel="noopener ugc nofollow" target="_blank">http://www . ram-verlag . de .</a></p><p id="1c18" class="pw-post-body-paragraph jj jk hi jm b jn kj jp jq jr kk jt ju kl la jx jy kn lb kb kc kp lc kf kg je hb bi translated">[12]闫，郭，兰，程，“短文本的双主题模式”，<em class="jl">中国英语学习网，2013 — Proc .22日国际。糖膏剂环球网</em>，2013年，第1445–1455页，doi:10.1145/24888851386</p><h1 id="c8b7" class="mf mg hi bd mh mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc bi translated"><strong class="ak"> <em class="jf">鸣谢</em> </strong></h1><blockquote class="jg jh ji"><p id="11c0" class="jj jk jl jm b jn kj jp jq jr kk jt ju jv la jx jy jz lb kb kc kd lc kf kg je hb bi translated">特别感谢教授和助教们</p><p id="a701" class="jj jk jl jm b jn kj jp jq jr kk jt ju jv la jx jy jz lb kb kc kd lc kf kg je hb bi translated"><strong class="jm hj"> <em class="hi">导师- </em> </strong> <em class="hi">坦莫博士</em> <a class="ae ni" href="https://www.iiitd.ac.in/tanmoy" rel="noopener ugc nofollow" target="_blank"> <em class="hi">网站</em></a><em class="hi">】</em><a class="ae ni" href="https://www.linkedin.com/in/tanmoy-chakraborty-89553324/" rel="noopener ugc nofollow" target="_blank"><em class="hi">领英</em></a><em class="hi">】</em><a class="ae ni" href="https://www.facebook.com/chak.tanmoy" rel="noopener ugc nofollow" target="_blank"><em class="hi">脸书</em></a><em class="hi">】</em></p><p id="8845" class="jj jk jl jm b jn kj jp jq jr kk jt ju jv la jx jy jz lb kb kc kd lc kf kg je hb bi translated"><strong class="jm hj"> <em class="hi">导读</em> </strong> - <a class="ae ni" href="https://www.linkedin.com/in/pragya-srivastava-742896136/" rel="noopener ugc nofollow" target="_blank">普拉加·斯里瓦斯塔瓦(M.Tech，IIITD) </a> [ <a class="ae ni" href="https://www.linkedin.com/in/pragya-srivastava-742896136/" rel="noopener ugc nofollow" target="_blank">领英</a> ]</p><p id="ebb5" class="jj jk jl jm b jn kj jp jq jr kk jt ju jv la jx jy jz lb kb kc kd lc kf kg je hb bi translated">所有助教:查维·贾恩，尼兰·迪万，希夫·库马尔·盖洛特，康查·维韦克·雷迪，什卡·辛格。</p></blockquote></div></div>    
</body>
</html>