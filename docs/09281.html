<html>
<head>
<title>Super Resolution and its Recent Advances in Deep Learning — Part 2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">超分辨率及其在深度学习中的最新进展——第二部分</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/super-resolution-and-its-recent-advances-in-deep-learning-part-2-5868965f89e5?source=collection_archive---------13-----------------------#2020-08-31">https://medium.com/analytics-vidhya/super-resolution-and-its-recent-advances-in-deep-learning-part-2-5868965f89e5?source=collection_archive---------13-----------------------#2020-08-31</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="5945" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi jd translated">嗨，欢迎来到超分辨率系列的第二部分(你可以在最后找到其余部分的链接)。现在我们已经有了什么是超分辨率的背景，也对深度学习的概念有了一点介绍，我们就不多说了，来深入挖掘更有趣的概念吧！</p><p id="9980" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">正如我们在早期文章中讨论的那样，我们的深度学习模型需要一个包含低分辨率(LR)图像和高分辨率(HR)图像的数据集来调整其参数，并使其适应这种特定的图像环境。通常有两种方法来创建这样的数据集-监督和非监督超分辨率。在本文中，我们将详细讨论监督超分辨率。</p><h1 id="7f5f" class="jm jn hi bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated">监督超分辨率</h1><p id="49ae" class="pw-post-body-paragraph if ig hi ih b ii kk ik il im kl io ip iq km is it iu kn iw ix iy ko ja jb jc hb bi translated">在这种训练深度学习框架的方法中，在训练数据中考虑LR和HR图像的映射对，即，我们教导网络HR图像是特定LR对应物(输入:x)的预期超分辨率图像(网络输出:f(x))。</p><h2 id="d56e" class="kp jn hi bd jo kq kr ks js kt ku kv jw iq kw kx ka iu ky kz ke iy la lb ki lc bi translated">深度学习——一个背景</h2><p id="c61c" class="pw-post-body-paragraph if ig hi ih b ii kk ik il im kl io ip iq km is it iu kn iw ix iy ko ja jb jc hb bi translated">从之前的<a class="ae ld" href="https://arxiv.org/abs/1902.06068?utm_campaign=Dynamically%20Typed&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank">帖</a>中，我们明白了深度学习学习一个复变函数方程的目的。现在，让我们看看它实际上是如何执行的。神经元是神经网络的最小组成部分，是该领域的心脏和灵魂。单个神经元对输入(<strong class="ih hj"> X </strong>)和赋予它的权重(<strong class="ih hj"> W </strong>)应用两个函数，并返回结果输出。权重和输入之间的点积是第一个函数。为了将非线性引入到模型中，将合适的激活函数应用于先前的点积，该点积成为神经元的最终输出。</p><figure class="lf lg lh li fd lj er es paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="er es le"><img src="../Images/36911d95911d297095d683a04544a286.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*6Nnm4kLvV2oPUJI5oZBQqQ.gif"/></div></div><figcaption class="lq lr et er es ls lt bd b be z dx translated">神经元的工作；来源:<a class="ae ld" href="https://machinelearningknowledge.ai/animated-explanation-of-feed-forward-neural-network-architecture/" rel="noopener ugc nofollow" target="_blank">神经网络</a></figcaption></figure><p id="9c5c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这种神经元的不同层一个接一个地堆叠形成了神经网络。一层中每个神经元的输出被发送到下一层中的每个神经元，然后乘以相应的权重(在下面的动画中，想象神经元通过网络中每个权重/边的输出)。简单来说，一个神经网络的整套权值类似于我们普遍关心的精确估计<em class="lu">的一个简单线性方程组情形<em class="lu"/><strong class="ih hj"><em class="lu">f(x)= ax+b</em></strong>中类似<strong class="ih hj">a，b </strong></em> 的系数。</p><figure class="lf lg lh li fd lj er es paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="er es lv"><img src="../Images/a2bd95fe82f3aff95edf723c1a7eea36.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*KJu3jZwHxsCbc3RTfTBPkQ.gif"/></div></div><figcaption class="lq lr et er es ls lt bd b be z dx translated">可视化简单的猫/狗分类器；来源:<a class="ae ld" href="https://towardsdatascience.com/how-to-build-your-own-neural-network-from-scratch-in-python-68998a08e4f6" rel="noopener" target="_blank">文章</a></figcaption></figure><p id="0ec3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae ld" href="https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53#:~:text=A%20Convolutional%20Neural%20Network%20(ConvNet,differentiate%20one%20from%20the%20other." rel="noopener" target="_blank">卷积神经网络</a> (CNN)是一种典型地用于图像环境中的神经网络。虽然图像只是像素强度数字的数组，但是独立处理这些值意味着我们忽略了它们之间的空间相关性。CNN就是为了解决这个问题而设计的。</p><blockquote class="lw lx ly"><p id="c7c7" class="if ig lu ih b ii ij ik il im in io ip lz ir is it ma iv iw ix mb iz ja jb jc hb bi translated">研究人员已经提出了各种基于CNN的监督模型，这些模型可能是独一无二的，但它们本质上有一些主干组件，如<strong class="ih hj">模型框架、上采样方法、网络设计和学习策略</strong>。</p></blockquote><p id="f3dc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为什么我们不深入研究一下它们是如何工作的呢？</p><h2 id="5450" class="kp jn hi bd jo kq kr ks js kt ku kv jw iq kw kx ka iu ky kz ke iy la lb ki lc bi translated">模型框架</h2><p id="fd0c" class="pw-post-body-paragraph if ig hi ih b ii kk ik il im kl io ip iq km is it iu kn iw ix iy ko ja jb jc hb bi translated">请记住，我们超分辨率图像的第一个想法是增加图像的尺寸，然后用有意义的像素强度填充空白空间。类似地，在CNN网络架构(神经元层的堆叠)中的某一点，很少层被分配用于对输入图像进行上采样以匹配预期输出图像的尺寸。这可以通过下列不同方式实现:</p><p id="1250" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="lu">(一)预上采样超分辨率</em> </strong></p><figure class="lf lg lh li fd lj er es paragraph-image"><div class="er es mc"><img src="../Images/e0f11d8b262a7a7087459d916c1639cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1272/format:webp/1*sym9HwWHwqZrecMC9ST06A.png"/></div><figcaption class="lq lr et er es ls lt bd b be z dx translated">预上采样SR；资料来源:<a class="ae ld" href="https://arxiv.org/abs/1902.06068?utm_campaign=Dynamically%20Typed&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> DeepSR调查</a></figcaption></figure><p id="4f49" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在我们之前的帖子中，我们已经看到简单的插值方法产生了粗糙纹理的模糊图像。那么，我们为什么不在这个插值图像的基础上建立一个网络，并训练我们的网络参数(权重),使其接近原始HR图像呢？这种方法最初是最流行的框架之一，因为困难的上采样操作是在开始时完成的。但是，事实证明，这种惯例往往会带来副作用，如模糊和噪声放大。此外，我们所有的卷积网络层都处理巨大的上采样图像矩阵，这使得我们的计算效率低下。</p><p id="404e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="lu">(二)后上采样超分辨率</em> </strong></p><figure class="lf lg lh li fd lj er es paragraph-image"><div class="er es md"><img src="../Images/35a0c97cab4fa6d50b27e1bed5190cc7.png" data-original-src="https://miro.medium.com/v2/resize:fit:988/format:webp/1*UrDKmdNM20EdSxthDWzyZg.png"/></div><figcaption class="lq lr et er es ls lt bd b be z dx translated">后上采样SR；来源:<a class="ae ld" href="https://arxiv.org/abs/1902.06068?utm_campaign=Dynamically%20Typed&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> DeepSR调查</a></figcaption></figure><p id="0f55" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因为我们发现预上采样的计算开销很大，所以让我们试着将它移到最后，这意味着在最终上采样之前，图像的所有特征都在卷积层中提取。随着计算和空间复杂性的降低，这种方法变得非常流行。</p><p id="56ca" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="lu">(三)渐进上采样超分辨率</em> </strong></p><figure class="lf lg lh li fd lj er es paragraph-image"><div class="er es me"><img src="../Images/e82966655350c96b62011be59be59f28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1378/format:webp/1*4Tqcsrm3VNeVl19n1J8cPw.png"/></div><figcaption class="lq lr et er es ls lt bd b be z dx translated">渐进上采样；资料来源:<a class="ae ld" href="https://arxiv.org/abs/1902.06068?utm_campaign=Dynamically%20Typed&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> DeepSR调查</a></figcaption></figure><p id="9b51" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最简单的上采样因子之一是2x(即30x30像素到60x60像素)。但是，假设我们对实现更高的系数感兴趣，如4倍、8倍等。在这种情况下，网络发现在一个步骤中调整其参数以对整个图像进行上采样是复杂的。让我们通过在不同点添加较小的上采样层来简化网络的任务。如果我们希望生成8x超分辨率图像，渐进增加2x上采样层比最终增加8x层更可取。然而，这种方法需要先进的训练策略和复杂的多阶段模型设计，以确保整体训练的稳定性。</p><p id="5c90" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="lu">(四)迭代上下采样超分辨率</em> </strong></p><figure class="lf lg lh li fd lj er es paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="er es mf"><img src="../Images/8aa08b4b5ba61929adc18d599456c6e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*si_EMHAIh5_zmxPnAq972g.png"/></div></div><figcaption class="lq lr et er es ls lt bd b be z dx translated"><em class="mg">迭代上下采样SR；</em>资料来源:<a class="ae ld" href="https://arxiv.org/abs/1902.06068?utm_campaign=Dynamically%20Typed&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> DeepSR调查</a></figcaption></figure><p id="1ff9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是该领域中最近引入的框架之一，被认为具有很大的探索范围和潜力。从图中可以清楚地看到，这种方法在网络的各个部分迭代地增加了上采样和下采样层。研究人员观察到，这种框架更准确地捕捉LR和HR图像之间的相互依赖性，从而提供更高质量的重建结果。像<a class="ae ld" href="https://arxiv.org/abs/1803.02735" rel="noopener ugc nofollow" target="_blank"> DBPN </a>、<a class="ae ld" href="https://arxiv.org/abs/1903.09814" rel="noopener ugc nofollow" target="_blank"> SRFBN </a>、<a class="ae ld" href="https://arxiv.org/abs/1903.10128" rel="noopener ugc nofollow" target="_blank"> RBPN </a>等网络已经试验了这个框架。</p><h2 id="7a16" class="kp jn hi bd jo kq kr ks js kt ku kv jw iq kw kx ka iu ky kz ke iy la lb ki lc bi translated">上采样方法</h2><p id="a5c5" class="pw-post-body-paragraph if ig hi ih b ii kk ik il im kl io ip iq km is it iu kn iw ix iy ko ja jb jc hb bi translated">我们已经看到了在CNN中引入上采样层的不同方法。但是这一层到底是怎么设计的呢？</p><p id="6eda" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="lu">(一)基于插值的上采样</em> </strong></p><p id="997e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这些是我在第<a class="ae ld" rel="noopener" href="/analytics-vidhya/super-resolution-and-its-recent-advances-in-deep-learning-part-1-c6d927914d32">部分</a>中介绍的传统插值方法，即最近邻上采样、双线性插值和双三次插值，并且易于实施。在这些方法中，最近邻插值法是最快的，但会产生意外的块状伪像。另一方面，双三次生成相对平滑的图像，但计算速度较慢。</p><p id="240c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然而，这些传统算法是基于图像自身的像素强度，并没有捕捉其他有用的图像信息。它们通常倾向于引入噪声放大和模糊结果。因此，研究人员已经从基于插值的方法升级到可学习的上采样图层。</p><p id="2990" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="lu">(二)基于学习的上采样</em> </strong></p><ul class=""><li id="4975" class="mh mi hi ih b ii ij im in iq mj iu mk iy ml jc mm mn mo mp bi translated"><strong class="ih hj"> <em class="lu">转置卷积层:</em> </strong></li></ul><figure class="lf lg lh li fd lj er es paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="er es mq"><img src="../Images/89f5843959a1fd4493792ac636dd6d8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1300/format:webp/1*_iBw3MKWxfPfAoTjFYSvtg.png"/></div></div><figcaption class="lq lr et er es ls lt bd b be z dx translated"><strong class="bd jo">转置卷积层</strong>。蓝框是输入，绿框是卷积输出；来源:<a class="ae ld" href="https://arxiv.org/abs/1902.06068?utm_campaign=Dynamically%20Typed&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> DeepSR调查</a></figcaption></figure><p id="5e12" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">考虑这样一种情况，我们希望将图像从3×3像素上采样到6×6像素。首先，我们以交替的方式添加零值像素，它们由白色方框表示。然后，我们用零值填充图像的边界，以便于对该图像应用卷积。卷积阶段中的3×3绿色矩阵(也称为内核)是应用于图像矩阵顶部的过滤器，该图像矩阵只是数字的点积[来自具有3×3内核矩阵的图像点积的3×3矩阵给出1×1最终绿色框。这在整个图像上移动以创建最终输出。检查这个<a class="ae ld" href="https://towardsdatascience.com/types-of-convolutions-in-deep-learning-717013397f4d" rel="noopener" target="_blank">动画</a>以获得更好的可视化效果】。卷积后的最终图像矩阵现在是6×6。但是在少数情况下，这一层往往会产生棋盘状的工件图案。</p><ul class=""><li id="32dd" class="mh mi hi ih b ii ij im in iq mj iu mk iy ml jc mm mn mo mp bi translated"><strong class="ih hj"> <em class="lu">子像素层:</em> </strong></li></ul><figure class="lf lg lh li fd lj er es paragraph-image"><div class="er es mr"><img src="../Images/e63d5f5e560d3f6450ceef1d7cff77d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/format:webp/1*_h8XqxEA0Iw4Dlfw0NxotA.png"/></div><figcaption class="lq lr et er es ls lt bd b be z dx translated"><strong class="bd jo">子像素层。</strong>蓝色方框为输入，其他颜色的方框表示不同的卷积运算和不同的输出特征图；资料来源:<a class="ae ld" href="https://arxiv.org/abs/1902.06068?utm_campaign=Dynamically%20Typed&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> DeepSR调查</a></figcaption></figure><p id="cccb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这种情况下，我们不是交替地添加零值和使用一个滤波器/内核，而是尝试在边界填零后使用4个内核进行2x上采样。在整形阶段，来自相应的4个点积中的每一个的1×1输出被组合在一起以形成2×2矩阵，该矩阵成为最终上采样输出的一部分。类似于前一种情况，这些滤波器在整个矩阵上移动，以获得多个这样的2×2矩阵。与转置卷积层相比，子像素层提供了更多的上下文信息，有助于生成更真实的细节。</p><h1 id="2ce1" class="jm jn hi bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated">参考</h1><ul class=""><li id="d5f2" class="mh mi hi ih b ii kk im kl iq ms iu mt iy mu jc mm mn mo mp bi translated"><a class="ae ld" href="https://arxiv.org/abs/1902.06068?utm_campaign=Dynamically%20Typed&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank">图像超分辨率的深度学习:综述</a></li><li id="7575" class="mh mi hi ih b ii mv im mw iq mx iu my iy mz jc mm mn mo mp bi translated"><a class="ae ld" href="https://towardsdatascience.com/types-of-convolutions-in-deep-learning-717013397f4d" rel="noopener" target="_blank">深度学习中不同类型卷积的介绍</a></li></ul><h2 id="d9d1" class="kp jn hi bd jo kq kr ks js kt ku kv jw iq kw kx ka iu ky kz ke iy la lb ki lc bi translated">所有零件的链接:</h2><ul class=""><li id="0d32" class="mh mi hi ih b ii kk im kl iq ms iu mt iy mu jc mm mn mo mp bi translated"><a class="ae ld" rel="noopener" href="/analytics-vidhya/super-resolution-and-its-recent-advances-in-deep-learning-part-1-c6d927914d32">超分辨率及其在深度学习方面的最新进展——第一部分</a></li><li id="4052" class="mh mi hi ih b ii mv im mw iq mx iu my iy mz jc mm mn mo mp bi translated"><a class="ae ld" rel="noopener" href="/@rapole.shivani.reddy.98/super-resolution-and-its-recent-advances-in-deep-learning-part-2-5868965f89e5">超分辨率及其在深度学习领域的最新进展——第二部分</a></li></ul><p id="f5e0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="lu">敬请期待，更多部分即将推出:)</em></p></div></div>    
</body>
</html>