<html>
<head>
<title>APS component failure classification in Scania Trucks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">斯堪尼亚卡车APS部件故障分类</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/aps-component-failure-classification-in-scania-trucks-a971fcf71846?source=collection_archive---------11-----------------------#2020-10-06">https://medium.com/analytics-vidhya/aps-component-failure-classification-in-scania-trucks-a971fcf71846?source=collection_archive---------11-----------------------#2020-10-06</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/f03b7ee862dcb6b8246f3ce4f8e7d9e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*khDzHqnIVy3Hn_mb.jpg"/></div></div></figure><h1 id="8add" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">商业问题</h1><blockquote class="jo jp jq"><p id="1dbd" class="jr js jt ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">该数据集包括从日常使用的重型斯堪尼亚卡车上收集的数据。重点介绍的系统是空气压力系统(APS ),它产生压缩空气，用于卡车的各种功能，如制动和换档。数据集的正类由APS系统特定组件的组件故障组成。负类包括与APS无关的部件出现故障的卡车。这些数据由专家选择的所有可用数据的子集组成。</p><p id="8f16" class="jr js jt ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">在这项工作中，我们使用了由斯堪尼亚CV AB在UCI机器学习知识库上发布的数据集——斯堪尼亚卡车数据集上的<a class="ae kq" href="https://archive.ics.uci.edu/ml/datasets/APS+Failure+at+Scania+Trucks" rel="noopener ugc nofollow" target="_blank"> APS故障。</a></p><p id="be90" class="jr js jt ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">我们在这项工作中的目标是预测卡车是否需要维修，并最大限度地降低以下相关成本:</p><p id="e6ff" class="jr js jt ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">I .机械师进行不必要的检查。(Cost _ 1:10 $)-如果负标注点被分类为正标注点。</p><p id="23ca" class="jr js jt ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">二。错过一辆有故障的卡车，这可能会导致故障。(Cost _ 2:500 $)-如果正标记点被标记为负。</p></blockquote><figure class="ks kt ku kv fd ij er es paragraph-image"><div class="er es kr"><img src="../Images/c04ae7f831f381a904fb893317013f59.png" data-original-src="https://miro.medium.com/v2/resize:fit:662/format:webp/1*mX7kMXM5xZSVibcberVbPw.png"/></div><figcaption class="kw kx et er es ky kz bd b be z dx translated">错误分类的成本度量</figcaption></figure><h1 id="b78b" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated"><strong class="ak">数据集详情</strong></h1><blockquote class="jo jp jq"><p id="8191" class="jr js jt ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">训练集总共包含60000个样本，其中59000个属于负类，1000个属于正类。测试集包含16000个例子。</p><p id="b52f" class="jr js jt ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">属性数量:171</p><p id="097f" class="jr js jt ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">属性信息:出于专有原因，数据的属性名称已被匿名化。它由单个数字计数器和直方图组成，直方图由不同条件的仓组成。通常，直方图在每一端都有开放式条件。例如，如果我们测量环境温度‘T ’,那么直方图可以用4个箱来定义，其中:</p><p id="e77f" class="jr js jt ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">bin 1收集温度T &lt; -20</p><p id="1aae" class="jr js jt ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">bin 2 collect values for temperature T &gt; = -20和T &lt; 0</p><p id="040c" class="jr js jt ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">bin 3 collect values for temperature T &gt; = 0和T &lt; 20</p><p id="631b" class="jr js jt ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">bin 4 collect values for temper</p><p id="89b9" class="jr js jt ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated">The attributes are as follows: class, then anonymized operational data. The operational data have an identifier and a bin id, like ‘Identifier_Bin’. In total there are 171 attributes, of which 7 are histogram variables. Missing values are denoted by ‘na’.</p></blockquote><pre class="ks kt ku kv fd la lb lc ld aw le bi"><span id="6917" class="lf ir hi lb b fi lg lh l li lj">class,aa_000,ab_000,ac_000,ad_000,ae_000,.......,ee_007,ee_008,ee_009,ef_000,eg_000<br/>neg,76698,na,2130706438,280,0,.....,339156,157956,73224,0,0,0<br/>neg,33058,na,0,na,0,0,.....,133654,81140,97576,1500,0,0<br/>neg,41040,na,228,100,0,0....,409564,320746,158022,95128,514,0,0<br/>.<br/>.<br/>pos,153204,0,182,na,0,0,......,22472,34362,0,0,0,0,0<br/>.<br/>.</span></pre><p id="ff4e" class="pw-post-body-paragraph jr js hi ju b jv jw jx jy jz ka kb kc lk ke kf kg ll ki kj kk lm km kn ko kp hb bi translated">So the dataset is highly imbalanced. And also most of the columns found to (from visual inspection) have missing data values.</p><h1 id="7ba6" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated"><strong class="ak">的值，将现实世界的问题映射到ML问题</strong></h1><p id="b0b7" class="pw-post-body-paragraph jr js hi ju b jv ln jx jy jz lo kb kc lk lp kf kg ll lq kj kk lm lr kn ko kp hb bi translated">我们可以利用机器学习在这个数据集的基础上建立一个分类模型，以满足我们预测卡车是否需要维修的目标。</p><ul class=""><li id="5014" class="ls lt hi ju b jv jw jz ka lk lu ll lv lm lw kp lx ly lz ma bi translated">这是一个二元分类问题。对于给定的数据点，我们需要预测故障的发生是否是由于APS。</li><li id="a9cf" class="ls lt hi ju b jv mb jz mc lk md ll me lm mf kp lx ly lz ma bi translated">这里我们需要最小化错误分类的成本，也就是说，我们的模型应该有很低的假阴性和假阳性。</li><li id="9658" class="ls lt hi ju b jv mb jz mc lk md ll me lm mf kp lx ly lz ma bi translated">回忆分数或F1分数或成本函数(总成本=成本1 *无功能+成本2 *无功能)</li><li id="bf10" class="ls lt hi ju b jv mb jz mc lk md ll me lm mf kp lx ly lz ma bi translated">错误分类的代价应该被最小化，特别是假阴性(Cost_2= 500)</li><li id="fd7d" class="ls lt hi ju b jv mb jz mc lk md ll me lm mf kp lx ly lz ma bi translated">没有严格的延迟问题</li></ul><h1 id="9876" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated"><strong class="ak">现有方法</strong></h1><p id="1015" class="pw-post-body-paragraph jr js hi ju b jv ln jx jy jz lo kb kc lk lp kf kg ll lq kj kk lm lr kn ko kp hb bi translated">[1].<a class="ae kq" href="https://www.researchgate.net/publication/330854331_An_Empirical_Comparison_of_Missing_Value_Imputation_Techniques_on_APS_Failure_Prediction" rel="noopener ugc nofollow" target="_blank">APS故障预测中缺失值插补技术的实证比较</a>:</p><ul class=""><li id="4ddb" class="ls lt hi ju b jv jw jz ka lk lu ll lv lm lw kp lx ly lz ma bi translated"><strong class="ju hj"> <em class="jt">缺失值</em> </strong> <em class="jt">:删除数据缺失50%以上的特征(8个)。并使用5种不同的技术处理缺失值:I)通过链式方程的多重插补ii)软插补iii)期望最大化和iv)均值插补v)基于奇异值分解的方法(SVD方法)并形成数据集的5种不同变化。</em></li><li id="3ace" class="ls lt hi ju b jv mb jz mc lk md ll me lm mf kp lx ly lz ma bi translated"><em class="jt">数据集的这些变化中的每一个都用于基于5种算法来训练模型:I)朴素贝叶斯ii) KNN iii)随机森林iv)支持向量机和v)梯度提升树。</em></li><li id="341e" class="ls lt hi ju b jv mb jz mc lk md ll me lm mf kp lx ly lz ma bi translated"><strong class="ju hj"> <em class="jt">不平衡数据</em> </strong> <em class="jt">:平衡数据集(使用随机欠采样)，发现所有模型的表现分别优于不平衡数据。</em></li><li id="1b75" class="ls lt hi ju b jv mb jz mc lk md ll me lm mf kp lx ly lz ma bi translated"><em class="jt">在这项工作中，模型的性能是根据假阴性的数量进行评估的，而不是根据成本最小化方程。</em></li><li id="d82f" class="ls lt hi ju b jv mb jz mc lk md ll me lm mf kp lx ly lz ma bi translated"><em class="jt">所有成本中最小的是12210(鼠标插补和随机森林分类器)。</em></li></ul><p id="dd30" class="pw-post-body-paragraph jr js hi ju b jv jw jx jy jz ka kb kc lk ke kf kg ll ki kj kk lm km kn ko kp hb bi translated">[2].<a class="ae kq" rel="noopener" href="/analytics-vidhya/aps-failure-at-scania-trucks-data-set-1eb97b12812">斯堪尼亚卡车数据集的APS故障:预测卡车是否需要维修</a></p><ul class=""><li id="537d" class="ls lt hi ju b jv jw jz ka lk lu ll lv lm lw kp lx ly lz ma bi translated"><strong class="ju hj"> <em class="jt">缺失值</em> </strong> <em class="jt">:使用均值、中值和众数进行估算，形成数据集的3个变量。</em></li><li id="aaa2" class="ls lt hi ju b jv mb jz mc lk md ll me lm mf kp lx ly lz ma bi translated"><strong class="ju hj"> <em class="jt">不平衡数据</em> </strong> <em class="jt">:使用SMOTE对数据进行过采样，处理不平衡数据</em></li><li id="eea5" class="ls lt hi ju b jv mb jz mc lk md ll me lm mf kp lx ly lz ma bi translated"><em class="jt">使用逻辑回归、线性SVM、随机森林和GBDT算法训练这些数据集。</em></li><li id="3777" class="ls lt hi ju b jv mb jz mc lk md ll me lm mf kp lx ly lz ma bi translated">在所有用中间值估算数据训练的GBDT中，表现良好，成本最低8660。</li></ul><p id="0b60" class="pw-post-body-paragraph jr js hi ju b jv jw jx jy jz ka kb kc lk ke kf kg ll ki kj kk lm km kn ko kp hb bi translated">[3].<a class="ae kq" rel="noopener" href="/swlh/aps-failure-at-scania-trucks-203975cdc2dd">斯堪尼亚卡车的APS故障</a></p><ul class=""><li id="f284" class="ls lt hi ju b jv jw jz ka lk lu ll lv lm lw kp lx ly lz ma bi translated"><strong class="ju hj"> <em class="jt">缺失值</em> </strong> <em class="jt">:删除缺失数据值超过70%的特征。在剩余的160个特征中，使用平均值、中值和众数估算缺失值，形成数据集的3个变体。</em></li><li id="b876" class="ls lt hi ju b jv mb jz mc lk md ll me lm mf kp lx ly lz ma bi translated"><strong class="ju hj"> <em class="jt">不平衡数据</em> </strong> <em class="jt"> : SMOTE用于向上采样正类数据点。</em></li><li id="7b22" class="ls lt hi ju b jv mb jz mc lk md ll me lm mf kp lx ly lz ma bi translated">使用逻辑回归、随机森林和GBDT算法训练这些数据集。在每种情况下，超参数都是通过以“F1”分数为目标进行调整来选择的。甚至为较低成本函数值选择了优化的阈值。</li><li id="0c2f" class="ls lt hi ju b jv mb jz mc lk md ll me lm mf kp lx ly lz ma bi translated"><em class="jt">用中位数估算数据训练的随机森林表现良好，成本最低9920。</em></li><li id="d091" class="ls lt hi ju b jv mb jz mc lk md ll me lm mf kp lx ly lz ma bi translated"><strong class="ju hj"> <em class="jt">特征工程技术</em> </strong> <em class="jt"> : i)创建缺失的指示器特征ii)使用PCA降低尺寸。即使这些数据变化表现相对较好。</em></li></ul><blockquote class="jo jp jq"><p id="a3f9" class="jr js jt ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated"><em class="hi">由于平衡数据在之前的案例中给出了更好的结果，我们将通过上采样或过采样仅尝试平衡数据的案例。我们将使用SMOTE对正类数据点进行上采样。</em></p><p id="7df4" class="jr js jt ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp hb bi translated"><em class="hi">为了处理缺失值问题，我们可以尝试一些基于模型的估算器或多变量估算器，以及中值估算器(因为这在之前的工作中取得了更好的结果)。</em></p></blockquote><h1 id="37e2" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated"><strong class="ak"> EDA </strong></h1><figure class="ks kt ku kv fd ij"><div class="bz dy l di"><div class="mg mh l"/></div></figure><p id="f240" class="pw-post-body-paragraph jr js hi ju b jv jw jx jy jz ka kb kc lk ke kf kg ll ki kj kk lm km kn ko kp hb bi translated">从EDA分析来看，很明显，训练和测试数据集都非常不平衡，并且包含许多缺失值。我们观察到大多数列和行都有缺失值:在训练数据中，171(98.83%)列中的169列和60000(99.02%)行中的59409行包含缺失值。如果我们删除所有缺失值或缺失值百分比较高的行/列，我们可能会丢失大量信息和数据，这可能会使模型过拟合。</p><p id="a577" class="pw-post-body-paragraph jr js hi ju b jv jw jx jy jz ka kb kc lk ke kf kg ll ki kj kk lm km kn ko kp hb bi translated">因此，我们不是删除行/列，而是尝试用不同的插补技术对数据进行插补。</p><h1 id="546a" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated"><strong class="ak">第一次切割解决方案</strong></h1><ul class=""><li id="2fd3" class="ls lt hi ju b jv ln jz lo lk mi ll mj lm mk kp lx ly lz ma bi translated">我们会将可用的训练数据集(60000个点)分成训练(51000个点)和cv(9000个点)数据，其Y值的分层比例为85:15。测试数据集是16000个点。</li><li id="eaa3" class="ls lt hi ju b jv mb jz mc lk md ll me lm mf kp lx ly lz ma bi translated">我们将使用sklearn 的<a class="ae kq" href="https://scikit-learn.org/stable/modules/g enerated/sklearn.preprocessing.StandardScaler.html" rel="noopener ugc nofollow" target="_blank"> StandardScaler通过移除平均值并缩放至单位方差来标准化特征。我们将使用训练数据来训练标准缩放器模型。然后，我们将使用经过训练的StandardScaler模型转换所有3个训练、cv和测试数据集。</a></li><li id="7cb9" class="ls lt hi ju b jv mb jz mc lk md ll me lm mf kp lx ly lz ma bi translated">除了中位数输入器，我们还可以使用sklearn的KNNImputer和IterativeImputer。我们还可以尝试实现2个基于模型的估算器。因此，我们将能够用这些插补技术形成数据集的5种不同变化。</li><li id="af68" class="ls lt hi ju b jv mb jz mc lk md ll me lm mf kp lx ly lz ma bi translated">我们还可以创建具有布尔/二进制值的新要素，以指示数据集中是否存在缺失值。我们会将这些缺失的指标列连接到数据集的5个变体中的每一个，这又形成了数据集的5个变体。通过这样做，我们将能够保存这些值丢失的信息。</li><li id="e592" class="ls lt hi ju b jv mb jz mc lk md ll me lm mf kp lx ly lz ma bi translated">我们将通过使用分类算法(如朴素贝叶斯、逻辑回归、线性SVM、随机森林、Adaboost和XGBoost算法)训练不同的模型，来试验这10种不同的数据。</li><li id="9257" class="ls lt hi ju b jv mb jz mc lk md ll me lm mf kp lx ly lz ma bi translated">在使用训练数据集训练这些模型之前，我们将使用<a class="ae kq" href="https://en.wikipedia.org/wiki/Oversampling_and_undersampling_in_data_analysis#SMOTE" rel="noopener ugc nofollow" target="_blank">合成少数过采样技术SMOTE </a>对它们进行上采样。</li></ul><h1 id="fe3f" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated"><strong class="ak">处理缺失数据——插补</strong></h1><figure class="ks kt ku kv fd ij"><div class="bz dy l di"><div class="mg mh l"/></div></figure><h2 id="3eef" class="lf ir hi bd is ml mm mn iw mo mp mq ja lk mr ms je ll mt mu ji lm mv mw jm mx bi translated">1.中位数估算值</h2><p id="80f5" class="pw-post-body-paragraph jr js hi ju b jv ln jx jy jz lo kb kc lk lp kf kg ll lq kj kk lm lr kn ko kp hb bi translated">我们使用sklearn 的<a class="ae kq" href="https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html" rel="noopener ugc nofollow" target="_blank">simple imputr实现，策略参数选择为“中值”。在这种插补技术中，每一列中的缺失值由一个常数值(相应列的中值)进行插补。</a></p><h2 id="3276" class="lf ir hi bd is ml mm mn iw mo mp mq ja lk mr ms je ll mt mu ji lm mv mw jm mx bi translated">2.KNNImputer</h2><p id="96a5" class="pw-post-body-paragraph jr js hi ju b jv ln jx jy jz lo kb kc lk lp kf kg ll lq kj kk lm lr kn ko kp hb bi translated">我们使用sklearn 的<a class="ae kq" href="https://scikit-learn.org/stable/modules/generated/sklearn.impute.KNNImputer.html" rel="noopener ugc nofollow" target="_blank"> KNNImputer实现，将权重参数作为“距离”，并将n_neighbors参数值保留为默认值(即5)。在这种插补技术中，使用训练集中找到的n_neighbors(= 5)个最近邻的加权平均值来插补每个样本的缺失值。</a></p><h2 id="ea2a" class="lf ir hi bd is ml mm mn iw mo mp mq ja lk mr ms je ll mt mu ji lm mv mw jm mx bi translated">3.带贝叶斯岭回归器的迭代估算器</h2><p id="955e" class="pw-post-body-paragraph jr js hi ju b jv ln jx jy jz lo kb kc lk lp kf kg ll lq kj kk lm lr kn ko kp hb bi translated">我们使用sklearn 的<a class="ae kq" href="https://scikit-learn.org/stable/modules/generated/sklearn.impute.IterativeImputer.html" rel="noopener ugc nofollow" target="_blank">迭代输入器实现，将估计值留给sklearn的BayesianRidge </a>回归模型的默认对象。在这种插补技术中，缺失值用模型的预测值进行插补，该模型用其他特征的值进行训练。</p><p id="7386" class="pw-post-body-paragraph jr js hi ju b jv jw jx jy jz ka kb kc lk ke kf kg ll ki kj kk lm km kn ko kp hb bi translated">迭代估算器是一种多变量估算器，通过所有其他要素来估算每个要素。而简单估算是一个单变量，用于估算要素中缺失的值。</p><h2 id="f23f" class="lf ir hi bd is ml mm mn iw mo mp mq ja lk mr ms je ll mt mu ji lm mv mw jm mx bi translated">4.基于回归模型的插补–RandomForestRegressor(基于监督学习模型的插补)</h2><p id="c77e" class="pw-post-body-paragraph jr js hi ju b jv ln jx jy jz lo kb kc lk lp kf kg ll lq kj kk lm lr kn ko kp hb bi translated">这种基于模型的插补是自动实现的，如下所示:</p><ol class=""><li id="61b4" class="ls lt hi ju b jv jw jz ka lk lu ll lv lm lw kp my ly lz ma bi translated">计算每一列中缺失值的百分比。</li><li id="6c77" class="ls lt hi ju b jv mb jz mc lk md ll me lm mf kp my ly lz ma bi translated">过滤(median_imp_cols)出缺失值百分比小于阈值(这里我们取3%)的列，并使用SimpleImputer对这些具有中值的已过滤列中的缺失值进行估算。</li><li id="ab1c" class="ls lt hi ju b jv mb jz mc lk md ll me lm mf kp my ly lz ma bi translated">缺失值%大于阈值的列(model_imp_cols)将使用监督学习回归模型进行估算。</li><li id="9555" class="ls lt hi ju b jv mb jz mc lk md ll me lm mf kp my ly lz ma bi translated">对于model_imp_cols中的每一列:使用该列的非缺失行(每行包含model_imp_cols之外的列)和作为该列值的目标值来定型回归模型。此列中缺少的值是使用此训练模型的预测值估算的。</li></ol><p id="fa13" class="pw-post-body-paragraph jr js hi ju b jv jw jx jy jz ka kb kc lk ke kf kg ll ki kj kk lm km kn ko kp hb bi translated">由于我们的数据集有很高比例的缺失值，我们在第二步中使用中位数而不是模型来输入缺失值。如果缺失值的比例较小，我们可以直接对所有列使用基于模型的插补。</p><figure class="ks kt ku kv fd ij"><div class="bz dy l di"><div class="mg mh l"/></div></figure><p id="45d0" class="pw-post-body-paragraph jr js hi ju b jv jw jx jy jz ka kb kc lk ke kf kg ll ki kj kk lm km kn ko kp hb bi translated">这里我们使用RandomForestRegressor进行插补。在训练阶段保存的median _ imputer、median_imp_cols和reg_model的值作为转换数据的函数的参数传递。</p><h2 id="d114" class="lf ir hi bd is ml mm mn iw mo mp mq ja lk mr ms je ll mt mu ji lm mv mw jm mx bi translated">5.基于贝叶斯高斯混合模型的插补(基于无监督学习模型的插补)</h2><p id="751e" class="pw-post-body-paragraph jr js hi ju b jv ln jx jy jz lo kb kc lk lp kf kg ll lq kj kk lm lr kn ko kp hb bi translated">参考工作实现了以下模型:<a class="ae kq" href="https://www.researchgate.net/publication/276834803_Missing_Value_Imputation_Based_on_Gaussian_Mixture_Model_for_the_Internet_of_Things" rel="noopener ugc nofollow" target="_blank">基于物联网高斯混合模型的缺失值插补</a>。</p><ol class=""><li id="26ed" class="ls lt hi ju b jv jw jz ka lk lu ll lv lm lw kp my ly lz ma bi translated">过滤没有任何缺失值的行，并使用这些行拟合BayesianGaussianMixture(无监督学习模型)。这里，我们考虑n_components = 5，因此它形成具有5个相应平均值的5个混合成分。</li><li id="11b3" class="ls lt hi ju b jv mb jz mc lk md ll me lm mf kp my ly lz ma bi translated">计算所有行中每一行的所有5个平均值的距离(使用sklearn的nan_euclidean_distances，因为我们的数据包含nan值),并找到每一行的最近平均值。</li><li id="9e64" class="ls lt hi ju b jv mb jz mc lk md ll me lm mf kp my ly lz ma bi translated">用最接近平均值的相应值填充每行的缺失值。</li><li id="d9cd" class="ls lt hi ju b jv mb jz mc lk md ll me lm mf kp my ly lz ma bi translated">初始插补后，使用全部数据来拟合BayesianGaussianMixture模型，并使用其最近平均值的相应值(在该迭代中形成)不断更新缺失值位置处的值。重复这个步骤几次，数据点就可以稳定到最合适的混合成分。</li></ol><figure class="ks kt ku kv fd ij"><div class="bz dy l di"><div class="mg mh l"/></div></figure><p id="7781" class="pw-post-body-paragraph jr js hi ju b jv jw jx jy jz ka kb kc lk ke kf kg ll ki kj kk lm km kn ko kp hb bi translated">参考这篇文章来理解和更好地洞察贝叶斯高斯混合:<a class="ae kq" href="https://towardsdatascience.com/gaussian-mixture-models-explained-6986aaf5a95" rel="noopener" target="_blank">高斯混合模型解释</a>。</p><h2 id="5471" class="lf ir hi bd is ml mm mn iw mo mp mq ja lk mr ms je ll mt mu ji lm mv mw jm mx bi translated">插补方法的质量检查</h2><ul class=""><li id="02d4" class="ls lt hi ju b jv ln jz lo lk mi ll mj lm mk kp lx ly lz ma bi translated">出于质量检查的目的，我们有意将列中的已知值替换为NaN值，并在训练模型的帮助下预测它们。</li><li id="c436" class="ls lt hi ju b jv mb jz mc lk md ll me lm mf kp lx ly lz ma bi translated">然后使用这些已知值和预测值，计算均方误差(作为插补质量的衡量标准)。</li><li id="468a" class="ls lt hi ju b jv mb jz mc lk md ll me lm mf kp lx ly lz ma bi translated">在这个数据集中，有更多的列缺少值，所以只考虑10个随机列进行质量检查。</li></ul><figure class="ks kt ku kv fd ij"><div class="bz dy l di"><div class="mg mh l"/></div></figure><ul class=""><li id="c214" class="ls lt hi ju b jv jw jz ka lk lu ll lv lm lw kp lx ly lz ma bi translated">所有基于模型的估算都比中位数估算产生更小的误差值。</li><li id="06ef" class="ls lt hi ju b jv mb jz mc lk md ll me lm mf kp lx ly lz ma bi translated">KNN估算结果与所有最小均方误差。</li></ul><h2 id="3ced" class="lf ir hi bd is ml mm mn iw mo mp mq ja lk mr ms je ll mt mu ji lm mv mw jm mx bi translated"><strong class="ak">特征工程(缺失指标—特征生成)</strong></h2><p id="93db" class="pw-post-body-paragraph jr js hi ju b jv ln jx jy jz lo kb kc lk lp kf kg ll lq kj kk lm lr kn ko kp hb bi translated">我们使用sklearn 的<a class="ae kq" href="https://scikit-learn.org/stable/modules/generated/sklearn.impute.MissingIndicator.html" rel="noopener ugc nofollow" target="_blank"> MissingIndicator来创建新的特征，其布尔/二进制值指示数据集中缺失值的存在。</a></p><p id="77aa" class="pw-post-body-paragraph jr js hi ju b jv jw jx jy jz ka kb kc lk ke kf kg ll ki kj kk lm km kn ko kp hb bi translated">我们可以用这个数据集连接以上5种不同的数据集，形成另外5种新的数据形式。通过这种方式，我们将能够保存这些值丢失的信息。</p><h1 id="91f5" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated"><strong class="ak">机器学习模型</strong></h1><p id="82d5" class="pw-post-body-paragraph jr js hi ju b jv ln jx jy jz lo kb kc lk lp kf kg ll lq kj kk lm lr kn ko kp hb bi translated">我们将使用以下算法训练模型，使用每个估算数据集，并对所有模型执行超参数调整，以优化结果。</p><p id="db59" class="pw-post-body-paragraph jr js hi ju b jv jw jx jy jz ka kb kc lk ke kf kg ll ki kj kk lm km kn ko kp hb bi translated">在训练之前，使用<a class="ae kq" href="https://imbalanced-learn.org/stable/generated/imblearn.over_sampling.SMOTE.html" rel="noopener ugc nofollow" target="_blank"> SMOTE实施imblearn </a>对训练数据集进行上采样。它从minor类创建合成样本，而不是创建副本。</p><h2 id="d5c4" class="lf ir hi bd is ml mm mn iw mo mp mq ja lk mr ms je ll mt mu ji lm mv mw jm mx bi translated">1.物流回收</h2><p id="15c0" class="pw-post-body-paragraph jr js hi ju b jv ln jx jy jz lo kb kc lk lp kf kg ll lq kj kk lm lr kn ko kp hb bi translated">我们使用了sklearn 的<a class="ae kq" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html" rel="noopener ugc nofollow" target="_blank"> LogisticRegression实现。用于超参数调整的参数分布为:</a></p><pre class="ks kt ku kv fd la lb lc ld aw le bi"><span id="fb6c" class="lf ir hi lb b fi lg lh l li lj">{<br/>  "C" : [10**-4, 10**-3, 10**-2, 10**-1, 1, 10**1, 10**2, 10**3, 10**4],<br/>  "penalty": ['l1', 'l2']<br/>}</span></pre><figure class="ks kt ku kv fd ij"><div class="bz dy l di"><div class="mg mh l"/></div></figure><ul class=""><li id="c74a" class="ls lt hi ju b jv jw jz ka lk lu ll lv lm lw kp lx ly lz ma bi translated">使用<a class="ae kq" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html" rel="noopener ugc nofollow" target="_blank"> sklearn的RandomizedSearchCV </a>对上述参数进行超参数调谐。</li><li id="eb4a" class="ls lt hi ju b jv mb jz mc lk md ll me lm mf kp lx ly lz ma bi translated">并且以优化召回分数为目标来选择最佳参数。</li><li id="c8c9" class="ls lt hi ju b jv mb jz mc lk md ll me lm mf kp lx ly lz ma bi translated">用最佳参数值训练模型后，我们发现如果能减少漏报数量，就有降低成本的余地(成本= fp*10 + fn*500)。</li><li id="6cf8" class="ls lt hi ju b jv mb jz mc lk md ll me lm mf kp lx ly lz ma bi translated">因此，我们通过基于CV数据选择优化的阈值来进一步降低成本值。</li><li id="65c4" class="ls lt hi ju b jv mb jz mc lk md ll me lm mf kp lx ly lz ma bi translated">该模型的性能与基于测试数据的成本值一起报告。在这里，物流对中间估算数据的回归实现了23390的成本值。</li></ul><p id="4ca1" class="pw-post-body-paragraph jr js hi ju b jv jw jx jy jz ka kb kc lk ke kf kg ll ki kj kk lm km kn ko kp hb bi translated">类似地，我们执行了相同的调整步骤，以获得针对所有数据变化的所有以下算法的优化成本值。</p><p id="30e7" class="pw-post-body-paragraph jr js hi ju b jv jw jx jy jz ka kb kc lk ke kf kg ll ki kj kk lm km kn ko kp hb bi translated">你可以在我的<a class="ae kq" href="https://github.com/AkhilPenta/APS-component-failure-classification" rel="noopener ugc nofollow" target="_blank"> Github repo </a>中找到所有的实用函数和其他算法代码实现。</p><h2 id="9e69" class="lf ir hi bd is ml mm mn iw mo mp mq ja lk mr ms je ll mt mu ji lm mv mw jm mx bi translated">2.线性SVC</h2><p id="89db" class="pw-post-body-paragraph jr js hi ju b jv ln jx jy jz lo kb kc lk lp kf kg ll lq kj kk lm lr kn ko kp hb bi translated">我们使用了sklearn 的<a class="ae kq" href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html" rel="noopener ugc nofollow" target="_blank"> LinearSVC实现。用于超参数调整的参数分布为:</a></p><pre class="ks kt ku kv fd la lb lc ld aw le bi"><span id="55f2" class="lf ir hi lb b fi lg lh l li lj">{<br/>  "C" : [10**-4, 10**-3, 10**-2, 10**-1, 1, 10**1, 10**2, 10**3, 10**4],<br/>  "penalty": ['l1', 'l2']<br/>}</span></pre><h2 id="aac2" class="lf ir hi bd is ml mm mn iw mo mp mq ja lk mr ms je ll mt mu ji lm mv mw jm mx bi translated">3.随机森林分类器</h2><p id="ab8e" class="pw-post-body-paragraph jr js hi ju b jv ln jx jy jz lo kb kc lk lp kf kg ll lq kj kk lm lr kn ko kp hb bi translated">我们使用了sklearn 的<a class="ae kq" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html" rel="noopener ugc nofollow" target="_blank"> RandomForestClassifier实现。用于超参数调整的参数分布为:</a></p><pre class="ks kt ku kv fd la lb lc ld aw le bi"><span id="aef3" class="lf ir hi lb b fi lg lh l li lj">{<br/>  "max_depth": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12],<br/>  "n_estimators": [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000],<br/>  "min_samples_split": [2,3,4,5,6,7,8,9,10,11,12],<br/>  "min_samples_leaf": [1,2,3,4,5,6,7,8,9,10,11]<br/>}</span></pre><h2 id="e866" class="lf ir hi bd is ml mm mn iw mo mp mq ja lk mr ms je ll mt mu ji lm mv mw jm mx bi translated">4.XGBClassifier</h2><p id="05d3" class="pw-post-body-paragraph jr js hi ju b jv ln jx jy jz lo kb kc lk lp kf kg ll lq kj kk lm lr kn ko kp hb bi translated">我们使用了<a class="ae kq" href="https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn" rel="noopener ugc nofollow" target="_blank">XGBoost</a>的XGBClassifier实现。用于超参数调整的参数分布为:</p><pre class="ks kt ku kv fd la lb lc ld aw le bi"><span id="aa37" class="lf ir hi lb b fi lg lh l li lj">{<br/>  "learning_rate":[0.01,0.03,0.05,0.1,0.15,0.2],<br/>  "n_estimators":[100, 200, 300, 400, 500, 600, 700, 800, 900, 1000],<br/>  "max_depth":[3,4,5,6,7,8,9,10, 11, 12],<br/>  "colsample_bytree":[0.1,0.3,0.5,1],<br/>  "subsample":[0.1,0.3,0.5,1]<br/>}</span></pre><h2 id="52a7" class="lf ir hi bd is ml mm mn iw mo mp mq ja lk mr ms je ll mt mu ji lm mv mw jm mx bi translated">5.AdaBoost分类器</h2><p id="aa6c" class="pw-post-body-paragraph jr js hi ju b jv ln jx jy jz lo kb kc lk lp kf kg ll lq kj kk lm lr kn ko kp hb bi translated">我们使用<a class="ae kq" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html" rel="noopener ugc nofollow" target="_blank"> AdaBoostClassifier实现sklearn </a>。用于超参数调整的参数分布为:</p><pre class="ks kt ku kv fd la lb lc ld aw le bi"><span id="2ed3" class="lf ir hi lb b fi lg lh l li lj">{<br/>  "n_estimators": [50, 75, 100,150,200,250,400,500],<br/>  "learning_rate":[0.01,0.03, 0.05, 0.075, 0.1, 0.3, 0.5, 0.75, 1],<br/>  "algorithm" : ['SAMME', 'SAMME.R']    <br/>}</span></pre><h2 id="c7c5" class="lf ir hi bd is ml mm mn iw mo mp mq ja lk mr ms je ll mt mu ji lm mv mw jm mx bi translated">6.金属分类器</h2><p id="812a" class="pw-post-body-paragraph jr js hi ju b jv ln jx jy jz lo kb kc lk lp kf kg ll lq kj kk lm lr kn ko kp hb bi translated">这是一个定制的集成分类器模型(参考工作<a class="ae kq" href="https://www.semanticscholar.org/paper/A-Study-of-Meta-Learning-in-Ensemble-Based-Rani-Kumari/449e7116d7e2cff37b4d3b1357a23953231b4709" rel="noopener ugc nofollow" target="_blank">基于集成分类器的元学习研究</a> <a class="ae kq" href="https://www.semanticscholar.org/paper/A-Study-of-Meta-Learning-in-Ensemble-Based-Rani-Kumari/449e7116d7e2cff37b4d3b1357a23953231b4709)" rel="noopener ugc nofollow" target="_blank"> ) </a>如下:</p><ul class=""><li id="cddb" class="ls lt hi ju b jv jw jz ka lk lu ll lv lm lw kp lx ly lz ma bi translated">训练阶段:</li></ul><ol class=""><li id="a6b5" class="ls lt hi ju b jv jw jz ka lk lu ll lv lm lw kp my ly lz ma bi translated">将列车组分成D1和D2(50:50)。</li><li id="b809" class="ls lt hi ju b jv mb jz mc lk md ll me lm mf kp my ly lz ma bi translated">从d1表格k样本D1，d2，d3，… dk。</li><li id="1c92" class="ls lt hi ju b jv mb jz mc lk md ll me lm mf kp my ly lz ma bi translated">创建K个基本分类器模型，并用K个样本中的每一个来训练这些模型中的每一个。</li><li id="9691" class="ls lt hi ju b jv mb jz mc lk md ll me lm mf kp my ly lz ma bi translated">现在把D2传给k个模特。这给了你每个模型对D2的k个预测。</li><li id="ef2d" class="ls lt hi ju b jv mb jz mc lk md ll me lm mf kp my ly lz ma bi translated">使用这些k个预测创建新的数据集，并使用D2的相应目标值在这个新的数据集之上训练元分类器模型。</li></ol><ul class=""><li id="941c" class="ls lt hi ju b jv jw jz ka lk lu ll lv lm lw kp lx ly lz ma bi translated">测试阶段:</li></ul><ol class=""><li id="b02e" class="ls lt hi ju b jv jw jz ka lk lu ll lv lm lw kp my ly lz ma bi translated">将测试传递给k个基础模型中的每一个，并使用这些k个预测创建一个新的数据集。</li><li id="fe61" class="ls lt hi ju b jv mb jz mc lk md ll me lm mf kp my ly lz ma bi translated">将这个新的数据集传递给元模型，这就给出了最终的预测。</li><li id="b3ec" class="ls lt hi ju b jv mb jz mc lk md ll me lm mf kp my ly lz ma bi translated">使用这些最终预测以及测试集的相应目标值来计算模型性能得分。</li></ol><p id="4ee1" class="pw-post-body-paragraph jr js hi ju b jv jw jx jy jz ka kb kc lk ke kf kg ll ki kj kk lm km kn ko kp hb bi translated">在这里，我们调整基本模型的参数数，即k。</p><figure class="ks kt ku kv fd ij"><div class="bz dy l di"><div class="mg mh l"/></div></figure><h1 id="669e" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated"><strong class="ak">车型对比</strong></h1><p id="9446" class="pw-post-body-paragraph jr js hi ju b jv ln jx jy jz lo kb kc lk lp kf kg ll lq kj kk lm lr kn ko kp hb bi translated">这些是用这6种分类算法对前5种数据进行实验后的结果。</p><figure class="ks kt ku kv fd ij er es paragraph-image"><div class="er es mz"><img src="../Images/33aa81d8fdb616ff02bdfcb1b7e6bf34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*KyIZJnhTyFYXD5z8zMaDUQ.png"/></div></figure><ul class=""><li id="a40b" class="ls lt hi ju b jv jw jz ka lk lu ll lv lm lw kp lx ly lz ma bi translated">在这些试验中，RandomForestRegressor用RandomForestClassifier估算数据的成本最低，为9510。</li></ul><figure class="ks kt ku kv fd ij er es paragraph-image"><div class="er es mz"><img src="../Images/1334b44d986a103964eedbdbe76d2629.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*bHzFIUGlbHEe0-6A0Gx2Eg.png"/></div></figure><ul class=""><li id="b61a" class="ls lt hi ju b jv jw jz ka lk lu ll lv lm lw kp lx ly lz ma bi translated">从上面的柱状图可以明显看出，RandomForest和XGBoost分类器的成本值明显较低。</li></ul><p id="68aa" class="pw-post-body-paragraph jr js hi ju b jv jw jx jy jz ka kb kc lk ke kf kg ll ki kj kk lm km kn ko kp hb bi translated">因此，对于后续数据集(与缺失指标连接的估算数据集的5种变体)，我们将仅尝试使用RandomForest和XGBoost分类器。</p><p id="e3dd" class="pw-post-body-paragraph jr js hi ju b jv jw jx jy jz ka kb kc lk ke kf kg ll ki kj kk lm km kn ko kp hb bi translated">这些是所有实验后的结果:</p><figure class="ks kt ku kv fd ij er es paragraph-image"><div class="er es mz"><img src="../Images/e0cedca6df15812a2901a8e64cb89d96.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*FnJt5Vb73XePnpUhhPCNig.png"/></div></figure><ul class=""><li id="b924" class="ls lt hi ju b jv jw jz ka lk lu ll lv lm lw kp lx ly lz ma bi translated">对于与使用RandomForestClassifier训练的缺失指标列连接的BayesianGaussianMixture估算数据，在与缺失指标连接的数据集中获得的最低成本值是10000。</li><li id="683b" class="ls lt hi ju b jv mb jz mc lk md ll me lm mf kp lx ly lz ma bi translated">当比较估算数据集和相同数据集以及连接的指示列的性能时，很明显没有绝对的赢家。</li><li id="cc40" class="ls lt hi ju b jv mb jz mc lk md ll me lm mf kp lx ly lz ma bi translated">因此，性能最佳的模型保持不变，即，用RandomForestRegressor训练的RandomForestClassifier估算的数据的成本值为9510。</li></ul><figure class="ks kt ku kv fd ij er es paragraph-image"><div class="er es mz"><img src="../Images/8416e0b831af049960c2a4069f6f51dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*qL0XfWaK5fPzrWfs8zdVng.png"/></div></figure><ul class=""><li id="41de" class="ls lt hi ju b jv jw jz ka lk lu ll lv lm lw kp lx ly lz ma bi translated">在使用RandomForest和XGBoost分类器进行训练时，估算数据集及其串联的缺失指标列都以相对较小的成本值表现得更好。</li></ul><p id="a70c" class="pw-post-body-paragraph jr js hi ju b jv jw jx jy jz ka kb kc lk ke kf kg ll ki kj kk lm km kn ko kp hb bi translated">从这个实验中得到的关键收获是，所有的插补技术和中值插补技术表现相对更好。因此，对于其他一些包含缺失值的数据集，有可能获得更好的结果。</p><h1 id="3ffd" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">参考</h1><ol class=""><li id="3038" class="ls lt hi ju b jv ln jz lo lk mi ll mj lm mk kp my ly lz ma bi translated"><a class="ae kq" href="https://www.researchgate.net/figure/Overall-workflow_fig1_330854331" rel="noopener ugc nofollow" target="_blank">https://www . researchgate . net/figure/Overall-workflow _ fig 1 _ 330854331</a></li><li id="4778" class="ls lt hi ju b jv mb jz mc lk md ll me lm mf kp my ly lz ma bi translated"><a class="ae kq" rel="noopener" href="/analytics-vidhya/aps-failure-at-scania-trucks-data-set-1eb97b12812">https://medium . com/analytics-vid hya/APS-failure-at-Scania-trucks-data-set-1 EB 97 b 12812</a></li><li id="4c23" class="ls lt hi ju b jv mb jz mc lk md ll me lm mf kp my ly lz ma bi translated"><a class="ae kq" rel="noopener" href="/swlh/aps-failure-at-scania-trucks-203975cdc2dd">https://medium . com/swlh/APS-failure-at-Scania-trucks-203975 CDC 2d</a></li><li id="87f6" class="ls lt hi ju b jv mb jz mc lk md ll me lm mf kp my ly lz ma bi translated"><a class="ae kq" href="https://www.appliedaicourse.com" rel="noopener ugc nofollow" target="_blank">https://www.appliedaicourse.com</a></li><li id="3505" class="ls lt hi ju b jv mb jz mc lk md ll me lm mf kp my ly lz ma bi translated"><a class="ae kq" href="https://wallpapercave.com/w/2GFdZrW" rel="noopener ugc nofollow" target="_blank">https://wallpapercave.com/w/2GFdZrW</a></li></ol><p id="24df" class="pw-post-body-paragraph jr js hi ju b jv jw jx jy jz ka kb kc lk ke kf kg ll ki kj kk lm km kn ko kp hb bi translated"><strong class="ju hj">详细代码参考我的</strong><a class="ae kq" href="https://github.com/AkhilPenta/APS-component-failure-classification" rel="noopener ugc nofollow" target="_blank"><strong class="ju hj">GitHub repo</strong></a><strong class="ju hj">。</strong></p><div class="na nb ez fb nc nd"><a href="https://github.com/AkhilPenta/APS-component-failure-classification" rel="noopener  ugc nofollow" target="_blank"><div class="ne ab dw"><div class="nf ab ng cl cj nh"><h2 class="bd hj fi z dy ni ea eb nj ed ef hh bi translated">AkhilPenta/APS-组件-故障-分类</h2><div class="nk l"><h3 class="bd b fi z dy ni ea eb nj ed ef dx translated">这是一个关于斯堪尼亚卡车APS部件故障分类的端到端案例研究…</h3></div><div class="nl l"><p class="bd b fp z dy ni ea eb nj ed ef dx translated">github.com</p></div></div><div class="nm l"><div class="nn l no np nq nm nr io nd"/></div></div></a></div><p id="fe59" class="pw-post-body-paragraph jr js hi ju b jv jw jx jy jz ka kb kc lk ke kf kg ll ki kj kk lm km kn ko kp hb bi translated"><strong class="ju hj">联系我上</strong><a class="ae kq" href="https://www.linkedin.com/in/akhil-penta-63468511a/" rel="noopener ugc nofollow" target="_blank"><strong class="ju hj">LinkedIn</strong></a><strong class="ju hj"/>🙂<strong class="ju hj">。</strong></p></div></div>    
</body>
</html>