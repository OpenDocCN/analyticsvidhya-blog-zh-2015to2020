<html>
<head>
<title>Handling Out-of-Vocabulary Words in Natural Language Processing based on Context</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于上下文的自然语言处理中未登录词的处理</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/handling-out-of-vocabulary-words-in-natural-language-processing-based-on-context-4bbba16214d5?source=collection_archive---------0-----------------------#2018-10-28">https://medium.com/analytics-vidhya/handling-out-of-vocabulary-words-in-natural-language-processing-based-on-context-4bbba16214d5?source=collection_archive---------0-----------------------#2018-10-28</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="00c6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">单词嵌入通过单词的向量表示来编码单词之间的关系。这些单词向量类似于单词的意思。单词嵌入的局限性在于，它们是通过自然语言模型(word2vec、GloVe等)来学习的，因此，为了进行嵌入，单词必须之前在训练数据中出现过。</p><p id="4c2a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">本文提供了一种方法，可用于处理自然语言处理中的词汇外(OOV)单词。给定一个OOV单词及其所在的句子，语言建模用于对句子中的单词进行排序，并通过与类似句子进行比较来预测该单词的含义。这是一种快速学习词义的优雅方式。</p><h1 id="5c07" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated"><strong class="ak">模型概述</strong></h1><p id="900e" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">该模型被构建为根据OOV单词的上下文来产生词汇表外(OOV)单词的嵌入。这是通过使用具有长短期记忆单元的双向递归神经网络建立的语言模型来完成的。通过预测代替OOV单词的单词，然后取它们的映射单词嵌入的加权平均值，该语言模型用于基于其上下文预测OOV单词的最可能的单词嵌入。这给出了OOV单词的单词嵌入，其在实体识别任务的可用性方面是可靠的，并且其在向量空间中是有意义的表示。</p><p id="b644" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">用于预测OOV单词嵌入的模型包括两个部分:第一步是通过基于训练语料库对模型进行表征、训练和保存来准备模型，第二步是将准备好的模型用于预测嵌入。第一步称为准备步骤，第二步称为嵌入预测步骤。</p><h1 id="3743" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated"><strong class="ak">模型的伪代码</strong></h1><h2 id="532c" class="kg je hi bd jf kh ki kj jj kk kl km jn iq kn ko jr iu kp kq jv iy kr ks jz kt bi translated"><strong class="ak">模型准备</strong></h2><figure class="kv kw kx ky fd kz er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es ku"><img src="../Images/2f2c1d76dfd9b86d3e4f0fc9490317e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xGyYJdWbmRTG5Y18fJ8P-g.png"/></div></div><figcaption class="lg lh et er es li lj bd b be z dx translated">模型准备步骤</figcaption></figure><p id="f946" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如上所示，在模型准备的步骤1中，对大型语料库进行预处理以用于步骤2，在步骤2中，对该语料库进行标记化，并将文本编码为整数。</p><p id="a65d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">步骤2中的记号赋予器用于适应源文本，以开发从单词到唯一整数的映射。然后这些整数可以用来对文本行进行排序。在步骤3.1.1中，使用记号赋予器来检索文本语料库的词汇大小，以定义模型的单词嵌入层。在步骤2.4中，我们准备文本数据的前向和后向序列，其中序列的两个方向都用于基于来自OOV单词的前一个和后一个单词来预测嵌入。然后，序列被分成每个正向和反向序列的输入(X)和输出元素(y ),用于在RNN LSTM模型预测模型上训练它们。正向和反向序列被填充以使所有序列具有相同的长度。</p><p id="5d82" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在步骤3中，我们为每个正向和反向序列定义一个具有3层的模型。第一嵌入层为每个序列创建一个实值向量。第二层是具有设定数量的单元的双向LSTM层，其可以被修剪以最适合训练语料库。输出层是一个密集层，由词汇表中每个单词的一个神经元组成。该层使用SoftMax函数来确保输出被归一化以返回概率。</p><p id="c09a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在步骤4中，前向和后向序列的编码文本被编译成适合各自的rnn。由于网络在技术上用于基于所提供的序列来预测词汇的概率分布，所以我们使用稀疏分类交叉熵损失函数来更新网络上的权重。Adam优化器是梯度下降算法的有效实现，用于跟踪训练的每个时期的准确性。然后保存模型以用于根据正向或反向排序模型返回词汇的概率分布。</p><h2 id="4fad" class="kg je hi bd jf kh ki kj jj kk kl km jn iq kn ko jr iu kp kq jv iy kr ks jz kt bi translated">OOV嵌入预测步骤</h2><figure class="kv kw kx ky fd kz er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es lk"><img src="../Images/bb6f7c462c17425d328e14b459848bf8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2XPDV_kU64cevY53sAnAGg.png"/></div></div><figcaption class="lg lh et er es li lj bd b be z dx translated">预测单词嵌入步骤</figcaption></figure><p id="c3fd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">OOV字嵌入预测步骤比模型准备步骤短。步骤1包括加载运行嵌入预测函数所需的所有模型和参数。在步骤2中，生成序列函数被用作由步骤4的Set嵌入函数调用的函数，以便能够预测在样本文本中代替OOV单词出现的最可能的单词。这些预测用于映射到预测单词的手套向量，并且步骤4函数定义了预测单词嵌入的加权平均值。这种嵌入被分配给我们的预训练模型的词汇。使用这种分配嵌入的方法，使得OOV词将基于其上下文在向量空间中具有合理的位置，即使它最初没有被分配嵌入。</p><h1 id="827e" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">结果和分析</h1><p id="65ac" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">我们可以根据模型处理前后单词的单词嵌入的余弦相似性来分析我们的结果。</p><p id="f578" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">例如，给定一个输入句子:</p><p id="5af1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="ll">‘我在学校玩菲迪奇’</em></p><p id="578f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，只看这句话我们就能看出<em class="ll"> fidditch </em>很可能是一个游戏。让我们看看模型的表现。</p><figure class="kv kw kx ky fd kz er es paragraph-image"><div class="er es lm"><img src="../Images/b3080f36e7f59a1897aa76f4778e0fe2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1110/format:webp/1*xl2xH7IH8Y17x9XQuJ_Dcw.png"/></div><figcaption class="lg lh et er es li lj bd b be z dx translated">OOV词的原始嵌入——FID ditch</figcaption></figure><p id="f0b3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">通过快速查找来检查这个单词是否存在于词汇表中，我们看到这个单词没有表示形式(很明显，因为这个单词是我刚刚创造的)。在通过OOV模型后，我们得到下面的单词嵌入:</p><figure class="kv kw kx ky fd kz er es paragraph-image"><div class="er es ln"><img src="../Images/53acd951cf3c42ce2dd7dc9ba7c2afc4.png" data-original-src="https://miro.medium.com/v2/resize:fit:990/format:webp/1*iOogqQubmIOnTBZixC5vLg.png"/></div><figcaption class="lg lh et er es li lj bd b be z dx translated">OOV词fidditch的300维单词嵌入</figcaption></figure><p id="9f5f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们基于由我们的模型产生的新嵌入获得与<em class="ll">FID dich</em>最相似的单词(使用余弦相似度),并且获得以下结果:</p><figure class="kv kw kx ky fd kz er es paragraph-image"><div class="er es lo"><img src="../Images/1c363e46d4b11f3e265b4b446feed1ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*Wu2bz6Y6erac7zCD_32Qxg.png"/></div><figcaption class="lg lh et er es li lj bd b be z dx translated">与OOV单词“fidditch”嵌入最相似的单词</figcaption></figure><p id="2f11" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">哇！模型认识到这个词可能是一种运动。因此，该模型检测到未知单词，然后将该序列与其训练集中的相似句子进行比较，然后为该单词指定一个含义。相当可观！</p><h1 id="ef8b" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated"><strong class="ak">进一步阅读和编码</strong></h1><p id="9e8f" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">我已经在上面的文章中给出了这个模型的简要概述。完整的代码和完整的文档可以在下面我的GitHub页面上找到:</p><p id="9329" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae lp" href="https://github.com/shabeelkandi/Handling-Out-of-Vocabulary-Words-in-Natural-Language-Processing-using-Language-Modelling.git" rel="noopener ugc nofollow" target="_blank">https://github . com/shabeelkandi/Handling-Out-of-Vocabulary-Words in-Natural-Language-Processing-using-Language-modeling</a></p><p id="7bf9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">或在ResearchGate上:</p><p id="1fa8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae lp" href="https://www.researchgate.net/publication/335757797_Language_Modelling_for_Handling_Out-of-Vocabulary_Words_in_Natural_Language_Processing?showFulltext=1&amp;linkId=5d7a26a04585151ee4afb0c5" rel="noopener ugc nofollow" target="_blank">https://www . researchgate . net/publication/335757797 _ Language _ modeling _ for _ Handling _ Out-of-Vocabulary _ Words _ in _ Natural _ Language _ Processing？show full text = 1&amp;linkId = 5d 7a 26 a 04585151 E4 AFB 0 c 5</a></p></div></div>    
</body>
</html>