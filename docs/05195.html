<html>
<head>
<title>Training Recurrent Neural Networks with sequences of arbitrary length in Keras.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Keras中任意长度的序列训练递归神经网络。</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/training-recurrent-neural-networks-with-sequences-of-arbitrary-length-in-keras-2edd5a79e665?source=collection_archive---------34-----------------------#2020-04-13">https://medium.com/analytics-vidhya/training-recurrent-neural-networks-with-sequences-of-arbitrary-length-in-keras-2edd5a79e665?source=collection_archive---------34-----------------------#2020-04-13</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/e1498154945997fc7802c431359774ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hDeQ0a-7A3T1s1hBAeKHjQ.png"/></div></div></figure><p id="105f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi jo translated">嗨，在这篇文章中，我想介绍一些我在网上没怎么讨论过的东西。假设你想训练一个关于时间数据的分类器，时间数据可以是视频数据或时间序列数据。所有深度学习实践者都知道，递归神经网络(RNNs)是实现这一目标的主要方法之一。</p><p id="9f42" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这篇文章中，我不打算讨论RNNs的基础，而是关注一个具体的问题。大多数真实数据都带有不同时间长度的序列。一些视频剪辑可能持续200帧，而另一些则可能短得多。</p><p id="3208" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">大多数人所做的是通过用合成帧/样本填充给定序列或者统一采样一组时间指数来标准化时间步长。考虑到rnn的设计方式，不需要采用任何一种方法。根据设计，标准rnn对序列的每个元素应用相同的操作符，而不管其长度如何。</p></div><div class="ab cl jx jy gp jz" role="separator"><span class="ka bw bk kb kc kd"/><span class="ka bw bk kb kc kd"/><span class="ka bw bk kb kc"/></div><div class="hb hc hd he hf"><p id="675b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">抽象的讨论到此为止。让我们深入研究代码。</p><pre class="ke kf kg kh fd ki kj kk kl aw km bi"><span id="9610" class="kn ko hi kj b fi kp kq l kr ks">from keras.models import Sequential<br/>from keras.layers import Dense<br/>from keras.layers import LSTM<br/>from keras import models, layers<br/>from keras import regularizers</span><span id="b41f" class="kn ko hi kj b fi kt kq l kr ks">class FunkyLSTMSequential:<br/>    <a class="ae ku" href="http://twitter.com/staticmethod" rel="noopener ugc nofollow" target="_blank">@staticmethod</a><br/>    def build(n_features):<br/>        model = Sequential()<br/>        model.add(LSTM(32, return_sequences=True, input_shape=(None, n_features)))<br/>        model.add(LSTM(64, return_sequences=True))<br/>        model.add(LSTM(32))<br/>        model.add(Dense(100))<br/>        model.add(Dense(2, activation='sigmoid', kernel_regularizer=regularizers.l2(0.01)))<br/>        return model</span></pre><p id="a98b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这段代码中，我们依次定义了一个非常简单的基于LSTM的架构。这里的关键部分是输入形状的定义。如果定义两个维度，它们将分别被解释为时间步长和特征维度。无<strong class="is hj">对于时间步长来说是一个有效的选择，并且会完全按照你想要的去做。</strong></p><p id="2598" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">不幸的是，这还不够，因为要训练网络，您需要实现一个生成器，向模型提供批量张量。这就是为什么这种方法只有在批量大小设置为1时才有效。</p></div><div class="ab cl jx jy gp jz" role="separator"><span class="ka bw bk kb kc kd"/><span class="ka bw bk kb kc kd"/><span class="ka bw bk kb kc"/></div><div class="hb hc hd he hf"><p id="2823" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">最后，我想说明同样的逻辑可以应用于Keras中的卷积LSTMs。下面是第二段代码:</p><pre class="ke kf kg kh fd ki kj kk kl aw km bi"><span id="d22b" class="kn ko hi kj b fi kp kq l kr ks">class FunkyConvLSTMSequential:<br/>    <a class="ae ku" href="http://twitter.com/staticmethod" rel="noopener ugc nofollow" target="_blank">@staticmethod</a><br/>    def build(width, height):<br/>        model = Sequential()<br/>        model.add(ConvLSTM2D(filters = 32, kernel_size=(3,3), data_format='channels_first', return_sequences=True, padding='same',<br/>                             input_shape=(None, 3, width, height), kernel_regularizer=regularizers.l2(0.01)))<br/>        model.add(Dropout(0.5))<br/>        model.add(ConvLSTM2D(filters=32, kernel_size=(3, 3), data_format='channels_first', return_sequences=False,<br/>                             padding='same', kernel_regularizer=regularizers.l2(0.01)))<br/>        model.add(Dropout(0.5))<br/>        model.add(Flatten())<br/>        model.add(Dense(12))<br/>        model.add(Dense(2, activation='sigmoid', kernel_regularizer=regularizers.l2(0.01)))<br/>        return model</span></pre><p id="b5ce" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这里，输入形状是4维的(考虑到批量大小，实际上是5维的)。input_shape的第一个元素必须设置为None，以反映序列长度的灵活性。第二个条目用于颜色通道，第三和第四个条目用于输入帧的宽度和高度。注意:这是因为我们选择了data_format='channels_first '，但据我所知，时间步长总是先走。</p><p id="5e8f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这个帖子到此为止。让我知道你的想法。最重要的是:</p><p id="19d7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">你如何解决这个问题？<br/>你知道更好的方法吗？<br/>你认为拥有这种灵活性可以提高填充和采样的性能吗？</p></div></div>    
</body>
</html>