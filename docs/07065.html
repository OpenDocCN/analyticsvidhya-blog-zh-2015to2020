<html>
<head>
<title>Face mask detection using Deep Learning.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用深度学习的人脸面具检测。</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/identifying-face-masks-using-cnn-b1991d74800?source=collection_archive---------13-----------------------#2020-06-12">https://medium.com/analytics-vidhya/identifying-face-masks-using-cnn-b1991d74800?source=collection_archive---------13-----------------------#2020-06-12</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/fb5c4dd0c35a1ec7402441222f75a884.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*gTcdzRl8Vl8m4ipx"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">照片由<a class="ae iu" href="https://unsplash.com/@unitednations?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">联合国新冠肺炎回应</a>在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></figcaption></figure><p id="e30e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">看到整个世界的新冠肺炎局势，保持我们自己和我们家人的健康和安全变得非常重要，因为到今天为止还没有疫苗可用。能让我们保持一步之遥的基本装备就是使用口罩。所以我一直想为此做点什么。</p><p id="426e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">所以我决定使用深度学习概念来检查一个人是否戴着面罩，或者是否使用CNN。</p><p id="6e9c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">什么是CNN？</strong></p><p id="7c59" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">卷积神经网络(CNN)是一种特殊类型的神经网络，能够处理图像并基于它们的类别区分它们。它们类似于人眼感知图像的方式，并将数据传回我们的大脑，即视觉皮层。要了解更多细节，你可以在网上搜索，也可以查看这个<a class="ae iu" href="https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53#:~:text=A%20Convolutional%20Neural%20Network%20(ConvNet,differentiate%20one%20from%20the%20other." rel="noopener" target="_blank">帖子</a>。</p><figure class="ju jv jw jx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es jt"><img src="../Images/8fea9e9ca8055b502ac6e6675d8662dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TELoi4Dq78pVZHuBwBUsMg.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">CNN的基本架构</figcaption></figure><p id="825d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">假设你对让我们开始吧有了基本的概念！</p><p id="bfb4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">让我们从导入库和图像开始</strong>。</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="1d43" class="kd ke hi jz b fi kf kg l kh ki">import os<br/>import cv2<br/>import numpy as np<br/>from sklearn.model_selection import train_test_split<br/>from keras.models import Sequential<br/>from keras.utils import to_categorical<br/>from keras.layers import MaxPooling2D,Convolution2D,Dense,Dropout,Flatten,Input<br/>import pickle<br/>import pandas as pd<br/>from keras.preprocessing.image import ImageDataGenerator<br/>%matplotlib inline<br/>import matplotlib.pyplot as plt</span></pre><p id="79bd" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在我们将逐个导入图像，并根据您下载数据集的位置设置路径。</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="bc73" class="kd ke hi jz b fi kf kg l kh ki">path="dataset"<br/>count=0<br/>dir=os.listdir(path)<br/>imgs=[]<br/>count=0<br/>classno=[]</span><span id="cff6" class="kd ke hi jz b fi kj kg l kh ki">print("with and without mask")<br/>nosf=len(dir)<br/>print("getting images")</span><span id="42bc" class="kd ke hi jz b fi kj kg l kh ki">for x in range(0,nosf):<br/>    mypics=os.listdir(path+"/"+str(count))<br/>    for y in mypics:<br/>        curimg = cv2.imread(path+"/"+str(count)+"/"+y)<br/>        imgs.append(curimg)<br/>        classno.append(count)<br/>    print(count,end=" ")<br/>    count+=1<br/>print(" ")</span><span id="af34" class="kd ke hi jz b fi kj kg l kh ki">imgnp=np.array(imgs)<br/>clsnp=np.array(classno)</span></pre><p id="39ec" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">运行该部分后，输出如下:</p><figure class="ju jv jw jx fd ij er es paragraph-image"><div class="er es kk"><img src="../Images/d23e1826819481ce4bc0230e2fd5f209.png" data-original-src="https://miro.medium.com/v2/resize:fit:624/format:webp/1*4vN-kT5vwGLJjqzu9Zf3KA.png"/></div></figure><p id="5f78" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，我们将拆分数据用于培训测试和验证。</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="83e9" class="kd ke hi jz b fi kf kg l kh ki">x_train, x_test, y_train, y_test = train_test_split(imgnp,clsnp,test_size=0.2)<br/>x_train, x_valid, y_train, y_valid = train_test_split(x_train,y_train,test_size=0.2)</span></pre><p id="3bba" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">分割数据后，我们将对其进行预处理，以获得正确的格式。</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="21f5" class="kd ke hi jz b fi kf kg l kh ki">def processing(img):<br/>    img = cv2.resize(img,(28,28))<br/>    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)<br/>    img = cv2.equalizeHist(img)<br/>    img = img/255<br/>    return img</span><span id="0afc" class="kd ke hi jz b fi kj kg l kh ki">x_train = np.array(list(map(processing,x_train)))<br/>x_test = np.array(list(map(processing,x_test)))<br/>x_valid = np.array(list(map(processing,x_valid)))</span></pre><p id="0730" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，我们将重塑图像添加深度1。</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="e3a3" class="kd ke hi jz b fi kf kg l kh ki">x_train=x_train.reshape(880,28,28,1)<br/>x_test=x_test.reshape(276,28,28,1)<br/>x_valid=x_valid.reshape(220,28,28,1)</span></pre><p id="99bf" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在此之后，我们将增加我们的数据，这将提供更好的结果。</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="7172" class="kd ke hi jz b fi kf kg l kh ki">datagen = ImageDataGenerator(width_shift_range=0.1,<br/>                            height_shift_range=0.1,<br/>                            zoom_range=0.2,<br/>                            shear_range=0.1,<br/>                            rotation_range=10)<br/>datagen.fit(x_train)</span><span id="77c7" class="kd ke hi jz b fi kj kg l kh ki">batch = datagen.flow(x_train,y_train,batch_size=20)<br/>x_batch, y_batch = next(batch)</span></pre><p id="819a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在我们将标签数据转换成分类数据。</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="244e" class="kd ke hi jz b fi kf kg l kh ki">y_train = to_categorical(y_train)<br/>y_test = to_categorical(y_test)<br/>y_valid = to_categorical(y_valid)</span></pre><p id="fdb3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">接下来，让我们建立我们的模型！</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="f4e7" class="kd ke hi jz b fi kf kg l kh ki">def mymod():<br/>    <br/>    model = Sequential()<br/>    <br/>    model.add(Convolution2D(60,(5,5),activation='relu',input_shape=(28,28,1)))<br/>    model.add(Convolution2D(60,(5,5),activation='relu'))<br/>    model.add(MaxPooling2D(2,2))<br/>    <br/>    model.add(Convolution2D(30,(3,3),activation='relu'))<br/>    model.add(Convolution2D(30,(3,3),activation='relu'))<br/>    model.add(MaxPooling2D(2,2))<br/>    model.add(Dropout(0.5))<br/>    <br/>    model.add(Flatten())<br/>    model.add(Dense(500,activation='relu'))<br/>    model.add(Dropout(0.5))<br/>    model.add(Dense(2,activation='softmax'))<br/>    <br/>    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])<br/>    return model</span></pre><p id="04d3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">请注意，这里我使用了分类损失，尽管这是一个二元分类，所以您也可以使用“二元交叉熵”。</p><p id="4409" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这是我们模型的总结</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="3e77" class="kd ke hi jz b fi kf kg l kh ki">mod = mymod()<br/>print(mod.summary())</span></pre><figure class="ju jv jw jx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kl"><img src="../Images/aba372c0a4ebc7c9d629508ba647344d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P5WHeyyevbAhzi8wgfmgdw.png"/></div></div></figure><p id="f598" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，我们将开始训练我们的模型。此外，如果你使用的是GPU，那么训练时间将大大减少。</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="ec37" class="kd ke hi jz b fi kf kg l kh ki">history = mod.fit_generator(datagen.flow(x_train,y_train,batch_size=50),<br/>                             steps_per_epoch=880,<br/>                             epochs=11,<br/>                             validation_data=(x_valid,y_valid),<br/>                             shuffle=1)</span></pre><p id="a55f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这将需要一些时间来训练，所以坐好，放松！</p><p id="fa97" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">一旦训练完成，让我们检查结果。</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="b8d1" class="kd ke hi jz b fi kf kg l kh ki">score = mod.evaluate(x_test,y_test)<br/>print(score[0])<br/>print(score[1])</span></pre><figure class="ju jv jw jx fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es km"><img src="../Images/3a7b6e0709f8959017400804733c1fa4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rR0lyGW1ZWYKbe2Lv2Dwyw.png"/></div></div></figure><p id="d4c6" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">从结果来看，损失偏高，您可以播放和调整代码以获得更好的结果。还有一点需要注意的是，数据集中的图像非常有限，这也会影响准确性，并且模型也可能过度拟合，因此请谨慎选择参数。但它仍然有效！。</p><p id="d7f8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">接下来，我们将保存我们的模型。</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="8066" class="kd ke hi jz b fi kf kg l kh ki">pik = open("ready.p","wb")<br/>pickle.dump(mod,pik)<br/>pik.close()<br/>cv2.waitKey(0)</span></pre><p id="a894" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">最后，让我们做一些预测，并交叉检查。</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="8876" class="kd ke hi jz b fi kf kg l kh ki">y_pred=mod.predict(x_test)</span></pre><p id="48c5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们将从测试集中随机选择一个图像进行比较。</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="6d28" class="kd ke hi jz b fi kf kg l kh ki">plt.matshow(x_test[0].reshape(28,28))</span></pre><p id="a7d0" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">结果为1，这是正确的，因为非屏蔽索引为0，屏蔽索引为1。</p><figure class="ju jv jw jx fd ij er es paragraph-image"><div class="er es kn"><img src="../Images/a905554cda57e24594b718e3a6b6faa1.png" data-original-src="https://miro.medium.com/v2/resize:fit:76/format:webp/1*AUgu9ME7ohiuJgG8oQKiFA.png"/></div></figure><p id="dec4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">总结我们到目前为止所做的一切。</p><p id="8e98" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">因此，我们用这种方法建立了CNN模型，它可以识别面具是否被戴上，同样，这个模型并不是最准确的，正如我之前所说的，因为可用的数据较少，如果你有更多的图像，那么你可以将它添加到文件夹中并再次训练，但仍然值得一试！。此外，您可以使用超参数调谐来获得更好的精度，并减少损失。我还建立了一个驱动代码，它将从网络摄像头捕捉视频，并预测面具是否存在，这是在open-cv的帮助下完成的。你可以从我的<a class="ae iu" href="https://github.com/patrickn699/Face-Mask-Detection.git" rel="noopener ugc nofollow" target="_blank"> GitHub </a>获得源代码。希望这篇文章能帮助你了解CNN识别口罩，感谢你花时间阅读，谢谢。</p></div></div>    
</body>
</html>