<html>
<head>
<title>Decoding Learning Rate Decay..!!(Code included)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">解码学习率衰减..！！(包括代码)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/decoding-learning-rate-decay-code-included-fd60c727ceb9?source=collection_archive---------16-----------------------#2020-12-29">https://medium.com/analytics-vidhya/decoding-learning-rate-decay-code-included-fd60c727ceb9?source=collection_archive---------16-----------------------#2020-12-29</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="eb1c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">嘿ML爱好者。！！</strong>我敢肯定，当你第一次浏览互联网试图学习机器学习背后的数学时，你肯定遇到过这个等式——</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jc"><img src="../Images/9264c5c990b3a1127f01998abad099cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:702/format:webp/1*KNXE2YTR0pwoKtO1C8Opgw.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated"><strong class="bd jo">梯度下降</strong></figcaption></figure><p id="5d78" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">今天，让我们深入了解这个等式的一个组成部分。从标题中有任何猜测吗？</p><p id="8797" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">是的。！如果你在考虑<strong class="ig hi">学习率</strong>，你绝对是正确的。在我们继续之前，简单回顾一下-</p><h1 id="0fdf" class="jp jq hh bd jo jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">什么是学习率？</h1><p id="e658" class="pw-post-body-paragraph ie if hh ig b ih km ij ik il kn in io ip ko ir is it kp iv iw ix kq iz ja jb ha bi translated">简单地说,<strong class="ig hi">学习速度</strong>是一个基本上帮助我们<strong class="ig hi">调整学习速度</strong>的值。现在在机器学习中，机器将要学习什么？<strong class="ig hi"> <em class="kr">权重当然</em> </strong>。！！因此，使用学习率，我们可以控制我们将要相对于损失梯度调整多少权重，并最终学习。现在谁来决定价值。</p><p id="bd69" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">嗯，这是一个<strong class="ig hi">超参数</strong>，这意味着我们将决定这个值。看起来是个艰巨的任务，不是吗？我们将如何决定？</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es ks"><img src="../Images/2aee3a87c8ad22922dda6cae83b57840.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/0*4GdIkgPnZ8nuTqJv"/></div></figure><p id="c9b0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们逐一探索可供选择的不同方案。</p><h2 id="d34c" class="kt jq hh bd jo ku kv kw ju kx ky kz jy ip la lb kc it lc ld kg ix le lf kk lg bi translated">首先让我们看看如果我们选择非常低的学习率值会发生什么？</h2><p id="035b" class="pw-post-body-paragraph ie if hh ig b ih km ij ik il kn in io ip ko ir is it kp iv iw ix kq iz ja jb ha bi translated">嗯，问题是<strong class="ig hi">需要很多时间来收敛，因为你的学习会非常慢。</strong></p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es lh"><img src="../Images/e4c67287f5b9d403dd74a974fedfc2c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1062/format:webp/1*jy0-rDke-qvGlcrNuVdyAg.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated"><strong class="bd jo">学习率太小的问题</strong></figcaption></figure><p id="272b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">看看要达到最小值需要多少步骤。</p><h2 id="8b6a" class="kt jq hh bd jo ku kv kw ju kx ky kz jy ip la lb kc it lc ld kg ix le lf kk lg bi translated">现在如果我们选择高学习率呢？</h2><p id="4139" class="pw-post-body-paragraph ie if hh ig b ih km ij ik il kn in io ip ko ir is it kp iv iw ix kq iz ja jb ha bi translated">好吧，在那种情况下，你可能<strong class="ig hi">错过最小值</strong>而<strong class="ig hi">继续围绕它切换</strong>或者你<strong class="ig hi">甚至可能发散</strong>。因此，你将无法收敛。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es li"><img src="../Images/0062e4aaa4679804e000179e6ba11b06.png" data-original-src="https://miro.medium.com/v2/resize:fit:1094/format:webp/1*JCs7B2RhnpiexI-4w_ikpw.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated"><strong class="bd jo">学习率过高的问题</strong></figcaption></figure><p id="a523" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下图总结了可能出现的不同情况</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es lj"><img src="../Images/e83c8b6bb473353ca7e9ede56c0f9400.png" data-original-src="https://miro.medium.com/v2/resize:fit:918/0*xH_N3_XR83b9LwzI"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated"><strong class="bd jo">不同学习率值的损失-时期图</strong></figcaption></figure><p id="016b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">因此，你意识到选择正确的学习速度非常重要！！现在如何找到学习率的最佳值？我们能做的是，我们可以从一开始就用一个<strong class="ig hi">较高的学习率值，因为这将帮助我们快速收敛</strong>，然后随着训练的进行，我们可以<strong class="ig hi">继续降低学习率</strong>。因此，总结一下</p><p id="f9fe" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="kr"> 1。以较大的学习率开始</em> </strong></p><p id="6022" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">2<em class="kr">。在训练过程中减少它(这样才能达到你的最佳领域)</em> </strong></p><h1 id="659e" class="jp jq hh bd jo jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">这被称为学习率衰减..！！</h1><p id="1fda" class="pw-post-body-paragraph ie if hh ig b ih km ij ik il kn in io ip ko ir is it kp iv iw ix kq iz ja jb ha bi translated">让我们实现一个代码来更好地理解LR衰减的概念！！我们将研究一个基于电离层数据集的简单二元分类问题。链接如下:-</p><p id="e178" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">dataset:<a class="ae lk" href="https://drive.google.com/file/d/19EVWjpMofMZJTd6dVyfDwysnBWrT9g4u/view?usp=sharing" rel="noopener ugc nofollow" target="_blank">https://drive . Google . com/file/d/19 evwjpmofmzjtd 6 dvyfdwysnbwrt 9g 4 u/view？usp =共享</a></p><p id="25d1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">首先你需要<strong class="ig hi">导入必要的模块</strong>:</p><pre class="jd je jf jg fd ll lm ln lo aw lp bi"><span id="a30f" class="kt jq hh lm b fi lq lr l ls lt">import pandas as pd    </span><span id="3555" class="kt jq hh lm b fi lu lr l ls lt">from keras.models import Sequential</span><span id="2ece" class="kt jq hh lm b fi lu lr l ls lt">from keras.layers import Dense</span><span id="cc11" class="kt jq hh lm b fi lu lr l ls lt">from keras.optimizers import SGD</span><span id="5fcb" class="kt jq hh lm b fi lu lr l ls lt">from sklearn.preprocessing import Label Encoder</span></pre><p id="a314" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在让我们<strong class="ig hi">加载数据集:</strong></p><pre class="jd je jf jg fd ll lm ln lo aw lp bi"><span id="2b73" class="kt jq hh lm b fi lq lr l ls lt">df = pd.read_csv(“/content/ionosphere_csv.csv”) </span></pre><p id="89bf" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，如果你看一下数据集，你会看到<strong class="ig hi">目标特征列在对象数据类型</strong>中。所以我们需要做<strong class="ig hi">编码</strong>它。为此，我们将使用<strong class="ig hi">标签编码器</strong>。如果你想了解更多关于标签编码器的信息，你可以查看这个链接:<a class="ae lk" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html" rel="noopener ugc nofollow" target="_blank">https://sci kit-learn . org/stable/modules/generated/sk learn . preprocessing . Label Encoder . html</a></p><pre class="jd je jf jg fd ll lm ln lo aw lp bi"><span id="88d5" class="kt jq hh lm b fi lq lr l ls lt"># Split data input (X) and output (Y) variables</span><span id="a58e" class="kt jq hh lm b fi lu lr l ls lt">X = df.drop('class',axis=1).astype(float)</span><span id="3c83" class="kt jq hh lm b fi lu lr l ls lt">Y = df['class'] #Target feature</span><span id="2b5c" class="kt jq hh lm b fi lu lr l ls lt"># encode class values as integers</span><span id="df86" class="kt jq hh lm b fi lu lr l ls lt">encoder = LabelEncoder()</span><span id="4849" class="kt jq hh lm b fi lu lr l ls lt">encoder.fit(Y)</span><span id="a75d" class="kt jq hh lm b fi lu lr l ls lt">Y = encoder.transform(Y)</span></pre><p id="f951" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在让我们<strong class="ig hi">创建模型</strong>:</p><pre class="jd je jf jg fd ll lm ln lo aw lp bi"><span id="d686" class="kt jq hh lm b fi lq lr l ls lt"># create model</span><span id="b796" class="kt jq hh lm b fi lu lr l ls lt">model = Sequential()</span><span id="7951" class="kt jq hh lm b fi lu lr l ls lt">model.add(Dense(34, input_dim=34, activation='relu'))</span><span id="3daf" class="kt jq hh lm b fi lu lr l ls lt">model.add(Dense(1, activation='sigmoid'))</span></pre><h2 id="5b05" class="kt jq hh bd jo ku kv kw ju kx ky kz jy ip la lb kc it lc ld kg ix le lf kk lg bi translated">这里我们将使用SGD作为我们的优化器。</h2><h2 id="2d2e" class="kt jq hh bd jo ku kv kw ju kx ky kz jy ip la lb kc it lc ld kg ix le lf kk lg bi translated">现在让我们首先从一个恒定的学习速率开始:</h2><pre class="jd je jf jg fd ll lm ln lo aw lp bi"><span id="3a3d" class="kt jq hh lm b fi lq lr l ls lt">epochs = 50  #mention the number of epochs</span><span id="e68f" class="kt jq hh lm b fi lu lr l ls lt">learning_rate = 0.1 # declare constant learning rate</span><span id="de22" class="kt jq hh lm b fi lu lr l ls lt"># Declaring the optimizer that we are going to use specifying the learning rate</span><span id="1bae" class="kt jq hh lm b fi lu lr l ls lt">sgd = SGD(lr=learning_rate, momentum=0, decay=0, nesterov=False)</span><span id="7a80" class="kt jq hh lm b fi lu lr l ls lt">model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy']) #Specify the loss, optimizer and metric </span><span id="0172" class="kt jq hh lm b fi lu lr l ls lt"># Fit the model</span><span id="8ab4" class="kt jq hh lm b fi lu lr l ls lt">history=model.fit(X, Y, validation_split=0.33, epochs=epochs, batch_size=28, verbose=2)</span></pre><p id="895f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在你可以看到，我们将<strong class="ig hi">衰变和动量保持为零，因为我们希望学习率保持不变</strong>。<strong class="ig hi">衰变帮助我们降低学习率</strong>，我们很快就会看到。动量和内斯特洛夫都有助于更快的收敛。</p><p id="e5bf" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在回到恒定学习率实现，让我们看看我们的模型可以达到什么精度:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es lv"><img src="../Images/6b23aead2c2504390b7dec27a8795df3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1306/format:webp/1*z93M4aF1yqWQTvvBojkOKQ.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated"><strong class="bd jo">使用恒定学习速率训练50个周期后获得的精度</strong></figcaption></figure><p id="76f6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">嗯，我们得到了相当好的精确度。如果您想要一个<strong class="ig hi">直观的表示精度是如何随时期变化的</strong>，您可以尝试下面几行代码:</p><pre class="jd je jf jg fd ll lm ln lo aw lp bi"><span id="733f" class="kt jq hh lm b fi lq lr l ls lt">import matplotlib.pyplot as plt</span><span id="8d4c" class="kt jq hh lm b fi lu lr l ls lt">plt.title('Classification Accuracy')</span><span id="2d9a" class="kt jq hh lm b fi lu lr l ls lt">plt.plot(history.history['accuracy'], color='blue', label='train')</span><span id="8168" class="kt jq hh lm b fi lu lr l ls lt">plt.plot(history.history['val_accuracy'], color='orange', label='test')</span></pre><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es lw"><img src="../Images/6168d2c001e623c69fe8e860dc7bab85.png" data-original-src="https://miro.medium.com/v2/resize:fit:1194/format:webp/1*8djoCZIdxHlpChdgVLq5hQ.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated"><strong class="bd jo">恒定学习速率的训练和验证精度与时期</strong></figcaption></figure><p id="51ac" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">嗯，你可以看到曲线是崎岖不平的，这可能是由于<strong class="ig hi">在最小值附近来回切换，并且由于后面时代的高学习率而无法快速收敛</strong>。此外，大约需要50个历元才能达到这个精度。让我们看看我们是否能改善这一点。</p><p id="6250" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，我们将尝试在代码中实现学习率衰减。在我们进入编码部分之前，让我们讨论一下不同种类的衰变</p><ol class=""><li id="8e5e" class="lx ly hh ig b ih ii il im ip lz it ma ix mb jb mc md me mf bi translated">基于时间的衰减</li><li id="088d" class="lx ly hh ig b ih mg il mh ip mi it mj ix mk jb mc md me mf bi translated">基于阶跃的衰减</li><li id="f8b7" class="lx ly hh ig b ih mg il mh ip mi it mj ix mk jb mc md me mf bi translated">指数式衰减</li></ol><h2 id="4b40" class="kt jq hh bd jo ku kv kw ju kx ky kz jy ip la lb kc it lc ld kg ix le lf kk lg bi translated">基于时间的衰减:</h2><p id="bf45" class="pw-post-body-paragraph ie if hh ig b ih km ij ik il kn in io ip ko ir is it kp iv iw ix kq iz ja jb ha bi translated">顾名思义，基于时间的衰减意味着久而久之，也就是说，随着时代的增加，我们的学习率会因某种因素而改变。这个因素被称为<strong class="ig hi">衰变</strong>。</p><p id="18bf" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> lr = lr0/ (1。+ k*t)) </strong></p><p id="e664" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> lr0:初始学习率</strong></p><p id="6635" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> k:衰变率</strong></p><p id="bb5a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> t:迭代/历元数(注意:虽然我们有从1开始的历元，但是这个函数考虑从索引=0开始的历元)</strong></p><p id="1154" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们看看如何在代码中实现它:</p><p id="5a9d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">像我们在前面的案例中所做的那样创建模型，现在指定优化器的细节:</p><pre class="jd je jf jg fd ll lm ln lo aw lp bi"><span id="8f39" class="kt jq hh lm b fi lq lr l ls lt"># Compile model</span><span id="b5ef" class="kt jq hh lm b fi lu lr l ls lt">epochs = 50</span><span id="c11a" class="kt jq hh lm b fi lu lr l ls lt">learning_rate = 0.1  #initial learning rate</span><span id="db56" class="kt jq hh lm b fi lu lr l ls lt">decay_rate = learning_rate / epochs      #defining decay rate</span><span id="9737" class="kt jq hh lm b fi lu lr l ls lt">momentum = 0.8</span><span id="0c5a" class="kt jq hh lm b fi lu lr l ls lt">sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)</span><span id="8d6f" class="kt jq hh lm b fi lu lr l ls lt">model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])</span><span id="f85a" class="kt jq hh lm b fi lu lr l ls lt"># Fit the model</span><span id="30d3" class="kt jq hh lm b fi lu lr l ls lt">history=model.fit(X, Y, validation_split=0.33, epochs=epochs, batch_size=28, verbose=2)</span></pre><p id="01cf" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">您可以看到我们如何<strong class="ig hi">定义衰变率，然后在声明优化器</strong>时传递衰变率和动量的值。这段代码将实现基于时间的衰减。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es ml"><img src="../Images/23aaf468bf9f1b5055652e5180333bbe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1226/format:webp/1*TSHEHhcMgxapk3czvWhq6g.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated"><strong class="bd jo">在执行基于时间的衰减时，训练50个时期后获得的精度</strong></figcaption></figure><p id="1f80" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">很明显，训练的准确性有所提高。使用与上面相同的代码来显示图形。让我们看一下图表:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mm"><img src="../Images/5de902601f51e084ffb1073d219e08b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1154/format:webp/1*0IVcgdFPEhgZCL1ly0QmcQ.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated"><strong class="bd jo">基于时间衰减的学习率的训练和验证精度与时期</strong></figcaption></figure><p id="d436" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在注意两件事:</p><ol class=""><li id="093c" class="lx ly hh ig b ih ii il im ip lz it ma ix mb jb mc md me mf bi translated"><strong class="ig hi">曲线平滑</strong></li><li id="42e8" class="lx ly hh ig b ih mg il mh ip mi it mj ix mk jb mc md me mf bi translated"><strong class="ig hi">在第20个历元左右已经达到高精度，这意味着您甚至不需要运行50个历元。这证明了更快的收敛并节省了计算时间和功率。</strong></li></ol><p id="268c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">当然这比恒定的学习速率要好。现在让我们来看看另外两种类型的衰变</p><h2 id="ea2a" class="kt jq hh bd jo ku kv kw ju kx ky kz jy ip la lb kc it lc ld kg ix le lf kk lg bi translated">阶跃衰减:</h2><p id="3ddb" class="pw-post-body-paragraph ie if hh ig b ih km ij ik il kn in io ip ko ir is it kp iv iw ix kq iz ja jb ha bi translated">在这种类型的衰减中，每隔几个时期后，学习率就会降低一定的系数。通常，每过10个周期，我们的学习率就会减半。让我们来看看这个表达-</p><p id="78e7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> lr = lr0 * drop^floor(epoch /纪元_丢弃)</strong></p><p id="ac43" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> lr0:初始学习率</strong></p><p id="1950" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">下降:我们想下降多少</strong></p><p id="ca49" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> epochs_drop:多少个epochs之后我们想要降低学习率</strong></p><p id="10c2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">纪元:纪元编号</strong></p><p id="1cea" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了应用这个，我们还需要一个叫做<strong class="ig hi">学习率调度器的东西。</strong></p><h2 id="a12c" class="kt jq hh bd jo ku kv kw ju kx ky kz jy ip la lb kc it lc ld kg ix le lf kk lg bi translated">学习率计划程序:</h2><p id="988d" class="pw-post-body-paragraph ie if hh ig b ih km ij ik il kn in io ip ko ir is it kp iv iw ix kq iz ja jb ha bi translated">用于在根据预定义的时间表进行训练时调整学习率。</p><p id="7b38" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这样你<strong class="ig hi">就定义了你想要改变你的学习率</strong>的函数，通过<strong class="ig hi">学习率调度器</strong>(这会创建一个<strong class="ig hi">回调</strong>)然后<strong class="ig hi">在训练</strong>时传递那个回调。</p><p id="70db" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">回调是在每个训练时期应用的一组函数。</strong></p><p id="c60c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们首先定义函数:</p><pre class="jd je jf jg fd ll lm ln lo aw lp bi"><span id="9852" class="kt jq hh lm b fi lq lr l ls lt">from keras.callbacks import LearningRateScheduler</span><span id="4638" class="kt jq hh lm b fi lu lr l ls lt"># learning rate schedule</span><span id="2317" class="kt jq hh lm b fi lu lr l ls lt">def step_decay(epoch):</span><span id="d2d5" class="kt jq hh lm b fi lu lr l ls lt">initial_lrate = 0.1</span><span id="68b5" class="kt jq hh lm b fi lu lr l ls lt">drop = 0.5</span><span id="95f6" class="kt jq hh lm b fi lu lr l ls lt">epochs_drop = 10.0</span><span id="472f" class="kt jq hh lm b fi lu lr l ls lt">lrate = initial_lrate * math.pow(drop, math.floor((epoch)/epochs_drop))</span><span id="8bdc" class="kt jq hh lm b fi lu lr l ls lt">return lrate</span></pre><p id="fb17" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">因此，纪元编号被传递，这返回该纪元的学习率。<strong class="ig hi">注:虽然我们有从1开始的时期，但学习率调度程序认为时期从index=0开始</strong></p><p id="f9cf" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">因此，<strong class="ig hi">对于第一个历元，<em class="kr">历元=0，(历元/历元_丢弃)=0，因此floor返回0，lrate = initial _ lrate</em>T3。对于9之前的所有下一个值，学习率保持初始学习率不变。<strong class="ig hi"> <em class="kr">现在是第11个历元，当历元变为10时，底值变为1，学习率变为= initial_lrate*0.5，即学习率减半。</em> </strong>这个过程还在继续。</strong></p><p id="b384" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在像以前一样创建模型，现在将优化器定义为:</p><pre class="jd je jf jg fd ll lm ln lo aw lp bi"><span id="93cc" class="kt jq hh lm b fi lq lr l ls lt">import math</span><span id="f843" class="kt jq hh lm b fi lu lr l ls lt"># Compile model</span><span id="8686" class="kt jq hh lm b fi lu lr l ls lt">sgd = SGD(lr=0.0, momentum=0.9)</span><span id="e44a" class="kt jq hh lm b fi lu lr l ls lt">model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])</span><span id="aee3" class="kt jq hh lm b fi lu lr l ls lt"># learning schedule callback<br/># Mentioning verbose=1 helps you visualize what is the learning rate at each epoch while training</span><span id="c1d5" class="kt jq hh lm b fi lu lr l ls lt">lrate = LearningRateScheduler(step_decay,verbose=1) </span><span id="83b4" class="kt jq hh lm b fi lu lr l ls lt">callbacks_list = [lrate] #Creating a list of callbacks</span><span id="2a39" class="kt jq hh lm b fi lu lr l ls lt"># Fit the model</span><span id="ab65" class="kt jq hh lm b fi lu lr l ls lt">history=model.fit(X, Y, validation_split=0.33, epochs=50, batch_size=28, callbacks=callbacks_list, verbose=2) #Pass the callbacks list while training the model</span></pre><p id="860d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">你一定想知道，如果我们把lr=0.0，然后再次定义学习率，我们的模型将考虑哪一个。嗯，<strong class="ig hi">如果你定义了一个学习率调度器，那么它总是考虑你在学习率调度器</strong>中定义的内容，并忽略lr=0.0</p><p id="412a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们看看训练结果-</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mn"><img src="../Images/10055e3a63d2aa86c9b678a8fe90e8e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1250/format:webp/1*wclZEUW5Y4_1gsvb2h5MFw.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated">使用基于步长的衰减进行训练</figcaption></figure><p id="a1d8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">注意<strong class="ig hi">学习率如何在历元=11时减半(因为现在在学习率调度器内历元值=10) </strong>。这个过程还在继续。让我们看看精确度和图表:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mo"><img src="../Images/7365aa0c2b976da83f19dcff7a1c5660.png" data-original-src="https://miro.medium.com/v2/resize:fit:1134/format:webp/1*XvDAHDjtdBoq_Zit_anfKQ.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated"><strong class="bd jo">执行基于步长的衰减时，训练50个时期后的精度</strong></figcaption></figure><p id="f6b2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">嗯，<strong class="ig hi">训练准确率和验证准确率都挺高的。</strong></p><p id="476a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们看一下图表:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mp"><img src="../Images/abd2b314d221b8b31291f5c32aa38d45.png" data-original-src="https://miro.medium.com/v2/resize:fit:1126/format:webp/1*JvYQugi8o5bllXLU_SCkig.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated"><strong class="bd jo">基于步长衰减的学习率的训练和验证精度与时期</strong></figcaption></figure><p id="5568" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这比前一个更加平滑，这里你也达到了接近第20个纪元的精度。</p><h2 id="d09d" class="kt jq hh bd jo ku kv kw ju kx ky kz jy ip la lb kc it lc ld kg ix le lf kk lg bi translated">指数衰减:</h2><p id="6111" class="pw-post-body-paragraph ie if hh ig b ih km ij ik il kn in io ip ko ir is it kp iv iw ix kq iz ja jb ha bi translated">在指数衰减中，学习率根据以下等式指数下降:</p><p id="0e79" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> lr = lr0 * e^(−kt) </strong></p><p id="e41c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> lr0:初始学习率</strong></p><p id="c400" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> k:衰变率</strong></p><p id="f9c2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> t:纪元编号</strong></p><p id="6ed3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这种情况下，我们还将<strong class="ig hi">定义一个函数</strong>返回学习率，<strong class="ig hi">使用学习率调度器</strong>定义一个回调，然后<strong class="ig hi">在训练时传递回调。</strong></p><p id="3c6e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们看一下代码:</p><pre class="jd je jf jg fd ll lm ln lo aw lp bi"><span id="e6dd" class="kt jq hh lm b fi lq lr l ls lt">def lr_exp_decay(epoch):</span><span id="6eb2" class="kt jq hh lm b fi lu lr l ls lt">initial_learning_rate = 0.01    #lr0</span><span id="a99d" class="kt jq hh lm b fi lu lr l ls lt">k = 0.01    #decay</span><span id="2ef5" class="kt jq hh lm b fi lu lr l ls lt">lrate=initial_learning_rate * math.exp(-k*epoch)</span><span id="f174" class="kt jq hh lm b fi lu lr l ls lt">return lrate</span></pre><p id="2972" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在创建与之前相同的模型，并在编译时进行以下更改:</p><pre class="jd je jf jg fd ll lm ln lo aw lp bi"><span id="ab4e" class="kt jq hh lm b fi lq lr l ls lt"># Compile model</span><span id="41ab" class="kt jq hh lm b fi lu lr l ls lt">sgd = SGD(lr=0.0, momentum=0.9)</span><span id="b062" class="kt jq hh lm b fi lu lr l ls lt">model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])</span><span id="65f4" class="kt jq hh lm b fi lu lr l ls lt"># learning schedule callback</span><span id="adb1" class="kt jq hh lm b fi lu lr l ls lt">lrate = LearningRateScheduler(lr_exp_decay,verbose=1) #verbose=1 helps you visualize the learning rate while training</span><span id="a4fe" class="kt jq hh lm b fi lu lr l ls lt">callbacks_list = [lrate] #create a list of the callback</span><span id="1114" class="kt jq hh lm b fi lu lr l ls lt"># Fit the model</span><span id="ea3b" class="kt jq hh lm b fi lu lr l ls lt">history=model.fit(X, Y, validation_split=0.33, epochs=50, batch_size=28, callbacks=callbacks_list, verbose=2) </span></pre><p id="cb2e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们来看看学习率是如何随着时代的变化而变化的</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mq"><img src="../Images/ff3f6f449a224d0df7d29d57be8e4216.png" data-original-src="https://miro.medium.com/v2/resize:fit:1114/format:webp/1*WDsF8Q4YakDpYYIA4p4V1A.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated"><strong class="bd jo">使用指数衰减进行训练</strong></figcaption></figure><p id="fdf4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对于第一个历元，经过的历元值=0 <strong class="ig hi">(记住学习速率调度器中的历元号从0开始)</strong>，学习rate=0.01*e^(-0.01*0)，即学习速率=0.01。现在对于纪元1，学习rate=0.01*e^(-0.01*1)，学习率=0.0099。因此，对于每个时期，你可以看到学习率是如何指数下降的。</p><p id="c054" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在让我们看看最终精度:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mr"><img src="../Images/dd38e0d5922f1de527b360c2f36f767d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1086/format:webp/1*Ku_CIGh8zviEI7Qr6WRwSA.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated"><strong class="bd jo">使用学习率指数衰减训练50个时期后获得的准确度</strong></figcaption></figure><p id="39fc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们看一下图表:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es ms"><img src="../Images/e382ef705fee5eb00ea8c0c6296a5c73.png" data-original-src="https://miro.medium.com/v2/resize:fit:1008/format:webp/1*3lU78ORuIaRnHA5UNHD53A.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated"><strong class="bd jo">具有指数衰减的学习速率的训练和验证精度与时期的关系</strong></figcaption></figure><p id="2d1f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">你可以自己比较每种情况下的表现，我们可以得出结论，使用LR衰变我们可以实现更快的收敛，从而加快我们的训练。</strong></p><p id="3a20" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">希望这对您有所帮助。请不要在评论区留下任何问题或建议，如果你觉得这很有帮助，请“鼓掌”。</p><p id="a3bf" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">祝你愉快..！！</p></div></div>    
</body>
</html>