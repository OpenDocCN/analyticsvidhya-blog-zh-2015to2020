<html>
<head>
<title>Processing Time Series Data in Real-Time with InfluxDB and Structured Streaming</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用InfluxDB和结构化流实时处理时间序列数据</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/processing-time-series-data-in-real-time-with-influxdb-and-structured-streaming-d1864154cf8b?source=collection_archive---------0-----------------------#2018-12-16">https://medium.com/analytics-vidhya/processing-time-series-data-in-real-time-with-influxdb-and-structured-streaming-d1864154cf8b?source=collection_archive---------0-----------------------#2018-12-16</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="cff8" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">本文重点介绍如何利用流行的开源数据库“Influxdb”以及spark结构化流来实时处理、存储和可视化数据。在这里，我们将详细介绍如何设置Influxdb的单个节点实例，如何扩展SPARK的Foreach编写器以使用它来写入Influxdb，以及在设计Influxdb数据库时需要注意的事项。</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/531f10ace66caf9e8d971d2ede0faa8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RHzJmVWk626MK1o_OkJG5w.jpeg"/></div></div></figure><p id="82c5" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">在数据世界中，人们希望看到的一个主要趋势是指标如何随着时间的推移而发展。这使得管理和处理时间序列数据(简单地说，数据值依赖于时间)成为数据科学家生活中非常重要的一个方面。</p><p id="0c5d" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">围绕这种高效处理时间序列数据的思想，已经开发了许多工具和数据库。在我最近的项目中，我探索了一个非常受欢迎的开源数据库，名为<strong class="jl hj">“Influxdb”</strong>，这篇文章是关于如何用influx db和Spark处理实时数据的。</p><h1 id="0553" class="kf kg hi bd kh ki kj kk kl km kn ko kp io kq ip kr ir ks is kt iu ku iv kv kw bi translated">Influxdb</h1><p id="4d14" class="pw-post-body-paragraph jj jk hi jl b jm kx ij jo jp ky im jr js kz ju jv jw la jy jz ka lb kc kd ke hb bi translated">从定义的角度来看</p><blockquote class="lc"><p id="3c66" class="ld le hi bd lf lg lh li lj lk ll ke dx translated">InfluxDB用作任何涉及大量时间戳数据的用例的数据存储，包括DevOps监控、日志数据、应用程序指标、物联网传感器数据和实时分析。</p></blockquote><p id="d7dd" class="pw-post-body-paragraph jj jk hi jl b jm lm ij jo jp ln im jr js lo ju jv jw lp jy jz ka lq kc kd ke hb bi translated">从这篇文章的范围来看，我将不详细讨论数据库是如何工作的以及它所使用的算法，这些细节可以在<a class="ae lr" href="https://docs.influxdata.com/influxdb/v1.7/" rel="noopener ugc nofollow" target="_blank"> <strong class="jl hj">这里</strong> </a>找到</p><p id="aa73" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">在这篇文章中，我将主要关注安装，写作和阅读能力，写作通过火花和行为的涌入与数据量。</p><h2 id="5525" class="ls kg hi bd kh lt lu lv kl lw lx ly kp js lz ma kr jw mb mc kt ka md me kv mf bi translated">装置</h2><p id="d4af" class="pw-post-body-paragraph jj jk hi jl b jm kx ij jo jp ky im jr js kz ju jv jw la jy jz ka lb kc kd ke hb bi translated">Influxdb作为解决方案有两个版本，一个是只能安装在单个实例上的开源版本，另一个是付费的企业版，可以安装在集群上。</p><p id="3c6f" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">在很多情况下，开源版本非常有用，满足了需求。Influxdb的单实例安装非常简单。我遵循的步骤与文档中提到的不同(我发现安装起来有点棘手)，如下所示:</p><ol class=""><li id="bc4c" class="mg mh hi jl b jm jn jp jq js mi jw mj ka mk ke ml mm mn mo bi translated">下载influxdb的rpm文件</li><li id="b3af" class="mg mh hi jl b jm mp jp mq js mr jw ms ka mt ke ml mm mn mo bi translated">如果没有安装“sudo apt-get install alien ”,请安装alien软件包</li><li id="193c" class="mg mh hi jl b jm mp jp mq js mr jw ms ka mt ke ml mm mn mo bi translated">用“alien name.rpm”从rpm获取一个. deb文件</li><li id="597c" class="mg mh hi jl b jm mp jp mq js mr jw ms ka mt ke ml mm mn mo bi translated">用“sudo dpkg -i name.deb”安装潮人</li><li id="1e0b" class="mg mh hi jl b jm mp jp mq js mr jw ms ka mt ke ml mm mn mo bi translated">用“sudo influxd”或“sudo服务流入启动”启动流入服务器</li></ol><h2 id="54b9" class="ls kg hi bd kh lt lu lv kl lw lx ly kp js lz ma kr jw mb mc kt ka md me kv mf bi translated">硬件规模指南</h2><p id="2c7c" class="pw-post-body-paragraph jj jk hi jl b jm kx ij jo jp ky im jr js kz ju jv jw la jy jz ka lb kc kd ke hb bi translated">Influxdb非常慷慨地为我们提供了硬件规模指南。单个实例节点的情况如下。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mu"><img src="../Images/8b31e7f6094a5d79e517f0acf0b0b969.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lZyWdyDOjTv6H_8G2EbVXA.png"/></div></div></figure><p id="a717" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">这些指导原则在中有详细介绍</p><div class="mv mw ez fb mx my"><a href="https://docs.influxdata.com/influxdb/v1.7/guides/hardware_sizing/" rel="noopener  ugc nofollow" target="_blank"><div class="mz ab dw"><div class="na ab nb cl cj nc"><h2 class="bd hj fi z dy nd ea eb ne ed ef hh bi translated">流入数据文件</h2><div class="nf l"><h3 class="bd b fi z dy nd ea eb ne ed ef dx translated">InfluxDB、Telegraf、Chronograf、Kapacitor和Flux的文档</h3></div><div class="ng l"><p class="bd b fp z dy nd ea eb ne ed ef dx translated">docs.influxdata.com</p></div></div><div class="nh l"><div class="ni l nj nk nl nh nm jh my"/></div></div></a></div><p id="1c62" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jl hj"> InfluxDB基本概念</strong></p><p id="8859" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">这里有一些重要的Influxdb概念需要理解</p><blockquote class="nn no np"><p id="3771" class="jj jk nq jl b jm jn ij jo jp jq im jr nr jt ju jv ns jx jy jz nt kb kc kd ke hb bi translated"><strong class="jl hj"> 1。度量</strong>:度量大致相当于关系数据库中的表的概念。数据存储在测量中，一个数据库可以有多个测量。度量主要由三种类型的列组成:输入法、标签和字段</p><p id="dc53" class="jj jk nq jl b jm jn ij jo jp jq im jr nr jt ju jv ns jx jy jz nt kb kc kd ke hb bi translated">2.<strong class="jl hj">时间</strong>:时间不过是一个跟踪时间戳的列，用来更好地执行时间序列操作。缺省值是Influxdb时间，单位是纳秒，但是可以用事件时间替换。</p><p id="3e5f" class="jj jk nq jl b jm jn ij jo jp jq im jr nr jt ju jv ns jx jy jz nt kb kc kd ke hb bi translated">3.标签:标签类似于关系数据库中的索引列。<strong class="jl hj">需要记住的重要一点是，只有当列被标记为标签时，才能对其执行WHERE、GROUP BY等关系操作</strong></p><p id="3096" class="jj jk nq jl b jm jn ij jo jp jq im jr nr jt ju jv ns jx jy jz nt kb kc kd ke hb bi translated">4.<strong class="jl hj">字段</strong>:字段是可以进行<strong class="jl hj">求和、均值、非负导数等数学运算的列。</strong>但是，在最近的版本中，字符串值也可以存储为字段。</p><p id="53cb" class="jj jk nq jl b jm jn ij jo jp jq im jr nr jt ju jv ns jx jy jz nt kb kc kd ke hb bi translated">5.<strong class="jl hj">系列</strong>:系列是Influxdb最重要的概念。<strong class="jl hj">系列是标签、测量和保留策略的组合(Influxdb的默认值)。</strong>influx db数据库的性能高度依赖于它所包含的唯一序列的数量，<strong class="jl hj">这又是标签的基数x测量数量x保留策略</strong></p></blockquote><p id="c236" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">必须明智地决定将哪些值存储为标签，哪些值存储为字段，因为它们对于确定可以执行的操作类型和数据库本身的性能是必要的。</p><p id="f979" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jl hj">从Spark写入数据</strong></p><p id="d6f4" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">Spark是目前大数据处理领域最流行、最高效的开源工具。目前有两个InfluxDb sink的开源实现可用于通过结构化流写入数据，<a class="ae lr" href="https://github.com/fsanaulla/chronicler-spark" rel="noopener ugc nofollow" target="_blank"> <strong class="jl hj">编年史</strong> </a>和<a class="ae lr" href="https://github.com/pygmalios/reactiveinflux" rel="noopener ugc nofollow" target="_blank"> <strong class="jl hj">反应流入</strong> </a>。</p><p id="4960" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">这两种方法都很有效，chronicler的唯一问题是<strong class="jl hj">通过chronicler写入数据，必须首先将流入数据点转换/创建为influxdb线路协议，这有时会变得很棘手，需要处理大量的字段和字符串值</strong>。仅仅因为这个原因，我更喜欢反应式流入。</p><p id="ec51" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">要在<strong class="jl hj"> sbt </strong>项目中包含反应性流入，只需</p><pre class="iy iz ja jb fd nu nv nw nx aw ny bi"><span id="f29d" class="ls kg hi nv b fi nz oa l ob oc">libraryDependencies ++= Seq(<br/>"com.pygmalios" % "reactiveinflux-spark_2.11" % "1.4.0.10.0.5.1",<br/>"com.typesafe.netty" % "netty-http-pipelining" % "1.1.4"<br/>)</span></pre><p id="c7f5" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">在application.conf中创建一个条目</p><pre class="iy iz ja jb fd nu nv nw nx aw ny bi"><span id="6d8d" class="ls kg hi nv b fi nz oa l ob oc">reactiveinflux {<br/>  url = "localhost<a class="ae lr" href="http://96.112.246.169:8086/" rel="noopener ugc nofollow" target="_blank">:8086/</a>"<br/>  spark {<br/>    batchSize = 1000 // No of records to be send in each batch<br/>  }<br/>}</span></pre><p id="1e8e" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">要使spark流查询能够写入Influxdb，需要扩展Spark结构化流中可用的Foreach编写器。下面给出了它的伪代码</p><pre class="iy iz ja jb fd nu nv nw nx aw ny bi"><span id="9aff" class="ls kg hi nv b fi nz oa l ob oc">import com.pygmalios.reactiveinflux._<br/>import com.pygmalios.reactiveinflux.spark._<br/>import org.apache.spark.SparkConf<br/>import org.apache.spark.rdd.RDD<br/>import org.apache.spark.streaming.dstream.DStream<br/>import org.apache.spark.streaming.{Seconds, StreamingContext}<br/>import org.joda.time.DateTime<br/>import com.pygmalios.reactiveinflux.{ReactiveInfluxConfig, ReactiveInfluxDbName}<br/>import com.pygmalios.reactiveinflux.sync.{SyncReactiveInflux, SyncReactiveInfluxDb}<br/>import scala.concurrent.duration._</span><span id="98b9" class="ls kg hi nv b fi od oa l ob oc">class influxDBSink(dbName: String) extends org.apache.spark.sql.ForeachWriter[org.apache.spark.sql.Row] {<br/>        <br/>        var  db:SyncReactiveInfluxDb = _<br/>        implicit val awaitAtMost = 1.second<br/>        </span><span id="33f4" class="ls kg hi nv b fi od oa l ob oc">// Define the database connection here<br/><strong class="nv hj">def open(partitionId: Long, version: Long): Boolean</strong> = {<br/>            val syncReactiveInflux =<br/>SyncReactiveInflux(ReactiveInfluxConfig(None))<br/>            db = syncReactiveInflux.database(dbName);<br/>            db.create() // create the database <br/>          <br/>            true<br/>        }</span><span id="326b" class="ls kg hi nv b fi od oa l ob oc">// Write the process logic, and database commit code here<br/><strong class="nv hj">def process(value: org.apache.spark.sql.Row): Unit</strong> = {</span><span id="071d" class="ls kg hi nv b fi od oa l ob oc">          val point = Point(<br/>                           time = time,  // system or event time <br/>                           measurement = "measurement1",<br/>                           tags = Map(<br/>                                      "t1" -&gt; "A", <br/>                                      "t2" -&gt; "B"<br/>                                     ),<br/>                           fields = Map(<br/>                                   "f1" -&gt; 10.3, // BigDecimal field<br/>                                   "f2" -&gt; "x",  // String field<br/>                                   "f3" -&gt; -1,   // Long field<br/>                                   "f4" -&gt; true) // Boolean field<br/>                                  )<br/>          <br/>            db.write(point)<br/>        }</span><span id="487d" class="ls kg hi nv b fi od oa l ob oc">// Close connection here<br/> <strong class="nv hj">def close(errorOrNull: Throwable): Unit</strong> = {</span><span id="a44a" class="ls kg hi nv b fi od oa l ob oc">}<br/>    }</span></pre><p id="a276" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">然后将它包含在writer中，如下所示</p><pre class="iy iz ja jb fd nu nv nw nx aw ny bi"><span id="9367" class="ls kg hi nv b fi nz oa l ob oc">val influxWriter = new influxDBSink("dbName")</span><span id="d9ce" class="ls kg hi nv b fi od oa l ob oc">val influxQuery = ifIndicatorData<br/>                     .writeStream<br/>                     .foreach(influxWriter)<br/>                     .outputMode("append")<br/>                     .start()</span></pre><h2 id="a391" class="ls kg hi bd kh lt lu lv kl lw lx ly kp js lz ma kr jw mb mc kt ka md me kv mf bi translated"><strong class="ak">可视化</strong></h2><p id="7c58" class="pw-post-body-paragraph jj jk hi jl b jm kx ij jo jp ky im jr js kz ju jv jw la jy jz ka lb kc kd ke hb bi translated">一旦数据被存储，使用各种工具，如Grafana，计时等可视化可以绘制。一个可视化示例应该是这样的。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es oe"><img src="../Images/b9a581cedd17bb62861ac8eed1371fcf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ut-wxwo0HBh-7bivPnVMiA.png"/></div></div><figcaption class="of og et er es oh oi bd b be z dx translated">influxdata.com</figcaption></figure><p id="3961" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">在Medium和其他平台上也有许多关于可视化的文章，因此我不会详细讨论。</p><h2 id="2c55" class="ls kg hi bd kh lt lu lv kl lw lx ly kp js lz ma kr jw mb mc kt ka md me kv mf bi translated">结论</h2><p id="d0b7" class="pw-post-body-paragraph jj jk hi jl b jm kx ij jo jp ky im jr js kz ju jv jw la jy jz ka lb kc kd ke hb bi translated">总之，我发现Influxdb在数据存储方面非常高效，而且非常容易使用。Influxdb的压缩算法非常强大，可以将数据压缩到几乎一半。在我的数据本身中，我看到压缩导致从大约67GB减少到35GB。</p><p id="e6dc" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">然而，究竟是什么决定了压缩的规模和效果，这超出了本文的范围。</p></div></div>    
</body>
</html>