<html>
<head>
<title>How Facebook AI used this Network to generate more data to train a Pose-Estimation Model.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">脸书人工智能如何使用该网络生成更多数据来训练姿势估计模型。</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/how-facebook-ai-used-this-network-to-generate-more-data-to-train-a-pose-estimation-model-339a45d09415?source=collection_archive---------21-----------------------#2020-04-17">https://medium.com/analytics-vidhya/how-facebook-ai-used-this-network-to-generate-more-data-to-train-a-pose-estimation-model-339a45d09415?source=collection_archive---------21-----------------------#2020-04-17</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="3710" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">读者们好。这篇博客是对我目前在Tensorflow 2.0中实现的一篇研究论文的评价。我个人认为这篇论文的目的和发现值得与尚未阅读的读者分享。因此，在深入研究这篇能够生成更多数据来训练自身并提高其准确性的论文之前，我要感谢作者——<strong class="ih hj">宾夕法尼亚大学的Gedas Bertasius、Christoph Feichtenhofer、Du Tran、时剑波、Lorenzo Torre Sani——脸书·艾。</strong></p><p id="2fd0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">用于姿态估计的深度神经网络中的现代方法需要大量密集注释。这意味着，如果你想训练一个用于姿态估计的神经网络，你将需要视频中大量手动标记的帧，这些帧带有你希望你的模型估计的点的坐标。这个过程非常昂贵，因为它需要手工劳动。现在，这就是论文中提出的网络前进的方向。本文命名为<strong class="ih hj"><em class="jd"/></strong>pose warper网络，能够仅借助于视频中的少量标记帧来标记视频中的帧。</p><p id="d455" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了训练，PoseWarper网络输入相同视频的两个帧——一个标记的帧<strong class="ih hj"> A </strong>和一个未标记的帧B，它们之间仅相隔几步时间<strong class="ih hj">。</strong>现在，两个帧都被馈入网络(<strong class="ih hj"> <em class="jd"> SimpleHRNet </em> </strong>)，该网络生成热图<strong class="ih hj"> f(A) </strong>和<strong class="ih hj"> f(B)。</strong>对于那些不熟悉HRNet的人来说，HRNet是一个网络，它输入人的图像并输出热图(指定人的关节的标记图像)。有关SimpleHRNet的详细信息，请点击<a class="ae je" href="https://github.com/stefanopini/simple-HRNet.git" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">此处</strong> </a>。为了更好地理解，请参考下图。</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div class="er es jf"><img src="../Images/510f3708c888818f290a1634ea7a0088.png" data-original-src="https://miro.medium.com/v2/resize:fit:1220/format:webp/1*dI14UcKJfPZfkUQ_oVHRbg.png"/></div><figcaption class="jn jo et er es jp jq bd b be z dx translated">简单HRNet的输入和相应的输出</figcaption></figure><p id="d890" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，在从<strong class="ih hj">预训练的</strong> HRNet获得两个热图(f(A)，f(B))之后，开始<strong class="ih hj"> <em class="jd"> PoseWarper </em> </strong>网络的可训练区域。简而言之，该网络使用未标记帧<strong class="ih hj"> B </strong>和标记帧<strong class="ih hj"> A </strong>的热图，并计算两者的差异。(f(A)-f(B)=<strong class="ih hj"><em class="jd">φ</em></strong>)。现在这个<strong class="ih hj">φ</strong>被发送到网络的可训练区域，该区域进一步用<strong class="ih hj"> f(B) </strong>扭曲<strong class="ih hj">φ</strong>，并试图使其与标记为<strong class="ih hj">帧a</strong>中的地面真实情况相匹配。这形成了网络的训练部分。这正是PoseWarper网络的目的:训练权重，以使在未标记帧<strong class="ih hj"> B </strong>中估计的姿势与在标记帧<strong class="ih hj">a</strong>中的真实姿势相匹配。为了更清楚起见，请参考这个图示。</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div class="er es jr"><img src="../Images/6cd053418a8bfb285a88102c3d9fffba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*SxxxDXKjFZp5IWGn3YzrSw.png"/></div><figcaption class="jn jo et er es jp jq bd b be z dx translated">PoseWarper的训练部分</figcaption></figure><p id="a799" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用稀疏标记的视频进行姿态检测的方法的高级概述。在每个训练视频中，姿势注释仅每k帧可用。在训练过程中，系统会考虑一对帧——一个标记的帧A和一个未标记的帧B，并使用帧B的特征来检测帧A中的姿态。</p><p id="34cb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在训练模型之后，我们感兴趣的是传递一些未标记的帧，并作为输出得到那些标记的帧。我们的目标是通过使用PoseWarper标记视频中未标记的帧来不断生成新数据，从而增加我们的训练数据集。下图显示了模型如何标记未标记的帧。</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="jt ju di jv bf jw"><div class="er es js"><img src="../Images/d3a2c8e22675b262532e8694d2eb2e6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bGvgfw41Sp-RHw9H2B7caA.png"/></div></div><figcaption class="jn jo et er es jp jq bd b be z dx translated">标记未标记的帧并同时生成更多数据</figcaption></figure><p id="609c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因为这篇文章的目的是提出本文中提到的想法，而不是实现细节。然而，为了更加清晰，我们可以考虑模型架构。下面是模型架构的图像。</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div class="er es jr"><img src="../Images/7f65c0ef8c145c88ab4330279a36545c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*LXELsc9-iHB9i8wZxPwFfA.png"/></div><figcaption class="jn jo et er es jp jq bd b be z dx translated">模型架构</figcaption></figure><p id="21f8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果读者需要了解更多关于架构、实现细节、实验和模型能力的信息，他们可以随时在这里阅读研究工作<a class="ae je" href="https://arxiv.org/abs/1906.04016" rel="noopener ugc nofollow" target="_blank"><strong class="ih hj"/></a>。</p></div></div>    
</body>
</html>