<html>
<head>
<title>Performance Metrics of Supervised Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">监督学习的性能度量</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/performance-metrics-precision-recall-f1-score-efb51ac111bd?source=collection_archive---------1-----------------------#2019-07-06">https://medium.com/analytics-vidhya/performance-metrics-precision-recall-f1-score-efb51ac111bd?source=collection_archive---------1-----------------------#2019-07-06</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/c0819139f73059fb8b0c3fb4269059e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*t-OmQmokRZOpi-fu"/></div></div></figure><p id="30fc" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我热烈欢迎所有的读者。这是我第一个关于机器学习相关主题的博客。先说一般的事情。当你听到“机器学习”时，你会想到什么？不要用技术术语来定义什么是机器学习；概括来说，机器学习无非就是用一定的数据训练一台机器，让机器去学习和分析未来看不见的数据。</p><p id="f17b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">回到我们博客的主题“性能指标”。我们使用许多性能指标来检查模型的性能。假设我们参加了一个烹饪比赛，我们做的食物被评为x分，这里x表示我们可以根据它来分析我们做得有多好。</p><p id="f623" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">同样，在机器学习中，我们有性能指标来检查我们的模型表现如何。我们有各种性能指标，如混淆矩阵、精确度、召回率、F1分数、精确度、AUC-ROC、对数损失等。</p><p id="292b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这篇博客中，我将讨论</p><ol class=""><li id="91d3" class="jo jp hi is b it iu ix iy jb jq jf jr jj js jn jt ju jv jw bi translated"><strong class="is hj">精度</strong></li><li id="8b06" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated"><strong class="is hj">召回/灵敏度</strong></li><li id="00fc" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated"><strong class="is hj">F1-得分</strong></li><li id="26fb" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated"><strong class="is hj"> AUC-ROC曲线</strong></li><li id="e2cf" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated"><strong class="is hj">日志丢失</strong></li></ol><p id="38dd" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在讨论什么是精确度、召回率和F1分数之前，我们首先需要理解一个混淆矩阵。不深入混乱矩阵，我将给出一个混乱矩阵是什么的小理解。</p><h1 id="1315" class="kc kd hi bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">混淆矩阵:</h1><p id="79a2" class="pw-post-body-paragraph iq ir hi is b it la iv iw ix lb iz ja jb lc jd je jf ld jh ji jj le jl jm jn hb bi translated">混淆矩阵是N*N维矩阵，其中一个轴代表“实际”标签，而另一个轴代表“预测”标签。</p><figure class="lg lh li lj fd ij er es paragraph-image"><div class="er es lf"><img src="../Images/af175c11dbc7d9590fa0450e78020dc1.png" data-original-src="https://miro.medium.com/v2/resize:fit:482/format:webp/1*B5hfoNqki2BQsWwPgAsF3w.png"/></div><figcaption class="lk ll et er es lm ln bd b be z dx translated"><strong class="bd ke">来源链接:</strong> <a class="ae lo" href="https://www.google.com/search?q=confusion+matrix&amp;rlz=1C1RLNS_enIN844IN844&amp;source=lnms&amp;tbm=isch&amp;sa=X&amp;ved=0ahUKEwja6bqN3Z_jAhXBuo8KHZ9PBsYQ_AUIECgB&amp;biw=1366&amp;bih=625#imgrc=qaM5X9E7c28zqM:" rel="noopener ugc nofollow" target="_blank"> <strong class="bd ke">谷歌图片</strong> </a></figcaption></figure><p id="0fec" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">从上图来看——混淆矩阵是2*2维的。x轴代表“预测”标签，Y轴代表“实际”标签。</p><p id="5a4f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了更好地理解什么是TP、FP、TN和FN，我们将考虑一个例子-<strong class="is hj">‘如果收到的邮件是垃圾邮件或火腿’</strong></p><p id="5092" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">肯定</strong> —收到的邮件是火腿</p><p id="f1e0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">否定的 —收到的邮件是垃圾邮件</p><p id="8311" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">真阳性(TP): </strong>表示预测标签为阳性，实际标签也为阳性——预测正确。我们预测收到的邮件是“ham”(阳性)，实际收到的邮件也是“ham”(阳性)。</p><p id="de72" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">真阴性(TN): </strong>表示预测标签为阴性，实际标签也为阴性——预测正确。我们预测收到的邮件是“垃圾邮件”(负面)，实际收到的邮件也是“垃圾邮件”(负面)。</p><p id="5243" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">假阴性(FN): </strong>表示预测标签为阴性，而实际标签为阳性——预测错误。我们预测收到的邮件是“垃圾邮件”(负面)，但实际收到的邮件是“垃圾邮件”(正面)。</p><p id="e5ce" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">假阳性(FP): </strong>表示预测标签为阳性，实际标签为阴性——预测错误。我们预测收到的邮件是“垃圾邮件”(正面)，但实际收到的邮件是“垃圾邮件”(负面)。</p><p id="7444" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">混淆矩阵是最直观和最基本的度量，从中我们可以获得各种其他度量，如精确度、召回率、准确度、F1分数、AUC-ROC。</p><p id="e397" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> <em class="lp">现在让我们深入探讨一下精确度、召回率和F1得分指标。</em> </strong></p><h1 id="683a" class="kc kd hi bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">1.精度:</h1><p id="c08b" class="pw-post-body-paragraph iq ir hi is b it la iv iw ix lb iz ja jb lc jd je jf ld jh ji jj le jl jm jn hb bi translated"><strong class="is hj">一般定义:</strong>精度衡量预测阳性标签实际为阳性的比例。</p><p id="296e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了解释precision及其用例，我们将考虑'<strong class="is hj"> <em class="lp">机器学习课程推荐</em> </strong>'示例，即我们必须推荐学生选择xyz机器学习课程。</p><p id="bf21" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">积极— </strong>推荐给学生的课程</p><p id="2ca0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">否定</strong> —不推荐给学生的课程</p><p id="1688" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">真阳性和假阳性的精确度:</p><figure class="lg lh li lj fd ij er es paragraph-image"><div class="er es lq"><img src="../Images/2c918d9f5a096443a1da50129e46d72c.png" data-original-src="https://miro.medium.com/v2/resize:fit:888/format:webp/1*2XWJOMrse1aFpLuOAPWKMg.png"/></div><figcaption class="lk ll et er es lm ln bd b be z dx translated"><strong class="bd ke">来源链接:</strong> <a class="ae lo" href="https://www.google.com/url?sa=i&amp;source=images&amp;cd=&amp;ved=2ahUKEwiz9tLX8J_jAhUIRo8KHT2OA0EQjRx6BAgBEAU&amp;url=https%3A%2F%2Ftowardsdatascience.com%2Faccuracy-precision-recall-or-f1-331fb37c5cb9&amp;psig=AOvVaw0wnXdzL2uEjpYHniqNImaG&amp;ust=1562488302609499" rel="noopener ugc nofollow" target="_blank"> <strong class="bd ke">谷歌图片</strong> </a></figcaption></figure><p id="3bc1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">从图像中的上述公式，我们可以分析出，随着“假阳性”的减少，我们的精度增加，反之亦然。让我们看看'<strong class="is hj"> <em class="lp">机器学习课程推荐</em> </strong>'例子中的'真阳性'、'假阳性'、'假阴性'是什么。</p><p id="2ae4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">真阳性(TP): </strong>预测为推荐给学生的课程，实际上也是推荐给学生的课程。</p><p id="8b9e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">假阳性(FP): </strong>预测为推荐给学生的课程，但实际上并未推荐给学生。</p><p id="5fef" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">假阴性(FN): </strong>预测为未推荐给学生的课程，但实际上是推荐给学生的课程。</p><h2 id="da11" class="lr kd hi bd ke ls lt lu ki lv lw lx km jb ly lz kq jf ma mb ku jj mc md ky me bi translated">何时使用Precision？</h2><p id="8d07" class="pw-post-body-paragraph iq ir hi is b it la iv iw ix lb iz ja jb lc jd je jf ld jh ji jj le jl jm jn hb bi translated">当我们希望主要关注假阳性时，即减少假阳性值从而增加精度值时，使用精度。可能会出现一个问题，为什么我们主要关注假阳性而不是假阴性。要回答这个问题，让我们考虑'<strong class="is hj"> <em class="lp">机器学习课程推荐</em> </strong>'的例子。</p><p id="2a86" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">假阳性(FP): </strong>表示我们预测的标签为阳性，而实际标签为阴性——错误预测。在我们的例子中应用假阳性-这意味着我们已经预测到该课程已经被推荐给学生，但是实际上该课程并没有被推荐给学生。如果我们的假阳性值很高，这显然意味着我们应该错过一些或大多数学生来推荐这门课程。这将是学院的一个损失，因为学院没有几个或大多数学生推荐这门课程。因此，我们主要关注误报值，并试图将其减少到尽可能小的值。</p><p id="3c46" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">假阴性(FN): </strong>表示我们预测的标签为阴性，而实际标签为阳性——预测错误。在我们的例子中应用假阴性-这意味着我们已经预测到该课程没有被推荐给学生，但实际上该课程被推荐给了学生。如果我们的假阴性值很高，这显然意味着我们必须向已经被推荐的学生推荐一门课程。如果我们向已经被推荐的学生推荐这门课程，这根本不是问题。所以，我们不太关注假负值。</p><p id="2d72" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">结论:</strong>考虑到以上两个原因，我们主要关注假阳性值，并试图将其降低到尽可能小的值，从而提高精度值。</p><h1 id="f9f2" class="kc kd hi bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">2.回忆/敏感度</h1><p id="536c" class="pw-post-body-paragraph iq ir hi is b it la iv iw ix lb iz ja jb lc jd je jf ld jh ji jj le jl jm jn hb bi translated"><strong class="is hj">一般定义:</strong>召回衡量实际阳性标签被正确预测为阳性的比例。</p><p id="bab7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了解释召回及其使用案例，我们将考虑<strong class="is hj"> <em class="lp">【癌症诊断】</em> </strong>示例，即我们必须预测患者是否被诊断为癌症。</p><p id="d746" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">阳性</strong>——诊断为癌症的患者。</p><p id="bdee" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">阴性</strong> —患者未被诊断为癌症。</p><p id="2271" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">根据真阳性和假阴性回忆:</p><figure class="lg lh li lj fd ij er es paragraph-image"><div class="er es mf"><img src="../Images/6a502145f854adb14ef0a5dd9859bcba.png" data-original-src="https://miro.medium.com/v2/resize:fit:908/format:webp/1*OZudoZHrrygChE8ejo4Jlw.png"/></div><figcaption class="lk ll et er es lm ln bd b be z dx translated"><strong class="bd ke">来源链接:</strong> <a class="ae lo" href="https://www.google.com/url?sa=i&amp;source=images&amp;cd=&amp;ved=2ahUKEwiz9tLX8J_jAhUIRo8KHT2OA0EQjRx6BAgBEAU&amp;url=https%3A%2F%2Ftowardsdatascience.com%2Faccuracy-precision-recall-or-f1-331fb37c5cb9&amp;psig=AOvVaw0wnXdzL2uEjpYHniqNImaG&amp;ust=1562488302609499" rel="noopener ugc nofollow" target="_blank"> <strong class="bd ke">谷歌图片</strong> </a></figcaption></figure><p id="7e73" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">从图像中的上述公式，我们可以分析出，随着“假阴性”的减少，我们的回忆增加，反之亦然。让我们看看<strong class="is hj"> <em class="lp">【癌症诊断】</em> </strong>例子中的‘真阳性’、‘假阳性’、‘假阴性’是什么。</p><p id="eecf" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">真阳性(TP): </strong>预测为诊断为癌症的患者，实际上也是诊断为癌症的患者。</p><p id="263a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">假阳性(FP): </strong>预测为诊断为癌症的患者，但实际为未诊断为癌症的患者。</p><p id="b231" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">假阴性(FN): </strong>预测为未诊断为癌症的患者，实际诊断为癌症的患者。</p><h2 id="4d1e" class="lr kd hi bd ke ls lt lu ki lv lw lx km jb ly lz kq jf ma mb ku jj mc md ky me bi translated">何时使用召回？</h2><p id="eca6" class="pw-post-body-paragraph iq ir hi is b it la iv iw ix lb iz ja jb lc jd je jf ld jh ji jj le jl jm jn hb bi translated">当我们希望主要关注假阴性时，即减少假阴性值从而增加召回值时，使用召回。可能会出现一个问题，为什么我们主要关注假阴性而不是假阳性。为了回答这个问题，让我们考虑一下<strong class="is hj"> <em class="lp">【癌症诊断】</em> </strong> <em class="lp">的例子。</em></p><p id="6f54" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">假阴性(FN): </strong>表示我们预测的标签为阴性，而实际标签为阳性——预测错误。在我们的例子中应用假阴性——这意味着我们预测患者没有被诊断为癌症，但是实际的患者被诊断为癌症。如果是这种情况，根据预测，患者可能无法获得治愈癌症的治疗。但事实是病人被诊断患有癌症。我们错误的负面预测会导致病人死亡。因此，我们主要关注假负值，并试图将其减少到尽可能小的值。</p><p id="15be" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">假阳性(FP): </strong>表示我们预测的标签为阳性，而实际标签为阴性——错误预测。在我们的例子中应用假阳性-这意味着我们已经预测到患者被诊断患有癌症，但是实际的患者没有被诊断患有癌症。如果是这种情况，根据预测，患者将接受癌症诊断检查。令他高兴的是，他将会知道他没有被诊断出患有癌症。万岁！他现在没有癌症了。所以，我们不太关注假阳性值。</p><p id="698e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">结论:</strong>考虑到以上两个原因，我们主要关注假阴性值，并试图将其降低到尽可能小的值，从而提高召回值。</p><h1 id="3e76" class="kc kd hi bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">F1分数:</h1><p id="ef6d" class="pw-post-body-paragraph iq ir hi is b it la iv iw ix lb iz ja jb lc jd je jf ld jh ji jj le jl jm jn hb bi translated">F1-score是另一个很好的性能指标，它同时利用了精确度和召回率指标。F1分数可以通过简单地取精确度和召回率的“调和平均值”来获得。与主要关注假阳性的精度和主要关注假阴性的召回不同，F1-score同时关注假阳性和假阴性。</p><p id="ac29" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了解释F1分数及其用例，我们将考虑<strong class="is hj"><em class="lp">‘玫瑰&amp;茉莉花</em></strong>’的例子，即我们必须预测花是玫瑰还是茉莉花。</p><p id="b4b9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">阳性— </strong>归类为玫瑰的花。</p><p id="2562" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">阴性— </strong>花归类为茉莉花。</p><p id="250d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">f1-精确度和召回率得分:</p><figure class="lg lh li lj fd ij er es paragraph-image"><div class="er es mg"><img src="../Images/e504c39ffe00538bd63ade760578e0c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/format:webp/0*iokMsMqIkiumlk4J.jpg"/></div><figcaption class="lk ll et er es lm ln bd b be z dx translated"><strong class="bd ke">来源链接:</strong> <a class="ae lo" href="https://www.google.com/url?sa=i&amp;source=images&amp;cd=&amp;cad=rja&amp;uact=8&amp;ved=2ahUKEwjJ5cKljqDjAhXPXSsKHTePCxoQjRx6BAgBEAU&amp;url=%2Furl%3Fsa%3Di%26source%3Dimages%26cd%3D%26ved%3D%26url%3D%252Furl%253Fsa%253Di%2526source%253Dimages%2526cd%253D%2526ved%253D%2526url%253Dhttps%25253A%25252F%25252Fdeepai.org%25252Fmachine-learning-glossary-and-terms%25252Ff-score%2526psig%253DAOvVaw10OJ-_diqDWdlv09dlPAkP%2526ust%253D1562496208540558%26psig%3DAOvVaw10OJ-_diqDWdlv09dlPAkP%26ust%3D1562496208540558&amp;psig=AOvVaw10OJ-_diqDWdlv09dlPAkP&amp;ust=1562496208540558" rel="noopener ugc nofollow" target="_blank"> <strong class="bd ke">谷歌图片</strong> </a></figcaption></figure><p id="ee10" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">让我们看看<strong class="is hj"><em class="lp">‘玫瑰&amp;茉莉花’</em></strong>例子中的‘假阳性’和‘假阴性’是什么。</p><p id="cdc0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">假阳性(FP): </strong>预测花是玫瑰，但实际花是茉莉。</p><p id="f9b5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">假阴性(FN): </strong>预测花为茉莉，但实际花为玫瑰。</p><h2 id="c45c" class="lr kd hi bd ke ls lt lu ki lv lw lx km jb ly lz kq jf ma mb ku jj mc md ky me bi translated">何时使用F1得分:</h2><p id="bfa9" class="pw-post-body-paragraph iq ir hi is b it la iv iw ix lb iz ja jb lc jd je jf ld jh ji jj le jl jm jn hb bi translated">如上所述，F1分数关注假阳性和假阴性，无论如何我们不希望玫瑰被归类为茉莉，而茉莉被归类为玫瑰。在这种情况下，我们关注假阳性和假阴性，并试图减少假阳性和假阴性，从而增加F1分数。</p><p id="b17b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">结论:</strong>牢记上述原因，我们可以说我们的重点应该是假阳性和假阴性，并试图减少假阳性和假阴性，从而增加F1分数。</p><h1 id="2fcc" class="kc kd hi bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">4.AUC-ROC曲线</h1><p id="22a9" class="pw-post-body-paragraph iq ir hi is b it la iv iw ix lb iz ja jb lc jd je jf ld jh ji jj le jl jm jn hb bi translated">AUC-ROC是用于检查模型性能的最重要的性能度量之一。AUC-ROC用于二元和多类分类，但主要用于二元分类问题。在这个博客中，我们将考虑一个二元类分类。</p><p id="f4f2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">AUC展开为曲线 下的<strong class="is hj"> <em class="lp">面积，ROC展开为<strong class="is hj"> <em class="lp">受试者工作特性</em> </strong>。也称为AUROC，在接收机工作特性下扩展为<strong class="is hj"> <em class="lp">区域。</em> </strong></em></strong></p><p id="4fe0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">AUC-ROC是模型性能的图形表示。ROC是概率曲线，AUC是可分离性的度量。根据阈值集，我们可以分析我们的模型在分离两个类别方面的表现。AUC越高，我们分离两个类别的模型越好。</p><p id="66d9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">AUC-ROC的图示:</strong></p><figure class="lg lh li lj fd ij er es paragraph-image"><div class="ab fe cl mh"><img src="../Images/ece3a5ce0250e390d5dc937671fbe6cd.png" data-original-src="https://miro.medium.com/v2/format:webp/1*pk05QGzoWhCgRiiFbz-oKQ.png"/></div><figcaption class="lk ll et er es lm ln bd b be z dx translated"><strong class="bd ke">来源链接:</strong> <a class="ae lo" href="https://www.google.com/url?sa=i&amp;source=images&amp;cd=&amp;ved=2ahUKEwj8qMXSl6fjAhUTU30KHdiWDWEQjRx6BAgBEAU&amp;url=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-auc-roc-curve-68b2303cc9c5&amp;psig=AOvVaw2WaAqBNnvHYLVy5H2-gFYZ&amp;ust=1562738759613951" rel="noopener ugc nofollow" target="_blank"> <strong class="bd ke">谷歌图片</strong> </a></figcaption></figure><p id="93bb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">参考上图，我们可以看到AUC-ROC曲线是用FPR对TPR绘制的，其中FPR(假阳性率)在X轴上，而TPR(真阳性率)在Y轴上。绿色曲线代表ROC曲线，而ROC曲线下的面积/区域(绿色曲线)代表AUC。穿过原点的连续黑线不过是‘门槛’。</p><p id="7e60" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们先来了解一下什么是TPR和FPR:</p><p id="48fd" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">真阳性率(TPR): </strong></p><p id="551f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">TPR无非就是回忆/敏感。TPR的公式如下</p><figure class="lg lh li lj fd ij er es paragraph-image"><div class="er es mi"><img src="../Images/e8c792d347c3fd79d8c72d22a27e694b.png" data-original-src="https://miro.medium.com/v2/resize:fit:940/format:webp/1*qqUqNXYZoYEKEofVDJwy9Q.png"/></div><figcaption class="lk ll et er es lm ln bd b be z dx translated">真实阳性率</figcaption></figure><p id="43fc" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">假阳性率(FPR): </strong></p><p id="ce82" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">TPR的公式如下</p><figure class="lg lh li lj fd ij er es paragraph-image"><div class="er es mj"><img src="../Images/2ebe9296497735b7ae7f4a4c031a2e77.png" data-original-src="https://miro.medium.com/v2/resize:fit:856/format:webp/1*-pqIwTf3WoWM5COhKzD9aw.png"/></div><figcaption class="lk ll et er es lm ln bd b be z dx translated"><strong class="bd ke">假阳性率</strong></figcaption></figure><p id="f6f3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">AUC-ROC曲线的解释:</strong></p><p id="64e5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在让我们看看基于AUC分数和ROC曲线的二元分类的分析。为此，我们将以上面的例子<strong class="is hj"> <em class="lp">【癌症诊断】</em> </strong>为例，即我们必须预测患者是否被诊断为癌症。</p><p id="97f0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">红色曲线:</strong><strong class="is hj"/>阳性——确诊为癌症患者。</p><p id="a8d0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">绿色曲线:</strong>阴性<strong class="is hj"> </strong> —未确诊为癌症的患者。</p><p id="f619" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">示例— 1: </strong></p><p id="2114" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">阈值设置为0.5。两条曲线(绿色和红色)之间没有重叠。这是最好的模型，AUC值为1.0。这表明模型区分正负类的概率是1.0。换句话说，我们可以说，有100%的机会模型可以把积极的和消极的阶级分开。</p><figure class="lg lh li lj fd ij er es paragraph-image"><div class="er es mk"><img src="../Images/985e700e3d82f065f834c0288ba09ec1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1296/format:webp/1*e0uI8k4yZGhv9nPZVDeuOg.png"/></div><figcaption class="lk ll et er es lm ln bd b be z dx translated"><strong class="bd ke">AUC值为1.0的ROC曲线</strong></figcaption></figure><p id="adeb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">示例— 2: </strong></p><p id="0e3e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">阈值设置为0.5。两条曲线(绿色和红色)之间有一点重叠。这是一个很好的模型，AUC值为0.8。这表明模型分离正类和负类的概率是0.8。换句话说，我们可以说有80%的机会模型可以把积极和消极的阶层分开。</p><figure class="lg lh li lj fd ij er es paragraph-image"><div class="er es ml"><img src="../Images/f3a66c42c313a29bf75f00df24c4d718.png" data-original-src="https://miro.medium.com/v2/resize:fit:1268/format:webp/1*V4mTHGL2uA-HG9lWcNFsmA.png"/></div><figcaption class="lk ll et er es lm ln bd b be z dx translated"><strong class="bd ke">AUC值为0.8的ROC曲线</strong></figcaption></figure><p id="688c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">示例— 3: </strong></p><p id="0adf" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">阈值设置为0.5。我们可以看到两条曲线(绿色和红色)完全重叠。这是一个糟糕的模型，AUC值为0.5。这表明模型区分正负类的概率是0.5。换句话说，我们可以说有50%的机会模型可以把积极和消极的阶层分开。</p><figure class="lg lh li lj fd ij er es paragraph-image"><div class="er es mm"><img src="../Images/e80224eca087199cf3213b00d603c3cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1218/format:webp/1*tgekXzyB92l8uYcU9iTfTA.png"/></div><figcaption class="lk ll et er es lm ln bd b be z dx translated"><strong class="bd ke">AUC值为0.5的ROC曲线</strong></figcaption></figure><p id="41ca" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">例— 4: </strong></p><p id="872a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">阈值设置为0.5。我们可以看到两条曲线(绿色和红色)之间的重叠，曲线也是往复运动的。这是最差的模型，AUC值为0.2。这表明模型区分正负类的概率是0.2。换句话说，我们可以说有20%的机会模型可以把积极和消极的阶层分开。</p><figure class="lg lh li lj fd ij er es paragraph-image"><div class="er es mn"><img src="../Images/53ce86840898d0e222deb7a6ddb52e27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1260/format:webp/1*QsCBC2GIe-BttqDQnGVdRA.png"/></div><figcaption class="lk ll et er es lm ln bd b be z dx translated"><strong class="bd ke">AUC值为0.2的ROC曲线</strong></figcaption></figure><p id="bbcb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">AUC-ROC曲线与其他指标的不同之处在于，在AUC-ROC曲线中，我们可以设置阈值。阈值的设置取决于业务需求和重要性。例如:在医疗领域，阈值设置为0.95。所以高于0.95的AUC分数被认为是最好的，否则是最差的。</p><h2 id="2874" class="lr kd hi bd ke ls lt lu ki lv lw lx km jb ly lz kq jf ma mb ku jj mc md ky me bi translated">何时使用AUC-ROC曲线:</h2><p id="bdd4" class="pw-post-body-paragraph iq ir hi is b it la iv iw ix lb iz ja jb lc jd je jf ld jh ji jj le jl jm jn hb bi translated">嗯，这有时很令人困惑，因为存在矛盾的说法，例如当数据平衡时我们可以使用AUC-ROC，另一方面，当数据不平衡时我们也可以使用。</p><ol class=""><li id="42a2" class="jo jp hi is b it iu ix iy jb jq jf jr jj js jn jt ju jv jw bi translated"><strong class="is hj">平衡数据:</strong>有一个清晰的图像，当数据几乎平衡时，可以使用AUC-ROC，例如正负类的比例约为60:40或70:30。它很好地解释了真阳性率(TPR)和假阳性率(FPR)。</li><li id="fc8d" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated"><strong class="is hj">不平衡数据:</strong>另一方面，AUC — ROC也可以在数据不平衡时使用，可以根据数据和业务需求灵活设置阈值。</li></ol><p id="4a97" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">注:</strong>参考上述第二点，补充说明，在数据不平衡的情况下，很少使用AUC — ROC。相反，使用精确-召回曲线，因为它比AUC-ROC曲线更有意义。在不平衡数据的情况下，有时很难选择指标，它仅仅取决于数据和业务需求。AUC — ROC的主要优势之一是，我们可以根据业务需求设置阈值。</p><h1 id="9fb2" class="kc kd hi bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">5.对数损失</h1><p id="b211" class="pw-post-body-paragraph iq ir hi is b it la iv iw ix lb iz ja jb lc jd je jf ld jh ji jj le jl jm jn hb bi translated">对数损失(对数损失)是用于检查模型性能的良好度量之一。对数损失通过考虑分类的概率来惩罚错误的分类。</p><p id="e741" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">与其他度量不同，对数损失使用概率得分。它既用于二元类分类，也用于多类分类。随着对数损失的增加，预测概率偏离实际标签。对数损失越低，模型越好。因此，我们的目标是尽可能减少日志损失。对数损失为0的模型被称为最佳模型。</p><p id="5428" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">对数损失公式如下:</strong></p><figure class="lg lh li lj fd ij er es paragraph-image"><div class="er es mo"><img src="../Images/d9e041c8b9d529d0a7b215a91f906d7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1162/format:webp/1*bUv2Dgcfw6OG9vhcpRXIeg.png"/></div><figcaption class="lk ll et er es lm ln bd b be z dx translated"><strong class="bd ke">测井—损失公式</strong></figcaption></figure><p id="a14c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">测井曲线损失的图示:</strong></p><figure class="lg lh li lj fd ij er es paragraph-image"><div class="er es mp"><img src="../Images/45401dc0b2a9a8c1f9e19d056776f7bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:866/format:webp/1*o1Qo_z2Z8O93S2n-eTkP7w.png"/></div><figcaption class="lk ll et er es lm ln bd b be z dx translated"><strong class="bd ke">原木损失的图形表示</strong></figcaption></figure><h2 id="68f5" class="lr kd hi bd ke ls lt lu ki lv lw lx km jb ly lz kq jf ma mb ku jj mc md ky me bi translated">什么时候对我们日志丢失？</h2><ol class=""><li id="56dd" class="jo jp hi is b it la ix lb jb mq jf mr jj ms jn jt ju jv jw bi translated">当模型输出是二进制类{0，1}的概率时，使用对数损失。对数损失的主要优点是，它惩罚了错误分类或错误预测。</li><li id="2c54" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated">对数丢失可用于平衡和不平衡数据。由于测井曲线丢失会受到不平衡数据的影响，因此最好使用过采样、欠采样等技术来平衡数据。</li></ol><h1 id="073e" class="kc kd hi bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">总结:</h1><ol class=""><li id="6916" class="jo jp hi is b it la ix lb jb mq jf mr jj ms jn jt ju jv jw bi translated"><strong class="is hj">精度:</strong>精度衡量预测阳性标记实际为阳性的比例。我们主要关注假阳性值，并试图将其降低到最小可能值，从而提高精度值。</li><li id="f082" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated"><strong class="is hj">召回:</strong>召回衡量实际阳性标签被正确预测为阳性的比例。我们主要关注假阴性值，并试图将其降低到尽可能小的值，从而提高召回值。</li><li id="8714" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated"><strong class="is hj"> F1得分:</strong> F1得分是精确度和召回率的“调和平均值”。我们关注假阳性和假阴性，并试图减少假阳性和假阴性，从而提高F1分数。</li><li id="3144" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated"><strong class="is hj"> AUC — ROC曲线:</strong>是ROC曲线和曲线下区域/面积的图形表示，即AUC。它主要用于二元类分类。它解释了正类和负类可分性的概率或百分比。AUC-ROC越高，我们的模型在区分阳性和阴性类别方面就越好。</li><li id="7fd9" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated"><strong class="is hj">对数损失:</strong>对数损失也称对数损失，用于二元和多类分类。与其他指标不同，它基于概率得分。我们的模型是对数损失越低越好。</li></ol><h2 id="a23e" class="lr kd hi bd ke ls lt lu ki lv lw lx km jb ly lz kq jf ma mb ku jj mc md ky me bi translated">来源:</h2><ol class=""><li id="b68c" class="jo jp hi is b it la ix lb jb mq jf mr jj ms jn jt ju jv jw bi translated"><a class="ae lo" href="https://www.appliedaicourse.com/lecture/11/applied-machine-learning-online-course/2982/log-loss/3/module-3-foundations-of-natural-language-processing-and-machine-learning" rel="noopener ugc nofollow" target="_blank">https://www . applied ai course . com/lecture/11/applied-machine-learning-online-course/2982/log-loss/3/module-3-foundations of-natural-language-processing-and-machine-learning</a></li><li id="c1ab" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated"><a class="ae lo" href="https://www.appliedaicourse.com/lecture/11/applied-machine-learning-online-course/2981/receiver-operating-characteristic-curve-roc-curve-and-auc/3/module-3-foundations-of-natural-language-processing-and-machine-learning" rel="noopener ugc nofollow" target="_blank">https://www . applied ai course . com/lecture/11/applied-machine-learning-online-course/2981/receiver-operating-character istic-curve-roc-curve-and-AUC/3/module-3-foundations-of-natural-language-processing-and-machine-learning</a></li><li id="60be" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated"><a class="ae lo" href="https://www.appliedaicourse.com/lecture/11/applied-machine-learning-online-course/2980/precision-and-recall-f1-score/3/module-3-foundations-of-natural-language-processing-and-machine-learning" rel="noopener ugc nofollow" target="_blank">https://www . applied ai course . com/lecture/11/applied-machine-learning-online-course/2980/precision-and-recall-f1-score/3/module-3-foundations of-natural-language-processing-and-machine-learning</a></li><li id="affb" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated">https://developers . Google . com/machine-learning/crash-course/classification/precision-and-recall</li><li id="9323" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated"><a class="ae lo" rel="noopener" href="/thalus-ai/performance-metrics-for-classification-problems-in-machine-learning-part-i-b085d432082b">https://medium . com/thal us-ai/performance-metrics-for-class ification-problems-in-machine-learning-part-I-b085d 432082 b</a></li><li id="c247" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated">【http://wiki.fast.ai/index.php/Log_Loss T4】</li><li id="8433" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated"><a class="ae lo" rel="noopener" href="/datadriveninvestor/understanding-the-log-loss-function-of-xgboost-8842e99d975d">https://medium . com/datadriveninvestor/understanding-the-log-loss-function-of-xgboost-8842 e 99d 975d</a></li><li id="37cf" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated"><a class="ae lo" href="https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5" rel="noopener" target="_blank">https://towards data science . com/understanding-AUC-roc-curve-68b 2303 cc9 C5</a></li><li id="97d9" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated"><a class="ae lo" href="https://classeval.wordpress.com/simulation-analysis/roc-and-precision-recall-with-imbalanced-datasets/" rel="noopener ugc nofollow" target="_blank">https://classe val . WordPress . com/simulation-analysis/roc-and-precision-recall-with-unbalanced-datasets/</a></li><li id="5442" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated"><a class="ae lo" href="https://stats.stackexchange.com/questions/180116/when-is-log-loss-metric-appropriate-for-evaluating-performance-of-a-classifier" rel="noopener ugc nofollow" target="_blank">https://stats . stack exchange . com/questions/180116/when-log-loss-metric-just-for-evaluation-of-a-a-performance-of-a-classifier</a></li></ol></div></div>    
</body>
</html>