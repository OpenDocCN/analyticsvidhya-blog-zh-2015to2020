<html>
<head>
<title>Eigen component analysis (ECA) introduction — A brand new feature extraction algorithm</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">特征分量分析(ECA)介绍——一种全新的特征提取算法</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/eigen-component-analysis-eca-introduction-a-brand-new-feature-extraction-algorithm-d6547e7553ff?source=collection_archive---------21-----------------------#2020-04-01">https://medium.com/analytics-vidhya/eigen-component-analysis-eca-introduction-a-brand-new-feature-extraction-algorithm-d6547e7553ff?source=collection_archive---------21-----------------------#2020-04-01</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/25b73545ab1285f966eda81587d25049.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*0pzIdFQDEOV_LCcw"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">照片由<a class="ae iu" href="https://unsplash.com/@siora18?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Siora摄影</a>在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="9523" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这是github知识库对论文<em class="jt">本征分量分析的介绍:一种结合了机器学习技术的量子理论，用于寻找线性最大可分离分量。本实验包括两个主要部分，特征分量分析(ECA)和特征分量分析网络(ECAN)。无论是ECA还是ECAN，都可以用标准的特征成分分析(VECA)或近似的特征成分分析(AECA)来训练。正如论文中提到的，VECA经常导致稀疏结果，是降维的更好选择。</em></p><p id="35f1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">依我的愚见，ECA是一种一流的特征提取或降维算法。得到的特征矩阵(EFM)和特征类映射矩阵(ECMM)可以用来进行具体的降维。在没有背景或噪声的情况下，具体的降维数接近整个数据集的秩。此外，随着具体维数的减少，方差比接近1。<strong class="ix hj">例如，MNIST数据集使用VECA的具体降维数是110(使用AECA的是328)，不多也不少。这可能意味着MNIST数据集或背景/无噪声数据集仅占据维度为110的子空间。VECA和AECA结果的不同之处在于，VECA忽略了一些不太重要的信息。</strong>在ECAN，利用维数算子，非线性降维优于许多经典算法，这将在我们未来的工作中报道。</p><p id="0399" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">核心算法在<em class="jt"> real_eigen.py </em>中实现(<em class="jt"> complex_eigen.py </em>独立实现)。用于训练的基础模型以前缀<em class="jt"> base </em>命名，可以独立运行，也可以作为一个模块工作。与ECAN相关的文件以<em class="jt">网络</em>为后缀。数据加载在<em class="jt"> load_data.py </em>中实现。与其他模型的对比在<em class="jt"> other_models.py </em>中实现。获得的EFM、ECMM、RaDO或ReDO存储在目录<em class="jt"> history中。</em></p><ul class=""><li id="b7ac" class="ju jv hi ix b iy iz jc jd jg jw jk jx jo jy js jz ka kb kc bi translated">Analytic ECA: analytic_eca.py，可以找到满秩数据集的解析解</li><li id="1002" class="ju jv hi ix b iy kd jc ke jg kf jk kg jo kh js jz ka kb kc bi translated">近似ECA:base _ approximate py</li><li id="4a28" class="ju jv hi ix b iy kd jc ke jg kf jk kg jo kh js jz ka kb kc bi translated">复杂ECA: complex_eigen.py，base_complex_eigen.py</li></ul><p id="5860" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">分析ECA和基本模型中的所有<em class="jt"> data_tag </em>都可以被改变以训练其他数据集。历史和检查点由<em class="jt">real _ eigen . py/complex _ eigen . py</em>中的MAGIC_CODE和每个待执行文件中的WORK_MAGIC_CODE管理。</p><p id="08ee" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在训练之前，应设置EFM和ECMM约束的两个超参数:</p><pre class="ki kj kk kl fd km kn ko kp aw kq bi"><span id="1044" class="kr ks hi kn b fi kt ku l kv kw">RealEigen.HP_ORTHONORMAL = 0.001<br/>RealEigen.HP_EIGENDIST = 0.001</span></pre><p id="acfe" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">它们都可以被设置为较小的数目(根据经验<code class="du kx ky kz kn b">1e3</code>或更小),具有相对较大数目的训练时期。对于维数较低的数据集，这两个超参数取相对较大的值会加速收敛。放松对EFM的约束通常没有什么影响。然而，如果获得的ECMM不是二进制的，则相应的超参数应该设置得更大。一般来说，训练VECA比AECA容易，因为ECMM的二元性和稀疏性，这反映在VECA的惰性超参数设置上。</p><h1 id="e54b" class="la ks hi bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated">火车VECA</h1><ul class=""><li id="dea1" class="ju jv hi ix b iy lx jc ly jg lz jk ma jo mb js jz ka kb kc bi translated">这些文件包括twodim.py ( <code class="du kx ky kz kn b">data_tag="2d"</code>)、threedim.py ( <code class="du kx ky kz kn b">data_tag="3d"</code>)、bc.py ( <code class="du kx ky kz kn b">data_tag="breast_cancer"</code>)、wis.py ( <code class="du kx ky kz kn b">data_tag="wis"</code>)、mnist.py ( <code class="du kx ky kz kn b">data_tag="mnist"</code>)对应的2D、3D、Wis1992、Wis1995、mnist数据集。</li><li id="d348" class="ju jv hi ix b iy kd jc ke jg kf jk kg jo kh js jz ka kb kc bi translated">将<em class="jt"> to_train </em>选项设置为<strong class="ix hj"> True </strong>，否则将只在之前保存的模型上进行测试。</li><li id="97af" class="ju jv hi ix b iy kd jc ke jg kf jk kg jo kh js jz ka kb kc bi translated">那么Wis1992上的培训应该是</li></ul><blockquote class="mc"><p id="6a8d" class="md me hi bd mf mg mh mi mj mk ml js dx translated">python bc.py</p></blockquote><h1 id="67d9" class="la ks hi bd lb lc ld le lf lg lh li lj lk mm lm ln lo mn lq lr ls mo lu lv lw bi translated">火车AECA</h1><ul class=""><li id="4382" class="ju jv hi ix b iy lx jc ly jg lz jk ma jo mb js jz ka kb kc bi translated">可以改变data_tag来测试其他数据集。</li></ul><blockquote class="mc"><p id="8f1c" class="md me hi bd mf mg mh mi mj mk ml js dx translated">python base_approx.py</p></blockquote><p id="62bf" class="pw-post-body-paragraph iv iw hi ix b iy mp ja jb jc mq je jf jg mr ji jj jk ms jm jn jo mt jq jr js hb bi translated"><strong class="ix hj">在MNIST数据集上用AECA训练二折ECAN</strong></p><ul class=""><li id="2ac6" class="ju jv hi ix b iy iz jc jd jg jw jk jx jo jy js jz ka kb kc bi translated">ECAN的代码在base_network.py中。可以将data_tag改为load_data.py中提到的那个</li><li id="827a" class="ju jv hi ix b iy kd jc ke jg kf jk kg jo kh js jz ka kb kc bi translated">设置要使用的尺寸运算符</li></ul><figure class="ki kj kk kl fd ij"><div class="bz dy l di"><div class="mu mv l"/></div></figure><ul class=""><li id="332e" class="ju jv hi ix b iy iz jc jd jg jw jk jx jo jy js jz ka kb kc bi translated">和AECA一起训练</li></ul><figure class="ki kj kk kl fd ij"><div class="bz dy l di"><div class="mu mv l"/></div></figure><ul class=""><li id="54c5" class="ju jv hi ix b iy iz jc jd jg jw jk jx jo jy js jz ka kb kc bi translated">将<em class="jt">设置为训练</em>为真<strong class="ix hj">并在MNIST数据集上训练</strong></li></ul><blockquote class="mc"><p id="bee5" class="md me hi bd mf mg mh mi mj mk ml js dx translated">python base_network.py</p></blockquote><p id="08e5" class="pw-post-body-paragraph iv iw hi ix b iy mp ja jb jc mq je jf jg mr ji jj jk ms jm jn jo mt jq jr js hb bi translated"><strong class="ix hj">在MNIST数据集上用VECA训练二折ECAN</strong></p><ul class=""><li id="5072" class="ju jv hi ix b iy iz jc jd jg jw jk jx jo jy js jz ka kb kc bi translated">与AECA训练的唯一区别在于这段代码</li></ul><figure class="ki kj kk kl fd ij"><div class="bz dy l di"><div class="mu mv l"/></div></figure><h1 id="62a3" class="la ks hi bd lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw bi translated">降维</h1><p id="60d1" class="pw-post-body-paragraph iv iw hi ix b iy lx ja jb jc ly je jf jg mw ji jj jk mx jm jn jo my jq jr js hb bi translated">在history文件夹中，有了对应的MAGIC_CODE和WORK_MAGIC_CODE，我们就可以找到获得的EFM <em class="jt"> P </em>，ECMM <em class="jt"> LL </em>。在2折ECAN，EFM和ECMM有后缀一个数字表示相应的折叠。RaDO或ReDO都属于第一类。在ECAN，单位运算符每隔一个折叠安装一次，因为一行中两个连续的维度运算符是微不足道的。</p><h2 id="119b" class="kr ks hi bd lb mz na nb lf nc nd ne lj jg nf ng ln jk nh ni lr jo nj nk lv nl bi translated">使用ECA降维</h2><figure class="ki kj kk kl fd ij"><div class="bz dy l di"><div class="mu mv l"/></div></figure><h2 id="f677" class="kr ks hi bd lb mz na nb lf nc nd ne lj jg nf ng ln jk nh ni lr jo nj nk lv nl bi translated">使用2重ECAN进行降维</h2><figure class="ki kj kk kl fd ij"><div class="bz dy l di"><div class="mu mv l"/></div></figure><p id="88e0" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">降维运算符(重做)定义为</p><figure class="ki kj kk kl fd ij"><div class="bz dy l di"><div class="mu mv l"/></div></figure></div><div class="ab cl nm nn gp no" role="separator"><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr ns"/><span class="np bw bk nq nr"/></div><div class="hb hc hd he hf"><p id="b634" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="jt">原载于</em><a class="ae iu" href="https://gist.github.com/fd45cea867dbe203f571268cd219788e" rel="noopener ugc nofollow" target="_blank"><em class="jt">http://github.com</em></a><em class="jt">。</em></p><p id="0a26" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">源代码:<a class="ae iu" href="https://github.com/chenmiaomiao/eca" rel="noopener ugc nofollow" target="_blank">https://github.com/chenmiaomiao/eca</a></p><p id="9479" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">参考:</p><div class="nt nu ez fb nv nw"><a href="https://arxiv.org/abs/2003.10199" rel="noopener  ugc nofollow" target="_blank"><div class="nx ab dw"><div class="ny ab nz cl cj oa"><h2 class="bd hj fi z dy ob ea eb oc ed ef hh bi translated">本征成分分析:一个量子理论结合机器学习技术，以寻找线性…</h2><div class="od l"><h3 class="bd b fi z dy ob ea eb oc ed ef dx translated">对于一个线性系统，对一个刺激的反应常常被它对其他分解刺激的反应所叠加。在…</h3></div><div class="oe l"><p class="bd b fp z dy ob ea eb oc ed ef dx translated">arxiv.org</p></div></div></div></a></div><p id="56b3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><a class="ae iu" href="https://www.researchgate.net/publication/340113956_Eigen_component_analysis_A_quantum_theory_incorporated_machine_learning_technique_to_find_linearly_maximum_separable_components" rel="noopener ugc nofollow" target="_blank">https://www . researchgate . net/publication/340113956 _ Eigen _ component _ analysis _ A _ quantum _ theory _ incorporated _ machine _ technique _ to _ find _ linear _ maximum _ separable _ components</a></p></div></div>    
</body>
</html>