# BERT 数据集上的多类文本分类

> 原文：<https://medium.com/analytics-vidhya/bert-multi-class-text-classification-e3822836ee0d?source=collection_archive---------15----------------------->

![](img/ec6b902415b52ae9fbc9a8c46340d738.png)

印度比哈尔邦的古代那烂陀大学遗址

我正在为我的一个客户进行多类文本分类，我想根据 BERT 序列分类来评估我当前的模型准确性。

这就是我的一切开始。鉴于 BERT 的受欢迎程度，我确信我会得到一些在线代码的帮助，以便将结果与我现有的分类模型进行比较。但是，令人惊讶的是，我找不到任何现成的东西来研究它。

因此，我想为其他人节省时间，并决定为那些想使用 BERT 对数据集进行多类文本分类的人写这篇文章

多亏了《变形金刚》中的“拥抱脸”,现在 pytorch 上也有了。您可以从安装变压器 pip 开始。该模型将在第一次代码运行时安装。

我已经使用了***Bert-base-uncased***作为模型，所以在这篇文章中的进一步讨论将是关于这个预训练的模型。

为了使用预先训练的模型，你需要坚持指定的序列特征。按给定顺序阅读以下函数，以理解矢量化步骤。

根据您的训练/有效/测试示例创建数据集

在您实际进行训练练习之前，理解以下函数很重要，这是需要根据您计划使用的模型进行修改的函数。另外，使用特定的*记号赋予器*很重要，所以要小心。

下面的特征化代码是针对***Bert-base-un cased***模型的。

数据的矢量化

一旦我们有了矢量化的数据集，我们就可以进入训练步骤。所有其他步骤，如运行一段时间，保存模型以供评估，都保持不变。

就我而言，我已经接受了大约 10，000 次训练和 2，000 个验证句子。我运行了 10 个时期来提高现有分类模型的准确性。

**运行自己的数据**

通过按如下所述排列数据，您可以直接在自己的数据集上运行此代码或笔记本:

*   安装的附属设备，如变压器、手电筒等。(我在《回购》中已经提到了名单。)
*   将您的数据分为三个通常的类别，“*训练、有效和测试*”，并存储为 CSV 文件。
*   CSV 文件至少应该有两列，分别命名为“**文本**和“**标签**
*   你一定已经猜到“**文本**应该包含你的句子，而“**标签**应该包含它的类别/范畴

以下是我关于 BERT 评估的超参数。一旦你能够使用默认值和评估运行，我建议你使用“per_gpu_train_batch_size”、“max_seq_length”和“learning_rate”来重新运行并评估结果。

我的作品在此提交[，随意叉评。](https://github.com/kumardeepak/bert-multi-class.git)

**运行其他预训练模型**

你需要调整一下我的代码来运行其他可用的模型，如 XLNet，GPT2 或 RoBERT 等。如果你需要帮助，一定要联系我。然而，我敢肯定，你需要调整或固定到矢量化步骤，如上所述。

请克隆[变形金刚库](https://github.com/huggingface/transformers.git)，具体为二分类还是多分类，查看“run_glue.py”代码。