<html>
<head>
<title>Using the Corrected Paired Student’s t-test for comparing Machine Learning Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用校正后的配对学生t检验来比较机器学习模型</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/using-the-corrected-paired-students-t-test-for-comparing-the-performance-of-machine-learning-dc6529eaa97f?source=collection_archive---------1-----------------------#2019-09-26">https://medium.com/analytics-vidhya/using-the-corrected-paired-students-t-test-for-comparing-the-performance-of-machine-learning-dc6529eaa97f?source=collection_archive---------1-----------------------#2019-09-26</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="e500" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">比较机器学习(ML)方法对于给定任务的性能并选择最终方法是应用ML中的常见操作。</p><p id="1544" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这篇文章的目的是，首先，展示为什么我们需要使用统计方法来选择最终的模型。然后，它解释了为什么一种常用的统计假设检验(即配对学生的t检验)不足以比较ML模型的性能。最后，这篇文章演示了如何实现配对学生t检验的校正版本，以检查ML模型的性能。</p><p id="fe82" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下图显示了十种不同分类模型在使用特定数据集训练的F分数方面的性能。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/31dcb7038d27cf07e14b82a0d35f568a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mN7BZL_3RhgEcDqto_0a5A.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">十种不同ML模型的性能(QDA:二次判别分析，LDA:线性判别分析，SVM:支持向量机，KNN K-最近邻)</figcaption></figure><p id="c662" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">模型的性能使用测试数据集或看不见的数据集来衡量。此外，使用K折叠交叉验证对它们进行训练，K折叠交叉验证将数据集随机划分到不同的折叠中，如下图所示。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jt"><img src="../Images/1e2fb65bf960fca1de9d8c1f86ce7b61.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OsY2PjdFJOIsQj9E5S34cQ.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">将数据集分成测试和训练数据集。这两个数据集可能每次都改变，因此，训练的ML模型的性能可能改变</figcaption></figure><p id="8271" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从图中可以清楚地看出，对于这个特定的数据集，QDA比其他分类模型表现得好得多。可能出现的问题是:“这些结果是否在统计上提供了令人信服的证据，证明QDA优于其他应用的ML模型？”。事实上，我们需要估计最大似然模型之间的性能差异是真实可靠的，还是仅仅由于统计上的偶然。</p><p id="a85a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在回答上述问题之前，我们需要知道，在实践中，我们通常有一个大小为N的数据集，所有的估计都必须从这个数据集获得。通常通过二次采样获得不同的训练集，并使用未采样的实例进行测试训练。当使用不同的数据子样本进行测试和训练时，分类器的性能可能会发生变化。换句话说，ML模型的性能对训练过程中使用的特定随机划分非常敏感。下图显示了当使用不同的训练和测试子集时，ML模型的性能可能会发生变化。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ju"><img src="../Images/74c208e52ae4e4a3037dbcc331869163.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eI1NwbducmU5CRHZlBZRgg.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">为了训练ML模型，我们应该将数据集分成两个不同的测试和训练数据集。然后，我们使用k-fold交叉验证基于训练数据集训练模型，并在维持测试数据集上评估模型。</figcaption></figure><p id="4e0c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了理解改变训练集和测试集可能如何改变模型的性能，我们将用<a class="ae jv" href="https://www.kaggle.com/uciml/pima-indians-diabetes-database" rel="noopener ugc nofollow" target="_blank"> Pima Indians diabetes </a>数据集做一个非常简单的例子。数据集的目的是基于数据集中包含的某些诊断测量结果，诊断性地预测患者是否患有糖尿病。我们使用两种不同的ML模型，包括随机森林和支持向量机(SVM ),来训练预测一个人是否患有糖尿病的模型。我们对模型进行了两次训练，每次都使用不同的数据子样本作为训练集(这可以通过更改种子数量或random_state来实现)。此外，我们使用那些没有被采样用于训练的观察值作为测试数据集。</p><pre class="je jf jg jh fd jw jx jy jz aw ka bi"><span id="0f7f" class="kb kc hi jx b fi kd ke l kf kg">#Import required libraries<br/>#import kaggle<br/>import random<br/>import pandas as pd<br/>import numpy as np<br/>from sklearn.model_selection import train_test_split<br/>from sklearn import model_selection, svm<br/>from sklearn.ensemble import RandomForestClassifier<br/>from sklearn.model_selection import cross_val_score<br/>from sklearn.metrics import classification_report, confusion_matrix<br/>from sklearn.model_selection import RandomizedSearchCV<br/>import warnings<br/>warnings.filterwarnings("ignore")</span><span id="92e7" class="kb kc hi jx b fi kh ke l kf kg"># To download the dataset<br/>!kaggle datasets download -d uciml/pima-indians-diabetes-database</span><span id="ba63" class="kb kc hi jx b fi kh ke l kf kg">#To read the dataset<br/>df_pima = pd.read_csv('pima-indians-diabetes-database.zip')</span><span id="8ae2" class="kb kc hi jx b fi kh ke l kf kg">X = df_pima.drop('Outcome', axis=1)<br/>y = df_pima['Outcome']</span><span id="073b" class="kb kc hi jx b fi kh ke l kf kg">RFC_score = []<br/>SVM_score = []<br/>for random_state in [42, 193]:<br/>    # Splitting the dataset into train and test set<br/>    #random_state = random.randint(100, 10000)<br/>    #print(random_state)<br/>    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state= random_state)<br/>    <br/>    # number of trees in random forest<br/>    n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]<br/>    # number of features at every split<br/>    max_features = ['auto', 'sqrt']</span><span id="9df3" class="kb kc hi jx b fi kh ke l kf kg"># max depth<br/>    max_depth = [int(x) for x in np.linspace(100, 500, num = 11)]<br/>    max_depth.append(None)<br/>    # create random grid<br/>    random_grid = {<br/>     'n_estimators': n_estimators,<br/>     'max_features': max_features,<br/>     'max_depth': max_depth<br/>     }<br/>    # Random search of parameters<br/>    rfc_random = RandomizedSearchCV(estimator = RandomForestClassifier(), param_distributions = random_grid, <br/>                                    n_iter = 100, cv = 3, verbose=0, random_state=42, n_jobs = -1)<br/>    # Fit the model<br/>    rfc_random.fit(X_train, y_train)</span><span id="779d" class="kb kc hi jx b fi kh ke l kf kg"># print results<br/>    best_params = rfc_random.best_params_</span><span id="897f" class="kb kc hi jx b fi kh ke l kf kg">rfc = RandomForestClassifier(n_estimators=best_params['n_estimators'], <br/>                                 max_depth=best_params['max_depth'],<br/>                                 max_features=best_params['max_features'], <br/>                                 random_state=42).fit(X_train,y_train);<br/>    RFC_score.append(rfc.score(X_test, y_test))<br/>    <br/>    <br/>    ##Train SVM <br/>    random_grid_svm = {<br/>    'C': [0.001, 0.01, 0.1, 1, 10],<br/>    'gamma': [0.001, 0.01, 0.1, 1]}<br/>    svm_random = RandomizedSearchCV(estimator = svm.SVC(kernel='rbf'),<br/>                                    param_distributions = random_grid_svm, <br/>                                    n_iter = 100, cv = 3, verbose=0,<br/>                                    random_state=42, n_jobs = -1)<br/>    svm_random.fit(X_train, y_train)<br/>    <br/>    best_params = svm_random.best_params_<br/>    <br/>    SVM_model = svm.SVC(kernel='rbf',C = best_params['C'],<br/>              gamma=best_params['gamma'], random_state=42).fit(X_train,y_train);<br/>    <br/>    SVM_score.append(SVM_model.score(X_test, y_test))<br/>    <br/>    #print('Iteration {}'.format(i))<br/>    print('The accuracy of SVM model is {}'.format(round(SVM_model.score(X_test, y_test),2)*100))<br/>    print('The accuracy of Random Forest model is {}'.format(round(rfc.score(X_test, y_test),2)*100))<br/>    print('-'*30)</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ki"><img src="../Images/bc86a09174c2bc3880427bfc10b02c10.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mvjCMumqZv4UzSKO3aCkxQ.png"/></div></div></figure><p id="cc31" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以看到，随机森林法第一次表现得比SVM好；而SVM在第二次迭代中表现出更好的性能。这意味着利用模型性能之间的差异来选择最终模型并不合适。此外，我们不知道域下面的分布，因此不能精确地计算差异。因此，我们需要估计差异的分布。有了差异的分布，我们就可以检查估计的差异是否可能是“真正的”差异，或者只是由于偶然。为了回答这个问题，我们可以使用统计测试。</p><p id="e516" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了执行统计测试，我们还需要不同迭代的差异的均值和方差。如果有足够的数据供应，获得差异的均值和方差的无偏估计是容易的。为此，我们可以从主数据集中抽取一些训练集和测试集。然后，我们应该在每个训练集上训练ML模型，并使用维持测试子集测量模型的性能。接下来，我们可以计算每对分类器的模型性能差异。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es kj"><img src="../Images/a7c0fe30823f713749589f9b11ee68ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZSihnPAYD350e2OHNrAd6w.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">两个分类器性能差异的均值和方差的估计</figcaption></figure><p id="d31f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们在例子中实现它。我们将训练ML模型的过程重复了100次，以观察随机分割数据集对模型性能的影响。下图比较了随机森林模型和SVM模型在准确性方面的性能。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es kk"><img src="../Images/adf1fabf8141f920e35c3d2bea0e7cc7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KMUoSHJKLO3Eah0bIWEpkQ.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">随机森林和SVM重复100次的性能比较</figcaption></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es kk"><img src="../Images/de825cae56b8cfbbe2646cb5ed26859b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Vly2nq3x1lHA_jMkDVJmTw.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">随机森林和SVM重复100次后的性能差异</figcaption></figure><h1 id="9334" class="kl kc hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">统计假设检验</h1><p id="7afb" class="pw-post-body-paragraph if ig hi ih b ii li ik il im lj io ip iq lk is it iu ll iw ix iy lm ja jb jc hb bi translated">有了以上信息，我们现在可以使用统计假设检验来选择最终模型。统计显著性检验旨在比较最大似然模型的表现，并量化表现得分样本被观察到的可能性，假设它们来自相同的分布。如果这个假设或无效假设被拒绝，这表明技能得分的差异在统计学上是显著的。</p><p id="1309" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">用于比较ML模型性能的最常见的统计假设检验是通过训练数据集的随机子样本组合的成对<a class="ae jv" href="https://en.wikipedia.org/wiki/Student's_t-test" rel="noopener ugc nofollow" target="_blank">学生t检验</a>。该测试中的零假设是两个应用的ML模型的性能之间没有差异。换句话说，零假设假设两个ML模型表现相同。另一方面，另一个假设假设两个应用的ML模型表现不同。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ln"><img src="../Images/c4292dadb4a4d21d6dc1d84710dd660d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*1i2uU0DMRC3UmEj4.gif"/></div></div></figure><p id="521e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">虽然配对的<a class="ae jv" href="https://en.wikipedia.org/wiki/Student's_t-test" rel="noopener ugc nofollow" target="_blank">学生的t检验</a>是比较两个不同ML模型性能的一种非常常见的方法，但我们需要在使用它之前检查这个检验背后的假设。关键的假设是:“用于进行配对学生t检验的数据应独立于被比较的两个总体进行抽样”。这种假设通常无法从数据中得到验证。然而，如果已知数据是独立抽样的，那么配对学生的t检验可能会给出误导性的结果。违反这一假设的主要后果是一个高I型错误(即拒绝一个真正的零假设)。</p><p id="a47c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在比较ML模型的性能的情况下，如上所述，测试和训练集通常从原始数据的不同子样本中获得。测试集和训练集在不同的迭代中重叠，因此它们不是独立的。这违反了适当的显著性检验所必需的独立性假设，因为我们重复使用数据来获得差异。违反独立性假设的后果是I类误差超过显著性水平。因此，如果我们使用这个测试，我们可能会发现两个ML模型的性能之间有“显著的”差异，而实际上没有。</p><p id="5502" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">总的来说，配对学生的t检验不是比较两个ML模型性能的有效检验。</p><p id="39ce" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae jv" href="https://link.springer.com/article/10.1023/A:1024068626366" rel="noopener ugc nofollow" target="_blank"> Nadeau和Bengio </a>表明，违反独立性t检验可能会导致差异方差的低估。为了用配对学生的t检验解决这个问题，他们建议通过考虑这种依赖性来修正方差估计。下图显示了我们如何使用由<a class="ae jv" href="https://link.springer.com/article/10.1023/A:1024068626366" rel="noopener ugc nofollow" target="_blank">纳多和本吉奥</a>提出的方法修改方差估计并计算P值。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lo"><img src="../Images/4348ee3f45c00fb6d0f73db8f4e8e61b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y_pF_cDQ2iD4JMl_1Z9kOA.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">由<a class="ae jv" href="https://link.springer.com/article/10.1023/A:1024068626366" rel="noopener ugc nofollow" target="_blank">纳多和本吉奥</a>提出的校正后的配对学生t检验</figcaption></figure><p id="b5d0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上面计算的t统计与具有<em class="lp"> n-1 </em>自由度的Student-t分布一起使用，以量化模型性能差异的置信水平或显著性。这使得作为模型选择的一部分，比使用原始的成对学生t检验更有力和更可靠。</p><p id="ffbb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">由于零假设是没有任何事情发生或者两个ML模型的性能之间没有差异，所以小于所考虑的显著性水平的P值拒绝零假设，而支持替代假设，替代假设假设ML模型的性能不同。此外，大于显著性水平的P值表明我们未能拒绝零假设。</p><p id="0a54" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们使用上面的过程来比较随机森林和SVM模型对于我们的案例研究数据集的性能。</p><pre class="je jf jg jh fd jw jx jy jz aw ka bi"><span id="518d" class="kb kc hi jx b fi kd ke l kf kg">#Compute the difference between the results</span><span id="f284" class="kb kc hi jx b fi kh ke l kf kg">diff = [y - x for y, x in zip(RFC_score, SVM_score)]</span><span id="cbf3" class="kb kc hi jx b fi kh ke l kf kg">#Comopute the mean of differences<br/>d_bar = np.mean(diff)</span><span id="77f5" class="kb kc hi jx b fi kh ke l kf kg">#compute the variance of differences<br/>sigma2 = np.var(diff)</span><span id="fe05" class="kb kc hi jx b fi kh ke l kf kg">#compute the number of data points used for training <br/>n1 = len(y_train)</span><span id="593a" class="kb kc hi jx b fi kh ke l kf kg">#compute the number of data points used for testing <br/>n2 = len(y_test)</span><span id="241f" class="kb kc hi jx b fi kh ke l kf kg">#compute the total number of data points<br/>n = len(y)</span><span id="2155" class="kb kc hi jx b fi kh ke l kf kg">#compute the modified variance<br/>sigma2_mod = sigma2 * (1/n + n2/n1)</span><span id="1531" class="kb kc hi jx b fi kh ke l kf kg">#compute the t_static</span><span id="ef35" class="kb kc hi jx b fi kh ke l kf kg">t_static =  d_bar / np.sqrt(sigma2_mod)</span><span id="ae60" class="kb kc hi jx b fi kh ke l kf kg">from scipy.stats import t</span><span id="f28c" class="kb kc hi jx b fi kh ke l kf kg">#Compute p-value and plot the results <br/>Pvalue = ((1 - t.cdf(t_static, n-1))*200)</span><span id="8ea9" class="kb kc hi jx b fi kh ke l kf kg">Pvalue</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lq"><img src="../Images/c1b6672fb1f721841263d71a0e74c43b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0p4eUEtdFIZwvopWWbdQ8g.png"/></div></div></figure><p id="8d2b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">本案例研究的P值约为1.85%，小于考虑的显著性水平(即5%)，表明我们可以拒绝零假设。因此，统计结果提供了令人信服的证据，表明随机森林和SVM表现不同。平均而言，随机森林模型的平均精度比SVM模型高4%。</p></div></div>    
</body>
</html>