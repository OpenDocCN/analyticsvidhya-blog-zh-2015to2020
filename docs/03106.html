<html>
<head>
<title>Principal Component Analysis: Too many variables here…</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">主成分分析:这里的变量太多了…</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/principal-component-analysis-too-many-variables-here-73dddec6b53d?source=collection_archive---------8-----------------------#2020-01-16">https://medium.com/analytics-vidhya/principal-component-analysis-too-many-variables-here-73dddec6b53d?source=collection_archive---------8-----------------------#2020-01-16</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="e509" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们生活在一个多维的世界里(三维空间，时间和++)！重要的业务变量，如收入、客户保持率、运营成本等。往往取决于各种其他变量，如广告预算、市场规模、客户人口统计、经济状况等等！企业可以控制这些变量中的一些，以优化他们想要的结果，还有一些是企业必然要处理的自然/经济的一部分。可以改变以改善结果的变量被称为<em class="jd">自变量</em>，历史上用“<strong class="ih hj"> <em class="jd"> X </em> </strong>”(单个变量的向量<strong class="ih hj"> x1、x2、x3、</strong>…等)表示。并且，结果变量，或者感兴趣的变量称为<em class="jd">因变量</em>，通常用“<strong class="ih hj"> <em class="jd"> Y </em> </strong>”表示。</p><p id="d6a5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">好的统计分析可以帮助我们更好地理解<strong class="ih hj"> <em class="jd"> X </em> </strong>和<strong class="ih hj"> <em class="jd"> Y </em> </strong>之间的关系，并赋能最优决策，即如何在<strong class="ih hj"> <em class="jd"> X </em> </strong>空间中移动来改进我们的<strong class="ih hj"> <em class="jd"> Y </em> </strong>。在现实世界的利益场景中，独立变量空间<strong class="ih hj"><em class="jd">【X】</em></strong>通常由许多变量组成，这使得分析它们变得复杂。此外，自变量经常是相关的，这使得确定单个自变量对因变量的影响更加困难。</p><h2 id="288e" class="je jf hi bd jg jh ji jj jk jl jm jn jo iq jp jq jr iu js jt ju iy jv jw jx jy bi translated">方差是信息(它使变量成为“变量”<em class="jz"> ) </em></h2><p id="be93" class="pw-post-body-paragraph if ig hi ih b ii ka ik il im kb io ip iq kc is it iu kd iw ix iy ke ja jb jc hb bi translated">主成分分析假设将所有数据(所有自变量，<strong class="ih hj"> <em class="jd"> X </em> </strong>)视为一条连续的信息，用数据中的方差来表示。为了分析这些信息对因变量<strong class="ih hj"> <em class="jd"> Y </em> </strong>的影响，我们需要量化这些信息。出于这个目的，正交坐标表示是最合适的，因为笛卡尔坐标系统有许多成熟的分析技术。假设原始数据已经在笛卡尔坐标系中表示，寻找数据的新表示只需要我们找到原始数据的适当变换。</p><p id="d6a8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">此外，主成分分析试图找到最佳的性价比，即新的转换变量应该捕获数据中的大部分信息(方差！)用最少的变量，这有助于减少要分析的变量数量和它们之间的相互关联。</p><p id="c97e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">此外，主成分分析是一种线性技术，因此转换可以用矩阵形式表示，而且PCA不缩放数据，这将无缘无故地改变数据中的方差。因此，更具体地说，PCA变换仅由旋转矩阵确定。</p><blockquote class="kf kg kh"><p id="fb76" class="if ig jd ih b ii ij ik il im in io ip ki ir is it kj iv iw ix kk iz ja jb jc hb bi translated">PCA变换原始独立数据以最少数量的变换变量最大化方差。变换只是旋转。</p></blockquote></div><div class="ab cl kl km gp kn" role="separator"><span class="ko bw bk kp kq kr"/><span class="ko bw bk kp kq kr"/><span class="ko bw bk kp kq"/></div><div class="hb hc hd he hf"><h1 id="c370" class="ks jf hi bd jg kt ku kv jk kw kx ky jo kz la lb jr lc ld le ju lf lg lh jx li bi translated">算术地</h1><p id="22b3" class="pw-post-body-paragraph if ig hi ih b ii ka ik il im kb io ip iq kc is it iu kd iw ix iy ke ja jb jc hb bi translated">等等什么！？但是，如何用最少的变量使方差最大化，我们如何事先知道变量的数量。此外，如果我们只进行坐标旋转，所有变量之间的总方差将保持不变，因此如何定义该问题不是一个简单的优化问题。因此，我们试图为新坐标系顺序地找到单位矢量:</p><p id="3c7a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">设<strong class="ih hj"> <em class="jd"> X </em> </strong>为(n <em class="jd"> x </em> p)矩阵，n个观测值和p个变量。正如，我们只旋转新矢量(w)应当是一个单位矢量。因此，转换到新的基向量系统的所有数据点的方差可以表示为:</p><figure class="lk ll lm ln fd lo er es paragraph-image"><div class="er es lj"><img src="../Images/55381aec0bbdc1627a403e656b824250.png" data-original-src="https://miro.medium.com/v2/resize:fit:286/format:webp/1*Po2urSibtCPC5C0Su4iyqA.png"/></div><figcaption class="lr ls et er es lt lu bd b be z dx translated">w是新的单位向量| xi是第I个X向量的值</figcaption></figure><figure class="lk ll lm ln fd lo er es paragraph-image"><div class="er es lv"><img src="../Images/d4d2df174d19d0e08f4af93fad6de4e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:316/format:webp/1*gKEWvi-6GQs1DyWhiQTSTA.png"/></div></figure><p id="6d03" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里中项实质上是<strong class="ih hj"> <em class="jd"> X、</em> </strong>的协方差矩阵，我们用<strong class="ih hj"> <em class="jd"> v </em> </strong>来表示:</p><figure class="lk ll lm ln fd lo er es paragraph-image"><div class="er es lw"><img src="../Images/b5f4b415f6076f51e2d1ba52982b83a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:172/format:webp/1*7dx22ZBocjIa9BwEHWdjsw.png"/></div></figure><p id="15ab" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了最大化这个方程中的方差，我们可以使用拉格朗日乘数。遵守约束<strong class="ih hj"> <em class="jd"> w </em> </strong>成为单位矢量:</p><figure class="lk ll lm ln fd lo er es paragraph-image"><div class="er es lx"><img src="../Images/bf9d22453e60d9907a59d9ddd675897c.png" data-original-src="https://miro.medium.com/v2/resize:fit:156/format:webp/1*YWMmj8d-WpOki7qMfq15mg.png"/></div><figcaption class="lr ls et er es lt lu bd b be z dx translated">单位向量约束</figcaption></figure><figure class="lk ll lm ln fd lo er es paragraph-image"><div class="er es ly"><img src="../Images/a5caf0e2998c519245b886c05dc44d7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:396/format:webp/1*ISZrbdLtNSym2kc1N6hIMg.png"/></div><figcaption class="lr ls et er es lt lu bd b be z dx translated">拉格朗日优化函数</figcaption></figure><p id="c64d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对上述方程进行偏导数，我们得到:</p><figure class="lk ll lm ln fd lo er es paragraph-image"><div class="er es lz"><img src="../Images/fe50fca4e2d88111436955b776f70541.png" data-original-src="https://miro.medium.com/v2/resize:fit:242/format:webp/1*ufxfJVlF_J7YtruyOtrkFQ.png"/></div></figure><p id="e4ee" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了获得最佳解，我们将导数设为零，从而得到:</p><figure class="lk ll lm ln fd lo er es paragraph-image"><div class="er es ma"><img src="../Images/bc7c10df7c9263aca8cf6e88ee8bbd88.png" data-original-src="https://miro.medium.com/v2/resize:fit:150/format:webp/1*um854ULX5NXjOlZ_o7g3PA.png"/></div></figure><p id="978d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里，第一个方程本质上是我们的约束。而第二个等式表明<strong class="ih hj"> <em class="jd"> w </em> </strong>是协方差矩阵<strong class="ih hj"> <em class="jd"> v </em> </strong>的特征向量，特征值为λ <em class="jd">。</em>另外，协方差矩阵的其他特征向量表示要变换到的其他向量。所有的特征向量a合起来就是数据的主成分，而特征值就是相应特征向量所解释的数据中总方差的比例。</p><p id="42e3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于p维空间对共方差矩阵进行特征分解我们会得到p-特征向量，它解释了数据中的所有方差(没有那么多的降维，嗯！).这并不奇怪，因为储存在p维空间的信息只能在p维空间中被完整地捕捉到(不总是，但大部分是，耶！).然而，主成分在几个变量中积累了最大的方差，允许我们在不损失太多总信息(方差)的情况下显著减少维数。</p><p id="55d5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后，原始数据点的值可以作为主成分向量(协方差矩阵的特征向量)的投影来获得。</p></div><div class="ab cl kl km gp kn" role="separator"><span class="ko bw bk kp kq kr"/><span class="ko bw bk kp kq kr"/><span class="ko bw bk kp kq"/></div><div class="hb hc hd he hf"><h1 id="ada0" class="ks jf hi bd jg kt ku kv jk kw kx ky jo kz la lb jr lc ld le ju lf lg lh jx li bi translated">代码化(希望是一个字！)</h1><p id="6db1" class="pw-post-body-paragraph if ig hi ih b ii ka ik il im kb io ip iq kc is it iu kd iw ix iy ke ja jb jc hb bi translated">在这个例子中，我将使用Python (Numpy)。为了绘图，我将使用散景。</p><figure class="lk ll lm ln fd lo"><div class="bz dy l di"><div class="mb mc l"/></div></figure><figure class="lk ll lm ln fd lo er es paragraph-image"><div class="er es md"><img src="../Images/8dbe629921add8c7cdd61cb5cad90e49.png" data-original-src="https://miro.medium.com/v2/resize:fit:418/format:webp/1*kQ--atS6vh5N0BQ1h7S2Dg.png"/></div></figure><figure class="lk ll lm ln fd lo"><div class="bz dy l di"><div class="mb mc l"/></div></figure><figure class="lk ll lm ln fd lo er es paragraph-image"><div class="er es me"><img src="../Images/5dde661d008780a41d2f5d6271e2c6e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1212/format:webp/1*MswxMKva3BU7USyslvEgeg.png"/></div></figure><figure class="lk ll lm ln fd lo"><div class="bz dy l di"><div class="mb mc l"/></div></figure><figure class="lk ll lm ln fd lo er es paragraph-image"><div class="er es mf"><img src="../Images/9c639f965b216233c5789553130a1ae2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1214/format:webp/1*7FF8nbIHrLs6rrsgdGXB2Q.png"/></div></figure><p id="2570" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，数据在新坐标系(以特征向量为基础)上的表示可以简单地通过原始数据与特征向量的矩阵乘法来获得。</p><figure class="lk ll lm ln fd lo"><div class="bz dy l di"><div class="mb mc l"/></div></figure><figure class="lk ll lm ln fd lo er es paragraph-image"><div class="er es mg"><img src="../Images/e18d0e5b32fcf602f2e23f36bc2e385c.png" data-original-src="https://miro.medium.com/v2/resize:fit:554/format:webp/1*nMEToHnwk-x6CFCRIkchRw.png"/></div></figure><p id="8ab2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">数据中的总方差是协方差矩阵的对角元素之和。</p><ul class=""><li id="7c8b" class="mh mi hi ih b ii ij im in iq mj iu mk iy ml jc mm mn mo mp bi translated">原始矩阵:3.59779384+7.95821334 =<strong class="ih hj">11.55600718</strong></li><li id="435f" class="mh mi hi ih b ii mq im mr iq ms iu mt iy mu jc mm mn mo mp bi translated">已转换:0.344003084+11.2120041 =<strong class="ih hj">11.55600718</strong></li><li id="fd36" class="mh mi hi ih b ii mq im mr iq ms iu mt iy mu jc mm mn mo mp bi translated">特征值之和:0.34400308+11.212004 =<strong class="ih hj">11.55600718</strong></li></ul><p id="0561" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，总方差保持不变！此外，特征值表示由新数据表示法解释的方差，这也累加到相同的值。但好的一面是，一个向量现在代表了所有数据中97%的方差。因此，如果减少一个特征向量(即减少50%的维数)，我们将只损失3%的信息，很大，对吧！</p></div></div>    
</body>
</html>