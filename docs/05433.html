<html>
<head>
<title>OhMyGraphs: GraphSAGE and inductive representation learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">OhMyGraphs: GraphSAGE和归纳表示学习</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/ohmygraphs-graphsage-and-inductive-representation-learning-ea26d2835331?source=collection_archive---------1-----------------------#2020-04-21">https://medium.com/analytics-vidhya/ohmygraphs-graphsage-and-inductive-representation-learning-ea26d2835331?source=collection_archive---------1-----------------------#2020-04-21</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="e08d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi jd translated">他的文章假设你对图及其在图神经网络中的作用有所了解。这是我遇到的一系列很酷的图形神经网络/图形表示学习论文中的第一篇！</p><h1 id="d586" class="jm jn hi bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated">什么是GraphSAGE？</h1><p id="a64b" class="pw-post-body-paragraph if ig hi ih b ii kk ik il im kl io ip iq km is it iu kn iw ix iy ko ja jb jc hb bi translated"><a class="ae kp" href="https://arxiv.org/abs/1706.02216" rel="noopener ugc nofollow" target="_blank"> GraphSAGE </a> [1]是一种迭代算法，学习某个图中每个节点的图嵌入。GraphSAGE的新颖之处在于，它是第一个以无人监管的方式创建归纳节点嵌入的作品！就像在NLP中一样，创建嵌入对于下游任务非常有用。GNNs可以将节点嵌入用于各种任务，包括节点分类、链路预测、社区检测、网络分析等。</p><p id="4880" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">对GraphSAGE的需求:</strong></p><p id="83f1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在GraphSAGE之前，大多数节点嵌入模型都是基于谱分解/矩阵分解方法的。</p><p id="13d1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">问题？矩阵分解方法有<strong class="ih hj">固有<em class="kq">直推</em> </strong>！简而言之，直推式方法在从未见过的数据上表现不佳。也就是说，这些方法期望整个图结构在列车运行时出现，以生成节点嵌入。如果稍后有新的节点添加到图中，则必须重新训练模型。</p><p id="0702" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">相反，归纳方法可以推广到看不见的数据——显然更有用，对吗？让我们深入了解GraphSAGE背后的直觉。</p><h1 id="128e" class="jm jn hi bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated">GraphSAGE背后的主要思想是:</h1><blockquote class="kr"><p id="4bab" class="ks kt hi bd ku kv kw kx ky kz la jc dx translated">你被你的朋友所知。</p></blockquote><figure class="lc ld le lf lg lh er es paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="er es lb"><img src="../Images/c0d5043a8d2e77bfafe31b1e9b5324e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yBwgEX7OxVtFkTqrrH_Mvw.png"/></div></div></figure><p id="144d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在上图中，如果你是一个90年代的孩子，你很容易猜出弗雷德、维尔玛、达芙妮和沙吉都和谁有关系。如果你猜是Scooby，那是因为你意识到无论中间节点是谁，都必须与所有相邻节点有关系。你在脑子里秘密做的是，你根据史酷比节点的相邻节点来近似表示它！</p><h1 id="8dc5" class="jm jn hi bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated">真正的文法</h1><p id="0891" class="pw-post-body-paragraph if ig hi ih b ii kk ik il im kl io ip iq km is it iu kn iw ix iy ko ja jb jc hb bi translated">GraphSAGE的目标是基于其相邻节点的某种组合来学习每个节点的表示，由<strong class="ih hj"> h </strong>参数化。</p><figure class="lp lq lr ls fd lh er es paragraph-image"><div class="er es lo"><img src="../Images/2f6667717a40cf0443f685d185a616b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:490/format:webp/1*3fIUrq5IDkhlbBNblVQzbQ.png"/></div></figure><p id="5d0f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">回想一下，每个节点都可以有自己的特征向量，该向量由<strong class="ih hj"> X </strong>参数化。现在让我们假设每个节点的所有特征向量大小相同。一层GraphSAGE可以运行<strong class="ih hj"> k </strong>次迭代，因此，在每次<strong class="ih hj"> k </strong>次迭代中，每个节点都有一个节点表示<strong class="ih hj"> h </strong>。</p><p id="686a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">请注意以下符号:</p><figure class="lp lq lr ls fd lh er es paragraph-image"><div class="er es lt"><img src="../Images/a1f49393965ce61331dd6b8bab04971a.png" data-original-src="https://miro.medium.com/v2/resize:fit:822/format:webp/1*wwosgHbSU5sg6JrB7UDpLA.png"/></div></figure><p id="c9de" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因为每个节点都可以由它们的邻居来定义，所以节点A的嵌入可以由它的邻居节点嵌入向量的某种组合来表示。通过一轮GraphSAGE算法，我们将获得节点a的新表示。原始图中的所有节点都遵循相同的过程。</p><figure class="lp lq lr ls fd lh er es paragraph-image"><div class="er es lu"><img src="../Images/5eebe556993b82eda55e75329b149a6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/format:webp/1*i1Be2LdgQQDZiLu_M-XnDQ.png"/></div></figure><p id="33fa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">GraphSAGE算法遵循两步过程。因为它是迭代的，所以有一个初始化步骤，将所有初始节点嵌入向量设置为它们的特征向量。(<strong class="ih hj"> k </strong>将从<strong class="ih hj"> 1…K </strong>开始迭代)</p><figure class="lp lq lr ls fd lh er es paragraph-image"><div class="er es lv"><img src="../Images/eea1680d6dca742767e8efe7b50621b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:688/format:webp/1*NGc5vzMHMQivcuZUVNkKgw.png"/></div></figure><ol class=""><li id="9c29" class="lw lx hi ih b ii ij im in iq ly iu lz iy ma jc mb mc md me bi translated"><strong class="ih hj">聚合。</strong></li></ol><p id="a872" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">聚合目标节点的相邻节点表示。<strong class="ih hj"> f_aggregate </strong>函数是任何可微分函数的占位符。这可以像平均函数一样简单，也可以像神经网络一样复杂。下面的等式转化为:</p><blockquote class="mf mg mh"><p id="adcb" class="if ig kq ih b ii ij ik il im in io ip mi ir is it mj iv iw ix mk iz ja jb jc hb bi translated">聚集在我的目标节点节点<strong class="ih hj"> v </strong>的<em class="hi">直接</em>邻域中的所有节点<strong class="ih hj"> u </strong>的所有嵌入向量。这导致节点<strong class="ih hj"> v </strong>的聚集节点表示为<strong class="ih hj"> a_v: </strong></p></blockquote><figure class="lp lq lr ls fd lh er es paragraph-image"><div class="er es ml"><img src="../Images/a523ec8b2b447e77f742214f0f4fc93e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1300/format:webp/1*tGsIPlCUt6C6DZ0zGfXT4g.png"/></div></figure><p id="3c1c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.<strong class="ih hj">更新。</strong></p><p id="ee97" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在基于其邻居获得节点<strong class="ih hj"> v </strong>的聚集表示之后，使用其先前表示和聚集表示的组合来更新当前节点<strong class="ih hj"> v </strong>。<strong class="ih hj"> f_update </strong>函数是任何可微分函数的占位符，它可以像平均函数一样简单，也可以像神经网络一样复杂。</p><p id="f335" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面的等式转化为:</p><blockquote class="mf mg mh"><p id="0815" class="if ig kq ih b ii ij ik il im in io ip mi ir is it mj iv iw ix mk iz ja jb jc hb bi translated">基于节点<strong class="ih hj"> v </strong>的邻域聚合表示和节点<strong class="ih hj"> v </strong>的先前表示，为节点<strong class="ih hj">v</strong>创建更新的表示:</p></blockquote><figure class="lp lq lr ls fd lh er es paragraph-image"><div class="er es mm"><img src="../Images/c6b1b19bfa4740c9f6f8ccaf684adef5.png" data-original-src="https://miro.medium.com/v2/resize:fit:888/format:webp/1*MIyBPacSYKsYEH6IOad-lQ.png"/></div></figure><p id="3d75" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，GraphSAGE背后的基础包括聚合和更新节点表示——但是这个<strong class="ih hj"> k </strong>超参数呢？k参数告诉算法使用多少个<em class="kq">邻域或多少跳</em>来计算节点<strong class="ih hj"> v </strong>的表示。</p><p id="260a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了说明这一点，请观察下图。我们不需要将节点B的表示初始化为它的特征向量，实际上我们可以运行这个聚合更新函数来获得节点B基于其邻居的表示。我们可以对<strong class="ih hj"> k=1 </strong>层中的节点C和D进行同样的操作。在k=0层，我们将初始化嵌入到其初始特征向量的邻居节点。</p><figure class="lp lq lr ls fd lh er es paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="er es mn"><img src="../Images/24750c9d6cccd61d7cc1354c5be82bd3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_szCU91LLdyE_ZQmqSTJBQ.png"/></div></div></figure><p id="11e9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在上面的例子中，我们简单地设置<strong class="ih hj"> k </strong> =2，并使用节点A的邻居和邻居来获得最终的目标节点表示。你可以尝试使用多个邻域，例如，更大的T2 k T3值。然而，太多的邻域可能会稀释节点<strong class="ih hj"> v </strong>的节点表示，但是太少(少于2个)可能类似于不使用GNNs，而只使用MLP——值得思考！</p><p id="eb20" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">太好了！所以现在，我们应该没有问题理解原始论文中的以下算法:</p><figure class="lp lq lr ls fd lh er es paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="er es mo"><img src="../Images/55d7bcc645012aa8f3d7923463ce82a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OV96VB0hDMsGuYhgzI4ZLw.png"/></div></div></figure><p id="0619" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">关于本文的实现，需要注意以下几点:</p><ul class=""><li id="7e46" class="lw lx hi ih b ii ij im in iq ly iu lz iy ma jc mp mc md me bi translated"><strong class="ih hj">第4行:</strong>作者试验了各种聚合函数，包括使用最大池、平均聚合甚至LSTM聚合。LSTM聚合方法要求每k次迭代对节点进行洗牌，以便在计算聚合时不会暂时偏向任何一个节点。</li><li id="740e" class="lw lx hi ih b ii mq im mr iq ms iu mt iy mu jc mp mc md me bi translated"><strong class="ih hj">第四行:</strong>我们概括为<strong class="ih hj"> f_aggregate </strong>的，在文中实际上表示为<strong class="ih hj"> AGGREGATE_k </strong>。</li><li id="0ed0" class="lw lx hi ih b ii mq im mr iq ms iu mt iy mu jc mp mc md me bi translated"><strong class="ih hj">第5行:</strong>文中的<strong class="ih hj"> f_update </strong>函数是一个串联操作。因此，在连接之后，输出的形状是多维的<em class="kq"> (2F，1) </em>。级联的输出通过与权重矩阵<strong class="ih hj"> W^k </strong>的矩阵乘法进行变换。该权重矩阵旨在将输出的维度减少到<em class="kq"> (F，1) </em>。最后，连接和变换的节点嵌入向量经历非线性。</li><li id="88b6" class="lw lx hi ih b ii mq im mr iq ms iu mt iy mu jc mp mc md me bi translated"><strong class="ih hj">第5行:</strong>每个k次迭代有一个单独的权重矩阵。这具有对学习权重的解释，学习权重知道多个邻域对目标节点有多重要。</li><li id="b8e7" class="lw lx hi ih b ii mq im mr iq ms iu mt iy mu jc mp mc md me bi translated"><strong class="ih hj">第7行:</strong>节点嵌入通过除以向量范数进行归一化，防止梯度爆炸。</li></ul><h1 id="ed98" class="jm jn hi bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated">无监督损失函数</h1><p id="d9b2" class="pw-post-body-paragraph if ig hi ih b ii kk ik il im kl io ip iq km is it iu kn iw ix iy ko ja jb jc hb bi translated">那么，一个人如何训练一个笔迹学家GNN呢？</p><p id="a71d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">作者训练了无监督和有监督的GraphSAGE模型。监督设置遵循节点分类任务的常规交叉熵风格预测。然而，无监督的情况试图通过实施以下损失函数来保持图形结构:</p><figure class="lp lq lr ls fd lh er es paragraph-image"><div class="er es mv"><img src="../Images/a677a0780f7f7f5903b7938a1172e7e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1184/format:webp/1*rMO7jjiW5Br8K647PHnD7g.png"/></div></figure><p id="2153" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">损失函数的蓝色部分试图强调如果节点<strong class="ih hj"> u </strong>和<strong class="ih hj"> v </strong>在实际的图中是接近的，那么它们的节点嵌入应该是语义相似的。在完美的场景中，我们期望<strong class="ih hj"> z_u </strong>和<strong class="ih hj"> z_v </strong>的内积是一个大数。这个大数的sigmoid被推向1，log(1) = 0。</p><p id="eae2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">损失函数的粉色部分试图执行相反的情况！也就是说，如果节点<strong class="ih hj"> u </strong>和<strong class="ih hj"> v </strong>在实际的图中实际上很远，我们期望它们的节点嵌入是不同的/相反的。在完美的场景中，我们期望<strong class="ih hj"> z_u </strong>和<strong class="ih hj"> z_v </strong>的内积是一个大的负数。这可以解释为，嵌入<strong class="ih hj"> z_u </strong>和<strong class="ih hj"> z_v </strong>相差如此之大，以至于相差大于90度。两个大负数的乘积变成一个大正数。这个大数的sigmoid被推向1，log(1) = 0。由于在图中可能有更多的节点<strong class="ih hj"> u </strong>远离我们的目标节点<strong class="ih hj"> v </strong>，我们只从远离节点<strong class="ih hj"> v </strong> : <strong class="ih hj"> P_n(v) </strong>的节点分布中抽取几个负节点<strong class="ih hj"> u </strong>。这确保了训练时损失函数是平衡的。</p><p id="6836" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">epsilon的加入确保了我们永远不会取log(0)。</p><h1 id="2cf3" class="jm jn hi bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated">TL，DR: GraphSAGE</h1><p id="0c0f" class="pw-post-body-paragraph if ig hi ih b ii kk ik il im kl io ip iq km is it iu kn iw ix iy ko ja jb jc hb bi translated">GraphSAGE是一种聚合给定目标节点的相邻节点嵌入的方法。一轮GraphSAGE的输出包括为图中的每个节点找到新的节点表示。GraphSAGE的几个堆叠层可以为任何下游任务创建复杂的、结构化的和语义级的特性！</p><p id="ac69" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在以后的文章中，我将为简单的任务实现GraphSAGE，比如节点分类。敬请期待！</p><h1 id="05b1" class="jm jn hi bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated"><strong class="ak">参考文献</strong>:</h1><p id="1453" class="pw-post-body-paragraph if ig hi ih b ii kk ik il im kl io ip iq km is it iu kn iw ix iy ko ja jb jc hb bi translated">[1]<a class="ae kp" href="http://snap.stanford.edu/graphsage/" rel="noopener ugc nofollow" target="_blank">http://snap.stanford.edu/graphsage/</a></p></div></div>    
</body>
</html>