<html>
<head>
<title>Machine Learning 101 — Web Scraping using BeautifulSoup</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习101 —使用BeautifulSoup进行网页抓取</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/machine-learning-101-web-scraping-using-beautifulsoup-b81504ed4d65?source=collection_archive---------21-----------------------#2020-05-23">https://medium.com/analytics-vidhya/machine-learning-101-web-scraping-using-beautifulsoup-b81504ed4d65?source=collection_archive---------21-----------------------#2020-05-23</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="3b03" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Web抓取是一种用于从网站中访问和提取大量数据的基本技术。虽然该过程可以手动完成，但它通常指的是使用bot或网络爬虫从特定网页中自动提取我们所需数据的过程。这最终为用户节省了大量的时间和精力。今天我们来看一个小例子，我们从<a class="ae jd" href="https://www.imdb.com/" rel="noopener ugc nofollow" target="_blank"> IMDb </a>那里收集评论。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/95a3f25ac8e95f419fb5284f5f293698.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*M71v502iM5VvzbrY"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated"><a class="ae jd" href="https://unsplash.com/@pankajpatel?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">潘卡杰·帕特尔</a>在<a class="ae jd" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><h2 id="bec7" class="kb kc hi bd kd ke kf kg kh ki kj kk kl iq km kn ko iu kp kq kr iy ks kt ku kv bi translated">Python中的Web抓取</h2><p id="24a1" class="pw-post-body-paragraph if ig hi ih b ii kw ik il im kx io ip iq ky is it iu kz iw ix iy la ja jb jc hb bi translated">Python包含一些可用于web抓取的框架:</p><ul class=""><li id="370c" class="lb lc hi ih b ii ij im in iq ld iu le iy lf jc lg lh li lj bi translated">这个库是一个完整的包，它自动化了所有的任务，包括以HTML格式下载我们的页面，并以我们想要的格式存储它们。由于它是一个成熟的框架，学习曲线非常陡峭，对于简单的任务来说可能过于复杂。</li><li id="2a5c" class="lb lc hi ih b ii lk im ll iq lm iu ln iy lo jc lg lh li lj bi translated">BeautifulSoup: 一个非常适合初学者的库，学习曲线很短。它本质上是一个解析库，创建一个解析树，帮助我们轻松地在网页上找到我们的数据。</li><li id="624b" class="lb lc hi ih b ii lk im ll iq lm iu ln iy lo jc lg lh li lj bi translated"><strong class="ih hj"> Selenium: </strong>自动化库<strong class="ih hj"> </strong>访问浏览器并从通过JavaScript呈现的HTML中提取数据。它通过执行点击、选择和滚动来模仿人类的动作。</li><li id="f0e3" class="lb lc hi ih b ii lk im ll iq lm iu ln iy lo jc lg lh li lj bi translated"><strong class="ih hj"> Urllib: </strong>一个包含几个模块的包，用于处理统一资源定位器(URL)。它预装在Python库中，定义了执行URL操作的简单函数和类。</li><li id="77fd" class="lb lc hi ih b ii lk im ll iq lm iu ln iy lo jc lg lh li lj bi translated">请求:它类似于urllib库，除了它提供了一个更简单的接口，对于简单的任务非常有用。</li></ul><p id="bf03" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">出于我们的目的，我们将使用<em class="lp"> BeautifulSoup </em>和<em class="lp"> Requests </em>从IMDb提取评论。我们的重点是网飞和亚马逊Prime Video上的印度节目。我们的节目列表包括:</p><p id="1eb2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">网飞:</p><ol class=""><li id="46dd" class="lb lc hi ih b ii ij im in iq ld iu le iy lf jc lq lh li lj bi translated">神圣的游戏</li><li id="a91e" class="lb lc hi ih b ii lk im ll iq lm iu ln iy lo jc lq lh li lj bi translated">小事情</li><li id="bc27" class="lb lc hi ih b ii lk im ll iq lm iu ln iy lo jc lq lh li lj bi translated">贾姆塔拉:萨布卡号</li><li id="3333" class="lb lc hi ih b ii lk im ll iq lm iu ln iy lo jc lq lh li lj bi translated">血吟游诗人</li><li id="f05a" class="lb lc hi ih b ii lk im ll iq lm iu ln iy lo jc lq lh li lj bi translated">利拉</li></ol><figure class="jf jg jh ji fd jj er es paragraph-image"><a href="https://www.gqindia.com/binge-watch/collection/list-of-all-the-best-web-series-original-shows-to-watch-on-netflix-india-amazon-prime-video-tvf-play-youtube/"><div class="er es lr"><img src="../Images/aa85e2f1b225ae7895af030f5e4f1d57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*RfhS0_V3dW83GRkc.jpg"/></div></a><figcaption class="jq jr et er es js jt bd b be z dx translated">过多的印度电视节目在OTT平台上留下了印记</figcaption></figure><p id="045f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">亚马逊Prime视频:</strong></p><ol class=""><li id="b867" class="lb lc hi ih b ii ij im in iq ld iu le iy lf jc lq lh li lj bi translated">米尔扎布尔</li><li id="d5a0" class="lb lc hi ih b ii lk im ll iq lm iu ln iy lo jc lq lh li lj bi translated">天堂制造</li><li id="88cc" class="lb lc hi ih b ii lk im ll iq lm iu ln iy lo jc lq lh li lj bi translated">内部边缘</li><li id="d1b4" class="lb lc hi ih b ii lk im ll iq lm iu ln iy lo jc lq lh li lj bi translated">五人长老会</li><li id="1345" class="lb lc hi ih b ii lk im ll iq lm iu ln iy lo jc lq lh li lj bi translated">《居家男人》</li></ol></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><p id="d6a5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="lp">一句提醒的话</em> </strong></p><p id="617d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">大多数网站可能不允许网络抓取，因为它们包含敏感信息。要检查是否允许web scraper，首先访问该网站的<em class="lp"> /robots.txt </em>页面。IMDb <em class="lp"> /robots.txt </em>页面显示如下:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es ls"><img src="../Images/53af593e76a7b7aca1fb477da82014fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:702/format:webp/1*dLG3MSW7GfWB_TtBR3aJUA.png"/></div><figcaption class="jq jr et er es js jt bd b be z dx translated">【https://www.imdb.com/robots.txt T4】</figcaption></figure><p id="c165" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">此外，重要的是要记住不要在短时间内执行大量的请求，从而过度使用web scraper。这可能会导致您的IP地址被标记，并随后被阻止，所以一定要小心。大多数网站，如雅虎！如今，金融和Twitter提供了非常成熟的API来提取数据，所以你可以使用它们。</p></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><h2 id="97c5" class="kb kc hi bd kd ke kf kg kh ki kj kk kl iq km kn ko iu kp kq kr iy ks kt ku kv bi translated">开始抓取网页吧！</h2><p id="6347" class="pw-post-body-paragraph if ig hi ih b ii kw ik il im kx io ip iq ky is it iu kz iw ix iy la ja jb jc hb bi translated">第一项任务是打开我们的web页面，通过右键单击我们希望从中提取信息的元素来检查它。我们目前正在为2018年风靡网飞的印度节目《神圣的游戏》提取评论。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lt"><img src="../Images/bdd6e5f278e816360bdc77fd4548909f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YHeyEoGK2bamcQTm9dRsOQ.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated"><a class="ae jd" href="https://www.imdb.com/title/tt6077448/reviews?ref_=tt_urv" rel="noopener ugc nofollow" target="_blank">https://www.imdb.com/title/tt6077448/reviews?ref_=tt_urv</a></figcaption></figure><p id="1d33" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一旦我们点击inspect，DevTools选项卡就会在我们页面的右侧打开(因为我用的是Google Chrome)。在这之后，我们必须找到包含我们要寻找的信息的各种div。</p><pre class="jf jg jh ji fd lu lv lw lx aw ly bi"><span id="1c99" class="kb kc hi lv b fi lz ma l mb mc">from bs4 import BeautifulSoup as bs<br/>from requests import get<br/>url = '<a class="ae jd" href="https://www.imdb.com/title/tt6077448/reviews?ref_=tt_urv" rel="noopener ugc nofollow" target="_blank">https://www.imdb.com/title/tt6077448/reviews?ref_=tt_urv</a>'<br/>response = get(url)<br/>bs4object = bs(response.text, features='html.parser')</span></pre><p id="9aad" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上面的代码单元打开我们指定的URL，并使用BeautifulSoup HTML解析器将我们的数据存储为BS4对象。我们将提取评论、评论标题、用户名以及评论发布的日期。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es md"><img src="../Images/f6d7973cc053cbb0e75e19ceb91acce9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oR9Jfna4Fpx92NnygtPLbA.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">一旦我们检查了我们的页面，DevTools选项卡就会打开</figcaption></figure><p id="ad89" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从上面的截图中我们可以看到，我们所有的评论都存储在一个<em class="lp"> div </em>中，它的<em class="lp">类</em>组件被称为<em class="lp">内容。</em>经过进一步检查，我们发现我们需要的数据存放在如下不同的容器中:</p><pre class="jf jg jh ji fd lu lv lw lx aw ly bi"><span id="044f" class="kb kc hi lv b fi lz ma l mb mc"># container which has all usernames<br/>user = bs4object.find_all('span', attrs={'class':'display-name-link'})</span><span id="3f3f" class="kb kc hi lv b fi me ma l mb mc"># container which has all review dates<br/>review_dates = bs4object.find_all('span', attrs={'class':'review-date'})</span><span id="3413" class="kb kc hi lv b fi me ma l mb mc"># container which has all review titles<br/>review_titles = bs4object.find_all('a', attrs={'class':'title'})</span><span id="9d29" class="kb kc hi lv b fi me ma l mb mc"># container which has all reviews<br/>review_tags = bs4object.find_all('div', attrs={'class':'text show-more__control'})</span><span id="232e" class="kb kc hi lv b fi me ma l mb mc"># name of TV show<br/>name = bs4object.find('meta', property='og:title')</span></pre><p id="9a58" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上面的代码提取了我们前面提到的所有信息，并将它们存储在容器中。目前，我们只能设法提取神圣游戏的评论。要获得其他节目的评论，我们需要做的就是替换网址。因此，我们可以定义一个函数如下:</p><pre class="jf jg jh ji fd lu lv lw lx aw ly bi"><span id="31d0" class="kb kc hi lv b fi lz ma l mb mc">def get_review(url):<br/>    response = get(url)<br/>    bs4object = bs(response.text, features='html.parser')</span><span id="6d3c" class="kb kc hi lv b fi me ma l mb mc"># container which has all usernames<br/>    user = bs4object.find_all('span', attrs={'class':'display-name-link'})</span><span id="e583" class="kb kc hi lv b fi me ma l mb mc"># container which has all review dates<br/>    review_dates = bs4object.find_all('span', attrs={'class':'review-date'})<br/>    <br/>    # container which has all review titles<br/>    review_titles = bs4object.find_all('a', attrs={'class':'title'})<br/>    <br/>    # container which has all reviews<br/>    review_tags = bs4object.find_all('div', attrs={'class':'text show-more__control'})</span><span id="c227" class="kb kc hi lv b fi me ma l mb mc"># name of TV show<br/>    name = bs4object.find('meta', property='og:title')</span><span id="b032" class="kb kc hi lv b fi me ma l mb mc">for i in range(0,len(user)):<br/>        username.append(user[i].text)<br/>        review_date.append(review_dates[i].text)<br/>        review_title.append(review_titles[i].text)<br/>        review.append(review_tags[i].text)<br/>        show_name.append(name['content'])</span></pre><p id="a696" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因为我们将所有数据放入列表中，所以我们可以将所有数据放入pandas数据框架中:</p><pre class="jf jg jh ji fd lu lv lw lx aw ly bi"><span id="827c" class="kb kc hi lv b fi lz ma l mb mc">df = pd.DataFrame({'show':show_name, 'username':username,<br/>'date':review_date, 'title':review_title, 'review':review})</span></pre><p id="8ef3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在让我们将数据保存到一个CSV文件中，以便我们可以随时访问它。因为我更喜欢使用Google Colab环境，所以代码看起来像这样:</p><pre class="jf jg jh ji fd lu lv lw lx aw ly bi"><span id="cb43" class="kb kc hi lv b fi lz ma l mb mc">from google.colab import files<br/>df.to_csv('indian_shows.csv')<br/>files.download('indian_shows.csv')</span></pre><p id="d4de" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们的CSV文件现在包含我们的所有信息，如下所示:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es mf"><img src="../Images/643e38f2779be11d02e557c9851ad22f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_9pY1uTNcBcB2jwMTDTxMg.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">网络抓取后的CSV文件</figcaption></figure></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><p id="0c16" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">恭喜你终于创建了你的第一个网页抓取工具！感谢阅读，敬请期待更多内容！</p><p id="cb20" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="lp">注意:本文中提到的代码仅从我们的IMDb页面中提取有限的评论。现在你知道从哪里开始，试着从这个页面提取所有的评论。(提示:查看硒！)</em></p><p id="bf1e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="lp">资源:</em></p><ol class=""><li id="2963" class="lb lc hi ih b ii ij im in iq ld iu le iy lf jc lq lh li lj bi translated">【https://www.scrapehero.com/python-web-scraping-frameworks/】T5<a class="ae jd" href="https://www.scrapehero.com/python-web-scraping-frameworks/" rel="noopener ugc nofollow" target="_blank">T6</a></li><li id="4655" class="lb lc hi ih b ii lk im ll iq lm iu ln iy lo jc lq lh li lj bi translated"><a class="ae jd" href="https://www.dataquest.io/blog/web-scraping-beautifulsoup/" rel="noopener ugc nofollow" target="_blank"><em class="lp">https://www.dataquest.io/blog/web-scraping-beautifulsoup/</em></a></li><li id="6c76" class="lb lc hi ih b ii lk im ll iq lm iu ln iy lo jc lq lh li lj bi translated"><a class="ae jd" href="https://www.imdb.com/title/tt6077448/reviews?ref_=tt_urv" rel="noopener ugc nofollow" target="_blank"><em class="lp">https://www.imdb.com/title/tt6077448/reviews?ref_=tt_urv</em></a></li></ol></div></div>    
</body>
</html>