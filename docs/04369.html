<html>
<head>
<title>Understanding Machine Learning Algorithms — Support Vector Machine(SVM)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">理解机器学习算法—支持向量机(SVM)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/understanding-machine-learning-algorithms-support-vector-machine-svm-7790a8bce637?source=collection_archive---------12-----------------------#2020-03-16">https://medium.com/analytics-vidhya/understanding-machine-learning-algorithms-support-vector-machine-svm-7790a8bce637?source=collection_archive---------12-----------------------#2020-03-16</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="ad2a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">SVM(支持向量机)可以用于回归和分类。在这个博客中，我们从第一原理推导出SVM。</p><h1 id="4014" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">你会学到什么？</h1><ol class=""><li id="19b6" class="kb kc hi ih b ii kd im ke iq kf iu kg iy kh jc ki kj kk kl bi translated"><strong class="ih hj">几何直觉</strong></li><li id="a459" class="kb kc hi ih b ii km im kn iq ko iu kp iy kq jc ki kj kk kl bi translated"><strong class="ih hj">SVM如何工作和数学</strong></li><li id="3ecd" class="kb kc hi ih b ii km im kn iq ko iu kp iy kq jc ki kj kk kl bi translated"><strong class="ih hj">内核绝招</strong></li><li id="557a" class="kb kc hi ih b ii km im kn iq ko iu kp iy kq jc ki kj kk kl bi translated"><strong class="ih hj">当我们有异常值时它是如何工作的</strong></li><li id="bd4c" class="kb kc hi ih b ii km im kn iq ko iu kp iy kq jc ki kj kk kl bi translated"><strong class="ih hj">SVM的使用案例</strong></li></ol><h2 id="b8d3" class="kr je hi bd jf ks kt ku jj kv kw kx jn iq ky kz jr iu la lb jv iy lc ld jz le bi translated"><strong class="ak"> 1。几何直觉</strong></h2><figure class="lg lh li lj fd lk er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es lf"><img src="../Images/28bd4eaea1d521a98430d9c2fac45cb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gps03VYMHEyNa8ABAukZnA.jpeg"/></div></div></figure><p id="978f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">案例1: </strong>在案例1中，有两个平面将这些点分开，我们对这些平面没有问题，因为这些平面无论如何都在对点进行分类。</p><p id="37ea" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">情况-2: </strong>在情况-2中，也有一个平面直观地分隔这些点，与情况-1分类器相比，它是一个更好的分类器，因为它以这样的方式分类，当任何新的数据点或看不见的数据点出现时，它很容易将其分类。</p><blockquote class="lr ls lt"><p id="28f5" class="if ig lu ih b ii ij ik il im in io ip lv ir is it lw iv iw ix lx iz ja jb jc hb bi translated"><strong class="ih hj">SVM的想法:- </strong></p><p id="340f" class="if ig lu ih b ii ij ik il im in io ip lv ir is it lw iv iw ix lx iz ja jb jc hb bi translated"><strong class="ih hj">该平面试图尽可能广泛地对正负点进行分类，它被称为边缘最大化超平面。在上面的例-2中，正负分尽可能广泛地分类。</strong></p></blockquote><figure class="lg lh li lj fd lk er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es lf"><img src="../Images/2f4031f77c21a46f95305751b41351fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-gE8bPAF5D28QqrgBvQe_Q.jpeg"/></div></div></figure><figure class="lg lh li lj fd lk er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es ly"><img src="../Images/894ad340a137d3698575fa9d3cd1e3e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zfGsaqbdStAlywvIL55swg.png"/></div></div></figure><h2 id="1d0b" class="kr je hi bd jf ks kt ku jj kv kw kx jn iq ky kz jr iu la lb jv iy lc ld jz le bi translated"><strong class="ak"> 2。SVM如何工作和数学</strong></h2><figure class="lg lh li lj fd lk er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es lz"><img src="../Images/3e364ea52a0400d1f356dd581e90e6c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uD89hrNHp3ac3K2Kh3PE_g.png"/></div></div></figure><figure class="lg lh li lj fd lk er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es ma"><img src="../Images/0ae4128cd888bb79bdd169f2e1348706.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tjTkJV-oGnRweCOx4I130w.png"/></div></div></figure><blockquote class="lr ls lt"><p id="fc86" class="if ig lu ih b ii ij ik il im in io ip lv ir is it lw iv iw ix lx iz ja jb jc hb bi translated"><strong class="ih hj">任务:-任务是找到W和b，使得最大化边距距离，我们可以用数学方法写出来</strong></p></blockquote><figure class="lg lh li lj fd lk er es paragraph-image"><div class="er es mb"><img src="../Images/d2a6b20086963cbefec34c5f96ce1a4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1256/format:webp/1*u2qfPofuYyy0EI0rtdrPeQ.png"/></div></figure><figure class="lg lh li lj fd lk er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es mc"><img src="../Images/ccae4f9028f97218af751d7c520d82f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lu6W8y4QTpkFjnoAU2nIsQ.png"/></div></div></figure><p id="9079" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于通过正点的点的支持向量，该点是正的，并且支持向量是正的，所以它是wT+b=1。对于负点，该点是负的，并且支持向量是负的，所以wT+b=1。</p><blockquote class="lr ls lt"><p id="d05f" class="if ig lu ih b ii ij ik il im in io ip lv ir is it lw iv iw ix lx iz ja jb jc hb bi translated"><strong class="ih hj">因此，我们可以得出，对于距离支持向量正侧或负侧的每个远点，它将大于一个wT+b &gt; 1，对于正确分类的点，它应该满足这个条件，如果它小于wT+b &lt; 1，这意味着该点被错误分类，我们可以写为数学上…..</strong></p></blockquote><figure class="lg lh li lj fd lk er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es md"><img src="../Images/3fa09ca5a78b22f00650c28584268b07.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WJINKlJpny4Nw5-DyIUbLA.png"/></div></div></figure><blockquote class="lr ls lt"><p id="4a4b" class="if ig lu ih b ii ij ik il im in io ip lv ir is it lw iv iw ix lx iz ja jb jc hb bi translated"><strong class="ih hj">这里有一个问题，我们在正区域有一些负的点，或者在负区域有一些正的点，它不满足约束，它不会找到w和b</strong></p></blockquote><h1 id="43c3" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">我们如何修改它的原始SVM？</h1><p id="41c6" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq me is it iu mf iw ix iy mg ja jb jc hb bi translated">我们正在为错误分类的点创建一个变量<strong class="ih hj"> Zi </strong>，如果任何点在负区域或正区域中被错误分类，那么<strong class="ih hj"> Zi </strong>将为正，否则对于正确分类的点将为0。</p><figure class="lg lh li lj fd lk er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es mh"><img src="../Images/534f1814e2e422fc425d67bd6b3a4148.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_CpTv1uMIm8aCg0fGowSmg.png"/></div></div></figure><p id="666d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里，C是超参数，随着C的增加，我们越来越重视不犯错误，所以它会过度拟合训练数据，而随着C的减少，我们越来越不重视犯错误，所以我们的模型对训练数据的拟合不足。这种形式的SVM被称为原始SVM</p><h1 id="8c22" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">SVM的双重形式</h1><p id="a9d6" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq me is it iu mf iw ix iy mg ja jb jc hb bi translated">在使用数学的最优化理论中，我们可以证明SVM的这个原始形式等于SVM的对偶形式，而不是求解SVM的原始形式，我们求解SVM的对偶形式是因为。在SVM <strong class="ih hj">的对偶形式中，Xi的</strong>以<strong class="ih hj">的形式出现，</strong>转置<strong class="ih hj">的Xj。</strong></p><figure class="lg lh li lj fd lk er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es mi"><img src="../Images/ee4fb21d4681b07b1ffa622bfe752c0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Zku426sqngU48kMXUPLcUQ.png"/></div></div></figure><h2 id="d754" class="kr je hi bd jf ks kt ku jj kv kw kx jn iq ky kz jr iu la lb jv iy lc ld jz le bi translated">3.内核技巧</h2><blockquote class="lr ls lt"><p id="819b" class="if ig lu ih b ii ij ik il im in io ip lv ir is it lw iv iw ix lx iz ja jb jc hb bi translated"><strong class="ih hj">在SVM的对偶公式中我们可以使用任何相似函数sim(Xi，Xj)而不是使用Xi转置Xj。这里，一类相似性函数是核函数，因此这通常由K(Xi，Xj) </strong>代替</p></blockquote><p id="fa8f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">SVM最重要的思想是核技巧，它非常重要，因为在超平面的软SVM中，除了我们的边际最大化思想之外，它非常类似于逻辑回归，所以如果我们不应用核技巧，我们就称它为线性SVM。</p><p id="e73e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，使SVM如此强大的线性SVM的内核技巧在某些情况下会失败，如果我们的数据不是线性分离的，但如果我们应用内核SVM，它工作得相当好。</p><h1 id="2a58" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">内核Trick是做什么的？</h1><p id="7dbb" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq me is it iu mf iw ix iy mg ja jb jc hb bi translated">使用核技巧的核SVM可以解决非线性可分数据。Kernel-SVM从字面上看，它将数据转换到不同的空间，并在该空间中找到超平面。有许多可用的核，如多项式，RBF等…</p><h2 id="6601" class="kr je hi bd jf ks kt ku jj kv kw kx jn iq ky kz jr iu la lb jv iy lc ld jz le bi translated">4.<strong class="ak">当我们有异常值时它是如何工作的</strong></h2><p id="4787" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq me is it iu mf iw ix iy mg ja jb jc hb bi translated">离群值对我们的模型影响很小，因为支持向量对我们的模型很重要，如果我们的数据中有离群值，影响是非常小的。</p><h2 id="9b15" class="kr je hi bd jf ks kt ku jj kv kw kx jn iq ky kz jr iu la lb jv iy lc ld jz le bi translated">5.<strong class="ak">SVM的使用案例</strong></h2><p id="97c2" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq me is it iu mf iw ix iy mg ja jb jc hb bi translated">在SVM的例子中，特性转换被内核所取代，我们必须设计一个运行良好的内核。对于给定的问题，找到正确的核有时并不容易，但我们有默认的核RBF，但如果我们为给定的问题找到合适的核，SVM工作得非常好。</p><p id="16c4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在线性SVM的情况下，我们的决策可以是超平面，而核SVM可以具有非线性决策表面。使用核技巧，我们也可以解决非线性可分离数据。如果给我们相似性或距离函数，它工作得很好。</p></div></div>    
</body>
</html>