<html>
<head>
<title>Learning parameters of 3D simulations</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">3D模拟的学习参数</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/learning-parameters-of-3d-simulations-2d4591b47826?source=collection_archive---------15-----------------------#2019-10-03">https://medium.com/analytics-vidhya/learning-parameters-of-3d-simulations-2d4591b47826?source=collection_archive---------15-----------------------#2019-10-03</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="4aff" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我简要看了一下http://ailivesim.com/提供的一些数据。<strong class="ih hj"> AIliveSim </strong>建立了一个模拟工具，在非常真实的3D环境中训练和测试代理。</p><p id="64bc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">他们的一些海上模拟给我留下了深刻的印象。来自模拟3D环境的快照看起来非常真实。这包括逼真的海浪，以及反射和相机镜头上最终的水花。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/e4117a97b924934c84cc8ad5ccecb5fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E8X6g9CD6gTT2L9xLavkYQ.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">白天拍摄的模拟快照。</figcaption></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/a67e76dd8779fc345440ddfaea723f40.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U2kefx54y_o8r_wLGgvEfA.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">黄昏时拍摄的模拟快照。</figcaption></figure><h1 id="814d" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">从图片中预测参数</h1><p id="2c64" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">定义特定模拟的参数有很多。你可以在下面看到其中的一些:</p><blockquote class="kx ky kz"><p id="6e0a" class="if ig la ih b ii ij ik il im in io ip lb ir is it lc iv iw ix ld iz ja jb jc hb bi translated">【SeasonDefaultSettings】<br/>树叶密度=1.707774 <br/>季节=夏季<br/>enable Rain = false<br/>Randomize = true<br/>Rain = NoRain<br/>enable leaves = false<br/>ground wetness type = Dry<br/>…</p></blockquote><p id="8090" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这些参数中，存在数字参数，例如:一天中的时间、雾量、降雨量、太阳亮度等。我决定分析是否有可能从一张图片中预测出任何参数。这对于从<em class="la">任何真实图片</em>中估计新模拟的参数可能是有用的。我从<strong class="ih hj">开始，从一张图片</strong>中预测时间。</p><p id="0260" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我得到了一组在不同时间拍摄的模拟图像的数据集:<strong class="ih hj">从早上5点到下午6点</strong>。每一次，都有大致相同数量的图片。换言之，目标标签是均匀分布的。这可能使训练分类器更容易。</p><h1 id="c5db" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">图像的迁移学习</h1><p id="5de1" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">我发现了这个使用<strong class="ih hj"> Keras </strong>和<strong class="ih hj">tensor flow 2.0</strong>:<a class="ae jd" href="https://www.tensorflow.org/tutorials/images/transfer_learning" rel="noopener ugc nofollow" target="_blank">https://www . tensor flow . org/tutorials/images/transfer _ learning</a>的<strong class="ih hj">迁移学习</strong>的便捷教程。在本教程中，迁移学习用于在<strong class="ih hj"> ImageNet </strong>上定制预训练的模型<strong class="ih hj">。他们的目标任务是区分“猫图片”和“狗图片”。同样，我使用预先训练的模型来区分白天拍摄的照片和黎明或黄昏拍摄的照片。我白天的代理是“上午11点至下午3点之间拍摄的照片”。更具体地说，我的二元分类问题有两类:</strong></p><ul class=""><li id="8d09" class="le lf hi ih b ii ij im in iq lg iu lh iy li jc lj lk ll lm bi translated">第一类:上午11点至下午3点之间拍摄的照片；</li><li id="3188" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">第0类:上午5点至11点之间拍摄的照片，以及下午3点至6点之间拍摄的照片。</li></ul><p id="ba15" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对上述笔记本的主要修改在于<strong class="ih hj">从Google Drive加载我自己的图片。</strong>为此，我编写了一个脚本，让<strong class="ih hj">将</strong>图像的大小调整为160x160像素，并让<strong class="ih hj">将它们的标签</strong>添加到文件名中。例如，<code class="du ls lt lu lv b">d4321a23_raw_13.0.png</code>是下午1点拍摄的调整过大小的图像的输出。我把脚本放在这里:<a class="ae jd" href="https://github.com/simoroma/PythonMLUtils" rel="noopener ugc nofollow" target="_blank">https://github.com/simoroma/PythonMLUtils</a>。图像一旦调整到160x160，就不会占用太多空间，可以方便地传输到Google Drive。我还修改了上面的笔记本，直接从Google drive加载图片。这里有:<a class="ae jd" href="https://github.com/simoroma/TransferLearningOnImages" rel="noopener ugc nofollow" target="_blank">https://github.com/simoroma/TransferLearningOnImages</a>。如果你提供自己的图片，你可以在<strong class="ih hj"> Google Colab </strong>上尝试一下(只需点击在Colab中打开)。Google Colab也为这类实验提供了基本的GPU。</p><p id="a43d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我用了1000张图片进行训练，500张图片进行验证。训练集中的图像是从与验证集不同的模拟中获得的。在不同的模拟集上验证结果应该是对分类器概括能力的更好的估计。</p><h1 id="e559" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">初步结果</h1><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es lw"><img src="../Images/e9b0a70d63a54d077d6c689cae9a74f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1304/format:webp/1*rpt1zVrUqhoGRI6io0-61w.png"/></div></figure><p id="9f35" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae jd" href="https://www.tensorflow.org/beta/tutorials/images/transfer_learning" rel="noopener ugc nofollow" target="_blank"> T </a>顶部的图显示了每个时期的<strong class="ih hj">训练和验证精度</strong>。</p><p id="9fff" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用用于<strong class="ih hj">特征提取的预训练网络获得第一个时期的结果，</strong>图的第二部分显示了<strong class="ih hj">微调的结果。</strong></p><p id="039e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">特征提取:</strong>预训练的网络不是为了这个任务而重新训练的，而是仅仅用于提取特征。在提取的特征上训练的分类器被添加到网络的顶部，以根据我们的特定任务定制它。</p><p id="47d0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">微调:</strong>使用新图像对整个网络或网络的某些部分进行微调。</p><p id="9ba5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们看到，当我们开始微调时，训练集上的预测<strong class="ih hj">准确性增加了</strong>相当多。另一方面，<strong class="ih hj">验证精度缓慢增加</strong>。对于网络来说，预测一天中的时间似乎是一项具有挑战性的任务，尽管如此，该模型肯定会选择一些模式来预测它。</p><h1 id="cfa0" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">洞察力</h1><p id="2ed6" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">这只是一个分析的起点。在继续深入分析之前，我只想分享一些初步见解:</p><ul class=""><li id="13fd" class="le lf hi ih b ii ij im in iq lg iu lh iy li jc lj lk ll lm bi translated">将1级定义为“上午11点至下午3点之间拍摄的照片”似乎有所帮助。其他设置包括选择不同的时间范围。尽管如此，该模型似乎表现更差；</li><li id="7db1" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">我还测试了另一组雾和海的颜色设置为常量的图片。这似乎实际上并没有改善模型；</li><li id="8ccd" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">当然，最好将这项任务视为一个回归问题。该网络可以将一天中的时间作为数值来学习。为此目的更换笔记本并不太困难；</li><li id="e452" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">如前所述，验证集中的模拟不同于训练集中的模拟。使用相同的模拟并没有真正的帮助；</li><li id="4f2d" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">在同一台笔记本电脑上的不同运行之间，准确性结果有很大的差异。我没想到会有这么大的变化，这肯定是需要调查的事情；</li><li id="a493" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">我们可以使用<code class="du ls lt lu lv b">model.evaluate</code>来检查我们的模型在不同场景下的性能。尽管结果似乎与<code class="du ls lt lu lv b">model.fit</code>的输出不匹配。我没有深究它，但它似乎仍然是一个开放的问题在Keras:【https://github.com/keras-team/keras/issues/6977<a class="ae jd" href="https://github.com/keras-team/keras/issues/6977" rel="noopener ugc nofollow" target="_blank">。</a></li></ul><h1 id="25b4" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">摘要</h1><p id="00b3" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">我展示了一个关于从单幅图片中提取参数的初步分析。图片是由<strong class="ih hj"> AIliveSim </strong>通过3D模拟获得的。如果使用<strong class="ih hj">转移学习</strong>，似乎完全可以从图片中学习参数。</p><p id="61e6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">以下脚本也是将这些技术应用到您自己的图像的良好起点:</p><ul class=""><li id="d606" class="le lf hi ih b ii ij im in iq lg iu lh iy li jc lj lk ll lm bi translated">Python脚本给<strong class="ih hj">调整图像尺寸</strong>和<strong class="ih hj">添加它们的标签</strong>它们的文件名<a class="ae jd" href="https://github.com/simoroma/PythonMLUtils" rel="noopener ugc nofollow" target="_blank">https://github.com/simoroma/PythonMLUtils</a>；</li><li id="670d" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">我在Colab使用的从<strong class="ih hj"> Google Drive加载图片的笔记本:</strong><a class="ae jd" href="https://github.com/simoroma/TransferLearningOnImages" rel="noopener ugc nofollow" target="_blank">https://github.com/simoroma/TransferLearningOnImages</a>；</li><li id="a800" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">原Google关于图像的迁移学习教程:<a class="ae jd" href="https://www.tensorflow.org/tutorials/images/transfer_learning" rel="noopener ugc nofollow" target="_blank">https://www . tensor flow . org/tutorials/images/transfer _ learning</a>。</li></ul></div></div>    
</body>
</html>