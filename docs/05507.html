<html>
<head>
<title>Data Cleaning: Journey of raw data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">数据清理:原始数据之旅</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/data-cleaning-journey-of-raw-data-d25ae6e4a9aa?source=collection_archive---------15-----------------------#2020-04-23">https://medium.com/analytics-vidhya/data-cleaning-journey-of-raw-data-d25ae6e4a9aa?source=collection_archive---------15-----------------------#2020-04-23</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/b64cf698bc6a607c6818366c6e13f97e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NatM7eDiT5RQ3K01vFdjBg.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">来源:媒体</figcaption></figure><p id="2d9a" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">每个人都知道数据科学家和数据分析师。但是有一个角色，我们很多人都把它和这两个角色混在一起。而这个角色叫做<strong class="iw hj">数据工程师</strong>。数据分析师处理数据并创建报告，指出可以为企业带来利润的方法。数据科学家处理海量数据，并利用他们在数学、统计、编程和机器学习方面的专业知识来获得对未来的洞察力。但是这两个角色都需要大量的数据来工作。</p><figure class="jt ju jv jw fd ij er es paragraph-image"><div class="er es js"><img src="../Images/b5d1967f29a07474029b840e0becd722.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*Dmk8Vi4G2r0KNfWYcVyb9Q.png"/></div></figure><p id="5b41" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">为了填补这一空白，数据工程师利用他们的专业知识。在现实世界中，数据是从多个来源收集的。该数据不能直接用于训练模型。首先，需要做一些处理来使数据集结构化和统一。数据工程师通过收集数据开发一个大的数据池，并确保数据管道的顺畅工作。他们从事各种工作，如处理脏数据，形成数据管道和数据优化。因此，让我们来看看数据是如何清理的。</p><p id="7da5" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">考虑这个数据集。(这个数据集没有任何意义。创建它只是为了显示数据预处理阶段的各个方面，包括替换缺失值、编码成数值、特征缩放以及拆分成训练集和测试集。)</p><figure class="jt ju jv jw fd ij er es paragraph-image"><div class="er es jx"><img src="../Images/2600614d89a07745bb21b64e7e0f3177.png" data-original-src="https://miro.medium.com/v2/resize:fit:384/format:webp/1*fuYO2NZGRYczd9pFuqQgSg.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">资料组</figcaption></figure><p id="3ce5" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">步骤1:-导入python库</strong></p><figure class="jt ju jv jw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es jy"><img src="../Images/7a8f736c50932ef19f3eb29837b7199f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VG9KI5qR_m34iAewoJhrDQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">导入库</figcaption></figure><pre class="jt ju jv jw fd jz ka kb kc aw kd bi"><span id="23af" class="ke kf hi ka b fi kg kh l ki kj">import pandas as pd<br/>import numpy as np</span></pre><p id="75a5" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj"> Pandas </strong>是数据科学中使用最广泛的python库之一。它提供了易于使用的结构和数据分析工具。它强大的对象pandas data frame对数据分析非常有帮助。</p><p id="f943" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">另一方面，<strong class="iw hj"> NumPy </strong>是一个Python库，它提供了对大型多维数组的支持，并允许对它们执行数学运算。</p><p id="1722" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">除了这两个库，<strong class="iw hj"> matplotlib </strong>也是一个常用的库，用于以图表、直方图等形式可视化数据。</p><p id="fe54" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">步骤2:-导入数据集</strong></p><figure class="jt ju jv jw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kk"><img src="../Images/501bf8538838ba5bb4055e2b52027f22.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cQzcsjj3YLSnNkNM5uKWbA.png"/></div></div></figure><pre class="jt ju jv jw fd jz ka kb kc aw kd bi"><span id="8a32" class="ke kf hi ka b fi kg kh l ki kj">dataset = pd.read_csv(‘Data.csv’)</span></pre><p id="30f6" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在导入库之后，我们需要获得数据集，进一步的工作将在这些数据集上进行。Pandas库用于导入数据集。使用read_csv()函数，数据集被转换为pandas数据框架。熊猫数据框是一个2 D表格对象。</p><p id="9162" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">该数据集可以分为两部分:- i)特征ii)输出。<strong class="iw hj">特性</strong>是对输出有影响的数据的独立属性(可测量的属性或特性)。<strong class="iw hj">输出</strong>可视为依赖于特征(一个或多个)的因变量。</p><p id="e573" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在这里，国家和薪水是特征。</p><figure class="jt ju jv jw fd ij er es paragraph-image"><div class="er es kl"><img src="../Images/a66b02746253f6a225018ca6b1abfb4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:278/format:webp/1*Z4LoLKcOFcAM4HwHkr5njQ.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">特征</figcaption></figure><p id="8964" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">“是”或“否”是依赖于这些特征的输出。</p><figure class="jt ju jv jw fd ij er es paragraph-image"><div class="er es km"><img src="../Images/8008054c3fefabdb9e1676dfbdc0742d.png" data-original-src="https://miro.medium.com/v2/resize:fit:142/format:webp/1*9SADw8MNRX1fFrPBUl-Rmw.png"/></div></figure><pre class="jt ju jv jw fd jz ka kb kc aw kd bi"><span id="ad95" class="ke kf hi ka b fi kg kh l ki kj">X = dataset.iloc[:,:-1].values<br/>Y = dataset.iloc[:,-1].values</span></pre><p id="5714" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">生成pandas数据帧后，<strong class="iw hj"> iloc </strong>用于根据其整数索引指定行(如代码片段所示[:，:-1]表示从开始到结束的所有行以及除最后一列之外的所有列)和列。它用于分离数据集中的要素和输出。这里X包含了所有的特征(所有的行和第1、2列)。而Y包含因变量(所有行和第3列)。</p><p id="8dad" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">步骤3:-替换缺失值</strong></p><figure class="jt ju jv jw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kn"><img src="../Images/f8f24c5303f0ac5f7c5bb842cc23e868.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gCzq3WxqAzKXO-r2ERoklw.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">替换丢失的值</figcaption></figure><p id="f46f" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在现实世界中，可能会发生某些特征值丢失的情况，这可能会在将来造成问题。所以，我们需要解决这个问题。可以用两种方法处理:- i)删除整行或ii)替换丢失的值。第一个选项可能会导致数据丢失，因此不是首选。所以让我们坚持后一个。</p><pre class="jt ju jv jw fd jz ka kb kc aw kd bi"><span id="8215" class="ke kf hi ka b fi kg kh l ki kj">from sklearn.impute import SimpleImputer</span><span id="6614" class="ke kf hi ka b fi ko kh l ki kj">imputer = SimpleImputer(missing_values = np.nan, strategy = ‘mean’)</span></pre><p id="cb7a" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj"> SciKit (sklearn) </strong>库包含了很多用于机器学习和统计建模的高效工具。sklearn的<strong class="iw hj"> Impute </strong>包提供了一个名为<strong class="iw hj"> SimpleImputer </strong>的类，可以用来用列的均值、中值或最频繁值替换缺失值。这里我们使用了<strong class="iw hj"> mean </strong>策略，该策略表示一列中所有缺失的值都将被该列的平均值替换。<strong class="iw hj"> missing_values </strong>参数等于np.nan代表需要替换的缺失数据。</p><pre class="jt ju jv jw fd jz ka kb kc aw kd bi"><span id="91e6" class="ke kf hi ka b fi kg kh l ki kj">imputer.fit(X[:,1:2])</span><span id="1bad" class="ke kf hi ka b fi ko kh l ki kj">X[:,1:2] = imputer.transform(X[:,1:2])</span></pre><p id="2c4f" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在我们选择了替换缺失值的策略后，<strong class="iw hj"> fit() </strong>方法用于计算所有缺失条目的值，而<strong class="iw hj"> transform() </strong>方法用于在条目缺失的地方应用这些值。这也可以使用<strong class="iw hj"> fit_transform() </strong>方法一步完成。</p><p id="156a" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">步骤4:-编码特征并输出</strong></p><figure class="jt ju jv jw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kp"><img src="../Images/04ce27ec33ae28dd4cb238d0c54c343b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xLsh2Bw8JFRpahMVEe1NAQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">编码功能(OneHotEncoder)</figcaption></figure><p id="89c1" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">这些数据的问题在于，机器无法将国家名称理解为特征。所以需要将它们编码成数值。sklearn的预处理包提供了<strong class="iw hj"> LabelEncoder </strong>和<strong class="iw hj"> OneHotEncoder </strong>。</p><p id="974c" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj"> LabelEncoder </strong>将特征中的类别转换成连续的数值。在我们的比赛中，印度0分，美国1分，澳大利亚2分。但是由于这个原因，机器开始进行比较，认为这是一个订单(印度&lt;美国&lt;澳大利亚)。可能发生的情况是，机器会认为印度和澳大利亚的平均值就是美国。所以这种方法不应该用于这样的特性。</p><pre class="jt ju jv jw fd jz ka kb kc aw kd bi"><span id="9576" class="ke kf hi ka b fi kg kh l ki kj">from sklearn.compose import ColumnTransformer</span><span id="4277" class="ke kf hi ka b fi ko kh l ki kj">from sklearn.preprocessing import OneHotEncoder</span><span id="d438" class="ke kf hi ka b fi ko kh l ki kj">ct = ColumnTransformer(transformers=[(‘encoder’, OneHotEncoder(), [0])], remainder=’passthrough’)</span></pre><p id="00a5" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">OneHotEncoder 所做的是为一个特性中的n个不同类别创建n个不同的列。因此，在我们的例子中，生成了3个不同的列，美国、澳大利亚和印度各一个。现在，在所有将印度作为国家的行的原始数据中，在OneHotEncoding之后为印度创建的列包含值1，而其他2列包含值0。</p><p id="84e6" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj"> ColumnTransformer </strong>使用OneHotEncoder转换指定的列，并将结果与剩余的列连接起来。这里，r <strong class="iw hj"> emainder='passthrough' </strong>表示所有其他特性列保持不变。</p><pre class="jt ju jv jw fd jz ka kb kc aw kd bi"><span id="758a" class="ke kf hi ka b fi kg kh l ki kj">X = np.array(ct.fit_transform(X))</span></pre><p id="ffbb" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">现在，我们使用fit_transform计算并应用特征的数值，并将它们转换成一个NumPy数组。</p><figure class="jt ju jv jw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kq"><img src="../Images/05a445052ccf6cb0a7409380a43204da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Yr9oYEys_s4XW8uBayGYmQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">编码输出(LabelEncoder)</figcaption></figure><p id="ff51" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在我们的例子中，输出只有2个值，即是或否。因此，可以使用标签编码器将它们编码为0和1。</p><p id="159c" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">步骤5:-特征缩放</strong></p><figure class="jt ju jv jw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kp"><img src="../Images/17de7d56bafa444feb886362ab947717.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uG5CUJ7H1NDv1X-lLaqByw.png"/></div></div></figure><p id="0bbe" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">可能发生每个特征的范围非常大的情况。观察到在该特征的最小值和最大值之间存在巨大差异。需要对这些特征进行缩放，以便所有的特征都落在相同的范围内。有两种方法可以做到。</p><figure class="jt ju jv jw fd ij er es paragraph-image"><div class="er es kr"><img src="../Images/25b87451eae64c0351c6fac459261f99.png" data-original-src="https://miro.medium.com/v2/resize:fit:1042/format:webp/1*5IqcQTaeYc3jRo-ZoGxdlw.jpeg"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">正常化</figcaption></figure><figure class="jt ju jv jw fd ij er es paragraph-image"><div class="er es ks"><img src="../Images/715643d53b91b7dc40646edb773818ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:932/format:webp/1*_xSuxV8nDAKCjB_Ft3Ewqw.jpeg"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">标准化(来源:GeeksForGeeks)</figcaption></figure><pre class="jt ju jv jw fd jz ka kb kc aw kd bi"><span id="10cf" class="ke kf hi ka b fi kg kh l ki kj">from sklearn.preprocessing import StandardScaler</span><span id="7464" class="ke kf hi ka b fi ko kh l ki kj">ss = StandardScaler()</span><span id="76a8" class="ke kf hi ka b fi ko kh l ki kj">X = ss.fit_transform(X)</span></pre><p id="ceb2" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">以上两种方法各有利弊。所以，要看什么最适合你的机型。<strong class="iw hj"> sklearn </strong>的<strong class="iw hj">预处理</strong>包提供了执行标准化的<strong class="iw hj"> StandardScaler </strong>类。一个then as always fit_transform()用于计算和应用缩放值。</p><p id="878d" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">步骤6:-将数据分成训练集和测试集。</strong></p><figure class="jt ju jv jw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kt"><img src="../Images/7b8232359e29cfaf983ef5ee705c1e64.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tKeuTC22iaxG59D9kgj2Sw.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">分割数据集</figcaption></figure><p id="7bfe" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">现在是将数据集分成两部分的最后一步。这是非常重要的一步。如果没有正确实现，可能会导致低效的模型。<strong class="iw hj">如果有大量数据需要训练，导致复杂的假设(预测)，可能会出现过拟合</strong>。<strong class="iw hj">如果可用于训练模型的数据非常少，可能会出现欠拟合</strong>。因此，应该在训练和测试数据之间保持一个健康的比率。</p><pre class="jt ju jv jw fd jz ka kb kc aw kd bi"><span id="ec0a" class="ke kf hi ka b fi kg kh l ki kj">from sklearn.model_selection import train_test_split</span><span id="d956" class="ke kf hi ka b fi ko kh l ki kj">X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)</span></pre><p id="7da6" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">train_test_split()函数用于将数据分成两部分。它接受诸如特征、输出和test_size之类的参数(在我们的例子中，test_size=0.2，这意味着数据集将被分成80%的训练数据和20%的测试数据)。</p><p id="dc33" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">这就是为进一步使用准备数据的方式。请记住，有许多其他方法可以做到这一点，这只是清理数据的一种方式。作为这个过程的一个产品，我们得到了一个结构化的训练数据集，可以用来训练不同的模型。这只是一个小场景，但在大规模上，这个过程需要定期进行，因为原始数据是从各种来源频繁收集的。需要维护一个顺畅的数据管道，以便数据科学家和分析师能够处理这些数据。</p><p id="28ff" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">有各种各样的在线资源，包含了许多关于这些主题的信息。在网上寻找时，可以探索许多不同的方法。我不是专家，但我正在尝试学习新的东西。感谢您的阅读。</p><p id="4122" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">这是<a class="ae ku" href="https://colab.research.google.com/drive/1p3v5JfAlT0Pb94k-VeyD7n495YvgtiNs" rel="noopener ugc nofollow" target="_blank"> Google Colab链接</a>。</p></div></div>    
</body>
</html>