<html>
<head>
<title>Go from Beginner to Pro in Logistic Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在逻辑回归中从初学者到专家</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/go-from-beginner-to-pro-in-logistic-regression-8900af57fb35?source=collection_archive---------10-----------------------#2020-03-23">https://medium.com/analytics-vidhya/go-from-beginner-to-pro-in-logistic-regression-8900af57fb35?source=collection_archive---------10-----------------------#2020-03-23</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/86dda421bb317f7f22d425d871f762bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*oAq_B-DrlgSHeQvQ.jpg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">演职员表:<a class="ae iu" href="https://pixabay.com/users/free-photos-242387/" rel="noopener ugc nofollow" target="_blank">https://pixabay.com/users/free-photos-242387/</a></figcaption></figure><p id="7569" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">监督学习是机器学习的一部分，它处理附有输出标签的数据集。</p><p id="06b7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">给定数据集<em class="jt">d = yᵢ}{xᵢ</em>其中xᵢ ∈ Rᵈ，yᵢ∈c₃,….{c₁、Cₙ}和查询点xₚ，我们必须预测该点属于哪个类。</p><p id="826e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">那么，我们开始吧。🚗</p><p id="124a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="jt">逻辑回归的假设</em>:假设数据是线性可分或近似线性可分的。</p><figure class="jv jw jx jy fd ij er es paragraph-image"><div class="er es ju"><img src="../Images/479fdfe82a5d5d79365aca7d18a4859a.png" data-original-src="https://miro.medium.com/v2/resize:fit:590/format:webp/1*HQSwIIFzwPIkIxejRQ3MiA.png"/></div></figure><figure class="jv jw jx jy fd ij er es paragraph-image"><div class="er es jz"><img src="../Images/07bf9594acf024c682b27766617ed853.png" data-original-src="https://miro.medium.com/v2/resize:fit:356/format:webp/1*YKsNj9KF7Qmv0E-uwJUDIQ.png"/></div></figure><p id="2946" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">逻辑回归的目的是找到一个最好的分类超平面。</p><p id="86d5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为了找到平面，我们需要找到w和b，其中w垂直于平面，b是截距项。</p><p id="bb21" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们知道，一架飞机到xᵢ一点的距离是:</p><figure class="jv jw jx jy fd ij er es paragraph-image"><div class="er es ka"><img src="../Images/395d6f9c7eac937baa3900118d119c1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:326/format:webp/1*0_j202uyPRF_lV8Bvzzfvw.png"/></div></figure><p id="5ed6" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为简单起见，我们假设</p><figure class="jv jw jx jy fd ij er es paragraph-image"><div class="er es kb"><img src="../Images/000004bf368acde62cbab725687a5525.png" data-original-src="https://miro.medium.com/v2/resize:fit:534/format:webp/1*9GwaPeXGmDU1qnsnXFZipw.png"/></div></figure><p id="79e4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">一个平面穿过原点。因此，</p><figure class="jv jw jx jy fd ij er es paragraph-image"><div class="er es kc"><img src="../Images/f0d381f631d214782954943b54f110a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:254/format:webp/1*ae3yjN1DhsLXLcSy_xaKIw.png"/></div></figure><p id="2beb" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">另一个假设:-</p><figure class="jv jw jx jy fd ij er es paragraph-image"><div class="er es kd"><img src="../Images/853ab46a02b9227f74f5cafb205c2926.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*1Q0mINdfYRt7LcdncEGbkw.png"/></div></figure><p id="5bb3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">即正的点标记为+1，负的点标记为-1。</p></div><div class="ab cl ke kf gp kg" role="separator"><span class="kh bw bk ki kj kk"/><span class="kh bw bk ki kj kk"/><span class="kh bw bk ki kj"/></div><div class="hb hc hd he hf"><h2 id="c7f6" class="kl km hi bd kn ko kp kq kr ks kt ku kv jg kw kx ky jk kz la lb jo lc ld le lf bi translated">我们的分类器将如何分类一个点？</h2><ul class=""><li id="7e89" class="lg lh hi ix b iy li jc lj jg lk jk ll jo lm js ln lo lp lq bi translated">如果一个点属于w向量方向上的区域，那么这个点将被标记为正</li></ul><figure class="jv jw jx jy fd ij er es paragraph-image"><div class="er es lr"><img src="../Images/ad677d34d4009c8886f3af1103d0671f.png" data-original-src="https://miro.medium.com/v2/resize:fit:572/format:webp/1*k5TcdITl1Z57g_5PV5EfpA.png"/></div></figure><ul class=""><li id="e7d4" class="lg lh hi ix b iy iz jc jd jg ls jk lt jo lu js ln lo lp lq bi translated">如果一个点属于w向量相反方向的区域，那么这个点将被标记为负。</li></ul><figure class="jv jw jx jy fd ij er es paragraph-image"><div class="er es lr"><img src="../Images/ada77bda3c1d2ae50cbe1562eae1e7d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:572/format:webp/1*YsoCsTqXmFMv4ouNtNc8Wg.png"/></div></figure><p id="4954" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们考虑分类器的所有情况</p><p id="bf85" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">情况1 : yᵢ = 1(点是正的)，wᵀ xᵢ &gt; 0(模型预测是正的)</p><p id="f3b7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在这种情况下，yᵢ wᵀ xᵢ &gt; 0</p><p id="5828" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">案例二:yᵢ = -1(点数为负)，wᵀ xᵢ &lt; 0 (model predicts negative)</p><p id="cef5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">In this case, yᵢ wᵀ xᵢ &gt; 0</p><p id="b20b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">情况3 : yᵢ = 1(点是正的)和wᵀ xᵢ &lt; 0 (model predicts negative)</p><p id="c8a4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">In this case, yᵢ wᵀ xᵢ &lt; 0</p><p id="7080" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">Case 4 : yᵢ = -1 (point is negative) and wᵀ xᵢ &gt; 0(模型预测是正的)</p><p id="c539" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在这种情况下，yᵢ wᵀ xᵢ &lt; 0</p><p id="6eb4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">We want more and more points to be classified correctly i.e. we want more points to belong to case 1 and case 2 rather than to case 3 and case 4.</p><h2 id="533e" class="kl km hi bd kn ko kp kq kr ks kt ku kv jg kw kx ky jk kz la lb jo lc ld le lf bi translated">The Objective function of Logistic Regression</h2><p id="9d67" class="pw-post-body-paragraph iv iw hi ix b iy li ja jb jc lj je jf jg lv ji jj jk lw jm jn jo lx jq jr js hb bi translated">Suppose we have n data points, then we want a hyperplane</p><figure class="jv jw jx jy fd ij er es paragraph-image"><div class="er es ly"><img src="../Images/268c8864aa2ddab6602f942d480e114f.png" data-original-src="https://miro.medium.com/v2/resize:fit:618/format:webp/1*OumRMqIYqx7Bws_nwIUjDA.png"/></div></figure><h2 id="dff6" class="kl km hi bd kn ko kp kq kr ks kt ku kv jg kw kx ky jk kz la lb jo lc ld le lf bi translated">Problem with the mathematical objective function of Logistic Regression</h2><p id="a1c3" class="pw-post-body-paragraph iv iw hi ix b iy li ja jb jc lj je jf jg lv ji jj jk lw jm jn jo lx jq jr js hb bi translated">It is sensitive to outliers. How?</p><p id="fa54" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">Let’s imagine a scenario like this-</p><figure class="jv jw jx jy fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lz"><img src="../Images/561d1864adc7f7e2716e8435fe013820.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_72dQPguDF2uNA-eCyufww.png"/></div></div></figure><p id="386e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">Here, point P is an outlier w.r.t plane π₁ which is at the distance of 100 units in the opposite direction.</p><p id="f1ad" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">Before moving forward, just by looking at the scenario, π₁ appears to be a better hyperplane than π₂, as π₁ has less misclassified points.</p><p id="d2da" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">Now let’s see what out mathematical objective function has to say about this.</p><p id="30d8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">for π₁ :</p><figure class="jv jw jx jy fd ij er es paragraph-image"><div class="er es ma"><img src="../Images/e5b978c9ba4718944dc9428df2bd6c65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1118/format:webp/1*1pFgqnNTQWy2grZRX8UhiQ.png"/></div></figure><p id="1b67" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">for π₂ :</p><figure class="jv jw jx jy fd ij er es paragraph-image"><div class="er es mb"><img src="../Images/87bfb8d4c176a9f464e9f1327626f0e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RY9D83LfPnyOIt53cvUgzg.png"/></div></figure><p id="bb72" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">Even though π₁ appears to be a better option, just because of an outlier P, our objective function says π₂ to be the better one.</p><p id="14bc" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">Moreover,</p><figure class="jv jw jx jy fd ij er es paragraph-image"><div class="er es mc"><img src="../Images/e2f88c3b7d37aecacfb0ac7388319c82.png" data-original-src="https://miro.medium.com/v2/resize:fit:436/format:webp/1*1sgiQqvrYB8qBO3vAmFGKQ.png"/></div></figure><p id="7317" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="jt">那么，如何处理离群值呢？</em></p><p id="92a5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">只有当异常值非常远时，这才是一个主要问题。</p><p id="397b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">💡想法是，如果一个点到平面的距离很小，就按原样使用它，否则，如果距离很大，就最小化它。</p><p id="b87f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这种使大距离最小化的过程被称为挤压。为我们完成这项工作的函数之一是最受欢迎的函数<em class="jt"> Sigmoid函数</em>。</p><h2 id="f3c2" class="kl km hi bd kn ko kp kq kr ks kt ku kv jg kw kx ky jk kz la lb jo lc ld le lf bi translated">Sigmoid函数</h2><p id="f921" class="pw-post-body-paragraph iv iw hi ix b iy li ja jb jc lj je jf jg lv ji jj jk lw jm jn jo lx jq jr js hb bi translated">对于较小的值，它呈线性增长，但当输入过大时，它会达到饱和。</p><figure class="jv jw jx jy fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es md"><img src="../Images/9b0617ed466699a15e1d3fc6fef42510.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*M0ELncpZEXaxBeLu.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">学分:Towardsdatascience.com</figcaption></figure><ul class=""><li id="db16" class="lg lh hi ix b iy iz jc jd jg ls jk lt jo lu js ln lo lp lq bi translated">sig(0) =σ(0) = 0.5</li><li id="f587" class="lg lh hi ix b iy me jc mf jg mg jk mh jo mi js ln lo lp lq bi translated">到平面的距离可以是(-∞，+∞)，但通过σ函数后，我们将在(0，1)中得到一个值。</li></ul><p id="87e9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="jt">阈值:</em></p><p id="20e4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">通常，在二元分类中，0.5被作为阈值来决定查询点的类别标签。</p><p id="ca3c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如果σ(wᵀ x) ≥ 0.5，则预测+1，否则预测0</p><p id="14fa" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="jt">为什么使用sigmoid函数</em>？</p><ul class=""><li id="cce6" class="lg lh hi ix b iy iz jc jd jg ls jk lt jo lu js ln lo lp lq bi translated">容易微分。</li><li id="6764" class="lg lh hi ix b iy me jc mf jg mg jk mh jo mi js ln lo lp lq bi translated">它给出了一个概率解释。</li><li id="c16f" class="lg lh hi ix b iy me jc mf jg mg jk mh jo mi js ln lo lp lq bi translated">小值时线性增长，大值时饱和。</li></ul><p id="bcad" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">所以，我们新的数学目标函数将是-</p><figure class="jv jw jx jy fd ij er es paragraph-image"><div class="er es mj"><img src="../Images/67ce7d21539ee801513a687318405927.png" data-original-src="https://miro.medium.com/v2/resize:fit:666/format:webp/1*6JO8LV1P2NW3RAKWY2rF3w.png"/></div></figure><h2 id="2e32" class="kl km hi bd kn ko kp kq kr ks kt ku kv jg kw kx ky jk kz la lb jo lc ld le lf bi translated">简化目标函数:</h2><figure class="jv jw jx jy fd ij er es paragraph-image"><div class="er es mk"><img src="../Images/35dfa7d4ca2eaa2e8b23fdde5cd2cd80.png" data-original-src="https://miro.medium.com/v2/resize:fit:948/format:webp/1*gJ89fHQ2Ag1BVW7NOAuD_Q.png"/></div></figure><p id="1013" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为什么我们取负对数？</p><ul class=""><li id="9631" class="lg lh hi ix b iy iz jc jd jg ls jk lt jo lu js ln lo lp lq bi translated">使σ(yᵢ wᵀ xᵢ)成为凸函数，这样更容易优化。</li><li id="3516" class="lg lh hi ix b iy me jc mf jg mg jk mh jo mi js ln lo lp lq bi translated">我们可以使用另外两种方法来推导逻辑回归的目标函数:(1)概率方法(其中我们认为特征遵循高斯分布，输出标签遵循伯努利分布)，以及(2)最小化逻辑损失函数(这是对<a class="ae iu" href="https://en.wikipedia.org/wiki/Loss_function#0-1_loss_function" rel="noopener ugc nofollow" target="_blank">0–1损失函数</a>的近似)。这两个都有一个对数项。由于log是单调函数，所以不会影响我们的优化问题。</li></ul></div><div class="ab cl ke kf gp kg" role="separator"><span class="kh bw bk ki kj kk"/><span class="kh bw bk ki kj kk"/><span class="kh bw bk ki kj"/></div><div class="hb hc hd he hf"><h2 id="e15d" class="kl km hi bd kn ko kp kq kr ks kt ku kv jg kw kx ky jk kz la lb jo lc ld le lf bi translated">w的解释</h2><p id="fb82" class="pw-post-body-paragraph iv iw hi ix b iy li ja jb jc lj je jf jg lv ji jj jk lw jm jn jo lx jq jr js hb bi translated">假设我们得到一个最优w值，那么</p><figure class="jv jw jx jy fd ij er es paragraph-image"><div class="er es ml"><img src="../Images/760800284645b5c65f3d455d04947ffe.png" data-original-src="https://miro.medium.com/v2/resize:fit:524/format:webp/1*C4S7zOQM339cq97NwLFfHA.png"/></div></figure><p id="4941" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">即对于每个特征fᵢ，将有一个与之对应的权重。这就是为什么w也被称为权重向量。</p><p id="25c1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">案例1:当wᵢ为+ve时</p><figure class="jv jw jx jy fd ij er es paragraph-image"><div class="er es mm"><img src="../Images/9aa4a13bf48c65f697f3dc69a21701a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:522/format:webp/1*tk1nJj_W_2h_DWBCZyLMKw.png"/></div></figure><p id="93e3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">案例2:当wᵢ被-ve</p><figure class="jv jw jx jy fd ij er es paragraph-image"><div class="er es mn"><img src="../Images/25d075a16bdb78a2de324c1723884644.png" data-original-src="https://miro.medium.com/v2/resize:fit:502/format:webp/1*pvWnLd7EBEl05dzrNPh5fw.png"/></div></figure></div><div class="ab cl ke kf gp kg" role="separator"><span class="kh bw bk ki kj kk"/><span class="kh bw bk ki kj kk"/><span class="kh bw bk ki kj"/></div><div class="hb hc hd he hf"><h2 id="2d8e" class="kl km hi bd kn ko kp kq kr ks kt ku kv jg kw kx ky jk kz la lb jo lc ld le lf bi translated">正规化</h2><p id="c1e1" class="pw-post-body-paragraph iv iw hi ix b iy li ja jb jc lj je jf jg lv ji jj jk lw jm jn jo lx jq jr js hb bi translated">让zᵢ = yᵢ wᵀ xᵢ</p><figure class="jv jw jx jy fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mo"><img src="../Images/b18250bf74691463c0716c36d07f9617.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5MMNzcBdgaEFi4xBkt2oMw.png"/></div></div></figure><p id="e616" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">损失函数的最佳值在以下情况下获得:</p><p id="61f1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">每个<em class="jt"> log (1 + exp(-zᵢ)) </em>都是最小值，这发生在zᵢ趋于+∞时</p><p id="8358" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这意味着，所有的zᵢ必须是正的，或者换句话说，所有的yᵢ wᵀ xᵢ必须是正的(<em class="jt">这是我们之前讨论过的情形1和情形2</em>)。<br/>所有完全分类的训练数据有时会导致<strong class="ix hj">数据过拟合</strong>。</p><p id="4f8a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如何避免这种情况？</p><p id="8581" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们需要控制w的值，使它不会达到很高。</p><p id="9bf8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">惩罚w值有三种方式:</p><ol class=""><li id="4d36" class="lg lh hi ix b iy iz jc jd jg ls jk lt jo lu js mp lo lp lq bi translated"><strong class="ix hj"> L2正规化</strong></li></ol><figure class="jv jw jx jy fd ij er es paragraph-image"><div class="er es mq"><img src="../Images/db0bb6003d300110d8919093244bbd29.png" data-original-src="https://miro.medium.com/v2/resize:fit:1042/format:webp/1*Q7NsMZakbv1CLZvPyIA0AQ.png"/></div></figure><p id="31dc" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在逻辑损失和正则化项之间有一个折衷。</p><figure class="jv jw jx jy fd ij er es paragraph-image"><div class="er es mr"><img src="../Images/02b68c97f52e0ca452df2aee75e9eb25.png" data-original-src="https://miro.medium.com/v2/resize:fit:1076/format:webp/1*pSh3lh0Oc7oqRQYXsdBVOg.png"/></div></figure><p id="23e3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">2.<strong class="ix hj"> L1正规化</strong></p><figure class="jv jw jx jy fd ij er es paragraph-image"><div class="er es ms"><img src="../Images/296298c1979322434aacb22e3524ce36.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*amW9K4y4exx8i3QchGxh6Q.png"/></div></figure><p id="a1da" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="jt">要点</em>:</p><ul class=""><li id="2b72" class="lg lh hi ix b iy iz jc jd jg ls jk lt jo lu js ln lo lp lq bi translated">对于不太重要的特征fᵢ，L1正则化生成wᵢ = 0(即，L1正则化创建稀疏权重向量)，而L2正则化wᵢ较小。</li><li id="0ec6" class="lg lh hi ix b iy me jc mf jg mg jk mh jo mi js ln lo lp lq bi translated">由于生成了稀疏向量，L1正则化导致快速计算。</li></ul><p id="879e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">3.<strong class="ix hj">弹力网</strong></p><p id="dcd6" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">它结合了L1正则化和L2正则化的优点。</p><figure class="jv jw jx jy fd ij er es paragraph-image"><div class="er es mt"><img src="../Images/74fce450df8294f9dba685df65423815.png" data-original-src="https://miro.medium.com/v2/resize:fit:1228/format:webp/1*V4yuFJv344rSzGgo__t-Ig.png"/></div></figure><ul class=""><li id="acbc" class="lg lh hi ix b iy iz jc jd jg ls jk lt jo lu js ln lo lp lq bi translated">它将有两个超参数</li><li id="9146" class="lg lh hi ix b iy me jc mf jg mg jk mh jo mi js ln lo lp lq bi translated">耗时的</li><li id="22ea" class="lg lh hi ix b iy me jc mf jg mg jk mh jo mi js ln lo lp lq bi translated">高性能</li></ul></div><div class="ab cl ke kf gp kg" role="separator"><span class="kh bw bk ki kj kk"/><span class="kh bw bk ki kj kk"/><span class="kh bw bk ki kj"/></div><div class="hb hc hd he hf"><h2 id="dd72" class="kl km hi bd kn ko kp kq kr ks kt ku kv jg kw kx ky jk kz la lb jo lc ld le lf bi translated">列标准化</h2><ul class=""><li id="b45b" class="lg lh hi ix b iy li jc lj jg lk jk ll jo lm js ln lo lp lq bi translated">因为它是基于距离的模型，所以需要标准化。</li><li id="0374" class="lg lh hi ix b iy me jc mf jg mg jk mh jo mi js ln lo lp lq bi translated">标准化也有助于我们优化问题的快速收敛。</li></ul><h2 id="f226" class="kl km hi bd kn ko kp kq kr ks kt ku kv jg kw kx ky jk kz la lb jo lc ld le lf bi translated">特征重要性和模型可解释性</h2><ul class=""><li id="9a92" class="lg lh hi ix b iy li jc lj jg lk jk ll jo lm js ln lo lp lq bi translated">如果数据的要素不共线/多重共线，则对应于较高wᵢ权重的要素fᵢ会更重要。</li><li id="a583" class="lg lh hi ix b iy me jc mf jg mg jk mh jo mi js ln lo lp lq bi translated">然而，如果特征是共线的，可以切换到向前特征选择或向后特征消除，这是获得特征重要性的标准方式，并且不管模型如何都有效。</li><li id="edca" class="lg lh hi ix b iy me jc mf jg mg jk mh jo mi js ln lo lp lq bi translated">一旦知道了特征的重要性，模型就可以根据这些特征给出它已经预测了+1或-1的推理。</li></ul></div><div class="ab cl ke kf gp kg" role="separator"><span class="kh bw bk ki kj kk"/><span class="kh bw bk ki kj kk"/><span class="kh bw bk ki kj"/></div><div class="hb hc hd he hf"><h2 id="96ef" class="kl km hi bd kn ko kp kq kr ks kt ku kv jg kw kx ky jk kz la lb jo lc ld le lf bi translated">时间和空间的复杂性</h2><p id="10eb" class="pw-post-body-paragraph iv iw hi ix b iy li ja jb jc lj je jf jg lv ji jj jk lw jm jn jo lx jq jr js hb bi translated"><em class="jt">列车</em>:</p><ul class=""><li id="c998" class="lg lh hi ix b iy iz jc jd jg ls jk lt jo lu js ln lo lp lq bi translated">逻辑回归的训练无非是利用<a class="ae iu" href="https://towardsdatascience.com/stochastic-gradient-descent-clearly-explained-53d239905d31" rel="noopener" target="_blank"> SGD </a>优化耗时O(n*d)的损失函数。</li><li id="c781" class="lg lh hi ix b iy me jc mf jg mg jk mh jo mi js ln lo lp lq bi translated">我们需要存储所有的点，这需要O(n*d)的空间。</li></ul><p id="cc3e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="jt">测试</em>:</p><ul class=""><li id="ffd1" class="lg lh hi ix b iy iz jc jd jg ls jk lt jo lu js ln lo lp lq bi translated">我们只需要存储d维向量的权重向量，因此需要O(d)空间</li><li id="0962" class="lg lh hi ix b iy me jc mf jg mg jk mh jo mi js ln lo lp lq bi translated">计算σ(wᵀxₚ)需要d次乘法，因此时间为O(d)。</li></ul></div><div class="ab cl ke kf gp kg" role="separator"><span class="kh bw bk ki kj kk"/><span class="kh bw bk ki kj kk"/><span class="kh bw bk ki kj"/></div><div class="hb hc hd he hf"><h2 id="6596" class="kl km hi bd kn ko kp kq kr ks kt ku kv jg kw kx ky jk kz la lb jo lc ld le lf bi translated">维度及其效应</h2><p id="c319" class="pw-post-body-paragraph iv iw hi ix b iy li ja jb jc lj je jf jg lv ji jj jk lw jm jn jo lx jq jr js hb bi translated"><em class="jt">如果d很小:</em></p><ul class=""><li id="33f8" class="lg lh hi ix b iy iz jc jd jg ls jk lt jo lu js ln lo lp lq bi translated">逻辑回归非常有效。</li><li id="84b5" class="lg lh hi ix b iy me jc mf jg mg jk mh jo mi js ln lo lp lq bi translated">它可以集成到低延迟系统中。</li><li id="0643" class="lg lh hi ix b iy me jc mf jg mg jk mh jo mi js ln lo lp lq bi translated">时空复杂度更少。</li></ul><p id="df75" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="jt">如果d很大:</em></p><ul class=""><li id="a008" class="lg lh hi ix b iy iz jc jd jg ls jk lt jo lu js ln lo lp lq bi translated">它受到<a class="ae iu" rel="noopener" href="/@anujshrivastav97/curse-of-dimensionality-the-curse-that-all-ml-engineers-need-to-deal-with-5d459d39dc8a">维度诅咒</a>的影响。</li><li id="7e47" class="lg lh hi ix b iy me jc mf jg mg jk mh jo mi js ln lo lp lq bi translated">可以使用L1正则化来移除不太重要的特征。然而，应仔细选择λ值，以处理偏差、方差和延迟。</li></ul></div><div class="ab cl ke kf gp kg" role="separator"><span class="kh bw bk ki kj kk"/><span class="kh bw bk ki kj kk"/><span class="kh bw bk ki kj"/></div><div class="hb hc hd he hf"><h2 id="b558" class="kl km hi bd kn ko kp kq kr ks kt ku kv jg kw kx ky jk kz la lb jo lc ld le lf bi translated">处理不平衡的数据</h2><p id="e60f" class="pw-post-body-paragraph iv iw hi ix b iy li ja jb jc lj je jf jg lv ji jj jk lw jm jn jo lx jq jr js hb bi translated">让我们看看不平衡数据是如何影响逻辑回归的</p><figure class="jv jw jx jy fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mu"><img src="../Images/e7f4b8c400ed39da09bcc73aab1aed22.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*II_c2Iknf0S9wg58Iu_cXg.png"/></div></div></figure><p id="7e5f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为了π₁:</p><figure class="jv jw jx jy fd ij er es paragraph-image"><div class="er es mv"><img src="../Images/6bd07b95f0c518dfc3d38d9f79086cda.png" data-original-src="https://miro.medium.com/v2/resize:fit:770/format:webp/1*pOjWIq99e6AM0NsDIpz7Kg.png"/></div></figure><p id="12e1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">对于π₂:</p><figure class="jv jw jx jy fd ij er es paragraph-image"><div class="er es mw"><img src="../Images/00ffd4b7dfa8c92541e310c46dee6295.png" data-original-src="https://miro.medium.com/v2/resize:fit:696/format:webp/1*HAY1XquLP1PVM5Rp7q5o6A.png"/></div></figure><ul class=""><li id="3640" class="lg lh hi ix b iy iz jc jd jg ls jk lt jo lu js ln lo lp lq bi translated">π₂给出了比π₁更好的结果，然而，通过观察超平面的位置，我们知道π₁是一个更好的选择</li></ul><p id="3258" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="jt">怎么处理？</em></p><p id="055a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">处理不平衡数据的标准方法是执行上采样或下采样</p><ol class=""><li id="d85d" class="lg lh hi ix b iy iz jc jd jg ls jk lt jo lu js mp lo lp lq bi translated"><strong class="ix hj">上采样:</strong></li></ol><ul class=""><li id="e8e8" class="lg lh hi ix b iy iz jc jd jg ls jk lt jo lu js ln lo lp lq bi translated">给少数阶级更多的权利。</li><li id="b647" class="lg lh hi ix b iy me jc mf jg mg jk mh jo mi js ln lo lp lq bi translated">制造人为的小众阶层之分。</li></ul><p id="226c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> SMOTE或合成少数过采样技术:</strong></p><ul class=""><li id="f9a8" class="lg lh hi ix b iy iz jc jd jg ls jk lt jo lu js ln lo lp lq bi translated">另一种上采样方式，使用最近邻生成新点。</li></ul><p id="f35e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> 2。缩减采样:</strong></p><ul class=""><li id="670e" class="lg lh hi ix b iy iz jc jd jg ls jk lt jo lu js ln lo lp lq bi translated">从多数班级中随机抽取样本。</li></ul></div><div class="ab cl ke kf gp kg" role="separator"><span class="kh bw bk ki kj kk"/><span class="kh bw bk ki kj kk"/><span class="kh bw bk ki kj"/></div><div class="hb hc hd he hf"><h2 id="7683" class="kl km hi bd kn ko kp kq kr ks kt ku kv jg kw kx ky jk kz la lb jo lc ld le lf bi translated">处理多类分类</h2><ul class=""><li id="dc25" class="lg lh hi ix b iy li jc lj jg lk jk ll jo lm js ln lo lp lq bi translated">逻辑回归本身并不支持多类分类。</li><li id="e18d" class="lg lh hi ix b iy me jc mf jg mg jk mh jo mi js ln lo lp lq bi translated">然而，人们可以使用<a class="ae iu" href="http://mlwiki.org/index.php/One-vs-All_Classification" rel="noopener ugc nofollow" target="_blank">一对所有</a>的策略来处理它。</li></ul><p id="45ab" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">暂时就这样吧！</p><p id="4adc" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">恭喜你。您现在已经成功地将逻辑回归添加到您的武器库中。😎</p></div></div>    
</body>
</html>