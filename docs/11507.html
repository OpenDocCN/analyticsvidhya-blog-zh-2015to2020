<html>
<head>
<title>YOLO v3 and MiDaS from a single Resnext101 backbone.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">YOLO v3和MiDaS来自单一的Resnext101主干网。</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/yolo-v3-and-midas-from-a-single-resnext101-backbone-8ba42948bf65?source=collection_archive---------16-----------------------#2020-12-06">https://medium.com/analytics-vidhya/yolo-v3-and-midas-from-a-single-resnext101-backbone-8ba42948bf65?source=collection_archive---------16-----------------------#2020-12-06</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/047bbe59ef5b881fa82dc69080bef37f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KfzMpJvf4eLSbfa_tTBZrg.jpeg"/></div></div></figure><p id="11e4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在自主导航和增强现实等应用中，您可能需要不止一个输入来分析环境，以精确评估条件并采取行动。例如，自动驾驶汽车可能需要检测路上的行人及其深度，以便调整速度、刹车时间等。我们可以使用<a class="ae jo" href="https://github.com/ultralytics/yolov3" rel="noopener ugc nofollow" target="_blank"> YOLO v3 </a>并训练它检测乘客、标志牌等，并使用类似<a class="ae jo" href="https://github.com/intel-isl/MiDaS" rel="noopener ugc nofollow" target="_blank">迈达斯</a>的网络并使用它来检测深度。这种方法的问题是，在大多数边缘设备中，推理能力较低，并且在实时情况下，必须保持推理符合帧速率，因此我们需要在业务端有效实施这些网络。</p><p id="4ee2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">想法是使用单个特征提取网络。在我们的例子中，YOLO v3使用了暗网主干。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es jp"><img src="../Images/4956617f31cec64e1497a7327d02fedb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eCckwBcPjALQSPLgvnpDxA.png"/></div></div></figure><p id="4f56" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">MiDaS使用预训练的Resnext101作为特征提取器。因此，这里我们将选择MiDaS的ResNext101作为公共特征提取器，并从那里训练YOLO v3头。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ju"><img src="../Images/3927441769d0771e044c979279096f96.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ewHa8h8Nyf61Yy6LFnTYlQ.png"/></div></div><figcaption class="jv jw et er es jx jy bd b be z dx translated">从单幅图像中检测物体和深度</figcaption></figure><p id="85f7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">上面重新设计的结构减少了参数的数量，并且反过来减少了边缘设备中的推理时间。我们将使用有助于检测建筑工人安全装备的数据集。</p></div><div class="ab cl jz ka gp kb" role="separator"><span class="kc bw bk kd ke kf"/><span class="kc bw bk kd ke kf"/><span class="kc bw bk kd ke"/></div><div class="hb hc hd he hf"><h1 id="f0da" class="kg kh hi bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">方法</h1><ol class=""><li id="3427" class="le lf hi is b it lg ix lh jb li jf lj jj lk jn ll lm ln lo bi translated">MiDaS是一个训练有素的网络。砝码可以原样使用。</li><li id="fb27" class="le lf hi is b it lp ix lq jb lr jf ls jj lt jn ll lm ln lo bi translated">用MiDaS网络的特征提取器连接3个YOLO层。</li><li id="4bd4" class="le lf hi is b it lp ix lq jb lr jf ls jj lt jn ll lm ln lo bi translated">在YOLO图层之前添加一些卷积图层，以便更好地学习边界框。</li><li id="df7c" class="le lf hi is b it lp ix lq jb lr jf ls jj lt jn ll lm ln lo bi translated">冻结迈达斯分部，只为YOLO分部训练，节省重量。</li><li id="73fb" class="le lf hi is b it lp ix lq jb lr jf ls jj lt jn ll lm ln lo bi translated">为MiDaS网络引入损耗函数，定义总损耗。</li><li id="1c34" class="le lf hi is b it lp ix lq jb lr jf ls jj lt jn ll lm ln lo bi translated">用所有预训练的权重加载模型，并用非常小的学习率训练所有层。</li></ol><p id="a8f2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">具有Imagenet权重的Resnext101对于对象检测问题是一个非常有能力的网络，此外，YOLOv3中使用的Darknet主干实际上是Resnet的变体。因此，从头开始培训主干并不是一个好主意，尤其是当两个分支机构都在使用它的时候。因此，我们在主干之后增加了学习包围盒的能力，并进行迁移学习。</p><p id="07bf" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">用迈达斯缝合YOLO</strong></p><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lu"><img src="../Images/7238be9033dfe18908ac80c2b172d585.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BbvyPxhryIwFnAPmWsC5OA.png"/></div></div></figure><p id="d4aa" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在让我们来训练这个网络，正如你在这个练习中看到的，MiDaS解码器被冻结了。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lv"><img src="../Images/7176126cf281b5121d396432590951f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_LAwGB7RuzkLlaNyCvV4rg.png"/></div></div><figcaption class="jv jw et er es jx jy bd b be z dx translated">仅训练YOLO分支50个时代</figcaption></figure><p id="cbf1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">仅仅过了50个纪元，我们就看到了惊人的结果！记得最初的YOLO v3被训练了300个纪元。现在，我们保存模型权重，并专注于包括MiDaS在内的整个网络的损耗函数。</p><p id="9d0f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">损失函数</strong></p><p id="799c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们没有关于从头开始训练MiDaS网络的详细解释，否则很难用我们可支配的有限资源来训练这样的网络，因此我们使用预训练的MiDaS并为我们的图像生成深度图。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lw"><img src="../Images/3f091ae34043a119f13f2b4df913d961.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4halwyu_RHplUJ3V9nB2vQ.png"/></div></div><figcaption class="jv jw et er es jx jy bd b be z dx translated">原始图像</figcaption></figure><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lx"><img src="../Images/72cb6eadd0d083bf25edd7dfaefe6e5f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_maZR1Z_-Msc03nBCNTy4A.png"/></div></div><figcaption class="jv jw et er es jx jy bd b be z dx translated">从MiDaS推断的深度图</figcaption></figure><p id="89f5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们使用这些深度图作为我们网络的地面实况。现在，当从两个分支训练网络时，来自每个分支的梯度可能渗入主干权重，因此可能完全破坏它们。首先，让我们确保为MiDaS网络定义一个损失函数，并单独训练它，以查看损失是否减少(损失将减少非常非常少，因为我们已经在使用训练有素的网络)。</p><p id="e79c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们可以使用图像质量评估作为损失的度量。我们可以使用</p><ol class=""><li id="a620" class="le lf hi is b it iu ix iy jb ly jf lz jj ma jn ll lm ln lo bi translated">SSIM(结构相似指数)</li><li id="c13a" class="le lf hi is b it lp ix lq jb lr jf ls jj lt jn ll lm ln lo bi translated">MSE(像素级)</li></ol><p id="34bb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">SSIM(建议更接近人类感知)从亮度、对比度和结构方面测量图像之间的结构相似性。SSIM在相似图像之间为1，在随机图像之间为0。但是在我们的观察中，我们看到下面两张深度图像的SSIM值为0.00711</p><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mb"><img src="../Images/641db394a86e10359308ccc64c037db5.png" data-original-src="https://miro.medium.com/v2/resize:fit:914/format:webp/1*FwMRGq_RZLTaRVnncGuBbg.png"/></div></div><figcaption class="jv jw et er es jx jy bd b be z dx translated">SSIM 0.00711</figcaption></figure><p id="9b24" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">根据我们的问题，我们需要一个度量来告诉我们这两个图像彼此有些相似。我们将选择像素方式的MSE作为损失函数，因为它简单。有了这个，我们可以单独训练我们的迈达斯分部冷冻YOLO分部。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mc"><img src="../Images/a1a667219df36f543ecb5ebf3373b35d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cvkbmttqRl3PZqMQdkSHUA.png"/></div></div><figcaption class="jv jw et er es jx jy bd b be z dx translated">深度图预测的损失减少</figcaption></figure><p id="d8a5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在让我们来定义网络的总损耗。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es md"><img src="../Images/1ec31302a54760f240a4894a10102044.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DWfsyD3hu5pVvaIV1vDxrw.png"/></div></div></figure><p id="8794" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在以非常小的学习速率用上述损失函数训练之后(为了不使权重偏离范围太多，因为各个分支表现得相当好)，我们得到如下结果。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es me"><img src="../Images/f90da3d30b494c9278ee88d95f1336ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7Aj3TU2td9nTzRvg0BgmtQ.png"/></div></div></figure><p id="83d7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这看起来很好，现在我们可以使用这个网络部署在导航系统中。感谢阅读！</p><p id="4f42" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">参考资料:</p><div class="mf mg ez fb mh mi"><a href="https://github.com/intel-isl/MiDaS" rel="noopener  ugc nofollow" target="_blank"><div class="mj ab dw"><div class="mk ab ml cl cj mm"><h2 class="bd hj fi z dy mn ea eb mo ed ef hh bi translated">英特尔-isl/MiDaS</h2><div class="mp l"><h3 class="bd b fi z dy mn ea eb mo ed ef dx translated">这个库包含了从一幅图像计算深度的代码。它伴随着我们的论文:走向稳健的单目…</h3></div><div class="mq l"><p class="bd b fp z dy mn ea eb mo ed ef dx translated">github.com</p></div></div><div class="mr l"><div class="ms l mt mu mv mr mw io mi"/></div></div></a></div><div class="mf mg ez fb mh mi"><a href="https://github.com/ultralytics/yolov3" rel="noopener  ugc nofollow" target="_blank"><div class="mj ab dw"><div class="mk ab ml cl cj mm"><h2 class="bd hj fi z dy mn ea eb mo ed ef hh bi translated">ultralytics/yolov3</h2><div class="mp l"><h3 class="bd b fi z dy mn ea eb mo ed ef dx translated">分支通知:ultralytics/yolov3存储库现在分为两个分支:$ git clone…</h3></div><div class="mq l"><p class="bd b fp z dy mn ea eb mo ed ef dx translated">github.com</p></div></div><div class="mr l"><div class="mx l mt mu mv mr mw io mi"/></div></div></a></div><div class="mf mg ez fb mh mi"><a href="https://arxiv.org/abs/1804.02767" rel="noopener  ugc nofollow" target="_blank"><div class="mj ab dw"><div class="mk ab ml cl cj mm"><h2 class="bd hj fi z dy mn ea eb mo ed ef hh bi translated">YOLOv3:增量改进</h2><div class="mp l"><h3 class="bd b fi z dy mn ea eb mo ed ef dx translated">我们向YOLO展示一些更新！我们做了一些设计上的小改动，让它变得更好。我们还培训了这个新的…</h3></div><div class="mq l"><p class="bd b fp z dy mn ea eb mo ed ef dx translated">arxiv.org</p></div></div></div></a></div><div class="mf mg ez fb mh mi"><a href="https://arxiv.org/abs/1907.01341v3" rel="noopener  ugc nofollow" target="_blank"><div class="mj ab dw"><div class="mk ab ml cl cj mm"><h2 class="bd hj fi z dy mn ea eb mo ed ef hh bi translated">走向稳健的单目深度估计:用于零炮跨数据集传输的混合数据集</h2><div class="mp l"><h3 class="bd b fi z dy mn ea eb mo ed ef dx translated">单目深度估计的成功依赖于大量不同的训练集。由于相关的挑战…</h3></div><div class="mq l"><p class="bd b fp z dy mn ea eb mo ed ef dx translated">arxiv.org</p></div></div></div></a></div><div class="mf mg ez fb mh mi"><a href="https://ece.uwaterloo.ca/~z70wang/publications/ssim.html" rel="noopener  ugc nofollow" target="_blank"><div class="mj ab dw"><div class="mk ab ml cl cj mm"><h2 class="bd hj fi z dy mn ea eb mo ed ef hh bi translated">图像质量评估:从错误可见性到结构相似性</h2><div class="mp l"><h3 class="bd b fi z dy mn ea eb mo ed ef dx translated">图像质量评估:从误差可见性到结构相似性，卷…</h3></div><div class="mq l"><p class="bd b fp z dy mn ea eb mo ed ef dx translated">ece.uwaterloo.ca</p></div></div></div></a></div></div></div>    
</body>
</html>