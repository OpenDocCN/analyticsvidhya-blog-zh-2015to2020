<html>
<head>
<title>Implement SRCNN with Pure C++</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用纯C++实现SRCNN</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/implement-srcnn-with-pure-c-33dcacfbb333?source=collection_archive---------26-----------------------#2020-06-15">https://medium.com/analytics-vidhya/implement-srcnn-with-pure-c-33dcacfbb333?source=collection_archive---------26-----------------------#2020-06-15</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="ab8d" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">一次走过提醒我主人的时光。</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/e5a0eea7cb2561d4ee2d488994cf93ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*1ZFK0tKrOMZRxlpx"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">布鲁斯·马斯在<a class="ae jn" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><h1 id="76ea" class="jo jp hi bd jq jr js jt ju jv jw jx jy io jz ip ka ir kb is kc iu kd iv ke kf bi translated">动机</h1><p id="715a" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko kp kq kr ks kt ku kv kw kx ky kz la lb hb bi translated">刚开始考硕士的时候，教授叫我用纯C++和CUDA实现。经过两个月的工作，我终于完成了第一个版本，但结果似乎不仅模糊，而且大小错误。</p><p id="25f1" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">然而，我在这个项目中学会了如何使用指针和基本的CUDA概念。此外，我对CNN的工作方式和架构有了一些概念。作为报复，我想从零开始实现SRCNN，这篇帖子说的是做这个项目时的注意事项。</p><h1 id="0cf0" class="jo jp hi bd jq jr js jt ju jv jw jx jy io jz ip ka ir kb is kc iu kd iv ke kf bi translated">什么是超分辨率？</h1><p id="a9af" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko kp kq kr ks kt ku kv kw kx ky kz la lb hb bi translated">超分辨率是一种以更高分辨率构建图像的图像处理技术。到目前为止，我们使用了很多特征来表示图像的属性，神经网络是提取特征的一种方法。在神经网络的帮助下，我们创造了一个前所未有的诱人结果。</p><h1 id="a19f" class="jo jp hi bd jq jr js jt ju jv jw jx jy io jz ip ka ir kb is kc iu kd iv ke kf bi translated">那么什么是SRCNN呢？</h1><p id="2aa8" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko kp kq kr ks kt ku kv kw kx ky kz la lb hb bi translated">卷积神经网络(CNN)广泛应用于视觉任务。在超分辨率方面，SRCNN是第一个使用CNN来完成这项任务的。超东<em class="lh">等人</em>在2014年提出的SRCNN优于包括稀疏编码在内的许多方法。</p><p id="12d3" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">更重要的是，SRCNN的组成非常简单:3个卷积和2个激活层。我很惊讶这种结构可以击败传统方法，尽管它有两个缺点:</p><ol class=""><li id="da0b" class="li lj hi ki b kj lc km ld kp lk kt ll kx lm lb ln lo lp lq bi translated">在把图像传给CNN之前，你必须把图像调整到输出尺寸。</li><li id="7cf6" class="li lj hi ki b kj lr km ls kp lt kt lu kx lv lb ln lo lp lq bi translated">随着输出图像大小的增长，产生结果需要更多的时间。</li></ol><h1 id="54f0" class="jo jp hi bd jq jr js jt ju jv jw jx jy io jz ip ka ir kb is kc iu kd iv ke kf bi translated">整体结构</h1><p id="2381" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko kp kq kr ks kt ku kv kw kx ky kz la lb hb bi translated">下图显示了SRCNN的结构，取自[1]。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lw"><img src="../Images/17a962de3c6c1f4769fe505049347e84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Fev_pMiSulzxJJJc.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">SRCNN的整体结构。</figcaption></figure><p id="8f12" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">图中暗示，我们要做的就是实现卷积和激活层。</p><h1 id="f028" class="jo jp hi bd jq jr js jt ju jv jw jx jy io jz ip ka ir kb is kc iu kd iv ke kf bi translated">实施细节</h1><p id="2451" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko kp kq kr ks kt ku kv kw kx ky kz la lb hb bi translated">这部分我将展示一些关于我的实现的细节。</p><h1 id="1be0" class="jo jp hi bd jq jr js jt ju jv jw jx jy io jz ip ka ir kb is kc iu kd iv ke kf bi translated">卷积层</h1><h2 id="7d7d" class="lx jp hi bd jq ly lz ma ju mb mc md jy kp me mf ka kt mg mh kc kx mi mj ke mk bi translated">朴素方法</h2><p id="6d14" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko kp kq kr ks kt ku kv kw kx ky kz la lb hb bi translated">实现朴素卷积很简单:每个输出神经元的值是输入神经元乘以核参数的总和。以下伪代码有助于您实现这一计算:</p><pre class="iy iz ja jb fd ml mm mn mo aw mp bi"><span id="f3c3" class="lx jp hi mm b fi mq mr l ms mt">for(k = 0; k &lt; # of output channels; k += stride)<br/>    for(n = 0; n &lt; # of input channels; n += stride)<br/>        for(i = 0; i &lt; # of input height; i += stride)<br/>            for(j = 0; j &lt; # of input width; j += stride)<br/>                sum = 0;<br/>                for(l = 0; l &lt; # of kernel height; l++)<br/>                    for(m = 0; m &lt; # of kernel width; m++)<br/>                        sum += input[n][i][j] * kernel[k][n][l][m];<br/>                output[k][i][j] += sum;</span></pre><h2 id="f2d3" class="lx jp hi bd jq ly lz ma ju mb mc md jy kp me mf ka kt mg mh kc kx mi mj ke mk bi translated">im2col法</h2><p id="2411" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko kp kq kr ks kt ku kv kw kx ky kz la lb hb bi translated">我们看到，在前面的部分中，我们需要6个for-loop来进行简单的卷积。此外，如果跨度足够大，我们必须收集相距较远的值，因此会失去缓存的局部性使用。</p><p id="8867" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">Caffe 作者<a class="ae jn" href="https://github.com/Yangqing/caffe/wiki/Convolution-in-Caffe:-a-memo" rel="noopener ugc nofollow" target="_blank">建议，可以使用im2col技术将卷积计算转化为矩阵乘法问题。在这种情况下，当执行乘法时，我们利用计算机体系结构的局部性。此外，我们可以进一步使用高度优化的BLAS(基本线性代数子程序)库来提高我们的卷积计算。</a></p><p id="4d4e" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">这种方法的缺点是需要更多的内存来存储由<code class="du mu mv mw mm b">im2col</code>函数创建的矩阵。</p><p id="c5e3" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">下图展示了im2col的概念，摘自[2]:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mx"><img src="../Images/92105b8025d5bb0b968a2377f40144db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*qgMDFgO5qA1Qh4Bq.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">im2col的一个直观概念。</figcaption></figure><h1 id="f8d3" class="jo jp hi bd jq jr js jt ju jv jw jx jy io jz ip ka ir kb is kc iu kd iv ke kf bi translated">活化层</h1><p id="889a" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko kp kq kr ks kt ku kv kw kx ky kz la lb hb bi translated">与卷积层相比，这一层相当简单；你只要把每个神经元的值传递给激活函数，就得到结果了。</p><p id="24e4" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">我选择ReLU是因为这种激活函数在SRCNN中使用。</p><h1 id="7aaf" class="jo jp hi bd jq jr js jt ju jv jw jx jy io jz ip ka ir kb is kc iu kd iv ke kf bi translated">读取重量</h1><p id="f28b" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko kp kq kr ks kt ku kv kw kx ky kz la lb hb bi translated">虽然Caffe使用NCHW格式，但是SRCNN的作者使用<strong class="ki hj"> CHWN格式</strong>来存储他们的网络权重[1]:</p><pre class="iy iz ja jb fd ml mm mn mo aw mp bi"><span id="1be6" class="lx jp hi mm b fi mq mr l ms mt"><strong class="mm hj">for</strong> i <strong class="mm hj">=</strong> 1 : channel<br/>        <strong class="mm hj">for</strong> j <strong class="mm hj">=</strong> 1 : fnum<br/>             temp <strong class="mm hj">=</strong> conv_filters(:,:,i,j);<br/>             <strong class="mm hj">if</strong> channel <strong class="mm hj">==</strong> 1<br/>                weights(:,j) <strong class="mm hj">=</strong> temp(:);<br/>             <strong class="mm hj">else</strong><br/>                weights(i,:,j) <strong class="mm hj">=</strong> temp(:);<br/>             <strong class="mm hj">end</strong> <br/>        <strong class="mm hj">end</strong> <br/>    <strong class="mm hj">end</strong></span></pre><p id="ff7d" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">有关权重格式布局的更多信息，您可以访问英特尔MKLDNN的<a class="ae jn" href="https://oneapi-src.github.io/oneDNN/understanding_memory_formats.html" rel="noopener ugc nofollow" target="_blank">这篇文章</a>。</p><p id="7192" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">在我的实现中，我使用NCHW格式，因为大多数神经网络框架都采用这种格式。</p><h1 id="ca98" class="jo jp hi bd jq jr js jt ju jv jw jx jy io jz ip ka ir kb is kc iu kd iv ke kf bi translated">密码</h1><blockquote class="my mz na"><p id="1d63" class="kg kh lh ki b kj lc ij kl km ld im ko nb le kr ks nc lf kv kw nd lg kz la lb hb bi translated"><em class="hi">就那句老话，给我看看代码！</em></p></blockquote><p id="f43d" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">没错，这里的代码是<a class="ae jn" href="https://github.com/Cuda-Chen/SRCNN-cpp" rel="noopener ugc nofollow" target="_blank">这里的</a>，你可以在<code class="du mu mv mw mm b">src/srcnn.cpp</code>里看一下。然而我把它写成了一个怪物类(在<code class="du mu mv mw mm b">src/srcnn.cpp</code>中有1000多行)。因此，我认为我应该在将来创建单独的文件来存储每个组件。</p><h1 id="a2a2" class="jo jp hi bd jq jr js jt ju jv jw jx jy io jz ip ka ir kb is kc iu kd iv ke kf bi translated">结果</h1><p id="7308" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko kp kq kr ks kt ku kv kw kx ky kz la lb hb bi translated">我的SRCNN实现的结果如下表所示:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ne"><img src="../Images/32350171cbd362948558d4f367ad5b22.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*su5Qk6xW_MvF9z0UbkqC8g.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">两种实现方法的比较。</figcaption></figure><p id="2553" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">当然，我们需要一些比较来实现我的实现是否正确！</p><p id="07c3" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">所以这里是我实验室一个格式员的成果和我硕士一年级的实现:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nf"><img src="../Images/8bf60163c594bcf8fe694137d5081a56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7K0MFW6jT9D2PggAMDmjIA.png"/></div></div></figure><p id="a30a" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">您可以看到，与我在硕士一年级时实现的结果相比，这两种实现都产生了正确的结果(输出大小和图像质量)。然而，我的三个实现的质量似乎不如前一个成员。</p><h1 id="a0ad" class="jo jp hi bd jq jr js jt ju jv jw jx jy io jz ip ka ir kb is kc iu kd iv ke kf bi translated">贝克马克</h1><p id="9272" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko kp kq kr ks kt ku kv kw kx ky kz la lb hb bi translated">基准参数如下所示:</p><ul class=""><li id="2b3d" class="li lj hi ki b kj lc km ld kp lk kt ll kx lm lb ng lo lp lq bi translated">操作系统:macOS 10.13.4</li><li id="2f5e" class="li lj hi ki b kj lr km ls kp lt kt lu kx lv lb ng lo lp lq bi translated">CPU:英特尔酷睿i7 7700单核处理器</li><li id="b56b" class="li lj hi ki b kj lr km ls kp lt kt lu kx lv lb ng lo lp lq bi translated">内存:32 GB</li><li id="e11d" class="li lj hi ki b kj lr km ls kp lt kt lu kx lv lb ng lo lp lq bi translated">编译器:苹果LLVM版本10.0.0</li><li id="b157" class="li lj hi ki b kj lr km ls kp lt kt lu kx lv lb ng lo lp lq bi translated">理想的输出尺寸:512 x 512像素</li><li id="9255" class="li lj hi ki b kj lr km ls kp lt kt lu kx lv lb ng lo lp lq bi translated">测试方法:用一个因素运行程序三次，然后取平均值</li><li id="bdc1" class="li lj hi ki b kj lr km ls kp lt kt lu kx lv lb ng lo lp lq bi translated">计时方法:使用<code class="du mu mv mw mm b">std::chrono</code></li></ul><p id="18a1" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">下面是每个SRCNN实现方法比较的基准:</p><ul class=""><li id="53ca" class="li lj hi ki b kj lc km ld kp lk kt ll kx lm lb ng lo lp lq bi translated">天真:(125.414+122.221+124.625)/3 = 124.0867s</li><li id="d218" class="li lj hi ki b kj lr km ls kp lt kt lu kx lv lb ng lo lp lq bi translated">im2 col:(323.543+339.007+316.313)/3 = 326.2877s</li></ul><p id="dd18" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">正如您所看到的，虽然im2col方法可以通过牺牲内存来获得提升，但它比naive方法慢得多。我猜准备列矩阵需要很多时间。</p><h1 id="767a" class="jo jp hi bd jq jr js jt ju jv jw jx jy io jz ip ka ir kb is kc iu kd iv ke kf bi translated">变得更快</h1><p id="b587" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko kp kq kr ks kt ku kv kw kx ky kz la lb hb bi translated">卷积是一种尴尬的并行问题；也就是说，它对大量数据应用运算。所以我们可以使用一些并行计算技术来加速执行。</p><p id="1b53" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">在CPU并行场景下，我们可以选择OpenMP作为并行计算目标，因为它简单。</p><p id="835b" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">以下是应用OpenMP后的每个SRCNN实现比较的基准:</p><ul class=""><li id="a15d" class="li lj hi ki b kj lc km ld kp lk kt ll kx lm lb ng lo lp lq bi translated">天真:(37.6111+39.9825+38.3595)/3 = 38.6510s</li><li id="d2f3" class="li lj hi ki b kj lr km ls kp lt kt lu kx lv lb ng lo lp lq bi translated">im2 col:(97.9533+103.525+94.5232)/3 = 98.6672s</li></ul><p id="24f0" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">这两种技术都运行得更快，但是im2col仍然比naive运行得慢。</p><h1 id="204d" class="jo jp hi bd jq jr js jt ju jv jw jx jy io jz ip ka ir kb is kc iu kd iv ke kf bi translated">结论</h1><p id="a72e" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko kp kq kr ks kt ku kv kw kx ky kz la lb hb bi translated">在这篇文章中，我简单介绍一下超分辨率和SRCNN。然后我演示了SRCNN的结构，并讲述了这些层的实现细节。最后，我对两种实现方式的结果和执行时间进行了比较，并给出了一个假设，即为什么大多数框架中的优选实现比简单实现运行得慢得多。</p><h1 id="e059" class="jo jp hi bd jq jr js jt ju jv jw jx jy io jz ip ka ir kb is kc iu kd iv ke kf bi translated">特别感谢</h1><p id="8d58" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko kp kq kr ks kt ku kv kw kx ky kz la lb hb bi translated">我要特别感谢<a class="ae jn" href="https://github.com/masc4ii" rel="noopener ugc nofollow" target="_blank"> masc4ii </a>添加OpenMP和QMake构建选项功能。没有你的帮助，这个项目将远远不能完成。</p><h1 id="f033" class="jo jp hi bd jq jr js jt ju jv jw jx jy io jz ip ka ir kb is kc iu kd iv ke kf bi translated">参考</h1><p id="976e" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko kp kq kr ks kt ku kv kw kx ky kz la lb hb bi translated">[1]http://mmlab.ie.cuhk.edu.hk/projects/SRCNN.html<a class="ae jn" href="http://mmlab.ie.cuhk.edu.hk/projects/SRCNN.html" rel="noopener ugc nofollow" target="_blank"/></p><p id="e7dc" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">[2]<a class="ae jn" href="https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/making_faster.html" rel="noopener ugc nofollow" target="_blank">https://Leonardo araujosantos . git books . io/artificial-intelligence/content/making _ faster . html</a></p></div><div class="ab cl nh ni gp nj" role="separator"><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm"/></div><div class="hb hc hd he hf"><p id="7d43" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated"><em class="lh">原载于2020年6月15日</em><a class="ae jn" href="https://cuda-chen.github.io/machine%20learning/2020/06/15/implement-srcnn-in-pure-cpp.html" rel="noopener ugc nofollow" target="_blank"><em class="lh">https://cuda-Chen . github . io</em></a><em class="lh">。</em></p></div><div class="ab cl nh ni gp nj" role="separator"><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm"/></div><div class="hb hc hd he hf"><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="no np l"/></div></figure></div><div class="ab cl nh ni gp nj" role="separator"><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm nn"/><span class="nk bw bk nl nm"/></div><div class="hb hc hd he hf"><blockquote class="my mz na"><p id="3263" class="kg kh lh ki b kj lc ij kl km ld im ko nb le kr ks nc lf kv kw nd lg kz la lb hb bi translated"><em class="hi">如果你有什么想法和问题要分享，请联系我</em><a class="ae jn" href="http://clh960524@gmail.com/" rel="noopener ugc nofollow" target="_blank"><strong class="ki hj"><em class="hi">clh 960524【at】Gmail . com</em></strong></a><em class="hi">。还有，其他作品可以查看我的</em> <a class="ae jn" href="https://github.com/Cuda-Chen" rel="noopener ugc nofollow" target="_blank"> <em class="hi"> GitHub知识库</em> </a> <em class="hi">。如果你和我一样热衷于机器学习、图像处理和并行计算，欢迎在LinkedIn上</em> <a class="ae jn" href="https://www.linkedin.com/in/lu-hsuan-chen-78071b171/" rel="noopener ugc nofollow" target="_blank"> <em class="hi">加我</em> </a> <em class="hi">。</em></p></blockquote></div></div>    
</body>
</html>