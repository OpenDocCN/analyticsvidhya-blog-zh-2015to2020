<html>
<head>
<title>COVID Tweet Analysis — Part 3</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">COVID 推文分析—第 3 部分</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/covid-tweet-analysis-part-3-2e24ab3e484d?source=collection_archive---------16-----------------------#2020-10-08">https://medium.com/analytics-vidhya/covid-tweet-analysis-part-3-2e24ab3e484d?source=collection_archive---------16-----------------------#2020-10-08</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="1f07" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">构建情感分类器</h2></div><p id="25e9" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在我之前的博客<a class="ae jt" rel="noopener" href="/analytics-vidhya/covid-tweet-analysis-part-1-a88ef91f432f">第一部分</a>和<a class="ae jt" rel="noopener" href="/analytics-vidhya/covid-tweet-analysis-part-2-5faae4062c6e">第二部分</a>中，我们分别探索了 COVID 推文数据并进行主题建模，在这一部分，我们将构建一个情感分类器。</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="er es ju"><img src="../Images/ba8c0c7bf7ae304c889dde24728acc88.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VjKuVioLSXpiP4leVawJvw.png"/></div></div><figcaption class="kg kh et er es ki kj bd b be z dx translated">正面和负面推文中出现频率最高的词。</figcaption></figure><p id="13af" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">虽然前面几部分已经做了基本的数据探索，再次展现一点数据的惊鸿一瞥！！</p><h2 id="dfee" class="kk kl hi bd km kn ko kp kq kr ks kt ku jg kv kw kx jk ky kz la jo lb lc ld le bi translated">a)所用数据集的预览。</h2><ul class=""><li id="0bd0" class="lf lg hi iz b ja lh jd li jg lj jk lk jo ll js lm ln lo lp bi translated">COVID Tweet 数据集一瞥</li></ul><figure class="jv jw jx jy fd jz er es paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="er es lq"><img src="../Images/407b13d9b830831cce367db44ec5baed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o6K2hmCT8ly1LdIqrUqEfQ.png"/></div></div></figure><ul class=""><li id="5cc3" class="lf lg hi iz b ja jb jd je jg lr jk ls jo lt js lm ln lo lp bi translated">推文数据可用于一个月的时间段，最大推文数量从 3 月 19 日至 21 日。</li></ul><figure class="jv jw jx jy fd jz er es paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="er es lu"><img src="../Images/22f9c291df693339ea08b99690b28b70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pXJ0heo5d1L3E7mXlPNwdw.png"/></div></div></figure><ul class=""><li id="9710" class="lf lg hi iz b ja jb jd je jg lr jk ls jo lt js lm ln lo lp bi translated">让我们也看看推文的长度(我已经处理过推文)。大量的推文都有 20-22 个单词长。</li></ul><figure class="jv jw jx jy fd jz er es paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="er es lv"><img src="../Images/7136e04f7f360dc8df93294893937756.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HJ4_jRPnOmvIuikvJGHD_g.png"/></div></div></figure><p id="a500" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">关于探索性数据分析的更多细节，请参考<a class="ae jt" rel="noopener" href="/analytics-vidhya/covid-tweet-analysis-part-1-a88ef91f432f">这篇</a>博客。</p><h2 id="0309" class="kk kl hi bd km kn ko kp kq kr ks kt ku jg kv kw kx jk ky kz la jo lb lc ld le bi translated">b)建立情感分类器</h2><p id="bb3d" class="pw-post-body-paragraph ix iy hi iz b ja lh ij jc jd li im jf jg lw ji jj jk lx jm jn jo ly jq jr js hb bi translated">由于这是一个延续博客，数据清理已经在前面的步骤中处理过了。因此，我将从模型构建过程开始。</p><ul class=""><li id="90fd" class="lf lg hi iz b ja jb jd je jg lr jk ls jo lt js lm ln lo lp bi translated"><strong class="iz hj">将数据分为训练集和测试集</strong></li></ul><figure class="jv jw jx jy fd jz er es paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="er es lz"><img src="../Images/202668710566b020eae34240696c7967.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HbUA8aAU646hRJtZ7Qaw7w.png"/></div></div></figure><p id="7bd5" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我使用经过处理的 tweets 作为独立变量，并创建了一个目标变量，有 3 个级别——中性、积极和消极，分别表示为 0、1 和 2。为了训练，我使用了 70%的数据。</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="er es ma"><img src="../Images/42c2eb2050c61ba3c5bb020d5e04a558.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V8z3pJ563pw0QQulH9T_8g.png"/></div></div><figcaption class="kg kh et er es ki kj bd b be z dx translated">目标分布</figcaption></figure><ul class=""><li id="d0a7" class="lf lg hi iz b ja jb jd je jg lr jk ls jo lt js lm ln lo lp bi translated"><strong class="iz hj">创建用于文本特征提取的管道，随后拟合分类器模型</strong>。</li></ul><figure class="jv jw jx jy fd jz er es paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="er es mb"><img src="../Images/ecbc93f6dd1a8d1e4d02e9045b682dee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YDoZDVI61CLySh9iKvivVw.png"/></div></div></figure><p id="62b2" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我创建了一个函数，它将模型调用作为参数，并创建一个管道，首先使用<strong class="iz hj">tfidfvectorser</strong>转换 tweets，然后拟合分类模型。然后，拟合的模型用于预测测试数据，并且测试预测作为输出返回。</p><ul class=""><li id="b642" class="lf lg hi iz b ja jb jd je jg lr jk ls jo lt js lm ln lo lp bi translated"><strong class="iz hj">训练分类器</strong></li></ul><p id="db64" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">对于模型构建过程，我尝试了多个模型。让我们带你看一下适合这个数据集的各种基线模型。</p><ol class=""><li id="91cc" class="lf lg hi iz b ja jb jd je jg lr jk ls jo lt js mc ln lo lp bi translated"><strong class="iz hj">多项式朴素贝叶斯</strong></li></ol><p id="1e82" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">多项式朴素贝叶斯是文本分类中使用的两种经典朴素贝叶斯变体之一(其中数据通常表示为词向量计数，尽管已知 tf-idf 向量在实践中也工作得很好)。朴素贝叶斯在文本分类问题上多次被认为是成功的。让我们看看它的表现如何！</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="er es md"><img src="../Images/e427afdb95efb42810e489ea5a241846.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dBaFJhYih_UJYVw307UHGg.png"/></div></div></figure><p id="6cd8" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">其准确率为 64%，对于 0 类的召回率很低，而 1 类的召回率最高，为 0.89。</p><p id="7908" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj"> 2。使用 RandomForestClassifier </strong></p><p id="ad0d" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在尝试了朴素贝叶斯之后，让我们尝试使用基于树的分类器 RandomForestClassifier 对此数据进行建模。随机森林在数据集的各个子样本上拟合几个决策树分类器，并使用平均来提高预测精度和控制过拟合。</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="er es me"><img src="../Images/3b180cd0a9462952abbe2940b37436ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KvgDUE0GfLNN50JWk846BQ.png"/></div></div></figure><p id="bd69" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">对于随机森林，准确率提高到 73%。就类 1 和类 2 的精度和召回率而言，它在 0.7-0.79 的范围内，并且无疑是对以前构建的朴素贝叶斯模型的改进。</p><p id="d365" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj"> 3。使用线性支持向量分类</strong></p><p id="87ab" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">LinearSVC 执行“一个对其余的”多类策略，从而训练 n 类模型。它类似于参数 kernel=' linear '的 SVC。</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="er es mf"><img src="../Images/7231a8bbcae1b903a9bb3bc2ab12ec9b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SKr6E84I-gvpSjNUs-aBHQ.png"/></div></div></figure><p id="84f0" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">它将准确率大幅提高到 79%，特别是对于类别 1 和类别 2(分别为阳性和阴性)，准确率和召回率提高到≥0.81。</p><p id="c6b7" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">请注意，我只是在这里安装了基线模型，这些可以进一步调整。</p><ul class=""><li id="1274" class="lf lg hi iz b ja jb jd je jg lr jk ls jo lt js lm ln lo lp bi translated"><strong class="iz hj">文字云对测试数据的最终预测</strong></li></ul><p id="b811" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">可视化对应于预测情感值的测试数据集的频繁出现的词。在积极情绪词云中，可以看到像“帮助”、“感谢”、“好”这样的词，而在消极情绪词云中，可以看到像“抢购”、“价格”、“需要”这样的词。</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="er es mg"><img src="../Images/7bd04c3974483086d732e708d76be746.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ijr-8cxH0YrDYDbE6vUL3w.png"/></div></div></figure><p id="17ad" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">你可以在这个博客<a class="ae jt" href="https://github.com/poojamahajan0712/COVID_tweet_analysis/blob/master/COVID_Tweet_Sentiment_classifier.ipynb" rel="noopener ugc nofollow" target="_blank">这里</a>找到相关代码。</p><p id="fb98" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">参考资料:-</p><ul class=""><li id="a53c" class="lf lg hi iz b ja jb jd je jg lr jk ls jo lt js lm ln lo lp bi translated"><a class="ae jt" href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC" rel="noopener ugc nofollow" target="_blank">https://sci kit-learn . org/stable/modules/generated/sk learn . SVM . linear SVC . html # sk learn . SVM . linear SVC</a></li><li id="eef6" class="lf lg hi iz b ja mh jd mi jg mj jk mk jo ml js lm ln lo lp bi translated"><a class="ae jt" href="https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html" rel="noopener ugc nofollow" target="_blank">https://sci kit-learn . org/stable/modules/generated/sk learn . naive _ Bayes。MultinomialNB.html</a></li><li id="ee2c" class="lf lg hi iz b ja mh jd mi jg mj jk mk jo ml js lm ln lo lp bi translated"><a class="ae jt" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html" rel="noopener ugc nofollow" target="_blank">https://sci kit-learn . org/stable/modules/generated/sk learn . ensemble . randomforestclassifier . html</a></li></ul></div></div>    
</body>
</html>