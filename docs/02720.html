<html>
<head>
<title>A little Math / Linear Algebra behind Instagram Face 3D Filters</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Instagram Face 3D滤镜背后的一点数学/线性代数</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/a-little-math-linear-algebra-behind-instagram-face-3d-filters-7862200938f6?source=collection_archive---------9-----------------------#2019-12-30">https://medium.com/analytics-vidhya/a-little-math-linear-algebra-behind-instagram-face-3d-filters-7862200938f6?source=collection_archive---------9-----------------------#2019-12-30</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="4e84" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我坚信，我们所有人都曾经使用过Snapchat / Instagram过滤器，或者至少看到过我们的朋友使用它，并在他们的社交媒体故事或帖子上分享它。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="ji jj l"/></div></figure><p id="4f06" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们开始知道“滤镜”这个词是作为美化者或背景添加装饰品，后来它变得更受欢迎，因为它出现在相机的每个脸上，如嵌入太阳镜，兔子头，年龄转换等。我们急切地看着自己的脸🤭</p><p id="5cfa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">具体来说，在这篇文章中，我们将讨论当我们进行面部过滤时，我们的手机/ Instagram <em class="jk">会做什么，这样<strong class="ih hj">眼镜</strong>就会被放在<strong class="ih hj">的正确位置</strong>，并能够跟随我们的<strong class="ih hj">头部姿势</strong>。</em></p><h2 id="bd1b" class="jl jm hi bd jn jo jp jq jr js jt ju jv iq jw jx jy iu jz ka kb iy kc kd ke kf bi translated">简而言之，人脸3D滤镜的主要过程依次分为3个阶段:</h2><ol class=""><li id="b030" class="kg kh hi ih b ii ki im kj iq kk iu kl iy km jc kn ko kp kq bi translated">人脸检测</li><li id="4131" class="kg kh hi ih b ii kr im ks iq kt iu ku iy kv jc kn ko kp kq bi translated">面部标志检测</li><li id="42ce" class="kg kh hi ih b ii kr im ks iq kt iu ku iy kv jc kn ko kp kq bi translated">项目投影</li></ol><p id="0499" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">人脸检测和地标检测是<strong class="ih hj">机器学习/深度学习</strong>的一部分，分别从整个图像中进行物体检测和进行回归。对于每个检测到的人脸，它将被发送到第二阶段的算法，以估计鼻子，眼睛，嘴等的位置。到目前为止，许多算法和数据集覆盖了68个人脸标志。<a class="ae kw" href="http://pyimagesearch.com/2017/04/03/facial-landmarks-dlib-opencv-python/" rel="noopener ugc nofollow" target="_blank">这里是进一步阅读的绝佳资源</a>。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es kx"><img src="../Images/1e2d449266b98e991734c03bdd2776d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*vEJVICV_xewhsUrLsQVj-g.jpeg"/></div><figcaption class="la lb et er es lc ld bd b be z dx translated">pyimagesearch.com的面部标志</figcaption></figure><p id="4d55" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然而，我们将关注第三阶段<strong class="ih hj">(项目投影)</strong>，因为我们正在谈论数学/线性代数/矩阵变换。当然，前两个阶段有很多数学内容要讲，但是每个阶段都有一大堆问题要讨论。</p><h1 id="a108" class="le jm hi bd jn lf lg lh jr li lj lk jv ll lm ln jy lo lp lq kb lr ls lt ke lu bi translated">项目投影</h1><p id="62a6" class="pw-post-body-paragraph if ig hi ih b ii ki ik il im kj io ip iq lv is it iu lw iw ix iy lx ja jb jc hb bi translated">标志检测的结果是每个标志的一组x和y坐标，这仅仅是2D信息，同时我们需要知道z坐标，左眼是否比右眼离相机更远，所以我们可以说面部正在看左侧，因为眼镜会跟随我们看的方向。</p><p id="3f2d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们用来进行这种投影的问题/方法被称为<strong class="ih hj">“透视n点(PnP)”</strong>或<strong class="ih hj">“针孔摄像机模型”</strong>。这是几十年前的方法，但仍然经常用于许多计算机视觉案例，包括机器人，增强现实和我们的讨论。要使这种方法奏效，需要三个要素:</p><h2 id="d495" class="jl jm hi bd jn jo jp jq jr js jt ju jv iq jw jx jy iu jz ka kb iy kc kd ke kf bi translated">1.作为参考的世界坐标空间的3D点</h2><p id="a556" class="pw-post-body-paragraph if ig hi ih b ii ki ik il im kj io ip iq lv is it iu lw iw ix iy lx ja jb jc hb bi translated">术语是超级酷的“世界坐标空间”，它们是一些固定点，我们可以说是参考点或在正常情况下，因为世界知道这是真的！！！。在这种情况下，我们使用这14个点。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es ly"><img src="../Images/a9819da973f54d7f9919d112019110d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:952/1*vrxlaeXiwiQ3iQx94prl9g.gif"/></div></figure><p id="0234" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这些点的位置类似于人的面部标志坐标，鼻子在面部的前面和中心，下巴在底部等等。</p><h2 id="3c40" class="jl jm hi bd jn jo jp jq jr js jt ju jv iq jw jx jy iu jz ka kb iy kc kd ke kf bi translated">2.投影点的2D点，与世界坐标空间一一对应</h2><p id="6d69" class="pw-post-body-paragraph if ig hi ih b ii ki ik il im kj io ip iq lv is it iu lw iw ix iy lx ja jb jc hb bi translated">投影点来自第二阶段的深度学习模型，这是面部标志模型，我们只使用模型输出的68点中的14点。</p><h2 id="48e4" class="jl jm hi bd jn jo jp jq jr js jt ju jv iq jw jx jy iu jz ka kb iy kc kd ke kf bi translated">3.相机矩阵</h2><p id="f072" class="pw-post-body-paragraph if ig hi ih b ii ki ik il im kj io ip iq lv is it iu lw iw ix iy lx ja jb jc hb bi translated">该矩阵包含关于相机的<strong class="ih hj">焦距</strong>和<strong class="ih hj">主点</strong>的信息，其实际上被图像中心的坐标所替代。而焦距通常与图像宽度的总像素相同。</p><h1 id="e132" class="le jm hi bd jn lf lg lh jr li lj lk jv ll lm ln jy lo lp lq kb lr ls lt ke lu bi translated"><strong class="ak">透视-n点(PnP) / </strong>针孔摄像机模型</h1><p id="b1df" class="pw-post-body-paragraph if ig hi ih b ii ki ik il im kj io ip iq lv is it iu lw iw ix iy lx ja jb jc hb bi translated">通过使用上面的3个信息，我们希望从这个公式中得到一个<strong class="ih hj">旋转矩阵(R) </strong>和<strong class="ih hj">平移向量(t) </strong>。</p><div class="jd je jf jg fd ab cb"><figure class="lz jh ma mb mc md me paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><img src="../Images/d5c1142d038deaef3b69cf564db42b1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:738/format:webp/1*7pQ7yBUTJ3Rn1lshVFpinA.png"/></div></figure><figure class="lz jh mj mb mc md me paragraph-image"><div role="button" tabindex="0" class="mf mg di mh bf mi"><img src="../Images/39407d73138ef060efe218324ddf1629.png" data-original-src="https://miro.medium.com/v2/resize:fit:1264/format:webp/1*ASz7_WtJY2Ugxs30Bkt53g.png"/></div><figcaption class="la lb et er es lc ld bd b be z dx mk di ml mm translated">来源:<a class="ae kw" href="https://docs.opencv.org/2.4/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html" rel="noopener ugc nofollow" target="_blank"> OpenCV文档</a></figcaption></figure></div><p id="3161" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">它将世界坐标空间的14个点与实际检测到的面部的14个点进行匹配，以获得<strong class="ih hj">面部在每个维度上旋转了&amp;平移了</strong>多少。</p><h2 id="3f1b" class="jl jm hi bd jn jo jp jq jr js jt ju jv iq jw jx jy iu jz ka kb iy kc kd ke kf bi translated">新点投影</h2><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es kx"><img src="../Images/f664b9507206ee5a1e725727ba67e1f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*4bjabVfov_HWAoM_N7Rzbw.png"/></div><figcaption class="la lb et er es lc ld bd b be z dx translated">来源:<a class="ae kw" href="https://docs.opencv.org/2.4/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html" rel="noopener ugc nofollow" target="_blank"> OpenCV文档</a></figcaption></figure><p id="393b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在知道旋转矩阵和平移向量之后，我们想要投射新的点(可能不是14个输入点)。<strong class="ih hj">输入</strong>是3d坐标(X，Y，Z) <strong class="ih hj">类似世界坐标空间</strong>指向2D坐标(u，v)，最后我们只显示2D的图像。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mn"><img src="../Images/e45ad42d7ce456d6234648be706f95cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:282/format:webp/1*lpjWA_D2PjHoj402-BYRzg.png"/></div></figure><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mo"><img src="../Images/b7846d3c04d37ef536eb2d543df483cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/1*VyaQd6_zGsmkQgyxaA_gbA.gif"/></div><figcaption class="la lb et er es lc ld bd b be z dx translated">来源:<a class="ae kw" href="https://www.gogglesandglasses.com/article4.html" rel="noopener ugc nofollow" target="_blank">护目镜和眼镜</a></figcaption></figure><p id="7f56" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">例如，如果你想将一个镜头的一个新的点<strong class="ih hj">投射到2D，选择输入3D <strong class="ih hj">围绕眼睛的世界坐标</strong>加上少量的Z坐标，因为镜头比眼睛更靠近摄像机。同样，在<strong class="ih hj">鼻垫</strong>中，选择鼻子的世界坐标位置。</strong></p><p id="d379" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">要应用过滤器，你需要定义一些3D点<strong class="ih hj">给你的物体，比如眼镜、帽子或胡子，相对于世界坐标空间的14个点，然后投影<strong class="ih hj">将这些3D点转换成2D </strong>点，考虑到脸部和头部的姿势。</strong></p><blockquote class="mp"><p id="e672" class="mq mr hi bd ms mt mu mv mw mx my jc dx translated"><strong class="ak">综上所述，展示滤镜的流程是:检测人脸- &gt;估计2D人脸标志- &gt;获取旋转矩阵和平移向量- &gt;投影3D项指向2D - &gt;可视化。它发生在摄像机捕捉到的每一帧。</strong></p></blockquote><h1 id="86a6" class="le jm hi bd jn lf lg lh jr li lj lk jv ll mz ln jy lo na lq kb lr nb lt ke lu bi translated">python / C++中的代码来实现它</h1><p id="fd7d" class="pw-post-body-paragraph if ig hi ih b ii ki ik il im kj io ip iq lv is it iu lw iw ix iy lx ja jb jc hb bi translated">如果你想应用这个概念，请参考<a class="ae kw" href="https://docs.opencv.org/2.4/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html" rel="noopener ugc nofollow" target="_blank"> OpenCV文档</a>中关于这个的讨论。</p><p id="2d10" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">得到一个<strong class="ih hj">旋转矩阵&amp;平移向量的函数:</strong> <br/> C++ : <code class="du nc nd ne nf b"><strong class="ih hj">projectPoints</strong></code> <br/> Python : <code class="du nc nd ne nf b">cv2.<strong class="ih hj">projectPoints</strong></code></p><p id="45b4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">项目3D项的函数指向2D:<br/></strong>c++:<code class="du nc nd ne nf b"><strong class="ih hj">projectPoints</strong></code><br/>Python:<code class="du nc nd ne nf b">cv2.<strong class="ih hj">projectPoints</strong></code></p><p id="392c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">两者都在OpenCV包里面！！</p><h1 id="47f8" class="le jm hi bd jn lf lg lh jr li lj lk jv ll lm ln jy lo lp lq kb lr ls lt ke lu bi translated"><strong class="ak">免责声明</strong></h1><p id="35ab" class="pw-post-body-paragraph if ig hi ih b ii ki ik il im kj io ip iq lv is it iu lw iw ix iy lx ja jb jc hb bi translated">我不是Snapchat / Instagram的工程师，我没有说他们使用这个概念，我不知道他们在里面做什么，我感觉他们比你在这篇文章中读到的更复杂。我想传达给你的主要信息是，你可以用这个概念来做这件事！</p><h2 id="51a4" class="jl jm hi bd jn jo jp jq jr js jt ju jv iq jw jx jy iu jz ka kb iy kc kd ke kf bi translated">感谢阅读！！！干杯😃 😀 😄</h2></div></div>    
</body>
</html>