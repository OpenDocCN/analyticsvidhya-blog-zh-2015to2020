<html>
<head>
<title>Breakdown of PyTorch’s CNN Tutorial</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">PyTorch的CNN教程分解</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/breakdown-of-pytorchs-cnn-tutorial-5347891cecb?source=collection_archive---------8-----------------------#2019-10-05">https://medium.com/analytics-vidhya/breakdown-of-pytorchs-cnn-tutorial-5347891cecb?source=collection_archive---------8-----------------------#2019-10-05</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><blockquote class="if ig ih"><p id="6593" class="ii ij ik il b im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg hb bi translated">这是一篇文章，我将写下我通过PyTorch 提供的<a class="ae jh" href="https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html" rel="noopener ugc nofollow" target="_blank">卷积神经网络(CNN)教程所学到的东西。</a></p></blockquote><figure class="jj jk jl jm fd jn er es paragraph-image"><div class="er es ji"><img src="../Images/d9277cdde7e69dffd5da1684a1148eeb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1372/format:webp/1*GnWB55x0KcwIQguMq8KRbQ.jpeg"/></div></figure><p id="f1d3" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jq iv iw ix jr iz ja jb js jd je jf jg hb bi translated">嘿大家好。我叫Sean，我现在是高丽大学计算机科学专业的硕士研究生。具体来说，我的研究重点是深度学习方法。</p><p id="2b98" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jq iv iw ix jr iz ja jb js jd je jf jg hb bi translated">我一直在尝试研究一些PyTorch，因为我需要快速熟悉它，以便为我参与的项目进行研究和实验，还有什么地方比从文档提供的官方教程开始更好呢？这是一个非常简短的模型，但是通过一行一行的学习，我学到了很多东西。</p><h1 id="3726" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">基本信息</h1><h2 id="a385" class="kr ju hi bd jv ks kt ku jz kv kw kx kd jq ky kz kh jr la lb kl js lc ld kp le bi translated">数据</h2><p id="a343" class="pw-post-body-paragraph ii ij hi il b im lf io ip iq lg is it jq lh iw ix jr li ja jb js lj je jf jg hb bi translated">本教程基本上引导我们使用CNN对<a class="ae jh" href="https://www.cs.toronto.edu/~kriz/cifar.html" rel="noopener ugc nofollow" target="_blank"> CIFAR-10 </a>图像样本进行分类。CIFAR-10数据集是一个由60，000个标记图像组成的数据集，共有10个类别。每个图像都是形状(高度=32，宽度=32，通道=3)，有50，000个训练图像和10，000个测试图像。</p><p id="9d79" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jq iv iw ix jr iz ja jb js jd je jf jg hb bi translated">数据集分为5个训练批次，每个批次有10，000个图像，以及一个测试批次。</p><h2 id="8b50" class="kr ju hi bd jv ks kt ku jz kv kw kx kd jq ky kz kh jr la lb kl js lc ld kp le bi translated">模型架构</h2><p id="cf7e" class="pw-post-body-paragraph ii ij hi il b im lf io ip iq lg is it jq lh iw ix jr li ja jb js lj je jf jg hb bi translated">整体模型架构如下:</p><figure class="jj jk jl jm fd jn er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es lk"><img src="../Images/698e68794ab04420d12269e6b90b4b5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mp2fkh6gGlKZEgHnAMN2MQ.png"/></div></div></figure><p id="2f43" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jq iv iw ix jr iz ja jb js jd je jf jg hb bi translated">循序渐进:</p><ol class=""><li id="cd64" class="lp lq hi il b im in iq ir jq lr jr ls js lt jg lu lv lw lx bi translated">我们接收输入图像。</li><li id="c2c8" class="lp lq hi il b im ly iq lz jq ma jr mb js mc jg lu lv lw lx bi translated">我们让图像通过一个卷积层，它的内核大小为(5，5)，有6个滤波器，步长为1。</li><li id="6686" class="lp lq hi il b im ly iq lz jq ma jr mb js mc jg lu lv lw lx bi translated">我们使用shape (2，2)和stride 2执行最大池化。</li><li id="8d5d" class="lp lq hi il b im ly iq lz jq ma jr mb js mc jg lu lv lw lx bi translated">我们执行另一个卷积，但这次使用16个滤波器。</li><li id="babf" class="lp lq hi il b im ly iq lz jq ma jr mb js mc jg lu lv lw lx bi translated">我们执行另一个最大池操作。</li><li id="b7a2" class="lp lq hi il b im ly iq lz jq ma jr mb js mc jg lu lv lw lx bi translated">将图像展平为形状(16 * 5 * 5 = 400)，并穿过第一个完全连接的图层。</li><li id="deef" class="lp lq hi il b im ly iq lz jq ma jr mb js mc jg lu lv lw lx bi translated">图像再次通过两个更多的后续完全连接的层。</li><li id="03c5" class="lp lq hi il b im ly iq lz jq ma jr mb js mc jg lu lv lw lx bi translated">对于每个图像类，最终输出的形状是(1，10)，我们执行分类。</li></ol><p id="1cac" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jq iv iw ix jr iz ja jb js jd je jf jg hb bi translated">好奇的话请看一下<a class="ae jh" href="http://alexlenail.me/NN-SVG/LeNet.html" rel="noopener ugc nofollow" target="_blank">我曾经画过网的网站</a>！</p><h1 id="d3ac" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">代码</h1><p id="f2ad" class="pw-post-body-paragraph ii ij hi il b im lf io ip iq lg is it jq lh iw ix jr li ja jb js lj je jf jg hb bi translated">整个代码如下:</p><figure class="jj jk jl jm fd jn"><div class="bz dy l di"><div class="md me l"/></div></figure><p id="59f2" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jq iv iw ix jr iz ja jb js jd je jf jg hb bi translated">现在，让我们把它一部分一部分地分解。</p><h2 id="abfe" class="kr ju hi bd jv ks kt ku jz kv kw kx kd jq ky kz kh jr la lb kl js lc ld kp le bi translated">步骤1:数据的基本配置。</h2><p id="3c70" class="pw-post-body-paragraph ii ij hi il b im lf io ip iq lg is it jq lh iw ix jr li ja jb js lj je jf jg hb bi translated">这一步相对简单。我们只是通过使用<code class="du mf mg mh mi b">torchvision</code>库的函数下载CIFAR-10数据集，然后对数据执行一些基本的预处理(例如归一化)。如果你对变量<code class="du mf mg mh mi b">trainloader</code>和<code class="du mf mg mh mi b">testloader</code>不熟悉的话，它们可能会让你感到困惑(它们让我感到困惑)，但它们只是我们用来加载数据的工具。如果您查看第5步中的第二个<code class="du mf mg mh mi b">for</code>循环，这一点会变得很清楚。</p><h2 id="2e6e" class="kr ju hi bd jv ks kt ku jz kv kw kx kd jq ky kz kh jr la lb kl js lc ld kp le bi translated">步骤2:可视化一些样本。</h2><p id="9d48" class="pw-post-body-paragraph ii ij hi il b im lf io ip iq lg is it jq lh iw ix jr li ja jb js lj je jf jg hb bi translated">我跳过这一步的原因是因为我使用的服务器由于某种原因不允许可视化。不过，这没什么大不了的，因为本教程的重要部分不是看数据是什么样子。</p><h2 id="c4b9" class="kr ju hi bd jv ks kt ku jz kv kw kx kd jq ky kz kh jr la lb kl js lc ld kp le bi translated">步骤3:定义要使用的CNN。</h2><p id="02a8" class="pw-post-body-paragraph ii ij hi il b im lf io ip iq lg is it jq lh iw ix jr li ja jb js lj je jf jg hb bi translated">如果你看一下<code class="du mf mg mh mi b">Net</code>类，你会注意到我们已经使用PyTorch的内置函数和方法基本上定义了我们将使用的CNN的构建块。<code class="du mf mg mh mi b">forward</code>函数基本上是执行实际计算的函数。</p><p id="569c" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jq iv iw ix jr iz ja jb js jd je jf jg hb bi translated">如果您对我们如何得出函数中定义的具体数字感到困惑，请记住:</p><figure class="jj jk jl jm fd jn er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es mj"><img src="../Images/1eacc1b78767978a062e0f8ec13db5ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:660/format:webp/1*V5ZIZg7cGHLASKbnRbKBJQ.png"/></div></div></figure><p id="b056" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jq iv iw ix jr iz ja jb js jd je jf jg hb bi translated">回想一下我们的数据的形状(从(32，32，3)开始)，我们的内核的形状(5x5)，我们不使用任何填充，我们使用跨距1(对于池层，我们使用跨距2)。还要记住，池层也是一个卷积层，因此上面的等式也适用于它们。</p><p id="98d5" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jq iv iw ix jr iz ja jb js jd je jf jg hb bi translated">总之，当我们通过网络传递数据时，数据的形状会发生如下变化:</p><ol class=""><li id="f028" class="lp lq hi il b im in iq ir jq lr jr ls js lt jg lu lv lw lx bi translated">(32，32，3):输入数据</li><li id="c48b" class="lp lq hi il b im ly iq lz jq ma jr mb js mc jg lu lv lw lx bi translated">(28，28，conv1之后的数据</li><li id="1669" class="lp lq hi il b im ly iq lz jq ma jr mb js mc jg lu lv lw lx bi translated">(14，14，6):池后的数据</li><li id="d79c" class="lp lq hi il b im ly iq lz jq ma jr mb js mc jg lu lv lw lx bi translated">(10，10，conv2之后的数据</li><li id="f44e" class="lp lq hi il b im ly iq lz jq ma jr mb js mc jg lu lv lw lx bi translated">(5，5，16):池后的数据</li></ol><p id="edc8" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jq iv iw ix jr iz ja jb js jd je jf jg hb bi translated">如果您感到困惑，这里有一个模型架构的示意图，以供参考:</p><figure class="jj jk jl jm fd jn er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es lk"><img src="../Images/698e68794ab04420d12269e6b90b4b5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mp2fkh6gGlKZEgHnAMN2MQ.png"/></div></div></figure><p id="91ee" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jq iv iw ix jr iz ja jb js jd je jf jg hb bi translated">现在，注意最后一层的形状是(5，5，16)并且在我们的<code class="du mf mg mh mi b">Net</code>类的<code class="du mf mg mh mi b">forward</code>函数中，我们用<code class="du mf mg mh mi b">x.view(-1, 16 * 5 * 5)</code>展平我们的数据。如果你不确定<code class="du mf mg mh mi b">-1</code>是做什么用的，它意味着推断特定的尺寸大小。<a class="ae jh" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html#numpy.reshape" rel="noopener ugc nofollow" target="_blank">查看</a> <code class="du mf mg mh mi b"><a class="ae jh" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html#numpy.reshape" rel="noopener ugc nofollow" target="_blank">numpy.reshape()</a></code>的文档以获得更详细的解释。</p><p id="0829" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jq iv iw ix jr iz ja jb js jd je jf jg hb bi translated">如果你不熟悉<code class="du mf mg mh mi b">view</code>函数，那么我强烈推荐查看<a class="ae jh" href="https://stackoverflow.com/questions/49643225/whats-the-difference-between-reshape-and-view-in-pytorch" rel="noopener ugc nofollow" target="_blank">这个堆栈溢出问题</a>。<code class="du mf mg mh mi b">view</code>与<code class="du mf mg mh mi b">reshape</code>相似，但在技术意义上略有不同。不过，从概念上认为它们是相同的会有所帮助。</p><h2 id="5be9" class="kr ju hi bd jv ks kt ku jz kv kw kx kd jq ky kz kh jr la lb kl js lc ld kp le bi translated">步骤4:定义优化程序和损失详细信息。</h2><p id="66d2" class="pw-post-body-paragraph ii ij hi il b im lf io ip iq lg is it jq lh iw ix jr li ja jb js lj je jf jg hb bi translated">这一步并不复杂。我们只是定义了将要使用的损失标准，以及将要使用的优化器。如你所见，我们将使用<a class="ae jh" href="https://en.wikipedia.org/wiki/Cross_entropy" rel="noopener ugc nofollow" target="_blank">交叉熵损失</a>和<a class="ae jh" href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#Momentum" rel="noopener ugc nofollow" target="_blank">带动量的随机梯度下降算法</a>。如果有您不熟悉的地方，请查看文档！</p><h2 id="9231" class="kr ju hi bd jv ks kt ku jz kv kw kx kd jq ky kz kh jr la lb kl js lc ld kp le bi translated">第五步:训练网络。</h2><p id="0f26" class="pw-post-body-paragraph ii ij hi il b im lf io ip iq lg is it jq lh iw ix jr li ja jb js lj je jf jg hb bi translated">这一步是我们实际训练网络的时候。对于每个时代，我们基本上是:</p><ol class=""><li id="e49c" class="lp lq hi il b im in iq ir jq lr jr ls js lt jg lu lv lw lx bi translated">提取输入数据和相应的标签<code class="du mf mg mh mi b">inputs, labels = data</code>。</li><li id="a3d5" class="lp lq hi il b im ly iq lz jq ma jr mb js mc jg lu lv lw lx bi translated">清除我们的优化器<code class="du mf mg mh mi b">optimizer.zero_grad()</code>中的梯度值。</li><li id="ac74" class="lp lq hi il b im ly iq lz jq ma jr mb js mc jg lu lv lw lx bi translated">用我们的模型<code class="du mf mg mh mi b">outputs = net(inputs)</code>计算输出分数。</li><li id="55f7" class="lp lq hi il b im ly iq lz jq ma jr mb js mc jg lu lv lw lx bi translated">计算我们的预测和实际标签之间的交叉熵损失<code class="du mf mg mh mi b">loss = criterion(outputs, labels)</code>。</li><li id="db40" class="lp lq hi il b im ly iq lz jq ma jr mb js mc jg lu lv lw lx bi translated">使用<code class="du mf mg mh mi b">loss.backward()</code>计算<code class="du mf mg mh mi b">require_grads=True</code>处每个参数的梯度。</li><li id="0ff0" class="lp lq hi il b im ly iq lz jq ma jr mb js mc jg lu lv lw lx bi translated">使用<code class="du mf mg mh mi b">optimizer.step()</code>用从<code class="du mf mg mh mi b">loss.backward()</code>计算的梯度更新我们的优化器。</li><li id="dbfe" class="lp lq hi il b im ly iq lz jq ma jr mb js mc jg lu lv lw lx bi translated">更新我们的<code class="du mf mg mh mi b">running_loss</code>。</li><li id="a06d" class="lp lq hi il b im ly iq lz jq ma jr mb js mc jg lu lv lw lx bi translated">如果适用，打印结果。</li></ol><p id="5c33" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jq iv iw ix jr iz ja jb js jd je jf jg hb bi translated">一旦运行了这段代码，您会注意到损失逐渐减少！</p><h1 id="cd4b" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">结论</h1><p id="4035" class="pw-post-body-paragraph ii ij hi il b im lf io ip iq lg is it jq lh iw ix jr li ja jb js lj je jf jg hb bi translated">本教程不会带你完成整个深度学习过程，但我相信它对学习PyTorch的工作方式很有帮助。但是，您应该记住的一件事是，当您对某一行代码感到困惑时，要养成查看文档的习惯。</p><p id="98a8" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jq iv iw ix jr iz ja jb js jd je jf jg hb bi translated">我学习的目标是确保我能把这些材料教给别人。这很费时间，但我真的觉得这是正确的道路。</p><p id="dc55" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jq iv iw ix jr iz ja jb js jd je jf jg hb bi translated">我希望这篇教程对找到它的人有所帮助。快乐学习！</p></div></div>    
</body>
</html>