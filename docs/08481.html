<html>
<head>
<title>Fisher Linear Discriminant Analysis(LDA)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">费希尔线性判别分析(LDA)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/fisher-linear-discriminant-analysis-lda-fe3554800e06?source=collection_archive---------8-----------------------#2020-07-31">https://medium.com/analytics-vidhya/fisher-linear-discriminant-analysis-lda-fe3554800e06?source=collection_archive---------8-----------------------#2020-07-31</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="806f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">LDA 的目的是降低数据的维数。</p><p id="d6b9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">为什么是 LDA 而不是 PCA？</strong></p><p id="a02a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">原因</strong>:主成分分析有助于找到方差最大的方向，我们将数据投射到这个方向上。</p><p id="0bb8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们来看一个数据集，它有两个类标签 y=1 和 y =-1，这两个类平行放置并且非常靠近，当它们被投影用于分类时，这会导致一种可怕的情况(两个标签混淆)。</p><p id="1600" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以我们可能会丢失有用的信息。为了保存尽可能多的类别歧视数据，我们实现了 LDA。</p><p id="fe3f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">好吧！让我们深入探讨一下这个概念…</p><p id="c41e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">LDA 的目标</strong>:</p><p id="1e84" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为投影寻找一个向量，这样类别之间将有最大的可分性。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jd"><img src="../Images/870520c0e6d5d693c6af8a95849a9c12.png" data-original-src="https://miro.medium.com/v2/resize:fit:674/format:webp/1*aPEwxtsDlu0mddMVi7P7cA.png"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">通过将样本投影到直线上，我们得到一个标量“y”</figcaption></figure><p id="0492" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">以上两个阶层并没有分开多少。所以我们找到了另一个给出最大间距的向量。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jp"><img src="../Images/45cb31182db59a61e1fc08d96e2aed99.png" data-original-src="https://miro.medium.com/v2/resize:fit:474/format:webp/1*H_jcKdfgsq6GurHQk_ytLw.png"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">通过将样本投影到直线上，我们得到一个标量“y”</figcaption></figure><p id="1eab" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，最佳投影向量可以通过最大化函数 J(w)来获得。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jq"><img src="../Images/b52b26b0a76826628dcb80e7b5a88f74.png" data-original-src="https://miro.medium.com/v2/resize:fit:634/format:webp/1*B_4HZh8Tpg1IZYwWbk5cpw.png"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">线性判别分析的目标函数</figcaption></figure><p id="9d44" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">J(w)是通过类内散布矩阵的度量标准化的类均值之间的差异的度量。</p><p id="a565" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">J(w)的分子测量投影平均值之间的距离，即 Between_ Class_Scatter_Matrix。</strong></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jr"><img src="../Images/bd2fd45806a6d2355dfdfbea94b4ccae.png" data-original-src="https://miro.medium.com/v2/resize:fit:568/format:webp/1*Jw0BsM2_imzvoiFES0_EXw.png"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">Mu1 和 Mu2 是样本类的平均值</figcaption></figure><p id="2974" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">J(w)的分母测量类内可变性的总和，即类内散布矩阵。</strong></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es js"><img src="../Images/897b92fef33a61d02bed731fb5c6dcbf.png" data-original-src="https://miro.medium.com/v2/resize:fit:288/format:webp/1*9nr5hMdQS3TCbv5ehBIYYQ.png"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">S1 和 S2 是样本类的协方差</figcaption></figure><p id="cbd1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将 J(w)求导到零以获得最大值，</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jt"><img src="../Images/d1126adcf30d88bfe7d21d7ee30a1259.png" data-original-src="https://miro.medium.com/v2/resize:fit:1278/format:webp/1*bwKHkNkqiAhokadaMVH4SQ.png"/></div></figure><p id="d4ed" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">求解上述方程得到以下特征值(λ)。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ju"><img src="../Images/41ed31f4e0283dfc9fb1b02d22f654e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1066/format:webp/1*TmbGI1niQOygr7zglLsDqA.png"/></div></figure><p id="cd73" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们计算特征向量(投影向量)的特征值。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jv"><img src="../Images/e8448438981146967b3f3e246eaf1b00.png" data-original-src="https://miro.medium.com/v2/resize:fit:954/format:webp/1*nMkr3XliYTiYVuw4oCeqBQ.png"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">给出投影向量方向的线性判别式</figcaption></figure><p id="dad5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">其他作品包括… </strong></p><div class="jw jx ez fb jy jz"><a rel="noopener follow" target="_blank" href="/analytics-vidhya/google-page-rank-and-markov-chains-d65717b98f9c"><div class="ka ab dw"><div class="kb ab kc cl cj kd"><h2 class="bd hj fi z dy ke ea eb kf ed ef hh bi translated">谷歌网页排名和马尔可夫链</h2><div class="kg l"><h3 class="bd b fi z dy ke ea eb kf ed ef dx translated">无论何时你在谷歌上查询，你都会得到基于网页排名的网页。页面排名…</h3></div><div class="kh l"><p class="bd b fp z dy ke ea eb kf ed ef dx translated">medium.com</p></div></div><div class="ki l"><div class="kj l kk kl km ki kn jj jz"/></div></div></a></div><div class="jw jx ez fb jy jz"><a rel="noopener follow" target="_blank" href="/@ravi_ernesto/confidence-interval-using-bootstrapping-mathematical-intuition-3f39969c4f72"><div class="ka ab dw"><div class="kb ab kc cl cj kd"><h2 class="bd hj fi z dy ke ea eb kf ed ef hh bi translated">使用自举(数学直觉)的置信区间</h2><div class="kg l"><h3 class="bd b fi z dy ke ea eb kf ed ef dx translated">计算均值、中值、方差和标准差的置信区间。自举是一种…</h3></div><div class="kh l"><p class="bd b fp z dy ke ea eb kf ed ef dx translated">medium.com</p></div></div><div class="ki l"><div class="ko l kk kl km ki kn jj jz"/></div></div></a></div></div></div>    
</body>
</html>