<html>
<head>
<title>Understanding Wide and Deep Learning-based Recommendation System</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">理解基于广泛和深度学习的推荐系统</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/understanding-wide-and-deep-learning-based-recommendation-system-1aacc61d3bfd?source=collection_archive---------12-----------------------#2019-12-31">https://medium.com/analytics-vidhya/understanding-wide-and-deep-learning-based-recommendation-system-1aacc61d3bfd?source=collection_archive---------12-----------------------#2019-12-31</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/b1ef897cb1e77a74bb8af5877c70eafd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fczbqHBKuYq9XL1QQVifJA.jpeg"/></div></div></figure><p id="ee18" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">推荐系统是向用户建议相关项目(视频、图像、文本、产品等)的算法。对于网飞、亚马逊Prime、Youtube、Google Play、Pinterest等应用来说，这可能是至关重要的竞争优势。这些应用程序有海量的项目集合，需要提供给每个用户。准确的推荐有助于改善用户体验。</p><p id="936a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">简介</strong></p><p id="66ac" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">宽而深的神经网络结合了最初在Google play中为应用推荐引入的概括和记忆的优点。具有非线性特征变换的广义线性模型广泛用于具有稀疏输入的大规模回归和分类问题。通过广泛的跨产品特征转换来记忆特征交互是有效的和可解释的，而泛化需要更多的特征工程工作。使用MLP进行要素表示非常简单高效。</p><figure class="jp jq jr js fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es jo"><img src="../Images/c58e6d3e1c4abda1de730c0a5d734999.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FKR1nrt6RxlYUcJnr5RBZg.png"/></div></div></figure><p id="a2ad" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">宽学习组件是单层感知器，其也可以被视为广义线性模型。深度学习组件是一个MLP。结合这两种学习技术使得推荐器能够捕获记忆和概括。</p><p id="d3da" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">单层感知器</strong></p><figure class="jp jq jr js fd ij er es paragraph-image"><div class="er es jt"><img src="../Images/5eca805eb922593bccec00785564d16e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*_4ZZpnZKB-VhEgVGBZ2I3w.png"/></div></figure><p id="8027" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">感知器由4部分组成。</strong></p><p id="be5e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">输入值或一个输入层:</strong>感知器的输入层由人工输入神经元组成，将初始数据带入系统进行进一步处理。</p><p id="da90" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">权重和偏差:</strong></p><p id="785c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">重量:</strong>代表单元之间连接的尺寸或强度。如果节点1到节点2的权重较大，则神经元1对神经元的影响较大。</p><p id="4acb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">偏差:</strong>与线性方程中加入的截距相同。这是一个附加参数，其任务是修改输出以及对另一个神经元的输入的加权和。</p><p id="042c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">净和:</strong>计算总和。</p><p id="8a8f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">激活函数:</strong>一个神经元能否被激活，是由一个激活函数决定的。激活函数计算加权和，并进一步加上偏差以给出结果。</p><p id="c707" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在第一步中，所有输入x与它们的权重<strong class="is hj"> w </strong>相乘。</p><figure class="jp jq jr js fd ij er es paragraph-image"><div class="er es ju"><img src="../Images/ec1d41a17311da3695013b5251d4f27e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*sjiizOnbnavFsGNew8NatA.png"/></div></figure><p id="439b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这一步中，将所有增加的值相加，称之为<strong class="is hj">加权和</strong>。</p><figure class="jp jq jr js fd ij er es paragraph-image"><div class="er es ju"><img src="../Images/917890d9b66b66a17759af953f747e33.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*TqCYS5XGjhOPfYCjQvKgKg.png"/></div></figure><p id="ffcb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">最后一步，将加权和应用于正确的<strong class="is hj">激活函数</strong>。</p><figure class="jp jq jr js fd ij er es paragraph-image"><div class="er es jv"><img src="../Images/9809f1e4d477255bf5182d64bdbc1414.png" data-original-src="https://miro.medium.com/v2/resize:fit:940/format:webp/1*TyxUB857b_rNTvhtAnFB3A.png"/></div></figure><p id="4bff" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">多层感知器</strong></p><figure class="jp jq jr js fd ij er es paragraph-image"><div class="er es jw"><img src="../Images/bde2f639ffb091e7706f1e79e5b21d31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1184/format:webp/1*TLK8oWzGhI8V8T0LZcFGgg.png"/></div></figure><p id="f048" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">多层感知器(MLP)是一种前馈人工神经网络，它从一组输入生成一组输出。MLP的特征在于若干层输入节点，这些输入节点在输入层和输出层之间以有向图的形式连接。MLP使用反向传播来训练网络。</p><p id="5d90" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">反向传播</strong></p><p id="95b4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">反向传播是神经网络训练的本质。这是一种基于前一个时期(即迭代)获得的错误率微调神经网络权重的方法。通过适当调整权重，您可以降低错误率，并通过提高模型的泛化能力来提高模型的可靠性。</p><p id="8388" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">反向传播是“误差反向传播”的简称这是训练人工神经网络的标准方法。这种方法有助于计算损失函数相对于网络中所有权重的梯度。</p><figure class="jp jq jr js fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es jx"><img src="../Images/9928acff7c08b35defe8fbb4a8eee7f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eV88CnsfmEeDZ-igssNF8g.png"/></div></div></figure><p id="8f6c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">1.输入X通过预连接的路径到达</p><p id="18c3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">2.使用真实权重w对输入进行建模。权重通常是随机选择的。</p><p id="f15c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">3.计算每个神经元从输入层到隐藏层再到输出层的输出。</p><p id="e4a2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">4.计算输出中的误差</p><p id="a5a3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">5.从输出层返回到隐藏层以调整权重，从而减少误差。</p><p id="195b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">误差B=实际输出—期望输出</p><p id="8540" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">不断重复该过程，直到获得所需的输出</p><p id="f280" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">广而深的学习模式</strong></p><p id="a5fb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">通过将两种模型融合在一起，实现了宽深度学习模型</p><figure class="jp jq jr js fd ij er es paragraph-image"><div class="er es jy"><img src="../Images/9a583d15c2fccab8118df158367980eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:910/format:webp/1*OJIqpEjlxD1ck6JOhZWAbg.png"/></div></figure></div></div>    
</body>
</html>