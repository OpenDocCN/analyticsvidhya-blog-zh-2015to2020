<html>
<head>
<title>Assumptions which makes Artificial Neural Network Simple</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使人工神经网络简单的假设</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/assumptions-which-makes-artificial-neural-network-simple-81ba7f46abbc?source=collection_archive---------4-----------------------#2020-04-10">https://medium.com/analytics-vidhya/assumptions-which-makes-artificial-neural-network-simple-81ba7f46abbc?source=collection_archive---------4-----------------------#2020-04-10</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="5a8d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了使神经网络更简单，我们对信息从一层到另一层的流动做了某些假设。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/28f2cc02ac6f353996741b92e2d479cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*oM2utI-WP96ieTZt"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">由<a class="ae ju" href="https://unsplash.com/@magict1911?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">提莫·沃尔茨</a>在<a class="ae ju" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="b73f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">人工神经网络(ANN)架构基于动物大脑的类比，这意味着ANN试图模仿大脑的功能。</p><p id="3e90" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">但是你认为这是一个简单的任务吗？</p><p id="4949" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们知道机器的计算能力随着时间的推移已经有了巨大的增长，但是我们仍然能够像动物大脑那样做所有的操作/功能吗？当然，我们不是。我们离这一点还很远。</p><p id="11d4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们在提高机器的计算能力和存储能力方面取得了巨大的成功。我们将来肯定会到达一个点，在那里我们可能不需要遵循这些假设。在那之前，让我们看看这些假设是什么。</p><p id="7a40" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 01。人工神经元分层排列，依次排列。</strong></p><p id="ba9c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在人工神经网络中，我们有输入层、人工神经元层(隐藏层)和输出层。与动物大脑相比，这种假设可能不成立，因为在动物大脑中，神经元不是按顺序排列的。它们在自然界中是随机连接的，而在人工神经网络中是按顺序排列的。</p><p id="e6ac" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">正如你在下图中看到的，有2个隐藏层的神经网络按顺序排列。</em></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es jv"><img src="../Images/737b54f84b18c149f2218e670aa12d9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*38zk9AqjTqDqzTPm.png"/></div></div></figure><p id="f028" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 02。同一层内的神经元不会相互作用或相互通信。</strong></p><p id="033a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">在上图中，有两个隐藏层神经网络，输入层将信息传递给第一个隐藏层网络，然后将输出传递给第二个隐藏层网络。由第二网络层生成的输出Y。来自层1的神经元是h1、h2、h3，但是h2和h3彼此不相互作用，这在大脑的类比中也是不真实的。如果我们看图像的左侧，隐层网络的神经元都是相连的。</em></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es jw"><img src="../Images/7a50d705d6b6e9f19dbc53fe52f3c9c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GdXxY44XY7lky99K7eAMLw.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">来自同一层的神经元不相互作用</figcaption></figure><p id="45cf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 03。所有输入都通过输入层进入网络，然后通过输出层。</strong></p><p id="65e1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">神经网络的输入只能通过输入层提供。你不能向神经网络的隐藏层添加任何信息。所有信息都从输入层传递到隐藏层激活函数，然后该函数将对该信息执行操作。</em></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es jx"><img src="../Images/137e8b32fef83e538bb74a84b2d13998.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*fqabNuyRgavs1Yfa.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">来源:维基百科</figcaption></figure><p id="1590" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">04年。同一级别的所有隐藏层应具有相同的激活功能。</p><p id="193c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">存在于神经网络中相同级别的隐藏层应该具有相同的激活函数。如果我们在同一水平的不同神经元上有不同的激活函数，这将需要大量的计算能力，并且求解起来将变得非常复杂。在下面的例子中，左侧的隐藏层对每个神经元f1，f2 …f5有不同的激活函数。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es jw"><img src="../Images/b8e5bdf2539b9d21c35ca608c47c0c7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X0bDouBw3CIF02qzp7EWmA.png"/></div></div></figure><p id="699c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 05。连续层上人工神经元紧密相连。</strong></p><p id="cb33" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">这也是神经网络中的一个重要假设，所有的网络都是密集连接的。这意味着所有输入值将被传递到下一个神经元，并且它们的输出将被传递到网络层中的下一个神经元。</em></p><p id="ae5a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">在下图中，你可以清楚地看到左侧图像不是密集连接的。因为隐藏层神经元1没有连接到输出，并且有另一个神经元没有连接到下一层神经元。</em></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es jw"><img src="../Images/b1de25f27203e3d21ac7b5f6603c33a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NVZUz01T9VDNwTrRQHbcXw.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">密集连接的神经元</figcaption></figure><p id="7642" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 6。每个相互连接的神经网络都有自己的权重和与之相关的偏差。</strong></p><p id="950d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">将所有输入层信息传递给隐含层1的所有神经元，隐含层1对所有神经元具有相同的激活函数。这里，输入层和隐藏层之间的互连具有每个输入的权重和隐藏层的偏差。每一层都遵循这一点。</em></p><p id="5d8f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">像对于隐藏层2输出一样，隐藏层1将隐藏层2的权重和偏置输入到隐藏层2，如下例</em></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es jx"><img src="../Images/137e8b32fef83e538bb74a84b2d13998.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*fqabNuyRgavs1Yfa.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">来源:维基百科</figcaption></figure><p id="fdfa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">快乐阅读！！</p></div></div>    
</body>
</html>