<html>
<head>
<title>Paper Explanation: Going deeper with Convolutions (GoogLeNet)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">论文解释:用卷积更深入(谷歌网)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/paper-explanation-going-deeper-with-convolutions-googlenet-the-ai-blog-b79574ac8fe0?source=collection_archive---------10-----------------------#2020-06-05">https://medium.com/analytics-vidhya/paper-explanation-going-deeper-with-convolutions-googlenet-the-ai-blog-b79574ac8fe0?source=collection_archive---------10-----------------------#2020-06-05</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="c845" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Google提出了一个名为inception的深度卷积神经网络，在ILSVRC 2014中取得了分类和检测的顶级结果。</p><blockquote class="jd je jf"><p id="c460" class="if ig jg ih b ii ij ik il im in io ip jh ir is it ji iv iw ix jj iz ja jb jc hb bi translated"><em class="hi">ImageNet大规模视觉识别挑战赛(ILSVRC)评估大规模对象检测和图像分类算法。一个高层次的动机是允许研究人员在更广泛的对象上比较检测的进展——利用相当昂贵的标记工作。另一个动机是测量用于检索和注释的大规模图像索引的计算机视觉的进展</em></p><p id="2d73" class="if ig jg ih b ii ij ik il im in io ip jh ir is it ji iv iw ix jj iz ja jb jc hb bi translated"><a class="ae jk" href="http://www.image-net.org/challenges/LSVRC/" rel="noopener ugc nofollow" target="_blank">T3【http://www.image-net.org/challenges/LSVRC/】T5</a></p></blockquote><p id="d41a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">“用回旋更深入”实际上是受一个互联网迷因的启发:“我们需要更深入”</p><figure class="jm jn jo jp fd jq er es paragraph-image"><div class="er es jl"><img src="../Images/dc48071bbd3c93af8e4c84f63b36c509.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*W8LNnUr9FZLH7ghg.jpg"/></div></figure><p id="70db" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在ILSVRC 2014中，GoogLeNet使用的参数比两年前在2012年比赛中使用的<a class="ae jk" href="https://prabinnepal.com/alexnet-architecture-explained/" rel="noopener ugc nofollow" target="_blank"> AlexNet </a>少了12倍。</p><h1 id="aec2" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">盗梦空间v1试图解决的问题</h1><p id="99aa" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">图像中的重要部分在大小上可以有很大的变化。例如，对象图像可以在不同的位置，一些图片被放大，而另一些被缩小。由于图像中的这种变化，为执行卷积运算选择正确的核大小变得非常困难。我们需要一个较大的核来提取图像中分布较多的对象的信息，而较小的核更适合于提取图像中分布较少的信息。</p><p id="fe2f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">提高神经网络性能的主要途径之一是增加其规模。这包括增加其深度和尺寸。神经网络的规模越大，对应的参数数量就越多，这使得网络更容易过拟合，尤其是在有标签的训练样本有限的情况下。</p><p id="bd13" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">网络规模增大的另一个缺点是计算资源的使用增加。如果更多的卷积层被链接，则导致计算资源的更多消耗。如果这些增加的容量没有得到有效利用，那么计算资源就会被浪费。</p><h1 id="f4d7" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">解决办法</h1><p id="b0c2" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">为了解决这些问题，本文提出的解决方案是形成一个“更宽”而不是“更深”的网络，即所谓的“初始模块”。</p><figure class="jm jn jo jp fd jq er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es kw"><img src="../Images/d1ea4a53556269186b2bfe98d569f0a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*msCbt322mX9TJA8N.png"/></div></div><figcaption class="lb lc et er es ld le bd b be z dx translated"><em class="lf">天真的初始模块</em></figcaption></figure><p id="a06a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">“原始”初始模块对来自前一层的输入执行卷积，具有3种不同大小的内核或滤波器，具体为1×1、3×3和5×5。除此之外，还执行最大池。输出然后被连接并发送到下一个初始模块。</p><p id="52c1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">“天真”方法的一个问题是，即使具有5×5卷积也可能导致在计算方面需要大量资源。一旦增加了合用，这个问题就更加突出了。</p><p id="e767" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了使我们的网络在计算上便宜，作者通过在3×3和5×5卷积之前添加1×1卷积来应用降维。让我们看看这些如何影响神经网络中的参数数量。</p><p id="80b9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们看看5×5卷积的计算量是多少</p><figure class="jm jn jo jp fd jq er es paragraph-image"><div class="er es jl"><img src="../Images/170d6edd274683c2bb45a9c55c629b22.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*zj9mU2xHnnYAN8kB.png"/></div><figcaption class="lb lc et er es ld le bd b be z dx translated"><em class="lf"> 5 × 5卷积，天真方式</em></figcaption></figure><p id="9f49" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上述卷积运算的计算是:</p><p id="92b3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> (⁵ )(192)(32)(2⁸ ) = 120，422，400 </strong>次运营</p><p id="b493" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了减少如此大量的运算，可以使用降维。这里，在用更大的滤波器执行卷积之前，先用1×1滤波器进行卷积。</p><p id="64fd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">降维后，5×5卷积的运算次数变为:</p><figure class="jm jn jo jp fd jq er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es jl"><img src="../Images/d61e3540788874000bd56192e517283a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*e8P1In1cIa5zd3yV.png"/></div></div><figcaption class="lb lc et er es ld le bd b be z dx translated"><em class="lf"> 5×5卷积降维</em></figcaption></figure><p id="49e6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上述卷积的运算次数变为</p><p id="06c0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">()(192)(16)(2⁸)= 2408448次</strong>运算，用于<strong class="ih hj"> 1 × 1 </strong>卷积，</p><p id="d3be" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> (⁵ )(16)(32)(2⁸ ) = 10，035，200次</strong>运算，用于<strong class="ih hj"> 5 × 5 </strong>卷积。</p><p id="4e51" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">总共将有<strong class="ih hj">2408448+10035200 = 12443648</strong>个操作。计算量大大减少。</p><p id="1286" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，在应用降维之后，我们的初始模块变成了:</p><figure class="jm jn jo jp fd jq er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es lg"><img src="../Images/7002d6b9929a22c2c495caafde4a304a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*5W8i6SWSqUVacbFA.png"/></div></div><figcaption class="lb lc et er es ld le bd b be z dx translated"><em class="lf">降维的初始模块。(来源:</em> <a class="ae jk" href="https://arxiv.org/pdf/1409.4842v1.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="lf">盗梦空间v1 </em> </a> <em class="lf"> ) </em></figcaption></figure><p id="9fd9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">GoogLeNet是使用降维的初始模块构建的。GoogLeNet由22层深度网络组成(包括27层池层)。所有的卷积，包括初始模块中的卷积，都使用整流线性激活。</p><figure class="jm jn jo jp fd jq er es paragraph-image"><div class="er es jl"><img src="../Images/c400fad3cb74cfed3a2f8e6a535e721d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Tt7kChwQq2XkcN2q.png"/></div><figcaption class="lb lc et er es ld le bd b be z dx translated">GoogLeNet是盗梦空间架构的化身。来源:原始论文</figcaption></figure><blockquote class="lh"><p id="c6e2" class="li lj hi bd lk ll lm ln lo lp lq jc dx translated">所有的卷积，包括初始模块中的卷积，都使用整流线性激活。在我们的网络中，感受野的大小为224×224，采用RGB颜色通道，具有平均子牵引。“#3x3reduce”和“#5x5reduce”代表在3×3和5×5卷积之前使用的缩减层中1×1滤波器的数量。在pool proj列中的内置max-pooling之后，可以看到投影层中1×1滤镜的数量。所有这些缩小/投影层也使用整流线性激活</p><p id="d458" class="li lj hi bd lk ll lr ls lt lu lv jc dx translated"><em class="lf">原文</em></p></blockquote><p id="4c01" class="pw-post-body-paragraph if ig hi ih b ii lw ik il im lx io ip iq ly is it iu lz iw ix iy ma ja jb jc hb bi translated">GoogLeNet是一个22层的深度，只计算带参数的层。对于这样深的网络，可能会出现诸如消失梯度的问题。为了消除这一点，作者引入了连接到中间层的辅助分类器，并帮助梯度信号传播回来。这些辅助分类器被添加到初始(4a)和(4d)模块的输出之上。来自辅助分类器的损失在训练期间被添加，而在推理期间被丢弃。</p><p id="5633" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">包括辅助分类器的侧边额外网络的确切结构如下:</p><ul class=""><li id="a1af" class="mb mc hi ih b ii ij im in iq md iu me iy mf jc mg mh mi mj bi translated">具有5×5过滤器大小和跨距3的平均池层，导致(4a)的4×4 512输出和(4d)阶段的4×4 528输出。</li><li id="74b8" class="mb mc hi ih b ii mk im ml iq mm iu mn iy mo jc mg mh mi mj bi translated">具有128个滤波器的1×1卷积，用于降维和校正线性激活。</li><li id="b09d" class="mb mc hi ih b ii mk im ml iq mm iu mn iy mo jc mg mh mi mj bi translated">具有1024个单元和整流线性激活的全连接层。</li><li id="caa1" class="mb mc hi ih b ii mk im ml iq mm iu mn iy mo jc mg mh mi mj bi translated">输出丢失率为70%的丢失层</li><li id="94fd" class="mb mc hi ih b ii mk im ml iq mm iu mn iy mo jc mg mh mi mj bi translated">以softmax loss作为分类器的线性图层(预测与主分类器相同的1000个类，但在推理时被移除)。</li></ul><p id="c279" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">GoogLeNet架构的系统视图如下所示:</p><figure class="jm jn jo jp fd jq er es paragraph-image"><div class="er es mp"><img src="../Images/4aec3f73eb901327d2c1f87291f2bcc2.png" data-original-src="https://miro.medium.com/v2/resize:fit:458/format:webp/0*J_gng-9EtZ-Cg5pN.png"/></div><figcaption class="lb lc et er es ld le bd b be z dx translated"><em class="lf">谷歌网络架构</em></figcaption></figure><p id="8803" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">GoogLeNet总共包括9个初始模块，即3a、3b、4a、4b、4c、4d、4e、5a和5b。</p><h1 id="911a" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">GoogLeNet实施</h1><p id="7113" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">了解了inception模块及其在GoogLeNet架构中的包含，我们现在在<a class="ae jk" href="http://tensorflow.org" rel="noopener ugc nofollow" target="_blank"> tensorflow </a>中实现GoogLeNet。GoogLeNet的实现灵感来自inception net上的analytics vidya <a class="ae jk" href="https://www.analyticsvidhya.com/blog/2018/10/understanding-inception-network-from-scratch/#:~:text=The%20paper%20proposes%20a%20new,which%20is%2027%20layers%20deep.&amp;text=1%C3%971%20Convolutional%20layer%20before%20applying%20another%20layer%2C%20which,mainly%20used%20for%20dimensionality%20reduction" rel="noopener ugc nofollow" target="_blank">文章</a>。</p><p id="bc7c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">导入所需的库:</p><pre class="jm jn jo jp fd mq mr ms mt aw mu bi"><span id="521e" class="mv ju hi mr b fi mw mx l my mz">from tensorflow.keras.layers import Layer<br/>import tensorflow.keras.backend as K<br/>import tensorflow as tf<br/>from tensorflow.keras.datasets import cifar10<br/>from tensorflow.keras.models import Model<br/>from tensorflow.keras.layers import Conv2D, MaxPool2D, Dropout, Dense, Input, concatenate, GlobalAveragePooling2D, AveragePooling2D, Flatten<br/>import cv2<br/>import numpy as np<br/>from keras.utils import np_utils<br/>import math<br/>from tensorflow.keras.optimizers import SGD<br/>from tensorflow.keras.callbacks import LearningRateScheduler</span></pre><p id="c3c5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">接下来，我们将使用cifar10数据集作为我们的数据。</p><pre class="jm jn jo jp fd mq mr ms mt aw mu bi"><span id="a30f" class="mv ju hi mr b fi mw mx l my mz">num_classes <strong class="mr hj">=</strong> <!-- -->10</span><span id="27a4" class="mv ju hi mr b fi na mx l my mz"><strong class="mr hj">def</strong> <!-- -->load_cifar_data(img_rows, img_cols):</span><span id="f12d" class="mv ju hi mr b fi na mx l my mz">    #Loading training and validation datasets</span><span id="2be9" class="mv ju hi mr b fi na mx l my mz">    (X_train, Y_train), (X_valid, Y_valid) <strong class="mr hj">=</strong> <!-- -->cifar10.load_data()</span><span id="4c10" class="mv ju hi mr b fi na mx l my mz">    #Resizing images</span><span id="a4b4" class="mv ju hi mr b fi na mx l my mz">    X_train <strong class="mr hj">=</strong> <!-- -->np.array([cv2.resize(img, (img_rows, img_cols)) <strong class="mr hj">for</strong>       <!-- -->img <strong class="mr hj">in</strong> <!-- -->X_train[:,:,:,:]])</span><span id="3e82" class="mv ju hi mr b fi na mx l my mz">    X_valid <strong class="mr hj">=</strong> <!-- -->np.array([cv2.resize(img, (img_rows, img_cols)) <strong class="mr hj">for</strong> <!-- -->img <strong class="mr hj">in</strong> <!-- -->X_valid[:,:,:,:]])</span><span id="c5c3" class="mv ju hi mr b fi na mx l my mz">    #Transform targets to keras compatible format</span><span id="d74a" class="mv ju hi mr b fi na mx l my mz">    Y_train <strong class="mr hj">=</strong> <!-- -->np_utils.to_categorical(Y_train, num_classes)</span><span id="f8af" class="mv ju hi mr b fi na mx l my mz">    Y_valid <strong class="mr hj">=</strong> <!-- -->np_utils.to_categorical(Y_valid, num_classes)</span><span id="2fbc" class="mv ju hi mr b fi na mx l my mz">    X_train <strong class="mr hj">=</strong> <!-- -->X_train.astype('float32')</span><span id="42c9" class="mv ju hi mr b fi na mx l my mz">    X_valid <strong class="mr hj">=</strong> <!-- -->X_valid.astype('float32')</span><span id="9979" class="mv ju hi mr b fi na mx l my mz">    #Preprocessing data</span><span id="283b" class="mv ju hi mr b fi na mx l my mz">    X_train <strong class="mr hj">=</strong> <!-- -->X_train <strong class="mr hj">/</strong> <!-- -->255.0</span><span id="4786" class="mv ju hi mr b fi na mx l my mz">    Y_train <strong class="mr hj">=</strong> <!-- -->X_valid <strong class="mr hj">/</strong> <!-- -->255.0</span><span id="e4cf" class="mv ju hi mr b fi na mx l my mz"><strong class="mr hj">return</strong> <!-- -->X_train, Y_train, X_valid, Y_valid</span><span id="177e" class="mv ju hi mr b fi na mx l my mz">X_train, Y_trian, X_test, y_test = load_cifar_data(224,224)</span></pre><p id="32c8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">接下来是我们的初始模块</p><p id="dad2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">初始模块在3×3和5×5卷积运算之前包含1×1卷积。不同的卷积运算需要不同数量的滤波器，并将这些运算连接到下一层。</p><pre class="jm jn jo jp fd mq mr ms mt aw mu bi"><span id="c1c3" class="mv ju hi mr b fi mw mx l my mz">def inception_module(x, filters_1x1, filters_3x3_reduce, filters_3x3, filters_5x5_reduce, filters_5x5, filters_pool_proj, name=None):<br/>    <br/>    conv_1x1 = Conv2D(filters_1x1, (1,1), activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(x)</span><span id="37af" class="mv ju hi mr b fi na mx l my mz">    conv_3x3 = Conv2D(filters_3x3_reduce, (1,1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(x)<!-- -->  </span><span id="40c9" class="mv ju hi mr b fi na mx l my mz">    conv_3x3 = Conv2D(filters_3x3, (3,3), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(conv_3x3)</span><span id="4e28" class="mv ju hi mr b fi na mx l my mz">    conv_5x5 = Conv2D(filters_5x5_reduce, (1,1), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(x)</span><span id="7dd6" class="mv ju hi mr b fi na mx l my mz">    conv_5x5 = Conv2D(filters_5x5, (3,3), padding='same', activation='relu', kernel_initializer=kernel_init, bias_initializer=bias_init)(conv_5x5)</span><span id="0f63" class="mv ju hi mr b fi na mx l my mz">    pool_proj = MaxPool2D((3,3), strides=(1,1), padding='same')(x)</span><span id="fbe0" class="mv ju hi mr b fi na mx l my mz">    pool_proj = Conv2D(filters_pool_proj, (1, 1), padding='same',  activation='relu', kernel_initializer=kernel_init,  bias_initializer=bias_init)(pool_proj)</span><span id="ee9f" class="mv ju hi mr b fi na mx l my mz">    output = concatenate([conv_1x1, conv_3x3, conv_5x5, pool_proj], axis=3, name=name)</span><span id="c9a9" class="mv ju hi mr b fi na mx l my mz">return output</span></pre><p id="d54e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">获取模型的摘要</p><pre class="jm jn jo jp fd mq mr ms mt aw mu bi"><span id="a9a0" class="mv ju hi mr b fi mw mx l my mz">model.summary()</span><span id="8335" class="mv ju hi mr b fi na mx l my mz">epochs = 25 <br/>initial_lrate = 0.01 <br/>def decay(epoch, steps=100): <br/>    initial_lrate = 0.01 <br/>    drop = 0.96 <br/>    epochs_drop = 8 <br/>    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop)) <br/>return lrate sgd = SGD(lr=initial_lrate, momentum=0.9, nesterov=False) <br/>lr_sc = LearningRateScheduler(decay, verbose=1) <br/>model.compile(loss=['categorical_crossentropy', 'categorical_crossentropy', 'categorical_crossentropy'], loss_weights=[1, 0.3, 0.3], optimizer=sgd, metrics=['accuracy'])</span></pre><p id="6c4b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用我们的模型来拟合训练数据</p><pre class="jm jn jo jp fd mq mr ms mt aw mu bi"><span id="5726" class="mv ju hi mr b fi mw mx l my mz">history = model.fit(X_train, [y_train, y_train, y_train], validation_data=(X_test, [y_test, y_test, y_test]), epochs=epochs, batch_size=256, callbacks=[lr_sc])</span></pre><p id="f107" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">参考文献</strong></p><ul class=""><li id="3845" class="mb mc hi ih b ii ij im in iq md iu me iy mf jc mg mh mi mj bi translated"><a class="ae jk" href="https://www.analyticsvidhya.com/blog/2018/10/understanding-inception-network-from-scratch/" rel="noopener ugc nofollow" target="_blank">https://www . analyticsvidhya . com/blog/2018/10/understanding-inception-network-from-scratch/</a></li><li id="1f3e" class="mb mc hi ih b ii mk im ml iq mm iu mn iy mo jc mg mh mi mj bi translated"><a class="ae jk" href="https://arxiv.org/abs/1409.4842" rel="noopener ugc nofollow" target="_blank">用回旋加深</a></li><li id="2b1a" class="mb mc hi ih b ii mk im ml iq mm iu mn iy mo jc mg mh mi mj bi translated"><a class="ae jk" href="https://towardsdatascience.com/a-simple-guide-to-the-versions-of-the-inception-network-7fc52b863202" rel="noopener" target="_blank">https://towards data science . com/a-simple-guide-the-versions-of-the-inception-network-7fc 52 b 863202</a></li></ul><p id="1474" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jg">原载于2020年6月5日https://prabinnepal.com</em><a class="ae jk" href="https://prabinnepal.com/paper-explanation-going-deeper-with-convolutions-googlenet/" rel="noopener ugc nofollow" target="_blank"><em class="jg"/></a><em class="jg">。</em></p></div></div>    
</body>
</html>