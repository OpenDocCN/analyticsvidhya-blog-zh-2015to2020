<html>
<head>
<title>Polynomial Regression — The “curves” of a linear model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">多项式回归——线性模型的“曲线”</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/polynomial-regression-the-curves-of-a-linear-model-bef70876c998?source=collection_archive---------8-----------------------#2020-09-14">https://medium.com/analytics-vidhya/polynomial-regression-the-curves-of-a-linear-model-bef70876c998?source=collection_archive---------8-----------------------#2020-09-14</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/ad038b69aa5a53e8057ab05a1b4ea3ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:926/format:webp/1*8C39nYB1NGDxJ5eWk5lHAw.jpeg"/></div><figcaption class="im in et er es io ip bd b be z dx translated">被忽视的真相</figcaption></figure><p id="c5aa" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">正如许多人会同意的那样，数据分析项目/报告最迷人的部分是机器学习算法使用数据施展魔法的部分。然而，这个过程中最容易被忽视的部分是数据的预处理。</p><p id="54a2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">更重要的工作是准备数据以拟合模型，而不是调整模型以更好地拟合数据。我们想要解决的一个预处理技术是<strong class="is hj">多项式回归</strong>。</p></div><div class="ab cl jo jp gp jq" role="separator"><span class="jr bw bk js jt ju"/><span class="jr bw bk js jt ju"/><span class="jr bw bk js jt"/></div><div class="hb hc hd he hf"><h1 id="7b90" class="jv jw hi bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated"><strong class="ak">更深的潜水</strong></h1><p id="6cee" class="pw-post-body-paragraph iq ir hi is b it kt iv iw ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm jn hb bi translated">多项式回归的主要假设是特征(自变量)和目标(因变量)之间可能存在非线性关系。当线性模型不能捕捉数据中的趋势并且给出较差的R值时，也使用它。在这种情况下，多项式回归通过使用现有要素的更高功效和组合来添加“新”要素，从而增加了模型的复杂性。</p><p id="e9b6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">多项式回归揭示了特征和目标之间的相互作用以及特征之间的相互作用，如果有的话。使用多项式回归可以使线性模型(如线性回归和逻辑回归)变得更加强大和复杂。</p><p id="dd5d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">多项式回归的一个缺点是，它需要对其参数进行大量实验，因为没有与之相关的硬性规则。</p></div><div class="ab cl jo jp gp jq" role="separator"><span class="jr bw bk js jt ju"/><span class="jr bw bk js jt ju"/><span class="jr bw bk js jt"/></div><div class="hb hc hd he hf"><h1 id="096c" class="jv jw hi bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated"><strong class="ak">可视化多项式回归</strong></h1><p id="380d" class="pw-post-body-paragraph iq ir hi is b it kt iv iw ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm jn hb bi translated">先从正态分布在三次曲线y = 3x -2x +x周围的一些数据点说起。</p><figure class="kz la lb lc fd ij er es paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="er es ky"><img src="../Images/5e285c91b3ab70ad77320c318866484d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XduVyYJgmBg_hkjGZRVeFg.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">准备数据以拟合启用了多项式要素的线性模型</figcaption></figure><p id="32bb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">乍看之下，简单的线性模型显然会遗漏数据中复杂的立方趋势，从而导致模型欠拟合。因此，接下来需要做一些调整。</p><p id="1fd7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">使用sklearn.preprocessing中的<em class="lh">多项式特性</em>类可以填补简单线性模型和数据中复杂趋势之间的空白。</p><p id="d260" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">考虑一个特征矩阵X，包含三个特征X1，X2，X3。创建新的二次多项式特征向我们展示了这些新特征:</p><blockquote class="li"><p id="fe09" class="lj lk hi bd ll lm ln lo lp lq lr jn dx translated"><strong class="ak"> 1、X1、X2、X3、X1*X2、X1*X3、X2*X3 </strong></p></blockquote><p id="35ca" class="pw-post-body-paragraph iq ir hi is b it ls iv iw ix lt iz ja jb lu jd je jf lv jh ji jj lw jl jm jn hb bi translated">这些特征然后与原始特征一起用于预测，并且我们的线性模型相应地评估这些新特征的系数。</p><p id="e8b9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">sklearn <em class="lh">多项式特性</em>有<strong class="is hj">三个</strong>参数:</p><ul class=""><li id="0901" class="lx ly hi is b it iu ix iy jb lz jf ma jj mb jn mc md me mf bi translated"><strong class="is hj">次数:</strong>决定新多项式特征的最高次幂</li><li id="9581" class="lx ly hi is b it mg ix mh jb mi jf mj jj mk jn mc md me mf bi translated"><strong class="is hj"> include_bias: </strong>设置为True时，将在多项式特征集中包含一个常数项。默认为真。</li><li id="0e63" class="lx ly hi is b it mg ix mh jb mi jf mj jj mk jn mc md me mf bi translated"><strong class="is hj"> interaction_only: </strong>设置为True时，将只包括特性的交互项，而不包括单个特性的更高次幂。默认情况下，它为False。</li></ul><p id="e063" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">将我们目前所学应用于上述合成数据集:</p><figure class="kz la lb lc fd ij er es paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="er es ml"><img src="../Images/19cd74d997440aa7c8991248321bcb74.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*59kxZV2_34-iro8EpVfGVQ.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">我们引入了3次多项式特征来帮助提高性能，现在模型很好地拟合了数据。</figcaption></figure><p id="0c40" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">多项式特征的次数与模型的整体复杂性之间有很强的相关性。因此，度数的取值必须经过详尽的实验。</p><p id="7a61" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在来看看学位选择不当的影响:</p><figure class="kz la lb lc fd ij er es paragraph-image"><div class="er es mm"><img src="../Images/91bf98fb2de5a05464e4b7373a531ac8.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*6u5qt_OdkZRW3_Q8f5EPaA.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">学位值低；过于简单的模型；欠拟合</figcaption></figure><figure class="kz la lb lc fd ij er es paragraph-image"><div class="er es mm"><img src="../Images/638996c55ab7b61c1347bf127d203093.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*k_cc399hAgalFg2OnLvuAw.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">学位价值高；模型过于复杂；过度拟合</figcaption></figure><figure class="kz la lb lc fd ij er es paragraph-image"><div class="er es mn"><img src="../Images/902a005f9f6188878b14c57597ce5111.png" data-original-src="https://miro.medium.com/v2/resize:fit:804/format:webp/1*iFXW5Y6G0ts2NsXwR9k4yA.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">在2度和3度之间的分数有一个巨大的跳跃。如果我们超过3，我们只是过度拟合数据，因此我们以泛化能力差为代价获得了更高的训练数据分数。</figcaption></figure></div><div class="ab cl jo jp gp jq" role="separator"><span class="jr bw bk js jt ju"/><span class="jr bw bk js jt ju"/><span class="jr bw bk js jt"/></div><div class="hb hc hd he hf"><h1 id="196e" class="jv jw hi bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated"><strong class="ak">在使用多项式功能之前</strong></h1><p id="ad06" class="pw-post-body-paragraph iq ir hi is b it kt iv iw ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm jn hb bi translated">由于<em class="lh">多项式特征</em>使用现有特征，确保原始特征的正确性很重要。</p><p id="edd4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">当使用<em class="lh">多项式特性</em>时，数据中的缺失值会造成一个大问题。它遇到数据缺失会对你大吼大叫。因此，在实现之前处理丢失的数据是很重要的。</p><p id="0457" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">填充缺失数据的策略也起着关键作用。</p><p id="4e61" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">考虑这样一种情况，所有丢失的值都被一个常数值替换，并且该值为0。在这种情况下，所有的相互作用项将变成零，我们将得到意想不到的结果。</p><p id="fc8f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">因此，正确选择处理缺失值的策略非常重要。</p><p id="4cbd" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">当接下来要执行多项式回归时，KNN、平均值和中值通常是处理缺失值的合适选择。</p><p id="ba08" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">发现有用就留个掌声！</p></div></div>    
</body>
</html>