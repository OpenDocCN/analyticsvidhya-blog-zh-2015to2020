<html>
<head>
<title>Ensemble Models: Bagging vs. Boosting</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">集合模型:装袋与助推</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/ensemble-models-baggings-vs-boosting-8affa6d18098?source=collection_archive---------8-----------------------#2019-11-27">https://medium.com/analytics-vidhya/ensemble-models-baggings-vs-boosting-8affa6d18098?source=collection_archive---------8-----------------------#2019-11-27</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/cd28a10a7f7c2f703ae4d9ca6b311ef0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*iXZ263IGYc6HbgBnwCUYRw.gif"/></div></div></figure><p id="ce01" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">装袋和助推有什么区别？打包和提升是两种最常见的集成技术。</p><h1 id="18f9" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">哪个更好？—装袋与增压</h1><p id="fa29" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">如果超参数被正确修改，Boosting模型可以比bagging模型表现得更好。然而，这可能非常耗时。Bagging模型更好地避免了过度拟合，但很少会得到更好的偏差。另一方面，boosting可以生成误差较低的模型，但容易过度拟合。这是因为boosting更像是一个不断自我改进的单一模型，bagging将并行运行几个模型。</p><h1 id="c8d2" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">制袋材料</h1><p id="52dd" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">bagging也称为bootstrap aggregation，它通过替换从训练数据集中获取样本，并为每个样本训练一个模型。数据集中的所有要素被选中的概率相等。Bagging模型将独立运行，然后汇总输出。在bagging模型中，最终输出预测是所有子模型的平均值(例如树)正在运行。</p><p id="0c69" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">两种最常见的装袋模型是(1)装袋决策树和(2)随机森林。</p><p id="5750" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">袋装决策树</strong></p><p id="1629" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">决策树模型获取X个数据，并找到将这些数据分割成独立数据集的规则。在学习决策树的时候，我的大会讲师<a class="ae kr" href="http://argmatt.com/" rel="noopener ugc nofollow" target="_blank">马特·布雷斯</a>把运行这个模型比作一个有20个问题的游戏。基于这些数据(问题)，你的模型将计算出在每个节点上分割的最佳X变量。</p><p id="d756" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">与常规决策树相比，袋装决策树使用N #棵树，并且每棵树用于其自己的引导样本。预测是基于全班的投票。</p><p id="0cca" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">随机森林</strong></p><figure class="kt ku kv kw fd ij er es paragraph-image"><div class="er es ks"><img src="../Images/c1c0c328fc748de74725150ca5c9f348.png" data-original-src="https://miro.medium.com/v2/resize:fit:1328/format:webp/1*RDa7NUzOUU8-ueinOqnr-A.png"/></div></figure><p id="84ab" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">随机森林类似于袋装决策树。与袋装决策树不同，随机森林试图消除树与树之间的相关性。随机森林模型不是在决策树中选择最佳分割点，而是只为每个分割考虑一个随机的要素子集。在随机森林中，树是平行的，树之间在建造时没有相互作用。</p><h1 id="7d05" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">助推</h1><p id="4e55" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">Boosting将运行一个模型，识别第一个模型中的薄弱学习者，然后尝试在下一个模型中加强这些学习者。两种最常见的增强模型是(1)AdaBoost和(2)梯度增强。</p><p id="3421" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> AdaBoost </strong></p><p id="d7bd" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">AdaBoost代表自适应增压。</p><figure class="kt ku kv kw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kx"><img src="../Images/ab7a22c6f2210f4a9da44375149afb0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DwvwMlOcT1T9hZwIJvMfng.png"/></div></div><figcaption class="ky kz et er es la lb bd b be z dx translated"><a class="ae kr" href="https://www.researchgate.net/figure/Training-of-an-AdaBoost-classifier-The-first-classifier-trains-on-unweighted-data-then_fig3_306054843" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="602a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">最佳显示在图像中，AdaBoost将运行其第一个模型，识别错误分类的项目，然后为下一个模型将更多权重放在这些错误分类的项目上。当下一个模型运行时，该模型承认先前模型的错误分类，并更新它们的权重以进行关注。与梯度下降相比，AdaBoost逐渐向模型中加入预测因子，使模型更好。AdaBoost的一个缺点是它不能并行化。</p><p id="902a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">梯度推进</strong></p><figure class="kt ku kv kw fd ij er es paragraph-image"><div class="er es lc"><img src="../Images/1d5d4e2f8210f86a8eef25942cc907a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1292/format:webp/1*ehl-k6LBGFpDYfVnm9h-Cg.png"/></div><figcaption class="ky kz et er es la lb bd b be z dx translated">资料来源:由基弗·卡托维奇(科幻)、马特·布莱姆斯(DC)撰写的联大讲稿</figcaption></figure><p id="45ba" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">梯度推进模型通过将先前的预测器误分类预测添加到集合中来工作，这确保了错误将被纠正。梯度推进模型将尝试将新的预测器拟合到由先前预测器产生的残差。</p><p id="75f9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">当运行第一梯度增强模型时，计算误差，并在下一个模型中用作目标变量。最后一个模型的预测与前一个模型的预测相结合。使用预测值和实际值计算新的残差。重复这个过程，直到误差不变或达到估计量的最大极限(超参数)。</p></div></div>    
</body>
</html>