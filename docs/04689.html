<html>
<head>
<title>A Guideline to Conformal Prediction</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">保形预测指南</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/a-guideline-to-conformal-prediction-7a392fc29bc1?source=collection_archive---------2-----------------------#2020-03-29">https://medium.com/analytics-vidhya/a-guideline-to-conformal-prediction-7a392fc29bc1?source=collection_archive---------2-----------------------#2020-03-29</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/></div><div class="ab cl if ig gp ih" role="separator"><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik"/></div><div class="hb hc hd he hf"><p id="5081" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">当预测向量空间中的事件或点时，我们需要结果的有保证的有效性。这在统计学中已经作为置信区间或预测区间存在。它可以通过保形预测嵌入到机器学习中，这是相对较新的方法。</p><blockquote class="jk jl jm"><p id="71ad" class="im in jn io b ip iq ir is it iu iv iw jo iy iz ja jp jc jd je jq jg jh ji jj hb bi translated">保形预测的思想是根据过去的经验预测给定测试观察的标签。</p></blockquote><p id="af80" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">保形预测使用过去的经验来确定新预测的精确置信度。我们计算每个观察的不符合分数，它衡量我们的观察相对于以前的例子有多不寻常。保形预测算法使用不一致性度量，为每个误差概率ε产生一个预测区域。</p><p id="64b7" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">通俗地说，如果给定一个训练集和测试集，我们依次尝试测试集的每个潜在标签。对于每一个假设的标签，我们看看如何似是而非的扩展训练集。如果除了一个以外，所有的完成看起来都不可信，我们可以做出有把握的预测。为了评估扩展训练集的不可信程度，我们使用了统计概念<em class="jn"> p值。</em></p></div><div class="ab cl if ig gp ih" role="separator"><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik"/></div><div class="hb hc hd he hf"><h2 id="846c" class="jr js hi bd jt ju jv jw jx jy jz ka kb ix kc kd ke jb kf kg kh jf ki kj kk kl bi translated">步伐</h2><blockquote class="jk jl jm"><p id="7877" class="im in jn io b ip iq ir is it iu iv iw jo iy iz ja jp jc jd je jq jg jh ji jj hb bi translated">计算一致性度量</p></blockquote><p id="c2e3" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">一致性度量是一种为数据集中的每个样本分配一致性分数的函数。一致性分数(<em class="jn">∧</em>)定义了数据集中的样本(<em class="jn"> z </em>)与数据集中的其他样本的一致性。如果<em class="jn"> ∝ </em>小，我们就说<em class="jn"> z </em>是<em class="jn">不符合</em>或者<em class="jn">奇怪</em>。</p><figure class="kn ko kp kq fd kr er es paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="er es km"><img src="../Images/150ec639e1bfe0b16b44a8a24d87ed32.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h69ItjKhRq0PJBSz5AzQ8A.png"/></div></div></figure><h2 id="2dce" class="jr js hi bd jt ju jv jw jx jy jz ka kb ix kc kd ke jb kf kg kh jf ki kj kk kl bi translated">有效性和效率</h2><p id="f539" class="pw-post-body-paragraph im in hi io b ip ky ir is it kz iv iw ix la iz ja jb lb jd je jf lc jh ji jj hb bi translated">共形预测器自动满足以下有效性属性</p><figure class="kn ko kp kq fd kr er es paragraph-image"><div class="er es ld"><img src="../Images/4de644aa6c7e4c6f4d400162f9062b07.png" data-original-src="https://miro.medium.com/v2/resize:fit:330/format:webp/1*r_GID6LdxsAeE-J24QH-yg.png"/></div><figcaption class="le lf et er es lg lh bd b be z dx translated">即预测器最多以概率<strong class="bd jt"> <em class="li"> ε </em> </strong>出错(假设标记样本独立且同分布)</figcaption></figure><p id="f608" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">如果预测集/数据集非常大，共形预测通常效率非常低，因为我们必须计算测试集中每个样本的一致性度量并进行预测。如果我们需要提高效率，预测集必须很小。</p></div><div class="ab cl if ig gp ih" role="separator"><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik"/></div><div class="hb hc hd he hf"><h2 id="4cf3" class="jr js hi bd jt ju jv jw jx jy jz ka kb ix kc kd ke jb kf kg kh jf ki kj kk kl bi translated">用于分类的保形预测(最近邻实现)</h2><p id="6536" class="pw-post-body-paragraph im in hi io b ip ky ir is it kz iv iw ix la iz ja jb lb jd je jf lc jh ji jj hb bi translated">在最近邻分类中，我们可以以两种方式使用保形预测思想。</p><ol class=""><li id="9593" class="lj lk hi io b ip iq it iu ix ll jb lm jf ln jj lo lp lq lr bi translated">计算到不同类别的最近样本的距离</li><li id="82b5" class="lj lk hi io b ip ls it lt ix lu jb lv jf lw jj lo lp lq lr bi translated">一个是到最近的同类样本的距离</li></ol><p id="d2a9" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">结合这两种方式，</p><figure class="kn ko kp kq fd kr er es paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="er es lx"><img src="../Images/2b13598e96fbb73532dd0c57f1066f54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V72ISKDtSCLaZgJJq23UqA.png"/></div></div></figure><h2 id="23d6" class="jr js hi bd jt ju jv jw jx jy jz ka kb ix kc kd ke jb kf kg kh jf ki kj kk kl bi translated">不符合措施</h2><p id="4f4f" class="pw-post-body-paragraph im in hi io b ip ky ir is it kz iv iw ix la iz ja jb lb jd je jf lc jh ji jj hb bi translated">在形式上，不符合措施的定义与符合措施的定义相同。但是他们的解释是不同的</p><figure class="kn ko kp kq fd kr er es paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="er es ly"><img src="../Images/7892ac5c73accf6883e4471db58c2ff9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aeepndtz4-vFmYDYGGtpIg.png"/></div></div></figure><p id="30bb" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">原则上，无论您使用不一致措施(皇家霍洛韦公约)还是一致措施(卡内基梅隆公约)，都没有关系。但是在回归应用中，非一致性分数通常更方便。</p></div><div class="ab cl if ig gp ih" role="separator"><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik"/></div><div class="hb hc hd he hf"><p id="8c01" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">让我们做一个练习。</p><p id="f1b2" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj"> <em class="jn">训练设置:</em> </strong> <br/> 1。阳性样本:(0，3)，(2，2)，(3，3) <br/> 2。负样本:(-1，1)，(-1，-1)，(0，1) <br/> <strong class="io hj"> <em class="jn">测试样本:</em> </strong> (0，0) <br/>让我们计算一下新样本到每个训练样本的欧氏距离。</p><figure class="kn ko kp kq fd kr er es paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><div class="er es lz"><img src="../Images/52fe6752dbe99d97f20938362e89009c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jwHYxYJPse4E0WcBb4rJPw.png"/></div></div></figure><p id="3d36" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">作为一致性测量，使用到不同类别的最近样本的距离除以到相同类别的最近样本的距离。</p><div class="kn ko kp kq fd ab cb"><figure class="ma kr mb mc md me mf paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><img src="../Images/58eec27ee89046d59f42d173bb396826.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/1*jKqtJ5ePgFKNRPo_EJhlVw.png"/></div></figure><figure class="ma kr mg mc md me mf paragraph-image"><div role="button" tabindex="0" class="ks kt di ku bf kv"><img src="../Images/9fc78a749e1495b8a20b46bbcdcff717.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*dPLV8VitXcKlmhfw_QStxg.png"/></div></figure></div><blockquote class="mh"><p id="4045" class="mi mj hi bd mk ml mm mn mo mp mq jj dx translated">1.假设(0，0)的标签是+1。测试样本是最奇怪的，所以p值是1/7 = 0.143。</p><p id="4cb1" class="mi mj hi bd mk ml mr ms mt mu mv jj dx translated">2.假设(0，0)的标签是-1。测试样品是第二符合的；它的秩是6，所以p值是6/7 = 0.857。</p></blockquote><p id="27b5" class="pw-post-body-paragraph im in hi io b ip mw ir is it mx iv iw ix my iz ja jb mz jd je jf na jh ji jj hb bi translated"><em class="jn"> p值</em>分别为0.143(对于+1)和0.857(对于-1)。我们可以预测-1，但是我们的预测没有达到5%的统计显著性，因为我们至少应该有20个训练观察值。</p><p id="ebf5" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">保形预测也可以应用于回归模型，这不在本文讨论范围之内。</p><h2 id="2f57" class="jr js hi bd jt ju jv jw jx jy jz ka kb ix kc kd ke jb kf kg kh jf ki kj kk kl bi translated">Python中保形预测的实现</h2><pre class="kn ko kp kq fd nb nc nd ne aw nf bi"><span id="e880" class="jr js hi nc b fi ng nh l ni nj">def calculate_distance(X_tr, y_tr):<br/>    train_length = X_tr.shape[0]<br/>    same_class_dist, other_class_dist = [[math.inf for i in range(train_length)] for j in range(2)]<br/><br/>    for i in range(train_length-1):<br/>        for j in range(i+1,train_length):<br/>            distance = np.linalg.norm(X_tr[i]-X_tr[j])<br/><br/>            if y_tr[i]==y_tr[j]:<br/>                if distance &lt; same_class_dist[i]:<br/>                    same_class_dist[i] = distance<br/>                if distance &lt; same_class_dist[j]:<br/>                    same_class_dist[j] = distance<br/>            else:<br/>                if distance &lt; other_class_dist[i]:<br/>                    other_class_dist[i] = distance<br/>                if distance &lt; other_class_dist[j]:<br/>                    other_class_dist[j] = distance<br/><br/>    return [same_class_dist, other_class_dist]</span><span id="662c" class="jr js hi nc b fi nk nh l ni nj">def conformal_prediction(X, y, dataset, test_size=0.3, train_size=0.7, random_state=3006):<br/>    predicted_list, p_values = [[] for i in range(2)]<br/>    # splitting the data<br/>    X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=test_size, train_size=train_size, random_state=random_state)<br/>    lenrange = len(list(set(y_train)))<br/>    same_class_dist, other_class_dist = calculate_distance(X_train, y_train)<br/><br/>    for i in range(len(X_test)):<br/>        conformity_scores = [[] for j in range(lenrange)]<br/>        curr_testXval = X_test[i]<br/>        for j in range(lenrange):<br/>            new_same_dist = np.append(same_class_dist, math.inf)<br/>            new_other_class_dist = np.append(other_class_dist, math.inf)<br/>            extended_X = np.concatenate((X_train, [curr_testXval]), axis = 0)<br/>            extended_y = np.concatenate((y_train, [j]), axis = 0)<br/><br/>            for curr_idx, curr_elem in enumerate(extended_X):<br/>                distance = np.linalg.norm(curr_elem - curr_testXval)<br/>                idx = len(extended_X)-1<br/><br/>                if distance != 0: #to avoid duplicate value<br/>                    if j == extended_y[curr_idx]:<br/>                        if distance &lt; new_same_dist[idx]:<br/>                            new_same_dist[idx] = distance<br/>                    else:<br/>                        if distance &lt; new_other_class_dist[idx]:<br/>                            new_other_class_dist[idx] = distance<br/><br/>                if new_same_dist[curr_idx] == 0: #to avoid duplicate value<br/>                    conformity_scores[j].append(0)<br/>                else:<br/>                    conformity_scores[j].append(new_other_class_dist[curr_idx]/new_same_dist[curr_idx])<br/><br/>        p_vals = []<br/>        for k in range(lenrange):<br/>            p_vals.append(np.mean(conformity_scores[k]&lt;=conformity_scores[k][X_train.shape[0]]))<br/><br/>        predicted_list.append(p_vals.index(max(p_vals)))<br/>        p_values.append(p_vals)<br/><br/>    falsep = []<br/>    for i, p in enumerate(p_values):<br/>        sumval = 0;<br/>        for j, q in enumerate(p):<br/>            if j != y_test[i]:<br/>                sumval += q<br/>        falsep.append(sumval)<br/><br/>    false_p_value = np.sum(falsep)/(len(falsep)*2)<br/>    accuracy = np.mean(predicted_list == y_test)<br/><br/>    print("For {}, "<br/>          "The average false p-value : {} \n"<br/>          "The accuracy of prediction : {} \n"<br/>          "The test error rate is : {}"<br/>          .format(dataset, false_p_value, accuracy, 1-accuracy))</span></pre><p id="0a26" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这种共形预测适用于Iris和电离层数据集。代码的完整上下文可以在资源库中找到。</p><div class="nl nm ez fb nn no"><a href="https://github.com/venkatasandeepd/conformal_prediction" rel="noopener  ugc nofollow" target="_blank"><div class="np ab dw"><div class="nq ab nr cl cj ns"><h2 class="bd hj fi z dy nt ea eb nu ed ef hh bi translated">venkatasandeepd/conformal _预测</h2><div class="nv l"><h3 class="bd b fi z dy nt ea eb nu ed ef dx translated">IRIS和电离层数据集上的KNN和共形预测实现—venkatasandeepd/Conformal _ Prediction</h3></div><div class="nw l"><p class="bd b fp z dy nt ea eb nu ed ef dx translated">github.com</p></div></div><div class="nx l"><div class="ny l nz oa ob nx oc kw no"/></div></div></a></div><p id="6b38" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">还有保形预测的框架实现，它可以用作scikit-learn库的扩展。</p><h2 id="847d" class="jr js hi bd jt ju jv jw jx jy jz ka kb ix kc kd ke jb kf kg kh jf ki kj kk kl bi translated">Python包</h2><ol class=""><li id="0d5b" class="lj lk hi io b ip ky it kz ix od jb oe jf of jj lo lp lq lr bi translated">Orange 3中的保形预测附加组件(版本1.1.3，2019年5月)<br/>https://pypi.org/project/Orange3-Conformal/</li><li id="e981" class="lj lk hi io b ip ls it lt ix lu jb lv jf lw jj lo lp lq lr bi translated">不墨守成规者亨利克·利努松(2017年6月2.1.0版)<br/>https://pypi.org/project/nonconformist/<br/><a class="ae og" href="https://github.com/donlnz/nonconformist" rel="noopener ugc nofollow" target="_blank">https://github.com/donlnz/nonconformist</a><br/><a class="ae og" href="http://donlnz.github.io/nonconformist/" rel="noopener ugc nofollow" target="_blank">http://donlnz.github.io/nonconformist/</a></li></ol><h2 id="f82e" class="jr js hi bd jt ju jv jw jx jy jz ka kb ix kc kd ke jb kf kg kh jf ki kj kk kl bi translated">r包</h2><ol class=""><li id="de71" class="lj lk hi io b ip ky it kz ix od jb oe jf of jj lo lp lq lr bi translated">卡耐基梅隆共形推理团队(马克斯·格塞尔、井磊、亚历山德罗·里纳尔多、瑞安·蒂布拉尼和拉里·乏色曼)，《共形参考》(版本1.0.0，2018年6月)<br/>https://github.com/ryantibs/conformal/</li><li id="e556" class="lj lk hi io b ip ls it lt ix lu jb lv jf lw jj lo lp lq lr bi translated">Niharika Gauraha和Ola Spjuth，保形分类(版本1.0.0，2017年12月)<br/>https://cran . r-project . org/web/packages/保形分类/</li></ol><h2 id="2340" class="jr js hi bd jt ju jv jw jx jy jz ka kb ix kc kd ke jb kf kg kh jf ki kj kk kl bi translated">资源:</h2><ol class=""><li id="b6f4" class="lj lk hi io b ip ky it kz ix od jb oe jf of jj lo lp lq lr bi translated"><a class="ae og" href="http://jmlr.csail.mit.edu/papers/volume9/shafer08a/shafer08a.pdf" rel="noopener ugc nofollow" target="_blank">http://jmlr . csail . MIT . edu/papers/volume 9/shafer 08 a/shafer 08 a . pdf</a></li><li id="9f5c" class="lj lk hi io b ip ls it lt ix lu jb lv jf lw jj lo lp lq lr bi translated"><a class="ae og" href="https://cml.rhul.ac.uk/copa2017/presentations/CP_Tutorial_2017.pdf" rel="noopener ugc nofollow" target="_blank">https://CML . rhul . AC . uk/Copa 2017/presentations/CP _ Tutorial _ 2017 . pdf</a></li></ol><p id="567b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">感谢您的阅读:)</p></div></div>    
</body>
</html>