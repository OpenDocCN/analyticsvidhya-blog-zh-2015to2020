<html>
<head>
<title>Building Edge AI applications using TensorFlow Lite on ESP32</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在ESP32上使用TensorFlow Lite构建边缘AI应用</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/building-edge-ai-applications-using-tensorflow-lite-on-esp32-baf8534b176e?source=collection_archive---------4-----------------------#2020-05-11">https://medium.com/analytics-vidhya/building-edge-ai-applications-using-tensorflow-lite-on-esp32-baf8534b176e?source=collection_archive---------4-----------------------#2020-05-11</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="cb9f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">多年来，我一直在开发嵌入式IOT应用程序，大多数时候，所谓的“智能”设备被编程为像由云或应用程序控制的远程控制设备一样工作，或者只是将传感器读数传输到实际处理发生的云中。给定这些资源受限设备上可用的有限RAM或处理能力，只能完成有限的事情。</p><p id="0809" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">去年，当Tensorflow团队宣布支持微控制器时，我真的非常激动。我们一直听说AI on edge是IOT设备发展的合理下一步，但鉴于缺乏开源框架，这一方向的创新非常少，随着谷歌的宣布，它为嵌入式程序员打开了许多尝试在edge上构建AI应用的大门。</p><p id="bd1f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我有几个ESP32 Cam模块，所以我想为什么不训练和部署一个时装模特来直接使用机载摄像头识别时装。结果出乎我的意料，应用程序能够以合理的准确度识别图像。</p><p id="40b9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">以下是演示视频:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/382b811a22bf343aeeec3b498ca1fe6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*do6x-6rJdK-uqaWgT8mj8A.gif"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">ESP32识别时尚服装图片</figcaption></figure><p id="55f1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">以下是我训练和部署该模型的步骤，我希望它能作为其他嵌入式开发人员开发一些很酷的应用程序的指南。</p><p id="20cb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">建立模型:</strong></p><p id="c3fd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我使用Google Colab来构建和训练模型。笔记本的链接可以在<a class="ae jt" href="https://colab.research.google.com/drive/1zvHCe9iasUnex6wgStY1tHtIbhPC1uVz?usp=sharing" rel="noopener ugc nofollow" target="_blank">这里</a>找到。我构建了一个简单的CNN，有一个输入层，一个输出层和两个隐藏层，每个隐藏层有6个节点。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="ju jv l"/></div></figure><p id="336d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们首先像构建普通Tensorflow模型一样构建模型，然后使用tensorflow lite转换器以及所需的优化级别将模型转换为tflite文件。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="ju jv l"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">将Tensorflow模型转换为TFlite模型，优化后可在电潜泵上运行</figcaption></figure><p id="6bd4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">由于ESP没有文件系统，我们需要将TF-Lite文件导出到一个数据数组来访问权重。我们可以使用linux命令行工具“xxd”来做到这一点。</p><pre class="je jf jg jh fd jw jx jy jz aw ka bi"><span id="50f5" class="kb kc hi jx b fi kd ke l kf kg"># xxd -i model.tflite &gt; model_data.cc</span></pre><p id="9698" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这就完成了部署的第一部分，我们已经构建并训练了模型。该模型的最终大小约为11k字节。第二部分涉及将模型部署到ESP32上。</p><p id="22df" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">在ESP32上部署模型:</strong></p><p id="ad1f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第一步是下载并设置esp-idf，这是由Espressif开发的开发框架，您可以按照Espressif网站上的<a class="ae jt" href="https://docs.espressif.com/projects/esp-idf/en/latest/esp32/get-started/" rel="noopener ugc nofollow" target="_blank">设置指南</a>开始。确保我们使用正确版本的ESP-IDF也很重要，我使用的是最新发布的版本4.0。</p><p id="ae55" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在我们已经设置好了，可以开始构建了，我们可以继续在ESP32上构建我们的Fashion Mnist应用程序。你可以在这里找到完整源代码<a class="ae jt" href="https://github.com/akshayvernekar/esp_tensorflow_fmnist" rel="noopener ugc nofollow" target="_blank">的链接，按照步骤进行操作。</a></p><p id="5a8d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">文件夹结构如下所示</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es kh"><img src="../Images/071263236986027dca8724a9e6095f77.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*iGtLdAuTOjLYRKUb5CEJFg.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">示例项目的文件夹结构。</figcaption></figure><p id="afef" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们使用esp32-camera组件与相机模块和tfmicro库进行交互，TF micro库是由TFLite团队开发的TensorFlow lite解释器，它将解释我们的模型并为我们提供预测。如上图所示，我们将这两个组件添加到<em class="ki">【组件】</em>目录下。</p><p id="8338" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我用于演示的硬件是AI thinker的ESP CAM模块。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es kj"><img src="../Images/a381191bc72cddf183f0d89a3eea91cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HX0mb164FQke4FbckJBJzA.jpeg"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">ESP摄像机开发板。</figcaption></figure><p id="2549" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">市场上有许多可用的esp摄像头模块，请确保在构建之前，在<em class="ki">“menu config”</em>中的<em class="ki">“摄像头引脚”</em>部分下选择正确的摄像头模块。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es kk"><img src="../Images/d6fe1094d440437c0e3b93f3f627c951.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sxA1v9k1eWF4f4F1lhf5Hw.png"/></div></div></figure><p id="55c5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下一步是将我们在最后一步“<strong class="ih hj">构建模型”</strong>中构建的<em class="ki">“model _ data . cc”</em>文件放置在<em class="ki">“main/TF _ model/”</em>文件夹<em class="ki">中。</em>确保“include/model_data.h”中模型数组的变量名和数组长度与“model_data.cc”文件中的相同。接下来，我们检查<em class="ki">"/include/model _ settings . h "</em>文件，以确保输入大小和类别数量等设置与我们正在部署的模型相匹配，如果您使用任何其他模型，则需要修改设置以匹配您的模型。</p><p id="1d41" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">tfmicro库的设置过程很简单，</p><p id="e79d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">首先，我们使用GetModel函数映射model_data，并将模型数据数组名称作为参数传递。</p><pre class="je jf jg jh fd jw jx jy jz aw ka bi"><span id="f5c6" class="kb kc hi jx b fi kd ke l kf kg">model = tflite::GetModel(model_data_tflite);</span></pre><p id="8c8b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">其次，我们引入操作解析器，它包含实现模型所需的操作。在这里，我使用了“AllOpsResolver ”,它包含了所有的操作，最佳实践是只包含您的模型所需的操作，从而节省一些代码空间。</p><pre class="je jf jg jh fd jw jx jy jz aw ka bi"><span id="4f16" class="kb kc hi jx b fi kd ke l kf kg">static tflite::ops::micro::AllOpsResolver micro_op_resolver;</span></pre><p id="26d3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">接下来，我们构建解释器，并为解释器分配内存以开始推理。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="ju jv l"/></div></figure><p id="69de" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这完成了设置过程，我们现在准备开始解释输入数据以获得我们的预测。为了推断数据，我们需要首先用我们的输入数据填充解释器的输入缓冲区，然后调用解释器的“invoke”函数来运行推断，预测存储在解释器的输出缓冲区中。使用方法请参考“app_tensorflow.cc”中的“tf_start_inference()”函数。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="ju jv l"/></div></figure><p id="3e91" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">就是这样！我们现在已经了解了如何构建Tensorflow lite模型并将其部署到esp32上。如果您正在构建示例程序，您会发现在刷新固件后，设备会启动为SSID为“ESP_CAM”的接入点，您可以将智能手机或笔记本电脑连接到此SSID，并在浏览器中输入IP地址“192.168.4.1”以打开设备的网页。一旦网页被加载，按下“开始流”按钮，从相机获取相机流，并获得预测。</p><p id="72ce" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里还有一个例子，我使用TFlite团队构建的人物检测模型来检测视频中是否有人。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="kl jv l"/></div></figure><p id="91d7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如您所见，在ESP32上部署tensorflow lite模型非常容易。尽管我们受到可以部署的模型的复杂性的限制，但它仍然为在edge上构建一些创新的人工智能应用程序留下了很大的空间。</p></div></div>    
</body>
</html>