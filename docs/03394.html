<html>
<head>
<title>The Eyes of an Eye Doctor-Detect Blindness with Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">眼科医生的眼睛——用深度学习检测失明</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/the-eyes-of-an-eye-doctor-detect-blindness-with-deep-learning-51ce763a008b?source=collection_archive---------8-----------------------#2020-01-29">https://medium.com/analytics-vidhya/the-eyes-of-an-eye-doctor-detect-blindness-with-deep-learning-51ce763a008b?source=collection_archive---------8-----------------------#2020-01-29</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex if ig ih ii"><div class="bz dy l di"><div class="ij ik l"/></div><figcaption class="il im et er es in io bd b be z dx translated"><a class="ae ip" href="https://media.giphy.com/media/d1E0XQlBb5QIQEFi/giphy.gif" rel="noopener ugc nofollow" target="_blank">https://media.giphy.com/media/d1E0XQlBb5QIQEFi/giphy.gif</a></figcaption></figure><h2 id="2c71" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated"><strong class="ak">简介</strong></h2><p id="3803" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki hb bi translated">不可否认的事实是，深度学习的进步可以在许多方面让我们的生活变得更好，其中一个产生巨大影响的领域是医疗保健，让人们更加负担得起。<br/>深度学习在医疗保健中有各种各样的应用<br/>，如疟疾、癌症、肺炎检测等，但你有没有想过<br/>这在皮肤下是如何工作的？。<br/>计算机如何分析扫描图像并进行处理？。<br/>深度学习网络如何像医生的大脑一样思考？。在这篇博客中，我们将通过一个真实世界问题的解决方案来回答上述所有问题。</p><h2 id="63b9" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">有什么问题？。</h2><p id="76d3" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki hb bi translated">这里选择的问题是“糖尿病视网膜病变”，这是一种影响糖尿病患者视力的疾病，不受控制的血糖水平将导致血管损伤，当这种情况发生在眼睛后部的光敏组织(视网膜)时，视力开始恶化，并将最终完全丧失视力，有关这方面的更多信息，请参考<a class="ae ip" href="https://www.mayoclinic.org/diseases-conditions/diabetic-retinopathy/symptoms-causes/syc-20371611" rel="noopener ugc nofollow" target="_blank">链接</a>。</p><h2 id="05c6" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">深度学习在这里能有什么帮助？。</h2><p id="3ccd" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki hb bi translated">对抗任何健康问题的最佳方式是预防它，为了预防糖尿病视网膜病变，人们必须尽早发现它，那么如何发现这种情况呢？<br/> Ans)扫描患者的视网膜，由训练有素的医生对扫描图像进行评估，以提供诊断。<br/>现在，如果患者请不起医生，会发生什么情况？或者，当有数百万患者需要诊断，而可用的医生数量很少时，会发生什么？。<br/>想象一下，如果我们可以用神经网络代替医生的评估部分？或者，也许只是在医生的评估之前使用神经网络，这样医生就可以只查看严重的病例或神经网络不确定的病例，这难道不是一个很好的解决方案吗？。</p><p id="4e5f" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated">来自印度的Aravind眼科医院正试图通过利用上述想法为数百万来自农村地区的患者提供糖尿病视网膜病变诊断，以建立一个检测失明的神经网络。他们举办了一场kaggle <a class="ae ip" href="https://www.kaggle.com/c/aptos2019-blindness-detection/overview" rel="noopener ugc nofollow" target="_blank">竞赛</a> (APTOS 2019失明检测)，我们将从中获取数据并构建解决方案。</p></div><div class="ab cl ko kp gp kq" role="separator"><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt"/></div><div class="hb hc hd he hf"><h2 id="26c4" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated"><strong class="ak">深度学习的基础知识</strong></h2><p id="2cdd" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki hb bi translated"><strong class="jq hj">注意</strong>-如果你熟悉神经网络和卷积神经网络等概念，你可以跳过这一节。<br/>神经网络:-</p><figure class="kw kx ky kz fd ii er es paragraph-image"><div class="er es kv"><img src="../Images/78a6b6b70bba1cf245f8a6e699c90fe4.png" data-original-src="https://miro.medium.com/v2/resize:fit:914/format:webp/1*Rn-iBTI3Mwf8bcLz74Zs7Q.png"/></div><figcaption class="il im et er es in io bd b be z dx translated"><a class="ae ip" href="https://www.quora.com/What-is-the-differences-between-artificial-neural-network-computer-science-and-biological-neural-network#" rel="noopener ugc nofollow" target="_blank">https://www . quora . com/What-is-the-differences-between-artificial-neural-network-computer-science-and-biological-neural-network #</a></figcaption></figure><p id="6232" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated">这里的想法是模仿人类的神经元，提出一个能像人类一样思考的算法。这看起来有点复杂，但很容易理解。<br/>让我们看看生物神经元中发生了什么，假设你触摸一个热锅，然后你皮肤上的受体向你的大脑发送电信号，这些电信号被称为树突的触手状结构接收，这些来自不同来源的信号在细胞核中进行处理，然后通过轴突发送到其他神经元或大脑。<br/>科学家们希望利用这一想法，建立一个简单的算法，该算法可以将一些数字作为输入，在类似神经网络的结构中处理这些数字，并给出输出。有不同类型的神经网络，其中一种适用于图像数据的神经网络是卷积神经网络，我们将使用它来解决手头的问题。</p><p id="6589" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated">神经网络和CNN的深入工作是巨大的，不可能在一篇博客文章中涵盖，如果你有兴趣学习它们，我会给你留下一些有用的资源。现在把CNN想象成一个结构，它以数字形式接收图像，然后对这些输入数字执行一些操作，得到一个输出。</p><p id="62cd" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated">现在可能会有一些问题来自CNN的上述直觉，如<br/> <strong class="jq hj"> 1。图像是如何用数字表示的？。</strong> <br/> Ans。我们存储在计算机中的一切都是以0和1(二进制)的形式存储在内部的，让我们来看一个表示的图像。</p><figure class="kw kx ky kz fd ii er es paragraph-image"><div class="er es lc"><img src="../Images/f3574ae8613e58179ea41234bc8b0b2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:752/format:webp/1*E2SKm9Xzk4XT_WXCdu8-Tw.png"/></div><figcaption class="il im et er es in io bd b be z dx translated"><a class="ae ip" href="https://mitchellkscscomputing.wordpress.com/2015/10/21/how-bitmap-images-are-represented-in-binary/" rel="noopener ugc nofollow" target="_blank">https://mitchellkscscomputing . WordPress . com/2015/10/21/how-bitmap-images-is-presented-in-binary/</a></figcaption></figure><p id="cf51" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated">在上面的插图中，观察图像是如何在位图上表示的，深色方块用1表示，浅色单元用0表示。<br/>图像的分辨率也决定了位图的大小，例如上图的分辨率为8×8(8行8列),同样，分辨率为128×128的图像会有一个128行128列的位图。</p><p id="54bc" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated"><strong class="jq hj"> 2。我们如何将图像文件转换成？jpg或者。png格式转换成数值形式？。</strong> <br/>俺们。多亏了opencv，这个任务在python中只有一行答案，只需键入numeric _ rep = cv2 . im read(path)。<br/>函数imread将从指定的路径读取图像，并将其转换为数值数组，该数组现在存储在变量‘numeric _ rep’中。</p><p id="04a4" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated"><strong class="jq hj"> 3。CNN结构如何根据输入预测输出？。</strong> <br/> Ans。这里有两个阶段，第一个是训练阶段，它与训练人类大脑的任务有关，例如，我们通过展示狗和猫的多个例子，在儿童中注册一个像狗或猫的动物。同样，我们给出狗或猫的图像的数字表示作为输入，这些数字然后在CNN结构中进行一些运算，给出一个输出(狗或猫)。这也称为<strong class="jq hj">前向传播。</strong></p><figure class="kw kx ky kz fd ii er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es ld"><img src="../Images/164de1a9e62107c50d59552f782a7dca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*w-BAbj3Bi4kCjiHsDon_rw.gif"/></div></div><figcaption class="il im et er es in io bd b be z dx translated">https://towards data science . com/everything-you-neural-neural-propagation-machine-learning-make-easy-e 5285 BC 2 be 3a</figcaption></figure><p id="ed6e" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated">假设第一次尝试执行的操作是随机的，我们收到的输出是“猫”，但原始输出是“狗”， 由于我们的CNN错误地预测了输出，我们发现了原始输出和预测输出之间的差异，并将该误差传递回CNN结构，这也被称为<strong class="jq hj">反向传播</strong>通过重复的正向传播和反向传播过程，CNN学习输出标签为“狗”的图像中存在的模式。类似地，该结构学习标签为“猫”的图像中存在的模式。学习到的模式和特征的示例有颜色模式、耳朵形状、眼睛颜色、鼻子长度等。</p><p id="74ed" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated">一旦训练阶段结束，CNN已经从训练图像中学习了模式，现在使用这些知识，我们可以预测看不见的数据的输出，这也被称为测试阶段。至此，你应该对CNN如何运作有了一个非常基本的概念，并且能够理解博客的其余部分。</p></div><div class="ab cl ko kp gp kq" role="separator"><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt ku"/><span class="kr bw bk ks kt"/></div><div class="hb hc hd he hf"><h2 id="7779" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">APTOS 2019失明检测</h2><p id="7f83" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki hb bi translated"><strong class="jq hj">目的</strong> -建立一个神经网络，该网络可以接受扫描的视网膜图像作为输入，并根据失明的严重程度给出一个0-4之间的数字，其中“0”表示“无视网膜病变”，“4”表示“增生性视网膜病变”。</p><p id="9e73" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated"><strong class="jq hj">性能指标<br/> </strong>这些是评估我们的模型性能的不同度量，以便确定它在给定任务中有多好。</p><ol class=""><li id="f32e" class="li lj hi jq b jr kj jv kk jb lk jf ll jj lm ki ln lo lp lq bi translated">加权Kappa分数</li><li id="a57e" class="li lj hi jq b jr lr jv ls jb lt jf lu jj lv ki ln lo lp lq bi translated">混淆矩阵</li></ol><p id="3401" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated">混淆矩阵是众所周知的，但Kappa评分不是，但它非常类似于准确性，它也可以被理解为简单准确性测量的扩展。</p><p id="07d6" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated">κ是一个分数，它既考虑了模型相对于医生诊断的准确性，也考虑了模型和医生偶然的一致性，用κ表示，定义为</p><figure class="kw kx ky kz fd ii er es paragraph-image"><div class="er es lw"><img src="../Images/9b1fbaa4d5d3f5591fde4119ee3e08aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:568/format:webp/1*o3a6yWlhxtipEhMCc-Ci-A.jpeg"/></div><figcaption class="il im et er es in io bd b be z dx translated">https://en.wikipedia.org/wiki/Cohen%27s_kappa<a class="ae ip" href="https://en.wikipedia.org/wiki/Cohen%27s_kappa" rel="noopener ugc nofollow" target="_blank"/></figcaption></figure><p id="fb2f" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated">其中,“po”是评价人之间的相对观察一致(等同于准确性),“pe”是偶然一致的假设概率，使用观察数据计算每个观察者随机看到每个类别的概率。如果评价人完全同意，那么kappa =1。如果评价人之间没有达成一致意见，除了偶然预期的以外(如‘PE’给出的)，kappa =0。</p><p id="ef25" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated">加权Kappa是对此的一个小变化，在这里，如果两个评价人彼此不同意，则根据两个评价人给出的评价的距离给出分数。这意味着，如果(a)真实值为4，但模型预测a为3，我们的得分会更高，如果(b)模型预测a为0，得分会更低。</p><p id="b85e" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated"><strong class="jq hj">挑战</strong> <br/> 1。为训练提供的图像数量较少(3662)，深度学习通常需要大数据集才能获得好的结果。<br/> 2。图像的来源是多种多样的，图像是在各种光照条件下拍摄的，图像的质量也各不相同。<br/> 3。没有严格的延迟限制，但是该模型不应该花费超过几分钟来诊断图像。</p><h2 id="df51" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated"><strong class="ak">探索性数据分析和特征工程</strong></h2><p id="117d" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki hb bi translated">我们提供了两个图像文件夹，一个训练和其他测试以及两个相应的csv文件。训练csv文件包含图像名称，第一列为“id_code ”,第二列为医生给出的相应诊断。由于测试csv文件只有图像名称，没有给出诊断列，因此让我们加载csv文件并查看训练csv的样本。</p><figure class="kw kx ky kz fd ii er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es lx"><img src="../Images/9bca959087b8cac2cb2783f7e4f6a386.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FNeHoYcGRbmLqn3WNM0mXQ.png"/></div></div><figcaption class="il im et er es in io bd b be z dx translated">训练csv文件示例</figcaption></figure><p id="f00a" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated">在我们继续下一步之前，对我们来说重要的是将给定的训练集分层并交叉验证，这样我们将有一组看不见的数据来评估我们的模型。</p><p id="9433" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated"><strong class="jq hj">输出变量“诊断”在训练和交叉验证中的分布</strong></p><figure class="kw kx ky kz fd ii er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es ly"><img src="../Images/92c40268cd00d9d6aaafb809c205d652.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7pTVTvsTORzjK18poYrLvg.png"/></div></div><figcaption class="il im et er es in io bd b be z dx translated">训练集中输出变量的分布</figcaption></figure><figure class="kw kx ky kz fd ii er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es lz"><img src="../Images/97e9bd06f9d86bffd3e1057672ca3700.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DLhvZ48oKbd2ThnTHF6gpg.png"/></div></div><figcaption class="il im et er es in io bd b be z dx translated">交叉验证集中输出变量的分布</figcaption></figure><p id="f07f" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated">从上面的分布图中，我们可以看到，训练集和验证集中每一类的点的百分比是相似的。</p><p id="a24f" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated"><strong class="jq hj">我们如何知道患者患有糖尿病视网膜病变？。在</strong>上至少有5样东西可以发现</p><figure class="kw kx ky kz fd ii er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es ma"><img src="../Images/6f646f1a48daf2cd11c04c20639ee2a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jA3uaQAExUuQK9Lx3QaHFA.png"/></div></div><figcaption class="il im et er es in io bd b be z dx translated"><a class="ae ip" href="https://www.eyeops.com/" rel="noopener ugc nofollow" target="_blank">https://www.eyeops.com/</a></figcaption></figure><p id="cf78" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated">现在让我们看看属于每个类别的<strong class="jq hj">图像示例</strong></p><figure class="kw kx ky kz fd ii er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es mb"><img src="../Images/319273abdfe1c55040645d84d31561bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gD5ZwEzm-Iylw04ashBw2Q.png"/></div></div><figcaption class="il im et er es in io bd b be z dx translated">属于每个类别的图像的例子</figcaption></figure><p id="e1fb" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated">上图中的第一行包含5个诊断为“0”(“无糖尿病性视网膜病变”)的视网膜扫描示例，最后一行包含诊断为“4”(“增生性视网膜病变”)的视网膜扫描示例。如果您更仔细地观察，第一行中的图像要清晰得多，似乎没有任何异常形状或凸起，但最后一行中的图像有可见的斑点、像动脉瘤一样的凸起、棉絮状斑点等。</p><p id="eef0" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated">图像预处理 <br/>这是任何基于图像的任务中最重要的部分，一些常见的处理步骤有颜色转换、裁剪、调整大小等。</p><figure class="kw kx ky kz fd ii er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es mc"><img src="../Images/8b6c8e748ee484b88f72da04a231c800.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bOilAMiPWsAfjSsYbhoROg.png"/></div></div><figcaption class="il im et er es in io bd b be z dx translated">读取图像并处理它的功能</figcaption></figure><p id="00b8" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated">上述功能从硬盘读取图像，将其转换为RGB(默认情况下在BGR读取)，将图像大小调整为128X128像素，并有一个选项来启用本的预处理技术，如果启用，则应用高斯滤波器，这是一个低通滤波器，因为它有助于消除图像的噪声，并通过赋予不同的权重与原始图像合并，因为它有助于增强我们关心的特征。<br/> <strong class="jq hj">图像经过预处理后属于每一个类别，没有剪裁暗的多余部分</strong>。</p><figure class="kw kx ky kz fd ii er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es md"><img src="../Images/952903d2683ddb50820a8119be99c6aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bUxJz8oSubRPyWRcagPL5w.png"/></div></div><figcaption class="il im et er es in io bd b be z dx translated">Ben预处理后的图像</figcaption></figure><p id="a819" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated">从上面的图像中可以清楚地看到，由于特征更加明显，预处理已经起作用。<br/> 'Crop_dark_extras '该功能用于移除图像中额外的黑暗空间，因为从该示例中无法获得任何有用的信息-</p><figure class="kw kx ky kz fd ii er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es me"><img src="../Images/9b7a9f517aac6954dbe600cd6916d57a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*s08ENQCR1egkoWN5zdZeXA.png"/></div></div><figcaption class="il im et er es in io bd b be z dx translated">裁剪图像的代码</figcaption></figure><figure class="kw kx ky kz fd ii er es paragraph-image"><div class="er es mf"><img src="../Images/832296dd6adaf4feff4dbc123c35840d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1048/format:webp/1*XsJVp4X01XQuD-WPr_78Zw.png"/></div><figcaption class="il im et er es in io bd b be z dx translated">裁剪前的图像</figcaption></figure><figure class="kw kx ky kz fd ii er es paragraph-image"><div class="er es mg"><img src="../Images/6a051fb8cc6dd065afe4bd73962951f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:740/format:webp/1*XDdupdkioLdMUk-UY2gFRQ.png"/></div><figcaption class="il im et er es in io bd b be z dx translated">裁剪深色附加部分后的图像</figcaption></figure><p id="12ec" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated">在处理每个图像之后，图像的相应数字表示被添加到numpy数组，训练、cv和测试集具有不同的数组。这些数组也存储在。npy格式，以便在需要时可以加载它们。</p><p id="67ab" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated"><strong class="jq hj">转换输出变量<br/> </strong>最初，输出变量被编码为one-hot like(如果输出类别为3，则变量“y”被编码为[0，0，1，0，0])，因此这里提出的<strong class="jq hj">问题是一个“多类别分类”问题，这很好，但由于这是一个医疗保健问题，并且检测“假阴性”的成本非常高，我们将把该问题重新组织为一个有序回归问题。<br/> </strong>当转换为有序回归问题时，如果输出类为3，那么变量‘y’编码为[1，1，1，0，0]，这也意味着如果数据点属于类3，那么它也属于类1和类2(<a class="ae ip" href="https://arxiv.org/pdf/0704.1028.pdf" rel="noopener ugc nofollow" target="_blank">参考</a>)。</p><p id="7b90" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated"><strong class="jq hj">更多数据！<br/> </strong>拥有更多的数据总是有益的，通过一些搜索，我了解到2015年在Kaggle上举行了一场类似的比赛，因此我们也将下载并预处理2015年的数据集。</p><h2 id="194f" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">系统模型化</h2><p id="beed" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki hb bi translated">众所周知，没有一个通用的模型适用于任何数据，因此我们将尝试多种模型架构，看看在我们的情况下什么效果最好(有关逐步解释的更多详细信息，请参考github上的ipython笔记本)。</p><p id="7c4a" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated">在我们试验任何体系结构之前，让我们决定常数<br/><strong class="jq hj">Kappa得分的计算</strong> <br/>由于问题是作为一个有序回归问题提出的，因此模型的最后一层将是一个sigmoid层，它将为我们提供0-1之间的概率，并将每个类视为一个单独的二进制分类问题。例如，最后一层的输出为[0.8，0.4，0.7，0.2，0.1]，我们将概率阈值设置为0.5，则输出为[1，0，1，0，0] 现在取最高的类，并且在它之前的所有类都被认为是1，所以输出变成[1，1，1，0，0]，然后与原始输出变量进行比较，以确定二次加权Kappa得分。 <br/> <strong class="jq hj">损失函数</strong> <br/>对每个输出类计算二进制交叉熵，并求和以获得每个数据点的损失<br/> <strong class="jq hj">优化器</strong> <br/> Adam</p><p id="76e5" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated"><strong class="jq hj">架构实验<br/>模型-1(具有简单架构的基线模型)</strong> <br/>这是为了查看一个基本解决方案的表现和达到参考kappa分数的情况。</p><figure class="kw kx ky kz fd ii er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es mh"><img src="../Images/8d8c0d90d24f8880cb6d1d956d8adb8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UnPAgqrN_tdbm5TtztN7xA.png"/></div></div><figcaption class="il im et er es in io bd b be z dx translated">带有2019年比赛数据的模型-1</figcaption></figure><p id="d46f" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated">(详细日志和代码请参考<a class="ae ip" href="https://github.com/akashsambhangi/APTOS-blindness-Detection" rel="noopener ugc nofollow" target="_blank"> github </a>上的ipython笔记本。)<br/>该模型是一个相对较小的模型，因为它只有大约2.8M的参数</p><figure class="kw kx ky kz fd ii er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es mi"><img src="../Images/ecd12c6322b3dcdf2bf1367c89c23b7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WCEZGwbKF8Eb__-89nVQ2Q.png"/></div></div><figcaption class="il im et er es in io bd b be z dx translated">验证集的Kappa分数</figcaption></figure><p id="64a0" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated">该模型的kappa得分为0.70，表现不错。<br/>在Hyperas(支持GPU处理)的帮助下，以类似随机搜索的方式对更多此类架构进行了实验，来自此<strong class="jq hj">(2019年数据的模型-2)</strong>的最佳架构可以达到0.80的kappa分数，这很好，但从召回矩阵中我们可以看到，3级占主导地位，大多数点被错误分类为3级。</p><figure class="kw kx ky kz fd ii er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es mh"><img src="../Images/c09be0ef495c08002a05b581fe2e14db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UiVNL7zbIBocQsKNLOYKvg.png"/></div></div><figcaption class="il im et er es in io bd b be z dx translated">回忆最佳自有架构的矩阵</figcaption></figure><figure class="kw kx ky kz fd ii er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es mj"><img src="../Images/a6ea373859fa0e8f9598090439b8d9af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jjdRMIjc2QeudESQRK22iQ.png"/></div></div><figcaption class="il im et er es in io bd b be z dx translated">基线模型的张量板</figcaption></figure><p id="77f0" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated"><strong class="jq hj">迁移学习技术</strong> <br/>目前有许多针对图像数据集进行预训练的先进架构，这些架构可用于解决我们手头的问题，同时我们还将对我们的方法进行两项增强，以获得最佳解决方案。</p><p id="86c8" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated">a) <strong class="jq hj">使用图像数据生成器技术进行数据扩充</strong> <br/>在将列车图像输入模型之前，对列车图像进行旋转/翻转等操作。这将有助于模型更好地处理看不见的数据，并且在可用数据集较小时也很有用</p><figure class="kw kx ky kz fd ii er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es mk"><img src="../Images/cd571608511334e2eac628f9ac85a909.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y07VqK5A-kTlIO7dDUOc2Q.png"/></div></div><figcaption class="il im et er es in io bd b be z dx translated">可视化由ImageDataGenerator生成的图像</figcaption></figure><p id="2460" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated">b) <strong class="jq hj">利用2015年的比赛数据</strong> <br/>从现在开始所有的车型都是按照下面提到的流程，根据2015年的比赛数据进行预训练的。<br/>预处理2015年的数据- &gt;将训练、cv和测试集结合起来，形成一整套训练数据(因为我们只对2019年的比赛数据进行验证)- &gt;定义一个以imagenet权重作为起始权重的模型- &gt;用2015年的数据对模型进行5个时期的训练，并保存权重。</p><p id="2d0a" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated"><strong class="jq hj">dense net 121<br/></strong>dense net架构首先根据2015年的数据进行预训练，来自该模型的权重被用作使用2019年比赛数据的模型的起点。</p><figure class="kw kx ky kz fd ii er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es ml"><img src="../Images/7b8ceed1e57df649c1db006772308a06.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Tj0NFNm8_W7tri_USgyfuQ.png"/></div></div><figcaption class="il im et er es in io bd b be z dx translated">Densenet121</figcaption></figure><p id="3508" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated">从上面的单元格中，我们可以看到这里的参数数量约为7M，这明显大于我们的基线模型。<br/>这款车型表现非常出色，kappa评分为<strong class="jq hj"> 91.34 </strong>。<br/>该模型的召回矩阵是对我们基线模型的巨大改进。</p><figure class="kw kx ky kz fd ii er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es mm"><img src="../Images/0eb95ceb6da0e6c97d10e46950f02e8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M296iyc39O-cPgxXMSD0Uw.png"/></div></div><figcaption class="il im et er es in io bd b be z dx translated">Densenet 121召回表</figcaption></figure><figure class="kw kx ky kz fd ii er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es mn"><img src="../Images/fb1b4f979377d305243ddf6589ec5b61.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9ALsudULvvChdlKSkzJQiw.png"/></div></div><figcaption class="il im et er es in io bd b be z dx translated">Densenet121型号的张量板测井</figcaption></figure><p id="90b9" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated"><strong class="jq hj"> Resnet 50 <br/> </strong>这是一个比Densenet 121具有更多参数的更大架构，在2015年的数据上遵循相同的预训练过程。</p><figure class="kw kx ky kz fd ii er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es mo"><img src="../Images/1cf399e319198f8daee349ccc7a631ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tciKiJWJTzmYy5gpHZHksw.png"/></div></div><figcaption class="il im et er es in io bd b be z dx translated">Resnet 50</figcaption></figure><figure class="kw kx ky kz fd ii er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es mp"><img src="../Images/5b0a39114e8470dfeaedf608e6a9aa5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P6KcgMG0fPdTlqdye6zLoA.png"/></div></div><figcaption class="il im et er es in io bd b be z dx translated">Resnet50的张量板</figcaption></figure><p id="ce32" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated">与只有700万个参数的Densenet121架构相比，这里的参数数量已经增加到大约2350万个。<br/>虽然该模型的性能并没有明显优于Densenet121，因为其kappa得分为<strong class="jq hj"> 91.65 </strong>，并且该模型的召回矩阵也非常相似。</p><figure class="kw kx ky kz fd ii er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es mq"><img src="../Images/469e7d2b04ff2225f4cc86c5dbd47636.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*stH3cHy-2lG9ULP5pEWgjA.png"/></div></div><figcaption class="il im et er es in io bd b be z dx translated">Resnet-50型号的召回矩阵</figcaption></figure><p id="8589" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated"><strong class="jq hj">efficient net<br/></strong>这是一种设计工作类似于最先进架构的架构，但参数数量更少，因此计算能力更低，该架构基于Mobilenet(它使用深度卷积等概念来减少参数数量)，Efficientnet <a class="ae ip" href="https://arxiv.org/abs/1905.11946" rel="noopener ugc nofollow" target="_blank">论文</a>关注如何有效地扩展CNN架构。<br/>根据模型架构的深度和宽度，Efficientnet分为7个模型，其中Efficientnet-B0是最小的架构，Efficientnet-B7是最大的架构。</p><p id="1aca" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated">为了比较Efficientnet与Densenet121和Resnet50的性能，我们将选择参数数量相当的<strong class="jq hj"> Efficientnet-B4 </strong>(在github代码中也试验了Efficientnet B0和B3)。</p><figure class="kw kx ky kz fd ii er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es mo"><img src="../Images/18f97f61dcfb4b3d58fdb896a2ec3557.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aQT3zb05pbeoOz7NwCzPzA.png"/></div></div><figcaption class="il im et er es in io bd b be z dx translated">效率网络B4</figcaption></figure><p id="5a36" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated"><strong class="jq hj">此架构使用的参数数量多于Densenet121，少于Resnet50，但此处实现的性能是三者中最好的，因为此模型的kappa得分为92.01 </strong>，召回矩阵也有所改进。</p><figure class="kw kx ky kz fd ii er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es mr"><img src="../Images/ba4903a2e22cd4fdedb49888f80a0c61.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3eKHdZnb_GPfA5TxyUrtXQ.png"/></div></div><figcaption class="il im et er es in io bd b be z dx translated">Effieicntnet B4的召回矩阵</figcaption></figure><figure class="kw kx ky kz fd ii er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es ms"><img src="../Images/8f1a0d8bce5d0f38db060982212f9e14.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r806S2cFbxD_UEcHusRYFg.png"/></div></div><figcaption class="il im et er es in io bd b be z dx translated">Efficientnet-B4的Tensorboard</figcaption></figure><figure class="kw kx ky kz fd ii er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es mt"><img src="../Images/72aafcf60a8b25825c1159c1915bc25e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FhgVrjZfWSNPqJJ4EIHfng.png"/></div></div><figcaption class="il im et er es in io bd b be z dx translated">在Efficientnet模型上验证Kappa分数的图</figcaption></figure><figure class="kw kx ky kz fd ii er es paragraph-image"><div class="er es mu"><img src="../Images/58c846ea49bad20b8b76857b6ad92756.png" data-original-src="https://miro.medium.com/v2/resize:fit:1278/format:webp/1*2QavbUBu7IM_UYav4dhUpw.png"/></div><figcaption class="il im et er es in io bd b be z dx translated">Kappa分数显示没有过度拟合</figcaption></figure><p id="9c12" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated">此外，对各种模型的输出进行了XGBoost试验，但性能改善不明显，因此选择Efficientnet-B4作为最终模型。<br/>实现从预处理原始数据到预测输出一切的管道被创建并出现在<a class="ae ip" href="https://github.com/akashsambhangi/APTOS-blindness-Detection" rel="noopener ugc nofollow" target="_blank"> github链接</a>中。</p><figure class="kw kx ky kz fd ii er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es mv"><img src="../Images/a9fc6c09fa8e55c9670fdc701c0df8a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u1tPUKAnj0qykxdUkMW7AA.png"/></div></div><figcaption class="il im et er es in io bd b be z dx translated">模型摘要</figcaption></figure><p id="0318" class="pw-post-body-paragraph jo jp hi jq b jr kj jt ju jv kk jx jy jb kl ka kb jf km kd ke jj kn kg kh ki hb bi translated"><strong class="jq hj">92的Kappa分数意味着我们的最佳模特和医生在大约92%的时间里意见一致，这是一个例外！！</strong></p><figure class="kw kx ky kz fd ii er es paragraph-image"><div class="er es mw"><img src="../Images/80bb0f8c00c70c34c1cd1e3a55cd12fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:520/1*qjqvFePz4TA7gVMT3EAA8w.gif"/></div><figcaption class="il im et er es in io bd b be z dx translated"><a class="ae ip" href="https://media.giphy.com/media/9Ai5dIk8xvBm0/giphy.gif" rel="noopener ugc nofollow" target="_blank">https://media.giphy.com/media/9Ai5dIk8xvBm0/giphy.gif</a></figcaption></figure><h2 id="a5ac" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">链接</h2><p id="d67b" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jb jz ka kb jf kc kd ke jj kf kg kh ki hb bi translated"><strong class="jq hj"> LinkedIn </strong> - <a class="ae ip" href="https://www.linkedin.com/in/akash-sambhangi-41498396/" rel="noopener ugc nofollow" target="_blank">点击此处</a> <br/> <strong class="jq hj"> Github </strong> - <a class="ae ip" href="https://github.com/akashsambhangi/APTOS-blindness-Detection" rel="noopener ugc nofollow" target="_blank">点击此处</a></p><h2 id="9bf5" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">参考</h2><ol class=""><li id="7b1b" class="li lj hi jq b jr js jv jw jb mx jf my jj mz ki ln lo lp lq bi translated">Appliedaicourse.com(这是我获得机器学习和深度学习知识的地方)</li><li id="1825" class="li lj hi jq b jr lr jv ls jb lt jf lu jj lv ki ln lo lp lq bi translated"><a class="ae ip" href="https://github.com/btgraham/SparseConvNet/blob/kaggle_Diabetic_Retinopathy_competition/competitionreport.pdf" rel="noopener ugc nofollow" target="_blank">https://github . com/Bt Graham/SparseConvNet/blob/ka ggle _ Diabetic _ Retinopathy _ competition/competition report . pdf</a></li><li id="bb9d" class="li lj hi jq b jr lr jv ls jb lt jf lu jj lv ki ln lo lp lq bi translated"><a class="ae ip" href="https://arxiv.org/abs/1905.11946" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1905.11946</a></li><li id="80fc" class="li lj hi jq b jr lr jv ls jb lt jf lu jj lv ki ln lo lp lq bi translated"><a class="ae ip" href="https://arxiv.org/abs/0704.1028" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/0704.1028</a></li><li id="6190" class="li lj hi jq b jr lr jv ls jb lt jf lu jj lv ki ln lo lp lq bi translated"><a class="ae ip" href="https://www.kaggle.com/xhlulu/aptos-2019-densenet-keras-starter" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/xh lulu/aptos-2019-dense net-keras-starter</a></li><li id="124f" class="li lj hi jq b jr lr jv ls jb lt jf lu jj lv ki ln lo lp lq bi translated"><a class="ae ip" href="https://www.kaggle.com/c/aptos2019-blindness-detection/discussion/108065" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/c/aptos 2019-失明-检测/讨论/108065 </a></li></ol><h2 id="ceb6" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated"><strong class="ak">未来工作</strong></h2><ol class=""><li id="59c9" class="li lj hi jq b jr js jv jw jb mx jf my jj mz ki ln lo lp lq bi translated">根据2015年的数据预训练超过5个时期的最佳模型，以获得更强大的起始模型。</li><li id="f4d7" class="li lj hi jq b jr lr jv ls jb lt jf lu jj lv ki ln lo lp lq bi translated">尝试更多的图像增强技术。</li><li id="f703" class="li lj hi jq b jr lr jv ls jb lt jf lu jj lv ki ln lo lp lq bi translated">该模型可以部署在云上，以便可以在世界各地的农村医疗营地访问它。</li></ol></div></div>    
</body>
</html>