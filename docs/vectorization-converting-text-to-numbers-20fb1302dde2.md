# 矢量化——将文本转换成数字

> 原文：<https://medium.com/analytics-vidhya/vectorization-converting-text-to-numbers-20fb1302dde2?source=collection_archive---------15----------------------->

当你完成[文本清理](/swlh/text-cleaning-43fe4062952b)后，下一个重要步骤是将文本数据转换成数字，因为机器只理解数字。有许多方法可以将文本转换成矢量——计数矢量器、TFIDF 矢量器和单词嵌入。在此，我们将讨论计数矢量器和 TFIDF 及其计算:

***计数矢量器(或一个热编码):*** 这是用数字表示文本数据的基本技术。在这种情况下，从文本中提取独特的单词(称为特征)，然后计算文本中每个单词的频率。从文本中提取的特征称为 ***包词。*** 每行是一个文本，所有文档中的每个单词都是一列。每个单元格表示文本中的字数。现在，例如，我们有两个句子:文本 A:“我喜欢踢足球”和文本 B:“今天天气很好”，在删除停用词后，我们将剩下“喜欢踢足球”和“今天天气很好”。现在应用计数矢量器。

![](img/e25cbb55a4304a168c0b465115cb9e12.png)

每个单元格表示该单词在文本中出现的次数。

![](img/f9b282d2ad6b496e282fdc1989d485b3.png)

删除停用词

![](img/241378a4d06686fd7445b456aa059703.png)

从文本中提取所有独特的单词

![](img/7ab096265ffd22ddcede4b5ed89a6465.png)

这里获得的值是频率项

在计数矢量器中，我们只是获得单词的频率计数。当我们找到与从计数矢量器中提取的单词相似的单词时，我们将在那里放置 1，并在该特定单词再次出现在文本中时增加计数，在其他地方它将为 0。

计数矢量器的缺点是我们不能推断一个单词在文本中有多重要。

***TFIDF 矢量器-术语频率*逆文档频率*** :这将创建一个文档术语矩阵，其中每条文本消息仍有一行，各列代表单个唯一术语。但是单元格代表的不是计数，**单元格代表的是权重，这意味着确定一个单词对单个文本的重要性**。单词的重要性与它在文档中出现的次数(TF)成正比，与它在所有文档中出现的次数(DF)成反比。

词频(TF) =一个词在文档中出现的次数

文档频率(DF)=包含该单词的文档数量与文档总数的比率

逆文档频率(IDF) = ln(1/DF)+1

假设，我们有 50 个文档，一个术语(t1)在 50 个文档(d1)中的一个中出现了 10 次，这个术语在 50 个文档中的 45 个中出现，因此 TFIDF 值将是:

TF(t1，d1) = 10

DF(t1) = 45/50(包含 t1 的文档数/文档总数

IDF(t1) = ln(50/45)+1 = 1.1053

TFIDF(t1，d1) = TF*IDF = 10*1.1053= 11.053

现在，假设我们有另一个术语(t2 ),它在 50 个文档(d1)中的一个中出现了 10 次，并且在 50 个文档中的 10 个中出现了该术语，因此 TFIDF 值将是:

TF(t2，d1) = 10

DF(t2) = 10/50

IDF(t2) = ln(50/10)+1 = 2.6094

TFIDF(t2，d1) = TF*IDF = 10*2.6094= 26.094

如果观察到 t2 的 TFIDF 值高于 t1 的 TFIDF 值，这意味着 t2 项比 t1 项更重要。项的重要性随着其 TFIDF 值的增加而增加。术语 t2 比术语 t1 更重要，因为术语 t2 出现在比 t1 更少的文档中，或者我们可以说 t2 比 t1 对文档更重要。

假设我们有两个文档:

文档 1-“我真的很喜欢这个盒子的展示，这是一个很棒的礼物想法。”

文档 2-“哇，送人礼物真是太棒了”

下图显示了文档术语矩阵，其中包含每个单词的术语频率(TF)。

![](img/473f2f34faaa36d6b80e61dc2c7a74b5.png)

这是在删除停用词后获得的

现在我们计算文档频率(DF ),然后计算逆文档频率(IDF)

![](img/4d1407088ad9b85a96906677edb24d94.png)

在这一步中，将 TF 和 IDF 相乘以获得每个文档中每个单词的 TFIDF 值。请注意，在编码时，我们将获得不同的值，因为在初始化 TfidfVectorizer() give 时，norm=None，smooth_idf=False

![](img/14e95ebf22237dae0827e4c30b533f2e.png)![](img/9214fb64860b356b9ca02bd807cd6123.png)

python 中的编码部分

当应用附加平滑时，IDF 的公式变为:
DF =(包含单词的文档数+1)/(文档总数+1)
IDF = ln(1/DF)+1

![](img/24d60f34f6e87aa997d873bb36ef795c.png)

norm =无，smooth _ idf =真

现在应用 l2 范数:
在这里所有的 TFIDF 值将被平方并相加得到平方和，然后每个值除以这个平方和的平方根。

![](img/05b1321fe7260b1a415293e29937330a.png)![](img/717f6e24a0885e53411e4d1714443b2f.png)

现在我们可以看到，那些在数据集中不经常出现的单词被赋予了重要性。这样有助于提取更重要的单词。

从文本中提取的特征现在是数字格式。这些特征现在可以输入到机器学习算法中进行训练。

希望你喜欢这些内容，并继续关注更多 NLP 相关的帖子！

可以在 LinkedIn 上联系我！www.linkedin.com/in/yash-joshi-1904