<html>
<head>
<title>Creating an Autoencoder with PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用PyTorch创建自动编码器</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/creating-an-autoencoder-with-pytorch-a2b7e3851c2c?source=collection_archive---------5-----------------------#2020-11-01">https://medium.com/analytics-vidhya/creating-an-autoencoder-with-pytorch-a2b7e3851c2c?source=collection_archive---------5-----------------------#2020-11-01</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/1610400f47ceb3f76f7f0552e7cff189.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C6Z6i1_2EJn13jVEsAOkRQ@2x.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">自动编码器架构</figcaption></figure><p id="c638" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">自动编码器是创建更复杂数据的简单表示的基础。他们使用一种著名的编码器-解码器架构，允许网络获取数据的关键特征。如果你是自动编码器的新手，并且想了解更多，我推荐你阅读这篇关于自动编码器的文章:<a class="ae js" href="https://towardsdatascience.com/applied-deep-learning-part-3-autoencoders-1c083af4d798" rel="noopener" target="_blank">https://towards data science . com/applied-deep-learning-part-3-auto encoders-1c 083 af 4d 798</a></p><p id="940d" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在本文中，我们将实现一个自动编码器，并使用PyTorch，然后将该自动编码器应用于来自MNIST数据集的图像。</p><h1 id="672e" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">进口</h1><p id="8d1d" class="pw-post-body-paragraph iu iv hi iw b ix kr iz ja jb ks jd je jf kt jh ji jj ku jl jm jn kv jp jq jr hb bi translated">对于这个项目，您将需要一个内置的Python库:</p><pre class="kw kx ky kz fd la lb lc ld aw le bi"><span id="62a7" class="lf ju hi lb b fi lg lh l li lj">import os</span></pre><p id="31e3" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">您还需要以下技术库:</p><pre class="kw kx ky kz fd la lb lc ld aw le bi"><span id="ec9b" class="lf ju hi lb b fi lg lh l li lj">import numpy as np                       <br/>import torch                       <br/>import torchvision                       <br/>from torch import nn                       <br/>from torch.autograd import Variable                       <br/>from torchvision.datasets import MNIST                       <br/>from torchvision.transforms import transforms                       from torchvision.utils import save_image                       import matplotlib.pyplot as plt</span></pre><h1 id="7360" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">自动编码器类__init__</h1><p id="8984" class="pw-post-body-paragraph iu iv hi iw b ix kr iz ja jb ks jd je jf kt jh ji jj ku jl jm jn kv jp jq jr hb bi translated">对于自动编码器类，我们将扩展nn。模块类，并具有以下标题:</p><pre class="kw kx ky kz fd la lb lc ld aw le bi"><span id="48c6" class="lf ju hi lb b fi lg lh l li lj">class Autoencoder(nn.Module):</span></pre><h2 id="ed1a" class="lf ju hi bd jv lk ll lm jz ln lo lp kd jf lq lr kh jj ls lt kl jn lu lv kp lw bi translated">__init__方法头</h2><p id="8691" class="pw-post-body-paragraph iu iv hi iw b ix kr iz ja jb ks jd je jf kt jh ji jj ku jl jm jn kv jp jq jr hb bi translated">对于init，我们将有我们想要训练的纪元数量、数据的批量大小和学习速率的参数。方法标题应该如下所示:</p><pre class="kw kx ky kz fd la lb lc ld aw le bi"><span id="e44b" class="lf ju hi lb b fi lg lh l li lj">def __init__(self, epochs=100, batchSize=128, learningRate=1e-3):</span></pre><p id="b644" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">然后我们要调用超级方法:</p><pre class="kw kx ky kz fd la lb lc ld aw le bi"><span id="9155" class="lf ju hi lb b fi lg lh l li lj">super(Autoencoder, self).__init__()</span></pre><h2 id="8913" class="lf ju hi bd jv lk ll lm jz ln lo lp kd jf lq lr kh jj ls lt kl jn lu lv kp lw bi translated">初始化网络参数</h2><p id="9f06" class="pw-post-body-paragraph iu iv hi iw b ix kr iz ja jb ks jd je jf kt jh ji jj ku jl jm jn kv jp jq jr hb bi translated">对于这个网络，我们只需要初始化纪元、批量大小和学习速率:</p><pre class="kw kx ky kz fd la lb lc ld aw le bi"><span id="c37c" class="lf ju hi lb b fi lg lh l li lj">self.epochs = epochs                               <br/>self.batchSize = batchSize                               self.learningRate = learningRate</span></pre><h2 id="e95d" class="lf ju hi bd jv lk ll lm jz ln lo lp kd jf lq lr kh jj ls lt kl jn lu lv kp lw bi translated">编码器网络架构</h2><p id="e3bd" class="pw-post-body-paragraph iu iv hi iw b ix kr iz ja jb ks jd je jf kt jh ji jj ku jl jm jn kv jp jq jr hb bi translated">出于模块化的目的，编码器网络架构将全部位于init方法中。对于编码器，我们将有4个线性层，每个层中的节点数量都随着<strong class="iw hj">的减少而减少。我们还将使用3个ReLU激活函数。考虑到这一点，我们的编码器网络将如下所示:</strong></p><pre class="kw kx ky kz fd la lb lc ld aw le bi"><span id="df02" class="lf ju hi lb b fi lg lh l li lj">self.encoder = nn.Sequential(</span><span id="75ed" class="lf ju hi lb b fi lx lh l li lj">nn.Linear(784, 128),                                                            nn.ReLU(True),                                                            nn.Linear(128, 64),                                                            nn.ReLU(True),                                                            nn.Linear(64, 12),                                                            nn.ReLU(True),                                                            nn.Linear(12, 3)</span><span id="3c7a" class="lf ju hi lb b fi lx lh l li lj">)</span></pre><h2 id="0c09" class="lf ju hi bd jv lk ll lm jz ln lo lp kd jf lq lr kh jj ls lt kl jn lu lv kp lw bi translated">解码器网络架构</h2><p id="ed06" class="pw-post-body-paragraph iu iv hi iw b ix kr iz ja jb ks jd je jf kt jh ji jj ku jl jm jn kv jp jq jr hb bi translated">解码器网络架构也将位于init方法中。对于解码器，我们将使用一个非常相似的架构，具有4个线性层，每层中的节点数量增加<strong class="iw hj">。我们还将使用3个ReLU激活函数以及1个tanh激活函数。考虑到这一点，我们的解码器网络将如下所示:</strong></p><pre class="kw kx ky kz fd la lb lc ld aw le bi"><span id="c72f" class="lf ju hi lb b fi lg lh l li lj">self.decoder = nn.Sequential(</span><span id="b4c9" class="lf ju hi lb b fi lx lh l li lj">nn.Linear(3, 12),                                                            nn.ReLU(True),                                                            nn.Linear(12, 64),                                                            nn.ReLU(True),                                                            nn.Linear(64, 128),                                                            nn.ReLU(True),                                                            nn.Linear(128, 784),                                                            nn.Tanh()</span><span id="3fc3" class="lf ju hi lb b fi lx lh l li lj">)</span></pre><h2 id="47ab" class="lf ju hi bd jv lk ll lm jz ln lo lp kd jf lq lr kh jj ls lt kl jn lu lv kp lw bi translated">数据和数据加载器</h2><p id="d168" class="pw-post-body-paragraph iu iv hi iw b ix kr iz ja jb ks jd je jf kt jh ji jj ku jl jm jn kv jp jq jr hb bi translated">用于训练数据的数据和数据加载器将保存在init方法中。我们还将使用PyTorch库中的转换器将图像归一化并转换为张量。</p><pre class="kw kx ky kz fd la lb lc ld aw le bi"><span id="d39a" class="lf ju hi lb b fi lg lh l li lj">self.imageTransforms = transforms.Compose([ </span><span id="0eb3" class="lf ju hi lb b fi lx lh l li lj">transforms.ToTensor(),                                   transforms.Normalize([0.5], [0.5]) <br/>                              <br/>])</span><span id="abc7" class="lf ju hi lb b fi lx lh l li lj"><br/>self.data = MNIST('./Data', transform=self.imageTransforms)</span><span id="c79f" class="lf ju hi lb b fi lx lh l li lj">self.dataLoader = torch.utils.data.DataLoader(dataset=self.data,                                                                             batch_size=self.batchSize,                                                                             shuffle=True)</span></pre><h2 id="ac97" class="lf ju hi bd jv lk ll lm jz ln lo lp kd jf lq lr kh jj ls lt kl jn lu lv kp lw bi translated">优化器和标准</h2><p id="4b6a" class="pw-post-body-paragraph iu iv hi iw b ix kr iz ja jb ks jd je jf kt jh ji jj ku jl jm jn kv jp jq jr hb bi translated">对于这个网络，我们将使用Adams优化器和MSE损失作为损失函数。</p><pre class="kw kx ky kz fd la lb lc ld aw le bi"><span id="2b35" class="lf ju hi lb b fi lg lh l li lj">self.optimizer = torch.optim.Adam(self.parameters(), lr=self.learningRate, weight_decay=1e-5)</span><span id="73a2" class="lf ju hi lb b fi lx lh l li lj">self.criterion = nn.MSELoss()</span></pre><h2 id="394b" class="lf ju hi bd jv lk ll lm jz ln lo lp kd jf lq lr kh jj ls lt kl jn lu lv kp lw bi translated">完成自动编码器__init__</h2><p id="8b2a" class="pw-post-body-paragraph iu iv hi iw b ix kr iz ja jb ks jd je jf kt jh ji jj ku jl jm jn kv jp jq jr hb bi translated">完整的自动编码器初始化方法可以定义如下</p><figure class="kw kx ky kz fd ij"><div class="bz dy l di"><div class="ly lz l"/></div></figure><h1 id="8c74" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">正向方法</h1><p id="6af3" class="pw-post-body-paragraph iu iv hi iw b ix kr iz ja jb ks jd je jf kt jh ji jj ku jl jm jn kv jp jq jr hb bi translated">正向方法将通过数组x获取数字表示的图像，并通过编码器和解码器网络进行馈送。它可以非常简单地定义为:</p><figure class="kw kx ky kz fd ij"><div class="bz dy l di"><div class="ly lz l"/></div></figure><h1 id="6132" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">训练模型方法</h1><p id="dc19" class="pw-post-body-paragraph iu iv hi iw b ix kr iz ja jb ks jd je jf kt jh ji jj ku jl jm jn kv jp jq jr hb bi translated">对于此方法，我们将有以下方法头:</p><pre class="kw kx ky kz fd la lb lc ld aw le bi"><span id="0e1a" class="lf ju hi lb b fi lg lh l li lj">def trainModel(self):</span></pre><p id="98a5" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">然后，我们将根据纪元的数量重复训练过程:</p><pre class="kw kx ky kz fd la lb lc ld aw le bi"><span id="5abb" class="lf ju hi lb b fi lg lh l li lj">for epoch in range(self.epochs):</span></pre><p id="dd76" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">然后，我们需要使用以下方法遍历数据加载器中的数据:</p><pre class="kw kx ky kz fd la lb lc ld aw le bi"><span id="e4c2" class="lf ju hi lb b fi lg lh l li lj">for data in self.dataLoader:</span></pre><p id="d9c0" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">我们需要将图像数据初始化为一个变量，并使用以下方法对其进行处理:</p><pre class="kw kx ky kz fd la lb lc ld aw le bi"><span id="2c8c" class="lf ju hi lb b fi lg lh l li lj">image, _ = data                                       <br/>image = image.view(image.size(0), -1)                                       image = Variable(image)</span></pre><p id="2800" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">最后，我们需要输出预测，根据我们的标准计算损失，并使用反向传播。这可以非常简单地通过以下方式实现:</p><pre class="kw kx ky kz fd la lb lc ld aw le bi"><span id="3eb0" class="lf ju hi lb b fi lg lh l li lj"># Predict<br/>output = self(image)<br/>    <br/># Loss                                   <br/>loss = self.criterion(output, image)  </span><span id="d029" class="lf ju hi lb b fi lx lh l li lj"># Back propagation                                                                          self.optimizer.zero_grad()                                       loss.backward()                                       self.optimizer.step()</span></pre><p id="757d" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">然后，我们可以打印训练过程使用的损失和时期:</p><pre class="kw kx ky kz fd la lb lc ld aw le bi"><span id="6a7f" class="lf ju hi lb b fi lg lh l li lj">print('epoch [{}/{}], loss:{:.4f}'                                         .format(epoch + 1, self.epochs, loss.data))</span></pre><p id="2b1a" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">完整的训练方法应该是这样的:</p><figure class="kw kx ky kz fd ij"><div class="bz dy l di"><div class="ly lz l"/></div></figure><h1 id="090a" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">测试图像方法</h1><p id="7e7c" class="pw-post-body-paragraph iu iv hi iw b ix kr iz ja jb ks jd je jf kt jh ji jj ku jl jm jn kv jp jq jr hb bi translated">最后，我们可以使用我们新创建的网络来测试我们的自动编码器是否真正工作。我们可以编写这个方法，使用数据中的一个样本图像来查看结果:</p><figure class="kw kx ky kz fd ij"><div class="bz dy l di"><div class="ly lz l"/></div></figure><h1 id="7286" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">主要方法</h1><p id="79c9" class="pw-post-body-paragraph iu iv hi iw b ix kr iz ja jb ks jd je jf kt jh ji jj ku jl jm jn kv jp jq jr hb bi translated">对于main方法，我们首先需要初始化一个自动编码器:</p><pre class="kw kx ky kz fd la lb lc ld aw le bi"><span id="d81e" class="lf ju hi lb b fi lg lh l li lj">model = Autoencoder()</span></pre><p id="7620" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">然后我们需要训练网络:</p><pre class="kw kx ky kz fd la lb lc ld aw le bi"><span id="9759" class="lf ju hi lb b fi lg lh l li lj">model.trainModel()</span></pre><p id="6a1f" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">然后，我们需要创建一个新的张量，它是基于MNIST随机图像的网络输出。我们还需要重塑图像，以便我们可以查看它的输出。为了简单起见，我将使用的索引是7777。</p><pre class="kw kx ky kz fd la lb lc ld aw le bi"><span id="5456" class="lf ju hi lb b fi lg lh l li lj">tensor = model.testImage(7777)<br/>tensor = torch.reshape(tensor, (28, 28))</span></pre><p id="b293" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">然后，我们需要创建一个toImage对象，然后我们可以通过它传递张量，这样我们就可以真正地查看图像。我们也可以事后保存图像:</p><pre class="kw kx ky kz fd la lb lc ld aw le bi"><span id="d693" class="lf ju hi lb b fi lg lh l li lj">toImage = torchvision.transforms.ToPILImage()<br/>image = toImage(tensor)<br/>image.save('After.png')</span></pre><p id="37ae" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">我们完整的main方法应该是这样的:</p><figure class="kw kx ky kz fd ij"><div class="bz dy l di"><div class="ly lz l"/></div></figure><h1 id="dff6" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">自动编码器的结果</h1><p id="bc52" class="pw-post-body-paragraph iu iv hi iw b ix kr iz ja jb ks jd je jf kt jh ji jj ku jl jm jn kv jp jq jr hb bi translated">我们之前的图像是这样的:</p><figure class="kw kx ky kz fd ij er es paragraph-image"><div class="er es ma"><img src="../Images/b5a5c23fb52f19d5f46407301724dc6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:672/format:webp/1*gSXxtv7Ahz9dSwmlXa6uzg.png"/></div></figure><p id="4b08" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">应用自动编码器后，我们的图像看起来像这样:</p><figure class="kw kx ky kz fd ij er es paragraph-image"><div class="er es ma"><img src="../Images/c75cbf8d49aaeb254e29376979230d20.png" data-original-src="https://miro.medium.com/v2/resize:fit:672/format:webp/1*cdhtY9GucPnXj5KLJuFY4w.png"/></div></figure><p id="f02b" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">正如你所看到的，8的所有关键特征都被提取出来，现在它是原始8的一个更简单的表示，所以可以说自动编码器工作得非常好！我的完整代码可以在<a class="ae js" href="https://github.com/SamratSahoo/UT-Arlington-Research/blob/master/Week%209%20-%20PCA%20%26%20Autoencoders/Autoencoders.py" rel="noopener ugc nofollow" target="_blank"> Github </a>上找到</p><p id="a51d" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">如果你喜欢这个或者觉得它有帮助，如果你能给它一个掌声并给我一个关注，我将不胜感激！感谢您的阅读！</p></div></div>    
</body>
</html>