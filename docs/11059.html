<html>
<head>
<title>Object Detection using YOLO and Car Detection Implementation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 YOLO 的对象检测和汽车检测实现</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/object-detection-using-yolo-and-car-detection-implementation-1ec79e882875?source=collection_archive---------5-----------------------#2020-11-16">https://medium.com/analytics-vidhya/object-detection-using-yolo-and-car-detection-implementation-1ec79e882875?source=collection_archive---------5-----------------------#2020-11-16</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="7289" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用滑动窗口进行目标定位有几个缺点，例如选择合适的内核大小、步幅等。这导致高计算成本。</p><h1 id="9577" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated"><strong class="ak">简介</strong></h1><p id="68ed" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">《YOLO》(你只看一次)由约瑟夫·雷德蒙、桑托什·迪夫瓦拉、罗斯·吉斯克和阿里·法尔哈迪于 2015 年推出。YOLO 最大的优点是它在实现高精度的同时还能实时运行。YOLO 的方法是将目标检测作为一个回归问题，并将其完全传递给一个连接的神经网络。该系统将输入图像分成 S×S 网格，并且每个网格单元预测边界框、这些框的置信度、类别概率。这些预测被编码为 s×s×(B∫5+C)张量。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es kg"><img src="../Images/22d3bc337ba4e4d13d986d0204f5917f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*CYTDLg54ol-NpBOnrhFo2A.jpeg"/></div><figcaption class="ko kp et er es kq kr bd b be z dx translated">图一。展示了 YOLO 模型的工作原理</figcaption></figure><p id="9021" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">除了类别概率之外，每个边界框还有 5 个附加值，如下所示:</p><ol class=""><li id="c6d5" class="ks kt hi ih b ii ij im in iq ku iu kv iy kw jc kx ky kz la bi translated">Pc:物体出现在包围盒中的置信度</li><li id="7986" class="ks kt hi ih b ii lb im lc iq ld iu le iy lf jc kx ky kz la bi translated">bx，by:对象的中心坐标，如果有的话。如果没有对象存在，则该值为“无关”。</li><li id="5791" class="ks kt hi ih b ii lb im lc iq ld iu le iy lf jc kx ky kz la bi translated">bh，bw:当前物体的高度和宽度。如果没有对象存在，则该值为“无关”。</li><li id="81c6" class="ks kt hi ih b ii lb im lc iq ld iu le iy lf jc kx ky kz la bi translated">c:被检测对象的类别</li></ol><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es lg"><img src="../Images/248344c08abaa81dcc63a95f3abffb0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1042/format:webp/1*bdm4qEd8_CYPMzw5stTjxw.png"/></div><figcaption class="ko kp et er es kq kr bd b be z dx translated">图二。表示边界框的参数</figcaption></figure><p id="e0d0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">YOLO 架构由 24 个卷积层和 2 个全连接层组成。交替的 1×1 可选层减少了先前层的特征空间。网络的最终输出是 7×7×30 个预测张量。</p><h2 id="24f7" class="lh je hi bd jf li lj lk jj ll lm ln jn iq lo lp jr iu lq lr jv iy ls lt jz lu bi translated"><strong class="ak">非最大抑制</strong></h2><p id="bd83" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">当同一个对象出现在几个网格单元中时，就有了非最大抑制的概念。该算法然后可以检测具有不同置信度得分的相同对象周围的几个边界框。非最大值抑制抑制 Pc 值低于特定阈值的值(检测)。首先，它选择最高的 Pc 或 IOU 值，并抑制低于该值的所有值。然后选择第二高的并继续这个过程。以下是步骤:</p><p id="3689" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">第一步:</strong>预测所有网格对象的【Pc，bx，by，bw，bh】。</p><p id="321a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">第二步:</strong>当 Pc≤0.6(阈值)时报废。这是低概率的有条件丢弃。</p><p id="f6c8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">步骤 3: </strong>当有剩余的盒子时:<br/> <strong class="ih hj">步骤 3.1 </strong>:选取 Pc 最大的盒子，并将其作为预测输出。<br/> <strong class="ih hj">步骤 3.2 </strong>:丢弃 IOU≥0.5 的盒子(剩余)，输出在步骤 3.2 中预测。<br/> <strong class="ih hj">步骤 3.3 </strong>:返回步骤 3</p><h1 id="b2c0" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated"><strong class="ak">汽车检测使用(在 Keras 中实现):</strong></h1><ul class=""><li id="2ab8" class="ks kt hi ih b ii kb im kc iq lv iu lw iy lx jc ly ky kz la bi translated"><strong class="ih hj">输入</strong>是一批图像，每个图像的形状为(m，608，608，3)</li><li id="bab8" class="ks kt hi ih b ii lb im lc iq ld iu le iy lf jc ly ky kz la bi translated"><strong class="ih hj">输出</strong>是一个包含已识别类的边界框列表。每个包围盒由 6 个数字表示(<em class="lz"> pc </em>、<em class="lz"> bx </em>、<em class="lz"> by </em>、<em class="lz"> bh </em>、<em class="lz"> bw </em>、<em class="lz"> c </em> )(pc、bx、by、bh、bw、c)。输出维度为(19，19，5，85)</li><li id="7cdf" class="ks kt hi ih b ii lb im lc iq ld iu le iy lf jc ly ky kz la bi translated">我们选择了 5 个锚箱来覆盖 80 个班级</li><li id="e6a7" class="ks kt hi ih b ii lb im lc iq ld iu le iy lf jc ly ky kz la bi translated">YOLO 的架构是:图像(m，608，608，3) -&gt;深度 CNN -&gt;编码(m，19，19，5，85)</li><li id="0e80" class="ks kt hi ih b ii lb im lc iq ld iu le iy lf jc ly ky kz la bi translated">然后，我们只选择几个盒子，基于:分数阈值:丢弃已经检测到分数小于阈值的类的盒子</li><li id="b381" class="ks kt hi ih b ii lb im lc iq ld iu le iy lf jc ly ky kz la bi translated">非最大抑制:计算并集上的交集，避免选择重叠的框</li><li id="f1fc" class="ks kt hi ih b ii lb im lc iq ld iu le iy lf jc ly ky kz la bi translated">以上步骤给出了最终的 YOLO 输出。</li></ul><h2 id="37ac" class="lh je hi bd jf li lj lk jj ll lm ln jn iq lo lp jr iu lq lr jv iy ls lt jz lu bi translated">让我们开始编码:</h2><ol class=""><li id="6e2a" class="ks kt hi ih b ii kb im kc iq lv iu lw iy lx jc kx ky kz la bi translated">导入所需的库</li></ol><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="er es ma"><img src="../Images/9c722746fd323bad3d969eed67908c8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GSeC9CkHrhZvbXiogwT-4g.png"/></div></div><figcaption class="ko kp et er es kq kr bd b be z dx translated">导入所需的库</figcaption></figure><p id="a3a7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.接下来，我们读取类、锚盒并设置输入图像形状。<br/>class . txt 参考<a class="ae mf" href="https://gist.github.com/AruniRC/7b3dadd004da04c80198557db5da4bda" rel="noopener ugc nofollow" target="_blank">链接</a>，anchors.txt 参考<a class="ae mf" href="https://github.com/JudasDie/deeplearning.ai/blob/master/Convolutional%20Neural%20Networks/week3/model_data/yolo_anchors.txt" rel="noopener ugc nofollow" target="_blank">链接</a></p><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es mg"><img src="../Images/8a68b5d2c40cb26bda6f741937ae4a9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*mpAepCv_y1UvAB1Y_M2e3w.png"/></div><figcaption class="ko kp et er es kq kr bd b be z dx translated">阅读类、锚和图像形状</figcaption></figure><p id="e329" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">3.因为训练大型数据集需要很长时间，所以让我们下载训练好的 YOLO 模型并加载它。参考<a class="ae mf" href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=&amp;ved=2ahUKEwjGnNXfi_3sAhXrzDgGHSMxC1EQFjAAegQIAxAC&amp;url=https%3A%2F%2Fgithub.com%2FOlafenwaMoses%2FImageAI%2Freleases%2Fdownload%2F1.0%2Fyolo.h5&amp;usg=AOvVaw0J6cPR1x27wCKXmrin_Hwn" rel="noopener ugc nofollow" target="_blank">链接</a>下载 pickle 文件。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es mh"><img src="../Images/0168cd3fa7bf99c7a5b71a993f32cd51.png" data-original-src="https://miro.medium.com/v2/resize:fit:782/format:webp/1*ZFtkHi40khGGY2lNzRtoWg.png"/></div><figcaption class="ko kp et er es kq kr bd b be z dx translated">加载下载的预训练 YOLO 模型</figcaption></figure><p id="f61a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">4.以下命令处理并转换输出张量</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es mi"><img src="../Images/1427acc567d3afeba0c741212f5c5896.png" data-original-src="https://miro.medium.com/v2/resize:fit:1226/format:webp/1*LTyeL2wdXYbarS0B60ArpQ.png"/></div><figcaption class="ko kp et er es kq kr bd b be z dx translated">实现用于处理输出的 YOLO 头</figcaption></figure><p id="1dd7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">5.接下来，我们需要实现一个函数来过滤盒子。下面的函数执行两件事。首先，它通过用盒类概率乘以盒置信度来计算分数。通过这样做，我们可以拒绝低于某个阈值的盒子。其次，它通过选择最大值来输出盒子所属的类。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es mj"><img src="../Images/b76e0d70bcdabccb59d7820e729f1faa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1358/format:webp/1*gKw_5FsboBPncDJE4nPOEA.png"/></div><figcaption class="ko kp et er es kq kr bd b be z dx translated">实现过滤盒功能</figcaption></figure><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es lg"><img src="../Images/4d40d0375f5d6b7f5e0f1a94f56352df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1042/format:webp/1*oYoxyxf9hbr3vkcEQc9nRA.png"/></div><figcaption class="ko kp et er es kq kr bd b be z dx translated">调用实现的函数</figcaption></figure><p id="9495" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在我们已经初始化了所有需要的参数，现在我们可以编写 predict 函数来测试我们的图像模型。下面的函数处理一个输入图像，在初始化的分数、盒子和类上运行会话。然后，我们使用不同的颜色在不同的类名上生成和绘制边界框，并保存图像文件。现在，我们还可以看到使用 imshow 和带有类标签的边界框的坐标的输出图像</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="mb mc di md bf me"><div class="er es mk"><img src="../Images/509a1e9ad33b47e0a5a1d1251e9da367.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YmYcRy0v65ChXlKsxjeQlA.png"/></div></div><figcaption class="ko kp et er es kq kr bd b be z dx translated">用于检测图像中对象的预测函数</figcaption></figure><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es ml"><img src="../Images/cd057b02ab1eb9d8979dda090afee8b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1126/format:webp/1*Z-aZK4vRsxrNSNiGZI-SsQ.png"/></div><figcaption class="ko kp et er es kq kr bd b be z dx translated">通过传递所需的参数来调用预测函数</figcaption></figure><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es mm"><img src="../Images/58d388cb8d74ccf822582600c64e62bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:916/format:webp/1*RR9-ESR6V_IcgTetmXg4GA.png"/></div><figcaption class="ko kp et er es kq kr bd b be z dx translated">运行预测函数后的输出</figcaption></figure></div></div>    
</body>
</html>