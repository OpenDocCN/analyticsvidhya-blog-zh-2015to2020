<html>
<head>
<title>Scraping Box Office Info with Scrapy</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Scrapy抓取票房信息</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/scraping-box-office-info-with-scrapy-f23f1f2d684f?source=collection_archive---------11-----------------------#2020-02-11">https://medium.com/analytics-vidhya/scraping-box-office-info-with-scrapy-f23f1f2d684f?source=collection_archive---------11-----------------------#2020-02-11</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="631f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Scrapy是一个抓取网页的Python工具。这篇文章讲述了如何用Scrapy抓取网页。这里要刮的网站是票房魔咒。特别是，我将提取有关收入、发行商、流派等信息。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/f37111e59b9ab74acbf839f04efded5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*IHoBaUMdEyyKvCEf"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">照片由<a class="ae jt" href="https://unsplash.com/@addyire?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Addy Ire </a>在<a class="ae jt" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><h1 id="c139" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated"><strong class="ak">用于抓取的网页</strong></h1><p id="cecd" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">这个项目的目标是检查在美国特定时间内发行的所有电影，并提取关于个别电影的有用信息。如果你通过票房魔咒查看任何一部电影，你都可以看到关于这部电影的所有相关信息，格式如下:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es kx"><img src="../Images/aba6b6ad91570e5239866be7ea070819.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B-u3uEWDnWpT2y1ZPsB9AA.png"/></div></div></figure><p id="4f82" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我感兴趣的元素是'<strong class="ih hj">国内收入</strong>'、<strong class="ih hj">全球收入</strong>'、<strong class="ih hj">分销商</strong>'、<strong class="ih hj">开业</strong>'、<strong class="ih hj">预算</strong>'、<strong class="ih hj">美国电影协会</strong>'、<strong class="ih hj">流派</strong>、发行版中的<strong class="ih hj">。因此，我们将为每部电影提取这些信息。</strong></p><p id="fb6e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">抓取网页的代码和抓取的数据在这里是<a class="ae jt" href="https://github.com/yjeong5126/scraping_boxofficemojo" rel="noopener ugc nofollow" target="_blank"/>。</p><h1 id="ff3d" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated"><strong class="ak">创建新项目</strong></h1><p id="a897" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">一旦你在python上安装了Scrapy，让我们创建一个新的抓取网页的项目。打开命令行，转到要将项目放入的文件夹。然后，键入以下内容:</p><pre class="je jf jg jh fd ky kz la lb aw lc bi"><span id="404c" class="ld jv hi kz b fi le lf l lg lh"><strong class="kz hj">C:\...&gt;</strong> <strong class="kz hj">scrapy startproject</strong> boxofficeinfo</span></pre><p id="954b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du li lj lk kz b"><strong class="ih hj">scrapy startproject</strong></code>是创建和启动新项目的命令。用您自己的项目名称替换<code class="du li lj lk kz b">boxofficeinfo</code>。一旦您成功创建了项目，您将看到以下消息，说明现在您可以启动您的第一个蜘蛛了:</p><pre class="je jf jg jh fd ky kz la lb aw lc bi"><span id="76c6" class="ld jv hi kz b fi le lf l lg lh">...<br/>...\ ...\ boxofficeinfo</span><span id="e6eb" class="ld jv hi kz b fi ll lf l lg lh">You can start your first spider with:<br/>    cd boxofficeinfo<br/>    scrapy genspider example example.com</span></pre><p id="81d5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">与此同时，Scrapy创建了一个新文件夹，其中包含网络抓取所需的几个文件和子文件夹。因为我将新项目命名为'<strong class="ih hj"> boxofficeinfo </strong>'，所以创建的新文件夹的名称为'<strong class="ih hj"> boxofficeinfo </strong>'。</p><pre class="je jf jg jh fd ky kz la lb aw lc bi"><span id="13bd" class="ld jv hi kz b fi le lf l lg lh"><strong class="kz hj">boxofficeinfo</strong>&gt;    scrapy.cfg<br/>               <strong class="kz hj">boxofficeinfo</strong>&gt;      _init_.py<br/>                                    items.py<br/>                              middlewares.py<br/>                                pipelines.py<br/>                                 settings.py<br/>                                   _<strong class="kz hj">pycache_</strong><br/>                                     <strong class="kz hj">spiders&gt; </strong>_init_.py<strong class="kz hj"><br/>                                              _pycache_</strong> </span></pre><p id="91d5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们准备开始抓取网页。通过Scrapy进行网页抓取的整个过程包括以下步骤:</p><ul class=""><li id="489e" class="lm ln hi ih b ii ij im in iq lo iu lp iy lq jc lr ls lt lu bi translated">在items.py上书写</li><li id="13b5" class="lm ln hi ih b ii lv im lw iq lx iu ly iy lz jc lr ls lt lu bi translated">正在创建蜘蛛(。py)和识别网的模式</li><li id="ef01" class="lm ln hi ih b ii lv im lw iq lx iu ly iy lz jc lr ls lt lu bi translated">在pipelines.py上书写</li><li id="f849" class="lm ln hi ih b ii lv im lw iq lx iu ly iy lz jc lr ls lt lu bi translated">在Settings.py中更改设置</li><li id="6ed8" class="lm ln hi ih b ii lv im lw iq lx iu ly iy lz jc lr ls lt lu bi translated">奔跑吧。</li></ul><h1 id="8aa4" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated"><strong class="ak"> items.py </strong></h1><p id="7931" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">让我们先从<code class="du li lj lk kz b">items.py</code>开始。在<code class="du li lj lk kz b">items.py</code>中，我们将指定web中的哪些信息将被提取和存储。在这个网站上关于电影的许多信息中，我们将提取关于'<strong class="ih hj">国内</strong> <strong class="ih hj">收入</strong>'、<strong class="ih hj">全球收入</strong>'、<strong class="ih hj">发行商</strong>'、<strong class="ih hj">开业</strong>'、<strong class="ih hj">预算</strong>'、<strong class="ih hj">美国电影协会</strong>、<strong class="ih hj">流派</strong>、<strong class="ih hj">上映</strong>的个人电影信息。这是我的<code class="du li lj lk kz b">items.py</code>在文件中的内容:</p><pre class="je jf jg jh fd ky kz la lb aw lc bi"><span id="4fd5" class="ld jv hi kz b fi le lf l lg lh"><strong class="kz hj">import scrapy</strong></span><span id="d15b" class="ld jv hi kz b fi ll lf l lg lh"><strong class="kz hj">class</strong> BoxofficeItem<strong class="kz hj">(scrapy.Item)</strong>:<br/>    title <strong class="kz hj">=</strong> <strong class="kz hj">scrapy.Field()</strong><br/>    domestic_revenue <strong class="kz hj">=</strong> <strong class="kz hj">scrapy.Field()</strong><br/>    world_revenue <strong class="kz hj">=</strong> <strong class="kz hj">scrapy.Field()</strong><br/>    distributor <strong class="kz hj">=</strong> <strong class="kz hj">scrapy.Field()</strong><br/>    opening_revenue <strong class="kz hj">=</strong> <strong class="kz hj">scrapy.Field()</strong><br/>    opening_theaters <strong class="kz hj">=</strong> <strong class="kz hj">scrapy.Field()</strong><br/>    budget <strong class="kz hj">=</strong> <strong class="kz hj">scrapy.Field()</strong><br/>    MPAA <strong class="kz hj">=</strong> <strong class="kz hj">scrapy.Field()</strong><br/>    genres <strong class="kz hj">=</strong> <strong class="kz hj">scrapy.Field()</strong><br/>    release_days <strong class="kz hj">=</strong> <strong class="kz hj">scrapy.Field.()</strong></span></pre><h1 id="8bfa" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">创建你的蜘蛛。py)和<strong class="ak">识别幅材的图案</strong></h1><p id="e0ab" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">接下来我们需要做的是创建我们的蜘蛛。蜘蛛的文件不是由Scrapy自动创建的。在python文本编辑器中打开一个新文件，用你自己的名字将文件保存到<code class="du li lj lk kz b"><strong class="ih hj">spiders</strong></code>文件夹中。为了方便起见，我把这个文件命名为<code class="du li lj lk kz b">boxofficeinfo_spider.py</code>。我是这样开始我的蜘蛛的:</p><pre class="je jf jg jh fd ky kz la lb aw lc bi"><span id="8919" class="ld jv hi kz b fi le lf l lg lh"><strong class="kz hj">import scrapy</strong><br/><strong class="kz hj">from</strong> boxofficeinfo.<strong class="kz hj">items</strong> <strong class="kz hj">import</strong> BoxofficeItem</span><span id="a869" class="ld jv hi kz b fi ll lf l lg lh"><strong class="kz hj">class</strong> BoxofficeSpider<strong class="kz hj">(scrapy.Spider):</strong><br/>    <strong class="kz hj">name</strong> <strong class="kz hj">=</strong> "Boxofficeinfo"<br/>    <strong class="kz hj">allowed_domains</strong> <strong class="kz hj">=</strong> <strong class="kz hj">["</strong>boxofficemojo.com<strong class="kz hj">"]</strong><br/>    <strong class="kz hj">start_urls</strong> <strong class="kz hj">=</strong> <strong class="kz hj">[</strong><br/>    <strong class="kz hj">"</strong><a class="ae jt" href="https://www.boxofficemojo.com/year/2017/" rel="noopener ugc nofollow" target="_blank">https://www.boxofficemojo.com/year/2017/</a><strong class="kz hj">"</strong><br/>    <strong class="kz hj">]</strong></span></pre><p id="3c2c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">首先，我导入了前一阶段创建的<code class="du li lj lk kz b">scrapy</code>和<code class="du li lj lk kz b">BoxofficeItem</code>。我们在这里做的下一件事是给我们的蜘蛛它的<code class="du li lj lk kz b">name</code>，指定<code class="du li lj lk kz b">allowed_domains</code>，并设置<code class="du li lj lk kz b">start_urls</code>。<code class="du li lj lk kz b">start_urls</code>中的URL应该是你抓取的起点。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ma"><img src="../Images/76a428e6c7c82991a210427093b1c4f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CcUnh9Z7EnVDAurcWuJJLw.png"/></div></div></figure><p id="1d01" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du li lj lk kz b">start_urls</code>可以包含多个URL。如果我们想为2018年和2019年的电影提取相同的信息呢？然后，只需将这些页面的URL添加到<code class="du li lj lk kz b">start_urls</code>中。在某些情况下，您可以使用下一页或上一页按钮来进入这些页面。这里，我们将直接使用URL。你可以看到<code class="du li lj lk kz b"><a class="ae jt" href="http://www.boxofficemojo.com/year/2017/" rel="noopener ugc nofollow" target="_blank">www.boxofficemojo.com/year/2017/</a></code>包含了‘2017’，这意味着我们可以通过改变这个数字来移动到其他年份的页面。让我们通过以下方式添加2018年和2019年的URL:</p><pre class="je jf jg jh fd ky kz la lb aw lc bi"><span id="a0f6" class="ld jv hi kz b fi le lf l lg lh"><strong class="kz hj">start_urls</strong> <strong class="kz hj">=</strong> <strong class="kz hj">[</strong><br/>    <strong class="kz hj">"</strong><a class="ae jt" href="https://www.boxofficemojo.com/year/2017/" rel="noopener ugc nofollow" target="_blank">https://www.boxofficemojo.com/year/2017/</a><strong class="kz hj">"</strong><br/>    <strong class="kz hj">]</strong></span><span id="95b2" class="ld jv hi kz b fi ll lf l lg lh">for year in [2018, 2019]:<br/>    start_urls.append("https://<br/>                       <a class="ae jt" href="http://www.boxofficemojo.com" rel="noopener ugc nofollow" target="_blank">www.boxofficemojo.com</a>/year/"+str(year)+"/")     </span></pre><p id="6b12" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">创建蜘蛛的下一步是定义<code class="du li lj lk kz b">parse</code>函数，该函数指导蜘蛛如何抓取网页。在设定如何解析网页之前，我们有必要事先确定网页的模式。</p><p id="8a42" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们想要提取的电影信息不会直接显示在主页上。(从现在开始，我将把<code class="du li lj lk kz b">start_urls</code>中的页面称为“主页”。)基本上，我们可以通过使用它们的URL来访问各个电影的页面。例如，列表中的第一部电影“<strong class="ih hj">《星球大战:第八集——最后的绝地</strong>”的URL是<code class="du li lj lk kz b"><a class="ae jt" href="https://www.boxofficemojo.com/release/rl2708702721/?ref_=bo_yld_table_1" rel="noopener ugc nofollow" target="_blank">https://www.boxofficemojo.com/release/rl2708702721/?ref_=bo_yld_table_1</a></code>。那么，怎么才能获得所有电影的这个网址呢？主页上有所有指向单部电影的链接，这意味着主页包含了所有电影的URL。因此，我们可以通过检查主页面的HTML来获取这些URL。</p><p id="d7af" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">找出HTML中URL的最好方法是使用<strong class="ih hj"> Scrapy Shell </strong>。在命令行中，键入以下内容:</p><pre class="je jf jg jh fd ky kz la lb aw lc bi"><span id="12ea" class="ld jv hi kz b fi le lf l lg lh"><strong class="kz hj">&gt; scrapy shell "</strong><a class="ae jt" href="https://www.boxofficemojo.com/year/2017/" rel="noopener ugc nofollow" target="_blank">https://www.boxofficemojo.com/year/2017/</a><strong class="kz hj">"<br/>....&lt;scraped contents&gt;...<br/>......<br/>In [1]:_</strong></span></pre><p id="1390" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这个刺儿头把我们输入的网址刮了一整页。接下来要做的是找到指向各个电影的链接的xpath。使用Chrome上的Inspect可以找到xpath。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mb"><img src="../Images/672c6bf3b0284b01658de456d42bbbf6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xDVsdLSJt2JTU7Q4ej8KGw.png"/></div></div></figure><p id="d97c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上面复制的xpath是“<code class="du li lj lk kz b">//[<a class="ae jt" href="http://twitter.com/id" rel="noopener ugc nofollow" target="_blank">@id</a>=”table”]/div/table[2]/tbody/tr[2]/td[2]/a</code>”。现在，键入以下内容，看看这个xpath是否给出了我们想要的结果:</p><pre class="je jf jg jh fd ky kz la lb aw lc bi"><span id="1e26" class="ld jv hi kz b fi le lf l lg lh"><strong class="kz hj">&gt; scrapy shell "</strong><a class="ae jt" href="https://www.boxofficemojo.com/year/2017/" rel="noopener ugc nofollow" target="_blank">https://www.boxofficemojo.com/year/2017/</a><strong class="kz hj">"<br/>....&lt;scrapped contents&gt;...<br/>......<br/>In [1]: </strong>response.xpath(<strong class="kz hj">'</strong>//[<a class="ae jt" href="http://twitter.com/id" rel="noopener ugc nofollow" target="_blank">@id</a>=”table”]/<br/>                                   div/table[2]/tbody/tr[2]/td[2]/'<!-- -->)<br/><strong class="kz hj">Out [1]</strong>: []</span></pre><p id="363e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">它什么也没给！请记住，在许多情况下，我们通过之前的方法找到的xpath并不总是正确的。我们需要根据前一阶段复制的xpath手动找到正确的。</p><p id="2454" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">经过几次尝试，我找到了正确的xpath。</p><pre class="je jf jg jh fd ky kz la lb aw lc bi"><span id="fc1a" class="ld jv hi kz b fi le lf l lg lh"><strong class="kz hj">&gt; scrapy shell</strong> "<a class="ae jt" href="https://www.boxofficemojo.com/year/2017/" rel="noopener ugc nofollow" target="_blank">https://www.boxofficemojo.com/year/2017/</a>"<br/>.....<br/>.....</span><span id="53d7" class="ld jv hi kz b fi ll lf l lg lh"><strong class="kz hj">In [4]</strong>: response.xpath('//*[<a class="ae jt" href="http://twitter.com/id" rel="noopener ugc nofollow" target="_blank">@id</a>="table"]/div/table/tr[2]<br/>        /td[2]/a/@href')[0].extract()</span><span id="7cf9" class="ld jv hi kz b fi ll lf l lg lh"><strong class="kz hj">Out[4]</strong>: '/release/rl2708702721/?ref_=bo_yld_table_1' </span></pre><p id="8364" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在<code class="du li lj lk kz b">out[4]</code>中，我成功提取了“<strong class="ih hj">星球大战:第八集</strong>”的相对URL。使用<code class="du li lj lk kz b">urljoin</code>，我们可以将我们在这里找到的相对URL与基本URL结合起来。</p><pre class="je jf jg jh fd ky kz la lb aw lc bi"><span id="2a44" class="ld jv hi kz b fi le lf l lg lh"><strong class="kz hj">In [5]</strong>: response.urljoin('/release/rl2708702721<br/>        /?ref_=bo_yld_table_1')</span><span id="4317" class="ld jv hi kz b fi ll lf l lg lh"><strong class="kz hj">Out [5]</strong>:'<a class="ae jt" href="https://www.boxofficemojo.com/release/rl2708702721/?ref_=bo_yld_table_1" rel="noopener ugc nofollow" target="_blank">https://www.boxofficemojo.com/release/rl2708702721/? ref_=bo_yld_table_1</a>'</span></pre><p id="26bc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们能够获得我们选择的一部电影的URL。那么，我们如何获取列表中所有电影的URL呢？为此，让我们再次检查主页面的HTML，以便了解页面的一些模式。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mc"><img src="../Images/e52df8242fd70333bb93e614b8785cde.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OhfBUYMhau9VkS6hvpsoSA.png"/></div></div></figure><p id="855f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">每个电影的信息包含在<code class="du li lj lk kz b">&lt;tr&gt;…&lt;/tr&gt;</code>标签中，每个<code class="du li lj lk kz b">&lt;tr&gt;…&lt;/tr&gt;</code>标签具有相同的格式。因此，要找出单个电影的所有链接，请键入以下代码:</p><pre class="je jf jg jh fd ky kz la lb aw lc bi"><span id="bcf0" class="ld jv hi kz b fi le lf l lg lh"><strong class="kz hj">def parse(self, response):</strong><br/>    for tr in response.xpath('//*[@id="table"]/div/table/tr')[1:]:<br/>        href = tr.xpath('./td[2]/a/@href')<br/>        url = response.urljoin(href[0].extract())<br/>        yield scrapy.Request(url, callback=self.parse_page_contents)</span></pre><p id="5d64" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们知道了如何到达列表中每部电影的页面。我们在上面输入的<code class="du li lj lk kz b">scrapy.Request</code>将解析我们在下一步定义的<code class="du li lj lk kz b">parse_page_contents</code>函数后面的每个<code class="du li lj lk kz b">url</code>。</p><p id="a768" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du li lj lk kz b">parse_page_contents</code>函数的格式如下:</p><pre class="je jf jg jh fd ky kz la lb aw lc bi"><span id="51cd" class="ld jv hi kz b fi le lf l lg lh"><strong class="kz hj">def parse(self, response):</strong><br/>    for tr in response.xpath('//*[@id="table"]/div/table/tr')[1:]:<br/>        href = tr.xpath('./td[2]/a/@href')<br/>        url = response.urljoin(href[0].extract())<br/>        yield scrapy.Request(url, callback=self.<strong class="kz hj">parse_page_contents</strong>)</span><span id="ab69" class="ld jv hi kz b fi ll lf l lg lh"><strong class="kz hj">def parse_page_contents(self, response):</strong><br/>    <strong class="kz hj">item = BoxofficeItem()</strong><br/>    item["title"] =<br/>    item["domestic_revenue"] = <br/>     ...<br/>    item["release_days"] = <br/>    <strong class="kz hj">yield item</strong></span></pre><p id="6d0a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在<code class="du li lj lk kz b">parse_page_contents</code>中，我们决定在条目的每个元素中放入什么信息。在我们的例子中，我们想要放入<code class="du li lj lk kz b">item[“domestic_revenue”]</code>的应该是每部电影的国内收入。由于每部电影的页面格式和模式非常相似，一旦我们确定了一部电影的国内收入信息的存储位置，我们就能够将该位置应用于其他电影。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es md"><img src="../Images/cabe61fbc13dc8abbf29d16b15a45047.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6qSplAh4J9XDNotsviTmJw.png"/></div></div></figure><p id="a274" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">《星球大战:第八集》的国内收入是620，181，382美元。该信息的xpath是'<code class="du li lj lk kz b">//*[<a class="ae jt" href="http://twitter.com/id" rel="noopener ugc nofollow" target="_blank">@id</a>=”a-page”]/main/div/div[3]/div[1]/div/div[1]/span[2]/span’</code>。使用scrapy shell对于上面的页面，我们可以看到下面的命令对应的是国内收入的数字:</p><pre class="je jf jg jh fd ky kz la lb aw lc bi"><span id="05ac" class="ld jv hi kz b fi le lf l lg lh"><strong class="kz hj">In [2]</strong>: <strong class="kz hj">response.xpath('</strong><strong class="kz hj">//*[</strong><a class="ae jt" href="http://twitter.com/id" rel="noopener ugc nofollow" target="_blank"><strong class="kz hj">@id</strong></a><strong class="kz hj">=”a-page”]/main/div/div[3]/div[1]/div/div[1]/span[2]/span/text()'</strong><strong class="kz hj">)[0].extract()</strong></span><span id="6d3e" class="ld jv hi kz b fi ll lf l lg lh"><strong class="kz hj">Out [2]</strong>: '$620,181,382'</span></pre><p id="5655" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">基本上，该命令也可以应用于其他电影，因为对于任何其他电影，该信息将位于相同的位置。因此，我们可以对<code class="du li lj lk kz b">item[“domestic_revenue”]</code>使用这个命令。</p><pre class="je jf jg jh fd ky kz la lb aw lc bi"><span id="8002" class="ld jv hi kz b fi le lf l lg lh">def parse_page_contents(self, response):<br/>    item = <strong class="kz hj">BoxofficeItem</strong>()<br/>    item["title"] = <br/>    item["domestic_revenue"] = <strong class="kz hj">response.xpath('</strong><strong class="kz hj">//*[</strong><a class="ae jt" href="http://twitter.com/id" rel="noopener ugc nofollow" target="_blank"><strong class="kz hj">@id</strong></a><strong class="kz hj">=”a-page”]/main/div/div[3]/div[1]/div/div[1]/span[2]/span/text()'</strong><strong class="kz hj">)[0].extract()</strong><br/>     ...<br/>    item["release_days"] = <br/>    yield item</span></pre><p id="06d7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">“流派”呢？对于'<strong class="ih hj">星球大战:第八集</strong>'来说，关于“流派”的信息位于这个xpath: <code class="du li lj lk kz b">‘//*[<a class="ae jt" href="http://twitter.com/id" rel="noopener ugc nofollow" target="_blank">@id</a>=”a- page”]/main/div/div[3]/div[4]/div[7]/span[2]’</code>。让我们将这个xpath用于“流派”。</p><pre class="je jf jg jh fd ky kz la lb aw lc bi"><span id="2925" class="ld jv hi kz b fi le lf l lg lh"><strong class="kz hj">In [3]</strong>: response.xpath('//*[<a class="ae jt" href="http://twitter.com/id" rel="noopener ugc nofollow" target="_blank">@id</a>="a-     page"]/main/div/div[3]/div[4]/div[7]/span[2]/text()')[0].extract()</span><span id="9637" class="ld jv hi kz b fi ll lf l lg lh"><strong class="kz hj">Out [3]</strong>: 'Action\n    \n        Adventure\n    \n        Fantasy\n    \n        Sci-Fi' </span></pre><p id="0924" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们希望此信息的视觉效果是<code class="du li lj lk kz b">‘Action,Adventure,Fantasy,Sci-Fi’</code>，没有多余的间距。因此，我们可以像下面这样更改命令:</p><pre class="je jf jg jh fd ky kz la lb aw lc bi"><span id="17ab" class="ld jv hi kz b fi le lf l lg lh"><strong class="kz hj">In [4]</strong>: ",".join(response.xpath('//*[<a class="ae jt" href="http://twitter.com/id" rel="noopener ugc nofollow" target="_blank">@id</a>="a-page"]/main/div/div[3]/div[4]/div[7]/span[2]/text()')<br/>[0].extract().split())</span><span id="7b8f" class="ld jv hi kz b fi ll lf l lg lh"><strong class="kz hj">Out [4]</strong>: 'Action,Adventure,Fantasy,Sci-Fi'</span></pre><p id="a9aa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，我们可以为“流派”键入<code class="du li lj lk kz b">item[“genres”]= “,”.join(response.xpath(‘//*[<a class="ae jt" href="http://twitter.com/id" rel="noopener ugc nofollow" target="_blank">@id</a>=”a-page”]/main/div/div[3]/div[4]/div[7]/span[2]/text()’)<br/>[0].extract().split())</code>。我们可以对其余的信息做类似的事情来完成<code class="du li lj lk kz b">parse_page_contents</code>功能。</p><h1 id="0c6c" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated"><strong class="ak">挑战刮票房魔咒</strong></h1><p id="7681" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">我们的蜘蛛的完整格式如下所示:</p><pre class="je jf jg jh fd ky kz la lb aw lc bi"><span id="c2b1" class="ld jv hi kz b fi le lf l lg lh">import scrapy <br/>from Boxoffice.items import BoxofficeItem<br/>class BoxofficeSpider(self, response):<br/>    name = "..."<br/>    allowed_domains = ["..."]<br/>    start_urls = ["..."]<br/>    def parse(self,response):<br/>        ...<br/>        yield scrapy.Request(url, callback=self.parse_page_contents)<br/>    def parse_page_contents(self, response):<br/>        item = BoxofficeItem()<br/>        item["title"] = ...<br/>        ...<br/>        item["release_days"] = ...<br/>        yield item</span></pre><p id="eb2d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然而，只有当所有单个电影的信息位于每页的相同位置时，该代码<strong class="ih hj">才起作用。例如，'<strong class="ih hj">那不勒斯' 44 </strong>'的页面如下所示:</strong></p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es me"><img src="../Images/59d1c9242edf024b29c4e3fcf295bb18.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YhMTKsVSyUhObc1j_u5JGA.png"/></div></div></figure><p id="a704" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">它不包含有关“预算”和“美国电影协会”的信息。如果我们运行我们之前编写的代码，它将创建错误的信息或产生错误。例如，这个页面没有提供任何关于“美国电影协会”的信息。这部电影的<code class="du li lj lk kz b">item[‘MPAA’]</code>应该是<code class="du li lj lk kz b">‘N/A’</code>。然而，如果我们输入</p><pre class="je jf jg jh fd ky kz la lb aw lc bi"><span id="704e" class="ld jv hi kz b fi le lf l lg lh">item["MPAA"] = response.xpath('//*[<a class="ae jt" href="http://twitter.com/id" rel="noopener ugc nofollow" target="_blank">@id</a>="a-page"]/main/div/div[3]/div[4]/div[<strong class="kz hj">5</strong>]/span[2]/text()')[0].extract()</span></pre><p id="5817" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">根据'<strong class="ih hj">星球大战:第八集'</strong>'的信息，其中'美国电影协会'在第五排，'纪录片战争'将这样进入'美国电影协会':<code class="du li lj lk kz b">item[“MPAA”]=‘Documentary War’</code>。因此，当我们提取我们需要的信息时，我们应该考虑每部电影中是否包含所有的元素。</p><p id="e460" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我解决这个问题的策略是输入:</p><pre class="je jf jg jh fd ky kz la lb aw lc bi"><span id="21c1" class="ld jv hi kz b fi le lf l lg lh">elements = []<br/>for div in response.xpath('//*[<a class="ae jt" href="http://twitter.com/id" rel="noopener ugc nofollow" target="_blank">@id</a>="a-page"]/main/div/div[3]/div[4]/div')[0:]:<br/>    elements.append(' '.join(div.xpath('./span[1]/text()')[0].extract().split()))</span></pre><p id="cc95" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在为电影《那不勒斯44》运行scrapy shell之后，让我们运行这段代码。</p><pre class="je jf jg jh fd ky kz la lb aw lc bi"><span id="0fbc" class="ld jv hi kz b fi le lf l lg lh"><strong class="kz hj">&gt;</strong> scrapy shell "<a class="ae jt" href="https://www.boxofficemojo.com/release/rl1812104705/weekend/" rel="noopener ugc nofollow" target="_blank">https://www.boxofficemojo.com/release/rl1812104705/weekend/</a>"<br/>....<br/><strong class="kz hj">In [1]</strong>: elements = []<br/><strong class="kz hj">In [2]</strong>: for div in response.xpath('//*[<a class="ae jt" href="http://twitter.com/id" rel="noopener ugc nofollow" target="_blank">@id</a>="a-page"]/main/div/div[3]/div[4]/div')[0:]: elements.append(' '.join(div.xpath('./span[1]/text()')[0].extract().split()))<br/><strong class="kz hj">In [3]</strong>: elements</span><span id="0638" class="ld jv hi kz b fi ll lf l lg lh"><strong class="kz hj">Out [3]</strong>: ['Distributor','Opening','Release Date','Running Time','Genres','In Release','Widest Release','IMDbPro']</span></pre><p id="6c22" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">输出为我们提供了关于电影中包含哪些元素以及每个元素的顺序的信息。因此，为<code class="du li lj lk kz b">item[“MPAA”]</code>键入以下内容:</p><pre class="je jf jg jh fd ky kz la lb aw lc bi"><span id="ad58" class="ld jv hi kz b fi le lf l lg lh"><strong class="kz hj">if</strong> 'MPAA' in elements:<br/>    m = elements.index('MPAA') + 1<br/>    loc_MPAA = '//*[<a class="ae jt" href="http://twitter.com/id" rel="noopener ugc nofollow" target="_blank">@id</a>="a-page"]/main/div/div[3]/div[4]/div[<strong class="kz hj">{}</strong>]/span[2]/text()'.<strong class="kz hj">format(m)</strong><br/>    item["MPAA"] = response.xpath(loc_MPAA)[0].extract()<br/><strong class="kz hj">else</strong>:<br/>    item["MPAA"] = "N/A"</span></pre><p id="e54a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果一部电影的页面包括“美国电影协会”，它将给出关于“美国电影协会”的正确信息。否则，<code class="du li lj lk kz b">‘N/A’</code>将被输入。</p><h1 id="d6c7" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated"><strong class="ak"> pipelines.py和settings.py </strong></h1><p id="377a" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">一旦我们写完了<code class="du li lj lk kz b">items.py</code>和<code class="du li lj lk kz b">spider.py</code>的代码，我们就准备好抓取网页并提取我们想要的数据。但是，使用<code class="du li lj lk kz b">pipelines.py</code>，我们可以确定csv文件中的设置。这是我们用于这个项目的csv文件设置。打开Scrapy自动创建的<code class="du li lj lk kz b">pipelines.py</code>,写下如下代码:</p><pre class="je jf jg jh fd ky kz la lb aw lc bi"><span id="c361" class="ld jv hi kz b fi le lf l lg lh">import csv<br/>class <strong class="kz hj">YourPipelineName</strong>(object):<br/>    def __init__(self):<br/>        self.csvwriter = csv.writer(open("<strong class="kz hj">boxoffice2017_2019.csv</strong>", "w", newline=''))<br/>        self.csvwriter.writerow(["title", "domestic_revenue", "world_revenue", "distributor", "opening_revenue", "opening_theaters", "budget", "MPAA", "genres", "release_days"])</span><span id="5891" class="ld jv hi kz b fi ll lf l lg lh">    def process_item(self, item, spider):<br/>        row = []<br/>        row.append(item["title"])<br/>        row.append(item["domestic_revenue"])<br/>        row.append(item["world_revenue"])<br/>        row.append(item["distributor"])<br/>        row.append(item["opening_revenue"])<br/>        row.append(item["opening_theaters"])<br/>        row.append(item["budget"])<br/>        row.append(item["MPAA"])<br/>        row.append(item["genres"])<br/>        row.append(item["release_days"])<br/>        self.csvwriter.writerow(row)<br/>        return item</span></pre><p id="c3d0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了应用我们上面创建的设置，我们需要在<code class="du li lj lk kz b">settings.py</code>中改变一件事。在<code class="du li lj lk kz b">settings.py</code>的中间，我们需要激活<code class="du li lj lk kz b">ITEM_PIPELINES = {….}</code>。</p><pre class="je jf jg jh fd ky kz la lb aw lc bi"><span id="fb69" class="ld jv hi kz b fi le lf l lg lh"># Configure item pipelines<br/># See <a class="ae jt" href="https://docs.scrapy.org/en/latest/topics/item-pipeline.html" rel="noopener ugc nofollow" target="_blank">https://docs.scrapy.org/en/latest/topics/item-pipeline.html</a><br/><strong class="kz hj">ITEM_PIPELINES = {<br/>    'Boxoffice2019.pipelines.YourPipelineName': 300,<br/>}</strong></span></pre><p id="1871" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">确保您需要用您为管线创建的名称替换<code class="du li lj lk kz b">YourPipelineName</code>。</p><h1 id="f224" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated"><strong class="ak">跑蜘蛛！！</strong></h1><p id="d532" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">现在是时候运行我们创建的代码来提取电影的所有信息了。我们需要导航到<code class="du li lj lk kz b"><strong class="ih hj">boxofficeinfo</strong></code> <strong class="ih hj"> </strong>文件夹。然后，键入以下内容:</p><pre class="je jf jg jh fd ky kz la lb aw lc bi"><span id="3eaf" class="ld jv hi kz b fi le lf l lg lh"><strong class="kz hj">..\Boxofficeinfo</strong>&gt; scrapy <strong class="kz hj">crawl</strong> Boxofficeinfo</span></pre><p id="3805" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du li lj lk kz b">Boxofficeinfo</code>我们在<code class="du li lj lk kz b">scrapy crawl</code>后输入的是我们在<code class="du li lj lk kz b">Spider.py</code>中做的蜘蛛名。然后，在<code class="du li lj lk kz b">Boxofficeinfo</code>文件夹中创建<code class="du li lj lk kz b"><strong class="ih hj">boxoffice2017_2019.csv</strong></code>。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mf"><img src="../Images/c0e2f5c6c105ada32e686d281f72fd8f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-ft7M9Hw-TmCyE29Q9o-IQ.png"/></div></div></figure></div></div>    
</body>
</html>