<html>
<head>
<title>KNearestNeighbor Algorithm</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">KNearestNeighbor算法</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/knearestneighbor-algorithm-8fb57b877b5d?source=collection_archive---------6-----------------------#2019-09-10">https://medium.com/analytics-vidhya/knearestneighbor-algorithm-8fb57b877b5d?source=collection_archive---------6-----------------------#2019-09-10</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="f94a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">k近邻算法是机器学习中用于分类和回归问题的算法之一。KNN算法使用现有数据，并根据现有数据点的相似性和特征对新数据点进行分类。</p><p id="638f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">KNN算法的用途之一是在“搜索”。当你在网上购物时，你会发现，当你在你的商品展示的同一页面上看到相似的选项时。也就是说，你的任务是某种形式的“寻找与此相似的物品”。<br/>你会称这为<strong class="ih hj"> KNN </strong>搜索。</p><div class="jd je jf jg fd ab cb"><figure class="jh ji jj jk jl jm jn paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><img src="../Images/a83e3fe72ce01e54e272f7774355c3d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1108/format:webp/1*Uach6tz2j-Yc0_RfZXx10Q.png"/></div></figure><figure class="jh ji ju jk jl jm jn paragraph-image"><div role="button" tabindex="0" class="jo jp di jq bf jr"><img src="../Images/9ae6b546643fc240d393741b7df5766b.png" data-original-src="https://miro.medium.com/v2/resize:fit:894/format:webp/1*EdFsIeajiY8Nvf9q7MSHUQ.png"/></div></figure></div><p id="e986" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> KNN </strong>属于监督学习领域，在模式识别、数据挖掘和入侵检测中有着广泛的应用。</p><blockquote class="jv jw jx"><p id="d449" class="if ig jy ih b ii ij ik il im in io ip jz ir is it ka iv iw ix kb iz ja jb jc hb bi translated">KNN是一个非参数的，懒惰的学习算法。它的目的是使用一个数据库，其中的数据点被分为几类，以预测一个新的样本点的分类。</p></blockquote><figure class="jd je jf jg fd ji er es paragraph-image"><div class="er es kc"><img src="../Images/b09729660678ae7c4e8943f6b897d40b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1048/format:webp/1*HLtBlJpZrfpH7IG3HIJBcQ.png"/></div></figure><ol class=""><li id="3e05" class="kd ke hi ih b ii ij im in iq kf iu kg iy kh jc ki kj kk kl bi translated">KNN算法建立模型的第一步是在生成训练和测试数据之前处理数据并对其进行预处理。</li><li id="0a8f" class="kd ke hi ih b ii km im kn iq ko iu kp iy kq jc ki kj kk kl bi translated">选择<strong class="ih hj"> k </strong>非常关键——k值小意味着噪声对结果的影响更大。较大的值会导致计算开销很大，并且违背了KNN背后的基本原理(相邻的点可能具有相似的密度或类)。</li></ol><p id="831b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">选择k的一种简单方法是设置k = n^(1/2).</p><p id="c573" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这在很大程度上取决于你的个人情况，有时最好是浏览一下k的每个可能值，然后自己决定。”</p><figure class="jd je jf jg fd ji er es paragraph-image"><div class="er es kr"><img src="../Images/82b1e641b1b64991822d3ccf9705d541.png" data-original-src="https://miro.medium.com/v2/resize:fit:654/format:webp/1*o0lua-fxEAZDCrnkn7JuXA.png"/></div></figure><p id="1402" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当我们将数据记录绘制到数学空间中时，基于分类，我们将得到如图所示的数据。在这里，圆和三角形是两种不同的记录。</p><p id="187f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在使用KNN，当我们在数学空间中提出一个新的数据点时，它将首先计算已经存在的数据点和在数学空间中引入的新数据点之间的距离，以找到k个相似的数据实例。</p><p id="0ec6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jy">为了更好地理解…..</em> <br/>假设经过观察和处理数据，我们得出k值为6，那么使用KNN算法这个新的数据点将会找到6个最近或最短的数据点。</p><figure class="jd je jf jg fd ji er es paragraph-image"><div class="er es ks"><img src="../Images/1cc9b4d6bea75575c5c15e3bd6805023.png" data-original-src="https://miro.medium.com/v2/resize:fit:670/format:webp/1*a3zkJeciUcVlreJV13AfpA.png"/></div><figcaption class="kt ku et er es kv kw bd b be z dx translated">菱形是新的数据点</figcaption></figure><p id="f921" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了计算数学空间中两个数据点之间的距离，我们有不同的距离计算公式:</p><div class="jd je jf jg fd ab cb"><figure class="jh ji kx jk jl jm jn paragraph-image"><img src="../Images/5543210843e63a128cfa1bba9672d64d.png" data-original-src="https://miro.medium.com/v2/resize:fit:680/format:webp/1*QPaNPgT7-XS9qm52AUdy9A.png"/></figure><figure class="jh ji ky jk jl jm jn paragraph-image"><img src="../Images/1b4f6a1ff01cd2930f1fc0cb939a01be.png" data-original-src="https://miro.medium.com/v2/resize:fit:634/format:webp/1*f9I_8OcAXuLSLsRJvnccjA.png"/></figure></div><p id="01a4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一旦我们获得了k个最近邻，新的数据点将使用最近邻的类别标签来确定未知记录/数据的类别标签。<br/>这是通过在k个最近邻居之间进行<strong class="ih hj">多数投票</strong>来完成的。</p><figure class="jd je jf jg fd ji er es paragraph-image"><div class="er es kz"><img src="../Images/70abd3e508357687338a41e9376032eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*dbwgKi7A8oHC1i-Su355eg.gif"/></div></figure><p id="6ae0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这里。gif动画中，我们将k值设为3，在找到新数据点的最近邻居后，新记录将倾向于基于多数投票转移到三角形类，因为三角形数据记录更多地出现在k最近半径中。</p><p id="b87e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">KNN被称为<strong class="ih hj">懒惰算法</strong>，因为它不从训练数据中学习判别函数，而是“记忆”训练数据集。</p><p id="9779" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">例如，逻辑回归算法在训练期间学习其模型权重(参数)。相比之下，K-NN没有训练时间。虽然这听起来非常方便，但是这种属性不是没有代价的:K-NN中的“预测”步骤相对来说是很昂贵的！每次我们想要做一个预测，K-NN在整个训练集中搜索最近的邻居！</p><p id="ee98" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">姑且代号:</strong><br/><em class="jy">【KNN】属于监督学习算法家族。非正式地说，这意味着我们给定了一个由训练观察值(X，Y)组成的带标签的数据集，并且想要捕捉X和Y之间的关系。更正式地说，我们的目标是学习一个函数h:X→Y，以便给定一个看不见的观察值X，h(x)可以自信地预测相应的输出Y。"</em></p><ul class=""><li id="614a" class="kd ke hi ih b ii ij im in iq kf iu kg iy kh jc la kj kk kl bi translated">首先，我们需要获得数据读取、数据预处理和数据可视化所需的所有必要的库。</li><li id="1bdb" class="kd ke hi ih b ii km im kn iq ko iu kp iy kq jc la kj kk kl bi translated">现在，数据已准备好用于构建机器学习模型，让我们现在将数据分为训练数据和测试数据。</li></ul><figure class="jd je jf jg fd ji er es paragraph-image"><div class="er es lb"><img src="../Images/27b76935f7ba04153ca742cdac2b9bc6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1364/format:webp/1*vdw7ktfj0XW8wJjt0FOfzw.png"/></div></figure><ul class=""><li id="1233" class="kd ke hi ih b ii ij im in iq kf iu kg iy kh jc la kj kk kl bi translated">用不同的k值建立模型，检验最佳的最优值。</li><li id="1527" class="kd ke hi ih b ii km im kn iq ko iu kp iy kq jc la kj kk kl bi translated">检查交叉验证的错误分类误差vs k。</li></ul><div class="jd je jf jg fd ab cb"><figure class="jh ji lc jk jl jm jn paragraph-image"><img src="../Images/83dd8696fcce50ef55e2f6b691fb2f1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:906/format:webp/1*hAuzdvQE7tcJJa17Mr6n9Q.png"/></figure><figure class="jh ji ld jk jl jm jn paragraph-image"><img src="../Images/2ca09d82e4cffb80d31ebb338ec67e7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:802/format:webp/1*StRt6hJzaSngI0IKz39QDA.png"/></figure></div><h2 id="8fcf" class="le lf hi bd lg lh li lj lk ll lm ln lo iq lp lq lr iu ls lt lu iy lv lw lx ly bi translated">在这里找到Python代码<a class="ae lz" href="https://github.com/slsarath/Machine-Learning/tree/master/KNearestNeighbor" rel="noopener ugc nofollow" target="_blank"/></h2><p id="554f" class="pw-post-body-paragraph if ig hi ih b ii ma ik il im mb io ip iq mc is it iu md iw ix iy me ja jb jc hb bi translated">谢谢大家！<br/>保持支持</p></div></div>    
</body>
</html>