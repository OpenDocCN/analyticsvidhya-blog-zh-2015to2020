<html>
<head>
<title>Clustering ||Why and When||Hands-On ||Conclude</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">聚类| |原因和时间| |动手| |总结</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/clustering-why-and-when-hands-on-conclude-7c7c594f86c4?source=collection_archive---------13-----------------------#2020-12-03">https://medium.com/analytics-vidhya/clustering-why-and-when-hands-on-conclude-7c7c594f86c4?source=collection_archive---------13-----------------------#2020-12-03</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="3629" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">建设性的、有效的、有益的、结论性的、明确的、</em>等。这样的单词是单词<strong class="ih hj">的同义词</strong>。现在如果有人让你把这些单词放在其中一个袋子里(<strong class="ih hj">正面或反面</strong>，你会选择哪个？</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="jj jk l"/></div></figure><p id="43fb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">正右！。你会把写有这些字的包叫什么？<strong class="ih hj">单词群</strong>与<strong class="ih hj"> <em class="jd">重要性相同/词根相同/甚至来源相同，</em> </strong>这就是我们有聚类概念和形成聚类的地方。。</p><p id="187e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果上面的解释不清楚，让我说得更天真/正式些:<strong class="ih hj">将动作电影组合在一个播放列表中，将所有不同类型的牙膏放在一个部分，然后根据价格/大小将它们分开，将不同类型的动物归为一个种类</strong>(例如猫家族)。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jm jn di jo bf jp"><div class="er es jl"><img src="../Images/dd1e411e244dbb4a1c57aa44c73edd02.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gB1nBSPIlqZSHukH3E93Ng.jpeg"/></div></div><figcaption class="js jt et er es ju jv bd b be z dx translated">猫科动物</figcaption></figure><blockquote class="jw jx jy"><p id="6d2f" class="if ig jd ih b ii ij ik il im in io ip jz ir is it ka iv iw ix kb iz ja jb jc hb bi translated">聚类的任务是将人群或数据点分成不同数量的组，使得同一组中的<strong class="ih hj">数据点比其他组中的数据点更类似于同一组中的其他数据点。</strong>简而言之，<strong class="ih hj"> <em class="hi">目的是将具有相似特征的群体分离出来，并分配到聚类中。</em> </strong> <em class="hi">聚类的应用:</em></p></blockquote><ul class=""><li id="7c26" class="kc kd hi ih b ii ij im in iq ke iu kf iy kg jc kh ki kj kk bi translated">客户细分</li><li id="893f" class="kc kd hi ih b ii kl im km iq kn iu ko iy kp jc kh ki kj kk bi translated">数据分析</li><li id="a340" class="kc kd hi ih b ii kl im km iq kn iu ko iy kp jc kh ki kj kk bi translated">可用作<strong class="ih hj">降维技术</strong></li><li id="2a7c" class="kc kd hi ih b ii kl im km iq kn iu ko iy kp jc kh ki kj kk bi translated">离群点检测</li><li id="4e60" class="kc kd hi ih b ii kl im km iq kn iu ko iy kp jc kh ki kj kk bi translated">搜索引擎和分割图像。</li></ul><p id="b861" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，让我们从业务角度来理解集群。</p><p id="9824" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在<strong class="ih hj">商业智能</strong>中，<em class="jd">聚类可以用来将大量的客户组织成组，其中一个组内的客户具有很强的相似特征。</em>这有助于加强客户关系管理的业务战略的发展。而且，考虑一个有大量项目的顾问公司。为了改进项目管理，可以应用聚类来根据相似性将项目划分为不同的类别，以便可以有效地进行项目审计和诊断(以改进项目交付和成果)。</p></div><div class="ab cl kq kr gp ks" role="separator"><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv"/></div><div class="hb hc hd he hf"><h1 id="4168" class="kx ky hi bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">聚类的类型</h1><p id="9293" class="pw-post-body-paragraph if ig hi ih b ii lv ik il im lw io ip iq lx is it iu ly iw ix iy lz ja jb jc hb bi translated">为了理解聚类的类型，理解我们如何判断一个聚类是合适的是很重要的。</p><ul class=""><li id="bacc" class="kc kd hi ih b ii ij im in iq ke iu kf iy kg jc kh ki kj kk bi translated">高<strong class="ih hj"> <em class="jd">类内</em> </strong>相似度</li><li id="728a" class="kc kd hi ih b ii kl im km iq kn iu ko iy kp jc kh ki kj kk bi translated">●<strong class="ih hj"><em class="jd">类间</em> </strong>相似度</li></ul><p id="b023" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这意味着，为了获得良好的聚类结果，<strong class="ih hj">类内距离必须高，类间距离必须低。</strong></p><p id="a5a9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jd">类内</em> </strong>:</p><p id="3973" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">聚类内被定义为同一聚类中的数据点之间的距离。</p><p id="1366" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jd">课间:</em> </strong></p><p id="7a09" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">类间是属于两个不同聚类的数据点之间的距离。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ma"><img src="../Images/00c8db50ef1ac042ba274fd80eea16d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1268/format:webp/1*pDFDafJ6UlPaLmMn8rDNvQ.png"/></div><figcaption class="js jt et er es ju jv bd b be z dx translated">叙述</figcaption></figure><ol class=""><li id="b983" class="kc kd hi ih b ii ij im in iq ke iu kf iy kg jc mb ki kj kk bi translated"><em class="jd">软聚类</em>:数据点可以共享/属于<strong class="ih hj">一个或多个聚类</strong>的技术。</li><li id="1c1c" class="kc kd hi ih b ii kl im km iq kn iu ko iy kp jc mb ki kj kk bi translated"><em class="jd">硬聚类</em>:每一个数据点/对象只属于<strong class="ih hj">一个聚类</strong>的技术。将每个实例分配给一个集群。</li></ol><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jm jn di jo bf jp"><div class="er es mc"><img src="../Images/b76a86013ebf4be21421ba9e7601c1ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G0ZMEt-AZiDopeeF4t_dHw.png"/></div></div><figcaption class="js jt et er es ju jv bd b be z dx translated">硬集群与软集群</figcaption></figure><p id="069f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">3.<em class="jd">层次聚类</em>:使用<strong class="ih hj"> k-means 聚类</strong>的一个主要考虑是预先通过<strong class="ih hj">剪影评分或肘曲线法</strong>决定 k 的值。层次聚类没有这种限制。这里使用<strong class="ih hj">链接</strong>的概念将多个子聚类合并成一个聚类，直到所有点都成为一个聚类的一部分。有两种类型/方法可以执行层次聚类<strong class="ih hj"> <em class="jd">凝聚(自下而上)和分裂(自上而下)。</em>T19】</strong></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es md"><img src="../Images/9d15a4203db9a43bbef9d882f1f20ba5.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*JSL--bXl0OXLiGJR8qHb_g.png"/></div><figcaption class="js jt et er es ju jv bd b be z dx translated">凝聚层次聚类</figcaption></figure></div><div class="ab cl kq kr gp ks" role="separator"><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv"/></div><div class="hb hc hd he hf"><h1 id="f735" class="kx ky hi bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">让我们来谈谈剪影得分，肘部曲线，K-Means 和我们将要做的动手操作！</h1><p id="eb12" class="pw-post-body-paragraph if ig hi ih b ii lv ik il im lw io ip iq lx is it iu ly iw ix iy lz ja jb jc hb bi translated">随便看看下面，<strong class="ih hj">无监督聚类算法</strong>有多少种不同的类型和方法，以及什么时候使用场景:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es me"><img src="../Images/00c248d7f2dac19d75303902f182e8b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1192/format:webp/1*GRhyBFU4c6WcSb5Ju60QTA.jpeg"/></div><figcaption class="js jt et er es ju jv bd b be z dx translated">集群路线图！</figcaption></figure><p id="2657" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">剪影得分</strong>:剪影分析或剪影系数是一个数据点与自身聚类(<strong class="ih hj"><em class="jd"/></strong>)相比与其他聚类(<strong class="ih hj"><em class="jd"/></strong>)相似程度的度量。所以为了计算<em class="jd">轮廓度量</em>，我们需要比较两个度量，即<em class="jd"> a(i) </em>和<em class="jd"> b(i) </em>，其中</p><ul class=""><li id="83d7" class="kc kd hi ih b ii ij im in iq ke iu kf iy kg jc kh ki kj kk bi translated"><strong class="ih hj"><em class="jd"/></strong><em class="jd">a(I)是离自己星团的平均距离(</em><strong class="ih hj"/><em class="jd">)</em></li><li id="2323" class="kc kd hi ih b ii kl im km iq kn iu ko iy kp jc kh ki kj kk bi translated"><strong class="ih hj"><em class="jd">(I)</em></strong><em class="jd">b 是离最近邻簇的平均距离(</em><strong class="ih hj"/>)</li></ul><p id="40c1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在对于每一个<strong class="ih hj">数据点(i) </strong>，<em class="jd"> a(i) </em> <strong class="ih hj">应该尽可能小</strong>，<em class="jd"> b(i) </em> <strong class="ih hj">应该尽可能大。</strong></p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jm jn di jo bf jp"><div class="er es mf"><img src="../Images/5b72cc710c1be95ce342a9fee57c5ca7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cV-PCaIexOtHTC9_yftG9g.jpeg"/></div></div><figcaption class="js jt et er es ju jv bd b be z dx translated">剪影公式</figcaption></figure><ul class=""><li id="7a5b" class="kc kd hi ih b ii ij im in iq ke iu kf iy kg jc kh ki kj kk bi translated">轮廓分数范围的值在<strong class="ih hj"> -1 到+1 之间。</strong></li><li id="ad46" class="kc kd hi ih b ii kl im km iq kn iu ko iy kp jc kh ki kj kk bi translated"><strong class="ih hj">接近+1 的分数表示该数据点与聚类中的其他数据点非常相似。</strong></li><li id="d10f" class="kc kd hi ih b ii kl im km iq kn iu ko iy kp jc kh ki kj kk bi translated"><strong class="ih hj">分数越接近-1 表示该数据点与其聚类中的数据点不相似。</strong></li></ul><p id="cead" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">肘形曲线:</strong>求样本距各自聚类中心距离的平方和<strong class="ih hj">。要从 Elbow-Method 中选择最佳聚类数:</strong></p><ul class=""><li id="2bcb" class="kc kd hi ih b ii ij im in iq ke iu kf iy kg jc kh ki kj kk bi translated">针对不同的 k 值计算聚类算法(例如，k 均值聚类)。例如，通过将 k 从 1 变化到 10 个聚类。</li><li id="1f0e" class="kc kd hi ih b ii kl im km iq kn iu ko iy kp jc kh ki kj kk bi translated">对于每个 k，计算总的类内平方和(wss)。</li><li id="97d6" class="kc kd hi ih b ii kl im km iq kn iu ko iy kp jc kh ki kj kk bi translated">根据簇数 k 绘制 wss 曲线。</li><li id="f9a7" class="kc kd hi ih b ii kl im km iq kn iu ko iy kp jc kh ki kj kk bi translated">图中弯曲(拐点)的位置通常被认为是适当聚类数的指示。</li></ul><p id="08b6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">嗯，以上两种方法都是用于<strong class="ih hj">在<em class="jd"> K-MEANS 聚类算法中选择能够形成的最佳簇数！</em> </strong></p><p id="d5f4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">好了，到目前为止我们已经看到了，</p><ul class=""><li id="ec86" class="kc kd hi ih b ii ij im in iq ke iu kf iy kg jc kh ki kj kk bi translated">什么是聚类，什么时候应该进行聚类！</li><li id="6462" class="kc kd hi ih b ii kl im km iq kn iu ko iy kp jc kh ki kj kk bi translated">不同类型的聚类。</li><li id="0c87" class="kc kd hi ih b ii kl im km iq kn iu ko iy kp jc kh ki kj kk bi translated">如何才能选择<strong class="ih hj">最优聚类数</strong>进行聚类。</li></ul><p id="f1cd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，让我们看看<strong class="ih hj">聚类方法</strong>中的一种，以及我们如何继续实现它。</p><p id="523d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> K-Means 聚类:</strong>算法需要找到值彼此相似的数据点，因此这些点将属于同一个聚类。</p><blockquote class="jw jx jy"><p id="a551" class="if ig jd ih b ii ij ik il im in io ip jz ir is it ka iv iw ix kb iz ja jb jc hb bi translated">任何聚类算法都是通过一种叫做<strong class="ih hj"> <em class="hi">【距离度量】</em> </strong>的方法来实现的。在<strong class="ih hj"> K-Means </strong>聚类中使用的距离度量被称为<strong class="ih hj"> <em class="hi">“欧氏距离度量”。</em> </strong></p></blockquote><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mg"><img src="../Images/282e87eebd076b084bb54854acad1ed4.png" data-original-src="https://miro.medium.com/v2/resize:fit:968/format:webp/1*Tt6a01VofqCLd8YGJvgNKA.png"/></div><figcaption class="js jt et er es ju jv bd b be z dx translated"><strong class="bd kz"> d </strong>是两点之间的<strong class="bd kz">欧氏距离</strong></figcaption></figure><p id="53ae" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">大多数情况下，当我们执行聚类时，我们没有标签和质心。那么我们该如何进行呢？</p><ol class=""><li id="45ae" class="kc kd hi ih b ii ij im in iq ke iu kf iy kg jc mb ki kj kk bi translated">我们从随机放置<strong class="ih hj">质心</strong>开始。</li><li id="06e3" class="kc kd hi ih b ii kl im km iq kn iu ko iy kp jc mb ki kj kk bi translated">然后根据<strong class="ih hj">欧氏距离</strong>将实例标记到一个簇中，并更新质心，<strong class="ih hj">标记实例，更新质心，标记实例，更新质心</strong>，直到质心停止移动，即停止获得新的坐标。</li></ol><p id="36e6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">该算法保证在有限步内收敛。就是这样，在仅仅两步<strong class="ih hj">分配和优化</strong>中，算法迭代收敛。算法的内部循环迭代 2 个步骤:</p><ul class=""><li id="6c03" class="kc kd hi ih b ii ij im in iq ke iu kf iy kg jc kh ki kj kk bi translated">将每个观察值<strong class="ih hj"> X(i) </strong>分配到最近的群集质心。</li><li id="56b6" class="kc kd hi ih b ii kl im km iq kn iu ko iy kp jc kh ki kj kk bi translated">将每个质心更新为分配给它的点的平均值。</li></ul><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="mh jk l"/></div><figcaption class="js jt et er es ju jv bd b be z dx translated">比较每簇的<strong class="ak">平方和并显示<strong class="ak">簇形成的 Gif 表示！</strong></strong></figcaption></figure><p id="501a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果仍有任何疑问，可以参考 Stat-Quest <a class="ae mi" href="https://www.youtube.com/watch?v=4b5d3muPQmA&amp;feature=youtu.be" rel="noopener ugc nofollow" target="_blank">集群视频</a>，以获得更好的理解和更多的清晰度。这家伙真的解释得很好，唱得也很好！😛而如果你想玩<strong class="ih hj"> k-means </strong>，<a class="ae mi" href="https://www.naftaliharris.com/blog/visualizing-k-means-clustering/" rel="noopener ugc nofollow" target="_blank">这个</a>可以帮到你！</p><p id="e6d8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">终于，我们到了，我也渴望到达的地方！。</p></div><div class="ab cl kq kr gp ks" role="separator"><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv"/></div><div class="hb hc hd he hf"><h1 id="75fd" class="kx ky hi bd kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls lt lu bi translated">把手举起来。</h1><p id="68c2" class="pw-post-body-paragraph if ig hi ih b ii lv ik il im lw io ip iq lx is it iu ly iw ix iy lz ja jb jc hb bi translated">问题陈述:<strong class="ih hj"> <em class="jd">使用聚类方法论进行词语聚类</em> </strong>。因此，我们有了<strong class="ih hj">新闻推文的数据集，我们需要聚类出相似的词</strong>。<em class="jd">我们如何继续这样做？</em></p><p id="525b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我引用一些关于数据集和方法的事情:</p><ul class=""><li id="0eef" class="kc kd hi ih b ii ij im in iq ke iu kf iy kg jc kh ki kj kk bi translated">它的功能包括:<strong class="ih hj"> tweet_id、tweet 的日期和时间以及 tweet_text </strong>。这些新闻推文是从 UCI 的 BBC 健康推文中获得的。总共有大约<strong class="ih hj"> 3929 </strong>条推文，我们不会从整个数据中丢失任何值。</li><li id="6e00" class="kc kd hi ih b ii kl im km iq kn iu ko iy kp jc kh ki kj kk bi translated">现在，由于我们将对特征<strong class="ih hj"> tweet_text </strong>进行聚类，我们删除了特征<strong class="ih hj">日期和时间|| tweet_id </strong>。</li><li id="6b47" class="kc kd hi ih b ii kl im km iq kn iu ko iy kp jc kh ki kj kk bi translated">接下来，由于这是列中的文本数据，我们将执行一些基本的<strong class="ih hj">文本清理和文本处理</strong>步骤。</li><li id="8ff1" class="kc kd hi ih b ii kl im km iq kn iu ko iy kp jc kh ki kj kk bi translated">然后经过清洗和处理，我们将从<strong class="ih hj"> tweet_text </strong>特征中形成一个热编码词的<strong class="ih hj"> tf-idf 词汇表</strong>。因为聚类是在数值上执行的，所以我们需要构建一个单词词汇表并转换它们。</li><li id="c3c1" class="kc kd hi ih b ii kl im km iq kn iu ko iy kp jc kh ki kj kk bi translated">然后使用<strong class="ih hj">肘曲线法</strong>并在<strong class="ih hj">黄砖</strong>库的帮助下，我们将找出<strong class="ih hj">簇</strong>的最佳数目，并将其传递给最终的聚类模型。<strong class="ih hj">黄砖</strong>库帮助我们在每次编译模型/脚本时传递最优的<strong class="ih hj"> <em class="jd"> k </em> </strong>，因此我们不需要硬编码该值。</li></ul><p id="c308" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最终的结果不是很精确，因为它是无监督的学习，并且我们在<strong class="ih hj">范围 2 到 10 </strong>之间寻找聚类，否则，由于句子的语言属性，相同的单词可能出现在 2 个不同的聚类中。</p><h2 id="1fd7" class="mj ky hi bd kz mk ml mm ld mn mo mp lh iq mq mr ll iu ms mt lp iy mu mv lt mw bi translated">阅读数据集并探索一下:</h2><pre class="je jf jg jh fd mx my mz na aw nb bi"><span id="e4e0" class="mj ky hi my b fi nc nd l ne nf">data = pd.read_csv('Health-Tweets/bbchealth.txt', sep="|", header=None)<br/>data.columns = ["tweet_id", "date_time", "tweet_text"]<br/>data.head()</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jm jn di jo bf jp"><div class="er es ng"><img src="../Images/58c5de2ff87523d48e9424b0f025ff1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0P8qlZvfVWssBcmmFzMj0Q.png"/></div></div></figure><pre class="je jf jg jh fd mx my mz na aw nb bi"><span id="adcf" class="mj ky hi my b fi nc nd l ne nf">data.info() # Checking columns and number of entries<br/>print('-------------------------')<br/>print(round(data.isnull().sum()/len(data),2)) # Checking for any null values</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es nh"><img src="../Images/f43e0787db77ec813473a4177c91eb7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:708/format:webp/1*U7RBjMwmfL0wXi7zWW02Lw.png"/></div></figure><p id="b6a8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里我们看到了行和列名的总数。此外，与提到的特征/列相对应的行都不是空的。接下来，因为我们只需要<strong class="ih hj">的 tweet_text </strong>，我们删除剩余的 2 列！</p><pre class="je jf jg jh fd mx my mz na aw nb bi"><span id="167b" class="mj ky hi my b fi nc nd l ne nf">X_train = data.drop(columns=['tweet_id','date_time']).reset_index(drop=True)<br/>X_train.head()<br/>print(X_train.shape) #(3929, 1)</span></pre><h2 id="58b6" class="mj ky hi bd kz mk ml mm ld mn mo mp lh iq mq mr ll iu ms mt lp iy mu mv lt mw bi translated">现在，处理我们功能中的文本:</h2><p id="a078" class="pw-post-body-paragraph if ig hi ih b ii lv ik il im lw io ip iq lx is it iu ly iw ix iy lz ja jb jc hb bi translated">首先，我们只是做一个普通的正则表达式过滤器来删除我们 tweets 中存在的所有 href 链接，然后我们建立一个 T2 函数，当我们开始形成 tf-idf 词汇表时，它被用作 T4 分析器。这有助于逐句应用功能<strong class="ih hj">。</strong></p><blockquote class="jw jx jy"><p id="4941" class="if ig jd ih b ii ij ik il im in io ip jz ir is it ka iv iw ix kb iz ja jb jc hb bi translated">我们的函数<strong class="ih hj">接受一个文本字符串，然后执行以下操作:</strong> <br/> 1。删除所有标点符号<br/> 2。移除所有停用字<br/> 3。将清除的文本作为单词列表返回<br/> 4。删除单词</p></blockquote><pre class="je jf jg jh fd mx my mz na aw nb bi"><span id="40fb" class="mj ky hi my b fi nc nd l ne nf">X_train['tweet_text'] = X_train['tweet_text'].apply(lambda x: re.split('https:\/\/.*', str(x))[0])<br/>X_train['tweet_text'] = X_train['tweet_text'].apply(lambda x: re.split('http:\/\/.*', str(x))[0])</span><span id="6ca3" class="mj ky hi my b fi ni nd l ne nf"># Our analyser function:<br/>def text_process(text):<br/>    '''<br/>    Takes in a string of text, then performs the following:<br/>    1. Remove all punctuation<br/>    2. Remove all stopwords<br/>    3. Return the cleaned text as a list of words<br/>    4. Remove words<br/>    '''<br/>    stemmer = WordNetLemmatizer()<br/>    nopunc = [char for char in text if char not in string.punctuation]<br/>    nopunc = ''.join([i for i in nopunc if not i.isdigit()])<br/>    nopunc =  [word.lower() for word in nopunc.split() if word not in stopwords.words('english')]<br/>    return [stemmer.lemmatize(word) for word in nopunc]</span></pre><p id="49c5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">矢量化无非是创建一个称为词汇的单词向量。<br/> <strong class="ih hj"> <em class="jd"> TFIDF 矢量器用于创建一个词汇表。TFIDF 是一个单词在文档中的出现频率乘以该单词在整个语料库中的独特性。ngram_range 参数:这将有助于根据需求创建一个、两个或更多单词词汇表。</em> </strong></p><pre class="je jf jg jh fd mx my mz na aw nb bi"><span id="af39" class="mj ky hi my b fi nc nd l ne nf">tfidfconvert = TfidfVectorizer(analyzer=text_process,ngram_range=(1,3)).fit(X_train.tweet_text)</span><span id="f275" class="mj ky hi my b fi ni nd l ne nf">X_transformed=tfidfconvert.transform(X_train.tweet_text)</span><span id="7965" class="mj ky hi my b fi ni nd l ne nf"># Checking the length of the Vocabulary Created!<br/>len(tfidfconvert.vocabulary_) # 3933</span></pre><h2 id="b8c8" class="mj ky hi bd kz mk ml mm ld mn mo mp lh iq mq mr ll iu ms mt lp iy mu mv lt mw bi translated">使用肘形曲线决定聚类数！：</h2><pre class="je jf jg jh fd mx my mz na aw nb bi"><span id="2ef8" class="mj ky hi my b fi nc nd l ne nf">Sum_of_squared_distances = []<br/>K = range(1,20)<br/>for k in K:<br/>    km = KMeans(n_clusters=k)<br/>    km = km.fit(X_transformed)<br/>    Sum_of_squared_distances.append(km.inertia_)</span><span id="01cc" class="mj ky hi my b fi ni nd l ne nf">import matplotlib.pyplot as plt</span><span id="2e72" class="mj ky hi my b fi ni nd l ne nf">plt.plot(K, Sum_of_squared_distances, 'bx-')<br/>plt.xlabel('k')<br/>plt.ylabel('Sum_of_squared_distances')<br/>plt.title('Elbow Method For Optimal k')<br/>plt.show()</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es nj"><img src="../Images/c3124bec8ab5ae458cfb6d68966327ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:946/format:webp/1*1Wmjpw_WUWax-lAqVJtOxA.png"/></div><figcaption class="js jt et er es ju jv bd b be z dx translated">正常肘曲线法</figcaption></figure><p id="306b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">但是，让我给你展示一下<strong class="ih hj">黄砖库的魔法:</strong></p><pre class="je jf jg jh fd mx my mz na aw nb bi"><span id="8348" class="mj ky hi my b fi nc nd l ne nf">from yellowbrick.cluster import KElbowVisualizer<br/>from yellowbrick.cluster.elbow import kelbow_visualizer<br/>model = KMeans()<br/>visualizer = KElbowVisualizer(model, k=(1,20))<br/># visualizer = kelbow_visualizer(KMeans(random_state=4), X_transformed, k=(2,50))<br/>visualizer.fit(X_transformed)        # Fit the data to the visualizer<br/>visualizer.show();        # Finalize and render the figure</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es nk"><img src="../Images/f65aca2ec1bd4eb6762266f98c073597.png" data-original-src="https://miro.medium.com/v2/resize:fit:1234/format:webp/1*fV9f_GzVCeNA7ijqeupqBw.png"/></div><figcaption class="js jt et er es ju jv bd b be z dx translated">黄砖弯头曲线图</figcaption></figure><p id="69e4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">只要看看它，多么漂亮，它看起来！我们可以看到所附的分数和 k 处的<strong class="ih hj">弯头</strong>值。对于每个集群计算，它甚至还有时间轴<strong class="ih hj">和时间轴</strong>！接下来，事情是:</p><pre class="je jf jg jh fd mx my mz na aw nb bi"><span id="a325" class="mj ky hi my b fi nc nd l ne nf">optimal_k = visualizer.elbow_value_<br/>print('Optimal K found is:', optimal_k) # 9 </span></pre><p id="9023" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用 yellowbrick 实现中的<strong class="ih hj"> elbow_value_ </strong>方法，<strong class="ih hj">我们可以自动直接获取最佳 k 值</strong>，这将用于最终建模。</p><h2 id="c1a9" class="mj ky hi bd kz mk ml mm ld mn mo mp lh iq mq mr ll iu ms mt lp iy mu mv lt mw bi translated">建模:</h2><p id="a701" class="pw-post-body-paragraph if ig hi ih b ii lv ik il im lw io ip iq lx is it iu ly iw ix iy lz ja jb jc hb bi translated">现在，此时此刻，我们得到的最佳集群数是第 9 轮，因此同样的集群数将被向前传递。</p><pre class="je jf jg jh fd mx my mz na aw nb bi"><span id="a3bd" class="mj ky hi my b fi nc nd l ne nf"># Clustering the training sentences with K-means technique</span><span id="1e35" class="mj ky hi my b fi ni nd l ne nf">modelkmeans = KMeans(n_clusters=optimal_k, init='k-means++', n_init=100)<br/>modelkmeans.fit(X_transformed)</span></pre><p id="a596" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在我们形成模型后，我们也将可视化一些数据点来获得相同的感觉。</p><pre class="je jf jg jh fd mx my mz na aw nb bi"><span id="b2d7" class="mj ky hi my b fi nc nd l ne nf">pca = PCA(n_components=2, random_state=42)<br/>reduced_features = pca.fit_transform(X_transformed.toarray())</span><span id="1e72" class="mj ky hi my b fi ni nd l ne nf"># reduce the cluster centers to 2D<br/>reduced_cluster_centers = pca.transform(modelkmeans.cluster_centers_)</span><span id="bb52" class="mj ky hi my b fi ni nd l ne nf">plt.scatter(reduced_features[:,0], reduced_features[:,1], c=modelkmeans.predict(X_transformed));<br/>plt.scatter(reduced_cluster_centers[:, 0], reduced_cluster_centers[:,1], marker='x', s=150, c='b');</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es nl"><img src="../Images/afb2f1a7e58156adeb70f95f1512d099.png" data-original-src="https://miro.medium.com/v2/resize:fit:1100/format:webp/1*fom-aNe5SNcvWGzqJMppiA.png"/></div></figure><p id="04a5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">十字是模型选择的<strong class="ih hj">形心</strong>。最终的聚类形状是高度<strong class="ih hj">不均匀的</strong>，因此，如果我们选择更多数量的聚类，我们可能会得到更多<strong class="ih hj">均匀的聚类</strong>。接下来，我们按照我们的<strong class="ih hj"> <em class="jd">数据科学项目</em> </strong>方法，在同一数据集上也尝试了<strong class="ih hj"> MiniBatch KMEANS </strong>算法！</p><h2 id="f599" class="mj ky hi bd kz mk ml mm ld mn mo mp lh iq mq mr ll iu ms mt lp iy mu mv lt mw bi translated">小批量意味着:</h2><p id="7c73" class="pw-post-body-paragraph if ig hi ih b ii lv ik il im lw io ip iq lx is it iu ly iw ix iy lz ja jb jc hb bi translated">现在，<em class="jd"> Mini Batch KMEANS </em>只是对传统 KMEANS 算法的改进。这里，算法能够使用<strong class="ih hj"> <em class="jd">小批量</em> </strong>，而不是在每次迭代中使用完整的数据集，在每次迭代中稍微移动质心。</p><p id="d4bc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这将算法的速度提高了 3 到 4 倍，使得对不适合内存的大数据集进行聚类成为可能。作为我们实验的一部分，我们打算使用相同的方法并观察最终的聚类结果。</p><pre class="je jf jg jh fd mx my mz na aw nb bi"><span id="93b3" class="mj ky hi my b fi nc nd l ne nf">clusters = MiniBatchKMeans(n_clusters=optimal_k, init_size=1024, batch_size=2048, random_state=20).fit_predict(X_transformed)</span><span id="9911" class="mj ky hi my b fi ni nd l ne nf"># Looking at the Words Clustered out finally<br/>def get_top_keywords(data, clusters, labels, n_terms):<br/>    df = pd.DataFrame(data.todense()).groupby(clusters).mean()<br/>    final_df = pd.DataFrame(columns=['Cluster','Cluster Words'])<br/>    for i,r in df.iterrows():<br/>        print('\nCluster {}'.format(i))<br/>        print(','.join([labels[t] for t in np.argsort(r)[-n_terms:]]))<br/>        x = i<br/>        y = [labels[t] for t in np.argsort(r)[-n_terms:]]<br/>        final_df = final_df.append({'Cluster' : x , 'Cluster Words' : y} , ignore_index=True)<br/>    return final_df</span><span id="0626" class="mj ky hi my b fi ni nd l ne nf"># print the top words<br/>final_df = get_top_keywords(X_transformed, clusters, tfidfconvert.get_feature_names(), 15)</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jm jn di jo bf jp"><div class="er es nm"><img src="../Images/03e2ae8e2d33653d0331bfa0babf3bd6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_WYCOQXkvFT50QqVAZVTgQ.png"/></div></div></figure><p id="07bb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">类似地，我们将这个结果累积到一个数据帧中:</p><pre class="je jf jg jh fd mx my mz na aw nb bi"><span id="7f11" class="mj ky hi my b fi nc nd l ne nf">pd.set_option("max_colwidth", None)<br/>final_df.head(20)</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jm jn di jo bf jp"><div class="er es nn"><img src="../Images/c232b19e56845df94b1a193b27fbdd7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-ollozfc3L9bThNzBkawaw.png"/></div></div></figure><h2 id="8a4c" class="mj ky hi bd kz mk ml mm ld mn mo mp lh iq mq mr ll iu ms mt lp iy mu mv lt mw bi translated">结论:</h2><ul class=""><li id="a96e" class="kc kd hi ih b ii lv im lw iq no iu np iy nq jc kh ki kj kk bi translated">因此，我们研究了聚类算法的需求基础。</li><li id="5742" class="kc kd hi ih b ii kl im km iq kn iu ko iy kp jc kh ki kj kk bi translated">不同类型的聚类技术以及<strong class="ih hj"> K 均值和小批量 K 均值</strong>的实现。</li><li id="8044" class="kc kd hi ih b ii kl im km iq kn iu ko iy kp jc kh ki kj kk bi translated">我们甚至探索了一些<strong class="ih hj">文本处理/清理</strong>步骤，这些步骤可以帮助任何需要<strong class="ih hj">清理/处理</strong>文本数据的问题陈述。</li><li id="be36" class="kc kd hi ih b ii kl im km iq kn iu ko iy kp jc kh ki kj kk bi translated">最后，您可以自己探索更多的聚类算法，如:<strong class="ih hj"> DBSCAN、BIRCH、Mean-Shift、Agglomerative、Affinity、Gaussian Mixture </strong>模型。</li></ul><p id="51ce" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我希望这篇文章对读者有所帮助。更多的话题还在路上，如果有什么特别的话题，请在评论区告诉我，一如既往地…… <strong class="ih hj">快乐学习！</strong></p></div><div class="ab cl kq kr gp ks" role="separator"><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv"/></div><div class="hb hc hd he hf"><p id="d1a9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">请通过以下方式联系我:</p><ul class=""><li id="c306" class="kc kd hi ih b ii ij im in iq ke iu kf iy kg jc kh ki kj kk bi translated"><a class="ae mi" href="https://www.linkedin.com/in/atul-mishra-5001/" rel="noopener ugc nofollow" target="_blank">领英</a></li><li id="4c06" class="kc kd hi ih b ii kl im km iq kn iu ko iy kp jc kh ki kj kk bi translated"><a class="ae mi" href="https://github.com/mishra-atul5001" rel="noopener ugc nofollow" target="_blank"> Github </a></li><li id="5b43" class="kc kd hi ih b ii kl im km iq kn iu ko iy kp jc kh ki kj kk bi translated">邮件:<strong class="ih hj">atul.mishra5001@gmail.com</strong></li></ul></div></div>    
</body>
</html>