<html>
<head>
<title>Machine Learning with Kubernetes</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 Kubernetes 进行机器学习</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/machine-learning-with-kubernetes-50dd258a2d5d?source=collection_archive---------4-----------------------#2020-09-24">https://medium.com/analytics-vidhya/machine-learning-with-kubernetes-50dd258a2d5d?source=collection_archive---------4-----------------------#2020-09-24</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/9e01ab5d7daae513d07ad787e24810fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MeWDQY430wBcC8g8KOSnBA.png"/></div></div></figure><p id="ad30" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">随着信息不对称的减少，复杂的模型和算法变得更容易实现和使用，机器学习正在不断发展。像 scikit-learn 这样的 Python 库只需要几行代码(不包括 pre-proc)就可以使用 Random Forrest 这样复杂的高级集成学习技术进行拟合和预测。那么问题是什么给了你优势？</p><p id="d039" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">网上有许多指南和资源可以用来编写这几行代码并准确预测。挑战归结为如何有效和动态地使用 ML。在真实的用例中，我们知道我们不会仅仅使用一个模型来解决一个问题。我们使用数百种组合和优化程序来获得可能的最佳结果。</p><p id="9dd1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">因此，出现了洗钱活动。其目的是促进复杂的机器学习管道和过程。MLOps 是一个非常新的领域，每天都在制定规则和流程。我将在下面添加一些文章的链接，您可以在那里了解更多关于 MLOps 的信息。在本文中，我将举一个机器学习工作流的小例子，展示我们如何在 Kubernetes 集群上高效地部署它。我将使用以下内容:</p><ul class=""><li id="7d0e" class="jo jp hi is b it iu ix iy jb jq jf jr jj js jn jt ju jv jw bi translated">Kubernetes 集群(minikube 也可以工作)</li><li id="d516" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated">南船星座</li><li id="cd7c" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated">AWS S3</li><li id="4fde" class="jo jp hi is b it jx ix jy jb jz jf ka jj kb jn jt ju jv jw bi translated">码头工人</li></ul><p id="6e37" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">请注意，这些安装和设置是本文的先决条件</strong> <strong class="is hj">。</strong></p></div><div class="ab cl kc kd gp ke" role="separator"><span class="kf bw bk kg kh ki"/><span class="kf bw bk kg kh ki"/><span class="kf bw bk kg kh"/></div><div class="hb hc hd he hf"><p id="803d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如前所述，一个复杂的机器学习工作流程有几个阶段。为了节省时间，我们将在一个单独的容器中运行所有这些流程。对于这个小示例，我们将在第一个容器中进行数据预处理，然后在第二个和第三个容器中训练两个不同的模型。</p><h1 id="8674" class="kj kk hi bd kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg bi translated">1.Python 代码</h1><p id="8bd5" class="pw-post-body-paragraph iq ir hi is b it lh iv iw ix li iz ja jb lj jd je jf lk jh ji jj ll jl jm jn hb bi translated">这将分为 3 个脚本，第一个脚本将是数据处理，第二和第三个脚本将是模型训练。</p><p id="ce8c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">注意:</strong>数据需要被托管在某个地方，这样容器才能访问它</p><p id="0d81" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">文件 1:预处理脚本</p><pre class="lm ln lo lp fd lq lr ls lt aw lu bi"><span id="e024" class="lv kk hi lr b fi lw lx l ly lz">import pandas as pd<br/>from sklearn.model_selection import train_test_split</span><span id="22ec" class="lv kk hi lr b fi ma lx l ly lz">#any data i have hosted this <br/>df = pd.read_csv('http://localhost:8000/data/sales.csv')</span><span id="5458" class="lv kk hi lr b fi ma lx l ly lz">#for this small example, I will just remove a column as data preproc<br/>df.drop('size', inplace=True)</span><span id="36d7" class="lv kk hi lr b fi ma lx l ly lz">x = df.drop('sales', axis=1)<br/>y = df['sales']</span><span id="0609" class="lv kk hi lr b fi ma lx l ly lz">x_train, x_test, y_train, y_test = train_test_split(df, test_size=0.3)</span><span id="73a7" class="lv kk hi lr b fi ma lx l ly lz">df.to_csv('x_train.csv')<br/>df.to_csv('x_test.csv')<br/>df.to_csv('y_train.csv')<br/>df.to_csv('y_test.csv')</span></pre><p id="cf14" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">文件 2:随机福里斯特回归</p><pre class="lm ln lo lp fd lq lr ls lt aw lu bi"><span id="b7d3" class="lv kk hi lr b fi lw lx l ly lz">import pandas as pd<br/>from sklearn.ensemble import RandomForestRegressor<br/>from sklearn.metrics import mean_squared_error</span><span id="6b7c" class="lv kk hi lr b fi ma lx l ly lz"># reading the preproc data<br/>x_train = pd.read_csv('x_train.csv')<br/>x_test = pd.read_csv('x_test.csv')  <br/>y_train = pd.read_csv('y_train.csv') <br/>y_test = pd.read_csv('y_test.csv')</span><span id="5f6b" class="lv kk hi lr b fi ma lx l ly lz"># Instantiate model with 1000 decision trees<br/>rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)</span><span id="aa6d" class="lv kk hi lr b fi ma lx l ly lz"># Train the model on training data<br/>rf.fit(x_train, y_train)</span><span id="b6bd" class="lv kk hi lr b fi ma lx l ly lz"># Use the forest's predict method on the test data<br/>predictions = rf.predict(x_test)</span><span id="ead1" class="lv kk hi lr b fi ma lx l ly lz"># Calculate the MSE<br/>mse = mean_squared_error(y_test, predictions)</span><span id="f5b8" class="lv kk hi lr b fi ma lx l ly lz"># Print out the mean absolute error (mse)<br/>print('Mean Absolute Error:', mse)</span></pre><p id="b828" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">文件 3:套索回归</p><pre class="lm ln lo lp fd lq lr ls lt aw lu bi"><span id="2360" class="lv kk hi lr b fi lw lx l ly lz">from sklearn.linear_model import LassoCV<br/>import pandas as pd</span><span id="560c" class="lv kk hi lr b fi ma lx l ly lz"># reading the preproc data<br/>x_train = pd.read_csv('x_train.csv')<br/>x_test = pd.read_csv('x_test.csv')  <br/>y_train = pd.read_csv('y_train.csv') <br/>y_test = pd.read_csv('y_test.csv')</span><span id="f447" class="lv kk hi lr b fi ma lx l ly lz"># initialising and fitting the model<br/>model = LassoCV()<br/>model.fit(x_train, y_train)</span><span id="be85" class="lv kk hi lr b fi ma lx l ly lz"># Use the forest's predict method on the test data<br/>predictions = model.predict(x_test)</span><span id="a5c3" class="lv kk hi lr b fi ma lx l ly lz"># Calculate MSE<br/>mse = mean_squared_error(y_test, predictions)</span><span id="7271" class="lv kk hi lr b fi ma lx l ly lz"># Print out the mean absolute error (mse)<br/>print('Mean Absolute Error:', mse)</span></pre><h1 id="08ac" class="kj kk hi bd kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg bi translated">2.创建图像</h1><p id="1b6a" class="pw-post-body-paragraph iq ir hi is b it lh iv iw ix li iz ja jb lj jd je jf lk jh ji jj ll jl jm jn hb bi translated">一旦我们准备好代码，我们就可以创建图像并将其推送到 docker hub(或任何其他图像存储库)。一个简单的 docker 文件就可以了</p><pre class="lm ln lo lp fd lq lr ls lt aw lu bi"><span id="8e62" class="lv kk hi lr b fi lw lx l ly lz">FROM python3.6</span><span id="be46" class="lv kk hi lr b fi ma lx l ly lz">RUN mkdir codes</span><span id="788b" class="lv kk hi lr b fi ma lx l ly lz">COPY . codes/</span><span id="a537" class="lv kk hi lr b fi ma lx l ly lz">RUN pip3 install -r codes/requirements.txt</span></pre><p id="dd22" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">创建和推送图像</p><pre class="lm ln lo lp fd lq lr ls lt aw lu bi"><span id="343a" class="lv kk hi lr b fi lw lx l ly lz">docker image build -t ml_pipeline .<br/>docker image push ml_pipline</span></pre><h1 id="1788" class="kj kk hi bd kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg bi translated">3.使用 Argo 定义 ml 管道</h1><p id="813a" class="pw-post-body-paragraph iq ir hi is b it lh iv iw ix li iz ja jb lj jd je jf lk jh ji jj ll jl jm jn hb bi translated">您可以使用下面的链接找到在 Kubernetes 集群上安装和设置 Argo 的快速设置指南:</p><div class="mb mc ez fb md me"><a href="https://argoproj.github.io/argo/installation/" rel="noopener  ugc nofollow" target="_blank"><div class="mf ab dw"><div class="mg ab mh cl cj mi"><h2 class="bd hj fi z dy mj ea eb mk ed ef hh bi translated">安装 Argo 工作流 Kubernetes 的工作流引擎</h2><div class="ml l"><h3 class="bd b fi z dy mj ea eb mk ed ef dx translated">编辑描述</h3></div><div class="mm l"><p class="bd b fp z dy mj ea eb mk ed ef dx translated">argoproj.github.io</p></div></div></div></a></div><p id="3f51" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">此外，确保建立一个工件存储库。我使用 AWS S3，但还有许多其他选项可用:</p><div class="mb mc ez fb md me"><a href="https://argoproj.github.io/argo/configure-artifact-repository/" rel="noopener  ugc nofollow" target="_blank"><div class="mf ab dw"><div class="mg ab mh cl cj mi"><h2 class="bd hj fi z dy mj ea eb mk ed ef hh bi translated">配置工件库——Argo 工作流 Kubernetes 的工作流引擎</h2><div class="ml l"><h3 class="bd b fi z dy mj ea eb mk ed ef dx translated">要运行使用工件的 Argo 工作流，您必须配置和使用工件存储库。阿尔戈支持任何 S3…</h3></div><div class="mm l"><p class="bd b fp z dy mj ea eb mk ed ef dx translated">argoproj.github.io</p></div></div></div></a></div><p id="952f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">阿尔戈</strong></p><figure class="lm ln lo lp fd ij er es paragraph-image"><div class="er es mn"><img src="../Images/6b71c06332df01e7fd5b11c3b3e95518.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*NlH2qFvNE8KQwS0HY7d_lw.png"/></div></figure><p id="2421" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Argo 为我们提供了一个强大的工作流引擎，使我们能够实现工作流中的每个步骤，就像 Kubernetes 上的容器一样。Argo 使用 YML 文件来定义和编写管道。然而，有一个更受欢迎的替代阿尔戈被称为 Kubeflow。Kubeflow 使用 Argo 的引擎，并提供 python API 来定义管道。我将在这篇文章中使用 Argo，但在将来也会做一个关于 Kubeflow 的简短教程。</p><p id="5aa5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">让我们开始构建我们的管道，我将把它命名为 pipline.yml</p><pre class="lm ln lo lp fd lq lr ls lt aw lu bi"><span id="0bdb" class="lv kk hi lr b fi lw lx l ly lz"># Our pipeline<br/># We will make a DAG. That will allow us to do pre proc first <br/># and then train models in parallel.<br/>apiVersion: argoproj.io/v1alpha1<br/>kind: Workflow<br/>metadata:<br/>  generateName: ml-pipeline-<br/>spec:<br/>  entrypoint: ml-pipeline<br/>  templates:<br/>  <br/>  # definning the pipeline flow<br/>  - name: ml-pipeline<br/>    dag:<br/>        tasks:<br/>          - name: preprocessing<br/>            template: preproc<br/>          - name: training-rf<br/>            dependencies: [preprocessing]<br/>            template: randomforrest<br/>            arguments:<br/>              artifacts:<br/>              - name: x_train<br/>                from: tasks.preprocessing.outputs.artifacts.x_train<br/>              - name: x_test<br/>                from: tasks.preprocessing.outputs.artifacts.x_test<br/>              - name: y_train<br/>                from: tasks.preprocessing.outputs.artifacts.y_train<br/>              - name: y_test<br/>                from: tasks.preprocessing.outputs.artifacts.y_test                                                <br/>          <br/>          - name: training-lasso<br/>            dependencies: [preprocessing]<br/>            template: lasso<br/>            arguments:<br/>              artifacts:<br/>              - name: x_train<br/>                from: tasks.preprocessing.outputs.artifacts.x_train<br/>              - name: x_test<br/>                from: tasks.preprocessing.outputs.artifacts.x_test<br/>              - name: y_train<br/>                from: tasks.preprocessing.outputs.artifacts.y_train<br/>              - name: y_test<br/>                from: tasks.preprocessing.outputs.artifacts.y_test</span><span id="513f" class="lv kk hi lr b fi ma lx l ly lz"># defining the individual steps of our pipeline<br/>    - name: preproc<br/>      container: <br/>        image: docker.io/manikmal/ml_pipline<br/>        command: [sh, -c]<br/>        args: ["python3 codes/preproc.py"]<br/>      outputs:<br/>        artifacts:<br/>        - name: x_train<br/>          path: x_train.csv<br/>        - name: x_test<br/>          path: x_test.csv<br/>        - name: y_train<br/>          path: y_train.csv<br/>        - name: y_test<br/>          path: y_test.csv</span><span id="b08a" class="lv kk hi lr b fi ma lx l ly lz">- name: randomforrest<br/>      inputs: <br/>        artifacts:<br/>        - name: x_train<br/>          path: x_train.csv<br/>        - name: x_test<br/>          path: x_test.csv<br/>        - name: y_train<br/>          path: y_train.csv<br/>        - name: y_test<br/>          path: y_test.csv<br/>      container:<br/>        image: docker.io/manikmal/ml_pipline<br/>        command: [sh, -c]<br/>        args: ["python3 codes/rf.py"]</span><span id="ab1d" class="lv kk hi lr b fi ma lx l ly lz">- name: lasso<br/>      inputs: <br/>        artifacts:<br/>        - name: x_train<br/>          path: x_train.csv<br/>        - name: x_test<br/>          path: x_test.csv<br/>        - name: y_train<br/>          path: y_train.csv<br/>        - name: y_test<br/>          path: y_test.csv<br/>      container:<br/>        image: docker.io/manikmal/ml_pipline<br/>        command: [sh, -c]<br/>        args: ["python3 codes/lasso.py"]</span></pre><p id="a7f4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">那是一个大文件！这就是为什么数据科学家更喜欢使用 Kubeflow 在 Kubernetes 上定义和运行 ML-pipeline 的原因之一。我会留下我的代码回购链接，所以不要担心从这里复制它。简而言之，上面的 YML 文件声明了我们的工作流，它定义了所需任务的顺序，然后分别定义了每个任务。</p><h1 id="2fa3" class="kj kk hi bd kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg bi translated">4.在 Kubernetes 集群上部署我们的 ML 管道</h1><p id="c32c" class="pw-post-body-paragraph iq ir hi is b it lh iv iw ix li iz ja jb lj jd je jf lk jh ji jj ll jl jm jn hb bi translated">Argo 附带了一个方便的 CLI，用于提交我们的工作流并轻松获得结果。在主节点上，使用提交工作流</p><pre class="lm ln lo lp fd lq lr ls lt aw lu bi"><span id="5be6" class="lv kk hi lr b fi lw lx l ly lz">argo submit pipeline.yml --watch</span></pre><p id="c25c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">监视功能将显示管道的运行情况。一旦完成，我们就可以使用</p><pre class="lm ln lo lp fd lq lr ls lt aw lu bi"><span id="a682" class="lv kk hi lr b fi lw lx l ly lz">argo logs &lt;name of the workflow&gt;</span></pre><p id="f84f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">你会得到你的结果！</p><p id="3582" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们看到的是，我们能够成功地部署机器学习工作流，并通过并行进行不同模型的训练过程，带来大量的时间和资源效率。这些管道是执行许多复杂工作流的电缆，这是一个非常基本的功能示例。因此，越来越多的人需要 MLOps 来给你带来优势。</p><p id="91a7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如前所述，探索 MlOps 的链接:</p><div class="mb mc ez fb md me"><a href="https://ml-ops.org/" rel="noopener  ugc nofollow" target="_blank"><div class="mf ab dw"><div class="mg ab mh cl cj mi"><h2 class="bd hj fi z dy mj ea eb mk ed ef hh bi translated">ml-ops.org</h2><div class="ml l"><h3 class="bd b fi z dy mj ea eb mk ed ef dx translated">作为一个新兴领域，MLOps 正在数据科学家、ML 工程师和人工智能爱好者中迅速获得动力…</h3></div><div class="mm l"><p class="bd b fp z dy mj ea eb mk ed ef dx translated">ml-ops.org</p></div></div></div></a></div><div class="mb mc ez fb md me"><a href="https://towardsdatascience.com/ml-ops-machine-learning-as-an-engineering-discipline-b86ca4874a3f" rel="noopener follow" target="_blank"><div class="mf ab dw"><div class="mg ab mh cl cj mi"><h2 class="bd hj fi z dy mj ea eb mk ed ef hh bi translated">ML Ops:作为工程学科的机器学习</h2><div class="ml l"><h3 class="bd b fi z dy mj ea eb mk ed ef dx translated">随着 ML 从研究走向应用商业解决方案的成熟，我们是否需要提高其运营的成熟度…</h3></div><div class="mm l"><p class="bd b fp z dy mj ea eb mk ed ef dx translated">towardsdatascience.com</p></div></div><div class="mo l"><div class="mp l mq mr ms mo mt io me"/></div></div></a></div><p id="14a6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">该项目的 Git hub repo:</p><div class="mb mc ez fb md me"><a href="https://github.com/mnk-bot/mlpipeline_argo" rel="noopener  ugc nofollow" target="_blank"><div class="mf ab dw"><div class="mg ab mh cl cj mi"><h2 class="bd hj fi z dy mj ea eb mk ed ef hh bi translated">mnk-bot/mlpipeline_argo</h2><div class="ml l"><h3 class="bd b fi z dy mj ea eb mk ed ef dx translated">此时您不能执行该操作。您已使用另一个标签页或窗口登录。您已在另一个选项卡中注销，或者…</h3></div><div class="mm l"><p class="bd b fp z dy mj ea eb mk ed ef dx translated">github.com</p></div></div><div class="mo l"><div class="mu l mq mr ms mo mt io me"/></div></div></a></div><p id="bd39" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">谢谢！</p></div></div>    
</body>
</html>