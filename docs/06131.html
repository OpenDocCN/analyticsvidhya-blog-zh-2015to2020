<html>
<head>
<title>Starter Framework for Machine Learning Projects</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习项目的入门框架</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/starter-framework-for-machine-learning-projects-e443c4f774e6?source=collection_archive---------15-----------------------#2020-05-12">https://medium.com/analytics-vidhya/starter-framework-for-machine-learning-projects-e443c4f774e6?source=collection_archive---------15-----------------------#2020-05-12</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/967e4a16f7efe4c8649bf179bd92fa18.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jGZznuS0ybJgZvhf8runaw.png"/></div></div></figure><p id="fd51" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这篇文章中，我将展示某种用于机器学习项目的框架。正如你可能知道的，机器学习通常是从数据中提取知识。因此，大多数机器学习项目将依赖于来自特定领域的数据集合，称为<strong class="is hj">数据集</strong>，我们正在研究某个问题，以建立适合它的预测模型。这个模型应该遵循一定的步骤来完成它的目的，在下面的部分中，我将实际地介绍一个关于执行统计学习或构建机器学习模型的主要步骤的简化说明。我假设解释项目是在<em class="jo">Jupiter</em>Notebook(<em class="jo">IPython</em>)内部用<em class="jo"> Python </em>编程语言实现的，依赖于使用<em class="jo"> Numpy </em>、Pandas和S <em class="jo"> cikit-Learn </em>包。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es jp"><img src="../Images/e690e81e5fdbefa43b2383d68a9bd08f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1136/format:webp/1*_EoO2Q9UG71lKG54u5zfsg.jpeg"/></div><figcaption class="ju jv et er es jw jx bd b be z dx translated">使用机器学习项目的简化框架</figcaption></figure><h2 id="e691" class="jy jz hi bd ka kb kc kd ke kf kg kh ki jb kj kk kl jf km kn ko jj kp kq kr ks bi translated">问题陈述</h2><p id="5400" class="pw-post-body-paragraph iq ir hi is b it kt iv iw ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm jn hb bi translated">为了构建更好的模型，您应该清楚地定义您试图解决的问题，包括您将用来实现所需解决方案的策略。我选择了一个简单的鸢尾物种分类应用程序，其中我们将创建一个简单的机器学习模型，该模型可用于通过识别与每个鸢尾相关的一些测量值来区分一些鸢尾花的物种，例如花瓣的长度和宽度以及萼片的长度和宽度，所有这些都以厘米为单位。我们将依靠专家们先前鉴定测量的一组数据，他们已经将这些花分类为种类<em class="jo"> stosa </em>、<em class="jo"> versicolor </em>或<em class="jo"> virginica </em>。我们的任务是建立一个可以从这些测量中学习的模型，这样我们就可以为新的虹膜预测物种</p><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es ky"><img src="../Images/10d7804c17de1589e04eea7b658cdda0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1062/format:webp/1*TCo6AxVIQQE6xSdFYF7GEA.png"/></div></figure><h2 id="07d8" class="jy jz hi bd ka kb kc kd ke kf kg kh ki jb kj kk kl jf km kn ko jj kp kq kr ks bi translated">算法选择</h2><p id="7d1c" class="pw-post-body-paragraph iq ir hi is b it kt iv iw ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm jn hb bi translated">根据所研究问题的性质和特征，我们需要选择适合于解决它的算法和技术。因为我们有测量结果，我们知道虹膜的正确种类，这是一个<strong class="is hj">监督学习问题</strong>。在这个问题中，我们要预测几个选项中的一个(鸢尾的种类)。这是一个分类问题的例子。可能的输出(不同种类的鸢尾)被称为类。数据集中的每一个虹膜都属于三类中的一类，所以这个问题是一个三类分类问题。单个数据点(虹膜)的期望输出是这种花的种类。对于一个特定的数据点，其所属的物种称为其标签或类别。</p><h2 id="ef25" class="jy jz hi bd ka kb kc kd ke kf kg kh ki jb kj kk kl jf km kn ko jj kp kq kr ks bi translated">项目准备</h2><p id="4c25" class="pw-post-body-paragraph iq ir hi is b it kt iv iw ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm jn hb bi translated">为了开始处理我们项目的数据，我们将首先导入我们在实现中需要的功能，如<em class="jo"> Python </em>库，设置我们的环境以允许我们完成我们的任务以及成功加载我们的数据集:</p><figure class="jq jr js jt fd ij"><div class="bz dy l di"><div class="kz la l"/></div></figure><p id="3467" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">然后我们开始将我们的数据集加载到一个<em class="jo">熊猫</em>T6】数据帧中。这里将使用的数据是<em class="jo"> Iris </em>数据集，这是机器学习和统计中的经典数据集。它包含在数据集模块内的<em class="jo"> scikit-learn </em>中。</p><figure class="jq jr js jt fd ij"><div class="bz dy l di"><div class="kz la l"/></div></figure><p id="5fea" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">输出将如下所示</p><pre class="jq jr js jt fd lb lc ld le aw lf bi"><span id="9262" class="jy jz hi lc b fi lg lh l li lj"><strong class="lc hj">features</strong>: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']<br/><strong class="lc hj">target categories</strong>: ['setosa' 'versicolor' 'virginica']<br/><strong class="lc hj">Shape of data</strong>: (150, 4)</span></pre><p id="8666" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">isis flowers的数据包含萼片长度、萼片宽度、花瓣长度和花瓣宽度的数值测量，并存储为<strong class="is hj"> <em class="jo"> Numpy数组</em> </strong>，因此我们将其转换为pandas <strong class="is hj">数据帧。</strong></p><blockquote class="lk ll lm"><p id="eb04" class="iq ir jo is b it iu iv iw ix iy iz ja ln jc jd je lo jg jh ji lp jk jl jm jn hb bi translated"><strong class="is hj">注意</strong>:这里我们使用的是<strong class="is hj"> Sci-kit Learn </strong>库自带的内置数据集，但实际上，数据集通常以<strong class="is hj"> csv </strong>文件的形式出现，所以我们可以使用类似下面注释代码的代码:</p><p id="2860" class="iq ir jo is b it iu iv iw ix iy iz ja ln jc jd je lo jg jh ji lp jk jl jm jn hb bi translated"><em class="hi"># my file = ' my filename . CSV '</em><br/><em class="hi"># full _ data = PD . read _ CSV(my file，千位= '，'，delimiter = '；'，encoding='latin1 '，na_values="n/a") </em></p></blockquote><p id="a32d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">然后，我们开始将数据集加载到熊猫数据框架中。这里将使用的数据是Iris数据集，这是机器学习和统计中的经典数据集。它包含在sci kit-数据集学习模块中。</p><pre class="jq jr js jt fd lb lc ld le aw lf bi"><span id="ffbe" class="jy jz hi lc b fi lg lh l li lj"><strong class="lc hj">from</strong> <strong class="lc hj">sklearn.datasets</strong> <strong class="lc hj">import</strong> load_iris<br/>iris=load_iris()<br/><em class="jo">#printing feature names</em><br/>print('features: <strong class="lc hj">%s</strong>'%iris['feature_names'])<br/><em class="jo">#printing species of iris</em><br/>print('target categories: <strong class="lc hj">%s</strong>'%iris['target_names'])<br/><em class="jo">#iris data shape</em><br/>print("Shape of data: <strong class="lc hj">{}</strong>".format(iris['data'].shape))</span></pre><p id="441b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">输出将如下所示</p><pre class="jq jr js jt fd lb lc ld le aw lf bi"><span id="a562" class="jy jz hi lc b fi lg lh l li lj"><strong class="lc hj">features</strong>: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']<br/><strong class="lc hj">target categories</strong>: ['setosa' 'versicolor' 'virginica']<br/><strong class="lc hj">Shape of data</strong>: (150, 4)</span></pre><p id="a080" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">isis flowers的数据包含萼片长度、萼片宽度、花瓣长度和花瓣宽度的数字测量值，并存储为<code class="du lq lr ls lc b">NumPy array</code>，因此要将其转换为<code class="du lq lr ls lc b">pandas DataFrame</code>，我们将编写以下代码:</p><pre class="jq jr js jt fd lb lc ld le aw lf bi"><span id="dc41" class="jy jz hi lc b fi lg lh l li lj">full_data=pd.DataFrame(iris['data'],columns=iris['feature_names'])<br/>full_data['Classification']=iris['target']<br/>full_data['Classification']=full_data['Classification'].apply(<strong class="lc hj">lambda</strong> x: iris['target_names'][x])</span></pre><h1 id="fa2c" class="lt jz hi bd ka lu lv lw ke lx ly lz ki ma mb mc kl md me mf ko mg mh mi kr mj bi translated">数据探索</h1><p id="5771" class="pw-post-body-paragraph iq ir hi is b it kt iv iw ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm jn hb bi translated">在建立机器学习模型之前，我们必须首先分析我们用于解决问题的数据集，并且总是期望我们评估可能需要预处理的常见问题。因此，在继续我们的模型实现之前，数据探索是一项必要的工作。这是通过显示数据的快速样本、描述数据的类型、了解数据的形状或维度，并且如果需要，具有与加载的数据集相关的基本统计数据和信息来实现的。以及探索输入特征和关于可能需要解决的数据的任何异常或有趣的品质。数据探索可让您更深入地了解数据集，包括数据集模式、值分布、缺失值和分类要素的基数。</p><p id="7ee1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了开始研究由iris对象表示的数据集，该对象由load_iris()返回并存储在mydata<em class="jo">pandas</em>data frame中，我们可以使用。<strong class="is hj">头</strong>()功能。</p><pre class="jq jr js jt fd lb lc ld le aw lf bi"><span id="7a79" class="jy jz hi lc b fi lg lh l li lj">display(full_data.head())</span></pre><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mk"><img src="../Images/f01253142cbae7e17109d5720d635a68.png" data-original-src="https://miro.medium.com/v2/resize:fit:1224/format:webp/1*312O1BNunQiML1jLIERjuA.png"/></div></div></figure><blockquote class="lk ll lm"><p id="318a" class="iq ir jo is b it iu iv iw ix iy iz ja ln jc jd je lo jg jh ji lp jk jl jm jn hb bi translated">要显示有关数据结构的更多信息:</p><p id="9f65" class="iq ir jo is b it iu iv iw ix iy iz ja ln jc jd je lo jg jh ji lp jk jl jm jn hb bi translated">完整数据。<strong class="is hj">信息</strong>()或完整数据。<strong class="is hj">数据类型</strong></p></blockquote><p id="ba68" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">要检查数据集中是否存在任何空值，请执行以下操作:</p><pre class="jq jr js jt fd lb lc ld le aw lf bi"><span id="3ca0" class="jy jz hi lc b fi lg lh l li lj">full_data.<strong class="lc hj">isnull</strong>().<strong class="lc hj">sum</strong>()</span></pre><p id="10ad" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">或者使用以下函数来获取有关这些空值的更多详细信息:</p><figure class="jq jr js jt fd ij"><div class="bz dy l di"><div class="kz la l"/></div></figure><p id="2ed9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">从上面的数据集样本中，我们可以看到数据集包含了150种不同花卉的测量数据。每个单独的项目称为<strong class="is hj">示例</strong>，机器学习中的实例或样本，它们的属性(5列)称为<strong class="is hj">特征</strong> (4个特征和一列是每个实例或示例的<code class="du lq lr ls lc b">Target</code>或类)。数据阵列的形状是样本数乘以特征数。这是s <em class="jo"> cikit-learn </em>中的约定，我们的数据将始终被假定为这种形状。</p><p id="ac22" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">下面是对数据集中包含的特性和类的详细解释:-</p><ul class=""><li id="b2d3" class="ml mm hi is b it iu ix iy jb mn jf mo jj mp jn mq mr ms mt bi translated"><strong class="is hj">萼片长度</strong>:表示指定鸢尾花的萼片长度，单位为厘米。</li><li id="1c96" class="ml mm hi is b it mu ix mv jb mw jf mx jj my jn mq mr ms mt bi translated"><strong class="is hj">萼片宽度</strong>:表示指定鸢尾花的萼片宽度，单位为厘米。</li><li id="4eea" class="ml mm hi is b it mu ix mv jb mw jf mx jj my jn mq mr ms mt bi translated"><strong class="is hj">花瓣长度</strong>:表示指定鸢尾花的花瓣长度，单位为厘米。</li><li id="ae08" class="ml mm hi is b it mu ix mv jb mw jf mx jj my jn mq mr ms mt bi translated"><strong class="is hj">花瓣宽度</strong>:表示指定鸢尾花的花瓣宽度，单位为厘米。</li></ul><p id="bd6a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了显示新数据集的统计数据，我们可以使用:</p><pre class="jq jr js jt fd lb lc ld le aw lf bi"><span id="a00f" class="jy jz hi lc b fi lg lh l li lj">full_data.describe()</span></pre><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es mz"><img src="../Images/4732e60d0fc63fd5cff8206e814a8dd9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1090/format:webp/1*1Go4buzTzBA9aeqP1JCMsQ.png"/></div></figure><p id="bd8c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">您可以比较最小值和最大值，看看缩放比例是否较大，以及是否需要缩放数字要素。</p><p id="021d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">由于我们对鸢尾花的分类感兴趣，即我们只观察基于给定测量或特征的每朵花的类别或标签，我们可以从该数据集中移除<code class="du lq lr ls lc b">Classification</code>特征，并将其存储为自己的独立变量<code class="du lq lr ls lc b">Labels</code>。我们将使用这些标签作为我们的预测目标。下面的代码将删除作为数据集特征的<code class="du lq lr ls lc b">Classification</code>，并将其存储在<code class="du lq lr ls lc b">Labels</code>中。</p><pre class="jq jr js jt fd lb lc ld le aw lf bi"><span id="0b3d" class="jy jz hi lc b fi lg lh l li lj">Labels = full_data['Classification']<br/>mydata = full_data.<strong class="lc hj">drop</strong>('Classification', axis = 1)</span><span id="e143" class="jy jz hi lc b fi na lh l li lj"><strong class="lc hj">display</strong>(mydata.<strong class="lc hj">head</strong>())</span><span id="5cc6" class="jy jz hi lc b fi na lh l li lj"><strong class="lc hj">display</strong>(Labels.<strong class="lc hj">head</strong>())</span></pre><p id="dfd0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">从数据框中删除的<code class="du lq lr ls lc b">Classification</code>特征。注意，数据(鸢尾花数据)和<code class="du lq lr ls lc b">Labels</code>(鸢尾花的标签或分类)现在是成对的。这意味着任何鸢尾花<code class="du lq lr ls lc b">mydata.<strong class="is hj">loc</strong>[<em class="jo">i</em>]</code>，他们有一个分类或标签<code class="du lq lr ls lc b">Labels<strong class="is hj">[</strong><em class="jo">i</em><strong class="is hj">]</strong></code>。</p><p id="feac" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">通过删除与特定提供条件不匹配的元素来过滤输入数据。下面的函数将一个数据列表作为输入，并返回一个过滤后的列表，如下面的代码所示</p><pre class="jq jr js jt fd lb lc ld le aw lf bi"><span id="2124" class="jy jz hi lc b fi lg lh l li lj"><strong class="lc hj">def</strong> filter_data(data, conditionField,conditionOperation,conditionValue):<br/>    <em class="jo">"""</em><br/><em class="jo">    Remove elements that do not match the condition provided.</em><br/><em class="jo">    Takes a data list as input and returns a filtered list.</em><br/><em class="jo">    Conditions passed as separte parameresfor the field,operation and value.</em><br/><em class="jo">    </em><br/><em class="jo">    """</em><br/>   <br/>    <em class="jo">#field, op, value = condition.split(" ") # Example: ["field == 'value'", 'field &lt; 18']</em><br/>    field, op, value = conditionField,conditionOperation,conditionValue<br/>    <br/>    <em class="jo"># convert value into number or strip excess quotes if string</em><br/>    <strong class="lc hj">try</strong>:<br/>        value = float(value)<br/>    <strong class="lc hj">except</strong>:<br/>        value = value.strip("<strong class="lc hj">\'\"</strong>")<br/>    <br/>    <em class="jo"># get booleans for filtering</em><br/>    <strong class="lc hj">if</strong> op == "&gt;":<br/>        matches = data[field] &gt; value<br/>    <strong class="lc hj">elif</strong> op == "&lt;":<br/>        matches = data[field] &lt; value<br/>    <strong class="lc hj">elif</strong> op == "&gt;=":<br/>        matches = data[field] &gt;= value<br/>    <strong class="lc hj">elif</strong> op == "&lt;=":<br/>        matches = data[field] &lt;= value<br/>    <strong class="lc hj">elif</strong> op == "==":<br/>        matches = data[field] == value<br/>    <strong class="lc hj">elif</strong> op == "!=":<br/>        matches = data[field] != value<br/>    <strong class="lc hj">else</strong>: <em class="jo"># catch invalid operation codes</em><br/>        <strong class="lc hj">raise</strong> <strong class="lc hj">Exception</strong>("Invalid comparison operator. Only &gt;, &lt;, &gt;=, &lt;=, ==, != allowed.")<br/>    <br/>    <em class="jo"># filter data and outcomes</em><br/>    data = data[matches].reset_index(drop = <strong class="lc hj">True</strong>)<br/>    <strong class="lc hj">return</strong> data</span></pre><p id="c4e3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">例如，我们可以过滤我们的数据，使其成为属性<code class="du lq lr ls lc b">sepal width (cm)</code>小于<code class="du lq lr ls lc b">3</code>的所有花卉的列表，如下所示</p><pre class="jq jr js jt fd lb lc ld le aw lf bi"><span id="bcd2" class="jy jz hi lc b fi lg lh l li lj">filtered_data=filter_data(mydata, 'sepal width (cm)','&lt;','3')<br/>display(filtered_data.head())</span></pre><h1 id="da43" class="lt jz hi bd ka lu lv lw ke lx ly lz ki ma mb mc kl md me mf ko mg mh mi kr mj bi translated">数据可视化</h1><p id="5eb8" class="pw-post-body-paragraph iq ir hi is b it kt iv iw ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm jn hb bi translated">在建立机器学习模型之前，查看我们的数据以更多地了解构成它的各种组件之间的关系是一个好主意。检查我们的数据是发现异常和特性的好方法。例如，也许你的一些虹膜是用英寸而不是厘米来测量的。在现实世界中，数据不一致和意外测量是非常常见的。检查数据的最好方法之一是对我们的数据进行可视化。我们可以使用python <code class="du lq lr ls lc b"><strong class="is hj">matplotlib</strong></code> <strong class="is hj"> </strong>库或<code class="du lq lr ls lc b"><strong class="is hj">seaborn</strong></code> <strong class="is hj"> </strong>库来绘制和可视化数据，使用不同类型的图，如<em class="jo">条形图</em>、<em class="jo">箱线图</em>、<em class="jo">散点图</em>等。</p><p id="93ca" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">下面的函数显示了我们数据中任意单个属性的<code class="du lq lr ls lc b"><em class="jo">Bar graph</em></code></p><pre class="jq jr js jt fd lb lc ld le aw lf bi"><span id="0d5a" class="jy jz hi lc b fi lg lh l li lj"><strong class="lc hj">def</strong> BarGraph(theData,target,attributeName):<br/>    xValues = np.unique(target)<br/>    yValues=[]<br/>    <strong class="lc hj">for</strong> label <strong class="lc hj">in</strong> xValues:<br/>        yValues.append(theData.loc[target==label, attributeName].idxmax())<br/>    plt.bar(xValues,yValues)<br/>    plt.xticks(xValues, target)<br/>    plt.title(attributeName) <br/>    plt.show()</span></pre><p id="a34f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">下面的代码通过显示<code class="du lq lr ls lc b">sepal length (cm)</code>的条形图来测试上述功能。</p><pre class="jq jr js jt fd lb lc ld le aw lf bi"><span id="fd21" class="jy jz hi lc b fi lg lh l li lj">BarGraph(mydata,Labels,'sepal length (cm)')</span></pre><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es nb"><img src="../Images/d40c06c735bcad431373fddfdb2bb59d.png" data-original-src="https://miro.medium.com/v2/resize:fit:818/format:webp/1*6WkoNQ8QRJlTiPp2APeFYQ.png"/></div></figure><p id="b6c0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">此外，我们可以使用以下函数同时显示多个条形图:</p><pre class="jq jr js jt fd lb lc ld le aw lf bi"><span id="481b" class="jy jz hi lc b fi lg lh l li lj"><strong class="lc hj">def</strong> BarGraphs(theData,target,attributeNamesList,graphsTitle='Attributes Classifications'):<br/>    xValues = np.unique(target)<br/>    fig, ax = plt.subplots(nrows=int(len(attributeNamesList)/2), ncols=2,figsize=(16, 8))<br/>    k=0<br/>    <strong class="lc hj">for</strong> row <strong class="lc hj">in</strong> ax:<br/>        <strong class="lc hj">for</strong> col <strong class="lc hj">in</strong> row:<br/>            yValues=[]<br/>            <strong class="lc hj">for</strong> label <strong class="lc hj">in</strong> xValues:<br/>                yValues.append(theData.loc[target==label, attributeNamesList[k]].idxmax()) <br/>            col.set_title(attributeNamesList[k])<br/>            <em class="jo">#col.set(xlabel=" x Label", ylabel=' y Label')</em><br/>            col.bar(xValues,yValues)<br/>            k=k+1<br/>    fig.suptitle(graphsTitle)    <br/>    plt.show()</span></pre><p id="c121" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">示例:</p><pre class="jq jr js jt fd lb lc ld le aw lf bi"><span id="7646" class="jy jz hi lc b fi lg lh l li lj">BarGraphs(mydata,Labels,['sepal length (cm)','sepal width (cm)','petal length (cm)','petal width (cm)'])</span></pre><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nc"><img src="../Images/baa8086fc55719ab9d77305b0d5712ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Wy1WAdt6lLCQ65YOba6kFA.png"/></div></div></figure><p id="4a68" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">可视化数据集中的值分布，有助于更好地理解数据集中的属性分布，以检查该分布的性质是正态分布还是均匀分布，这可以通过以下方式完成</p><pre class="jq jr js jt fd lb lc ld le aw lf bi"><span id="665a" class="jy jz hi lc b fi lg lh l li lj"><strong class="lc hj">def</strong> Distribution(theData,datacolumn,type='value'):<br/>    <strong class="lc hj">if</strong> type=='value':<br/>        print("Distribution for <strong class="lc hj">{}</strong> ".format(datacolumn))<br/>        theData[datacolumn].value_counts().plot(kind='bar')<br/>    <strong class="lc hj">elif</strong> type=='normal':<br/>        attr_mean=theData[datacolumn].mean() <em class="jo"># Mean of the attribute values</em><br/>        attr_std_dev=full_data[datacolumn].std() <em class="jo"># Standard Deviation of the attribute values</em><br/>        ndist=np.random.normal(attr_mean, attr_std_dev, 100)<br/>        norm_ax = sns.distplot(ndist, kde=<strong class="lc hj">False</strong> )<br/>        plt.show()<br/>        plt.close()<br/>    <strong class="lc hj">elif</strong> type=='uniform':<br/>        udist = np.random.uniform(-1,0,1000)<br/>        uniform_ax = sns.distplot(udist, kde=<strong class="lc hj">False</strong> )<br/>        plt.show()    <br/>    <strong class="lc hj">elif</strong> type=='hist':<br/>        theData[datacolumn].hist()</span></pre><p id="b201" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了测试<code class="du lq lr ls lc b">Classification</code>属性的可视化值分布，我们可以写:-</p><pre class="jq jr js jt fd lb lc ld le aw lf bi"><span id="b805" class="jy jz hi lc b fi lg lh l li lj">Distribution(full_data, 'Classification')<br/></span></pre><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es nd"><img src="../Images/1a06e3cf8bfc1b2c3c0f897f3cac8545.png" data-original-src="https://miro.medium.com/v2/resize:fit:788/format:webp/1*FMynQbyVRaTnDSzBN09eUQ.png"/></div></figure><p id="9868" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">另一个可视化示例是显示某个属性的直方图，我们使用以下内容:</p><pre class="jq jr js jt fd lb lc ld le aw lf bi"><span id="eae9" class="jy jz hi lc b fi lg lh l li lj">Distribution(full_data, 'sepal length (cm)',type='hist')</span></pre><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es ne"><img src="../Images/f3a981e8a7c596975a21e0804f4fd879.png" data-original-src="https://miro.medium.com/v2/resize:fit:866/format:webp/1*3sBSsfPN1_ow-E7JMjxJyA.png"/></div></figure><pre class="jq jr js jt fd lb lc ld le aw lf bi"><span id="2a98" class="jy jz hi lc b fi lg lh l li lj">sns.<strong class="lc hj">distplot</strong>(full_data['sepal length (cm)'])</span></pre><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es nf"><img src="../Images/2a80e5940fb022d601722c0d69aef823.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*wPE0R-6BLGGIkAEMw21XoQ.png"/></div></figure><p id="a1c7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">看来属性<code class="du lq lr ls lc b">sepal length (cm)</code>具有正态分布。</p><p id="eca9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了探究这些特性是如何相互关联的，我们可以使用<em class="jo"> seaborn </em>库中的<code class="du lq lr ls lc b"><strong class="is hj">heatmap</strong></code> <strong class="is hj"> </strong>。我们可以看到，萼片长度和萼片宽度特征彼此略有关联。</p><pre class="jq jr js jt fd lb lc ld le aw lf bi"><span id="7598" class="jy jz hi lc b fi lg lh l li lj">plt.<strong class="lc hj">figure</strong>(figsize=(10,11))<br/>sns.<strong class="lc hj">heatmap</strong>(mydata.corr(),annot=<strong class="lc hj">True</strong>)<br/>plt.<strong class="lc hj">plot</strong>()</span></pre><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es ng"><img src="../Images/de188ae406ec6ae262b313081c35f34a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1178/format:webp/1*QIrfzb77JBiUmMF8oNEPKQ.png"/></div></figure><p id="4199" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了观察数据集中特征之间的关系，我们可以使用<strong class="is hj">散点图</strong>。数据的<em class="jo">散点图</em>沿x轴放置一个特征，沿y轴放置另一个特征，并为每个数据点绘制一个点。对于如何根据萼片长度宽度特征分布我们的数据的散点图，我们可以使用下面的代码:</p><pre class="jq jr js jt fd lb lc ld le aw lf bi"><span id="5180" class="jy jz hi lc b fi lg lh l li lj">sns.<strong class="lc hj">FacetGrid</strong>(full_data,hue="Classification").<strong class="lc hj">map</strong>(plt.scatter,"sepal length (cm)","sepal width (cm)").<strong class="lc hj">add_legend</strong>()<br/>plt.<strong class="lc hj">show</strong>()</span></pre><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es nh"><img src="../Images/2555352f56d8023c3851a93d39400a0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:572/format:webp/1*duSseFlDpJbafdkHwKL46Q.png"/></div></figure><p id="8f31" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了绘制具有三个以上特征的数据集，我们可以使用一个<code class="du lq lr ls lc b">pair plot</code>，它查看所有可能的特征对。如果你有少量的特性，比如我们这里的四个，这是很合理的。但是，您应该记住，配对图不会一次显示所有要素的相互作用，因此以这种方式进行可视化时，数据的一些有趣方面可能不会显示出来。我们可以使用<em class="jo"> seaborn </em>库中的<code class="du lq lr ls lc b"><strong class="is hj">pairplot</strong></code>函数，如下所示:</p><pre class="jq jr js jt fd lb lc ld le aw lf bi"><span id="86dd" class="jy jz hi lc b fi lg lh l li lj">sns.<strong class="lc hj">pairplot</strong>(mydata)</span></pre><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ni"><img src="../Images/56c503c0b6dfb1c4b77ce642d07fde4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VxON_F2rRvk51GQldumViw.png"/></div></div></figure><p id="e2b3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">另一种做散点图的方法是使用<code class="du lq lr ls lc b">pandas</code>库中<code class="du lq lr ls lc b">plotting</code>模块中的<code class="du lq lr ls lc b">scatter matrix</code>。下面的代码从数据帧中创建了一个散点图，颜色将根据类别或标签而定</p><pre class="jq jr js jt fd lb lc ld le aw lf bi"><span id="73ce" class="jy jz hi lc b fi lg lh l li lj"><strong class="lc hj">from</strong> <strong class="lc hj">pandas.plotting</strong> <strong class="lc hj">import</strong> scatter_matrix<br/>colors = list()<br/>palette = {0: "red", 1: "green", 2: "blue"}<br/><strong class="lc hj">for</strong> c <strong class="lc hj">in</strong> np.nditer(iris.target): colors.append(palette[int(c)])<br/>grr = scatter_matrix(mydata, alpha=0.3,figsize=(10, 10), diagonal='hist', color=colors, marker='o', grid=<strong class="lc hj">True</strong>)</span></pre><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es nj"><img src="../Images/3dd83bd18f5d6b5dd5f457518709714b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/1*rb2AJk27HIHNeweJNNyc3Q.png"/></div></figure><p id="f040" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">从图中，我们可以看到，使用萼片和花瓣测量，这三个类别似乎被相对很好地分开。这意味着机器学习模型将有可能学会将它们分开。</p><p id="cd22" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了显示物种的长度和宽度的密度，我们可以使用所有输入变量的<code class="du lq lr ls lc b"><strong class="is hj">violin plot</strong></code>来表示物种的输出变量。</p><pre class="jq jr js jt fd lb lc ld le aw lf bi"><span id="3c73" class="jy jz hi lc b fi lg lh l li lj">plt.figure(figsize=(12,10))<br/>plt.subplot(2,2,1)<br/>sns.<strong class="lc hj">violinplot</strong>(x="Classification",y="sepal length (cm)",data=full_data)<br/>plt.subplot(2,2,2)<br/>sns.<strong class="lc hj">violinplot</strong>(x="Classification",y="sepal width (cm)",data=full_data)<br/>plt.subplot(2,2,3)<br/>sns.<strong class="lc hj">violinplot</strong>(x="Classification",y="petal length (cm)",data=full_data)<br/>plt.subplot(2,2,4)<br/>sns.<strong class="lc hj">violinplot</strong>(x="Classification",y="petal width (cm)",data=full_data)</span></pre><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nk"><img src="../Images/e724bde4a4e865ad5fffa5113d5e45eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Eb4AmOVqIWkebY8s37kr3w.png"/></div></div></figure><p id="d5e5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><code class="du lq lr ls lc b"><strong class="is hj">thinner </strong>part denotes that there is <strong class="is hj">less density</strong></code>反之<code class="du lq lr ls lc b"><strong class="is hj">fatter </strong>part conveys <strong class="is hj">higher density</strong></code>。</p><p id="8e3a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">同样，我们可以使用<code class="du lq lr ls lc b"><strong class="is hj">boxplot</strong></code> <strong class="is hj"> </strong>来查看<em class="jo">分类特征</em> <code class="du lq lr ls lc b">Classification</code>如何与所有其他输入一起分布，并检查异常值变量</p><pre class="jq jr js jt fd lb lc ld le aw lf bi"><span id="1e98" class="jy jz hi lc b fi lg lh l li lj">plt.figure(figsize=(12,10))<br/>plt.subplot(2,2,1)<br/>sns.<strong class="lc hj">boxplot</strong>(x="Classification",y="sepal length (cm)",data=full_data)<br/>plt.subplot(2,2,2)<br/>sns.<strong class="lc hj">boxplot</strong>(x="Classification",y="sepal width (cm)",data=full_data)<br/>plt.subplot(2,2,3)<br/>sns.<strong class="lc hj">boxplot</strong>(x="Classification",y="petal length (cm)",data=full_data)<br/>plt.subplot(2,2,4)<br/>sns.<strong class="lc hj">boxplot</strong>(x="Classification",y="petal width (cm)",data=full_data)</span></pre><figure class="jq jr js jt fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nl"><img src="../Images/fca1b5539c7c7668d0c791e4f325fc86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3d_z4Grrgq9It3pcDTLUog.png"/></div></div></figure><p id="e42c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">要检查基数:</p><pre class="jq jr js jt fd lb lc ld le aw lf bi"><span id="20ca" class="jy jz hi lc b fi lg lh l li lj"><strong class="lc hj">def</strong> count_unique_values(theData, categorical_columns_list):<br/>    cats = theData[categorical_columns_list]<br/>    rValue = pd.DataFrame({'cardinality': cats.nunique()})<br/>    <strong class="lc hj">return</strong> rValue</span></pre><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es nm"><img src="../Images/e29d1a19f986d5da375623da975e9b6b.png" data-original-src="https://miro.medium.com/v2/resize:fit:458/format:webp/1*OFXGlnvjc9jFvsfWLDPPiQ.png"/></div></figure><h1 id="f57e" class="lt jz hi bd ka lu lv lw ke lx ly lz ki ma mb mc kl md me mf ko mg mh mi kr mj bi translated">将数据集拆分为训练和测试数据</h1><p id="cc0b" class="pw-post-body-paragraph iq ir hi is b it kt iv iw ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm jn hb bi translated">我们不能使用我们用来建立模型的相同数据来评估它。这是因为我们的模型总是可以简单地记住整个训练集，因此总是可以预测训练集中任何点的正确标签。这个<code class="du lq lr ls lc b">remembering</code>并没有向我们表明我们的模型是否会很好地推广，即它是否也会在新数据上表现良好。因此，在使用可以从看不见的数据中进行预测的机器学习模型之前，我们应该有一些方法来知道它实际上是否有效。因此，我们需要将带标签的数据分成两部分。其中一部分数据用于构建我们的机器学习模型，被称为<code class="du lq lr ls lc b">training data</code>或<code class="du lq lr ls lc b"><strong class="is hj">training set</strong></code>。其余的数据将用于衡量模型的效果；这被称为<code class="du lq lr ls lc b">test data</code>，或<code class="du lq lr ls lc b"><strong class="is hj">test set</strong></code>。</p><p id="957b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><code class="du lq lr ls lc b"><em class="jo">scikit-learn</em></code>包含一个函数<em class="jo">打乱</em>数据集，<em class="jo">为您拆分</em>数据集:函数<code class="du lq lr ls lc b"><strong class="is hj">train_test_split</strong></code>。该函数提取数据中的<strong class="is hj"> 75 </strong> %的行作为<code class="du lq lr ls lc b">training set</code>，以及该数据的相应标签。剩余的<strong class="is hj"> 25 </strong> %的数据，连同剩余的标签，被声明为<code class="du lq lr ls lc b">test set</code>。</p><p id="b5bc" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在<code class="du lq lr ls lc b">scikit-learn</code>中，数据通常用大写的X表示，而标签用小写的y表示。这是受数学中的标准公式f(x)=y的启发，其中X是函数的输入，y是输出。遵循更多的数学惯例，我们使用大写的X，因为数据是二维数组(一个矩阵)，小写的y，因为目标是一维数组(一个向量)。让我们对我们的数据调用train_test_split，并使用以下代码分配输出</p><pre class="jq jr js jt fd lb lc ld le aw lf bi"><span id="9e8a" class="jy jz hi lc b fi lg lh l li lj"><strong class="lc hj">from</strong> <strong class="lc hj">sklearn.model_selection</strong> <strong class="lc hj">import</strong> train_test_split<br/>X_train, X_test, y_train, y_test = <strong class="lc hj">train_test_split</strong>(mydata,Labels, random_state=0)</span><span id="e68f" class="jy jz hi lc b fi na lh l li lj">print("X_train shape: <strong class="lc hj">{}</strong>".format(X_train.<strong class="lc hj">shape</strong>))<br/>print("y_train shape: <strong class="lc hj">{}</strong>".format(y_train.<strong class="lc hj">shape</strong>))<br/>print("X_test shape: <strong class="lc hj">{}</strong>".format(X_test.<strong class="lc hj">shape</strong>))<br/>print("y_test shape: <strong class="lc hj">{}</strong>".format(y_test.<strong class="lc hj">shape</strong>))</span></pre><p id="1805" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在进行分割之前，train_test_split函数使用伪随机数发生器对数据集进行洗牌。如果我们只是将最后25%的数据作为测试集，所有的数据点都将具有标签2，因为数据点是按标签排序的(参见前面显示的iris['target']的输出)。使用只包含三个类中的一个的测试集并不能告诉我们我们的模型概括得有多好，所以我们打乱我们的数据以确保测试数据包含来自所有类的数据。为了确保多次运行相同的函数都会得到相同的输出，我们使用random_state参数为伪随机数生成器提供了一个固定的种子。这将使结果确定，所以这条线将总是有相同的结果。train_test_split函数的输出是X_train、X_test、y_train和y_test，它们都是NumPy数组。X_train包含数据集的75%的行，X_test包含剩余的25%</p><h1 id="a74b" class="lt jz hi bd ka lu lv lw ke lx ly lz ki ma mb mc kl md me mf ko mg mh mi kr mj bi translated">建立模型</h1><p id="91e3" class="pw-post-body-paragraph iq ir hi is b it kt iv iw ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm jn hb bi translated">现在我们可以开始构建实际的机器学习模型了。在<em class="jo"> scikit-learn </em>中有许多我们可以使用的分类算法。这里我们会用一个<code class="du lq lr ls lc b"><strong class="is hj">k-nearest neighbors classifier</strong></code>，很容易理解。构建该模型仅包括存储训练集。为了预测新的数据点，该算法会在训练集中找到最接近新点的点。然后，它将该训练点的标签分配给新的数据点。</p><p id="4aaf" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><code class="du lq lr ls lc b">k-nearest neighbors</code>中的<code class="du lq lr ls lc b">k</code>表示我们可以在训练中考虑任意固定数量的k个邻居(例如，最近的三个或五个邻居)，而不是只使用与新数据点最近的邻居。然后，我们可以使用这些邻居中的多数类进行预测。为了简化，我们将只使用一个邻居。</p><p id="b1c5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><code class="du lq lr ls lc b"><em class="jo">scikit-learn</em></code>中所有的机器学习模型都是在自己的类中实现的，这些类叫做估计器类。<code class="du lq lr ls lc b">k-nearest neighbors classification algorithm</code>在<code class="du lq lr ls lc b">neighbors</code>模块的<code class="du lq lr ls lc b"><strong class="is hj">KNeighborsClassifier </strong>class</code>中实现。在使用这个模型之前，我们需要将这个类实例化为一个对象。这时我们将设置模型的任何参数。KNeighbor sClassifier最重要的参数是<code class="du lq lr ls lc b">number of neighbors</code>，我们将它设置为1:</p><pre class="jq jr js jt fd lb lc ld le aw lf bi"><span id="93df" class="jy jz hi lc b fi lg lh l li lj"><strong class="lc hj">from</strong> <strong class="lc hj">sklearn.neighbors</strong> <strong class="lc hj">import</strong> KNeighborsClassifier<br/>knn = <strong class="lc hj">KNeighborsClassifier</strong>(n_neighbors=1)</span></pre><p id="ac75" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="jo"> knn </em>对象封装了将用于从训练数据构建模型的算法，以及对新数据点进行预测的算法。它还将保存算法从训练数据中提取的信息。在<strong class="is hj"> KNeighborsClassifier </strong>的情况下，它将只存储训练集。为了在训练集上构建模型，我们调用knn对象的<code class="du lq lr ls lc b">fit</code>方法，该方法将包含训练数据的<em class="jo"> NumPy </em>数组<code class="du lq lr ls lc b">X_train</code>和相应训练标签的<em class="jo"> NumPy </em>数组<code class="du lq lr ls lc b">y_train</code>作为参数:</p><pre class="jq jr js jt fd lb lc ld le aw lf bi"><span id="a7cc" class="jy jz hi lc b fi lg lh l li lj">knn.<strong class="lc hj">fit</strong>(X_train, y_train)</span></pre><p id="eec1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><code class="du lq lr ls lc b"><strong class="is hj">fit</strong></code>方法返回knn对象本身(并就地修改它)，因此我们得到了分类器的字符串表示。该表示向我们展示了在创建模型时使用了哪些参数。几乎所有的都是默认值，但是你也可以找到n_neighbors=1，这是我们传递的参数。scikit-learn中的大多数模型都有许多参数，但其中大多数要么是速度优化，要么是用于非常特殊的用例。您不必担心这个表示中显示的其他参数。打印scikit-learn模型可以产生很长的字符串，但是不要被这些吓倒。因此，我们不会显示fit的输出，因为它不包含任何新信息。</p><p id="40d6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们现在可以使用这个模型对我们可能不知道正确标签的新数据进行预测。想象一下，我们在野外发现一种鸢尾，萼片长5厘米，萼片宽2.9厘米，花瓣长1厘米，花瓣宽0.2厘米。这是哪种鸢尾？我们可以将这些数据放入一个NumPy数组中，同样通过计算形状来实现，即样本数(1)乘以特征数(4):</p><pre class="jq jr js jt fd lb lc ld le aw lf bi"><span id="d1f3" class="jy jz hi lc b fi lg lh l li lj">X_new = np.<strong class="lc hj">array</strong>([[5, 2.9, 1, 0.2]])<br/><strong class="lc hj">print</strong>("X_new.<strong class="lc hj">shape</strong>: <strong class="lc hj">{}</strong>".format(X_new.shape))</span></pre><blockquote class="lk ll lm"><p id="fbea" class="iq ir jo is b it iu iv iw ix iy iz ja ln jc jd je lo jg jh ji lp jk jl jm jn hb bi translated">请注意，我们将这一朵花的测量结果放入一个二维NumPy数组中的一行，因为scikit-learn总是希望数据是二维数组。</p></blockquote><p id="f649" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了进行预测，我们调用knn对象的<strong class="is hj">预测</strong>方法:</p><pre class="jq jr js jt fd lb lc ld le aw lf bi"><span id="1bee" class="jy jz hi lc b fi lg lh l li lj">prediction = knn.<strong class="lc hj">predict</strong>(X_new)<br/>print("Prediction: <strong class="lc hj">{}</strong>".format(prediction))</span></pre><p id="3a20" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们的模型预测这种新的鸢尾属于<code class="du lq lr ls lc b">setosa</code>类或标签或物种。但是我们如何知道我们是否可以信任我们的模型呢？我们不知道这个样本的正确物种，这就是建立模型的全部意义！</p><h1 id="050a" class="lt jz hi bd ka lu lv lw ke lx ly lz ki ma mb mc kl md me mf ko mg mh mi kr mj bi translated">模型评估</h1><p id="5e8e" class="pw-post-body-paragraph iq ir hi is b it kt iv iw ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm jn hb bi translated">对于任何项目，我们都需要明确定义我们将用来衡量模型性能或项目结果的指标或计算，即，为了衡量我们预测的性能，我们需要一个指标来根据给定示例的真实分类对我们的预测进行评分。这些计算和度量应该基于问题和问题域的特征进行调整。在机器学习分类模型中，我们通常使用各种性能测量指标。从通常应用于分类问题的度量中，我们可以提到<code class="du lq lr ls lc b"><strong class="is hj">Accuracy </strong>(A)</code>、<code class="du lq lr ls lc b"><strong class="is hj">Precision </strong>(P)</code>、<code class="du lq lr ls lc b"><strong class="is hj">Recall </strong>(R)</code>和<code class="du lq lr ls lc b"><strong class="is hj">F1-Score</strong></code>，...等等。</p><p id="6ef5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><a class="ae nn" href="https://developers.google.com/machine-learning/crash-course/classification/true-false-positive-negative" rel="noopener ugc nofollow" target="_blank">分类性能指标</a></p><h1 id="b10e" class="lt jz hi bd ka lu lv lw ke lx ly lz ki ma mb mc kl md me mf ko mg mh mi kr mj bi translated">准确(性)</h1><p id="ff54" class="pw-post-body-paragraph iq ir hi is b it kt iv iw ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm jn hb bi translated"><code class="du lq lr ls lc b">Accuracy</code>或者分类率衡量分类器正确的频率，它被定义为我们的模型正确预测的比例。准确度分数通过以下公式计算:</p><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es no"><img src="../Images/448be10391033208bb177e611100edc8.png" data-original-src="https://miro.medium.com/v2/resize:fit:692/format:webp/0*gzF3WU23uwkQuvqg.png"/></div></figure><p id="4d8a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了知道我们的预测有多准确，我们将计算我们对他们的诊断预测正确的情况的比例。下面的代码将创建我们的<code class="du lq lr ls lc b"><strong class="is hj">GetAccuracy</strong>()</code>函数，该函数计算<em class="jo">准确度分数</em>。</p><figure class="jq jr js jt fd ij"><div class="bz dy l di"><div class="kz la l"/></div></figure><p id="d878" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">示例:</strong>*在前五朵花中，如果我们预测它们都是列表<code class="du lq lr ls lc b">predictions = ['setosa','versicolor','versicolor','setosa','setosa']</code>，那么我们预期我们预测的准确性如下:-</p><pre class="jq jr js jt fd lb lc ld le aw lf bi"><span id="8bf3" class="jy jz hi lc b fi lg lh l li lj"><em class="jo"># Test the 'accuracy_score' function</em><br/>predictions = ['setosa','versicolor','versicolor','setosa','setosa']<br/>print(GetAccuracy(Labels[:5], predictions))</span><span id="8d01" class="jy jz hi lc b fi na lh l li lj">Predictions have an accuracy of 60.00%.</span></pre><p id="a3aa" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">同样作为第二个例子，我们可以假设我们数据集中的所有花都被预测为<code class="du lq lr ls lc b">setosa</code>。所以，下面的代码将总是预测我们数据集中的所有花都是<code class="du lq lr ls lc b">setosa</code>。</p><pre class="jq jr js jt fd lb lc ld le aw lf bi"><span id="7724" class="jy jz hi lc b fi lg lh l li lj"><strong class="lc hj">def</strong> predictions_example(data):<br/>    predictions = []<br/>    <strong class="lc hj">for</strong> flower <strong class="lc hj">in</strong> data:<br/>        <em class="jo"># Predict the survival of 'passenger'</em><br/>        predictions.append('setosa')<br/>    <br/>    <em class="jo"># Return our predictions</em><br/>    <strong class="lc hj">return</strong> pd.Series(predictions)</span><span id="576a" class="jy jz hi lc b fi na lh l li lj"><em class="jo"># Make the predictions</em><br/>predictions = predictions_example(Labels)</span></pre><ul class=""><li id="03b3" class="ml mm hi is b it iu ix iy jb mn jf mo jj mp jn mq mr ms mt bi translated">要知道预测所有的花都具有<code class="du lq lr ls lc b">setosa</code>的种类有多准确？下面的代码显示了这个预测的准确性。</li></ul><pre class="jq jr js jt fd lb lc ld le aw lf bi"><span id="ef94" class="jy jz hi lc b fi lg lh l li lj">print(GetAccuracy(Labels, predictions))</span><span id="03a0" class="jy jz hi lc b fi na lh l li lj">Predictions have an accuracy of 33.33%.</span></pre><h1 id="0748" class="lt jz hi bd ka lu lv lw ke lx ly lz ki ma mb mc kl md me mf ko mg mh mi kr mj bi translated">混淆矩阵</h1><p id="0697" class="pw-post-body-paragraph iq ir hi is b it kt iv iw ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm jn hb bi translated">在统计<code class="du lq lr ls lc b">classification</code>的情况下，我们可以使用所谓的<code class="du lq lr ls lc b">confusion matrix</code>，也称为<code class="du lq lr ls lc b">error matrix</code>。混淆矩阵被认为是对分类问题预测结果的总结。正确和错误预测的数量用计数值汇总，并按每个类别细分。这是混乱矩阵的关键。混淆矩阵显示了分类模型在进行预测时被混淆的方式。它不仅让我们洞察到分类器所犯的错误，更重要的是，让我们洞察到所犯错误的类型。</p><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es np"><img src="../Images/ca1a7e65f119bfc9e2afdca10c999eb4.png" data-original-src="https://miro.medium.com/v2/resize:fit:880/format:webp/1*9OiNMyRFSg_r0iVkMhC4WQ.png"/></div></figure><p id="59c3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">一个<code class="du lq lr ls lc b">confusion matrix</code>被构造成一个表格，通常用于描述一个<code class="du lq lr ls lc b">classification</code>模型(或“分类器”)在一组真实/真实/实际值已知的测试数据上的性能。它们是根据<code class="du lq lr ls lc b">Positive classes</code>和<code class="du lq lr ls lc b">Negative Classes</code>来定义的，前者是<code class="du lq lr ls lc b">positive</code>的观察值(例如:胸部x光图像指示存在肺炎)，后者是<code class="du lq lr ls lc b">not positive</code>的观察值(例如:胸部x光图像指示不存在肺炎，即正常)。要使用混淆矩阵计算性能指标，我们应该计算以下四个值:-</p><ul class=""><li id="46da" class="ml mm hi is b it iu ix iy jb mn jf mo jj mp jn mq mr ms mt bi translated"><strong class="is hj">真阳性</strong> ( <code class="du lq lr ls lc b"><strong class="is hj">TP</strong></code>):观测值为<code class="du lq lr ls lc b">positive</code>，预测为<code class="du lq lr ls lc b">positive</code>。</li><li id="d584" class="ml mm hi is b it mu ix mv jb mw jf mx jj my jn mq mr ms mt bi translated"><strong class="is hj">误报</strong> ( <code class="du lq lr ls lc b"><strong class="is hj">FP</strong></code>):是<code class="du lq lr ls lc b">negative</code>的观测值，但被预测<code class="du lq lr ls lc b">positive</code> ( <em class="jo">类型1错误</em>)。</li><li id="3cc9" class="ml mm hi is b it mu ix mv jb mw jf mx jj my jn mq mr ms mt bi translated"><strong class="is hj">真阴性</strong> ( <code class="du lq lr ls lc b"><strong class="is hj">TN</strong></code>):观测值为<code class="du lq lr ls lc b">negative</code>，预测为<code class="du lq lr ls lc b">negative</code>。</li><li id="8138" class="ml mm hi is b it mu ix mv jb mw jf mx jj my jn mq mr ms mt bi translated"><strong class="is hj">假阴性</strong> ( <code class="du lq lr ls lc b"><strong class="is hj">FN</strong></code>):是<code class="du lq lr ls lc b">positive</code>的观测值，但被预测<code class="du lq lr ls lc b">negative</code> ( <em class="jo">类型2误差</em>)。</li></ul><p id="7da1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><code class="du lq lr ls lc b"><strong class="is hj">True</strong></code> <strong class="is hj"> </strong>此处表示正确分类为阳性或阴性的病例，而<code class="du lq lr ls lc b"><strong class="is hj">False</strong></code> <strong class="is hj"> </strong>表示错误分类为阳性或阴性的病例。</p><p id="65a1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">监督学习算法中通常使用的混淆矩阵(在非监督学习中，它通常被称为匹配矩阵),大多数性能指标都是从混淆矩阵中计算出来的。因此，如果我们考虑<code class="du lq lr ls lc b"><strong class="is hj">accuracy</strong></code> <strong class="is hj"> </strong>得分，那么它将使用混淆矩阵计算为((TP+TN)/total)，如下所示:</p><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es nq"><img src="../Images/4f7258e20d91118345e18284f9d70651.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/0*-mTKEf5KbddOu5Uh.png"/></div></figure><p id="fc93" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">假设两种误差的成本相等，这种精度测量存在问题。根据问题的不同，99%的准确率可以是优秀、良好、一般、差或糟糕。如果我们数据集中的类都具有相似的大小，这可能是一个合理的初始度量。</p><h1 id="7a0a" class="lt jz hi bd ka lu lv lw ke lx ly lz ki ma mb mc kl md me mf ko mg mh mi kr mj bi translated">精确</h1><p id="9f77" class="pw-post-body-paragraph iq ir hi is b it kt iv iw ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm jn hb bi translated"><code class="du lq lr ls lc b">Precision</code>反映了报告的实际病例/类别的比例(即阳性鉴定的比例实际上是正确的)。它是通过将正确分类的正例总数除以预测的正例总数(TP/预测的是)来计算的，如下所示</p><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es nr"><img src="../Images/93301969a4750a4d06eaba9ab83bc928.png" data-original-src="https://miro.medium.com/v2/resize:fit:258/format:webp/1*weRSsPA2ysJK0xByDyj7YA.png"/></div></figure><p id="8f58" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">精度用于预测是，并测量其正确的频率。高精度表示标记为正的示例确实是正的(少量FP)。</p><h1 id="6087" class="lt jz hi bd ka lu lv lw ke lx ly lz ki ma mb mc kl md me mf ko mg mh mi kr mj bi translated">回忆</h1><p id="0c40" class="pw-post-body-paragraph iq ir hi is b it kt iv iw ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm jn hb bi translated">我们可以将<code class="du lq lr ls lc b">Recall</code>定义为分类器发现的真实类别的比例(TP/Actual Yes)，即实际阳性的比例被正确识别。它有时被称为<code class="du lq lr ls lc b">Sensitivity</code>，是正确分类的正例总数除以正例总数的比值，计算如下</p><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es ns"><img src="../Images/7094d57a2b594f92eb1577e69eddf52b.png" data-original-src="https://miro.medium.com/v2/resize:fit:260/format:webp/1*GzH5g4ES89mfY7ZI5XguHw.png"/></div></figure><p id="1c6e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">当它实际上是肯定的时候，使用回忆，并且测量分类器预测肯定的频率。它被称为<code class="du lq lr ls lc b">Sensitivity</code>或<code class="du lq lr ls lc b">True Positive Rate(TPR)</code>。高召回率表示类别被正确识别(少量FN)。敏感度是一种度量，它告诉我们在数据集中的所有阳性病例中，有多少被算法成功识别，即真阳性。换句话说，它测量准确识别的阳性病例的比例。你可以认为高度敏感的测试有利于排除阴性。如果有人在高灵敏度算法上得到否定的结果，很可能他们没有得到肯定的结果，因为高灵敏度算法的假阴性很低。</p><blockquote class="lk ll lm"><p id="c327" class="iq ir jo is b it iu iv iw ix iy iz ja ln jc jd je lo jg jh ji lp jk jl jm jn hb bi translated"><strong class="is hj">注意:- </strong></p><p id="2730" class="iq ir jo is b it iu iv iw ix iy iz ja ln jc jd je lo jg jh ji lp jk jl jm jn hb bi translated"><strong class="is hj">高召回</strong>，<strong class="is hj">低精度</strong>:这意味着大部分阳性样本被正确识别(低FN)但有大量的假阳性。</p><p id="5979" class="iq ir jo is b it iu iv iw ix iy iz ja ln jc jd je lo jg jh ji lp jk jl jm jn hb bi translated"><strong class="is hj">低回忆</strong>，<strong class="is hj">高精度</strong>:这表明我们错过了很多正面的例子(高FN)，但是那些我们预测为正面的确实是正面的(低FP)</p></blockquote><h1 id="146f" class="lt jz hi bd ka lu lv lw ke lx ly lz ki ma mb mc kl md me mf ko mg mh mi kr mj bi translated">f1-分数</h1><p id="d50b" class="pw-post-body-paragraph iq ir hi is b it kt iv iw ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm jn hb bi translated">因为我们有两个度量(精确度和召回率),所以有一个度量来代表这两者是有帮助的。我们计算一个F-measure，它使用<code class="du lq lr ls lc b">Harmonic Mean</code>代替算术平均值，因为它更多地惩罚了极值。F-Measure总是更接近精度或召回率的较小值。<code class="du lq lr ls lc b">F1-Score</code>是测试准确度的度量，并且用精确度和召回率(精确度和召回率之间的调和平均值)来表示，它可以被认为是同等地惩罚假阴性和假阳性的度量，但是通过它们对完整集的反向分数贡献来加权，以考虑大的类别号层次。它计算如下:-</p><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es nt"><img src="../Images/0ae34674cfb3f94b204c87f5c24ce154.png" data-original-src="https://miro.medium.com/v2/resize:fit:1026/format:webp/1*j--FZ430Xjrj1VlHIKVg_w.png"/></div></figure><h1 id="1c1c" class="lt jz hi bd ka lu lv lw ke lx ly lz ki ma mb mc kl md me mf ko mg mh mi kr mj bi translated">脱落(假阳性率)</h1><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es nu"><img src="../Images/3156ec18a1cbf57092018ec4f2a8e579.png" data-original-src="https://miro.medium.com/v2/resize:fit:356/format:webp/1*9WRkdRmjKqRRnHvhtSpXLg.png"/></div></figure><p id="d660" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">它在实际上是否定的时候使用，并测量分类器预测是的频率。I计算为(FP/实际数量)</p><h1 id="1cac" class="lt jz hi bd ka lu lv lw ke lx ly lz ki ma mb mc kl md me mf ko mg mh mi kr mj bi translated">特征</h1><p id="6a97" class="pw-post-body-paragraph iq ir hi is b it kt iv iw ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm jn hb bi translated">特异性测量数据集中的所有阴性病例，其中有多少被算法成功识别，即真阴性。换句话说，它测量准确识别的阴性病例的比例。你可以认为非常具体的测试有利于否定裁决。如果某人在高度特定的测试中有阳性结果，那么他们很可能是阳性的，因为高度特定的算法具有较低的假阳性。它也被称为<code class="du lq lr ls lc b">True Negative Rate</code>，当它实际上是否定的时候使用，因此它测量分类器预测否定的频率</p><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es nv"><img src="../Images/50de5ed00809ab23f6022970978f186a.png" data-original-src="https://miro.medium.com/v2/resize:fit:534/format:webp/1*UP0vfdGXfA1xCbfXQ29okw.png"/></div></figure><p id="5f0c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了尝试计算我们之前提到的评估指标，这就是我们之前创建的测试集出现的地方。这些数据没有被用来建立模型，但是我们确实知道测试集中每个虹膜的正确种类。因此，我们可以对测试数据中的每个虹膜进行预测，并与其标签(已知物种)进行比较。使用以下代码:</p><pre class="jq jr js jt fd lb lc ld le aw lf bi"><span id="33c0" class="jy jz hi lc b fi lg lh l li lj">y_pred = knn.<strong class="lc hj">predict</strong>(X_test)<br/><strong class="lc hj">print</strong>("Test set predictions:<strong class="lc hj">\n</strong> <strong class="lc hj">{}</strong>".<strong class="lc hj">format</strong>(y_pred))</span><span id="a46b" class="jy jz hi lc b fi na lh l li lj">Test set predictions:<br/> ['virginica' 'versicolor' 'setosa' 'virginica' 'setosa' 'virginica'<br/> 'setosa' 'versicolor' 'versicolor' 'versicolor' 'virginica' 'versicolor'<br/> 'versicolor' 'versicolor' 'versicolor' 'setosa' 'versicolor' 'versicolor'<br/> 'setosa' 'setosa' 'virginica' 'versicolor' 'setosa' 'setosa' 'virginica'<br/> 'setosa' 'setosa' 'versicolor' 'versicolor' 'setosa' 'virginica'<br/> 'versicolor' 'setosa' 'virginica' 'virginica' 'versicolor' 'setosa'<br/> 'virginica']</span></pre><p id="6762" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们可以通过计算<strong class="is hj">精确度</strong>来衡量模型的效果，精确度是预测到正确物种的花的比例:</p><pre class="jq jr js jt fd lb lc ld le aw lf bi"><span id="d742" class="jy jz hi lc b fi lg lh l li lj">print(<strong class="lc hj">GetAccuracy</strong>(y_test, y_pred))</span><span id="61d9" class="jy jz hi lc b fi na lh l li lj">Predictions have an accuracy of 97.37%.</span></pre><p id="7b2c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们也可以使用knn对象的<code class="du lq lr ls lc b">score</code>方法，它将为我们计算测试集<strong class="is hj">的准确性</strong>:</p><pre class="jq jr js jt fd lb lc ld le aw lf bi"><span id="a98f" class="jy jz hi lc b fi lg lh l li lj">print("Test set score: <strong class="lc hj">{:.2f}</strong>".format(knn.score(X_test, y_test)))</span><span id="6186" class="jy jz hi lc b fi na lh l li lj">Test set score: 0.97</span></pre><p id="2dc4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">对于这个模型，测试集<strong class="is hj">的准确度</strong>约为0.97，这意味着我们对测试集中97%的虹膜做出了正确的预测。在一些数学假设下，这意味着对于新的虹膜，我们可以预期我们的模型在97%的时候是正确的。对于我们的应用程序来说，这种高水平的准确性意味着我们的模型足够值得信赖。在大多数情况下，我们已经建立的初始模型被微调以提高其性能，我们一次又一次地重新评估它以获得最终接受的应用模型。</p><p id="e0cf" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，让我们使用<code class="du lq lr ls lc b"><em class="jo">SciKit-Learn</em></code>来创建我们的<code class="du lq lr ls lc b">Confusion Matrix,</code>并计算性能评估指标:</p><pre class="jq jr js jt fd lb lc ld le aw lf bi"><span id="75d5" class="jy jz hi lc b fi lg lh l li lj"><strong class="lc hj">from</strong> <strong class="lc hj">sklearn.metrics</strong> <strong class="lc hj">import</strong> confusion_matrix <br/><strong class="lc hj">from</strong> <strong class="lc hj">sklearn.metrics</strong> <strong class="lc hj">import</strong> accuracy_score <br/><strong class="lc hj">from</strong> <strong class="lc hj">sklearn.metrics</strong> <strong class="lc hj">import</strong> classification_report <br/><strong class="lc hj">import</strong> <strong class="lc hj">itertools</strong></span><span id="deac" class="jy jz hi lc b fi na lh l li lj">CM = <strong class="lc hj">confusion_matrix</strong>(y_test, y_pred)</span><span id="a893" class="jy jz hi lc b fi na lh l li lj">print ('Confusion Matrix :')<br/>print(CM)</span><span id="86ab" class="jy jz hi lc b fi na lh l li lj">Confusion Matrix :<br/>[[13  0  0]<br/> [ 0 15  1]<br/> [ 0  0  9]]</span><span id="62cb" class="jy jz hi lc b fi na lh l li lj">print ('Accuracy Score :',accuracy_score(y_test, y_pred) )</span><span id="77a2" class="jy jz hi lc b fi na lh l li lj">Accuracy Score : 0.9736842105263158</span><span id="ba43" class="jy jz hi lc b fi na lh l li lj">print ('Report : ')<br/>print(<strong class="lc hj">classification_report</strong>(y_test, y_pred))</span><span id="5567" class="jy jz hi lc b fi na lh l li lj"><strong class="lc hj">Report </strong>: <br/>              <strong class="lc hj">precision    recall  f1-score</strong>   support</span><span id="7aa7" class="jy jz hi lc b fi na lh l li lj">      setosa       1.00      1.00      1.00        13<br/>  versicolor       1.00      0.94      0.97        16<br/>   virginica       0.90      1.00      0.95         9</span><span id="f2bc" class="jy jz hi lc b fi na lh l li lj">    accuracy                           0.97        38<br/>   macro avg       0.97      0.98      0.97        38<br/>weighted avg       0.98      0.97      0.97        38</span></pre><p id="946f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">要绘制混淆矩阵:</p><p id="5277" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">def</strong>plot _ Confusion _ matrix(cm，classes，normalize= <strong class="is hj"> False </strong>，title= '混淆矩阵'，cmap = PLT . cm . blues):<br/><em class="jo">" " "</em><br/><em class="jo">该函数打印并绘制混淆矩阵。可以通过设置“normalize=True”来应用规范化。</em><br/><em class="jo"/><br/><strong class="is hj">if</strong>normalize:<br/>cm = cm . astype(' float ')/cm . sum(axis = 1)[:，np.newaxis] <br/> print("规格化的混淆矩阵")<br/> <strong class="is hj"> else </strong> : <br/> print('混淆矩阵，无规格化')</p><pre class="jq jr js jt fd lb lc ld le aw lf bi"><span id="7868" class="jy jz hi lc b fi lg lh l li lj">    print(cm)</span><span id="2251" class="jy jz hi lc b fi na lh l li lj">    plt.imshow(cm, interpolation='nearest', cmap=cmap)<br/>    plt.title(title)<br/>    plt.colorbar()<br/>    tick_marks = np.arange(len(classes))<br/>    plt.xticks(tick_marks, classes, rotation=45)<br/>    plt.yticks(tick_marks, classes)</span><span id="bd05" class="jy jz hi lc b fi na lh l li lj">    fmt = '.2f' <strong class="lc hj">if</strong> normalize <strong class="lc hj">else</strong> 'd'<br/>    thresh = cm.max() / 2.<br/>    <strong class="lc hj">for</strong> i, j <strong class="lc hj">in</strong> itertools.product(range(cm.shape[0]), range(cm.shape[1])):<br/>        plt.text(j, i, format(cm[i, j], fmt),<br/>                 horizontalalignment="center",<br/>                 color="white" <strong class="lc hj">if</strong> cm[i, j] &gt; thresh <strong class="lc hj">else</strong> "black")</span><span id="b92a" class="jy jz hi lc b fi na lh l li lj">    plt.ylabel('True label')<br/>    plt.xlabel('Predicted label')<br/>    plt.tight_layout()</span><span id="e53f" class="jy jz hi lc b fi na lh l li lj"><em class="jo"># Plot confusion matrix</em><br/>plt.figure()<br/>plot_confusion_matrix(CM, classes=iris['target_names'], title='Confusion matrix, without normalization',normalize=<strong class="lc hj">True</strong>)<br/>plt.show()</span></pre><figure class="jq jr js jt fd ij er es paragraph-image"><div class="er es no"><img src="../Images/efcc458277423808a959f85e2cfe4945.png" data-original-src="https://miro.medium.com/v2/resize:fit:692/format:webp/1*UNYEzF1fNPchhvH34OkeqQ.png"/></div></figure><h1 id="a676" class="lt jz hi bd ka lu lv lw ke lx ly lz ki ma mb mc kl md me mf ko mg mh mi kr mj bi translated">结论</h1><p id="a328" class="pw-post-body-paragraph iq ir hi is b it kt iv iw ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm jn hb bi translated">让我们在这里总结一下我们的故事。我们从问题陈述和算法选择开始，通过使用花的物理测量来制定预测特定花属于哪种鸢尾的任务，然后我们准备我们的项目并加载相关的数据集。我们使用一个由专家用正确的物种进行注释的测量数据集来建立我们的模型，使这成为一个监督学习任务(三类分类问题)。之后，我们开始探索和可视化数据以了解它，然后将我们的数据分为训练集和测试集，以构建我们的模型，并通过训练和测试来拟合它。简单地说，我们可以将构建机器学习应用程序的基本步骤总结如下</p><ul class=""><li id="3a33" class="ml mm hi is b it iu ix iy jb mn jf mo jj mp jn mq mr ms mt bi translated">定义问题</li><li id="ea81" class="ml mm hi is b it mu ix mv jb mw jf mx jj my jn mq mr ms mt bi translated">描述解决方案并选择算法</li><li id="6e34" class="ml mm hi is b it mu ix mv jb mw jf mx jj my jn mq mr ms mt bi translated">准备项目环境</li><li id="b0f3" class="ml mm hi is b it mu ix mv jb mw jf mx jj my jn mq mr ms mt bi translated">探索和可视化数据</li><li id="dc4a" class="ml mm hi is b it mu ix mv jb mw jf mx jj my jn mq mr ms mt bi translated">准备数据并将其拆分</li><li id="245b" class="ml mm hi is b it mu ix mv jb mw jf mx jj my jn mq mr ms mt bi translated">建立并训练一个初始模型</li><li id="1a77" class="ml mm hi is b it mu ix mv jb mw jf mx jj my jn mq mr ms mt bi translated">评估和微调</li><li id="0bfd" class="ml mm hi is b it mu ix mv jb mw jf mx jj my jn mq mr ms mt bi translated">构建最终模型并对其进行评估</li><li id="b9f8" class="ml mm hi is b it mu ix mv jb mw jf mx jj my jn mq mr ms mt bi translated">将最终模型应用于看不见的数据</li></ul><p id="9f71" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">最后，请注意，<code class="du lq lr ls lc b"><strong class="is hj">fit</strong></code>、<code class="du lq lr ls lc b"><strong class="is hj">predict</strong></code>和<code class="du lq lr ls lc b"><strong class="is hj">score</strong></code>、<strong class="is hj">、</strong>方法是<em class="jo"> scikit-learn </em>中监督模型的公共接口，借助本章介绍的概念，您可以将这些模型应用于许多机器学习任务。</p></div></div>    
</body>
</html>