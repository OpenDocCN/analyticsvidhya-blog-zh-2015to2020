<html>
<head>
<title>TOD-BERT: Pre-training Transformer for Task-Oriented Dialogue Systems</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">TOD-BERT:面向任务对话系统的预训练转换器</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/tod-bert-pre-training-transformer-for-task-oriented-dialogue-systems-80750c510134?source=collection_archive---------29-----------------------#2020-11-30">https://medium.com/analytics-vidhya/tod-bert-pre-training-transformer-for-task-oriented-dialogue-systems-80750c510134?source=collection_archive---------29-----------------------#2020-11-30</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="a75f" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">研究论文演练</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/7654f13f76d19b1948a459285f0c2fde.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*H-8lgumwUEI0MbGGHk5nLw.png"/></div></div></figure><p id="4c8d" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">对话代理(Conversational agents)是计算机系统，用于在输入和输出通道上以一种或多种文本、语音和其他通信模式与人对话。</p><p id="7a97" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">来自<a class="ae kf" href="https://2020.emnlp.org/" rel="noopener ugc nofollow" target="_blank"> EMNLP 2020 </a>的这篇论文针对面向任务的对话系统/聊天机器人在现有的 BERT 基础架构上提出了一个新的预训练目标，因为一般文本和面向任务的对话之间的语言模式的潜在差异使得现有的预训练<a class="ae kf" href="https://en.wikipedia.org/wiki/Language_model" rel="noopener ugc nofollow" target="_blank">语言模型</a>在实践中用处不大。</p><p id="d189" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">面向任务的聊天机器人只能帮助用户完成各种各样的任务。它们可以帮助一个人完成明确定义的任务，如查看账户余额、预订或找到正确的食谱。</p><p id="fdf5" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">作者使用 9 个不同的人-人多回合对话数据集来用修改的目标函数预训练他们的模型。他们的方法优于现有的方法，如<strong class="jl hj"> DialoGPT </strong>、<strong class="jl hj"> GPT2 </strong>、<strong class="jl hj"> BERT </strong>等。在这个领域，作者使用下游任务如意图检测、对话状态跟踪、对话状态预测、响应选择来验证它。他们还表明<strong class="jl hj"> TOD-BERT </strong>具有更强的少数镜头能力，可以缓解面向任务对话的数据稀缺问题。</p><h1 id="bef4" class="kg kh hi bd ki kj kk kl km kn ko kp kq io kr ip ks ir kt is ku iu kv iv kw kx bi translated">你对此感兴趣吗？</h1><p id="f000" class="pw-post-body-paragraph jj jk hi jl b jm ky ij jo jp kz im jr js la ju jv jw lb jy jz ka lc kc kd ke hb bi translated">然后，观看详细的论文演练—</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="ld le l"/></div></figure><blockquote class="lf lg lh"><p id="ddb8" class="jj jk li jl b jm jn ij jo jp jq im jr lj jt ju jv lk jx jy jz ll kb kc kd ke hb bi translated">⏩论文链接:<a class="ae kf" href="https://arxiv.org/pdf/2004.06871.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2004.06871.pdf</a></p><p id="fb85" class="jj jk li jl b jm jn ij jo jp jq im jr lj jt ju jv lk jx jy jz ll kb kc kd ke hb bi translated">⏩论文作者:钱，史蒂文·海，理查德·索契，熊</p><p id="2fa4" class="jj jk li jl b jm jn ij jo jp jq im jr lj jt ju jv lk jx jy jz ll kb kc kd ke hb bi translated">⏩组织:Salesforce Research</p></blockquote><p id="8319" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><em class="li">一定要让</em> <strong class="jl hj"> <em class="li">分享</em></strong><em class="li"/><strong class="jl hj"><em class="li">像</em> </strong> <em class="li">一样的工作！</em></p><p id="856d" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><em class="li">干杯！</em></p></div></div>    
</body>
</html>