<html>
<head>
<title>Introduction to Recurrent Neural Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">递归神经网络导论</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/introduction-to-recurrent-neural-networks-441d55321e2e?source=collection_archive---------21-----------------------#2020-03-05">https://medium.com/analytics-vidhya/introduction-to-recurrent-neural-networks-441d55321e2e?source=collection_archive---------21-----------------------#2020-03-05</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="0c2d" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">自然语言处理的核心</h2></div><p id="2ca9" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在人工神经网络介绍系列的这一章中，我们将讨论递归神经网络(RNNs ),它是自然语言处理(NLP)和机器翻译技术的构建模块。这是因为他们很容易理解像句子和语音片段这样的连续数据。</p><p id="946b" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">RNN的目标是利用基于内存的架构对序列数据进行预测。与没有两个输入共享知识的前馈网络相反，RNNs结合了额外的存储器状态。因此，预测不仅取决于当前状态，还取决于先前的信息。rnn在各种任务中都有其用途，如将文本翻译为语音、预测句子中的新单词、将音频转换为文本、语言翻译和图像/视频字幕。</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es jt"><img src="../Images/3a4d6287f871818001eefbf4f1e994bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5DEagKmxi-ffGcJX15QWCw.png"/></div></div><figcaption class="kf kg et er es kh ki bd b be z dx translated">RNN概述[1]</figcaption></figure><p id="95dc" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">经典的RNN架构包含输入、隐藏和输出层，但与前馈网络不同，隐藏状态本质上是循环的，允许数据从一个时间步长传播到另一个时间步长。为了清楚地理解RNN架构的工作机制，对展开的具有一层的RNN的详细探索就足够了。上图所示的(输入-隐藏RNN单元-输出)集合代表每个时间步的网络[1]。以下是每个时间步发生的事件:</p><ul class=""><li id="93ad" class="kj kk hi iz b ja jb jd je jg kl jk km jo kn js ko kp kq kr bi translated">在时间步骤<em class="ks"> t-1 </em>，网络使用像一键编码、word2vec或GloVe这样的单词嵌入技术对单词进行编码，以产生矢量<em class="ks"> xᵗ⁻ </em></li><li id="624e" class="kj kk hi iz b ja kt jd ku jg kv jk kw jo kx js ko kp kq kr bi translated">编码的输入字<em class="ks"> xᵗ⁻ </em>被馈入RNN单元，该单元产生输出<em class="ks"> y'ᵗ⁻ </em>和存储器状态<em class="ks"> hᵗ⁻ </em>。应当注意，存储器状态是输入<em class="ks"> xᵗ⁻ </em>和存储器状态<em class="ks"> hᵗ⁻ </em>的先前值的结果。</li><li id="ac9c" class="kj kk hi iz b ja kt jd ku jg kv jk kw jo kx js ko kp kq kr bi translated">通过将输出<em class="ks"> y'ᵗ⁻ </em>与训练开始时创建的文本语料库进行比较，对输出<em class="ks">进行解码，从而获得时间步长<em class="ks"> t-1 </em>处的实际单词预测。</em></li></ul><p id="d120" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这就结束了我们对递归神经网络的介绍，在这里我们讨论了它们的基本结构和通过它的信息流。在本系列的下一章中，我们将深入探讨构成我们现代RNN的循环人工神经元是如何工作的。(这是一个相当高级的话题，如果你不熟悉矩阵和激活函数等数学概念，我建议你跳过它)。</p></div><div class="ab cl ky kz gp la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="hb hc hd he hf"><p id="0822" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">[1] Kostadinov，S. &amp; Safari，一家奥莱利传媒公司，2018年。递归神经网络与Python快速入门指南第1版。，Packt出版公司。</p><p id="fe04" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">[2]朱利安博士，2018。用Pytorch进行深度学习快速入门指南:学习用Python训练和部署神经网络模型，伯明翰:Packt。</p></div></div>    
</body>
</html>