<html>
<head>
<title>Spam or Ham? Email Classifier Using Python (MultinomialNB v/s XGBoost Classifiers)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">垃圾邮件还是火腿？使用Python的电子邮件分类器(MultinomialNB v/s XGBoost分类器)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/spam-email-detector-73518ba46340?source=collection_archive---------6-----------------------#2020-07-11">https://medium.com/analytics-vidhya/spam-email-detector-73518ba46340?source=collection_archive---------6-----------------------#2020-07-11</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/2099a3c07ac5fa48d9b7c2afb3258513.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1xGIi6G_ukoYQ6mLU4zdVA.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">图片来自<a class="ae iu" href="https://www.needpix.com/photo/462592/spam-mail-email-mailbox-garbage-trash" rel="noopener ugc nofollow" target="_blank">cattu</a>(pixabay.com)</figcaption></figure><p id="67ab" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">你好。不久前，我正坐在电脑前，等待我的供应商发来一份大订单的邮件。在一天结束时变得焦躁不安后，我打电话给那个家伙，解释了延迟的原因。他向我保证，尽管我在收件箱里找不到它，他还是在早上就把它寄出去了。够困惑，我开始通过我所有的文件夹刮，让我惊讶的是，我发现它在我的垃圾邮件文件夹休息。我很好奇，最终了解到谷歌是如何在不通知我的情况下自动分类我所有的电子邮件的。可以肯定的是，这种情况可能会发生在我们很多人身上。所以我决定为自己做一个垃圾邮件或火腿分类器，看看我能不能让它工作。如果你想学习为自己制作一个，请继续阅读！</p><p id="571d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">此外，查看我的其他帖子，了解更多机器学习算法的应用。一定要检查，然后通过评论分享你的见解，并与你的朋友分享，看看他们对此有何看法。您也可以按照我的文章创建这样的模型，并根据您的兴趣进行调整。</p></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><h1 id="822f" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">什么是垃圾邮件？</h1><p id="7a3d" class="pw-post-body-paragraph iv iw hi ix b iy ky ja jb jc kz je jf jg la ji jj jk lb jm jn jo lc jq jr js hb bi translated">垃圾邮件是不请自来且不受欢迎的垃圾邮件，大量发送到任意的收件人列表中。通常，垃圾邮件是出于商业目的发送的。它可以通过僵尸网络，即被感染的计算机网络大量发送。虽然有些人认为这是不道德的，但许多企业仍然使用垃圾邮件。每封邮件的成本低得令人难以置信，而且企业可以持续地发送大量邮件。垃圾邮件也可能是恶意尝试访问您的计算机。<a class="ae iu" href="https://www.cisco.com/c/en/us/products/security/email-security/what-is-spam.html" rel="noopener ugc nofollow" target="_blank">阅读更多..</a></p><h1 id="5b95" class="ka kb hi bd kc kd ld kf kg kh le kj kk kl lf kn ko kp lg kr ks kt lh kv kw kx bi translated">关于项目</h1><p id="8f4e" class="pw-post-body-paragraph iv iw hi ix b iy ky ja jb jc kz je jf jg la ji jj jk lb jm jn jo lc jq jr js hb bi translated">这是我在学习数据科学和机器学习概念的同时从事的一个项目。这里的目标是识别电子邮件是垃圾邮件还是火腿。我们将获取一个带有标签的电子邮件数据集，并应用分类技术。我们可以稍后在未分类的电子邮件消息上测试该模型的准确性和性能。类似的技术可以应用于其他NLP应用，如情感分析等。</p><h1 id="8ba8" class="ka kb hi bd kc kd ld kf kg kh le kj kk kl lf kn ko kp lg kr ks kt lh kv kw kx bi translated">数据</h1><p id="15da" class="pw-post-body-paragraph iv iw hi ix b iy ky ja jb jc kz je jf jg la ji jj jk lb jm jn jo lc jq jr js hb bi translated">我使用的垃圾数据库数据集来自<a class="ae iu" href="https://archive.ics.uci.edu/ml/datasets/Spambase" rel="noopener ugc nofollow" target="_blank"> UCI的ML知识库</a>，可以从链接下载。</p><p id="0d88" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">“spambase.data”的最后一列表示电子邮件是否被视为垃圾邮件(1)或(0)，即未经请求的商业电子邮件。大多数属性表明特定的单词或字符是否在电子邮件中频繁出现。游程长度属性(55–57)测量连续大写字母序列的长度。以下是属性的定义:</p><ul class=""><li id="12cf" class="li lj hi ix b iy iz jc jd jg lk jk ll jo lm js ln lo lp lq bi translated">word _ freq _ word类型的连续实数[0，100]属性=电子邮件中匹配WORD的单词的百分比，即100 *(该单词在电子邮件中出现的次数)/电子邮件中的总单词数。在这种情况下,“单词”是由非字母数字字符或字符串结尾限定的任何字母数字字符串。</li><li id="86e1" class="li lj hi ix b iy lr jc ls jg lt jk lu jo lv js ln lo lp lq bi translated">char _ freq _ char类型的连续实数[0，100]属性=电子邮件中与CHAR匹配的字符的百分比，即100 *(字符出现次数)/电子邮件中的总字符数</li><li id="99b6" class="li lj hi ix b iy lr jc ls jg lt jk lu jo lv js ln lo lp lq bi translated">capital _ run _ length _ average类型的连续实数[1，…]属性=连续大写字母序列的平均长度</li><li id="22a0" class="li lj hi ix b iy lr jc ls jg lt jk lu jo lv js ln lo lp lq bi translated">1连续整数[1，capital _ run _ length _ longest类型的属性=最长不间断大写字母序列的长度</li><li id="03e4" class="li lj hi ix b iy lr jc ls jg lt jk lu jo lv js ln lo lp lq bi translated">1连续整数[1，capital _ run _ length _ total类型的属性=连续大写字母序列的长度总和=电子邮件中大写字母的总数</li><li id="25af" class="li lj hi ix b iy lr jc ls jg lt jk lu jo lv js ln lo lp lq bi translated">1垃圾邮件类型的名义{0，1}类属性=表示电子邮件是否被视为垃圾邮件(1)或(0)，即未经请求的商业电子邮件。</li></ul><h1 id="76f4" class="ka kb hi bd kc kd ld kf kg kh le kj kk kl lf kn ko kp lg kr ks kt lh kv kw kx bi translated">模型</h1><p id="d48e" class="pw-post-body-paragraph iv iw hi ix b iy ky ja jb jc kz je jf jg la ji jj jk lb jm jn jo lc jq jr js hb bi translated">我们使用多项式朴素贝叶斯分类器，然后使用XGBoost分类器来拟合模型，以寻求结果的改进。最后，准确度分数和混淆矩阵告诉我们模型的效果如何。</p><h2 id="34f9" class="lw kb hi bd kc lx ly lz kg ma mb mc kk jg md me ko jk mf mg ks jo mh mi kw mj bi translated"><strong class="ak">多项式朴素贝叶斯分类器</strong></h2><p id="4565" class="pw-post-body-paragraph iv iw hi ix b iy ky ja jb jc kz je jf jg la ji jj jk lb jm jn jo lc jq jr js hb bi translated">在统计学中，朴素贝叶斯分类器是一个简单的“概率分类器”家族，它基于应用贝叶斯定理，在特征之间具有强(朴素)独立性假设。它们是最简单的贝叶斯网络模型。朴素贝叶斯分类器是高度可扩展的，在学习问题中需要许多与变量(特征/预测器)数量成线性的参数。<a class="ae iu" href="https://en.wikipedia.org/wiki/Naive_Bayes_classifier" rel="noopener ugc nofollow" target="_blank">阅读更多..</a></p><h2 id="0bb7" class="lw kb hi bd kc lx ly lz kg ma mb mc kk jg md me ko jk mf mg ks jo mh mi kw mj bi translated"><strong class="ak"> XGBoost回归器</strong></h2><p id="6b4a" class="pw-post-body-paragraph iv iw hi ix b iy ky ja jb jc kz je jf jg la ji jj jk lb jm jn jo lc jq jr js hb bi translated">XGBoost是一个优化的分布式梯度增强库，旨在高效、灵活和可移植。它在梯度推进框架下实现机器学习算法。XGBoost提供了一种并行的树提升(也称为GBDT，GBM ),可以快速准确地解决许多数据科学问题。相同的代码运行在主要的分布式环境(Hadoop、SGE、MPI)上，可以解决超过数十亿个例子的问题。<a class="ae iu" href="https://github.com/dmlc/xgboost" rel="noopener ugc nofollow" target="_blank">阅读更多..</a></p><h1 id="7f5a" class="ka kb hi bd kc kd ld kf kg kh le kj kk kl lf kn ko kp lg kr ks kt lh kv kw kx bi translated">开发模型</h1><p id="3860" class="pw-post-body-paragraph iv iw hi ix b iy ky ja jb jc kz je jf jg la ji jj jk lb jm jn jo lc jq jr js hb bi translated"><strong class="ix hj">第一步:</strong>加载必要的包，读取数据。这里提供的数据没有带标签的列，因此可以选择更新标签以便更好地理解数据。为了保持整洁，我没有粘贴代码来包含本文中的列，尽管您可以在本文末尾附加的完整代码中找到它。</p><pre class="mk ml mm mn fd mo mp mq mr aw ms bi"><span id="909a" class="lw kb hi mp b fi mt mu l mv mw"><strong class="mp hj">import</strong> <strong class="mp hj">pandas</strong> <strong class="mp hj">as</strong> <strong class="mp hj">pd</strong><br/><strong class="mp hj">import</strong> <strong class="mp hj">numpy</strong> <strong class="mp hj">as</strong> <strong class="mp hj">np</strong><br/><strong class="mp hj">import</strong> <strong class="mp hj">re</strong></span><span id="cae5" class="lw kb hi mp b fi mx mu l mv mw">data = pd.read_csv('spambase_data', names=cols, header=<strong class="mp hj">None</strong>)<br/>X = data.iloc[:, :-1]<br/>y = data.classified</span><span id="8d23" class="lw kb hi mp b fi mx mu l mv mw">print('Data Table <strong class="mp hj">\n</strong>')<br/>display(X)<br/>print('<strong class="mp hj">\n\n</strong>Tags Table')<br/>display(y)</span></pre><p id="75c5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">输出:</p><figure class="mk ml mm mn fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es my"><img src="../Images/1f13c240a88e74a844591c04951692f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AfmIT79DUUIqWe72za_FEg.png"/></div></div></figure><p id="3bc7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在我们知道我们有4600封电子邮件样本。此外，我们注意到数据集已经从单词转换为数字，因此我们可以立即开始构建ML模型。你可以阅读我写的关于创建一个<a class="ae iu" href="https://medium.com/@palri/fake-news-detector-cbc47b085d4https://medium.com/@palri/fake-news-detector-cbc47b085d4" rel="noopener">假新闻检测器</a>的文章，我在文章中详细讨论了将文字转换成数字的过程。</p><p id="efc7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">第二步:</strong>将数据集分成训练和测试子集。</p><pre class="mk ml mm mn fd mo mp mq mr aw ms bi"><span id="86ea" class="lw kb hi mp b fi mt mu l mv mw"><strong class="mp hj">from</strong> <strong class="mp hj">sklearn.model_selection</strong> <strong class="mp hj">import</strong> train_test_split <strong class="mp hj">as</strong> tts<br/><br/>X_train, X_test, y_train, y_test = tts(X, y, test_size=0.3, random_state=0)</span></pre><p id="5a89" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">第三步:</strong>使用训练子集建立多项式分类器模型，然后在测试集上测试模型的有效性。</p><pre class="mk ml mm mn fd mo mp mq mr aw ms bi"><span id="4e7d" class="lw kb hi mp b fi mt mu l mv mw"><strong class="mp hj">from</strong> <strong class="mp hj">sklearn.naive_bayes</strong> <strong class="mp hj">import</strong> MultinomialNB<br/><strong class="mp hj">from</strong> <strong class="mp hj">sklearn.metrics</strong> <strong class="mp hj">import</strong> accuracy_score<br/><br/>mnb = MultinomialNB()<br/>mnb.fit(X_train, y_train)<br/><br/>predicted = mnb.predict(X_test)<br/><br/>score = accuracy_score(y_test, predicted)<br/>print('Accuracy Score: <strong class="mp hj">\n</strong>', (100*score))</span></pre><p id="d755" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">输出:</p><pre class="mk ml mm mn fd mo mp mq mr aw ms bi"><span id="e845" class="lw kb hi mp b fi mt mu l mv mw">Accuracy Score: 80.95582910934105</span></pre><p id="9a5f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们取得了大约81%的分数。这意味着大约20%的邮件会被错误分类。</p><p id="f79b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">由于我们正在对垃圾邮件和非垃圾邮件进行分类，因此避免误报分类(即将非垃圾邮件归类为垃圾邮件)至关重要。为此，我们将检查我们的分类的分布。</p><p id="29a3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">步骤4: </strong>创建分类报告和混淆矩阵(我已经使用了<a class="ae iu" href="https://seaborn.pydata.org/" rel="noopener ugc nofollow" target="_blank"> seabron </a>库来创建混淆矩阵的更具说明性的输出，您也可以使用默认的<a class="ae iu" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html" rel="noopener ugc nofollow" target="_blank">sk learn . Confusion _ Matrix()</a>视图来评估我们的模型执行得如何:</p><pre class="mk ml mm mn fd mo mp mq mr aw ms bi"><span id="c23b" class="lw kb hi mp b fi mt mu l mv mw"><strong class="mp hj">import</strong> <strong class="mp hj">seaborn</strong> <strong class="mp hj">as</strong> <strong class="mp hj">sn</strong><br/><strong class="mp hj">from</strong> <strong class="mp hj">sklearn.metrics</strong> <strong class="mp hj">import</strong> confusion_matrix <strong class="mp hj">as</strong> cm<br/><strong class="mp hj">from</strong> <strong class="mp hj">sklearn.metrics</strong> <strong class="mp hj">import</strong> classification_report <strong class="mp hj">as</strong> cr<br/><br/>cm1 = cm(y_test, predicted, labels=[0, 1])<br/>df_cm = pd.DataFrame(cm1, range(2), range(2))<br/>sn.set(font_scale=1)<br/>sn.heatmap(df_cm, annot=<strong class="mp hj">True</strong>, annot_kws={'size':14}, fmt='d').set_title('Confusion Matrix')<br/><br/>print('<strong class="mp hj">\n</strong>Classification Report: <strong class="mp hj">\n</strong>', cr(y_test, predicted))</span></pre><p id="3fdf" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">输出:</p><figure class="mk ml mm mn fd ij er es paragraph-image"><div class="er es mz"><img src="../Images/4f21aa634e0e80d4935056fdd696f1cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:820/format:webp/1*SyviMUOc9G1sP1pwmDSn1w.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">多项式分类器的结果</figcaption></figure><p id="8676" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">看起来我们有大约10%的假阳性分类。这可不好。这可能是我的供应商的电子邮件出现在我的垃圾邮件文件夹中的原因吗？请在评论区告诉我。</p><p id="7e10" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们发现如此高的误报率会使人们丢失一些重要的电子邮件。现在让我们使用一个更复杂的分类器，随机森林分类器的集合XGBoost。</p><p id="fdfe" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">第五步:</strong>用训练集建立XGBoost模型，在测试集上测试，打印出分类报告和混淆矩阵。</p><p id="e4d1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">注意:默认情况下，XGBoost作为回归变量工作，所以我们得到的结果是连续的数字，作为概率。我们需要根据需要将概率转换成二进制分类。</p><pre class="mk ml mm mn fd mo mp mq mr aw ms bi"><span id="46f4" class="lw kb hi mp b fi mt mu l mv mw"><strong class="mp hj">from</strong> <strong class="mp hj">xgboost</strong> <strong class="mp hj">import</strong> XGBRegressor<br/><br/>xgb = XGBRegressor(n_estimators=120, leanring_rate=0.075)<br/>xgb.fit(X_train, y_train)<br/><em class="na">#xgb.fit(X_train, y_train, early_stopping_rounds=10, eval_set=[(X_test, y_test)], verbose=False)</em><br/><br/>predicted1 = xgb.predict(X_test)</span><span id="9687" class="lw kb hi mp b fi mx mu l mv mw">score1 = accuracy_score(y_test, (predicted1 &gt; 0.5))<br/>print('Accuracy Score on XGBoost: <strong class="mp hj">\n</strong>', (100*score1))</span><span id="b8fa" class="lw kb hi mp b fi mx mu l mv mw">cm2 = cm(y_test, predicted1 &gt; 0.5, labels=[0, 1])<br/>df_cm = pd.DataFrame(cm2, range(2), range(2))<br/>sn.set(font_scale=1)<br/>sn.heatmap(df_cm, annot=<strong class="mp hj">True</strong>, annot_kws={'size':14}, fmt='d').set_title('Confusion Matrix')</span><span id="a411" class="lw kb hi mp b fi mx mu l mv mw">print('<strong class="mp hj">\n</strong>Classification Report: <strong class="mp hj">\n</strong>', cr(y_test, (predicted1 &gt; 0.5)))</span></pre><p id="8b73" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">输出:</p><pre class="mk ml mm mn fd mo mp mq mr aw ms bi"><span id="25ac" class="lw kb hi mp b fi mt mu l mv mw">Accuracy Score on XGBoost: <br/> 94.6415640839971</span></pre><figure class="mk ml mm mn fd ij er es paragraph-image"><div class="er es nb"><img src="../Images/099c3f67ff8028f1db932f9798a05c9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:816/format:webp/1*faODM5f6OBGnkWA_2zmk6w.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">XGBoost结果为假阳性</figcaption></figure><p id="ae64" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">使用XGBoost回归器，我们已经将假阳性分类减少到3%以下。此外，我们已经将所有错误分类减少到6%以下，将准确率提高到95%左右。</p><p id="28a4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">尽管准确率很高，但将3%的垃圾邮件标记为垃圾邮件可能是不可接受的。为了解决这个问题，我们现在将限制任何假阳性结果。</p><p id="da2d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">第六步:</strong>我们会照原样重复第五步，只有一个小改动。在将预测输出转换为概率时，我们将指示模型只将那些概率大于0.9的垃圾邮件标记为垃圾邮件。</p><pre class="mk ml mm mn fd mo mp mq mr aw ms bi"><span id="3d55" class="lw kb hi mp b fi mt mu l mv mw">score1 = accuracy_score(y_test, (predicted1 &gt; 0.9))<br/>print('Accuracy Score on XGBoost: <strong class="mp hj">\n</strong>', (100*score1))</span><span id="9a2b" class="lw kb hi mp b fi mx mu l mv mw">cm2 = cm(y_test, predicted1 &gt; 0.9, labels=[0, 1])<br/>df_cm = pd.DataFrame(cm2, range(2), range(2))<br/>sn.set(font_scale=1)<br/>sn.heatmap(df_cm, annot=<strong class="mp hj">True</strong>, annot_kws={'size':14}, fmt='d').set_title('Confusion Matrix')</span><span id="cefb" class="lw kb hi mp b fi mx mu l mv mw">print('<strong class="mp hj">\n</strong>Classification Report: <strong class="mp hj">\n</strong>', cr(y_test, (predicted1 &gt; 0.9)))</span></pre><p id="1ada" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">输出:</p><pre class="mk ml mm mn fd mo mp mq mr aw ms bi"><span id="3ced" class="lw kb hi mp b fi mt mu l mv mw">Accuracy Score on XGBoost: <br/> 87.97972483707458</span></pre><figure class="mk ml mm mn fd ij er es paragraph-image"><div class="er es nc"><img src="../Images/4b01f00813af7a8d27a8f235e3ffbd52.png" data-original-src="https://miro.medium.com/v2/resize:fit:826/format:webp/1*uBd8Z3-HvlNK3SLEM71dcA.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">允许最小假阳性的XGBoost结果</figcaption></figure><p id="d55b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在将火腿误分类为垃圾邮件的同时，我们放弃了自己的准确率，降到了88%。我相信阅读一些额外的垃圾邮件比遗漏一些非常重要的电子邮件要好，比如订单！</p><h1 id="1d6f" class="ka kb hi bd kc kd ld kf kg kh le kj kk kl lf kn ko kp lg kr ks kt lh kv kw kx bi translated">结果</h1><p id="9027" class="pw-post-body-paragraph iv iw hi ix b iy ky ja jb jc kz je jf jg la ji jj jk lb jm jn jo lc jq jr js hb bi translated">我们已经使用两种不同的算法成功地创建并实现了机器学习模型。我们发现，在我们的情况下，XGBoost的集合随机森林算法比基于朴素贝叶斯的多项式算法效果更好。</p><p id="c4ad" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们看到精度和准确度是成反比的，达到一个会导致另一个的损失。</p><h1 id="4b67" class="ka kb hi bd kc kd ld kf kg kh le kj kk kl lf kn ko kp lg kr ks kt lh kv kw kx bi translated">未来的工作</h1><p id="55d8" class="pw-post-body-paragraph iv iw hi ix b iy ky ja jb jc kz je jf jg la ji jj jk lb jm jn jo lc jq jr js hb bi translated">我打算通过添加一个图形用户界面(GUI)来扩展这个项目，用户可以粘贴任何文本片段，并在结果中获得其分类。给我写信，如果你有一些技巧来实现这一点！</p><h1 id="e6aa" class="ka kb hi bd kc kd ld kf kg kh le kj kk kl lf kn ko kp lg kr ks kt lh kv kw kx bi translated">参考</h1><p id="e686" class="pw-post-body-paragraph iv iw hi ix b iy ky ja jb jc kz je jf jg la ji jj jk lb jm jn jo lc jq jr js hb bi translated">你可以在<a class="ae iu" href="https://github.com/rpalri/Spam_Detection_ML" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上找到我的代码。</p><p id="5480" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如果你喜欢我的作品，请通过分享和关注我的故事来表达你的欣赏。当我不断学习新的东西时，这会让我有动力与你们分享！</p><p id="ab32" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如果你不喜欢我的作品，请分享你的想法和建议。这将有助于我下次为您改进和开发更好的阅读材料！</p><p id="235d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">谢谢你。</p></div></div>    
</body>
</html>