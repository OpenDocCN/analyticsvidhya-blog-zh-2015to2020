# çŠ¬ç§åˆ†ç±»å™¨â€”â€”ç¥žç»ç½‘ç»œçš„åŠ›é‡

> åŽŸæ–‡ï¼š<https://medium.com/analytics-vidhya/dog-breed-classifier-power-of-neural-networks-a277f4ad91be?source=collection_archive---------16----------------------->

ä¸ä»…æŠŠç‹—ï¼Œè€Œä¸”æŠŠäººçš„å½¢è±¡ä¹Ÿå½’ç±»ä¸ºç‹—çš„å“ç§ï¼Œè¿™æ˜¯å¤šä¹ˆæœ‰è¶£å•Šï¼

![](img/d515effc404b7752392c88f103e7d560.png)

äººå·¥ç¥žç»ç½‘ç»œ[æ¥æº](https://commons.wikimedia.org/wiki/File:Single-layer_feedforward_artificial_neural_network.png)

ä»¤äººéš¾ä»¥ç½®ä¿¡çš„æ˜¯ï¼Œä¸Šé¢æ˜¾ç¤ºçš„è¾¹å’ŒèŠ‚ç‚¹åˆ›é€ äº†ä¸€å¥—å¼ºå¤§çš„ç®—æ³•ï¼Œèƒ½å¤Ÿæ¼‚äº®åœ°è¯†åˆ«æ¨¡å¼ã€‚è¿™äº›éƒ½æ˜¯åœ¨äººè„‘çš„åŸºç¡€ä¸Šå»ºç«‹çš„ï¼Œäººè„‘å¯ä»¥é€šè¿‡ä¸€ç§æœºå™¨æ„ŸçŸ¥åˆ†ç±»æ¥è§£é‡Šæ„Ÿå®˜æ•°æ®ã€‚å®ƒæ‹æ‘„å›¾åƒã€å£°éŸ³ã€æ–‡æœ¬ã€æ—¶é—´åºåˆ—ç­‰ã€‚æ‰€æœ‰çœŸå®žä¸–ç•Œçš„æ•°æ®ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºæ•°å­—å‘é‡ä»¥è¯†åˆ«æ¨¡å¼ã€‚

åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å°†æ›´å¤šåœ°å…³æ³¨**å·ç§¯ç¥žç»ç½‘ç»œ** (ConvNets æˆ– CNN)ï¼Œå®ƒæ˜¯**æ·±åº¦ç¥žç»ç½‘ç»œ**çš„ä¸€ä¸ªç±»åˆ«ï¼Œå·²è¢«è¯æ˜Žåœ¨åˆ†æžè§†è§‰å›¾åƒå°¤å…¶æ˜¯å›¾åƒè¯†åˆ«å’Œåˆ†ç±»é¢†åŸŸéžå¸¸æœ‰æ•ˆã€‚ä¸ºäº†è¿›ä¸€æ­¥ç†è§£è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬å°†é€šè¿‡ä¸€ä¸ªå·ç§¯ç¥žç»ç½‘ç»œæ¥å¤„ç†çŽ°å®žä¸–ç•Œä¸­ç”¨æˆ·æä¾›çš„å›¾åƒã€‚

![](img/6e3a6c67ee2ace215fbeaaef7debfba1.png)

[æ¥æº](https://unsplash.com/photos/yihlaRCCvd4)

ç»™å®šä¸€å¼ ç‹—çš„å›¾åƒï¼Œè¯¥ç®—æ³•å°†è¯†åˆ«æ½œåœ¨çš„ç‹—å“ç§ã€‚å¦‚æžœæä¾›ä¸€ä¸ªäººçš„å½¢è±¡ï¼Œä»£ç å°†è¯†åˆ«ç›¸ä¼¼çš„ç‹—å“ç§ã€‚

å¬èµ·æ¥å¾ˆæœ‰è¶£ä¸æ˜¯å—ï¼Ÿè®©æˆ‘ä»¬æ½œå…¥æ›´æ·±çš„åœ°æ–¹â€¦

è¿™æ˜¯ä¸€ä¸ªéžå¸¸ç®€å•çš„ 7 æ­¥æµç¨‹**,ä¸åŒäºŽåœ¨å¹•åŽè¿è¡Œçš„å¤æ‚çš„ç¥žç»ç½‘ç»œæµç¨‹:**

**![](img/07acbc1d1bbb25a082fa4ef314a43166.png)**

**å·ç§¯ç¥žç»ç½‘ç»œ[æ¥æº](https://commons.wikimedia.org/wiki/File:Convolutional_Neural_Network.gif)**

*****ç¬¬ä¸€æ­¥:*** *å¯¼å…¥æ•°æ®é›†* ***ç¬¬äºŒæ­¥*** *:æ£€æµ‹äººç±»* ***ç¬¬ä¸‰æ­¥:*** *æ£€æµ‹ç‹—* ***ç¬¬å››æ­¥:*** *åˆ›å»º CNN å¯¹ç‹—çš„å“ç§è¿›è¡Œåˆ†ç±»* ***ç¬¬äº”æ­¥:)* ***ç¬¬å…­æ­¥:*** *å†™ä¸€ä¸ªç®—æ³•ç»‘å®šä¸Šé¢çš„æ­¥éª¤* ***ç¬¬ä¸ƒæ­¥:*** *æµ‹è¯•ç®—æ³•*****

# ****ç¬¬ä¸€æ­¥:**å¯¼å…¥æ•°æ®é›†**

**æˆ‘ä»¬ä»Žä»Ž [Udacity](https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip) å¯¼å…¥æ‰€éœ€çš„åº“å’Œæ•°æ®é›†å¼€å§‹ã€‚æ•°æ®é›†æœ‰**~ 8500 å¼ ç‹—çš„å›¾ç‰‡ï¼Œæ¨ªè·¨ 133 ä¸ªç‹—å“ç§**ã€‚å¯¼å…¥åŽï¼Œæˆ‘ä»¬å°†æ•°æ®åˆ†ä¸ºè®­ç»ƒã€éªŒè¯å’Œæµ‹è¯•æ•°æ®é›†ï¼Œåˆ†å¸ƒåˆ†åˆ«ä¸º 80%ã€10%å’Œ 10%ï¼Œå¹¶å­˜å‚¨æ¯ä¸ªæ•°æ®é›†çš„ç‰¹æ€§å’Œç›®æ ‡ã€‚**

```
from sklearn.datasets import load_files       
from keras.utils import np_utils
import numpy as np
from glob import glob# define function to load train, test, and validation datasets
def load_dataset(path):
    data = load_files(path)
    dog_files = np.array(data['filenames'])
    dog_targets = np_utils.to_categorical(np.array(data['target']), 133)
    return dog_files, dog_targets# load train, test, and validation datasets
train_files, train_targets = load_dataset('../../../data/dog_images/train')
valid_files, valid_targets = load_dataset('../../../data/dog_images/valid')
test_files, test_targets = load_dataset('../../../data/dog_images/test')# load list of dog names
dog_names = [item[20:-1] for item in sorted(glob("../../../data/dog_images/train/*/"))]
```

# **ç¬¬äºŒæ­¥:æŽ¢æµ‹äººç±»**

**åœ¨è¿™ä¸€æ­¥ï¼Œæˆ‘ä»¬å°†ç¼–å†™ä¸€ä¸ªå‡½æ•°æ¥æ£€æµ‹å›¾åƒæ˜¯å¦æœ‰äººè„¸ã€‚ä¸ºäº†èƒ½å¤Ÿè®¾è®¡è¿™ä¸ªå‡½æ•°ï¼Œæˆ‘ä»¬é¦–å…ˆä»Ž [Udacity](https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/lfw.zip) å¯¼å…¥ä¸€ä¸ªäººç±»å›¾åƒæ•°æ®é›†ã€‚**

```
import random
random.seed(8675309)# load filenames in shuffled human dataset
human_files = np.array(glob("../../../data/lfw/*/*"))
random.shuffle(human_files)# print statistics about the dataset
print('There are %d total human images.' % len(human_files))
```

**çŽ°åœ¨ï¼Œä¸ºäº†æ£€æµ‹äººè„¸ï¼Œæˆ‘ä»¬ä½¿ç”¨ OpenCV çš„ [Haar åŸºäºŽç‰¹å¾çš„çº§è”åˆ†ç±»å™¨](https://docs.opencv.org/trunk/db/d28/tutorial_cascade_classifier.html)çš„å®žçŽ°ã€‚OpenCV æä¾›äº†è®¸å¤šé¢„å…ˆè®­ç»ƒçš„äººè„¸æ£€æµ‹å™¨ï¼Œä½œä¸º XML æ–‡ä»¶å­˜å‚¨åœ¨ [Github](https://github.com/opencv/opencv/tree/master/data/haarcascades) ä¸Šï¼Œæˆ‘ä»¬ä¸‹è½½äº†å…¶ä¸­ä¸€ä¸ªæ£€æµ‹å™¨ã€‚æ­£å¦‚æˆ‘ä»¬åœ¨ä¸‹é¢çœ‹åˆ°çš„ï¼Œåœ¨æ£€æµ‹åˆ°äººè„¸ä¹‹å‰ï¼Œç®—æ³•è¿˜éœ€è¦ä¸€äº›é¢å¤–çš„å›¾åƒè½¬æ¢æ­¥éª¤ã€‚ä¸‹é¢çš„`face_detector`å‡½æ•°å°†å›¾åƒè·¯å¾„ä½œä¸ºå‚æ•°ï¼Œå¦‚æžœæ£€æµ‹åˆ°äººè„¸ï¼Œåˆ™è¿”å›ž`True`ï¼Œå¦åˆ™è¿”å›ž`False`ã€‚**

```
import cv2                
import matplotlib.pyplot as plt                        
%matplotlib inline# extract pre-trained face detector
face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_alt.xml')# returns "True" if face is detected in image stored at img_path
def face_detector(img_path):
    img = cv2.imread(img_path)
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    faces = face_cascade.detectMultiScale(gray)
    return len(faces) > 0
```

**æŽ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ä»Žä¹‹å‰ä¸‹è½½çš„äººå’Œç‹—çš„æ•°æ®ä¸­æŠ½å– 100 ä¸ªå›¾åƒæ ·æœ¬ï¼Œå¹¶é€šè¿‡å‡½æ•°è¿è¡Œå®ƒä»¬ã€‚æˆ‘ä»¬çš„æ¨¡åž‹èƒ½å¤Ÿåœ¨ **100%** çš„äººå›¾åƒå’Œ **11%** çš„ç‹—å›¾åƒä¸­æ£€æµ‹å‡ºäººè„¸ã€‚å¾ˆå¥½ï¼Œä½†è¿™è¶³å¤Ÿäº†å—ï¼Ÿ**

# **ç¬¬ä¸‰æ­¥:æŽ¢æµ‹ç‹—**

**åœ¨è¿™ä¸€æ­¥ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªé¢„å…ˆè®­ç»ƒå¥½çš„ [ResNet-50](http://ethereon.github.io/netscope/#/gist/db945b393d40bfa26006) æ¨¡åž‹æ¥æ£€æµ‹å›¾åƒä¸­çš„ç‹—ã€‚æˆ‘ä»¬é¦–å…ˆä¸‹è½½ ResNet-50 æ¨¡åž‹ä»¥åŠå·²ç»åœ¨ [ImageNet](http://www.image-net.org/) ä¸Šè®­ç»ƒè¿‡çš„æƒé‡ï¼Œè¿™æ˜¯ä¸€ä¸ªéžå¸¸å¤§çš„æµè¡Œæ•°æ®é›†ï¼Œç”¨äºŽå›¾åƒåˆ†ç±»å’Œå…¶ä»–è§†è§‰ä»»åŠ¡ã€‚**

```
from keras.applications.resnet50 import ResNet50# define ResNet50 model
ResNet50_model = ResNet50(weights='imagenet')
```

**è€ƒè™‘åˆ°çœŸå®žä¸–ç•Œçš„å›¾åƒå¯èƒ½æœ‰å¤šæ··ä¹±ï¼Œé€šå¸¸éœ€è¦åœ¨è¾“å…¥æ¨¡åž‹ä¹‹å‰è¿›è¡Œä¸€äº›é¢„å¤„ç†ã€‚ä¸‹é¢çš„`path_to_tensor`å‡½æ•°é¦–å…ˆå°†æ‰€æœ‰å›¾åƒçš„å¤§å°è°ƒæ•´ä¸º 224Ã—224 åƒç´ çš„æ­£æ–¹å½¢*(å…³é”®æ­¥éª¤ä¹‹ä¸€)*ã€‚æŽ¥ä¸‹æ¥ï¼Œå›¾åƒè¢«è½¬æ¢æˆ 4D æ•°ç»„*(åˆå 4D å¼ é‡)*ï¼Œå› ä¸º Keras CNN åœ¨è¿™é‡Œä½¿ç”¨ TensorFlow ä½œä¸ºåŽç«¯ã€‚*å¼ é‡æ˜¯çŸ©é˜µåˆ° N ç»´ç©ºé—´çš„æŽ¨å¹¿*ã€‚*æ›´å¤šè¯¦æƒ…è¯·çœ‹è¿™ç¯‡ä¼Ÿå¤§çš„* [*å¸–å­*](https://www.kdnuggets.com/2018/05/wtf-tensor.html) *by* [*é©¬ä¿®æ¢…å¥¥*](https://medium.com/u/a0bc63d95eb0?source=post_page-----a277f4ad91be--------------------------------) *ã€‚***

**è¾“å…¥å½¢çŠ¶: **(nb_samplesï¼Œrowsï¼Œcolumnsï¼Œchannels)** å…¶ä¸­ï¼Œ
`nb_samples`ä¸ºå›¾åƒ(æˆ–æ ·æœ¬)æ€»æ•°ï¼Œ
`rows`ï¼Œ`columns`ï¼Œ`channels`åˆ†åˆ«å¯¹åº”æ¯å¹…å›¾åƒçš„é«˜åº¦ï¼Œé•¿åº¦ï¼Œæ·±åº¦ã€‚æˆ‘ä»¬çš„ 4D å¼ é‡æ˜¯(1ï¼Œ224ï¼Œ224ï¼Œ3)ã€‚**

```
from keras.preprocessing import image                  
from tqdm import tqdmdef path_to_tensor(img_path):
    # loads RGB image as PIL.Image.Image type
    img = image.load_img(img_path, target_size=(224, 224))
    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)
    x = image.img_to_array(img)
    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor
    return np.expand_dims(x, axis=0)def paths_to_tensor(img_paths):
    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]
    return np.vstack(list_of_tensors)
```

**åœ¨æ¨¡åž‹å¯ç”¨äºŽé¢„æµ‹ä¹‹å‰ï¼Œéœ€è¦ä¸€äº›é¢å¤–çš„é¢„å¤„ç†æ­¥éª¤ï¼Œå¦‚å°† RGB å›¾åƒè½¬æ¢ä¸º BGRï¼Œé€šè¿‡ä»Žæ¯ä¸ªå›¾åƒçš„æ¯ä¸ªåƒç´ ä¸­å‡åŽ»å¹³å‡åƒç´ æ¥å½’ä¸€åŒ–æ¨¡åž‹ç­‰ã€‚è¿™éƒ½ç”±`preprocess_input`åŠŸèƒ½è´Ÿè´£ã€‚è¦äº†è§£æ›´å¤šä¿¡æ¯ï¼Œè¯·ç‚¹å‡»æŸ¥çœ‹ä»£ç [ã€‚](https://github.com/fchollet/keras/blob/master/keras/applications/imagenet_utils.py)**

**çŽ°åœ¨æˆ‘ä»¬çš„å›¾åƒå·²ç»æ ¼å¼åŒ–äº†ï¼Œæˆ‘ä»¬å‡†å¤‡æŠŠå®ƒæä¾›ç»™ ResNet-50 å¹¶è¿›è¡Œé¢„æµ‹ã€‚ä¸‹é¢çš„`predict`å‡½æ•°è¿”å›žå›¾åƒå±žäºŽç‰¹å®š ImageNet ç±»åˆ«çš„é¢„æµ‹æ¦‚çŽ‡ã€‚ä¸ºäº†å°†è¿”å›žçš„æ•´æ•°æ˜ å°„åˆ°æ¨¡åž‹çš„é¢„æµ‹å¯¹è±¡ç±»ï¼Œè¯·ä½¿ç”¨è¿™ä¸ª[å­—å…¸](https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a)ã€‚**

```
from keras.applications.resnet50 import preprocess_input, decode_predictionsdef ResNet50_predict_labels(img_path):
    # returns prediction vector for image located at img_path
    img = preprocess_input(path_to_tensor(img_path))
    return np.argmax(ResNet50_model.predict(img))
```

**å­—å…¸ä¸­æ‰€æœ‰çš„ç‹—ç±»åˆ«éƒ½å¯¹åº”äºŽ 151-268 é”®ã€‚å› æ­¤ï¼Œè¦æ£€æµ‹ä¸€å¼ ç‹—è„¸ï¼Œæˆ‘ä»¬éœ€è¦æ£€æŸ¥ä¸‹é¢çš„`ResNet50_predict_labels`å‡½æ•°æ˜¯å¦è¿”å›žä¸€ä¸ªä»‹äºŽ 151 å’Œ 268(å«)ä¹‹é—´çš„å€¼ã€‚å¦‚æžœæ£€æµ‹åˆ°ç‹—è„¸ï¼Œè¯¥å‡½æ•°è¿”å›ž`True`ï¼Œå¦åˆ™è¿”å›ž`False`ã€‚**

**ç±»ä¼¼äºŽæ­¥éª¤ 2ï¼Œæˆ‘ä»¬é€šè¿‡è¿™ä¸ªå‡½æ•°è¿è¡Œ 100 ä¸ªå›¾åƒçš„æ ·æœ¬ã€‚æˆ‘ä»¬çš„æ¨¡åž‹èƒ½å¤Ÿåœ¨ç‹—å›¾åƒçš„ **100%** å’Œäººå›¾åƒçš„ **0%** ä¸­æ£€æµ‹åˆ°ç‹—è„¸ã€‚**

# **ç¬¬å››æ­¥:åˆ›å»ºä¸€ä¸ª CNN æ¥åˆ†ç±»ç‹—çš„å“ç§**

**æ—¢ç„¶æˆ‘ä»¬èƒ½å¤Ÿåœ¨å›¾åƒä¸­æ£€æµ‹å‡ºäººå’Œç‹—çš„è„¸ï¼Œæˆ‘ä»¬çš„ä¸‹ä¸€ä¸ªç›®æ ‡æ˜¯å¯¹ç‹—çš„å“ç§è¿›è¡Œåˆ†ç±»ã€‚æˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ª CNN æ¨¡åž‹æ¥å¸®åŠ©è¿™äº›åˆ†ç±»é¢„æµ‹ã€‚åœ¨æˆ‘ä»¬å¼€å§‹å»ºç«‹æ¨¡åž‹ä¹‹å‰ï¼Œæˆ‘ä»¬é€šè¿‡å°†æ¯ä¸ªå›¾åƒä¸­çš„æ¯ä¸ªåƒç´ é™¤ä»¥ 255 æ¥é‡æ–°ç¼©æ”¾å›¾åƒã€‚**

```
# pre-process the data for Keras
train_tensors = paths_to_tensor(train_files).astype('float32')/255
valid_tensors = paths_to_tensor(valid_files).astype('float32')/255
test_tensors = paths_to_tensor(test_files).astype('float32')/255
```

**ä¸‹é¢æ˜¯æ¥è‡ªæˆ‘ä»¬åˆ†ç±»æ¨¡åž‹çš„ **CNN æž¶æž„**ã€‚CNN çš„è®¾è®¡ç›®æ ‡é€šå¸¸æ˜¯ä½¿è¾“å…¥é˜µåˆ—æ¯”å…¶é•¿åº¦æˆ–å®½åº¦æ›´æ·±ã€‚åœ¨ä¸‹é¢ä½¿ç”¨çš„ 3 ä¸ª**å·ç§¯å±‚**ä¸­ï¼Œæˆ‘å¢žåŠ äº†è¿‡æ»¤å™¨çš„æ•°é‡ï¼Œä»¥å¢žåŠ ç‰¹å¾çš„å †å ï¼Œä»Žè€Œå¢žåŠ å…¶æ·±åº¦ã€‚æ¯ä¸ªå·ç§¯å±‚ä¹‹åŽæ˜¯ä¸€ä¸ª**æœ€å¤§æ± å±‚**ï¼Œä»¥å‡å°‘å›¾åƒçš„ç©ºé—´ç»´åº¦ã€‚ç„¶åŽï¼Œæˆ‘ä»¬å°†çŸ©é˜µå±•å¹³æˆä¸€ä¸ªå‘é‡ï¼Œç„¶åŽå°†å®ƒé€å…¥ä¸€ä¸ªå®Œå…¨è¿žæŽ¥çš„**å¯†é›†å±‚**ï¼Œå› ä¸ºè¿™äº›ä¸æŽ¥å—å¤šç»´æ•°ç»„ã€‚è¯¥å±‚ä½¿ç”¨ softmax æ¿€æ´»å‡½æ•°æ¥èŽ·å¾—æ¯ä¸ªç±»åˆ«çš„åˆ†ç±»æ¦‚çŽ‡ï¼Œä»¥åŠ 133 ä¸ªè¾“å‡ºèŠ‚ç‚¹ï¼Œåœ¨æˆ‘ä»¬çš„è®­ç»ƒæ•°æ®ä¸­ï¼Œæ¯ä¸ªç‹—ç±»åˆ« 1 ä¸ªã€‚*è¦è¯¦ç»†äº†è§£æ¯ä¸ªå‚æ•°ï¼Œä»¥åŠè¿™äº›å‚æ•°æ˜¯å¦‚ä½•è®¡ç®—çš„ï¼Œè¯·å‚è§æœ¬* [*å¸–å­*](https://towardsdatascience.com/understanding-and-calculating-the-number-of-parameters-in-convolution-neural-networks-cnns-fc88790d530d)*by*[*Rakshith Vasudev*](https://medium.com/u/4ed456ddae20?source=post_page-----a277f4ad91be--------------------------------)*ã€‚***

```
from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D
from keras.layers import Dropout, Flatten, Dense
from keras.models import Sequential# Define your architecture.model = Sequential()
# Convolutional layers and maxpooling layers, note: all images are 224*224 pixel
model.add(Conv2D(filters=16, kernel_size=2, strides=1, padding='same',activation='relu', input_shape=[224,224,3]))
model.add(MaxPooling2D(pool_size=2, strides=1, padding='same'))model.add(Conv2D(filters=32, kernel_size=2, strides=2, padding='same',activation='relu'))
model.add(MaxPooling2D(pool_size=2, strides=1, padding='same'))model.add(Conv2D(filters=64, kernel_size=2, strides=2, padding='same',activation='relu'))
model.add(MaxPooling2D(pool_size=2, strides=1, padding='same'))
#model.add(GlobalAveragePooling2D())# Flatten the array into a vector and feed to a dense layer
model.add(Flatten())
model.add(Dense(133, activation='softmax'))model.summary()
```

**æŽ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬**ç¼–è¯‘**ï¼Œè€Œ**è®­ç»ƒ**æˆ‘ä»¬çš„æ¨¡åž‹ã€‚ModelCheckpoint ç”¨äºŽä¿å­˜èŽ·å¾—æœ€ä½³éªŒè¯æŸå¤±çš„æ¨¡åž‹ã€‚**

```
from keras.callbacks import ModelCheckpointmodel.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.from_scratch.hdf5', 
                               verbose=1, save_best_only=True)model.fit(train_tensors, train_targets, 
          validation_data=(valid_tensors, valid_targets),
          epochs=epochs, batch_size=20, callbacks=[checkpointer], verbose=1)
```

**ä¸€æ—¦æˆ‘ä»¬çš„æ¨¡åž‹è¢«è®­ç»ƒï¼Œæˆ‘ä»¬åŠ è½½ä¹‹å‰ä¿å­˜çš„æƒé‡ï¼Œå¹¶ä½¿ç”¨å®ƒåœ¨æˆ‘ä»¬çš„**æµ‹è¯•**æ•°æ®ä¸Šè¿è¡Œæ¨¡åž‹ï¼Œä»¥è¯„ä¼°æˆ‘ä»¬çš„æ¨¡åž‹çš„å‡†ç¡®æ€§ã€‚**

```
model.load_weights('saved_models/weights.best.from_scratch.hdf5')# get index of predicted dog breed for each image in test set
dog_breed_predictions = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]# report test accuracy
test_accuracy = 100*np.sum(np.array(dog_breed_predictions)==np.argmax(test_targets, axis=1))/len(dog_breed_predictions)
print('Test accuracy: %.4f%%' % test_accuracy)
```

**è¿™ä¸ªæ¨¡åž‹å·¥ä½œæ­£å¸¸ï¼Œå¹¶ä¸”ä¼šç»™å‡º **~7%** çš„ç²¾åº¦ã€‚ä½ ä¸€å®šåœ¨æƒ³ï¼Œè¿™ä¹ˆå¤šæ‰èƒ½å¾—åˆ°è¿™ä¹ˆä½Žçš„ç²¾åº¦ï¼Ÿè¯·è®°ä½ï¼Œè¿™æ˜¯æ²¡æœ‰ä»»ä½•å‚æ•°å¾®è°ƒå’Œæ•°æ®å¢žå¼ºã€‚è¿™æ˜¯æŽ¥ä¸‹æ¥çš„æ­¥éª¤å°†æœ‰åŠ©äºŽæé«˜å‡†ç¡®æ€§çš„åœ°æ–¹ã€‚**

# **ç¬¬äº”æ­¥:ä½¿ç”¨é¢„å…ˆæž„å»ºçš„ Keras CNN æ¨¡åž‹ï¼Œå¹¶ä¿®æ”¹è¿™äº›æ¨¡åž‹æ¥å¯¹ç‹—çš„å“ç§è¿›è¡Œåˆ†ç±»(ä½¿ç”¨è¿ç§»å­¦ä¹ )**

**Keras ä¸­æœ‰ä¸€äº›çªç ´æ€§çš„é¢„å»º CNN æž¶æž„ï¼Œå¯ä»¥é€šè¿‡è¿ç§»å­¦ä¹ æ¥ä½¿ç”¨ã€‚VGG16ã€VGG19ã€ResNet50ã€Xceptionã€InceptionV3ã€‚è¿™äº›æ¨¡åž‹æœ‰åŠ©äºŽåœ¨ä¸ç‰ºç‰²å‡†ç¡®æ€§çš„æƒ…å†µä¸‹å‡å°‘è®­ç»ƒæ—¶é—´ã€‚è¿™é‡Œä½¿ç”¨äº†é¢„å…ˆè®­ç»ƒçš„ VGG-16 æ¨¡åž‹ï¼Œå¹¶å°†å…¶è¾“å…¥åˆ°æˆ‘ä»¬çš„æ¨¡åž‹ä¸­ã€‚æˆ‘ä»¬åªæ·»åŠ äº†ä¸€ä¸ªå…¨å±€å¹³å‡æ± å±‚*(å‡å°‘ç»´åº¦)*å’Œä¸€ä¸ªå…·æœ‰ softmax æ¿€æ´»å‡½æ•°çš„å…¨è¿žæŽ¥å±‚*(ä¸ºæ¯ä¸ªç‹—ç±»åˆ«èŽ·å¾—ä¸€ä¸ªèŠ‚ç‚¹)*ã€‚**

```
bottleneck_features = np.load('bottleneck_features/DogVGG16Data.npz')
train_VGG16 = bottleneck_features['train']
valid_VGG16 = bottleneck_features['valid']
test_VGG16 = bottleneck_features['test']# CNN architecture using Transfer Learning
VGG16_model = Sequential()
VGG16_model.add(GlobalAveragePooling2D(input_shape=train_VGG16.shape[1:]))
VGG16_model.add(Dense(133, activation='softmax'))VGG16_model.summary()
```

**å½“æˆ‘ä»¬é€šè¿‡è¿™ä¸ªæ–°è®­ç»ƒçš„æ¨¡åž‹å’Œé¢„å…ˆè®¡ç®—çš„ç‰¹å¾è¿è¡Œæˆ‘ä»¬çš„æµ‹è¯•æ•°æ®æ—¶ï¼Œæˆ‘ä»¬çš„å‡†ç¡®æ€§åœ¨æ›´çŸ­çš„æ—¶é—´å†…å¢žåŠ åˆ°äº† **~45%** ï¼Œè¿™æ˜¯ä¸€ä¸ªæ˜¾è‘—çš„æ”¹è¿›ã€‚è¿™æ˜¯å› ä¸ºçŽ°åœ¨ç½‘ç»œä¸­åªæœ‰ 2 å±‚æ­£åœ¨å¤„ç†ã€‚ä½¿ç”¨ ResNet50 æ¨¡åž‹ï¼Œå‡†ç¡®çŽ‡è¿›ä¸€æ­¥è·ƒå‡è‡³ **~82%** ï¼Œè¿™æ˜¯æˆ‘æœ€ç»ˆåœ¨ä»£ç ä¸­ä½¿ç”¨çš„ã€‚**

# **ç¬¬å…­æ­¥:å†™ä¸€ä¸ªç®—æ³•æ¥ç»‘å®šä¸Šé¢çš„æ­¥éª¤**

**è¿™æ˜¯æˆ‘ä»¬æŠŠæ‰€æœ‰ä¸åŒçš„éƒ¨åˆ†æ”¾åœ¨ä¸€èµ·çš„æ­¥éª¤ã€‚æˆ‘ä»¬ç¼–å†™äº†ä¸€ä¸ªç®€å•çš„ç®—æ³•ï¼Œå®ƒæŽ¥å—ä¸€ä¸ªå›¾åƒè·¯å¾„ï¼Œå¹¶é¦–å…ˆç¡®å®šå®ƒæ˜¯å¦åŒ…å«äººè„¸ã€ç‹—è„¸ï¼Œæˆ–è€…ä¸¤è€…éƒ½ä¸åŒ…å«ã€‚ç„¶åŽï¼Œ**

*   **å¦‚æžœåœ¨å›¾åƒä¸­æ£€æµ‹åˆ°ä¸€åª**ç‹—**ï¼Œè¿”å›žé¢„æµ‹çš„å“ç§ã€‚**
*   **å¦‚æžœåœ¨å›¾åƒä¸­æ£€æµ‹åˆ°ä¸€ä¸ª**äºº**ï¼Œè¿”å›žç›¸ä¼¼çš„ç‹—å“ç§ã€‚**
*   **å¦‚æžœåœ¨å›¾åƒä¸­æ²¡æœ‰æ£€æµ‹åˆ°**æˆ–**ï¼Œåˆ™æä¾›æŒ‡ç¤ºé”™è¯¯çš„è¾“å‡ºã€‚**

```
def display_detect_image(img_path):
    detect_breed(img_path)
    # load color (BGR) image
    img = cv2.imread(img_path)
    # convert BGR image to RGB for plotting
    cv_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    # display the image
    plt.imshow(cv_rgb)
    return plt.show()def detect_breed(img_path):
    # check if image is human face
    if face_detector(img_path) == True:
        return print("Hello human! Your face resembles a: ",Resnet50_predict_breed(img_path).str.split(".")[-1])
    # check if image is dog face
    elif dog_detector(img_path) == True:
        return print("Hello dog! Your predicted breed is: ",Resnet50_predict_breed(img_path).str.split(".")[-1])
    # else print an error message
    else:
        return print("Oops! This is neither a human nor a dog")
```

# **æ­¥éª¤ 7:æµ‹è¯•æˆ‘ä»¬çš„ç®—æ³•**

**åœ¨è¿™ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬å°†çœ‹åˆ°æˆ‘ä»¬ç®—æ³•çš„å¼ºå¤§ä¹‹å¤„ï¼Œå¹¶å°è¯•ä¸€ä¸‹ï¼æˆ‘éšæœºæä¾›äº†ä¸€äº›ç‹—å’Œäººçš„å›¾åƒï¼Œçž§ï¼ç®—æ³•é¢„æµ‹å“ç§ã€‚çŽ°åœ¨ï¼Œå¦‚æžœä½ å–œæ¬¢è¡—ä¸Šæˆ–å…¬å›­é‡Œçš„ä¸€åªç‹—ï¼Œä½ æƒ³çŸ¥é“å®ƒçš„å“ç§ï¼Œä¸éœ€è¦é—®ä¸»äººï¼Œåªéœ€ç‚¹å‡»ä¸€å¼ å›¾ç‰‡ï¼Œå¹¶é€šè¿‡æ¨¡åž‹è¿è¡Œå®ƒðŸ˜„**

***è¦è®¿é—®å®Œæ•´çš„ä»£ç ï¼Œè¯·ç‚¹å‡»* *æŸ¥çœ‹æˆ‘çš„ GitHub çš„é“¾æŽ¥ã€‚***

**![](img/d1f36ee2c34e4d8def33e91070c650e9.png)****![](img/350754a206c14e66e7f449ffb7fe528c.png)****![](img/58b1bec9a259e5be388b3a6abca1d524.png)****![](img/db17803e4d71baed59bf7d3d8a939fd8.png)****![](img/46faeafc5eb40cbc2da5e4cf29c7e1b1.png)****![](img/71c2ee7ca01a48b8dac5bd096b6db5df.png)**

> ****å‚è€ƒæ–‡çŒ®:****
> 
> **[https://pathmind.com/wiki/neural-network](https://pathmind.com/wiki/neural-network)**
> 
> **[https://analyticsindiamag . com/tensor flow-vs-keras-ä½ åº”è¯¥é€‰æ‹©å“ªä¸€ä¸ª/](https://analyticsindiamag.com/tensorflow-vs-keras-which-one-should-you-choose/)**