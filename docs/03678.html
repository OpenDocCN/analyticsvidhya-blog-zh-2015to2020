<html>
<head>
<title>4 Boosting Algorithms You Should Know — GBM, XGBM, XGBoost &amp; CatBoost</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">你应该知道的4种升压算法——GBM、XGBM、XGBoost和CatBoost</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/4-boosting-algorithms-you-should-know-gbm-xgbm-xgboost-catboost-b13b07de7029?source=collection_archive---------12-----------------------#2020-02-13">https://medium.com/analytics-vidhya/4-boosting-algorithms-you-should-know-gbm-xgbm-xgboost-catboost-b13b07de7029?source=collection_archive---------12-----------------------#2020-02-13</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="ff6e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">提升算法已经存在多年了，但直到最近它们才成为机器学习社区的主流。但是为什么这些助推算法变得如此流行呢？</p><p id="cc7a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">boosting算法采用率上升的主要原因之一是机器学习竞赛。助推算法赋予机器学习模型超能力，以提高它们的预测精度。快速浏览一下Kaggle竞赛和<a class="ae jd" href="https://datahack.analyticsvidhya.com/?utm_source=blog&amp;utm_medium=4-boosting-algorithms-machine-learning" rel="noopener ugc nofollow" target="_blank"> DataHack黑客马拉松</a>就足以证明——助推算法非常流行！</p><p id="bc92" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">简而言之，助推算法往往胜过更简单的模型，如<a class="ae jd" href="https://www.analyticsvidhya.com/blog/2015/11/beginners-guide-on-logistic-regression-in-r/?utm_source=blog&amp;utm_medium=4-boosting-algorithms-machine-learning" rel="noopener ugc nofollow" target="_blank">逻辑回归</a>和<a class="ae jd" href="https://courses.analyticsvidhya.com/courses/getting-started-with-decision-trees?utm_source=blog&amp;utm_medium=4-boosting-algorithms-machine-learning" rel="noopener ugc nofollow" target="_blank">决策树</a>。事实上，在我们的DataHack平台上，大多数顶尖的完成者要么使用一种增强算法，要么使用多种增强算法的组合。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/8fd5024200ca68f8d669e6fbfd9f0898.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*bB-xfHWXsN4lE-x9.png"/></div></div></figure><p id="affd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这篇文章中，我将向你介绍四种流行的助推算法，你可以在你的下一个<a class="ae jd" href="https://courses.analyticsvidhya.com/courses/applied-machine-learning-beginner-to-professional?utm_source=blog&amp;utm_medium=4-boosting-algorithms-machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a>黑客马拉松或项目中使用它们。</p><h1 id="1fe0" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">机器学习中的4种助推算法</h1><ol class=""><li id="f2dc" class="ko kp hi ih b ii kq im kr iq ks iu kt iy ku jc kv kw kx ky bi translated">梯度推进机</li><li id="c0b8" class="ko kp hi ih b ii kz im la iq lb iu lc iy ld jc kv kw kx ky bi translated">极限梯度推进机</li><li id="94fe" class="ko kp hi ih b ii kz im la iq lb iu lc iy ld jc kv kw kx ky bi translated">LightGBM</li><li id="9d06" class="ko kp hi ih b ii kz im la iq lb iu lc iy ld jc kv kw kx ky bi translated">CatBoost</li></ol><h1 id="5105" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">Boosting快速入门(什么是Boosting？)</h1><p id="eafe" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq le is it iu lf iw ix iy lg ja jb jc hb bi translated">想象一下这个场景:</p><p id="2edf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">您已经构建了一个<a class="ae jd" href="https://www.analyticsvidhya.com/blog/2017/06/a-comprehensive-guide-for-linear-ridge-and-lasso-regression/?utm_source=blog&amp;utm_medium=4-boosting-algorithms-machine-learning" rel="noopener ugc nofollow" target="_blank">线性回归</a>模型，该模型在验证数据集上为您提供了77%的正确率。接下来，您决定通过在同一数据集上构建<a class="ae jd" href="https://www.analyticsvidhya.com/blog/2018/03/introduction-k-neighbours-algorithm-clustering/?utm_source=blog&amp;utm_medium=4-boosting-algorithms-machine-learning" rel="noopener ugc nofollow" target="_blank"> k近邻(KNN) </a>模型和<a class="ae jd" href="https://courses.analyticsvidhya.com/courses/getting-started-with-decision-trees?utm_source=blog&amp;utm_medium=4-boosting-algorithms-machine-learning" rel="noopener ugc nofollow" target="_blank">决策树</a>模型来扩展您的投资组合。这些模型在验证集上分别给出了62%和89%的准确率。</p><p id="d1e3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">很明显，这三种模式的工作方式完全不同。例如，线性回归模型试图捕捉数据中的线性关系，而决策树模型试图捕捉数据中的非线性关系。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es lh"><img src="../Images/6b494513c0be1031b0d6ce1ee90737e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:976/format:webp/0*kUcth89uhzFO79ua.png"/></div></figure><blockquote class="li lj lk"><p id="43fd" class="if ig ll ih b ii ij ik il im in io ip lm ir is it ln iv iw ix lo iz ja jb jc hb bi translated">我们不使用这些模型中的任何一个进行最终预测，而是使用所有这些模型的组合，这样如何？</p></blockquote><p id="da47" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我在考虑这些模型预测的平均值。通过这样做，我们将能够从数据中获取更多的信息，对吗？</p><p id="59c7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这主要是集成学习背后的想法。助推从何而来？</p><p id="c586" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Boosting是使用集成学习概念的技术之一。boosting算法结合多个简单模型(也称为弱学习器或基本估计器)来生成最终输出。</p><p id="af6b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本文中，我们将研究一些重要的提升算法。</p><h1 id="d9c0" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">1.梯度推进机</h1><p id="e926" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq le is it iu lf iw ix iy lg ja jb jc hb bi translated">梯度推进机器或GBM组合来自多个决策树的预测来生成最终预测。请记住，梯度推进机器中的所有弱学习器都是决策树。</p><p id="3085" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">但是如果我们使用相同的算法，那么使用一百棵决策树怎么会比使用一棵决策树好呢？不同的决策树如何从数据中捕捉不同的信号/信息？</p><p id="5e6c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里有一个诀窍— <strong class="ih hj">每个决策树中的节点都采用不同的特征子集来选择最佳分割。这意味着每棵树都不相同，因此它们能够从数据中捕捉不同的信号。</strong></p><p id="e823" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">此外，每个新的树都考虑了以前的树所犯的错误。所以，每一棵后继的决策树都是建立在先前的错误之上的。这就是梯度推进机器算法中的树是如何顺序构建的。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es lp"><img src="../Images/3e1acd4d539efcf5612318bb119919ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1334/format:webp/0*ZoGm71xAgjpgKDzZ.png"/></div></figure><p id="746a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里有一篇文章解释了GBM算法的超参数调整过程:</p><ul class=""><li id="5dbf" class="ko kp hi ih b ii ij im in iq lq iu lr iy ls jc lt kw kx ky bi translated"><a class="ae jd" href="https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/?utm_source=blog&amp;utm_medium=4-boosting-algorithms-machine-learning" rel="noopener ugc nofollow" target="_blank">Python中的梯度推进机(GBM)参数调整指南</a></li></ul><h1 id="71af" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">2.极限梯度推进机</h1><p id="a22b" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq le is it iu lf iw ix iy lg ja jb jc hb bi translated">极端梯度增强或XGBoost是另一种流行的增强算法。事实上，XGBoost只是GBM算法的一个临时版本！XGBoost的工作程序与GBM相同。XGBoost中的树是按顺序构建的，试图纠正前面树的错误。</p><p id="a969" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里有一篇文章直观地解释了XGBoost背后的数学原理，并且用Python实现了XGBoost:</p><ul class=""><li id="360b" class="ko kp hi ih b ii ij im in iq lq iu lr iy ls jc lt kw kx ky bi translated"><a class="ae jd" href="https://www.analyticsvidhya.com/blog/2018/09/an-end-to-end-guide-to-understand-the-math-behind-xgboost/?utm_source=blog&amp;utm_medium=4-boosting-algorithms-machine-learning" rel="noopener ugc nofollow" target="_blank">理解XGBoost背后的数学原理的端到端指南</a></li></ul><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es lu"><img src="../Images/652e3a848f5bc65c5c396a518a10c317.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/0*_sc2ej0BwyHV3QTn.jpg"/></div></figure><p id="59e9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">但是有一些特性使XGBoost比GBM略胜一筹:</p><ul class=""><li id="de09" class="ko kp hi ih b ii ij im in iq lq iu lr iy ls jc lt kw kx ky bi translated">最重要的一点是，XGBM实现了并行预处理(在节点级别),这使得它比GBM更快</li><li id="17d2" class="ko kp hi ih b ii kz im la iq lb iu lc iy ld jc lt kw kx ky bi translated">XGBoost还包括各种正则化技术，可以减少过度拟合并提高整体性能。您可以通过设置XGBoost算法的超参数来选择正则化技术</li></ul><p id="cfa8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在此了解XGBoost的不同超参数以及它们在模型训练过程中的作用:</p><ul class=""><li id="af25" class="ko kp hi ih b ii ij im in iq lq iu lr iy ls jc lt kw kx ky bi translated"><a class="ae jd" href="https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/?utm_source=blog&amp;utm_medium=4-boosting-algorithms-machine-learning" rel="noopener ugc nofollow" target="_blank">Python中XGBoost的超参数调优指南</a></li></ul><p id="c008" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">此外，如果使用XGBM算法，就不必担心在数据集中输入缺失值。<strong class="ih hj">XGBM模型可以自己处理缺失值</strong>。在训练过程中，模型学习缺失值应该在右节点还是左节点。</p><h1 id="d289" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">3.LightGBM</h1><p id="c30c" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq le is it iu lf iw ix iy lg ja jb jc hb bi translated">由于其速度和效率，LightGBM boosting算法正变得日益流行。LightGBM能够轻松处理大量数据。但请记住，这种算法在数据点数量较少的情况下表现不佳。</p><p id="9749" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们花点时间来理解为什么会这样。</p><p id="b00b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">LightGBM中的树是逐叶生长，而不是逐层生长。第一次分割后，下一次分割仅在具有较高增量损失的叶节点上进行。</p><p id="f349" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">考虑我在下图中举例说明的例子:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lv"><img src="../Images/17c681e7507fd566ab1bf63e2afac23f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*WWMFnKNaC4ONqBs9.png"/></div></div></figure><p id="060a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在第一次分割后，左边的节点具有更高的丢失，并被选择用于下一次分割。现在，我们有三个叶节点，中间的叶节点损失最大。LightGBM算法的逐叶分割使其能够处理大型数据集。</p><p id="1eab" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了加速训练过程，<strong class="ih hj"> LightGBM使用基于直方图的方法来选择最佳分割</strong>。对于任何连续变量，不使用单个值，而是将这些值划分到箱或桶中。这使得训练过程更快，并降低内存使用。</p><p id="47cd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里有一篇比较LightGBM和XGBoost算法的优秀文章:</p><ul class=""><li id="8eec" class="ko kp hi ih b ii ij im in iq lq iu lr iy ls jc lt kw kx ky bi translated"><a class="ae jd" href="https://www.analyticsvidhya.com/blog/2017/06/which-algorithm-takes-the-crown-light-gbm-vs-xgboost/?utm_source=blog&amp;utm_medium=4-boosting-algorithms-machine-learning" rel="noopener ugc nofollow" target="_blank"> LightGBM vs XGBOOST:哪种算法摘得桂冠？</a></li></ul><h1 id="7214" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">4.CatBoost</h1><p id="cfec" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq le is it iu lf iw ix iy lg ja jb jc hb bi translated">顾名思义，CatBoost是一种boosting算法，可以处理数据中的分类变量。大多数<a class="ae jd" href="https://www.analyticsvidhya.com/blog/2017/09/common-machine-learning-algorithms/?utm_source=blog&amp;utm_medium=4-boosting-algorithms-machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习算法</a>无法处理数据中的字符串或类别。因此，将分类变量转换成数值是一个必要的预处理步骤。</p><p id="3f13" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">CatBoost可以在内部处理数据中的分类变量。使用各种特征组合的统计将这些变量转换成数字变量。</p><p id="2c1f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你想了解这些类别如何转换成数字背后的数学原理，你可以浏览这篇文章:</p><ul class=""><li id="566e" class="ko kp hi ih b ii ij im in iq lq iu lr iy ls jc lt kw kx ky bi translated"><a class="ae jd" href="https://catboost.ai/docs/concepts/algorithm-main-stages_cat-to-numberic.html#algorithm-main-stages_cat-to-numberic" rel="noopener ugc nofollow" target="_blank">将分类特征转换为数字特征</a></li></ul><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lw"><img src="../Images/ed2f2aac432f12780b6625d284f91322.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*O6IJ2QG6X45MDETY.png"/></div></div></figure><p id="0776" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">CatBoost被广泛使用的另一个原因是，它与默认的超参数集配合得很好。因此，作为用户，我们不必花费大量时间来调优超参数。</p><p id="0aaf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面是一篇在机器学习挑战上实现CatBoost的文章:</p><ul class=""><li id="088a" class="ko kp hi ih b ii ij im in iq lq iu lr iy ls jc lt kw kx ky bi translated"><a class="ae jd" href="https://www.analyticsvidhya.com/blog/2017/08/catboost-automated-categorical-data/?utm_source=blog&amp;utm_medium=4-boosting-algorithms-machine-learning" rel="noopener ugc nofollow" target="_blank"> CatBoost:自动处理分类数据的机器学习库</a></li></ul><h1 id="12f6" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">结束注释</h1><p id="c191" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq le is it iu lf iw ix iy lg ja jb jc hb bi translated">在本文中，我们介绍了集成学习的基础知识，并研究了4种boosting算法。有兴趣了解其他集成学习方法吗？你应该看看下面这篇文章:</p><ul class=""><li id="64d3" class="ko kp hi ih b ii ij im in iq lq iu lr iy ls jc lt kw kx ky bi translated"><a class="ae jd" href="https://www.analyticsvidhya.com/blog/2018/06/comprehensive-guide-for-ensemble-models/?utm_source=blog&amp;utm_medium=4-boosting-algorithms-machine-learning" rel="noopener ugc nofollow" target="_blank">集成学习综合指南(带Python代码)</a></li></ul><p id="3704" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">你还用过其他什么助推算法？你用这些助推算法成功了吗？在下面的评论区和我分享你的想法和经验。</p></div><div class="ab cl lx ly gp lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="hb hc hd he hf"><p id="31a7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="ll">原载于2020年2月13日</em><a class="ae jd" href="https://www.analyticsvidhya.com/blog/2020/02/4-boosting-algorithms-machine-learning/" rel="noopener ugc nofollow" target="_blank"><em class="ll">【https://www.analyticsvidhya.com】</em></a><em class="ll">。</em></p></div></div>    
</body>
</html>