<html>
<head>
<title>Building a Random Forest from Scratch &amp; Understanding Real-World Data Products (ML for Programmers — Part 3)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从零开始构建随机森林&amp;理解真实世界的数据产品(面向程序员的ML——第3部分)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/building-a-random-forest-from-scratch-understanding-real-world-data-products-ml-for-programmers-7b87474b1fb5?source=collection_archive---------0-----------------------#2018-12-03">https://medium.com/analytics-vidhya/building-a-random-forest-from-scratch-understanding-real-world-data-products-ml-for-programmers-7b87474b1fb5?source=collection_archive---------0-----------------------#2018-12-03</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="f553" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">作为数据科学家和机器学习实践者，我们遇到并学习了大量的算法。你有没有想过每个算法的真正用处在哪里？大多数机器学习技术的主要目的是为了登上黑客马拉松的排行榜吗？</p><p id="ff33" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">不一定。检查和理解机器学习在现实世界的行业场景中的位置和使用方式非常重要。那是我们大多数人正在工作的地方(或者最终将会工作的地方)。这就是我打算在我们的热门系列的第3部分中展示的内容，涵盖了fast.ai机器学习入门课程！</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jd"><img src="../Images/ce0d4db694dd10cf20681a121daeb8fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/0*805MGsmeFi8IEXO5.jpg"/></div></figure><p id="f7a2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在第1部分中，我们使用fastai库对随机森林做了相当全面的介绍，随后我们又有趣地看了一下<a class="ae jl" href="https://www.analyticsvidhya.com/blog/2018/10/interpret-random-forest-model-machine-learning-programmers/" rel="noopener ugc nofollow" target="_blank">如何解释随机森林模型</a>。后一部分在当今世界尤为重要。</p><p id="da4a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本文中，我们将首先后退一步，从商业角度分析机器学习。然后，我们将直接跳到我们离开第2部分的地方——从头开始构建一个随机森林模型。我鼓励你回到以前的帖子，以防你需要更新任何概念，并在我们前进的时候带着这些知识。</p><h1 id="6fef" class="jm jn hi bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated">目录</h1><ul class=""><li id="6741" class="kk kl hi ih b ii km im kn iq ko iu kp iy kq jc kr ks kt ku bi translated">机器学习导论:第六课<br/> 1。机器学习在商业中的应用<br/> 2。随机森林解释技术</li><li id="b558" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc kr ks kt ku bi translated">机器学习入门:第7课<br/> 1。用Python从头开始构建随机森林</li></ul><h1 id="7fb5" class="jm jn hi bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated">机器学习导论:第6课</h1><p id="926b" class="pw-post-body-paragraph if ig hi ih b ii km ik il im kn io ip iq la is it iu lb iw ix iy lc ja jb jc hb bi translated">了解了随机森林模型的基本概念和用于解释结果的技术后，接下来要问的问题是——这些模型和解释技术在现实生活中的什么地方使用？知道这种技术当然很好，但是如果我们不知道何时何地应用它，那感觉就像是白费力气。</p><p id="3040" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">杰瑞米·霍华德在第六课中回答了这个问题，他解释了如何用随机森林模型来解释和理解数据。本课也是一个演练，涵盖了我们在前两篇文章中学到的所有技术。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="ld le l"/></div></figure><p id="270d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这一节中，我们将看看机器学习已经让人们感受到它的存在并正在成功实施的各个领域。</p><p id="a7ef" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">正如杰里米所解释的，商业市场可以大致分为两类——横向市场和纵向市场。我们将分别研究这些，但首先，让我们了解设计机器学习模型所涉及的最重要的步骤。</p><p id="2af6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们大致遵循四个步骤来完成这项工作。这些共同形成了“动力传动系统方法”，正如Jeremy在他的论文中解释的那样:<a class="ae jl" href="https://www.oreilly.com/ideas/drivetrain-approach-data-products" rel="noopener ugc nofollow" target="_blank">设计伟大的数据产品</a>。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="er es lf"><img src="../Images/eb03ed4a5d3607ed98d7419a9c04fad7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*s71WDg09u2XsIPAP.png"/></div></div></figure><p id="f7a0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">第一步:明确目标</strong></p><p id="c465" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在投入挑战和建立机器学习模型之前，人们必须在头脑中有一个清晰、明确的目标或最终目标。这可能因组织试图实现的目标而异。下面给出几个例子:</p><ul class=""><li id="46f8" class="kk kl hi ih b ii ij im in iq lk iu ll iy lm jc kr ks kt ku bi translated">销售更多书籍/产品</li><li id="74f8" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc kr ks kt ku bi translated">减少离开/流失的客户数量</li></ul><p id="a366" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">第二步:杠杆</strong></p><p id="a6d7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">杠杆是可以控制的输入，或组织可以做出的一些改变，以推动步骤1中定义的目标。例如，为了确保顾客满意:</p><ul class=""><li id="da0b" class="kk kl hi ih b ii ij im in iq lk iu ll iy lm jc kr ks kt ku bi translated">卖家可以对他的产品提供特别优惠</li><li id="6281" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc kr ks kt ku bi translated">购物超过20美元，赠送免费钢笔或其他商品</li></ul><p id="ff69" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">机器学习模型不能成为杠杆，但它可以<em class="ln">帮助</em>组织识别杠杆。清楚地理解这一区别很重要。</p><p id="c75e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">第三步:数据</strong></p><p id="5c6e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下一步是找出哪些数据有助于识别和设置组织可能拥有(或可以收集)的杠杆。这可能不同于组织先前已经提供或收集的数据。</p><p id="619a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">第四步:预测模型</strong></p><p id="b7b1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一旦我们获得了有助于实现上述目标的所需数据，最后一步就是根据这些数据建立一个模拟模型。请注意，一个模拟模型可以有多个预测模型。例如，构建一个模型来确定应该向用户推荐哪些商品，而构建另一个模型来预测用户根据推荐购买特定产品的概率。这个想法是创建一个优化模型，而不是一个预测模型。</p><p id="8a07" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">你可以阅读我在上面链接的论文来更详细地理解这些步骤。我们将继续从工业和商业的角度来理解机器学习的应用。</p><h1 id="93c3" class="jm jn hi bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated">机器学习在商业中的应用</h1><p id="56af" class="pw-post-body-paragraph if ig hi ih b ii km ik il im kn io ip iq la is it iu lb iw ix iy lc ja jb jc hb bi translated">正如我们前面提到的，我们可以将商业市场大致分为两类——横向和纵向。我将在这一节中详细阐述每一个问题，让您从行业的角度来看问题。</p><h2 id="8715" class="lo jn hi bd jo lp lq lr js ls lt lu jw iq lv lw ka iu lx ly ke iy lz ma ki mb bi translated">水平市场</h2><p id="bd32" class="pw-post-body-paragraph if ig hi ih b ii km ik il im kn io ip iq la is it iu lb iw ix iy lc ja jb jc hb bi translated">横向市场通常由人口统计学来定义(在不同类型的企业中可能很常见)，这大体上是指涉及营销的一切。这里是一组可以(并且正在)使用机器学习的营销应用。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mc"><img src="../Images/1dc7fd61d2a954cf9e1ab728e61a8a5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1338/format:webp/0*x49IpCkFCQ6NVTY2.png"/></div></figure><p id="283a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">以“流失”为例，目标是确定谁将离开或流失。假设一个组织有一个流失模型，该模型预测哪个员工将要离开，以及可以改变什么以减少离开的员工数量。</p><p id="857e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一旦确定了最终目标，我们就可以列出可以改变的事情，以减少离开组织的人数，并收集建立模型所需的任何数据。</p><p id="5167" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后，我们可以创建一个随机森林模型，并使用我们之前学到的解释技术。例如，来自随机森林模型的特征重要性方面可以帮助我们理解哪些特征最重要。或者，pdp绘图可视化可用于确定特定变化将如何影响目标变量(即员工流失的概率)。</p><h2 id="0e50" class="lo jn hi bd jo lp lq lr js ls lt lu jw iq lv lw ka iu lx ly ke iy lz ma ki mb bi translated">垂直市场</h2><p id="a85f" class="pw-post-body-paragraph if ig hi ih b ii km ik il im kn io ip iq la is it iu lb iw ix iy lc ja jb jc hb bi translated">垂直市场是指共享同一行业的一组业务，如教育、医疗保健、航空航天、金融等。下面是在这种情况下使用机器学习的几个例子:</p><ul class=""><li id="7d96" class="kk kl hi ih b ii ij im in iq lk iu ll iy lm jc kr ks kt ku bi translated"><strong class="ih hj">医疗保健:</strong>ML模型可用于预测患者再次入院的风险。基于关于患者的数据，例如他/她的年龄、血压、血小板计数、心率等。该模型可以预测患者再次入院的概率，并可用于找到其背后的确切原因。</li><li id="be39" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc kr ks kt ku bi translated"><strong class="ih hj">飞机排班:</strong>一个模型可以用来预测航班延误的几率，这对组织人员和决定登机口管理很有用。</li></ul><p id="4fbc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">讨论机器学习在各个领域的应用并回答每个领域的以下问题是一个很好的练习:</p><ul class=""><li id="c943" class="kk kl hi ih b ii ij im in iq lk iu ll iy lm jc kr ks kt ku bi translated">机器学习在各个领域有哪些可能的应用？</li><li id="31b9" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc kr ks kt ku bi translated">目标是什么？预测会是什么？</li><li id="561f" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc kr ks kt ku bi translated">将需要什么样的数据，哪种ML模型可用于该任务？</li></ul><p id="b02c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">到目前为止，我们的讨论已经让您对行业中过多的机器学习应用有了一个公平的想法。我们将快速回顾一下随机森林解释技术，然后继续从头开始构建随机森林模型。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="er es lf"><img src="../Images/76b2f1e71f501638601d39642668cdac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*AqY4m-Bof0kSSYMK.png"/></div></div></figure><h1 id="0440" class="jm jn hi bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated">随机森林解释技术</h1><p id="7bb8" class="pw-post-body-paragraph if ig hi ih b ii km ik il im kn io ip iq la is it iu lb iw ix iy lc ja jb jc hb bi translated">我们将快速回顾一下这些技术，因为我们已经在第2部分中介绍过了。要获得更详细的解释，您可以看看这篇文章:</p><ul class=""><li id="d8bf" class="kk kl hi ih b ii ij im in iq lk iu ll iy lm jc kr ks kt ku bi translated"><a class="ae jl" href="https://www.analyticsvidhya.com/blog/2018/10/interpret-random-forest-model-machine-learning-programmers/" rel="noopener ugc nofollow" target="_blank">使用fastai库解释随机森林模型的直观指南</a></li></ul><p id="e353" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">标准差</strong></p><p id="88b2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们计算了预测的标准偏差(针对<em class="ln">附件</em>和<em class="ln">产品尺寸</em>中的每个级别)，以找出模型错误预测的类别及其原因。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es md"><img src="../Images/922c8bc67ffc4ee87df77882828f800a.png" data-original-src="https://miro.medium.com/v2/resize:fit:976/format:webp/0*TAguM_agML8zVC9f.png"/></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es me"><img src="../Images/a5d0666597d64752984a03427dbab0d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:724/format:webp/0*wTfIJSjOJJCAIn7c.png"/></div></figure><p id="db39" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们发现，对于具有低数值计数的类别，模型给出了高标准偏差。因此，对具有较大值计数的类别的预测更准确的可能性更大(因为模型针对这些类别训练得很好)。有道理，对吧？</p><p id="ad2b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">特征重要性</strong></p><p id="0df5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">特征重要性基本上决定了一个特征在预测目标变量中的重要性。随机森林模型的前30个变量如下:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="er es mf"><img src="../Images/de3b93b8c95509d7d862701a17f6b52c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*fHI8xgkOVfRB6025.png"/></div></div></figure><p id="6e72" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从上图可以明显看出，<em class="ln"> YearMade </em>是最重要的变量。这是有道理的，因为车越老，<em class="ln">销售价格</em>越低。当不太重要的特征从训练集中移除时，模型性能得到改善。可以想象，这对于理解数据和变量非常有帮助。此外，我们可以使用一键编码为每个级别创建列，然后计算特性重要性:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="er es mg"><img src="../Images/4168e57953ebb41bae033927a3fef521.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*FrV3dnajP2I3Nxpp.png"/></div></div></figure><p id="ae81" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">部分依赖图(PDP) </strong></p><p id="a179" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">部分依赖用于理解特征对目标变量的依赖性。这是通过预测每一行的目标，保持一个变量不变来实现的。例如，当<em class="ln">年制</em>为1960年时，预测每一行的<em class="ln">销售价格</em>，然后预测<em class="ln">年制</em>为1961年，以此类推。结果会是这样一个图:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="er es mh"><img src="../Images/a374ffbcf4c82ea6bf07d0a3ecc887be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*YuvGx8U9QySBq-6c.png"/></div></div></figure><p id="278c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">树解释器</strong></p><p id="fd33" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">树解释器用于使用随机森林模型中的所有树来评估每行的预测。这也有助于我们理解每个变量对最终预测的贡献。</p><p id="f4f4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在我们理解如何计算多棵树的贡献之前，让我们先来看看一棵树:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="er es mi"><img src="../Images/376ce014bad79d8d52fe1a129b705eb0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*frylWGPiQhFVDaGu.png"/></div></div></figure><p id="2835" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="ln">耦合器_系统&lt; =5 </em>的值为10.189，对于<em class="ln">外壳&lt; =2 </em>的值为2.0，<em class="ln">型号_id </em>的值为9.955(现在只考虑最上面的路径)。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mj"><img src="../Images/32c58477299a8d2742f13a7aa6ad422d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1050/format:webp/0*S_Jy0-S4K7nVNYSH.png"/></div></figure><p id="d03e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="ln">外壳</em> &lt; =2的值不仅仅是因为<em class="ln">外壳</em>的特性，而是<em class="ln">耦合器_系统</em>和<em class="ln">外壳的组合。</em>换句话说，我们可以说<em class="ln">耦合器_系统</em>与<em class="ln">外壳</em>相互作用，贡献为0.156。同样，我们可以确定特征之间的交互重要性。</p><p id="1790" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们可以使用所有树的平均值来计算每个特征的总体贡献。对于验证集中的第一行，下面是每个变量的贡献:</p><pre class="je jf jg jh fd mk ml mm mn aw mo bi"><span id="8a57" class="lo jn hi ml b fi mp mq l mr ms">[('ProductSize', 'Mini', -0.54680742853695008),<br/>('age', 11, -0.12507089451852943),<br/>('fiProductClassDesc',<br/>'Hydraulic Excavator, Track - 3.0 to 4.0 Metric Tons',<br/>-0.11143111128570773),<br/>('fiModelDesc', 'KX1212', -0.065155113754146801),<br/>('fiSecondaryDesc', nan, -0.055237427792181749),<br/>('Enclosure', 'EROPS', -0.050467175593900217),<br/>('fiModelDescriptor', nan, -0.042354676935508852),<br/>('saleElapsed', 7912, -0.019642242073500914),<br/>('saleDay', 16, -0.012812993479652724),<br/>('Tire_Size', nan, -0.0029687660942271598),<br/>('SalesID', 4364751, -0.0010443985823001434),<br/>('saleDayofyear', 259, -0.00086540581130196688),<br/>('Drive_System', nan, 0.0015385818526195915),<br/>('Hydraulics', 'Standard', 0.0022411701338458821),<br/>('state', 'Ohio', 0.0037587658190299409),<br/>('ProductGroupDesc', 'Track Excavators', 0.0067688906745931197),<br/>('ProductGroup', 'TEX', 0.014654732626326661),<br/>('MachineID', 2300944, 0.015578052196894499),<br/>('Hydraulics_Flow', nan, 0.028973749866174004),<br/>('ModelID', 665, 0.038307429579276284),<br/>('Coupler_System', nan, 0.052509808150765114),<br/>('YearMade', 1999, 0.071829996446492878)]</span></pre><p id="6929" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">只是提醒一下，生成的值背后的计算已经在之前的帖子中讨论过了。</p><p id="1a01" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">外推</strong></p><p id="e26d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于这个特定的主题，Jeremy在讲座期间通过使用<em class="ln">行间距</em>创建一个合成数据集来执行现场编码。我们已经将起点和终点设置为0和1。</p><pre class="je jf jg jh fd mk ml mm mn aw mo bi"><span id="8cbb" class="lo jn hi ml b fi mp mq l mr ms">%matplotlib inline <br/>from fastai.imports import * <br/>from sklearn.ensemble import RandomForestRegressor</span><span id="861e" class="lo jn hi ml b fi mt mq l mr ms">x=np.linspace(0,1) <br/>x</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="er es mu"><img src="../Images/0109b568b82861b8c5740817c3c04b2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*KcvmD68l7dmW5FWz.png"/></div></div></figure><p id="992f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下一步是创建一个因变量。为简单起见，我们假设x和y之间存在线性关系。我们可以使用以下代码来生成目标变量并绘制该变量:</p><pre class="je jf jg jh fd mk ml mm mn aw mo bi"><span id="cc10" class="lo jn hi ml b fi mp mq l mr ms">y=x+np.random.uniform(-0.2,0.2,x.shape) <br/>plt.scatter(x,y)</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mv"><img src="../Images/16c6e9f89f75861f4f18f4d5d1dcb681.png" data-original-src="https://miro.medium.com/v2/resize:fit:766/format:webp/0*NROy6CrYVXfHz6K8.png"/></div></figure><p id="5f37" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将把1D数组转换成2D数组，作为随机森林模型的输入。</p><pre class="je jf jg jh fd mk ml mm mn aw mo bi"><span id="63ed" class="lo jn hi ml b fi mp mq l mr ms">x1=x[...,None]</span></pre><p id="5f19" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这50个数据点中，我们将选取40个数据点来训练我们的随机森林模型，并将剩下的10个数据点用作验证集。</p><pre class="je jf jg jh fd mk ml mm mn aw mo bi"><span id="2d16" class="lo jn hi ml b fi mp mq l mr ms">x_trn, x_val = x1[:40], x1[40:]<br/>y_trn, y_val = y[:40], y[40:]</span></pre><p id="8c04" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们现在可以拟合一个随机森林模型，并将预测值与实际值进行比较。</p><pre class="je jf jg jh fd mk ml mm mn aw mo bi"><span id="6ec7" class="lo jn hi ml b fi mp mq l mr ms">m = RandomForestRegressor().fit(x_trn, y_trn)<br/>plt.scatter(y_trn, m.predict(x_trn))</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mw"><img src="../Images/166b48613df04ee3245099792dbe7ddc.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*GEUkkL_x4a71X1mv.png"/></div></figure><p id="6f56" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">结果相当不错，但是你认为我们会在验证集上得到相似的结果吗？我们已经在前40个数据点上训练了我们的模型，其规模实际上与验证集的规模非常不同。因此，随机森林模型试图预测的任何新点，都不可避免地确定这些点更接近给定的40点中的最高点。</p><p id="c3c7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们来看看剧情:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mw"><img src="../Images/edc469f0fe7fff5aeaca4b05c2681319.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*gRoffLDEZsD6uFFz.png"/></div></figure><p id="b04f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这证实了我们的预感，random forest无法推断出它从未见过的数据类型。它基本上会给你之前看到的数据的平均值。那么应该如何处理这种类型的数据呢？我们可以潜在地使用神经网络，它已经被证明在这种情况下工作得更好。另一个显而易见的解决方案是使用时间序列技术(这是我亲自研究过的，可以证实它们显示出更好的结果)。</p><p id="eeab" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，为了结束第6课，我们讨论了构建机器学习模型的必要步骤，并简要介绍了我们在上一篇文章中学到的所有解释技术。如果你对这部分有任何问题，请在文章下面的评论中告诉我。</p><h1 id="2b2f" class="jm jn hi bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated">机器学习简介:第7课</h1><p id="1e39" class="pw-post-body-paragraph if ig hi ih b ii km ik il im kn io ip iq la is it iu lb iw ix iy lc ja jb jc hb bi translated">在前一篇文章中，我们开始学习如何从头开始构建随机森林模型。我们将从本节(第7课)停止的地方继续学习。本课结束时，您将能够自己从头构建一个端到端随机森林模型。听起来相当令人兴奋，所以让我们继续吧！</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="ld le l"/></div></figure><p id="d744" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们已经详细讨论了随机森林算法——从理解其工作原理到如何选择分割点，以及如何计算预测。我们现在将把我们的理解转化为代码形式，一次一步，也就是说，创建一个使用很少的功能、很少的树和数据子集的模型。</p><p id="b2ce" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="ln">注意:第1步到第6步已经在上一篇文章中介绍过了。</em></p><p id="56d3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">步骤1: </strong>导入基本库。</p><pre class="je jf jg jh fd mk ml mm mn aw mo bi"><span id="b50b" class="lo jn hi ml b fi mp mq l mr ms">%load_ext autoreload<br/>%autoreload 2<br/>%matplotlib inline<br/><br/>from fastai.imports import *<br/>from fastai.structured import *<br/>from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier<br/><br/>from IPython.display import display<br/>from sklearn import metrics</span></pre><p id="5510" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">第二步:</strong>读取数据并分成训练集和验证集。</p><pre class="je jf jg jh fd mk ml mm mn aw mo bi"><span id="4909" class="lo jn hi ml b fi mp mq l mr ms">PATH = "data/bulldozers/"<br/><br/>df_raw = pd.read_feather('tmp/bulldozers-raw')<br/>df_trn, y_trn, nas = proc_df(df_raw, 'SalePrice')<br/><br/>def split_vals(a,n): return a[:n], a[n:]<br/>n_valid = 12000<br/>n_trn = len(df_trn)-n_valid<br/><br/>X_train, X_valid = split_vals(df_trn, n_trn)<br/>y_train, y_valid = split_vals(y_trn, n_trn)<br/><br/>raw_train, raw_valid = split_vals(df_raw, n_trn)</span></pre><p id="1a96" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第三步:从数据的一个子集开始。</p><p id="5233" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">正如我之前提到的，我们将采取较小的步骤，所以这里我们只选择两个特性并使用它们。如果这样做很好，我们可以通过获取所有的特征来完成模型。</p><pre class="je jf jg jh fd mk ml mm mn aw mo bi"><span id="1b63" class="lo jn hi ml b fi mp mq l mr ms">x_sub = X_train[['YearMade', 'MachineHoursCurrentMeter']]</span></pre><p id="b635" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">步骤4: </strong>定义输入集:</p><ul class=""><li id="5973" class="kk kl hi ih b ii ij im in iq lk iu ll iy lm jc kr ks kt ku bi translated">一组特征— x</li><li id="3d2c" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc kr ks kt ku bi translated">目标变量— y</li><li id="4d9d" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc kr ks kt ku bi translated">随机森林中的树的数量— n_trees</li><li id="aa6b" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc kr ks kt ku bi translated">定义样本大小的变量— sample_sz</li><li id="5cf4" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc kr ks kt ku bi translated">最小叶子大小的变量min _ leaf</li><li id="5840" class="kk kl hi ih b ii kv im kw iq kx iu ky iy kz jc kr ks kt ku bi translated">用于测试的随机种子</li></ul><pre class="je jf jg jh fd mk ml mm mn aw mo bi"><span id="130e" class="lo jn hi ml b fi mp mq l mr ms">def __init__(self, x, y, n_trees, sample_sz, min_leaf=5):<br/>       np.random.seed(42)<br/>       self.x,self.y,self.sample_sz,self.min_leaf = x,y,sample_sz,min_leaf<br/>       self.trees = [self.create_tree() for i in range(n_trees)]</span></pre><p id="5d4a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">步骤5: </strong>定义一个使用数据样本(带替换)的函数，并在其上创建一个决策树。</p><pre class="je jf jg jh fd mk ml mm mn aw mo bi"><span id="1ab8" class="lo jn hi ml b fi mp mq l mr ms">def create_tree(self):<br/>       rnd_idxs = np.random.permutation(len(self.y))[:self.sample_sz]<br/>       return DecisionTree(self.x.iloc[rnd_idxs], self.y[rnd_idxs], min_leaf=self.min_leaf)</span></pre><p id="427c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">第6步:</strong>创建一个预测函数。特定行的每棵树的预测值的平均值作为最终预测返回。</p><pre class="je jf jg jh fd mk ml mm mn aw mo bi"><span id="170b" class="lo jn hi ml b fi mp mq l mr ms">def predict(self, x):<br/>       return np.mean([t.predict(x) for t in self.trees], axis=0)</span></pre><p id="266b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">结合以上所有函数，我们可以创建一个类<em class="ln"> TreeEnsemble </em>。</p><pre class="je jf jg jh fd mk ml mm mn aw mo bi"><span id="d0ea" class="lo jn hi ml b fi mp mq l mr ms">class TreeEnsemble():<br/>   def __init__(self, x, y, n_trees, sample_sz, min_leaf=5):<br/>       np.random.seed(42)<br/>       self.x,self.y,self.sample_sz,self.min_leaf = x,y,sample_sz,min_leaf<br/>       self.trees = [self.create_tree() for i in range(n_trees)]<br/><br/>   def create_tree(self):<br/>       rnd_idxs = np.random.permutation(len(self.y))[:self.sample_sz]<br/>       return DecisionTree(self.x.iloc[rnd_idxs], self.y[rnd_idxs], min_leaf=self.min_leaf)<br/>       <br/>   def predict(self, x):<br/>       return np.mean([t.predict(x) for t in self.trees], axis=0)</span></pre><p id="75f4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">步骤7: 创建一个类<em class="ln">决策树</em>。我们在函数<em class="ln"> create_tree，</em>中调用<em class="ln">决策树</em>，所以让我们在这里定义它。决策树有一组独立变量、一个目标变量和索引值。目前，我们只创建了一个决策树(稍后我们可以让它递归)。</p><pre class="je jf jg jh fd mk ml mm mn aw mo bi"><span id="2ab2" class="lo jn hi ml b fi mp mq l mr ms">class DecisionTree():<br/>  def __init__(self, x, y, idxs=None, min_leaf=5):<br/>      if idxs is None: idxs=np.arange(len(y))<br/>      self.x,self.y,self.idxs,self.min_leaf = x,y,idxs,min_leaf ##define x,y,index and minimum leaf size<br/>      self.n,self.c = len(idxs), x.shape[1]  ##number of rows and columns<br/>      self.val = np.mean(y[idxs])  <br/>      self.score = float('inf')<br/>      self.find_varsplit()</span></pre><p id="a581" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">第八步:</strong>确定最佳分割点。对于每一列，我们使用函数<em class="ln"> find_better_split </em>来识别拆分点，然后返回拆分的列名、值和分数。</p><pre class="je jf jg jh fd mk ml mm mn aw mo bi"><span id="5c7d" class="lo jn hi ml b fi mp mq l mr ms">def find_varsplit(self):<br/>      for i in range(self.c): self.find_better_split(i) #check for each column in the dataset<br/>   <br/>def find_varsplit(self):<br/>       for i in range(self.c): self.find_better_split(i)<br/><br/>  @property<br/>  def split_name(self): return self.x.columns[self.var_idx]<br/><br/>  @property<br/>  def split_col(self):<br/>      return self.x.values[self.idxs,self.var_idx]<br/><br/>  @property<br/>  def is_leaf(self): return self.score == float('inf')<br/><br/>  def __repr__(self):<br/>      s = f'n: {self.n}; val:{self.val}'<br/>      if not self.is_leaf:<br/>          s += f'; score:{self.score}; split:{self.split}; var:<br/>                 {self.split_name}'<br/>      return s</span></pre><p id="95f5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">第9步:</strong>用10棵树建立我们的第一个模型，样本大小为1000，最小叶子为3。</p><pre class="je jf jg jh fd mk ml mm mn aw mo bi"><span id="40c4" class="lo jn hi ml b fi mp mq l mr ms">m = TreeEnsemble(X_train, y_train, n_trees=10, sample_sz=1000,min_leaf=3)<br/>m.trees[0]</span></pre><p id="33e4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于第一棵树，结果是:</p><pre class="je jf jg jh fd mk ml mm mn aw mo bi"><span id="e114" class="lo jn hi ml b fi mp mq l mr ms">n: 1000; val:10.079014121552744</span></pre><p id="906f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在让我们填充我们在上面第8步中留下的块— <em class="ln"> find_better_split </em>。这是到目前为止代码中最难理解的部分，但是Jeremy已经用excel中的一个简单例子进行了解释。我在这里用直观的方式解释一下。</p><p id="4635" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于每个变量，我们将点分成左右两个节点，并检查每个值的得分。我们的想法是找到一个分割点，在这里我们可以将更多相似的点分割在一起。</p><p id="ff77" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">考虑下面的例子:我们有两列——一个我们试图分割的独立变量和一个二进制目标变量。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mx"><img src="../Images/a751063582e5ff609a7c1fd68ede9aa2.png" data-original-src="https://miro.medium.com/v2/resize:fit:402/format:webp/0*K6BFEy11hZcpf0cZ.png"/></div></figure><p id="c661" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将在第一列的每个值处进行分割，并计算标准偏差，以确定我们能够对目标进行分类的程度。我们假设第一个分裂点&gt; =3，然后计算标准差。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es my"><img src="../Images/50f7981e4a0760a8f704fd081f3fc0a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:578/format:webp/0*dlqumRG8F8MOFeRV.png"/></div></figure><p id="be85" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以取这个值的加权平均值。类似地，我们可以计算4、6、1等的分割。让我们把它写成代码:</p><pre class="je jf jg jh fd mk ml mm mn aw mo bi"><span id="46c5" class="lo jn hi ml b fi mp mq l mr ms">def find_better_split(self, var_idx):<br/>   x,y = self.x.values[self.idxs,var_idx], self.y[self.idxs]<br/><br/>   for i in range(self.n):<br/>       lhs = x&lt;=x[i]<br/>       rhs = x&gt;x[i]<br/>       if rhs.sum()&lt;self.min_leaf or lhs.sum()&lt;self.min_leaf: continue<br/>       lhs_std = y[lhs].std()<br/>       rhs_std = y[rhs].std()<br/>       curr_score = lhs_std*lhs.sum() + rhs_std*rhs.sum()<br/>       if curr_score&lt;self.score: <br/>           self.var_idx,self.score,self.split = var_idx,curr_score,x[i]</span></pre><p id="ceea" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果我们尝试分别打印两列的函数结果，我们会得到下面的结果:</p><pre class="je jf jg jh fd mk ml mm mn aw mo bi"><span id="6995" class="lo jn hi ml b fi mp mq l mr ms">find_better_split(tree,1) <br/>tree</span><span id="180e" class="lo jn hi ml b fi mt mq l mr ms">n: 1000; val:10.079014121552744; score:681.0184057251435; split:3744.0; var:MachineHoursCurrentMeter</span><span id="7261" class="lo jn hi ml b fi mt mq l mr ms">find_better_split(tree,0)<br/>tree</span><span id="6eb2" class="lo jn hi ml b fi mt mq l mr ms">n: 1000; val:10.079014121552744; score:658.5510186055949; split:1974.0; var:YearMade</span></pre><p id="4625" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">看起来1974年制造的是一个更好的分割点。</p><p id="4f51" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">第十步:</strong>对比<em class="ln"> scikit-learn </em>随机森林。但是请记住，这里有一个棘手的方面。在比较这两个模型时，它们应该具有相同的输入。因此，让我们存储我们刚刚构建的随机森林中使用的输入。</p><pre class="je jf jg jh fd mk ml mm mn aw mo bi"><span id="b3d7" class="lo jn hi ml b fi mp mq l mr ms">ens = TreeEnsemble(x_sub, y_train, 1, 1000) <br/>tree = ens.trees[0] <br/>x_samp,y_samp = tree.x, tree.y</span></pre><p id="dbaa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在我们在这个子集上建立一个模型:</p><pre class="je jf jg jh fd mk ml mm mn aw mo bi"><span id="56de" class="lo jn hi ml b fi mp mq l mr ms">m = RandomForestRegressor(n_estimators=1, max_depth=1, bootstrap=<strong class="ml hj">False</strong>)<br/>m.fit(x_samp, y_samp)<br/>draw_tree(m.estimators_[0], x_samp, precision=2)</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="er es lf"><img src="../Images/79458a2cb26250517cdc88a76462c8cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*WtsarOYM4wJc4VpP.png"/></div></div></figure><p id="79e8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们看到这里的分裂出现在1974.5年的<em class="ln">年制造的</em>列上，与我们模型的结果非常相似。还不错！</p><p id="d528" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">到目前为止，我们看到的代码有一个问题——你能认出它是什么吗？我们需要优化它！在当前的格式中，我们检查每一行的拆分分数，也就是多次检查一个值。看看我们之前使用的例子:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mx"><img src="../Images/ff7bbb744f6b8ee22e435d288f3c67c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:402/format:webp/0*8O45xXRYz_GrHNZY.png"/></div></figure><p id="6462" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">该函数将检查分割点4和1两次，因为它实际上是按行工作的。优化我们的代码以减少计算时间是一个好主意(不是每个人都有一台顶级机器！).想法是按列排序，然后在拆分后只检查唯一值的得分。</p><pre class="je jf jg jh fd mk ml mm mn aw mo bi"><span id="b832" class="lo jn hi ml b fi mp mq l mr ms">sort_idx = np.argsort(x) <br/>sort_y,sort_x = y[sort_idx], x[sort_idx]</span></pre><p id="34fb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">此外，为了计算标准偏差，我们定义了以下函数:</p><pre class="je jf jg jh fd mk ml mm mn aw mo bi"><span id="398c" class="lo jn hi ml b fi mp mq l mr ms">def std_agg(cnt, s1, s2): return math.sqrt((s2/cnt) - (s1/cnt)**2)</span></pre><p id="7547" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将需要跟踪分割的每一边的数据点的计数以及值的平方和。所以我们初始化变量<em class="ln"> rhs_cnt，lhs_cnt，rjs_sum2 </em>和<em class="ln"> lhs_sum2。</em></p><pre class="je jf jg jh fd mk ml mm mn aw mo bi"><span id="da9a" class="lo jn hi ml b fi mp mq l mr ms">rhs_cnt,rhs_sum,rhs_sum2 = self.n, sort_y.sum(), (sort_y**2).sum() lhs_cnt,lhs_sum,lhs_sum2 = 0,0.,0.</span></pre><p id="0fb2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">综上所述，代码如下所示:</p><pre class="je jf jg jh fd mk ml mm mn aw mo bi"><span id="230e" class="lo jn hi ml b fi mp mq l mr ms">tree = TreeEnsemble(x_sub, y_train, 1, 1000).trees[0]<br/>def std_agg(cnt, s1, s2): return math.sqrt((s2/cnt) - (s1/cnt)**2)<br/>def find_better_split_foo(self, var_idx):<br/>x,y = self.x.values[self.idxs,var_idx], self.y[self.idxs]<br/><br/>sort_idx = np.argsort(x)<br/>sort_y,sort_x = y[sort_idx], x[sort_idx]<br/><br/>rhs_cnt,rhs_sum,rhs_sum2 = self.n, sort_y.sum(), (sort_y**2).sum()<br/>lhs_cnt,lhs_sum,lhs_sum2 = 0,0.,0.<br/><br/>for i in range(0,self.n-self.min_leaf-1):<br/>  xi,yi = sort_x[i],sort_y[i]<br/>  lhs_cnt += 1; rhs_cnt -= 1<br/>  lhs_sum += yi; rhs_sum -= yi<br/>  lhs_sum2 += yi**2; rhs_sum2 -= yi**2<br/>  if i&lt;self.min_leaf or xi==sort_x[i+1]:<br/>    continue<br/>  <br/>  lhs_std = std_agg(lhs_cnt, lhs_sum, lhs_sum2)<br/>  rhs_std = std_agg(rhs_cnt, rhs_sum, rhs_sum2)<br/>  curr_score = lhs_std*lhs_cnt + rhs_std*rhs_cnt<br/>  if curr_score&lt;self.score:<br/>    self.var_idx,self.score,self.split = var_idx,curr_score,xi</span></pre><p id="2274" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">理想情况下，这个函数应该给出相同的结果。让我们检查一下:</p><pre class="je jf jg jh fd mk ml mm mn aw mo bi"><span id="b38b" class="lo jn hi ml b fi mp mq l mr ms">%timeit find_better_split_foo(tree,1) <br/>tree</span><span id="f99a" class="lo jn hi ml b fi mt mq l mr ms">2.2 ms ± 148 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)<br/>n: 1000; val:10.079014121552744; score:658.5510186055565; split:1974.0; var:YearMade</span></pre><p id="6d00" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">请注意，我们创建了一个新函数(将名称从<em class="ln"> find_better_split </em>略微更改为<em class="ln"> find_better_split_foo </em>)，我们需要在我们的<em class="ln">决策树</em>类中使用它。以下命令为我们做了这件事:</p><pre class="je jf jg jh fd mk ml mm mn aw mo bi"><span id="8f86" class="lo jn hi ml b fi mp mq l mr ms">DecisionTree.find_better_split = find_better_split_foo</span></pre><p id="6eb5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">第12步:</strong>用一个以上的分割来构建我们的树。</p><p id="3cc6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在第10步中，我们将模型的第一层与scikit-learn随机森林模型进行了比较。我们现在将创建一个完整的树(在我们的两个特征上分裂)并再次比较它。现在我们的<em class="ln"> find_varsplit </em>函数看起来像这样:</p><pre class="je jf jg jh fd mk ml mm mn aw mo bi"><span id="f846" class="lo jn hi ml b fi mp mq l mr ms">def find_varsplit(self):<br/>      for i in range(self.c): self.find_better_split(i)</span></pre><p id="fee1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里我们已经单独定义了<em class="ln"> find_better_split </em>。我们将更新这个函数，以便它自动检查叶节点，并在分割后在lhs和rhs中存储一个索引列表。</p><pre class="je jf jg jh fd mk ml mm mn aw mo bi"><span id="8d37" class="lo jn hi ml b fi mp mq l mr ms">def find_varsplit(self):<br/>  for i in range(self.c): self.find_better_split(i)<br/>  if self.is_leaf: return<br/>  x = self.split_col<br/>  lhs = np.nonzero(x&lt;=self.split)[0]<br/>  rhs = np.nonzero(x&gt;self.split)[0]<br/>  self.lhs = DecisionTree(self.x, self.y, self.idxs[lhs])<br/>  self.rhs = DecisionTree(self.x, self.y, self.idxs[rhs])<br/><br/>DecisionTree.find_varsplit = find_varsplit</span></pre><p id="b339" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将再次比较这两种模型。以前，<em class="ln"> max_depth </em>被限制为1，我们在这里将它设为2(我们现在只有两个特性):</p><pre class="je jf jg jh fd mk ml mm mn aw mo bi"><span id="e684" class="lo jn hi ml b fi mp mq l mr ms">m = RandomForestRegressor(n_estimators=1, max_depth=2,  bootstrap=<strong class="ml hj">False</strong>)<br/>m.fit(x_samp, y_samp)<br/>draw_tree(m.estimators_[0], x_samp, precision=2)</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mz"><img src="../Images/0993fe9a194158f40f7db817c869e681.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/0*3ZL97II4kZVkctzf.png"/></div></figure><p id="331c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在看看我们的结果:</p><pre class="je jf jg jh fd mk ml mm mn aw mo bi"><span id="249b" class="lo jn hi ml b fi mp mq l mr ms">tree = TreeEnsemble(x_sub, y_train, 1, 1000).trees[0] <br/>tree</span><span id="0049" class="lo jn hi ml b fi mt mq l mr ms">n: 1000; val:10.079014121552744; score:658.5510186055565; split:1974.0; var:YearMade</span></pre><p id="005a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">根据上图，lhs应该有159个样本，值为9.66，而rhs应该有841个样本，值为10.15。</p><pre class="je jf jg jh fd mk ml mm mn aw mo bi"><span id="2322" class="lo jn hi ml b fi mp mq l mr ms">tree.lhs <br/>n: 159; val:9.660892662981706; score:76.82696888346362; split:2800.0; var:MachineHoursCurrentMeter</span><span id="a538" class="lo jn hi ml b fi mt mq l mr ms">tree.rhs <br/>n: 841; val:10.158064432982941; score:571.4803525045031; split:2005.0; var:YearMade</span></pre><p id="dcf7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">到目前为止一切看起来都很完美！深入到树的下一层，lhs的左侧应该包含150个样本:</p><pre class="je jf jg jh fd mk ml mm mn aw mo bi"><span id="8a2f" class="lo jn hi ml b fi mp mq l mr ms">tree.lhs.lhs </span><span id="aec1" class="lo jn hi ml b fi mt mq l mr ms">n: 150; val:9.619280538108496; score:71.15906938383463; split:1000.0; var:YearMade</span></pre><p id="0558" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">太好了！我们能够建造自己的树。让我们创建一个函数来计算预测，然后我们将比较r平方值。</p><p id="468b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第十三步:计算最后的预测。我们在<em class="ln"> TreeEnsemble </em>中调用了一个预测函数，该函数返回每一行的预测值:</p><pre class="je jf jg jh fd mk ml mm mn aw mo bi"><span id="ed06" class="lo jn hi ml b fi mp mq l mr ms">def predict(self, x):<br/>return np.array([self.predict_row(xi) for xi in x])<br/><br/>def predict_row(self, xi):<br/>if self.is_leaf: return self.val<br/>t = self.lhs if xi[self.var_idx]&lt;=self.split else self.rhs<br/>return t.predict_row(xi)<br/>DecisionTree.predict_row = predict_row</span></pre><p id="d5f4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">至此，我们已经完成了我们自己的随机森林模型的构建。让我们在验证集上绘制预测:</p><pre class="je jf jg jh fd mk ml mm mn aw mo bi"><span id="fe2a" class="lo jn hi ml b fi mp mq l mr ms">cols = ['MachineID', 'YearMade', 'MachineHoursCurrentMeter', 'ProductSize', 'Enclosure','Coupler_System', 'saleYear']</span><span id="ed49" class="lo jn hi ml b fi mt mq l mr ms">%time tree = TreeEnsemble(X_train[cols], y_train, 1, 1000).trees[0]<br/>x_samp,y_samp = tree.x, tree.y<br/><br/>CPU times: user 288 ms, sys: 12 ms, total: 300 ms<br/>Wall time: 297 ms<br/><br/>plt.scatter(preds, y_valid, alpha=0.05)</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mw"><img src="../Images/f5eefd545235617a8463097fdda78464.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*g402BSEq8_fPaqxj.png"/></div></figure><pre class="je jf jg jh fd mk ml mm mn aw mo bi"><span id="f298" class="lo jn hi ml b fi mp mq l mr ms">metrics.r2_score(preds, y_valid)<br/><br/>0.4840854669925271</span></pre><p id="c7dc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对照scikit-learn模型检查性能和r-square:</p><pre class="je jf jg jh fd mk ml mm mn aw mo bi"><span id="63bb" class="lo jn hi ml b fi mp mq l mr ms">m = RandomForestRegressor(n_estimators=1, min_samples_leaf=5, bootstrap=False)<br/>%time m.fit(x_samp, y_samp)<br/>preds = m.predict(X_valid[cols].values)<br/>plt.scatter(preds, y_valid, alpha=0.05)</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mw"><img src="../Images/ac7b5543ded414d129dbdc8bbac220b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*EsxSxIvMBIodhuGg.png"/></div></figure><pre class="je jf jg jh fd mk ml mm mn aw mo bi"><span id="c14a" class="lo jn hi ml b fi mp mq l mr ms">metrics.r2_score(preds, y_valid) </span><span id="1b3b" class="lo jn hi ml b fi mt mq l mr ms">0.47541053100694797</span></pre><p id="2767" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第14步:把所有的东西放在一起！</p><pre class="je jf jg jh fd mk ml mm mn aw mo bi"><span id="64bf" class="lo jn hi ml b fi mp mq l mr ms">class TreeEnsemble():<br/>    def __init__(self, x, y, n_trees, sample_sz, min_leaf=5):<br/>        np.random.seed(42)<br/>        self.x,self.y,self.sample_sz,self.min_leaf = x,y,sample_sz,min_leaf<br/>        self.trees = [self.create_tree() for i in range(n_trees)]<br/><br/>    def create_tree(self):<br/>        idxs = np.random.permutation(len(self.y))[:self.sample_sz]<br/>        return DecisionTree(self.x.iloc[idxs], self.y[idxs], <br/>                    idxs=np.array(range(self.sample_sz)), min_leaf=self.min_leaf)<br/>        <br/>    def predict(self, x):<br/>        return np.mean([t.predict(x) for t in self.trees], axis=0)<br/><br/>def std_agg(cnt, s1, s2): return math.sqrt((s2/cnt) - (s1/cnt)**2)</span><span id="c479" class="lo jn hi ml b fi mt mq l mr ms">class DecisionTree():<br/>    def __init__(self, x, y, idxs, min_leaf=5):<br/>        self.x,self.y,self.idxs,self.min_leaf = x,y,idxs,min_leaf<br/>        self.n,self.c = len(idxs), x.shape[1]<br/>        self.val = np.mean(y[idxs])<br/>        self.score = float('inf')<br/>        self.find_varsplit()<br/>        <br/>    def find_varsplit(self):<br/>        for i in range(self.c): self.find_better_split(i)<br/>        if self.score == float('inf'): return<br/>        x = self.split_col<br/>        lhs = np.nonzero(x&lt;=self.split)[0]<br/>        rhs = np.nonzero(x&gt;self.split)[0]<br/>        self.lhs = DecisionTree(self.x, self.y, self.idxs[lhs])<br/>        self.rhs = DecisionTree(self.x, self.y, self.idxs[rhs])<br/><br/>    def find_better_split(self, var_idx):<br/>        x,y = self.x.values[self.idxs,var_idx], self.y[self.idxs]<br/>        sort_idx = np.argsort(x)<br/>        sort_y,sort_x = y[sort_idx], x[sort_idx]<br/>        rhs_cnt,rhs_sum,rhs_sum2 = self.n, sort_y.sum(), (sort_y**2).sum()<br/>        lhs_cnt,lhs_sum,lhs_sum2 = 0,0.,0.<br/><br/>        for i in range(0,self.n-self.min_leaf):<br/>            xi,yi = sort_x[i],sort_y[i]<br/>            lhs_cnt += 1; rhs_cnt -= 1<br/>            lhs_sum += yi; rhs_sum -= yi<br/>            lhs_sum2 += yi**2; rhs_sum2 -= yi**2<br/>            if i&lt;self.min_leaf-1 or xi==sort_x[i+1]:<br/>                continue<br/><br/>            lhs_std = std_agg(lhs_cnt, lhs_sum, lhs_sum2)<br/>            rhs_std = std_agg(rhs_cnt, rhs_sum, rhs_sum2)<br/>            curr_score = lhs_std*lhs_cnt + rhs_std*rhs_cnt<br/>            if curr_score&lt;self.score: <br/>                self.var_idx,self.score,self.split = var_idx,curr_score,xi<br/><br/>    @property<br/>    def split_name(self): return self.x.columns[self.var_idx]<br/>    <br/>    @property<br/>    def split_col(self): return self.x.values[self.idxs,self.var_idx]<br/><br/>    @property<br/>    def is_leaf(self): return self.score == float('inf')<br/>    <br/>    def __repr__(self):<br/>        s = f'n: {self.n}; val:{self.val}'<br/>        if not self.is_leaf:<br/>            s += f'; score:{self.score}; split:{self.split}; var:{self.split_name}'<br/>        return s<br/><br/>    def predict(self, x):<br/>        return np.array([self.predict_row(xi) for xi in x])<br/><br/>    def predict_row(self, xi):<br/>        if self.is_leaf: return self.val<br/>        t = self.lhs if xi[self.var_idx]&lt;=self.split else self.rhs<br/>        return t.predict_row(xi)</span><span id="49f3" class="lo jn hi ml b fi mt mq l mr ms">ens = TreeEnsemble(X_train[cols], y_train, 5, 1000)<br/>preds = ens.predict(X_valid[cols].values)<br/>plt.scatter(y_valid, preds, alpha=0.1, s=6);</span><span id="0a1d" class="lo jn hi ml b fi mt mq l mr ms">metrics.r2_score(y_valid, preds) </span><span id="b5e1" class="lo jn hi ml b fi mt mq l mr ms">0.7025757322910476</span></pre><p id="4f64" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这就对了。这是一次相当好的学习经历，我们现在已经从零开始正式建立了一种机器学习技术。真正值得骄傲的事情！</p><h1 id="0107" class="jm jn hi bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated">结束注释</h1><p id="dcfd" class="pw-post-body-paragraph if ig hi ih b ii km ik il im kn io ip iq la is it iu lb iw ix iy lc ja jb jc hb bi translated">让我们快速回顾一下我们在第3部分中讲述的内容。我们从<strong class="ih hj">第6课</strong>开始，它广泛涵盖了机器学习在各种商业领域的应用，以及我们在第2部分看到的解释技术的修订版。</p><p id="94af" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">本文的后半部分讲述了<strong class="ih hj">第7课</strong>，代码有点多。我们构建了一个完整的随机森林模型，并将其性能与scikit-learn的模型进行了比较。理解模型实际上是如何工作的，而不是简单地实现模型，这是一个很好的实践。</p><p id="3a43" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">至此，我们结束了对随机森林模型的理解、解释和构建。在下一部分，我们将把重点转移到神经网络上。我们将在非常受欢迎的MNIST数据集上工作，所以应该会很有趣！</p><p id="7e5d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">你也可以在分析Vidhya的Android应用上阅读这篇文章</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="er es na"><img src="../Images/23ebb2faf829e7872d64f53f845abbf6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1292/format:webp/0*xTFJYyITnIFrBt-Z.png"/></div></div></figure></div><div class="ab cl nb nc gp nd" role="separator"><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng"/></div><div class="hb hc hd he hf"><p id="a4f6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="ln">原载于2018年12月3日</em><a class="ae jl" href="https://www.analyticsvidhya.com/blog/2018/12/building-a-random-forest-from-scratch-understanding-real-world-data-products-ml-for-programmers-part-3/" rel="noopener ugc nofollow" target="_blank"><em class="ln">www.analyticsvidhya.com</em></a><em class="ln">。</em></p></div></div>    
</body>
</html>