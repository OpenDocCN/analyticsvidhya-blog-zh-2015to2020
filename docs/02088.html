<html>
<head>
<title>No need to be perplexed by perplexity</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">没有必要被困惑所困扰</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/no-need-to-be-perplexed-by-perplexity-cd4cb71ac97b?source=collection_archive---------8-----------------------#2019-11-29">https://medium.com/analytics-vidhya/no-need-to-be-perplexed-by-perplexity-cd4cb71ac97b?source=collection_archive---------8-----------------------#2019-11-29</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/596d1a2f62e6111714c8ac8d79190b8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*eBLIU3BAgOpR15rp9c2ZDg.jpeg"/></div></figure><p id="b196" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">当我第一次在自然语言处理中听到这个术语时，困惑这个名称引起了我的兴趣。于是想到了写一篇文章。相信我，困惑并不像听起来那样。</p><p id="943d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">一般来说，困惑是一种混乱的状态或复杂而困难的情况或事情。从技术上来说，困惑被用来衡量一个语言模型的效用。语言模型是估计一个句子或一系列单词或即将出现的单词的概率。在这篇文章中，你将会知道什么是真正的困惑，并且非常容易理解。</p></div><div class="ab cl jl jm gp jn" role="separator"><span class="jo bw bk jp jq jr"/><span class="jo bw bk jp jq jr"/><span class="jo bw bk jp jq"/></div><div class="hb hc hd he hf"><h1 id="bb99" class="js jt hi bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">介绍</h1><p id="c055" class="pw-post-body-paragraph im in hi io b ip kq ir is it kr iv iw ix ks iz ja jb kt jd je jf ku jh ji jj hb bi translated">困惑是对概率模型预测测试数据的程度的度量。基本上，它是一个句子、短语、单词序列等的概率分布。困惑是我们用来评估语言模型的一个变量。低困惑度表示概率分布擅长预测样本。让我们看看在评估语言模型时如何使用它。</p><h1 id="4463" class="js jt hi bd ju jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp bi translated">困惑背后的数学</h1><p id="1b89" class="pw-post-body-paragraph im in hi io b ip kq ir is it kr iv iw ix ks iz ja jb kt jd je jf ku jh ji jj hb bi translated">基本上，最好的模型是能够最好地预测未知测试集的模型。语言模型在测试集上的困惑度是测试集的逆概率，用单词数归一化。对于单词为W = w_1，w_2，…，w_N的测试集，测试集上模型的困惑度为:</p><figure class="lb lc ld le fd ij er es paragraph-image"><div class="er es la"><img src="../Images/91fa09f84e36ea5212132f38f75d476f.png" data-original-src="https://miro.medium.com/v2/resize:fit:616/format:webp/1*vV0XMYe69LPMlH3fFouDtw.png"/></div></figure><p id="6986" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这样，刑期越长，可能性就越小。然后再由链式法则:</p><figure class="lb lc ld le fd ij er es paragraph-image"><div class="er es lf"><img src="../Images/039880e37ff3304109f31dadf770c9f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:808/format:webp/1*tmWF4HzQatbzViErUXvRIA.png"/></div></figure><p id="742b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">困惑是句子概率的函数。困惑反转的意思是<strong class="io hj">每当我们最小化困惑时，我们就最大化了概率。</strong></p><h1 id="4a45" class="js jt hi bd ju jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp bi translated">概率分布的困惑</h1><p id="bef5" class="pw-post-body-paragraph im in hi io b ip kq ir is it kr iv iw ix ks iz ja jb kt jd je jf ku jh ji jj hb bi translated">离散概率分布p的困惑度被定义为熵的指数:</p><figure class="lb lc ld le fd ij er es paragraph-image"><div class="er es lg"><img src="../Images/dab8034d13f3bea72e332845bc3ee36e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*-eBZ2cBL7oQZ60qd9TqVXQ.png"/></div><figcaption class="lh li et er es lj lk bd b be z dx translated">来源:https://en.wikipedia.org/wiki/Perplexity<a class="ae jk" href="https://en.wikipedia.org/wiki/Perplexity" rel="noopener ugc nofollow" target="_blank"/></figcaption></figure><p id="7cec" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">其中H(p)是分布p(x)的熵，x是所有可能值上的随机变量</p><blockquote class="ll lm ln"><p id="44a8" class="im in lo io b ip iq ir is it iu iv iw lp iy iz ja lq jc jd je lr jg jh ji jj hb bi translated">熵是对随机变量的结果进行编码所需的预期或平均位数的度量。熵可以被视为一个信息量，而困惑可以被视为随机变量的选择数量。</p></blockquote><p id="2f4b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">举例:</strong></p><p id="6a9c" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">考虑扔一个公平的硬币，出现正面或反面的概率。</p><p id="f34e" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">下一次掷硬币的未知结果的熵被最大化，即如果正面和反面都有相等的概率1/2。</p><figure class="lb lc ld le fd ij er es paragraph-image"><div class="er es ls"><img src="../Images/d0343745b869a46c56aee55a492bb3f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:516/format:webp/1*jUc1XOoFZPEynoArp0tYAw.png"/></div></figure><p id="9cff" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">所以<strong class="io hj">，熵</strong>为1。</p><figure class="lb lc ld le fd ij er es paragraph-image"><div class="er es lf"><img src="../Images/48cfa25eed1c1cdc230fbbd5e2e11941.png" data-original-src="https://miro.medium.com/v2/resize:fit:808/format:webp/1*pMuY1UP5oTv9QorIs3FQFw.png"/></div></figure><p id="d104" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">困惑度</strong>为2。</p><p id="06dd" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">熵使用对数，而困惑和它的<strong class="io hj"> e^ </strong>使它回到线性范围。一个好的语言模型应该预测高的单词概率。所以，困惑越小越好。</p><p id="bbc9" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">作为分支因素的困惑</strong></p><p id="2a6d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">对任何指数熵度量的解释都是作为一个分支因子(随机变量拥有的加权平均选择数):熵以比特为单位来度量不确定性，但在指数形式中，它被度量为具有同等不确定性的同等加权分布的大小。也就是说，exp(H(p))是为了获得与分布p相同的不确定性，在一个公平骰子上需要多少个面</p><p id="8641" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">熵有一个常数的不同，这取决于你是用以2为底的对数还是用自然对数来测量，但是不管你用哪个底，困惑都是一样的。</p><h1 id="21d3" class="js jt hi bd ju jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp bi translated">困惑和概率是如何关联的？</h1><p id="f21b" class="pw-post-body-paragraph im in hi io b ip kq ir is it kr iv iw ix ks iz ja jb kt jd je jf ku jh ji jj hb bi translated">最小化困惑和最大化概率是一样的</p><ul class=""><li id="4556" class="lt lu hi io b ip iq it iu ix lv jb lw jf lx jj ly lz ma mb bi translated">更高的概率意味着更低的困惑</li><li id="3f0d" class="lt lu hi io b ip mc it md ix me jb mf jf mg jj ly lz ma mb bi translated">信息越多，困惑越少</li><li id="31f0" class="lt lu hi io b ip mc it md ix me jb mf jf mg jj ly lz ma mb bi translated">更低的困惑意味着更好的模型</li><li id="7302" class="lt lu hi io b ip mc it md ix me jb mf jf mg jj ly lz ma mb bi translated">困惑越低，我们就越接近真实的模型</li></ul><h1 id="d808" class="js jt hi bd ju jv kv jx jy jz kw kb kc kd kx kf kg kh ky kj kk kl kz kn ko kp bi translated">参考资料:</h1><ul class=""><li id="27e6" class="lt lu hi io b ip kq it kr ix mh jb mi jf mj jj ly lz ma mb bi translated"><a class="ae jk" href="https://web.stanford.edu/class/cs124/lec/languagemodeling.pdf" rel="noopener ugc nofollow" target="_blank">https://web . Stanford . edu/class/cs 124/LEC/language modeling . pdf</a></li><li id="f985" class="lt lu hi io b ip mc it md ix me jb mf jf mg jj ly lz ma mb bi translated"><a class="ae jk" href="https://en.wikipedia.org/wiki/Perplexity" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Perplexity</a></li></ul><p id="9187" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">谢谢你读到这里。敬请关注更多内容！</p></div></div>    
</body>
</html>