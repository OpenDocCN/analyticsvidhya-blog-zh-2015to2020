<html>
<head>
<title>Detecting COVID-19 from Chest X-Rays using Attention Maps in Keras/Tensorflow and making a Flask web app out of it.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Keras/Tensorflow中的注意力地图从胸部X射线中检测新冠肺炎，并使用它制作Flask web应用程序。</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/detecting-covid-19-from-chest-x-rays-using-attention-maps-in-keras-tensorflow-and-making-a-flask-a2f68a9ebf65?source=collection_archive---------15-----------------------#2020-03-30">https://medium.com/analytics-vidhya/detecting-covid-19-from-chest-x-rays-using-attention-maps-in-keras-tensorflow-and-making-a-flask-a2f68a9ebf65?source=collection_archive---------15-----------------------#2020-03-30</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/32a4fcecbecc24f55d80fba0ce33ac9b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*IMlv250dyr9h81uX"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">照片由<a class="ae iu" href="https://unsplash.com/@pillepriske?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">皮勒-张力尹·普里斯克</a>在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</figcaption></figure></div><div class="ab cl iv iw gp ix" role="separator"><span class="iy bw bk iz ja jb"/><span class="iy bw bk iz ja jb"/><span class="iy bw bk iz ja"/></div><div class="hb hc hd he hf"><blockquote class="jc jd je"><p id="3d2a" class="jf jg jh ji b jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd hb bi translated">2015年3月，比尔盖茨先生做了一个题为:<a class="ae iu" href="https://www.ted.com/talks/bill_gates_the_next_outbreak_we_re_not_ready/transcript?language=en#t-500745" rel="noopener ugc nofollow" target="_blank">“下一次爆发？我们还没准备好。”</a>。2015年3月18日，他在自己的博客GatesNotes上发表了一篇<a class="ae iu" href="https://africacheck.org/fbcheck/bill-gates-did-warn-in-2015-of-possible-global-virus-outbreak-but-not-coronavirus-specifically/" rel="noopener ugc nofollow" target="_blank">帖子</a>。这篇文章包括了他的TED演讲。他写道，下一次全球疫情可能比2014年至2016年的埃博拉病毒爆发更糟糕，那次爆发导致约11，000人死亡。</p></blockquote><p id="0cd5" class="pw-post-body-paragraph jf jg hi ji b jj jk jl jm jn jo jp jq ke js jt ju kf jw jx jy kg ka kb kc kd hb bi translated">快进5年，我们正在见证一个超越了我们对末日世界的所有想象的世界，让我们面临终极的生存危机。在世界各地，随着死亡人数的增加，封锁正在有序进行，这是人类团结起来的关键时刻。</p><p id="7ca8" class="pw-post-body-paragraph jf jg hi ji b jj jk jl jm jn jo jp jq ke js jt ju kf jw jx jy kg ka kb kc kd hb bi translated">冠状病毒是一个大的病毒家族，可以引起从普通感冒到更严重疾病的疾病。2019年12月下旬，中国发现了一种新毒株的爆发，命名为<a class="ae iu" href="https://www.who.int/emergencies/diseases/novel-coronavirus-2019" rel="noopener ugc nofollow" target="_blank">“2019-nCoV”</a>，被称为“新型冠状病毒”。这种病毒导致了新冠肺炎的疾病。</p><p id="3151" class="pw-post-body-paragraph jf jg hi ji b jj jk jl jm jn jo jp jq ke js jt ju kf jw jx jy kg ka kb kc kd hb bi translated">截至2020年3月28日，全球新冠肺炎确诊病例近65万例，死亡近3.1万人。</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div class="er es kh"><img src="../Images/f2d2bda2691403c0bc4c2935956c456f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1306/format:webp/1*ytPMtk3BvhWiTXEhbKmJqg.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">来源:路透社</figcaption></figure><p id="8b87" class="pw-post-body-paragraph jf jg hi ji b jj jk jl jm jn jo jp jq ke js jt ju kf jw jx jy kg ka kb kc kd hb bi translated">在这一点上，我们可能采取的最佳防御措施是呆在家里，不惜一切代价避免社交聚会。在目前的情况下，社交距离似乎是唯一的出路。然而，随着确诊病例呈指数增长，截至目前，许多国家的医疗机构因患者数量庞大而不堪重负<a class="ae iu" href="https://www.theguardian.com/world/2020/mar/28/coronavirus-vaccine-when-will-it-be-ready" rel="noopener ugc nofollow" target="_blank"> <strong class="ji hj">缺乏治愈方法</strong> </a>。</p><p id="3056" class="pw-post-body-paragraph jf jg hi ji b jj jk jl jm jn jo jp jq ke js jt ju kf jw jx jy kg ka kb kc kd hb bi translated">中国最近开发了一种人工智能头盔，可以测量5米以外人群的体温。</p><figure class="ki kj kk kl fd ij"><div class="bz dy l di"><div class="km kn l"/></div></figure><p id="4b39" class="pw-post-body-paragraph jf jg hi ji b jj jk jl jm jn jo jp jq ke js jt ju kf jw jx jy kg ka kb kc kd hb bi translated">其他基于人工智能的解决方案正在被广泛深入研究和<a class="ae iu" href="https://www.sciencedaily.com/releases/2019/09/190930104505.htm" rel="noopener ugc nofollow" target="_blank">研究</a>。但是，即使这些模型据报道具有很高的灵敏度和特异性，这些模型也不应该在没有人类干预的情况下孤立运行，因为研究表明，在将新冠肺炎病毒与其他类型的病毒疾病进行比较时，这些模型的预测可能非常不稳定。</p><p id="9537" class="pw-post-body-paragraph jf jg hi ji b jj jk jl jm jn jo jp jq ke js jt ju kf jw jx jy kg ka kb kc kd hb bi translated">在本文中，我们将探索实现这样一个过程的方法，并分析所获得的结果。我们将使用一个与视觉注意力机制相结合的转移学习过程，以便深度学习代理只关注图像的一部分，而不是同等重要地看待图像的每一部分。但是首先，我们将讨论视觉注意力是如何工作的，然后我们将直接进入代码<a class="ae iu" href="https://github.com/sagarnildass/covid_19_xray_classification" rel="noopener ugc nofollow" target="_blank">(完整的github报告在这里)</a>。</p><p id="1c76" class="pw-post-body-paragraph jf jg hi ji b jj jk jl jm jn jo jp jq ke js jt ju kf jw jx jy kg ka kb kc kd hb bi translated">该数据集由阿德里安·易捷·许编译。你可以在这里找到他的实现方法<a class="ae iu" href="https://towardsdatascience.com/detecting-covid-19-induced-pneumonia-from-chest-x-rays-with-transfer-learning-an-implementation-311484e6afc1" rel="noopener" target="_blank">。这是蒙特利尔大学的约瑟夫·保罗·寇恩博士收集的</a><a class="ae iu" href="https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia" rel="noopener ugc nofollow" target="_blank"> Kaggle胸部x光数据集</a>和<a class="ae iu" href="https://github.com/ieee8023/covid-chestxray-dataset" rel="noopener ugc nofollow" target="_blank"> COVID19胸部x光数据集</a>的组合。数据集包含4个类别:</p><ol class=""><li id="1564" class="ko kp hi ji b jj jk jn jo ke kq kf kr kg ks kd kt ku kv kw bi translated">COVID19: 60幅训练图像，9幅测试图像</li><li id="d3f2" class="ko kp hi ji b jj kx jn ky ke kz kf la kg lb kd kt ku kv kw bi translated">正常:70幅训练图像，9幅测试图像。</li><li id="87d2" class="ko kp hi ji b jj kx jn ky ke kz kf la kg lb kd kt ku kv kw bi translated">肺炎(细菌性):70幅训练图像，9幅测试图像</li><li id="400d" class="ko kp hi ji b jj kx jn ky ke kz kf la kg lb kd kt ku kv kw bi translated">肺炎(病毒性):70幅训练图像，9幅测试图像</li></ol><p id="91a9" class="pw-post-body-paragraph jf jg hi ji b jj jk jl jm jn jo jp jq ke js jt ju kf jw jx jy kg ka kb kc kd hb bi translated">一些图像样本如下所示:</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lc"><img src="../Images/06d370f77f8c24a8eb34d7487c33d6bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ByuxB2raK9Cbg0STrdHung.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">新冠肺炎（新型冠状病毒肺炎）</figcaption></figure><figure class="ki kj kk kl fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ld"><img src="../Images/e1646c5f8294076cee63caae1376b73f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nPSTSrPWXbrIU5hco0nW3w.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">正常/健康</figcaption></figure><figure class="ki kj kk kl fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es le"><img src="../Images/a55127bb53f33c4830711efcd4399529.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YwaJBuUfM39cEi37iSC79A.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">肺炎</figcaption></figure><p id="7bd8" class="pw-post-body-paragraph jf jg hi ji b jj jk jl jm jn jo jp jq ke js jt ju kf jw jx jy kg ka kb kc kd hb bi translated">这种方法的一个主要问题是在X射线图像中没有太多COVID19的阳性实例。因此，即使可以创建一个具有高测试准确性的模型，它也可能无法很好地推广到现实世界，因为我们根本不知道当我们查看一个被明确识别的患者的x光片时会有多大的差异。但话虽如此，这个模型已经达到了85%的高验证准确率和100%的测试准确率。所以我们只能希望我们走在正确的道路上。那么事不宜迟，我们先来了解一下什么是视觉注意。</p><h1 id="2f5e" class="lf lg hi bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">卷积神经网络中的视觉注意</h1><p id="f5d1" class="pw-post-body-paragraph jf jg hi ji b jj md jl jm jn me jp jq ke mf jt ju kf mg jx jy kg mh kb kc kd hb bi translated">视觉注意力的工作方式与我们的视觉非常相似。让我们考虑一个场景。假设有人告诉你:“嘿，看，有一只老虎！”你转向他/她所指的方向，然后当视觉皮层向你的大脑发送刺激时，首先你把你的整个视野看做一个图像。但是然后你开始聚焦，你开始聚焦在老虎身上，因为你知道它看起来像什么(我必须说，迁移学习的历史很长！).当你把注意力锁定在老虎身上，并开始对它投入注意力时，你的周边视觉变得模糊。</p><p id="2d69" class="pw-post-body-paragraph jf jg hi ji b jj jk jl jm jn jo jp jq ke js jt ju kf jw jx jy kg ka kb kc kd hb bi translated">现在想想吧。为了在你的大脑中识别或处理老虎的形象，你是否一部分一部分地吸收和处理了整个场景？不，你立即知道去哪里看，并锁定你的焦点，直到你的外围设备变得越来越模糊。这是你自己实施视觉注意的部分。神经网络与此并无太大不同。</p><p id="00a6" class="pw-post-body-paragraph jf jg hi ji b jj jk jl jm jn jo jp jq ke js jt ju kf jw jx jy kg ka kb kc kd hb bi translated">我们理解视觉注意的主要参考是这篇论文:“<a class="ae iu" href="https://arxiv.org/pdf/1804.02391.pdf" rel="noopener ugc nofollow" target="_blank">学会注意</a>”。在视觉注意机制中，有两种流行的类型。</p><ol class=""><li id="4dad" class="ko kp hi ji b jj jk jn jo ke kq kf kr kg ks kd kt ku kv kw bi translated"><strong class="ji hj">硬注意</strong>:该方法对感兴趣的区域进行图像裁剪。通常像<a class="ae iu" href="https://towardsdatascience.com/an-intuitive-explanation-of-policy-gradient-part-1-reinforce-aa4392cbfd3c" rel="noopener" target="_blank">加强</a>这样的算法被用来训练严格的注意力机制。硬注意的输出是0或1的二进制值。1对应于像素的保留，0表示该像素已被裁剪掉。</li><li id="785e" class="ko kp hi ji b jj kx jn ky ke kz kf la kg lb kd kt ku kv kw bi translated"><strong class="ji hj">软注意:</strong>软注意使用软阴影来关注区域。输出贴图的值是一个介于0和1之间的十进制数。</li></ol><p id="5b90" class="pw-post-body-paragraph jf jg hi ji b jj jk jl jm jn jo jp jq ke js jt ju kf jw jx jy kg ka kb kc kd hb bi translated">论文<em class="jh">学会注意</em>用软注意解决了一个多类分类问题。作者证明了软可训练注意力在<a class="ae iu" href="https://www.cs.toronto.edu/~kriz/cifar.html" rel="noopener ugc nofollow" target="_blank"> CIFAR-100 </a>上将多类分类的性能提高了7%，他们展示了示例热图，突出显示了注意力如何帮助模型专注于与正确的类标签最相关的图像部分。</p><p id="8a1a" class="pw-post-body-paragraph jf jg hi ji b jj jk jl jm jn jo jp jq ke js jt ju kf jw jx jy kg ka kb kc kd hb bi translated">下图描述了他们的模型架构:</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div class="er es mi"><img src="../Images/94c3bb5f019b8ef2094e8bf09170c35c.png" data-original-src="https://miro.medium.com/v2/resize:fit:984/format:webp/1*72ugJoRjzH7k6UG4-BIbJA.png"/></div></figure><p id="51de" class="pw-post-body-paragraph jf jg hi ji b jj jk jl jm jn jo jp jq ke js jt ju kf jw jx jy kg ka kb kc kd hb bi translated">由<a class="ae iu" href="https://www.kaggle.com/kmader" rel="noopener ugc nofollow" target="_blank"> K. Scott Mader </a>建议的一种更新颖的方法是建立一种注意机制，在汇集之前打开或关闭间隙中的像素，然后根据像素的数量重新调整(Lambda layer)结果。基本想法是，全球平均汇集过于简单，因为一些地区比其他地区更相关。</p><p id="19b1" class="pw-post-body-paragraph jf jg hi ji b jj jk jl jm jn jo jp jq ke js jt ju kf jw jx jy kg ka kb kc kd hb bi translated">在这项工作中，我们将做一些类似的方法来解决X射线分类问题。你可以在这里找到笔记本<a class="ae iu" href="https://github.com/sagarnildass/covid_19_xray_classification/blob/master/2_final_attention_multiclass.ipynb" rel="noopener ugc nofollow" target="_blank"/>。</p><p id="6d54" class="pw-post-body-paragraph jf jg hi ji b jj jk jl jm jn jo jp jq ke js jt ju kf jw jx jy kg ka kb kc kd hb bi translated">让我们写一些代码吧！我们将它细分为两个部分:</p><ol class=""><li id="b30e" class="ko kp hi ji b jj jk jn jo ke kq kf kr kg ks kd kt ku kv kw bi translated">深度学习部分</li><li id="ff48" class="ko kp hi ji b jj kx jn ky ke kz kf la kg lb kd kt ku kv kw bi translated">web应用程序创建部分</li></ol><h1 id="71f6" class="lf lg hi bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">深度学习部分</h1><h2 id="b858" class="mj lg hi bd lh mk ml mm ll mn mo mp lp ke mq mr lt kf ms mt lx kg mu mv mb mw bi translated">a)定义全局参数</h2><figure class="ki kj kk kl fd ij"><div class="bz dy l di"><div class="mx kn l"/></div></figure><p id="1a97" class="pw-post-body-paragraph jf jg hi ji b jj jk jl jm jn jo jp jq ke js jt ju kf jw jx jy kg ka kb kc kd hb bi translated">由于数据集的图像太少，我们将使用图像增强，以便我们的模型不会过度拟合。为此，我们将使用ImageDataGenerator类。</p><h2 id="dc80" class="mj lg hi bd lh mk ml mm ll mn mo mp lp ke mq mr lt kf ms mt lx kg mu mv mb mw bi translated">b)加载数据和扩充</h2><p id="4da2" class="pw-post-body-paragraph jf jg hi ji b jj md jl jm jn me jp jq ke mf jt ju kf mg jx jy kg mh kb kc kd hb bi translated">我们将使用keras中的ImageDataGenerator类来加载和扩充图像。该类创建了内存的扩充，并且图像在驱动器中不会改变。</p><figure class="ki kj kk kl fd ij"><div class="bz dy l di"><div class="mx kn l"/></div></figure><h2 id="a968" class="mj lg hi bd lh mk ml mm ll mn mo mp lp ke mq mr lt kf ms mt lx kg mu mv mb mw bi translated">c)模型架构</h2><p id="895b" class="pw-post-body-paragraph jf jg hi ji b jj md jl jm jn me jp jq ke mf jt ju kf mg jx jy kg mh kb kc kd hb bi translated">现在，我们将创建模型架构，并关注它。我们使用VGG16作为具有“imagenet”权重的预训练模型。在调用该模型时，我们将保持<strong class="ji hj"> include_top </strong>参数为<strong class="ji hj"> False </strong>，因为我们不会包括网络顶部的全连接层。这一层将跟随批量标准化层，批量标准化层是一种用于训练非常深的神经网络的技术，该神经网络对每个小批量的层的输入进行标准化。这具有稳定学习过程和显著减少训练深度网络所需的训练时期的效果。</p><p id="8429" class="pw-post-body-paragraph jf jg hi ji b jj jk jl jm jn jo jp jq ke js jt ju kf jw jx jy kg ka kb kc kd hb bi translated">在模型的注意力部分，我们将使用多个1x1卷积。这是因为我们希望避免大量的特征地图，因此我们希望对它们进行缩减采样。我们建立了一个注意机制，在汇集之前打开或关闭间隙中的像素，然后根据像素的数量重新缩放(Lambda层)结果。该模型可以被视为一种“全球加权平均”池。在最终模型中，我们以线性方式组合了预训练的VGG16模型和注意力模型。下图展示了注意力模型。</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es my"><img src="../Images/198c78d84d8fecf48a6c9aa354c8d0d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B4cdaVKxOhJ3w9keKjef9A.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">注意力模型架构</figcaption></figure><p id="e08d" class="pw-post-body-paragraph jf jg hi ji b jj jk jl jm jn jo jp jq ke js jt ju kf jw jx jy kg ka kb kc kd hb bi translated">这张图展示了最终的模型架构。</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div class="er es mz"><img src="../Images/96e4561600c933ab28f3d9c794cce44d.png" data-original-src="https://miro.medium.com/v2/resize:fit:426/format:webp/1*MLpZmvDahlhIsi2ajax3yA.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">最终模型架构</figcaption></figure><p id="22f4" class="pw-post-body-paragraph jf jg hi ji b jj jk jl jm jn jo jp jq ke js jt ju kf jw jx jy kg ka kb kc kd hb bi translated">创建此架构的代码如下:</p><figure class="ki kj kk kl fd ij"><div class="bz dy l di"><div class="mx kn l"/></div></figure><h2 id="59c3" class="mj lg hi bd lh mk ml mm ll mn mo mp lp ke mq mr lt kf ms mt lx kg mu mv mb mw bi translated">d)回访</h2><p id="2434" class="pw-post-body-paragraph jf jg hi ji b jj md jl jm jn me jp jq ke mf jt ju kf mg jx jy kg mh kb kc kd hb bi translated">对于这个模型，我们将使用两个回调。</p><ol class=""><li id="f53a" class="ko kp hi ji b jj jk jn jo ke kq kf kr kg ks kd kt ku kv kw bi translated"><a class="ae iu" href="https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint" rel="noopener ugc nofollow" target="_blank"> <strong class="ji hj">模型检查点</strong> </a>:随着模型被训练，我们将用最佳权重递归地覆盖同一个文件。稍后我们将需要这个文件来创建web应用程序。</li></ol><p id="559a" class="pw-post-body-paragraph jf jg hi ji b jj jk jl jm jn jo jp jq ke js jt ju kf jw jx jy kg ka kb kc kd hb bi translated">2.<strong class="ji hj"> </strong> <a class="ae iu" href="https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ReduceLROnPlateau" rel="noopener ugc nofollow" target="_blank"> <strong class="ji hj">降低平稳状态下的学习率</strong> </a>:该参数在指标停止提高时降低学习率。这在我们的例子中非常重要，因为我们的图像太少了，我们不想跳过<a class="ae iu" href="https://www.i2tutorials.com/technology/maxima-vs-minima-and-global-vs-local-in-machine-learning/" rel="noopener ugc nofollow" target="_blank">全局最小值而陷入局部最小值</a>。</p><figure class="ki kj kk kl fd ij"><div class="bz dy l di"><div class="mx kn l"/></div></figure><h2 id="5a1c" class="mj lg hi bd lh mk ml mm ll mn mo mp lp ke mq mr lt kf ms mt lx kg mu mv mb mw bi translated">e)拟合模型</h2><p id="07cd" class="pw-post-body-paragraph jf jg hi ji b jj md jl jm jn me jp jq ke mf jt ju kf mg jx jy kg mh kb kc kd hb bi translated">现在我们都准备好训练模型了。</p><figure class="ki kj kk kl fd ij"><div class="bz dy l di"><div class="mx kn l"/></div></figure><p id="2a5d" class="pw-post-body-paragraph jf jg hi ji b jj jk jl jm jn jo jp jq ke js jt ju kf jw jx jy kg ka kb kc kd hb bi translated"><a class="ae iu" href="https://datascience.stackexchange.com/questions/47405/what-to-set-in-steps-per-epoch-in-keras-fit-generator" rel="noopener ugc nofollow" target="_blank"> <strong class="ji hj"> steps_per_epoch </strong>它通常应等于<strong class="ji hj"> ceil(样本数/批量大小)</strong></a></p><h2 id="5b19" class="mj lg hi bd lh mk ml mm ll mn mo mp lp ke mq mr lt kf ms mt lx kg mu mv mb mw bi translated">f)绘制损失函数和精确度</h2><p id="2895" class="pw-post-body-paragraph jf jg hi ji b jj md jl jm jn me jp jq ke mf jt ju kf mg jx jy kg mh kb kc kd hb bi translated">让我们为精确度和损失函数创建一个图。</p><figure class="ki kj kk kl fd ij"><div class="bz dy l di"><div class="mx kn l"/></div></figure><h2 id="2a96" class="mj lg hi bd lh mk ml mm ll mn mo mp lp ke mq mr lt kf ms mt lx kg mu mv mb mw bi translated">g)根据测试数据评估模型，并在一些样本上进行测试</h2><p id="9258" class="pw-post-body-paragraph jf jg hi ji b jj md jl jm jn me jp jq ke mf jt ju kf mg jx jy kg mh kb kc kd hb bi translated">我们将评估测试数据上的模型，并绘制一些图像以及预测的标签和标签的概率。</p><figure class="ki kj kk kl fd ij"><div class="bz dy l di"><div class="mx kn l"/></div></figure><h2 id="2117" class="mj lg hi bd lh mk ml mm ll mn mo mp lp ke mq mr lt kf ms mt lx kg mu mv mb mw bi translated">h)创建主函数并调用它</h2><p id="dce6" class="pw-post-body-paragraph jf jg hi ji b jj md jl jm jn me jp jq ke mf jt ju kf mg jx jy kg mh kb kc kd hb bi translated">让我们在主函数中以适当的顺序调用所有这些函数，然后执行主函数。</p><figure class="ki kj kk kl fd ij"><div class="bz dy l di"><div class="mx kn l"/></div></figure><h2 id="094d" class="mj lg hi bd lh mk ml mm ll mn mo mp lp ke mq mr lt kf ms mt lx kg mu mv mb mw bi translated">I)损失和准确度图</h2><figure class="ki kj kk kl fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es na"><img src="../Images/7f0be0cf6056749aef7049e0e98c71de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7D55Vid_l4_0H_76V8Y53A.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">注意地</figcaption></figure><p id="cb13" class="pw-post-body-paragraph jf jg hi ji b jj jk jl jm jn jo jp jq ke js jt ju kf jw jx jy kg ka kb kc kd hb bi translated">我们看到这些图非常不稳定，但是模型有稳定的改进趋势。改善这些的主要方法之一是获得更多的训练数据。但是尽管如此，我们用这个数据达到了大约85%的验证准确率。</p><p id="6133" class="pw-post-body-paragraph jf jg hi ji b jj jk jl jm jn jo jp jq ke js jt ju kf jw jx jy kg ka kb kc kd hb bi translated">在github repo中，你还会发现一个没有注意的方法。在一些样本测试数据上比较注意和不注意的测试结果:</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nb"><img src="../Images/aa195282c327faad41b5fbc1954154ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gaeLgvdBb0KflOB2cgsTkA.png"/></div></div></figure><p id="4c6d" class="pw-post-body-paragraph jf jg hi ji b jj jk jl jm jn jo jp jq ke js jt ju kf jw jx jy kg ka kb kc kd hb bi translated">咻！那是很长的一段。但这就结束了我们的深度学习部分。现在让我们转到web应用程序开发部分，我们将使用flask创建一个简单的web界面，在该web界面中，我们可以上传一张x光图像，它将在应用程序本身中被分类为[COVID19，普通或三级肺炎]。</p><h1 id="0349" class="lf lg hi bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">Web应用程序创建部分</h1><p id="66e0" class="pw-post-body-paragraph jf jg hi ji b jj md jl jm jn me jp jq ke mf jt ju kf mg jx jy kg mh kb kc kd hb bi translated">对于web应用程序创建部分，我使用了<a class="ae iu" href="https://github.com/mtobeiyf/keras-flask-deploy-webapp" rel="noopener ugc nofollow" target="_blank">keras-flask-deploy-web app</a>repo。但是，您需要对代码进行一些重要的修改，以使其适用于这种情况。所以我会一步一步地告诉你怎么做。</p><ol class=""><li id="2bb4" class="ko kp hi ji b jj jk jn jo ke kq kf kr kg ks kd kt ku kv kw bi translated">克隆回购:</li></ol><pre class="ki kj kk kl fd nc nd ne nf aw ng bi"><span id="2303" class="mj lg hi nd b fi nh ni l nj nk">git clone <a class="ae iu" href="https://github.com/mtobeiyf/keras-flask-deploy-webapp" rel="noopener ugc nofollow" target="_blank">https://github.com/mtobeiyf/keras-flask-deploy-webapp</a></span></pre><p id="3049" class="pw-post-body-paragraph jf jg hi ji b jj jk jl jm jn jo jp jq ke js jt ju kf jw jx jy kg ka kb kc kd hb bi translated">2.更改目录</p><pre class="ki kj kk kl fd nc nd ne nf aw ng bi"><span id="5a6c" class="mj lg hi nd b fi nh ni l nj nk">cd keras-flask-deploy-webapp</span></pre><p id="c10e" class="pw-post-body-paragraph jf jg hi ji b jj jk jl jm jn jo jp jq ke js jt ju kf jw jx jy kg ka kb kc kd hb bi translated">3.安装要求</p><pre class="ki kj kk kl fd nc nd ne nf aw ng bi"><span id="c2f8" class="mj lg hi nd b fi nh ni l nj nk">pip install -r requirements.txt</span></pre><p id="f370" class="pw-post-body-paragraph jf jg hi ji b jj jk jl jm jn jo jp jq ke js jt ju kf jw jx jy kg ka kb kc kd hb bi translated">4.将您的模型(h5文件)复制并粘贴到keras-flask-deploy-webapp内的models目录中。这不仅是模型权重，也是模型架构。这就是为什么如果你使用上面的回调函数，你会发现我们设置了save_weights_only = False来保存整个模型，而不仅仅是权重。</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nl"><img src="../Images/1d9e7cbd857481c60bed91901326f9c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WVyEEJ9DKPm8zGNR6s2rnQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">模型文件夹(突出显示)</figcaption></figure><p id="dee2" class="pw-post-body-paragraph jf jg hi ji b jj jk jl jm jn jo jp jq ke js jt ju kf jw jx jy kg ka kb kc kd hb bi translated">5.打开app.py文件。在这里你必须做一些改变。</p><p id="c7f2" class="pw-post-body-paragraph jf jg hi ji b jj jk jl jm jn jo jp jq ke js jt ju kf jw jx jy kg ka kb kc kd hb bi translated">a)在顶部导入行中，更改行</p><pre class="ki kj kk kl fd nc nd ne nf aw ng bi"><span id="e21d" class="mj lg hi nd b fi nh ni l nj nk">from tensorflow.keras.applications.imagenet_utils import preprocess_input, decode_predictions</span></pre><p id="cf57" class="pw-post-body-paragraph jf jg hi ji b jj jk jl jm jn jo jp jq ke js jt ju kf jw jx jy kg ka kb kc kd hb bi translated">无论你用的是哪种型号。所以如果你用的是VGG16，那么应该是</p><pre class="ki kj kk kl fd nc nd ne nf aw ng bi"><span id="6360" class="mj lg hi nd b fi nh ni l nj nk">from keras.applications.vgg16 import preprocess_input</span></pre><p id="d866" class="pw-post-body-paragraph jf jg hi ji b jj jk jl jm jn jo jp jq ke js jt ju kf jw jx jy kg ka kb kc kd hb bi translated">另外，请注意，我在导入语句中去掉了<strong class="ji hj"> decode_predictions </strong>方法。这是因为只有在对Imagenet数据进行分类以使标签成为人类可读形式时，才会使用此语句。但既然我们不是，我们就不需要这个了。</p><p id="562f" class="pw-post-body-paragraph jf jg hi ji b jj jk jl jm jn jo jp jq ke js jt ju kf jw jx jy kg ka kb kc kd hb bi translated">b)接下来，注释掉这两行:</p><pre class="ki kj kk kl fd nc nd ne nf aw ng bi"><span id="a264" class="mj lg hi nd b fi nh ni l nj nk">#from keras.applications.mobilenet_v2 import MobileNetV2<br/>#model = MobileNetV2(weights='imagenet')<br/></span></pre><p id="9e5c" class="pw-post-body-paragraph jf jg hi ji b jj jk jl jm jn jo jp jq ke js jt ju kf jw jx jy kg ka kb kc kd hb bi translated">因为我们将使用自己的模型，所以不需要这两行。</p><p id="50d2" class="pw-post-body-paragraph jf jg hi ji b jj jk jl jm jn jo jp jq ke js jt ju kf jw jx jy kg ka kb kc kd hb bi translated">c)在<strong class="ji hj">模型路径</strong>参数中，指定您在步骤4中保存在模型文件夹中的模型名称。例如</p><pre class="ki kj kk kl fd nc nd ne nf aw ng bi"><span id="0c92" class="mj lg hi nd b fi nh ni l nj nk">MODEL_PATH = 'models/covid_attn_weights_best_vgg16.h5'</span></pre><p id="b6a4" class="pw-post-body-paragraph jf jg hi ji b jj jk jl jm jn jo jp jq ke js jt ju kf jw jx jy kg ka kb kc kd hb bi translated">d)在接下来的两行中添加注释，即</p><pre class="ki kj kk kl fd nc nd ne nf aw ng bi"><span id="916d" class="mj lg hi nd b fi nh ni l nj nk">model = load_model(MODEL_PATH)<br/>model._make_predict_function()</span></pre><p id="ee1c" class="pw-post-body-paragraph jf jg hi ji b jj jk jl jm jn jo jp jq ke js jt ju kf jw jx jy kg ka kb kc kd hb bi translated">e)在<strong class="ji hj"> model_predict </strong>函数中，将图像大小更改为150，150，因为这是我们使用的图像大小。</p><pre class="ki kj kk kl fd nc nd ne nf aw ng bi"><span id="0832" class="mj lg hi nd b fi nh ni l nj nk">img = img.resize((150, 150))</span></pre><p id="3d54" class="pw-post-body-paragraph jf jg hi ji b jj jk jl jm jn jo jp jq ke js jt ju kf jw jx jy kg ka kb kc kd hb bi translated">e)在<strong class="ji hj">预测</strong>函数中，去掉这两行:</p><pre class="ki kj kk kl fd nc nd ne nf aw ng bi"><span id="c09e" class="mj lg hi nd b fi nh ni l nj nk">pred_class = decode_predictions(preds, top=1)   # ImageNet Decode         result = str(pred_class[0][0][1])               # Convert to string<br/></span></pre><p id="3ded" class="pw-post-body-paragraph jf jg hi ji b jj jk jl jm jn jo jp jq ke js jt ju kf jw jx jy kg ka kb kc kd hb bi translated">改为添加以下几行:</p><pre class="ki kj kk kl fd nc nd ne nf aw ng bi"><span id="1abf" class="mj lg hi nd b fi nh ni l nj nk">pred_class = np.argmax(preds)<br/>        # Process your result for human<br/>pred_proba = "{:.3f}".format(np.amax(preds))    # Max probability<br/>        <br/>print(pred_class)<br/>if pred_class == 0:<br/>    result = 'COVID19'<br/>elif pred_class == 1:<br/>    result = 'NORMAL'<br/>elif pred_class == 2:<br/>    result = 'TERTIARY PNEUMONIA'</span></pre><p id="9555" class="pw-post-body-paragraph jf jg hi ji b jj jk jl jm jn jo jp jq ke js jt ju kf jw jx jy kg ka kb kc kd hb bi translated">因此，<strong class="ji hj"> model_predict </strong>函数现在看起来像这样:</p><figure class="ki kj kk kl fd ij"><div class="bz dy l di"><div class="mx kn l"/></div></figure><p id="16a5" class="pw-post-body-paragraph jf jg hi ji b jj jk jl jm jn jo jp jq ke js jt ju kf jw jx jy kg ka kb kc kd hb bi translated"><strong class="ji hj">预测</strong>函数如下所示:</p><figure class="ki kj kk kl fd ij"><div class="bz dy l di"><div class="mx kn l"/></div></figure><p id="c897" class="pw-post-body-paragraph jf jg hi ji b jj jk jl jm jn jo jp jq ke js jt ju kf jw jx jy kg ka kb kc kd hb bi translated">6.正在更改utils.py —差不多了。现在，这对于web应用程序的运行来说已经足够好了。但是我们需要解决最后一个警告。当你在网络应用程序中上传一张图片时，它会以<strong class="ji hj"> base64 </strong>编码数据的形式进入我们的应用程序。我们用一个名为<strong class="ji hj"> base64_to_pil </strong>的函数将它转换成<a class="ae iu" href="https://pillow.readthedocs.io/en/stable/reference/Image.html" rel="noopener ugc nofollow" target="_blank"> PIL图像</a>格式，这个函数驻留在我们的<strong class="ji hj"> utils.py </strong>文件中，以便我们用keras和opencv读取和预处理它。现在，我不知道这是一个怎样的常识，但由于我对VFX工业有些了解，我知道这是一个事实。JPG和PNG文件在一个方面有所不同。PNG文件除了通常的R、G、B通道之外，还有一个额外的通道。这个通道被称为阿尔法通道。在我们的数据集中，我们有Jpeg和Png文件。因此，当你上传一个PNG文件时出现的问题是，因为它包含一个额外的通道，解码图像的形状变成(150x150x4)而不是(150x150x3)，这将产生一个错误。所以解决这个问题的最好方法就是创建一个逻辑，如果image.mode不是<strong class="ji hj"> RGB </strong>，那么就使它成为<strong class="ji hj"> RGB </strong>。</p><p id="2fb7" class="pw-post-body-paragraph jf jg hi ji b jj jk jl jm jn jo jp jq ke js jt ju kf jw jx jy kg ka kb kc kd hb bi translated">所以转到utils.py，重写函数<strong class="ji hj"> base64_to_pil </strong>如下:</p><figure class="ki kj kk kl fd ij"><div class="bz dy l di"><div class="mx kn l"/></div></figure><p id="d718" class="pw-post-body-paragraph jf jg hi ji b jj jk jl jm jn jo jp jq ke js jt ju kf jw jx jy kg ka kb kc kd hb bi translated">现在打开命令终端并运行</p><pre class="ki kj kk kl fd nc nd ne nf aw ng bi"><span id="ad04" class="mj lg hi nd b fi nh ni l nj nk">python app.py<br/></span></pre><p id="e83a" class="pw-post-body-paragraph jf jg hi ji b jj jk jl jm jn jo jp jq ke js jt ju kf jw jx jy kg ka kb kc kd hb bi translated">转到<a class="ae iu" href="http://127.0.0.1:5000/" rel="noopener ugc nofollow" target="_blank"> http://127.0.0.1:5000/ </a>一切应该正常。:)</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nm"><img src="../Images/bf154acd8570b48c6c947cd4976981c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kcoW79tpcEmAMRAvjnVgOA.png"/></div></div></figure><p id="1065" class="pw-post-body-paragraph jf jg hi ji b jj jk jl jm jn jo jp jq ke js jt ju kf jw jx jy kg ka kb kc kd hb bi translated">7.上传一张图片，看看你的模型是如何分类的。</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nn"><img src="../Images/d0fe0e6a754008480e5290ec5c4fa3b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zWme36xF1KW_Rw7kITJRhw.png"/></div></div></figure><h1 id="8ef6" class="lf lg hi bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">结束注释</h1><p id="20fb" class="pw-post-body-paragraph jf jg hi ji b jj md jl jm jn me jp jq ke mf jt ju kf mg jx jy kg mh kb kc kd hb bi translated">希望这篇文章对你有所帮助。这种方法的主要问题是没有足够的数据。但最有可能的是，我们将在未来几天获得更多的数据，这将有助于我们以我们的方式帮助人类，无论它可能是多么微小。在这个黑暗的时代，我们每个人都需要通力合作。</p><p id="2f7b" class="pw-post-body-paragraph jf jg hi ji b jj jk jl jm jn jo jp jq ke js jt ju kf jw jx jy kg ka kb kc kd hb bi translated">恐惧是当今时代可能发生的最糟糕的事情。对更多人被感染的恐惧，对基本生存需求枯竭的恐惧，以及对我们明天命运的恐惧？在这些时候，我觉得也许这就是我如何为减轻和消灭这个本世纪以来最大的流行病贡献自己的一份力量。如果您认为您可以添加到这个数据集或改进我的程序，请派生这个<a class="ae iu" href="https://github.com/sagarnildass/covid_19_xray_classification" rel="noopener ugc nofollow" target="_blank"> repo </a>并提交，然后提出一个拉取请求。如果你认为，你认识的某个医学领域的人可以从中获得帮助，请让我知道，或者如果你可以的话，按照要求为他/她的利益执行这个模型。这可以是一个非常好的健全检查，因为这将在微秒内预测，特别是当时间是如此的本质。</p><p id="1e12" class="pw-post-body-paragraph jf jg hi ji b jj jk jl jm jn jo jp jq ke js jt ju kf jw jx jy kg ka kb kc kd hb bi translated">最重要的是，我们必须满怀希望，共同度过难关。正如他们所说:“黎明前的夜晚是最黑暗的。”</p><p id="b03e" class="pw-post-body-paragraph jf jg hi ji b jj jk jl jm jn jo jp jq ke js jt ju kf jw jx jy kg ka kb kc kd hb bi translated">你并不孤单…</p><h1 id="915c" class="lf lg hi bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">参考</h1><ol class=""><li id="059b" class="ko kp hi ji b jj md jn me ke no kf np kg nq kd kt ku kv kw bi translated"><a class="ae iu" href="https://healthcare-in-europe.com/en/news/imaging-the-coronavirus-disease-covid-19.html" rel="noopener ugc nofollow" target="_blank">https://health care-in-Europe . com/en/news/imaging-the-coronavirus-disease-covid-19 . html</a></li><li id="4dd8" class="ko kp hi ji b jj kx jn ky ke kz kf la kg lb kd kt ku kv kw bi translated"><a class="ae iu" href="https://towardsdatascience.com/detecting-covid-19-induced-pneumonia-from-chest-x-rays-with-transfer-learning-an-implementation-311484e6afc1" rel="noopener" target="_blank">https://towards data science . com/detecting-新冠肺炎诱发的肺炎-从胸部x光检查-转移-学习-实施-311484e6afc1 </a></li><li id="0080" class="ko kp hi ji b jj kx jn ky ke kz kf la kg lb kd kt ku kv kw bi translated"><a class="ae iu" href="https://arxiv.org/pdf/1804.02391.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1804.02391.pdf</a></li><li id="106c" class="ko kp hi ji b jj kx jn ky ke kz kf la kg lb kd kt ku kv kw bi translated"><a class="ae iu" href="https://www.kaggle.com/kmader/attention-on-pretrained-vgg16-for-bone-age" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/kmader</a></li></ol></div></div>    
</body>
</html>