<html>
<head>
<title>A Newbie’s Chronicles on Distributed Data Processing — S01E01: Pilot</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">分布式数据处理新手编年史—第一季第1集:试点</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/a-newbies-chronicles-on-distributed-data-processing-s01e01-pilot-5c76fb052db5?source=collection_archive---------22-----------------------#2020-09-06">https://medium.com/analytics-vidhya/a-newbies-chronicles-on-distributed-data-processing-s01e01-pilot-5c76fb052db5?source=collection_archive---------22-----------------------#2020-09-06</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="d355" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">作为一个刚刚从大学毕业并加入Intuit数据工程组织的人，获得分布式系统和相关技术栈的实践经验是一种特权。虽然我以前尝试过多个领域和开源项目，但是这个领域我还没有涉足太多。</p><p id="4828" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我最近开发了一项新功能，通过这项功能，我学到了很多理论和实际的用例，并伴随着激烈的咆哮！我将试着在这一系列文章中结合我的学习和经历，希望这是一篇有趣且引人入胜的文章。</p></div><div class="ab cl jd je gp jf" role="separator"><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji"/></div><div class="hb hc hd he hf"><h1 id="9a6e" class="jk jl hi bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated"><strong class="ak">更多一点的上下文……</strong></h1><p id="6f73" class="pw-post-body-paragraph if ig hi ih b ii ki ik il im kj io ip iq kk is it iu kl iw ix iy km ja jb jc hb bi translated">分布式数据处理是指在分布式连接节点集群上处理数据。通常，数据非常庞大，分布式体系结构确保我们可以通过改进节点群集(节点数量、其内存、内核等)来相应地扩展不断增长的数据量。</p><figure class="ko kp kq kr fd ks er es paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="er es kn"><img src="../Images/fe2530ed28bfef792cd54b3b33d28cea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9FQV-iJfPJJ08bvVrNy8UA.jpeg"/></div></div><figcaption class="kz la et er es lb lc bd b be z dx translated">多影克隆忍术:火影忍者版本的分布式架构。主火影忍者(名字节点)控制克隆体，每个克隆体(数据节点)做委托的任务！</figcaption></figure><p id="a54e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了支持这样的用例，我们需要一个合适的技术堆栈，这是众所周知的堆栈之一:</p><ul class=""><li id="996f" class="ld le hi ih b ii ij im in iq lf iu lg iy lh jc li lj lk ll bi translated"><strong class="ih hj"> Spark </strong> —提交分布式作业</li><li id="a053" class="ld le hi ih b ii lm im ln iq lo iu lp iy lq jc li lj lk ll bi translated"><strong class="ih hj">Scala</strong>——执行spark查询(这可以用其他Spark支持的语言来代替，比如Python、Java或R)</li><li id="4ab0" class="ld le hi ih b ii lm im ln iq lo iu lp iy lq jc li lj lk ll bi translated"><strong class="ih hj"> Hadoop </strong> —利用分布式处理的工具，如Hadoop文件系统(HDFS)、资源分配和管理(YARN)等</li><li id="5aa3" class="ld le hi ih b ii lm im ln iq lo iu lp iy lq jc li lj lk ll bi translated"><strong class="ih hj"> Hive </strong> —读取、操作和存储分布式数据仓库中的数据</li></ul><p id="f2d5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">还有更多组件，如Kafka、ZooKeeper等，它们一起完成了分布式数据架构的图景。然而，这可能会有点令人困惑——所以让我们先从这些组件开始。</p></div><div class="ab cl jd je gp jf" role="separator"><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji"/></div><div class="hb hc hd he hf"><h1 id="013a" class="jk jl hi bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">所需的能力</h1><p id="8a86" class="pw-post-body-paragraph if ig hi ih b ii ki ik il im kj io ip iq kk is it iu kl iw ix iy km ja jb jc hb bi translated">现在，让我解释一下我们需要的功能和最近增加的支持。作为数据工程组织，我们在拥有现成可消费数据的源团队和希望对如此大规模的数据运行高性能查询以获得洞察力的分析师之间充当桥梁。</p><p id="92ad" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这种特殊的情况下，我们必须每天从源团队支持大约16TB的增量数据，并在第二天提供给分析师。为了给出一个更好的画面，让我们说我们的源团队(比如说，尼克·弗瑞)有复仇者联盟的数据——分析师(比如说，神盾局的科学家)想从中获得洞见。</p><p id="db11" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们的一个hive表中有一些现有数据，我们每天都在接收增量数据——我们需要将这些增量数据合并到我们的hive中。可能是这样的:</p><figure class="ko kp kq kr fd ks"><div class="bz dy l di"><div class="lr ls l"/></div><figcaption class="kz la et er es lb lc bd b be z dx translated">历史数据——“最初的复仇者联盟”。唷，好时光！</figcaption></figure><p id="1d9a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">和流入的增量事件，看起来像这样:</p><ul class=""><li id="b017" class="ld le hi ih b ii ij im in iq lf iu lg iy lh jc li lj lk ll bi translated"><strong class="ih hj">更新</strong> —即更新+插入</li></ul><figure class="ko kp kq kr fd ks"><div class="bz dy l di"><div class="lr ls l"/></div><figcaption class="kz la et er es lb lc bd b be z dx translated">增量更新+插入—直到“复仇者联盟4：终局之战”:)</figcaption></figure><ul class=""><li id="d6d4" class="ld le hi ih b ii ij im in iq lf iu lg iy lh jc li lj lk ll bi translated"><strong class="ih hj">删除</strong>:</li></ul><figure class="ko kp kq kr fd ks"><div class="bz dy l di"><div class="lr ls l"/></div><figcaption class="kz la et er es lb lc bd b be z dx translated">增量删除—也是由于“复仇者联盟4：终局之战”(sob)</figcaption></figure><p id="11ba" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">预期的结果？</strong>将增量数据与现有历史数据合并后，我们需要将这些物化数据存储回同一个Hive表中:</p><figure class="ko kp kq kr fd ks"><div class="bz dy l di"><div class="lr ls l"/></div><figcaption class="kz la et er es lb lc bd b be z dx translated">在应用插入/更新/删除之后，即在“复仇者联盟4：终局之战”结束之后，最终的物化数据。也成为下次合并的历史数据！</figcaption></figure><p id="51d6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当然，确切的顺序并不重要——因为Hive中没有主键的概念，在我们的处理过程中数据可能会被打乱。然而，最终数据的精确快照需要逐行匹配。</p><p id="b3d8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这种能力的主要限制不是合并本身，而是使它能够适应如此巨大的数据量:<strong class="ih hj">~ 16TB/天</strong>！</p></div><div class="ab cl jd je gp jf" role="separator"><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji"/></div><div class="hb hc hd he hf"><h1 id="b99d" class="jk jl hi bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated"><strong class="ak">犯罪的伙伴:星火ft。Scala </strong></h1><p id="b7ea" class="pw-post-body-paragraph if ig hi ih b ii ki ik il im kj io ip iq kk is it iu kl iw ix iy km ja jb jc hb bi translated">我们的大部分工作都依赖于Spark &amp; Scala。在任何spark处理工作中，人们通常使用3种最基本的对象类型:</p><ul class=""><li id="0443" class="ld le hi ih b ii ij im in iq lf iu lg iy lh jc li lj lk ll bi translated"><strong class="ih hj"> RDD </strong>(弹性分布式数据集)——不可变的数据块，没有模式属性</li><li id="97fb" class="ld le hi ih b ii lm im ln iq lo iu lp iy lq jc li lj lk ll bi translated"><strong class="ih hj"> DataFrame </strong> —不可变的数据块，但是通过列将一些模式归属于它</li><li id="9752" class="ld le hi ih b ii lm im ln iq lo iu lp iy lq jc li lj lk ll bi translated"><strong class="ih hj">数据集</strong> —同样是不可变的数据块，但通常是强类型的</li></ul><p id="b9a4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我来自一个集中处理的背景，熟悉Python3 Pandas的数据帧，我以为我理解Spark数据帧是如何工作的——但是我大错特错了！🙃</p><p id="0a51" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Spark数据帧的核心功能非常不同，因为它们分布在一个节点集群中。结果没有“<em class="lt">索引</em>的概念，所有Spark交互默认为“<em class="lt">懒</em>”。也就是说，直到一个“<em class="lt">动作</em>开始，它们才被执行。</p><p id="c245" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">例如，让我们看看这个:</p><figure class="ko kp kq kr fd ks"><div class="bz dy l di"><div class="lr ls l"/></div><figcaption class="kz la et er es lb lc bd b be z dx translated">错误调试Spark作业的101种方法——欢迎来到我的Ted演讲！</figcaption></figure><p id="fca5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果您像我一样来自同步编程背景，您可能会犯错误，试图解释记录的时间戳，并根据时间差对步骤进行基准测试。如果是熊猫数据帧的Python3代码，你就对了。<strong class="ih hj"> <em class="lt">但是不对，这里不一样。</em>T25】</strong></p><figure class="ko kp kq kr fd ks er es paragraph-image"><div class="er es lu"><img src="../Images/12f04cafcee887254bc7adcbd9ec485b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1080/format:webp/1*hnqNT51mNn1MOCV8Fb9frw.png"/></div></figure><p id="6789" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果您尝试在spark-shell中运行类似的东西，您会更愿意查看时间戳之间的差异，并(不正确地)推断:</p><ul class=""><li id="bdc3" class="ld le hi ih b ii ij im in iq lf iu lg iy lh jc li lj lk ll bi translated">从Hive读取现有数据几乎是即时的</li><li id="0a1a" class="ld le hi ih b ii lm im ln iq lo iu lp iy lq jc li lj lk ll bi translated">从json读取增量数据几乎不需要时间</li><li id="5934" class="ld le hi ih b ii lm im ln iq lo iu lp iy lq jc li lj lk ll bi translated">联盟也很快！😮</li></ul><figure class="ko kp kq kr fd ks er es paragraph-image"><div class="er es lv"><img src="../Images/66fbc415ed959f2a906e76772c934a76.png" data-original-src="https://miro.medium.com/v2/resize:fit:712/format:webp/1*3WYfen32I0qKax-VJG4Fbg.jpeg"/></div><figcaption class="kz la et er es lb lc bd b be z dx translated">前三步执行得相当快，不是吗？</figcaption></figure><ul class=""><li id="9693" class="ld le hi ih b ii ij im in iq lf iu lg iy lh jc li lj lk ll bi translated">酪酪为什么。为什么<em class="lt"> count() </em>运算要花很多时间？如果使用节点集群，应该会花费更少的时间！</li></ul><figure class="ko kp kq kr fd ks er es paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="er es lw"><img src="../Images/39eb2073fb9aa220e9a4559457b918b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q3RrPHorvcFfeayTjxS64g.jpeg"/></div></div><figcaption class="kz la et er es lb lc bd b be z dx translated">当count()仍在执行时，重新评估人生决策</figcaption></figure><p id="8c51" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">是的，那是真的——只是我们还没有理解Spark的神秘工作方式。因此，Spark会根据我们的代码准备一个逻辑执行计划。所有的"<em class="lt">懒惰的</em>"部分从我们的代码中不断堆积，只有在遇到"<em class="lt">动作</em>时才会在我们的集群上执行。</p><p id="a111" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在我们的例子中，<em class="lt">动作</em>是<em class="lt">计数()</em>操作。在后台，所有的步骤如读取hive数据、读取增量数据、执行join/union；我们本质上都是懒惰的，只是不停地堆积。只有在遇到<em class="lt"> count() </em>操作时，所有这些步骤才会基于Catalyst的逻辑执行计划实际执行。</p><p id="67b2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这就是我们误解结果的原因——实际上，执行上述所有步骤是为了给出最终的时间戳差异；而不仅仅是<em class="lt"> count() </em>操作。如果你是一个新手，这是一个让你感到惊讶的提示。😉</p><figure class="ko kp kq kr fd ks er es paragraph-image"><div class="er es lx"><img src="../Images/0258bcdf501210c9d3bbb773f89719f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:440/1*GsxRnguq_7MfSiW189Gtpg.gif"/></div><figcaption class="kz la et er es lb lc bd b be z dx translated">那个痛苦而缓慢地实现的时刻</figcaption></figure></div><div class="ab cl jd je gp jf" role="separator"><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji"/></div><div class="hb hc hd he hf"><p id="f979" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">记住这些微小的细节，让我们进一步进入下一集第一季第二集，看看我们是如何构建POC并进行优化的。</p></div></div>    
</body>
</html>