<html>
<head>
<title>Image classification: A comparison of DNN, CNN and Transfer Learning approach</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">图像分类:DNN、CNN和迁移学习方法的比较</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/image-classification-a-comparison-of-dnn-cnn-and-transfer-learning-approach-704535beca25?source=collection_archive---------2-----------------------#2019-08-30">https://medium.com/analytics-vidhya/image-classification-a-comparison-of-dnn-cnn-and-transfer-learning-approach-704535beca25?source=collection_archive---------2-----------------------#2019-08-30</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/></div><div class="ab cl if ig gp ih" role="separator"><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik il"/><span class="ii bw bk ij ik"/></div><div class="hb hc hd he hf"><p id="d1f3" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">图像分类是深度学习模型非常成功地应用于实际应用的领域之一。这是一个活跃的研究领域。已经提出了许多方法，还有更多的方法正在涌现。最成功的深度学习模型，如ImageNet、GoogleNet，其性能比人类更好，它们都是非常庞大和复杂的模型。</p><p id="73b7" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">因此，作为初学者，您可能会发现很难在合理的时间内得到一个具有可接受性能的工作模型。在这篇文章中，我将尝试介绍一些基本的架构，我们可以设计来执行图像分类。在这个过程中，我将分享相关的代码样本和一些描述这些模型性能的指标。最终引入一个在合理时间内训练好并给出可接受性能的模型。</p><p id="262a" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我的设置的主要组件包括:</p><ol class=""><li id="beac" class="jk jl hi io b ip iq it iu ix jm jb jn jf jo jj jp jq jr js bi translated">数据集:来自Kaggle的猫和狗的数据集。识别图像中的猫是深度学习的经典问题。所以，这个数据集提供了一个很好的起点。它有8000个训练图像，每只猫和狗有4000个图像，以及2000个测试图像，每只猫和狗有1000个图像。</li><li id="f5c5" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj jp jq jr js bi translated">框架:Tensorflow 2.0.0和Keras，Keras现在包含在Tensorflow 2.0中，所以可能不需要单独导入。<a class="ae jy" href="https://www.tensorflow.org/beta" rel="noopener ugc nofollow" target="_blank">https://www.tensorflow.org/beta</a></li><li id="c393" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj jp jq jr js bi translated">电脑配置:Ubuntu 18.04.3 LTS，内存:13 GB，处理器:英特尔酷睿i5–6402 p CPU @ 2.80 GHz×4</li></ol><p id="8d01" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">进行这些实验的PC是一台配置一般的PC，没有任何支持DNN模型执行的GPU。目标是用这种配置实现合理的运行时间和性能。</p><h1 id="4838" class="jz ka hi bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">模型1:深度神经网络(DNN)</h1><p id="bb4b" class="pw-post-body-paragraph im in hi io b ip kx ir is it ky iv iw ix kz iz ja jb la jd je jf lb jh ji jj hb bi translated">作为第一个模型，讨论了深度神经网络(DNN)模型。我们可以成功地训练一个简单的神经网络来执行回归和分类。但是，DNN可能无法很好地处理图像。下图描述了使用DNN的实施概要。</p><figure class="ld le lf lg fd lh er es paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="er es lc"><img src="../Images/df786c7600e2fd8f549dc5a2c98aadc5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*29kriitcKI6M-wxtkV0NpQ.jpeg"/></div></div><figcaption class="lo lp et er es lq lr bd b be z dx translated">基于深度神经网络模型的图像分类</figcaption></figure><p id="fea1" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">为该实验设计的模型具有以下定义:</p><blockquote class="ls lt lu"><p id="35c9" class="im in lv io b ip iq ir is it iu iv iw lw iy iz ja lx jc jd je ly jg jh ji jj hb bi translated">model = Sequential()<br/><br/>model . add(Flatten(input _ shape = input _ shape))<br/>model . add(Dense(128))<br/>model . add(Activation(' relu '))<br/>model . add(Dropout(0.5))<br/>model . add(Dense(64))<br/>model . add(Activation(' relu '))<br/>model . add(Dropout(0.5))<br/>model . add(Dense(1))<br/>model . add(Activation(')。</p></blockquote><p id="6ad7" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">为了减少训练时间，我将输入图像的大小调整为64x64，因此，输入形状为64x64x3。第一层将此输入展平为1D张量，然后馈送给密集层。</p><h2 id="9584" class="lz ka hi bd kb ma mb mc kf md me mf kj ix mg mh kn jb mi mj kr jf mk ml kv mm bi translated">结果</h2><p id="a606" class="pw-post-body-paragraph im in hi io b ip kx ir is it ky iv iw ix kz iz ja jb la jd je jf lb jh ji jj hb bi translated">训练时间:6.3小时，损耗:7.7450 —准确度:0.4996—val _ loss:7.7479—val _准确度:0.5038</p><p id="ff6a" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">模型的准确性很差，我们可以通过以下方式提高DNN的性能</p><ol class=""><li id="e72f" class="jk jl hi io b ip iq it iu ix jm jb jn jf jo jj jp jq jr js bi translated">添加更多层</li><li id="d186" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj jp jq jr js bi translated">尝试不同的优化函数/正则化函数等。</li><li id="1715" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj jp jq jr js bi translated">不断增加的时代数量</li><li id="9cd9" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj jp jq jr js bi translated">不断增长的数据量</li></ol><p id="b5ed" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">但是，我们不会在这里深入探讨。相反，我们将采用另一种模型:卷积神经网络。</p><h1 id="e1e7" class="jz ka hi bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">模型2:卷积神经网络</h1><p id="45ed" class="pw-post-body-paragraph im in hi io b ip kx ir is it ky iv iw ix kz iz ja jb la jd je jf lb jh ji jj hb bi translated">卷积层已经被证明在涉及图像的任务中非常成功，例如图像分类、对象识别、人脸识别等。它们允许参数共享，与使用密集层相比，这产生了非常优化的网络。以下是理解卷积神经网络的一个很好的来源:<a class="ae jy" href="http://cs231n.github.io/convolutional-networks/" rel="noopener ugc nofollow" target="_blank">http://cs231n.github.io/convolutional-networks/</a></p><figure class="ld le lf lg fd lh er es paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="er es lc"><img src="../Images/cddb0867892c35ddf23aa713cc1e06cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1YGLNeWWyEsA9NpNK6Y0UA.jpeg"/></div></div><figcaption class="lo lp et er es lq lr bd b be z dx translated">基于CNN的图像分类</figcaption></figure><p id="5b41" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">为该实验设计的CNN模型具有以下定义:</p><blockquote class="ls lt lu"><p id="8314" class="im in lv io b ip iq ir is it iu iv iw lw iy iz ja lx jc jd je ly jg jh ji jj hb bi translated">model = Sequential()<br/><br/>model . add(Conv2D(32，(3，3)，input _ shape = input _ shape))<br/>model . add(Activation(' relu ')<br/>model . add(MaxPooling2D(pool _ size =(2，2)))<br/><br/>model . add(Conv2D(32，(3，3)))<br/>model . add(Activation(' relu ')<br/>model . add(maxpooling 2d(pool _ size =(2，2))。</p></blockquote><h2 id="aadd" class="lz ka hi bd kb ma mb mc kf md me mf kj ix mg mh kn jb mi mj kr jf mk ml kv mm bi translated">结果:</h2><p id="87ac" class="pw-post-body-paragraph im in hi io b ip kx ir is it ky iv iw ix kz iz ja jb la jd je jf lb jh ji jj hb bi translated">训练时间:5.4小时，损耗:0.0546，val_loss: 3.2969</p><p id="4f41" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">结果表明，CNN在处理图像时表现得更好。我们已经减少了近1小时的训练时间。训练损失非常优化，但验证损失仍然有点高，这表明过度拟合。我们可以进一步调整我们的模型，以减少过度拟合，或者我们可以使用DNN部分建议的任何方法来提高我们的模型性能。但是，同样这不是我们在这里要做的，相反，我们将直接转到我们将在这里使用的最后一种方法。</p><h1 id="17bc" class="jz ka hi bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">模式3:迁移学习</h1><p id="e855" class="pw-post-body-paragraph im in hi io b ip kx ir is it ky iv iw ix kz iz ja jb la jd je jf lb jh ji jj hb bi translated">迁移学习是一种重用已有知识的方法。这个想法是使用一个已经在一个更大的数据集上训练了很长时间并被证明在相关任务中工作良好的最先进的模型。许多这样的模型可供我们使用。</p><p id="de0a" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">Keras提供了一些经过预先训练的先进模型。这些模型的细节可以在https://keras.io/applications/找到</p><p id="515d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我们可以通过两种方式使用这些模型:</p><ol class=""><li id="3613" class="jk jl hi io b ip iq it iu ix jm jb jn jf jo jj jp jq jr js bi translated">直接应用:在这种方法中，</li></ol><p id="c8e8" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">a.我们研究这个模型来检验它是否能解决我们的目标问题。</p><p id="740e" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">b.如果是，我们需要根据模型预处理我们的输入，然后将它提供给模型以获得结果。</p><p id="a8fe" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">2.表征学习:在这种方法中，我们认为预先训练的模型可能不直接适用于我们的问题。但是，我们可以用它来获得输入数据的有用表示。</p><p id="2217" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">a.我们将输入数据输入到预先训练的模型中，以获得数据的表示。</p><p id="d067" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">b.我们设计自己的模型，并用预先训练好的模型给出的表示来输入它，以获得结果。</p><p id="debc" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">对于这里的图像分类任务，应用上述第二种方法。</p><p id="e87f" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">以下是相同的典型步骤:</p><ol class=""><li id="d28a" class="jk jl hi io b ip iq it iu ix jm jb jn jf jo jj jp jq jr js bi translated">所用型号:vgg16型号，<a class="ae jy" href="https://keras.io/applications/#vgg16" rel="noopener ugc nofollow" target="_blank">https://keras.io/applications/#vgg16</a></li><li id="e344" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj jp jq jr js bi translated">使用vgg16我们得到了有用的表示。</li><li id="7a4e" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj jp jq jr js bi translated">我们从vgg16得到的表示被输入到一个序列模型中。</li></ol><figure class="ld le lf lg fd lh er es paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="er es lc"><img src="../Images/6faf2051dd3e186500d7899eb3277efb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x3ldzOAdnUcky3Dqhtnjlw.jpeg"/></div></div><figcaption class="lo lp et er es lq lr bd b be z dx translated">图像分类的迁移学习[第二种方法]</figcaption></figure><p id="5172" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">模型定义如下:</p><blockquote class="ls lt lu"><p id="f311" class="im in lv io b ip iq ir is it iu iv iw lw iy iz ja lx jc jd je ly jg jh ji jj hb bi translated">VGG16型号:</p><p id="c777" class="im in lv io b ip iq ir is it iu iv iw lw iy iz ja lx jc jd je ly jg jh ji jj hb bi translated">型号=应用。VGG16(include_top = False，weights = 'imagenet ')</p><p id="aa06" class="im in lv io b ip iq ir is it iu iv iw lw iy iz ja lx jc jd je ly jg jh ji jj hb bi translated">顶级模特:</p><p id="1175" class="im in lv io b ip iq ir is it iu iv iw lw iy iz ja lx jc jd je ly jg jh ji jj hb bi translated">model = Sequential()<br/>model . add(Flatten(input _ shape = train _ data . shape[1:])<br/>model . add(Dense(256，activation = ' relu ')<br/>model . add(Dropout(0.5))<br/>model . add(Dense(1，activation = ' sigmoid ')<br/><br/>model . compile(optimizer = ' rms prop '，<br/> loss = 'binary_crossentropy '，<br/> metrics = ['accuracy'])</p></blockquote><h2 id="6da4" class="lz ka hi bd kb ma mb mc kf md me mf kj ix mg mh kn jb mi mj kr jf mk ml kv mm bi translated">结果:</h2><p id="1c6b" class="pw-post-body-paragraph im in hi io b ip kx ir is it ky iv iw ix kz iz ja jb la jd je jf lb jh ji jj hb bi translated">培训时间:12分钟[10分钟获得陈述]+2分钟培训顶级模特。</p><p id="ec54" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">损失:0.1985-精度:0.9219-val _ loss:0.6466-val _ accuracy:0.8045</p><p id="0af9" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">因此，使用迁移学习，我们可以在仅12分钟内训练一个具有92%训练准确度的模型，这与之前讨论的模型相比要好得多。</p><p id="bf80" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我们可以进一步提高这种训练模型的准确性，方法是使用</p><ol class=""><li id="b005" class="jk jl hi io b ip iq it iu ix jm jb jn jf jo jj jp jq jr js bi translated">更多数据/增强</li><li id="94ba" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj jp jq jr js bi translated">更多时代/训练步骤</li><li id="600d" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj jp jq jr js bi translated">添加更多层</li><li id="637a" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj jp jq jr js bi translated">更加正规化。</li></ol><p id="2eaa" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">您可以在以下存储库中找到该作品的完整代码:</p><p id="7259" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><a class="ae jy" href="https://github.com/lalitkpal/ImageClassification.git" rel="noopener ugc nofollow" target="_blank">https://github.com/lalitkpal/ImageClassification.git</a></p></div></div>    
</body>
</html>