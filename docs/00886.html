<html>
<head>
<title>Semantic segmentation to detect Nuclei using U-net</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于U-net的语义分割细胞核检测</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/semantic-segmentation-using-u-net-data-science-bowl-2018-data-set-ed046c2004a5?source=collection_archive---------5-----------------------#2019-09-16">https://medium.com/analytics-vidhya/semantic-segmentation-using-u-net-data-science-bowl-2018-data-set-ed046c2004a5?source=collection_archive---------5-----------------------#2019-09-16</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="3841" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">使用Tensorflow和Keras对数据科学碗2018数据集进行预测</h2></div><h1 id="cb24" class="ix iy hi bd iz ja jb jc jd je jf jg jh io ji ip jj ir jk is jl iu jm iv jn jo bi translated">介绍</h1><p id="d5d9" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">本文展示了U-net卷积神经网络在<a class="ae kl" href="https://www.kaggle.com/c/data-science-bowl-2018" rel="noopener ugc nofollow" target="_blank"> Data Science Bowl 2018 kaggle数据集</a>的原子核检测中的应用。Tensorflow/Keras框架用于模型、训练和预测程序的实施。这篇文章的完整代码可以在<a class="ae kl" href="https://github.com/Booritas/semantic-segmentation" rel="noopener ugc nofollow" target="_blank"> Github </a>上获得。</p><h1 id="7c52" class="ix iy hi bd iz ja jb jc jd je jf jg jh io ji ip jj ir jk is jl iu jm iv jn jo bi translated">数据集概述</h1><p id="ab07" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated"><a class="ae kl" href="https://www.kaggle.com/c/data-science-bowl-2018" rel="noopener ugc nofollow" target="_blank">数据科学碗2018 kaggle数据集</a>包含大量分割的细胞核图像。这些图像是在各种条件下获得的，并且在细胞类型、放大倍数和成像模式(明视野对荧光)方面有所不同。</p><p id="e3f1" class="pw-post-body-paragraph jp jq hi jr b js km ij ju jv kn im jx jy ko ka kb kc kp ke kf kg kq ki kj kk hb bi translated">数据集由一组文件夹表示。每个文件夹包含两个子文件夹:“图像”和“蒙版”。</p><figure class="ks kt ku kv fd kw er es paragraph-image"><div class="er es kr"><img src="../Images/f6b6d7ad3f32812d2c5e16f6e39f3190.png" data-original-src="https://miro.medium.com/v2/resize:fit:958/format:webp/1*-i7l-6rO-7mgBTrVNwqVQg.png"/></div><figcaption class="kz la et er es lb lc bd b be z dx translated">数据科学碗数据集结构</figcaption></figure><p id="e234" class="pw-post-body-paragraph jp jq hi jr b js km ij ju jv kn im jx jy ko ka kb kc kp ke kf kg kq ki kj kk hb bi translated">子文件夹“图像”包含一个组织扫描图像文件。子文件夹“masks”包含几个png文件—每个带注释的nucleus一个文件。掩模文件是具有原始组织扫描尺寸的黑白图片，其中白色像素描绘了细胞核的位置。下图显示了数据示例。原始图像在左上角，其余是遮罩图像(只显示了少数遮罩)。</p><figure class="ks kt ku kv fd kw er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es ld"><img src="../Images/3bc343d4868def0dcd755a8ec5cd7b89.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ucfCubutYQ0Om0CNv1sH_Q.png"/></div></div></figure><p id="3c65" class="pw-post-body-paragraph jp jq hi jr b js km ij ju jv kn im jx jy ko ka kb kc kp ke kf kg kq ki kj kk hb bi translated">扫描图像的颜色、放大倍数和大小各不相同。以下是一些图像示例(图像被缩放以适合文档):</p><figure class="ks kt ku kv fd kw er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es li"><img src="../Images/14f17f0e22a59ad991d51beb8ee480ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-wyxTFTqOgGP1ZyRaeA9pg.png"/></div></div></figure><h1 id="9bb6" class="ix iy hi bd iz ja jb jc jd je jf jg jh io ji ip jj ir jk is jl iu jm iv jn jo bi translated">数据集准备</h1><h2 id="4b28" class="lj iy hi bd iz lk ll lm jd ln lo lp jh jy lq lr jj kc ls lt jl kg lu lv jn lw bi translated">图像尺寸</h2><p id="c672" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">卷积神经网络处理相同大小的图像。<a class="ae kl" href="https://www.kaggle.com/c/data-science-bowl-2018" rel="noopener ugc nofollow" target="_blank">数据科学碗2018 kaggle数据集</a>包含不同大小的图像。第一个挑战是将所有数据集图像调整到相同的大小。一种可能的方法是将图像的大小调整到某个标准大小。这将导致缩小规模时丢失一些信息，并通过扩大规模增加计算复杂性。因为图像具有不同的宽/高比，所以它甚至更有问题。沿x轴和y轴使用不同的缩放系数会使图像失真。</p><p id="e4aa" class="pw-post-body-paragraph jp jq hi jr b js km ij ju jv kn im jx jy ko ka kb kc kp ke kf kg kq ki kj kk hb bi translated">在本文中，我们使用另一种方法。图像的最小尺寸(256x256像素)作为基础。所有图像都由具有基本尺寸的瓦片集合分解。原始的256x256图像由一个单幅图块表示。尺寸较大的图像由重叠的256x256拼贴分解。因此，大小为320x320的图像将由6个图块表示，如下图所示:</p><figure class="ks kt ku kv fd kw er es paragraph-image"><div class="er es lx"><img src="../Images/8c9439996c028a2d03ff77eee236439d.png" data-original-src="https://miro.medium.com/v2/resize:fit:966/0*XffYa968eJ5LHicU"/></div></figure><p id="b89f" class="pw-post-body-paragraph jp jq hi jr b js km ij ju jv kn im jx jy ko ka kb kc kp ke kf kg kq ki kj kk hb bi translated">平铺重叠带来了另一个积极的效果:它增加了训练集的大小。</p><h2 id="2309" class="lj iy hi bd iz lk ll lm jd ln lo lp jh jy lq lr jj kc ls lt jl kg lu lv jn lw bi translated">图像亮度</h2><p id="43e0" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">为了将所有图像置于同一色彩空间，彩色图像被转换为灰度图像。</p><p id="e51f" class="pw-post-body-paragraph jp jq hi jr b js km ij ju jv kn im jx jy ko ka kb kc kp ke kf kg kq ki kj kk hb bi translated">另一个挑战是数据集包含不同亮度的图像。高亮度图像显示细胞核为暗点，低亮度图像显示细胞核为亮点。见下图:</p><figure class="ks kt ku kv fd kw er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es ly"><img src="../Images/a718bc75f8f3016d165c5892418b4062.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*lQXYozSIubsjIMax.png"/></div></div></figure><p id="7183" class="pw-post-body-paragraph jp jq hi jr b js km ij ju jv kn im jx jy ko ka kb kc kp ke kf kg kq ki kj kk hb bi translated">为了减少差异，我们将明亮的图像反转。</p><h2 id="7b94" class="lj iy hi bd iz lk ll lm jd ln lo lp jh jy lq lr jj kc ls lt jl kg lu lv jn lw bi translated">培训、验证和测试集</h2><p id="f9b3" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">为了实现具有不同亮度水平和细胞核密度的图像的均匀分布，我们根据图像的光栅统计(像素值的最小值、最大值、平均值和标准偏差)将图像分成几个组。详情见Github上的<a class="ae kl" href="https://github.com/Booritas/semantic-segmentation/blob/master/data/data-science-bowl.ipynb" rel="noopener ugc nofollow" target="_blank">数据集笔记本</a>。训练、验证和测试数据集是用相同比例的不同聚类创建的。下图显示了几行图像。每一行代表一个集群。</p><figure class="ks kt ku kv fd kw er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es lz"><img src="../Images/be9ea92dd6db29b3c9cfea2d1b416edd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*2Ch9XNmItq0E_cAb.png"/></div></div></figure><h1 id="b18f" class="ix iy hi bd iz ja jb jc jd je jf jg jh io ji ip jj ir jk is jl iu jm iv jn jo bi translated">U-net架构</h1><p id="b527" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">最初这里提出了U-net神经网络架构:<a class="ae kl" href="https://arxiv.org/pdf/1505.04597.pdf" rel="noopener ugc nofollow" target="_blank"> U-Net:用于生物医学图像分割的卷积网络</a>。在原始版本的网络输入和输出图像有不同的大小。在本文中，我们使用对称架构(【https://github.com/zhixuhao/unet】<a class="ae kl" href="https://github.com/zhixuhao/unet" rel="noopener ugc nofollow" target="_blank">)。通过在原始模型中使用“相同”填充而不是“有效”来实现对称。</a></p><figure class="ks kt ku kv fd kw er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es ma"><img src="../Images/93c5bb603e717c3b8e84c01ea1b52840.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*l23lbOWx-_deTkyk.png"/></div></div></figure><h1 id="2f73" class="ix iy hi bd iz ja jb jc jd je jf jg jh io ji ip jj ir jk is jl iu jm iv jn jo bi translated">培养</h1><p id="75ec" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">使用Adam optimizer以1.e-4的学习率对模型进行训练。下图显示了在不同步骤的训练过程中生成的预测掩码的演变。最后一行显示手动注释。</p><figure class="ks kt ku kv fd kw er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es mb"><img src="../Images/a5664d6e2699f26d2447e8a3c228a232.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tBGbW6nV9lb2whJc3TmzDQ.png"/></div></div></figure><p id="e4f8" class="pw-post-body-paragraph jp jq hi jr b js km ij ju jv kn im jx jy ko ka kb kc kp ke kf kg kq ki kj kk hb bi translated">下面的图片显示了在模型训练过程中损失、精度和像素差异是如何变化的。</p><figure class="ks kt ku kv fd kw er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es mc"><img src="../Images/e201133e7b49296795363db5a46ecaf0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*5i5RR7nRf0aCdrxO.png"/></div></div><figcaption class="kz la et er es lb lc bd b be z dx translated">损失图</figcaption></figure><figure class="ks kt ku kv fd kw er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es md"><img src="../Images/2e913c79d064556e47e55cb18c9f7bb6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*cFyMpbIRdhi74NNG.png"/></div></div><figcaption class="kz la et er es lb lc bd b be z dx translated">准确度图</figcaption></figure><figure class="ks kt ku kv fd kw er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es me"><img src="../Images/80f0076f838b6b1c8550c3fbfa528fcb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ZSnVudA0N1wwnAhA.png"/></div></div><figcaption class="kz la et er es lb lc bd b be z dx translated">像素差异图</figcaption></figure><h1 id="2f4d" class="ix iy hi bd iz ja jb jc jd je jf jg jh io ji ip jj ir jk is jl iu jm iv jn jo bi translated">结果</h1><p id="107f" class="pw-post-body-paragraph jp jq hi jr b js jt ij ju jv jw im jx jy jz ka kb kc kd ke kf kg kh ki kj kk hb bi translated">在每个4000步的3个时期之后，训练损失下降到0.006，验证损失下降到0.14。训练数据集的精度达到0.9975，验证数据集的精度达到0.98。下图显示了来自测试数据集的几幅图像的预测结果(第一行是图像，第二行是预测，第三行是注释) :</p><figure class="ks kt ku kv fd kw er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es mf"><img src="../Images/1f71b7a5b8c66ea2bd97a5603c7f93bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*78oAagdzg9mspuDfHm7PSg.png"/></div></div></figure><p id="3837" class="pw-post-body-paragraph jp jq hi jr b js km ij ju jv kn im jx jy ko ka kb kc kp ke kf kg kq ki kj kk hb bi translated">下图显示了误差最大的图像(超过6%的错误分类像素)的结果与注释的偏差。第一行包含原始图像，第二行—预测结果，第三行—注释遮罩，第四行—预测图像和注释图像之间的像素差异:</p><figure class="ks kt ku kv fd kw er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es mg"><img src="../Images/663907b95d4fb7d711ba7f70e2e4de91.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*yETgkptYLP6V0QuO.png"/></div></div></figure><p id="2b89" class="pw-post-body-paragraph jp jq hi jr b js km ij ju jv kn im jx jy ko ka kb kc kp ke kf kg kq ki kj kk hb bi translated">尽管相对大量的像素在注释和预测掩模上不同，但是生成的分割的质量并不太差。大多数差异出现在弥散核边界和重叠核上。然而，所有的细胞核都被检测到了。</p></div></div>    
</body>
</html>