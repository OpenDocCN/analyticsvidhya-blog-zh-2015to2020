<html>
<head>
<title>TensorBoard Demonstration using Fashion MNIST Dataset</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用时尚MNIST数据集的张量板演示</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/tensorboard-demonstration-using-fashion-mnist-b978d4c55583?source=collection_archive---------13-----------------------#2019-12-19">https://medium.com/analytics-vidhya/tensorboard-demonstration-using-fashion-mnist-b978d4c55583?source=collection_archive---------13-----------------------#2019-12-19</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="b497" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">TensorBoard是Tensorflow的可视化工具包，提供了一种简单的方法来查看您的模型的图形，并查看损失、准确性等方面的改进。本教程使用keras建立和训练模型，tensorflow 1.13。</p><p id="17e4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们从导入必要的库开始:</p><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="d020" class="jm jn hi ji b fi jo jp l jq jr">from tensorflow.keras.layers import Input, Dense, Conv2D, Flatten, Dropout<br/>from tensorflow.keras.datasets import fashion_mnist<br/>from tensorflow.keras.optimizers import Adam<br/>from tensorflow.keras.models import Model<br/>from tensorflow.keras.callbacks import TensorBoard<br/>import numpy as np<br/>import tensorflow as tf</span></pre><p id="450a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们必须获取数据集，并将其分类为训练组和测试组。幸运的是，keras可以为我们做到这一点。之后，我们必须为我们的标签执行一次热编码。</p><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="84bf" class="jm jn hi ji b fi jo jp l jq jr">(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()</span><span id="502e" class="jm jn hi ji b fi js jp l jq jr">def one_hot(targets, nb_classes=10):<br/>    res = np.eye(nb_classes)[np.array(targets).reshape(-1)]<br/>    return res.reshape(list(targets.shape)+[nb_classes])</span><span id="03b5" class="jm jn hi ji b fi js jp l jq jr">y_train = one_hot(y_train)<br/>y_test = one_hot(y_test)<br/>x_train = np.reshape(np.expand_dims(x_train, axis=1), (60000, 28, 28, 1)) #reshaping for it to be compatible with model<br/>x_test = np.reshape(np.expand_dims(x_test, axis=1), (10000, 28, 28, 1))</span></pre><p id="b540" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们将定义模型架构。这里，有3个卷积层和2个密集层。请随意使用您自己的架构。模型也在这一步编译。</p><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="c520" class="jm jn hi ji b fi jo jp l jq jr">input = Input(shape=(28, 28, 1))<br/>x = Conv2D(4, (5, 5), strides=1, activation="relu", padding="same")(input)<br/>x = Conv2D(8, (5, 5), strides=2, activation="relu", padding="same")(x)<br/>x = Conv2D(12, (4, 4), strides=2, activation="relu", padding="same")(x)<br/>x = Flatten()(x)<br/>x = Dense(200, activation="relu")(x)<br/>x = Dropout(0.1)(x)<br/>output = Dense(10, activation="softmax")(x)<br/>model = Model(inputs=input, outputs=output)<br/>model.compile(loss="categorical_crossentropy",<br/>              optimizer=Adam(),<br/>              metrics=["accuracy"])</span></pre><p id="72e8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在训练我们的模型时，我们可以提供对它的回调，检查进度，提前停止训练，等等。在这里，我们定义一个tensorboard回调，训练和评估我们的模型。</p><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="6a68" class="jm jn hi ji b fi jo jp l jq jr">tensorboard = TensorBoard(log_dir="./logs/tboard")<br/>model.fit(x_train, y_train, batch_size=64, epochs=3, callbacks=[tensorboard])<br/>print(model.evaluate(x_test, y_test))</span></pre><p id="5fe0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">TensorBoard将日志写入您选择的目录中的文件，通常是。/logs/。我们必须定义作者。</p><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="5eb7" class="jm jn hi ji b fi jo jp l jq jr">writer = tf.summary.FileWriter("/path/to/your/directory", tf.get_default_graph())</span></pre><p id="c7c5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后，我们可以从命令行启动tensorboard。它将在本地主机上运行。</p><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="2658" class="jm jn hi ji b fi jo jp l jq jr">$tensorboard --logdir=./path/to/your/directory --port=6006</span></pre><p id="3c1c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在浏览器中打开localhost:6006。您可以查看随时间变化的损失和精确度的图表，也可以查看模型的计算图表。</p><div class="jd je jf jg fd ab cb"><figure class="jt ju jv jw jx jy jz paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><img src="../Images/4c86f34b4115db18f9d7e9c2cf4e08a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*hHwBRj_yw83tpONT2RsPwQ.png"/></div></figure><figure class="jt ju kg jw jx jy jz paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><img src="../Images/a0ccf04495c0c791e3124cad081b35e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*lxElgKBzpIco4aWCDjxZvw.png"/></div><figcaption class="kh ki et er es kj kk bd b be z dx kl di km kn translated">张量板上的计算图、精度图和损失图</figcaption></figure></div><p id="bb52" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们还可以将我们的图表上传到TensorBoard.dev，这将为我们提供一个任何人都可以查看的公共共享链接(这对每个人都是公开的，所以不要共享敏感信息)。</p><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="1ec5" class="jm jn hi ji b fi jo jp l jq jr">tensorboard dev upload --logdir ./path/to/your/directory</span></pre></div></div>    
</body>
</html>