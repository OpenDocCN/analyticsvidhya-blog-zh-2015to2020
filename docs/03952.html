<html>
<head>
<title>Quick Introduction to Bag-of-Words (BoW) and TF-IDF for Creating Features from Text</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">快速介绍用于从文本创建特征的词袋(BoW)和TF-IDF</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/quick-introduction-to-bag-of-words-bow-and-tf-idf-for-creating-features-from-text-46912dce0cd9?source=collection_archive---------6-----------------------#2020-02-27">https://medium.com/analytics-vidhya/quick-introduction-to-bag-of-words-bow-and-tf-idf-for-creating-features-from-text-46912dce0cd9?source=collection_archive---------6-----------------------#2020-02-27</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="220e" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">让机器理解文本的挑战</h2></div><p id="f701" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">语言是一种奇妙的交流媒介。</p><p id="1d10" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">你和我会在瞬间理解这句话。但是机器无法处理原始形式的文本数据。他们需要我们将文本分解成机器容易阅读的数字格式(自然语言处理背后的想法！).</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="er es ju"><img src="../Images/f2b78eff0d31652c46c1e0150100c9a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*F6o_ZEisocoU95yu.png"/></div></div><figcaption class="kg kh et er es ki kj bd b be z dx translated">抄送:西沃恩·格雷森/抄送BY-SA(【https://creativecommons.org/licenses/by-sa/4.0】T2</figcaption></figure><p id="7417" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这就是单词袋(BoW)和TF-IDF的概念发挥作用的地方。BoW和TF-IDF都是帮助我们将文本句子转换成数字向量的技术。</p><p id="fdef" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在本文中，我将同时讨论单词袋和TF-IDF。我们将使用一个直观和通用的例子来详细理解每个概念。</p><p id="3f63" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="kk">自然语言处理(NLP)新手？我们为您提供了完美的入门课程:</em></p><ul class=""><li id="03bd" class="kl km hi iz b ja jb jd je jg kn jk ko jo kp js kq kr ks kt bi translated"><a class="ae jt" href="https://courses.analyticsvidhya.com/courses/Intro-to-NLP" rel="noopener ugc nofollow" target="_blank"> <em class="kk">【自然语言处理(NLP)入门】</em> </a> <em class="kk"> —免费课程！</em></li><li id="1845" class="kl km hi iz b ja ku jd kv jg kw jk kx jo ky js kq kr ks kt bi translated"><a class="ae jt" href="https://courses.analyticsvidhya.com/courses/natural-language-processing-nlp" rel="noopener ugc nofollow" target="_blank"> <em class="kk">使用Python的自然语言处理(NLP)</em></a><em class="kk">—全面的端到端NLP课程</em></li></ul><h1 id="725f" class="kz la hi bd lb lc ld le lf lg lh li lj io lk ip ll ir lm is ln iu lo iv lp lq bi translated">让我们举个例子来理解词袋(BoW)和TF-IDF</h1><p id="ca1b" class="pw-post-body-paragraph ix iy hi iz b ja lr ij jc jd ls im jf jg lt ji jj jk lu jm jn jo lv jq jr js hb bi translated">我将举一个流行的例子来解释本文中的词袋(BoW)和TF-DF。</p><p id="f424" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们都爱看电影(程度不同)。在我决定看电影之前，我总是倾向于看电影的评论。我知道你们很多人也是这样做的！所以，我在这里用这个例子。</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="er es lw"><img src="../Images/7b11e0e0fcb88d69e64779924a8aeaad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*tWhAajiTJI3yY0y5.jpg"/></div></div><figcaption class="kg kh et er es ki kj bd b be z dx translated">抄送[<a class="ae jt" href="https://www.piqsels.com/en/public-domain-photo-stmmn" rel="noopener ugc nofollow" target="_blank">https://www.piqsels.com/en/public-domain-photo-stmmn]</a></figcaption></figure><p id="6c57" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">以下是对一部特定恐怖电影的评论样本:</p><ul class=""><li id="afb3" class="kl km hi iz b ja jb jd je jg kn jk ko jo kp js kq kr ks kt bi translated">评论1:这部电影很恐怖，很长</li><li id="0edd" class="kl km hi iz b ja ku jd kv jg kw jk kx jo ky js kq kr ks kt bi translated">点评2:这部电影不恐怖，节奏慢</li><li id="0cf1" class="kl km hi iz b ja ku jd kv jg kw jk kx jo ky js kq kr ks kt bi translated">评论3:这部电影很恐怖，很好</li></ul><p id="145b" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">你可以看到有一些关于这部电影的对比评论，以及电影的长度和节奏。想象一下看一千篇这样的评论。显然，我们可以从中获得许多有趣的见解，并以此为基础来衡量这部电影的表现。</p><p id="65a3" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">然而，正如我们在上面看到的，我们不能简单地将这些句子交给机器学习模型，并要求它告诉我们评论是积极的还是消极的。我们需要执行某些文本预处理步骤。</p><p id="c85c" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">单词袋和TF-IDF是如何做到这一点的两个例子。</p><h1 id="db93" class="kz la hi bd lb lc ld le lf lg lh li lj io lk ip ll ir lm is ln iu lo iv lp lq bi translated">从文本创建矢量</h1><p id="83c0" class="pw-post-body-paragraph ix iy hi iz b ja lr ij jc jd ls im jf jg lt ji jj jk lu jm jn jo lv jq jr js hb bi translated">你能想出一些我们可以用来在开头向量化一个句子的技术吗？基本要求是:</p><ol class=""><li id="950a" class="kl km hi iz b ja jb jd je jg kn jk ko jo kp js lx kr ks kt bi translated">它不应该产生稀疏矩阵，因为稀疏矩阵会导致高计算成本</li><li id="bc42" class="kl km hi iz b ja ku jd kv jg kw jk kx jo ky js lx kr ks kt bi translated">我们应该能够记住句子中的大部分语言信息</li></ol><p id="c106" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">单词嵌入就是这样一种技术，我们可以用向量来表示文本。更流行的单词嵌入形式有:</p><ol class=""><li id="9844" class="kl km hi iz b ja jb jd je jg kn jk ko jo kp js lx kr ks kt bi translated">BoW，代表单词袋</li><li id="7c2f" class="kl km hi iz b ja ku jd kv jg kw jk kx jo ky js lx kr ks kt bi translated">TF-IDF，代表术语频率-逆文档频率</li></ol><p id="2350" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，让我们看看如何将上述电影评论表示为嵌入，并为机器学习模型做好准备。</p><h1 id="54c3" class="kz la hi bd lb lc ld le lf lg lh li lj io lk ip ll ir lm is ln iu lo iv lp lq bi translated">单词袋(蝴蝶结)模型</h1><p id="5364" class="pw-post-body-paragraph ix iy hi iz b ja lr ij jc jd ls im jf jg lt ji jj jk lu jm jn jo lv jq jr js hb bi translated">单词袋(BoW)模型是最简单的单词表示形式。就像这个术语本身一样，我们可以将一个句子表示为一个单词包向量(一串数字)。</p><p id="e6da" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们回忆一下之前看到的三种类型的影评:</p><ul class=""><li id="046d" class="kl km hi iz b ja jb jd je jg kn jk ko jo kp js kq kr ks kt bi translated">评论1:这部电影很恐怖，很长</li><li id="d15f" class="kl km hi iz b ja ku jd kv jg kw jk kx jo ky js kq kr ks kt bi translated">点评2:这部电影不恐怖，节奏慢</li><li id="871f" class="kl km hi iz b ja ku jd kv jg kw jk kx jo ky js kq kr ks kt bi translated">评论3:这部电影很恐怖，很好</li></ul><p id="8931" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们将首先从所有文档中的单词语料库中构建一个词汇表。词汇由这11个词组成:“这个”、“电影”、“是”、“非常”、“吓人”、“长”、“不”、“慢”、“装神弄鬼”、“好”。</p><p id="5dbb" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们现在可以将这些单词中的每一个用1和0来标记它们在上面三个文档中的出现。这将为我们提供3个文档的3个向量:</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div role="button" tabindex="0" class="ka kb di kc bf kd"><div class="er es ly"><img src="../Images/860677c7ba12fdb398094d57ebd60d31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*2ZwUtbmaS2-J2RA5.png"/></div></div></figure><p id="0c58" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这就是单词袋(BoW)模型背后的核心思想。</p><h2 id="0c9c" class="lz la hi bd lb ma mb mc lf md me mf lj jg mg mh ll jk mi mj ln jo mk ml lp mm bi translated">使用单词袋(BoW)模型的缺点</h2><p id="e693" class="pw-post-body-paragraph ix iy hi iz b ja lr ij jc jd ls im jf jg lt ji jj jk lu jm jn jo lv jq jr js hb bi translated">在上面的例子中，我们可以有长度为11的向量。然而，当我们遇到新的句子时，我们开始面临问题:</p><ol class=""><li id="b4fc" class="kl km hi iz b ja jb jd je jg kn jk ko jo kp js lx kr ks kt bi translated">如果新句子的长度更长，我们的词汇量会增加，因此，向量的长度也会增加</li><li id="cf8a" class="kl km hi iz b ja ku jd kv jg kw jk kx jo ky js lx kr ks kt bi translated">新的句子可能包含更多的未知单词，如果我们保持固定的向量大小，我们必须忽略它们</li><li id="6ab5" class="kl km hi iz b ja ku jd kv jg kw jk kx jo ky js lx kr ks kt bi translated">此外，向量也将包含许多0，从而导致一个稀疏矩阵(这是我们想要避免的)</li><li id="1777" class="kl km hi iz b ja ku jd kv jg kw jk kx jo ky js lx kr ks kt bi translated">我们不保留句子的语法信息，也不保留实际文档中单词的顺序信息</li></ol><h1 id="ed32" class="kz la hi bd lb lc ld le lf lg lh li lj io lk ip ll ir lm is ln iu lo iv lp lq bi translated">术语频率-逆文档频率(TF-IDF)</h1><p id="79af" class="pw-post-body-paragraph ix iy hi iz b ja lr ij jc jd ls im jf jg lt ji jj jk lu jm jn jo lv jq jr js hb bi translated">我们先围绕TF-IDF放一个正式的定义。维基百科是这样说的:</p><blockquote class="mn mo mp"><p id="97a5" class="ix iy kk iz b ja jb ij jc jd je im jf mq jh ji jj mr jl jm jn ms jp jq jr js hb bi translated"><em class="hi">词频(Term frequency)——逆文档频率(inverse document frequency)，是一种数字统计，旨在反映一个词对集合或语料库中的文档有多重要。</em></p></blockquote><h2 id="e1ab" class="lz la hi bd lb ma mb mc lf md me mf lj jg mg mh ll jk mi mj ln jo mk ml lp mm bi translated">术语频率(TF)</h2><p id="df8f" class="pw-post-body-paragraph ix iy hi iz b ja lr ij jc jd ls im jf jg lt ji jj jk lu jm jn jo lv jq jr js hb bi translated">术语频繁度(TF)是术语t在文档d中出现频率的度量:</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div class="er es mt"><img src="../Images/c2f4dfddbaa7196c375afb8393b42230.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*ycq8B3kGH_FyJTgM.jpg"/></div></figure><p id="7126" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj"> <em class="kk">这里，在分子中，n是术语“t”在文档“d”中出现的次数。因此，每个文档和术语都有自己的TF值。</em> </strong></p><p id="b52e" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们将再次使用我们在单词袋模型中构建的相同词汇来展示如何计算复习#2的TF:</p><p id="97b9" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="kk">点评2:这部电影不恐怖，速度慢</em></p><p id="b0db" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这里，</p><ul class=""><li id="33d1" class="kl km hi iz b ja jb jd je jg kn jk ko jo kp js kq kr ks kt bi translated">词汇<strong class="iz hj"> : </strong>'这个'，'电影'，'是'，'非常'，'吓人'，'长'，'不'，'慢'，'装神弄鬼'，'好'</li><li id="3dbd" class="kl km hi iz b ja ku jd kv jg kw jk kx jo ky js kq kr ks kt bi translated">复习2的字数= 8</li><li id="9a42" class="kl km hi iz b ja ku jd kv jg kw jk kx jo ky js kq kr ks kt bi translated">单词‘this’的TF =(评论2中‘this’出现的次数)/(评论2中的术语数)= 1/8</li></ul><p id="92c3" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">同样的，</p><ul class=""><li id="26eb" class="kl km hi iz b ja jb jd je jg kn jk ko jo kp js kq kr ks kt bi translated">TF('电影')= 1/8</li><li id="19d9" class="kl km hi iz b ja ku jd kv jg kw jk kx jo ky js kq kr ks kt bi translated">TF('is') = 2/8 = 1/4</li><li id="f8c7" class="kl km hi iz b ja ku jd kv jg kw jk kx jo ky js kq kr ks kt bi translated">TF('very') = 0/8 = 0</li><li id="3114" class="kl km hi iz b ja ku jd kv jg kw jk kx jo ky js kq kr ks kt bi translated">TF('吓人')= 1/8</li><li id="53c6" class="kl km hi iz b ja ku jd kv jg kw jk kx jo ky js kq kr ks kt bi translated">TF('and') = 1/8</li><li id="2921" class="kl km hi iz b ja ku jd kv jg kw jk kx jo ky js kq kr ks kt bi translated">TF('long') = 0/8 = 0</li><li id="138f" class="kl km hi iz b ja ku jd kv jg kw jk kx jo ky js kq kr ks kt bi translated">TF('not') = 1/8</li><li id="6868" class="kl km hi iz b ja ku jd kv jg kw jk kx jo ky js kq kr ks kt bi translated">TF('慢')= 1/8</li><li id="7fcf" class="kl km hi iz b ja ku jd kv jg kw jk kx jo ky js kq kr ks kt bi translated">TF('幽灵')= 0/8 = 0</li><li id="81ce" class="kl km hi iz b ja ku jd kv jg kw jk kx jo ky js kq kr ks kt bi translated">TF('好')= 0/8 = 0</li></ul><p id="9f52" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们可以用这种方式计算所有术语和所有评论的术语频率:</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div class="er es mu"><img src="../Images/c6e47fe091c7785f8bc1e65fcfe145be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1026/format:webp/0*iUffHyG_9VlI1nKE.png"/></div></figure><h2 id="4ccb" class="lz la hi bd lb ma mb mc lf md me mf lj jg mg mh ll jk mi mj ln jo mk ml lp mm bi translated">反向文档频率(IDF)</h2><p id="f6df" class="pw-post-body-paragraph ix iy hi iz b ja lr ij jc jd ls im jf jg lt ji jj jk lu jm jn jo lv jq jr js hb bi translated">这是衡量一个术语有多重要的标准。我们需要IDF值，因为仅计算TF不足以理解单词的重要性:</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div class="er es mt"><img src="../Images/c586a1fd1031a87a65801ea05b34a813.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*NDoc4PQ_0IThkoa-.jpg"/></div></figure><p id="5fd5" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们可以计算复习2中所有单词的IDF值:</p><p id="e47a" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">IDF('this') = log(文档数/包含单词' this') = log(3/3) = log(1) = 0</p><p id="c122" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">同样的，</p><ul class=""><li id="df67" class="kl km hi iz b ja jb jd je jg kn jk ko jo kp js kq kr ks kt bi translated">IDF('电影'，)= log(3/3) = 0</li><li id="f8a1" class="kl km hi iz b ja ku jd kv jg kw jk kx jo ky js kq kr ks kt bi translated">IDF('is') = log(3/3) = 0</li><li id="bbef" class="kl km hi iz b ja ku jd kv jg kw jk kx jo ky js kq kr ks kt bi translated">IDF('非')= log(3/1) = log(3) = 0.48</li><li id="742b" class="kl km hi iz b ja ku jd kv jg kw jk kx jo ky js kq kr ks kt bi translated">IDF('吓人')= log(3/2) = 0.18</li><li id="faa5" class="kl km hi iz b ja ku jd kv jg kw jk kx jo ky js kq kr ks kt bi translated">IDF('和')= log(3/3) = 0</li><li id="d2c3" class="kl km hi iz b ja ku jd kv jg kw jk kx jo ky js kq kr ks kt bi translated">IDF(‘慢’)= log(3/1)= 0.48</li></ul><p id="d697" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们可以像这样计算每个单词的IDF值。因此，整个词汇表的IDF值将是:</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div class="er es mv"><img src="../Images/63faaa752e669be0aac6b7f8f74389ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:664/format:webp/0*KSItD6J7Ojr8Xslc.png"/></div></figure><p id="2646" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="iz hj">于是，我们看到像“是”、“这”、“和”等这样的词。，降为0，重要性不大；而像“吓人”、“长”、“好”等词。是更重要的词，因此具有更高的价值。</strong></p><p id="a9ba" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们现在可以计算语料库中每个单词的TF-IDF分数。分数较高的单词更重要，分数较低的单词不太重要:</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div class="er es mw"><img src="../Images/5fa57511809ca26e2654174de40061e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:562/format:webp/0*Z6VTqa4f2CJEl0MX.jpg"/></div></figure><p id="0e96" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们现在可以计算复习2中每个单词的TF-IDF分数:</p><p id="0b3c" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">TF-IDF('这个'，点评2) = TF('这个'，点评2) * IDF('这个')= 1/8 * 0 = 0</p><p id="e739" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">同样的，</p><ul class=""><li id="4e3b" class="kl km hi iz b ja jb jd je jg kn jk ko jo kp js kq kr ks kt bi translated">TF-IDF('电影'，评论2) = 1/8 * 0 = 0</li><li id="382a" class="kl km hi iz b ja ku jd kv jg kw jk kx jo ky js kq kr ks kt bi translated">TF-IDF('is '，审查2) = 1/4 * 0 = 0</li><li id="dffa" class="kl km hi iz b ja ku jd kv jg kw jk kx jo ky js kq kr ks kt bi translated">TF-IDF('非'，审查2) = 1/8 * 0.48 = 0.06</li><li id="b2bd" class="kl km hi iz b ja ku jd kv jg kw jk kx jo ky js kq kr ks kt bi translated">TF-IDF('吓人'，点评2) = 1/8 * 0.18 = 0.023</li><li id="7961" class="kl km hi iz b ja ku jd kv jg kw jk kx jo ky js kq kr ks kt bi translated">TF-IDF('and '，Review 2) = 1/8 * 0 = 0</li><li id="c693" class="kl km hi iz b ja ku jd kv jg kw jk kx jo ky js kq kr ks kt bi translated">TF-IDF('慢速'，审查2) = 1/8 * 0.48 = 0.06</li></ul><p id="d4d0" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">类似地，我们可以针对所有评论计算所有单词的TF-IDF分数:</p><figure class="jv jw jx jy fd jz er es paragraph-image"><div class="er es mx"><img src="../Images/cb72bf4df095beb26d55610567d35e3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1180/format:webp/0*LYd1odDo8EPbY4Ki.png"/></div></figure><p id="629a" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们现在已经获得了词汇的TF-IDF分数。TF-IDF也为不太频繁的单词给出较大的值，并且当IDF和TF值都高时，即该单词在所有组合的文档中很少，但是在单个文档中很频繁时，TF-IDF也很高。</p><h1 id="6bc2" class="kz la hi bd lb lc ld le lf lg lh li lj io lk ip ll ir lm is ln iu lo iv lp lq bi translated">结束注释</h1><p id="797c" class="pw-post-body-paragraph ix iy hi iz b ja lr ij jc jd ls im jf jg lt ji jj jk lu jm jn jo lv jq jr js hb bi translated">让我总结一下我们在文章中涉及的内容:</p><ol class=""><li id="135f" class="kl km hi iz b ja jb jd je jg kn jk ko jo kp js lx kr ks kt bi translated">单词包只是创建一组包含词汇单词及其在文档中出现次数的向量，而TF-IDF模型包含关于更重要的单词和不太重要的单词的信息。</li><li id="684a" class="kl km hi iz b ja ku jd kv jg kw jk kx jo ky js lx kr ks kt bi translated">单词袋模型可以用于更简单的任务，因为它易于理解和解释。然而，对于更复杂的任务，我们需要TF-IDF。</li></ol><p id="732c" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">虽然单词袋和TF-IDF在各自方面都很受欢迎，但在理解单词的上下文方面仍然存在空白。检测单词“幽灵”和“恐怖”之间的相似性，或者将我们给定的文档翻译成另一种语言，需要关于文档的更多信息。</p><p id="34ff" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这就是诸如Word2Vec、连续单词包(CBOW)、Skipgram等单词嵌入技术的地方。进来吧。你可以在这里找到这种技术的详细指南:<a class="ae jt" href="https://www.analyticsvidhya.com/blog/2017/06/word-embeddings-count-word2veec/" rel="noopener ugc nofollow" target="_blank">对单词嵌入的直观理解:从计数向量到Word2Vec </a></p><p id="a2b5" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">参考资料:</p><ol class=""><li id="26b2" class="kl km hi iz b ja jb jd je jg kn jk ko jo kp js lx kr ks kt bi translated">https://en.wikipedia.org/wiki/Tf%E2%80%93idf<a class="ae jt" href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf" rel="noopener ugc nofollow" target="_blank"/></li><li id="0f6c" class="kl km hi iz b ja ku jd kv jg kw jk kx jo ky js lx kr ks kt bi translated"><a class="ae jt" href="https://maelfabien.github.io/machinelearning/NLP_2/#2-term-frequency-inverse-document-frequency-tf-idf" rel="noopener ugc nofollow" target="_blank">https://mael fabien . github . io/machine learning/NLP _ 2/# 2-term-frequency-inverse-document-frequency-TF-IDF</a></li><li id="ef3f" class="kl km hi iz b ja ku jd kv jg kw jk kx jo ky js lx kr ks kt bi translated"><a class="ae jt" href="https://www.analyticsvidhya.com/blog/2017/06/word-embeddings-count-word2veec/" rel="noopener ugc nofollow" target="_blank">https://www . analyticsvidhya . com/blog/2017/06/word-embeddings-count-word 2 veec/</a></li></ol><p id="0ab1" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">你也可以在分析Vidhya的Android应用上阅读这篇文章</p><p id="ae89" class="pw-post-body-paragraph ix iy hi iz b ja jb ij jc jd je im jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="kk">原载于2020年2月27日https://www.analyticsvidhya.com</em><em class="kk">的</em> <a class="ae jt" href="https://www.analyticsvidhya.com/blog/2020/02/quick-introduction-bag-of-words-bow-tf-idf/" rel="noopener ugc nofollow" target="_blank"> <em class="kk">。</em></a></p></div></div>    
</body>
</html>