<html>
<head>
<title>A Logistic model for predicting divorce rates among couples, implemented using the statsmodel.api library.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">预测夫妇离婚率的逻辑模型，使用statsmodel.api库实现。</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/a-logistic-model-for-predicting-divorce-rates-among-couples-implemented-using-the-statsmodel-api-763e03d29d68?source=collection_archive---------5-----------------------#2019-11-21">https://medium.com/analytics-vidhya/a-logistic-model-for-predicting-divorce-rates-among-couples-implemented-using-the-statsmodel-api-763e03d29d68?source=collection_archive---------5-----------------------#2019-11-21</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/8322bf43db70c75366f0b88b159de22c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TM_8uoWEpJXNVR94yIsKAQ.jpeg"/></div></div></figure><p id="9dab" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">对土耳其84对(49%)离婚夫妇和86对(51%)已婚夫妇进行了调查。研究人员构建了54个问题，涵盖了基于以下内容的研究中的以下内容:</p><blockquote class="jo jp jq"><p id="8310" class="iq ir jr is b it iu iv iw ix iy iz ja js jc jd je jt jg jh ji ju jk jl jm jn hb bi translated">在这个模型中，合理关系房屋理论中定义的标准是重要的离婚预测因素。模型中最重要的离婚预测是《启示录》中的四骑士。戈特曼将其描述为<strong class="is hj">批评</strong>、<strong class="is hj">蔑视</strong>、<strong class="is hj">蒙混过关</strong>和<strong class="is hj">防御性</strong>(戈特曼，2014；Gottman和Gottman，2012年)</p></blockquote><p id="3578" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">虽然54个研究问题可以在本文的底部找到，但值得一提的是，本文采用的模型发现，其中只有5个问题足以作为离婚的预测因素。每个问题都有不同的几率(影响)作为离婚的预测因素。所有回答都以5分制收集，即(0 =从不，1 =很少，2 =一般，3 =经常，4 =总是)</p><p id="7d28" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这5个问题按影响顺序突出显示如下:</p><ol class=""><li id="6900" class="jv jw hi is b it iu ix iy jb jx jf jy jj jz jn ka kb kc kd bi translated">我们就像两个陌生人，在家里而不是在家里共享同一个环境。离婚夫妇对这个问题做出肯定回答的可能性要高275倍。</li><li id="226e" class="jv jw hi is b it ke ix kf jb kg jf kh jj ki jn ka kb kc kd bi translated">即使我在讨论中是对的，我保持沉默是为了伤害我的配偶。离婚夫妇对这个问题做出肯定回答的可能性要高0.54倍。</li><li id="ebe8" class="jv jw hi is b it ke ix kf jb kg jf kh jj ki jn ka kb kc kd bi translated">我通常保持沉默来让环境平静一点。离婚夫妇对这个问题做出肯定回答的可能性是普通夫妇的3.8倍。</li><li id="c2c3" class="jv jw hi is b it ke ix kf jb kg jf kh jj ki jn ka kb kc kd bi translated">我觉得我们的讨论是对的。离婚夫妇对这个问题做出肯定回答的可能性是T21的3.0倍。</li><li id="1bc5" class="jv jw hi is b it ke ix kf jb kg jf kh jj ki jn ka kb kc kd bi translated">我会毫不犹豫地告诉我的配偶她/他的不足。离婚夫妇对这个问题做出肯定回答的可能性是普通夫妇的3.0倍。</li></ol><p id="78a9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">要访问数据集，使用<a class="ae kj" href="https://archive.ics.uci.edu/ml/datasets/Divorce+Predictors+data+set" rel="noopener ugc nofollow" target="_blank">该链接</a>。</p><h1 id="98a9" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">创建逻辑回归模型的演练</h1><p id="3a77" class="pw-post-body-paragraph iq ir hi is b it li iv iw ix lj iz ja jb lk jd je jf ll jh ji jj lm jl jm jn hb bi translated">简单来说，逻辑回归模型是一个分类器，它将模型中的因变量分为两类。因此，它也被称为二元分类器。</p><figure class="lo lp lq lr fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ln"><img src="../Images/d0ef4d3d7a47e42eaf5ee2c2f480e2c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1340/format:webp/1*4VmxwL8fIIBKiqkWkKfMNg.png"/></div></div><figcaption class="ls lt et er es lu lv bd b be z dx translated">逻辑回归函数，也称为Sigmoid函数，显示0和1之间的概率</figcaption></figure><p id="0104" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">它通过给数据集中的每条记录分配概率(在0和1之间)来做到这一点。通常，所有小于0.5的概率被归入0类，所有大于或等于0.5的概率被归入1类。在这个特定的模型中，0级代表已婚，1级代表离异。</p><p id="d6a8" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，使用该特定数据集开发逻辑回归模型所需的步骤如下:</p><ol class=""><li id="dce8" class="jv jw hi is b it iu ix iy jb jx jf jy jj jz jn ka kb kc kd bi translated">导入必要的库。</li><li id="25a2" class="jv jw hi is b it ke ix kf jb kg jf kh jj ki jn ka kb kc kd bi translated">加载数据集。</li><li id="69da" class="jv jw hi is b it ke ix kf jb kg jf kh jj ki jn ka kb kc kd bi translated">删除缺失值，因为如果有任何缺失值，逻辑回归将会失败。在这个数据集中，没有。</li><li id="1ea6" class="jv jw hi is b it ke ix kf jb kg jf kh jj ki jn ka kb kc kd bi translated">查看数据集。</li><li id="30c7" class="jv jw hi is b it ke ix kf jb kg jf kh jj ki jn ka kb kc kd bi translated">分为训练数据集和测试数据集。</li><li id="97a5" class="jv jw hi is b it ke ix kf jb kg jf kh jj ki jn ka kb kc kd bi translated">分配因变量和自变量。</li><li id="582c" class="jv jw hi is b it ke ix kf jb kg jf kh jj ki jn ka kb kc kd bi translated">使用statsmodel add_constant功能添加常数。</li><li id="01ac" class="jv jw hi is b it ke ix kf jb kg jf kh jj ki jn ka kb kc kd bi translated">运行模型。</li><li id="bc9d" class="jv jw hi is b it ke ix kf jb kg jf kh jj ki jn ka kb kc kd bi translated">估计每个系数的影响。</li><li id="5bc5" class="jv jw hi is b it ke ix kf jb kg jf kh jj ki jn ka kb kc kd bi translated">开发混淆矩阵以使用模型检查准确性</li><li id="809d" class="jv jw hi is b it ke ix kf jb kg jf kh jj ki jn ka kb kc kd bi translated">检查每对预测概率</li><li id="b3b0" class="jv jw hi is b it ke ix kf jb kg jf kh jj ki jn ka kb kc kd bi translated">将预测测试值与实际测试值进行比较</li><li id="32bf" class="jv jw hi is b it ke ix kf jb kg jf kh jj ki jn ka kb kc kd bi translated">输出你的最终结果。</li></ol><p id="6e40" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这是我们深入研究技术内容的部分。系好安全带，伙计们！</p><figure class="lo lp lq lr fd ij"><div class="bz dy l di"><div class="lw lx l"/></div></figure><p id="ff57" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">导入相关库:</p><pre class="lo lp lq lr fd ly lz ma mb aw mc bi"><span id="ed09" class="md kl hi lz b fi me mf l mg mh">#import relevant libraries</span><span id="ddef" class="md kl hi lz b fi mi mf l mg mh">import pandas as pd<br/>import numpy as np<br/>import statsmodels.api as sm</span></pre><p id="2b40" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">将文件读入笔记本:</p><pre class="lo lp lq lr fd ly lz ma mb aw mc bi"><span id="0907" class="md kl hi lz b fi me mf l mg mh">#read file into notebook<br/>import os</span><span id="5c48" class="md kl hi lz b fi mi mf l mg mh">os.chdir(‘C:\\Users\\XXXXX\\Downloads\\divorce’) # Set working directory</span><span id="82a0" class="md kl hi lz b fi mi mf l mg mh">raw_data = pd.read_excel(‘divorce.xlsx’)</span><span id="97f4" class="md kl hi lz b fi mi mf l mg mh">raw_data.head()</span></pre><p id="0603" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">最后一行返回熊猫数据帧的前5列。见下文:</p><figure class="lo lp lq lr fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mj"><img src="../Images/6ebe7d7d7967ead04792724d86236c2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Blxycs7GKPKxg5OtCdHkdA.png"/></div></div><figcaption class="ls lt et er es lu lv bd b be z dx translated">离婚数据集的前5列快照</figcaption></figure><p id="9067" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">使用以下代码创建用于分析的数据集副本:</p><pre class="lo lp lq lr fd ly lz ma mb aw mc bi"><span id="2384" class="md kl hi lz b fi me mf l mg mh">#create copy of Dataset</span><span id="8b82" class="md kl hi lz b fi mi mf l mg mh">data = raw_data.copy()<br/>data.shape</span><span id="efbf" class="md kl hi lz b fi mi mf l mg mh"><strong class="lz hj">Output:<br/>(170, 55)</strong></span></pre><p id="7849" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这个数据集有170行和55列。Class列保存受试者的婚姻状况值，0表示已婚，1表示离异。</p><p id="e491" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，在这一点上，值得一提的是，使用数据集的所有54列来推导逻辑回归将产生以下类型的错误:</p><pre class="lo lp lq lr fd ly lz ma mb aw mc bi"><span id="f82b" class="md kl hi lz b fi me mf l mg mh">“<strong class="lz hj">LinAlgError</strong>: Singular matrix”</span></pre><p id="eb08" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">错误的出现是因为一些独立变量彼此之间有很强的相关性，这就要求分析人员消除这些变量，以得出独立变量中相关性最小的变量。</p><p id="bf8a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了确定我们的主要独立变量，我们删除了Class列，并对所有独立变量运行相关方法。</p><pre class="lo lp lq lr fd ly lz ma mb aw mc bi"><span id="33f3" class="md kl hi lz b fi me mf l mg mh">#declare independent and dependent variables<br/>y = train[‘Class’]<br/>x1 = train.drop(‘Class’, axis=1)</span><span id="b16e" class="md kl hi lz b fi mi mf l mg mh">#Check correlations between independent variables<br/>corr_measure = x1.corr()</span><span id="d5d2" class="md kl hi lz b fi mi mf l mg mh">#Sort values in descending order<br/>corr_measure.loc['Atr1', :].sort_values(ascending=False)</span><span id="6185" class="md kl hi lz b fi mi mf l mg mh">#Read the bottom 10 Records<br/>sorted_df = corr_measure.loc['Atr1', :].sort_values(ascending=False)</span><span id="2c47" class="md kl hi lz b fi mi mf l mg mh">sorted_df.tail(10)</span><span id="c092" class="md kl hi lz b fi mi mf l mg mh"><strong class="lz hj">Output:<br/>Atr42    0.616241<br/>Atr53    0.593598<br/>Atr48    0.593373<br/>Atr47    0.564280<br/>Atr52    0.548976<br/>Atr45    0.518663<br/>Atr43    0.462278<br/>Atr7     0.448927<br/>Atr46    0.393671<br/>Atr6     0.255335<br/>Name: Atr1, dtype: float64</strong></span></pre><p id="3f2f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">相关值通常在-1和1之间是连续的，其中接近-1的值彼此负相关(即彼此相反)，接近1的值彼此正相关(即联合相关)。越接近0的值表示没有相关性。</p><p id="2329" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在本练习中，我从这10列开始，经过几次迭代(为了让读者不至于看不到这篇文章)，我将列减少到5列。重要的剔除标准包括:<strong class="is hj">调查问题之间的相似度</strong>、<strong class="is hj">系数的p值</strong>和<strong class="is hj">模型的总体p值</strong>。</p><p id="69ad" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">选定的列显示在下面的代码中:</p><pre class="lo lp lq lr fd ly lz ma mb aw mc bi"><span id="a136" class="md kl hi lz b fi me mf l mg mh">#create new dataframe using the least homoscedactic variables<br/>new_df = raw_data[[‘Class’,’Atr52', ‘Atr48’, ‘Atr43’, ‘Atr46’, ‘Atr7’]]</span><span id="a8f2" class="md kl hi lz b fi mi mf l mg mh">#randomize the rows of the dataframe<br/>new_df = new_df.sample(frac=1).reset_index(drop=True)</span><span id="d048" class="md kl hi lz b fi mi mf l mg mh"><br/>new_df.head()</span></pre><figure class="lo lp lq lr fd ij er es paragraph-image"><div class="er es mk"><img src="../Images/775cb98e2d8458a10bbfc16de1ca85f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/1*tYy_OhBbWO5gpTzT_OQVgw.png"/></div><figcaption class="ls lt et er es lu lv bd b be z dx translated">具有相关列的新数据框架</figcaption></figure><p id="a7e6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">对于统计爱好者来说，除了相关性方法，你还可以对独立变量进行主成分分析(PCA)或方差膨胀因子，以得出最终的独立变量。为了简单起见，我使用了相关方法。</p><p id="efbd" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">接下来，我们将新的数据框架分成训练和测试数据集，并运行逻辑回归。</p><pre class="lo lp lq lr fd ly lz ma mb aw mc bi"><span id="c94e" class="md kl hi lz b fi me mf l mg mh">#split into train &amp; test datasets</span><span id="ea4b" class="md kl hi lz b fi mi mf l mg mh">new_train = new_df.sample(frac=0.9, random_state=45)<br/>new_test = new_df.drop(new_train.index)</span><span id="1c48" class="md kl hi lz b fi mi mf l mg mh">#Define Independent &amp; Dependent Variables</span><span id="24b7" class="md kl hi lz b fi mi mf l mg mh">x1 = new_train.drop(‘Class’, axis=1)<br/>y = new_train[‘Class’]</span><span id="76e0" class="md kl hi lz b fi mi mf l mg mh">#Add constant and run Regression</span><span id="b60b" class="md kl hi lz b fi mi mf l mg mh">x = sm.add_constant(x1)<br/>reg_log = sm.Logit(y,x)<br/>results_log = reg_log.fit()</span><span id="ae0f" class="md kl hi lz b fi mi mf l mg mh"><strong class="lz hj">Output:<br/>Optimization terminated successfully.<br/>         Current function value: 0.174361<br/>         Iterations 10</strong></span></pre><p id="f3f4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了查看模型的输出，我们在“results_log”上运行一个摘要:</p><pre class="lo lp lq lr fd ly lz ma mb aw mc bi"><span id="0ada" class="md kl hi lz b fi me mf l mg mh">results_log.summary()</span></pre><figure class="lo lp lq lr fd ij er es paragraph-image"><div class="er es ml"><img src="../Images/962582aae1783860e6b3bbec7f92772e.png" data-original-src="https://miro.medium.com/v2/resize:fit:744/format:webp/1*1MvV-sHh8jdPbOT0yJMCNg.png"/></div></figure><p id="11cc" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这为我们提供了模型的概要。伪R平方值明显高于02。-0.4的可接受性阈值，但在数据集上运行的所有模拟中，0.7484是达到的最合适的值。</p><p id="7189" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">此外，LLR p值表明模型足够强大，远低于0.05。</p><p id="1690" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">自变量的系数由Atr(52，48，43，46 &amp; 7)表示。要找出这些变量的影响，必须找出每个变量的指数，如下所示:</p><pre class="lo lp lq lr fd ly lz ma mb aw mc bi"><span id="f5d0" class="md kl hi lz b fi me mf l mg mh">#find the impact of each Variable</span><span id="8649" class="md kl hi lz b fi mi mf l mg mh">Atr52 = np.exp(1.0905)<br/>Atr48 = np.exp(1.1083)<br/>Atr43 = np.exp(1.3371)<br/>Atr46 = np.exp(-0.6117)<br/>Atr7 = np.exp(5.6193)</span><span id="3435" class="md kl hi lz b fi mi mf l mg mh">print(‘I who would not hesitate to tell my spouse about her/his inadequacy increases odds of divorce by: ‘, Atr52 )</span><span id="7fd9" class="md kl hi lz b fi mi mf l mg mh">print(‘I feel right in our discussions increases odds of divorce by: ‘, Atr48 )</span><span id="8b97" class="md kl hi lz b fi mi mf l mg mh">print(‘I mostly stay silent to calm the environment a little bit increases odds of divorce by: ‘, Atr43 )</span><span id="493a" class="md kl hi lz b fi mi mf l mg mh">print(‘Even if I am right in the discussion, I stay silent to hurt my spouse increases odds of divorce by: ‘, Atr46 )</span><span id="220f" class="md kl hi lz b fi mi mf l mg mh">print(‘We are like two strangers who share the same environment at home rather than family increases odds of divorce by: ‘, Atr7</span><span id="b658" class="md kl hi lz b fi mi mf l mg mh"><strong class="lz hj">Output:<br/>I who would not hesitate to tell my spouse about her/his inadequacy increases odds of divorce by:  2.975761581445578</strong></span><span id="116d" class="md kl hi lz b fi mi mf l mg mh"><strong class="lz hj">I feel right in our discussions increases odds of divorce by:  3.029204367329437</strong></span><span id="4985" class="md kl hi lz b fi mi mf l mg mh"><strong class="lz hj">I mostly stay silent to calm the environment a little bit increases odds of divorce by:  3.807984322766186</strong></span><span id="a1db" class="md kl hi lz b fi mi mf l mg mh"><strong class="lz hj">Even if I am right in the discussion, I stay silent to hurt my spouse increases odds of divorce by:  0.5424279572943541</strong></span><span id="063b" class="md kl hi lz b fi mi mf l mg mh"><strong class="lz hj">We are like two strangers who share the same environment at home rather than family increases odds of divorce by:  275.69632824364794</strong></span></pre><h2 id="1321" class="md kl hi bd km mm mn mo kq mp mq mr ku jb ms mt ky jf mu mv lc jj mw mx lg my bi translated">系数分解</h2><p id="d9fc" class="pw-post-body-paragraph iq ir hi is b it li iv iw ix lj iz ja jb lk jd je jf ll jh ji jj lm jl jm jn hb bi translated">从所有迹象来看，报告“感觉彼此陌生”的夫妇离婚的可能性是普通夫妇的275倍。对这个问题做出肯定的回答对一对夫妇来说是一个非常不好的信号。</p><p id="1497" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">该模型还揭示，对“保持沉默以平息环境”做出肯定回应的夫妇离婚的可能性是其他夫妇的3.8倍。</p><p id="00df" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">对“在我们的讨论中感觉正确”做出肯定回答的夫妇离婚的可能性是其他夫妇的3.0倍。</p><p id="c839" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">那些毫不犹豫地告诉配偶他/她的不足之处的夫妇离婚的可能性是其他夫妇的2.9倍。</p><h2 id="c1d4" class="md kl hi bd km mm mn mo kq mp mq mr ku jb ms mt ky jf mu mv lc jj mw mx lg my bi translated">模型精度</h2><p id="2a13" class="pw-post-body-paragraph iq ir hi is b it li iv iw ix lj iz ja jb lk jd je jf ll jh ji jj lm jl jm jn hb bi translated">根据测试数据集测试时，该模型的准确性如何？为了实现这一点，我依赖于statsmodel库的代码转储，它定义了可以在模型上实现的混淆矩阵。</p><p id="a456" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">该函数接受测试数据集的自变量、测试数据集的因变量和建立的初始回归模型。</p><pre class="lo lp lq lr fd ly lz ma mb aw mc bi"><span id="92ec" class="md kl hi lz b fi me mf l mg mh">def confusion_matrix(data,actual_values,model):<br/> <br/> # Confusion matrix <br/> <br/> # Parameters<br/> # — — — — — <br/> # data: data frame or array<br/> # data is a data frame formatted in the same way as your input data (without the actual values)<br/> # e.g. const, var1, var2, etc. Order is very important!<br/> # actual_values: data frame or array<br/> # These are the actual values from the test_data<br/> # In the case of a logistic regression, it should be a single column with 0s and 1s<br/> <br/> # model: a LogitResults object<br/> # this is the variable where you have the fitted model <br/> # e.g. results_log in this course<br/> # — — — — — <br/> <br/> #Predict the values using the Logit model<br/> pred_values = model.predict(data)<br/> # Specify the bins <br/> bins=np.array([0,0.5,1])<br/> # Create a histogram, where if values are between 0 and 0.5 tell will be considered 0<br/> # if they are between 0.5 and 1, they will be considered 1<br/> cm = np.histogram2d(actual_values, pred_values, bins=bins)[0]<br/> # Calculate the accuracy<br/> accuracy = (cm[0,0]+cm[1,1])/cm.sum()<br/> # Return the confusion matrix and <br/> return cm, accuracy</span></pre><p id="2d6a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在我们的训练数据集上实现这一点，我们有:</p><pre class="lo lp lq lr fd ly lz ma mb aw mc bi"><span id="0d08" class="md kl hi lz b fi me mf l mg mh">#prepare test data<br/>x2 = new_test.drop(‘Class’, axis=1)<br/>y1 = new_test[‘Class’]</span><span id="6dfd" class="md kl hi lz b fi mi mf l mg mh">x_test = sm.add_constant(x2)</span><span id="d516" class="md kl hi lz b fi mi mf l mg mh">cm = confusion_matrix(x_test,y1, results_log)<br/>cm</span><span id="a7d8" class="md kl hi lz b fi mi mf l mg mh"><strong class="lz hj">Output:</strong></span><span id="3243" class="md kl hi lz b fi mi mf l mg mh"><strong class="lz hj">(array([[9., 1.],<br/>        [0., 7.]]), 0.9411764705882353)</strong></span></pre><p id="bdd6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">测试该模型显示，该模型准确预测了94%的测试数据集值。显示预测的混淆矩阵如下所示:</p><pre class="lo lp lq lr fd ly lz ma mb aw mc bi"><span id="e9f3" class="md kl hi lz b fi me mf l mg mh">cm_df = pd.DataFrame(cm[0])<br/>cm_df.columns = [‘Predicted Not Divorced’, ‘Predicted Divorced’]<br/>cm_df = cm_df.rename(index={0: ‘Actual Not Divorced’, 1:’Actual Divorced’})<br/>cm_df</span></pre><figure class="lo lp lq lr fd ij er es paragraph-image"><div class="er es mz"><img src="../Images/76512379a4538f5c1bfa0f0326caae4a.png" data-original-src="https://miro.medium.com/v2/resize:fit:728/format:webp/1*ZtOrGHItrZH2n-YQNfbDuQ.png"/></div></figure><p id="6b42" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">一点都不差！</p><p id="4cd3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了确定测试数据集中每对夫妇的离婚概率，我们使用自变量x_test对模型运行预测函数:</p><pre class="lo lp lq lr fd ly lz ma mb aw mc bi"><span id="7fbe" class="md kl hi lz b fi me mf l mg mh">#Test model on test data set</span><span id="a23c" class="md kl hi lz b fi mi mf l mg mh">pred_values1 = results_log.predict(x_test)</span><span id="992f" class="md kl hi lz b fi mi mf l mg mh">#Save predicted values into new dataframe along with the original values</span><span id="c295" class="md kl hi lz b fi mi mf l mg mh">final_df = pd.DataFrame(new_test)<br/>final_df[‘Probability of Divorce’] = pred_values1</span><span id="5201" class="md kl hi lz b fi mi mf l mg mh">#Compare predicted values with actual outcomes</span><span id="ca75" class="md kl hi lz b fi mi mf l mg mh">final_df.sort_values(by=’Class’, ascending=False)</span></pre><p id="7d00" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">嘣！这给了我们一个最终的数据框架，让我们可以看到每对夫妇的离婚概率，以及他们与现实的对比。见下文:</p><figure class="lo lp lq lr fd ij er es paragraph-image"><div class="er es na"><img src="../Images/c271dae0f234000923b7747b32fe7dbb.png" data-original-src="https://miro.medium.com/v2/resize:fit:792/format:webp/1*wHS7O8be9I3oDymq7uHjdg.png"/></div><figcaption class="ls lt et er es lu lv bd b be z dx translated">最终数据帧值</figcaption></figure><p id="51e5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">163号夫妇有0.9999的离婚几率，我想他们已经离婚也就不足为奇了。非常有趣的数据集。</p><p id="9c6e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">逻辑回归有很多应用，但它非常适合分析调查数据，并根据年龄、收入、地点等因素将对象分为两类。这对于分析政治数据和媒体倾向非常有用。</p><p id="8e68" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果你是一个非技术性的读者，并且你做到了这一点，我为你的坚韧而喝彩。我也写一些与地缘政治和经济相关的非技术性文章，请在twitter @the_horoatio上关注我。</p><p id="ef21" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">谢谢你。</p><h2 id="515d" class="md kl hi bd km mm mn mo kq mp mq mr ku jb ms mt ky jf mu mv lc jj mw mx lg my bi translated">夫妻调查的54个问题</h2><p id="36fc" class="pw-post-body-paragraph iq ir hi is b it li iv iw ix lj iz ja jb lk jd je jf ll jh ji jj lm jl jm jn hb bi translated"><strong class="is hj">属性信息:</strong></p><p id="c9a6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">1.当我们的讨论恶化时，如果我们中的一个人道歉，讨论就结束了。<br/> 2。我知道我们可以忽略我们的差异，即使有时事情变得很困难。<br/> 3。当我们需要的时候，我们可以从一开始就和我的配偶讨论并改正它。<br/> 4。当我和我的配偶讨论时，联系他最终会起作用。<br/> 5。我和妻子共度的时光对我们来说很特别。<br/> 6。作为伴侣我们没有时间在家。<br/> 7。我们就像两个陌生人，在家里而不是在家里共享同一个环境。<br/> 8。我喜欢和妻子一起度假。<br/> 9。我喜欢和我的妻子一起旅行。<br/> 10。我们的大多数目标和我的配偶是一样的。<br/> 11。我想，在未来的某一天，当我回首往事，我看到我的配偶和我已经水乳交融。<br/> 12。我和我的配偶在个人自由方面有相似的价值观。<br/> 13。我和我的配偶有相似的娱乐意识。<br/> 14。我们对人的大部分目标(孩子、朋友等。)都一样。<br/> 15。我们和我配偶的梦想是相似而和谐的。<br/> 16。关于爱应该是什么，我们和我的配偶意见一致。<br/> 17。我们和我的配偶对幸福生活有着相同的看法。我和我的配偶对婚姻应该如何有相似的想法。我和我的配偶对婚姻中的角色有相似的想法。我和我的配偶在信任方面有相似的价值观。<br/> 21。我很清楚我妻子喜欢什么。22。我知道我的配偶在生病时希望得到怎样的照顾。<br/> 23。我知道我配偶最喜欢的食物。24。我可以告诉你我的配偶在她的/他的生活中面临着什么样的压力。25。我了解我配偶的内心世界。26。我知道我配偶的基本焦虑。27。我知道我配偶目前的压力来源是什么。28。我知道我配偶的希望和愿望。29。我非常了解我的配偶。三十岁。我了解我配偶的朋友和他们的社会关系。31。当我和我的配偶争论时，我感到咄咄逼人。<br/> 32。当我和我的配偶讨论时，我通常使用“你总是”或“你从不”这样的表达方式。<br/> 33。在我们的讨论中，我可以对我配偶的个性进行负面评价。34。在我们的讨论中，我可以使用攻击性的表达。<br/> 35。我可以在我们讨论的时候侮辱我的配偶。36。当我们讨论的时候，我会很丢脸。37。我和配偶的讨论并不平静。38。我讨厌我配偶打开话题的方式。39。我们的讨论经常突然发生。40。在我知道发生了什么之前，我们只是开始讨论。<br/> 41。当我和我的配偶谈论一些事情时，我的平静会突然打破。<br/> 42。当我和我的配偶争吵时，我只是出去，一句话也不说。<br/> 43。我通常保持沉默来让环境平静一点。<br/> 44。有时候我觉得离开家一段时间对我有好处。<br/> 45。我宁愿保持沉默，也不愿和我的配偶讨论。<br/> 46。即使我在讨论中是对的，我保持沉默是为了伤害我的配偶。<br/> 47。当我和配偶讨论时，我保持沉默，因为我害怕无法控制我的愤怒。<br/> 48。我觉得我们的讨论是对的。<br/> 49。我与我被指控的事无关。<br/>五十。实际上我并不是那个被指控有罪的人。<br/> 51。家里的问题不是我错。52。我会毫不犹豫地告诉我的配偶她/他的不足。<br/> 53。当我讨论时，我会提醒我的配偶她/他的不足。54。我不怕告诉我的配偶她/他的无能。</p><h1 id="a529" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">参考</h1><ul class=""><li id="ee41" class="jv jw hi is b it li ix lj jb nb jf nc jj nd jn ne kb kc kd bi translated">恩特姆、m、阿德姆、k、i̇lhan、t、科尔察斯兰、S. (2019年)。基于相关性特征选择和人工神经网络的离婚预测。nevehir hacebekta Veli大学SBE德尔吉斯，9 (1)，259–273。检索自<a class="ae kj" href="http://dergipark.org.tr/nevsosbilen/issue/46568/549416" rel="noopener ugc nofollow" target="_blank">【网页链接】</a></li><li id="2d4d" class="jv jw hi is b it ke ix kf jb kg jf kh jj ki jn ne kb kc kd bi translated">UCI机器学习知识库</li><li id="e4ce" class="jv jw hi is b it ke ix kf jb kg jf kh jj ki jn ne kb kc kd bi translated">戈特曼，J. M. (2014)。什么预测离婚？婚姻过程和婚姻结果之间的关系。纽约:心理学出版社。</li><li id="1f71" class="jv jw hi is b it ke ix kf jb kg jf kh jj ki jn ne kb kc kd bi translated">Gottman，J. M .和Gottman，J.S. (2012年)。伊夫特勒·阿拉桑达·科普吕·i̇nşa·埃特梅克:戈特曼伊夫·特拉皮西·埃蒂米1。Düzey Kitab，[1级临床培训。戈特曼夫妇疗法。给夫妻带来裂痕。i̇stanbul:·i̇stanbul.</li></ul></div></div>    
</body>
</html>