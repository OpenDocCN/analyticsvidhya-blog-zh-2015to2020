<html>
<head>
<title>New Aspects to consider while moving from Simple Linear Regression to Multiple Linear Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从简单线性回归到多元线性回归时要考虑的新方面</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/new-aspects-to-consider-while-moving-from-simple-linear-regression-to-multiple-linear-regression-dad06b3449ff?source=collection_archive---------6-----------------------#2019-09-19">https://medium.com/analytics-vidhya/new-aspects-to-consider-while-moving-from-simple-linear-regression-to-multiple-linear-regression-dad06b3449ff?source=collection_archive---------6-----------------------#2019-09-19</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/bd1156936f1d69f837c312125ddb05ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1120/format:webp/0*rGSfRsMjiQeG5jof.png"/></div></figure><p id="5c4d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">简单线性回归</strong>:用直线解释因变量和自变量之间关系的最基本模型。然而，在现实生活中，一个独立变量可能不足以解释输出或因变量。</p><p id="1876" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">所以，用多个变量来解释一个因变量可能是个好主意。</p><p id="299d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">优势</strong>:</p><ol class=""><li id="93ed" class="jk jl hi io b ip iq it iu ix jm jb jn jf jo jj jp jq jr js bi translated">添加变量有助于添加关于自变量方差的信息。</li><li id="b217" class="jk jl hi io b ip jt it ju ix jv jb jw jf jx jj jp jq jr js bi translated">一般来说，我们期望解释力随着变量的增加而增加</li></ol><p id="6384" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">因此，这就把我们带到了<strong class="io hj">多元线性回归</strong>，它是简单线性回归的扩展。</p><p id="ead9" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">以下是从单反转向多镜头反光时需要考虑的几个方面:</strong></p><ol class=""><li id="a2de" class="jk jl hi io b ip iq it iu ix jm jb jn jf jo jj jp jq jr js bi translated"><strong class="io hj">过度拟合</strong>:过度拟合是一种建模错误，当一个函数过于接近有限的数据点集合时就会出现这种错误。当我们不断增加模型的变量时，模型可能会“太好地”适应训练集，可能不会很好地概括。这将导致高训练精度、低测试精度，这是过度拟合的典型症状。</li></ol><figure class="jz ka kb kc fd ij er es paragraph-image"><div class="er es jy"><img src="../Images/b65225704b43160395e4332b43bb0110.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*e-l1-2RykjD1HnbdH2xpzg.png"/></div></figure><p id="a326" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj"> 2。多重共线性</strong>:多重共线性是独立变量之间高度相互关联的状态。因此，这是数据中的一种干扰，如果在数据中存在，对数据做出的统计推断可能不可靠。</p><figure class="jz ka kb kc fd ij er es paragraph-image"><div class="er es jy"><img src="../Images/01977a9124900908635392d35a6e39a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*taZmfcxaWHXNEc0L4GJYnA.png"/></div></figure><p id="c8c6" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">多重共线性主要影响:</p><p id="e111" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">1) <strong class="io hj"/></p><p id="393b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">2) <strong class="io hj"> <em class="kd">推论</em> </strong>:</p><p id="f39c" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">a.系数摇摆不定，符号可以颠倒</p><p id="43a5" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">b.因此，p值是不可靠的</p><p id="7798" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj"> <em class="kd">检测多重共线性</em> </strong>:</p><p id="1000" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">以下是检测模型中多重共线性的两种方法；</p><ol class=""><li id="d1db" class="jk jl hi io b ip iq it iu ix jm jb jn jf jo jj jp jq jr js bi translated"><strong class="io hj"> <em class="kd">看自变量之间的成对相关性或相关性:</em> </strong></li></ol><figure class="jz ka kb kc fd ij er es paragraph-image"><div role="button" tabindex="0" class="kf kg di kh bf ki"><div class="er es ke"><img src="../Images/2bc6acaf38755309d9be7e2612477f16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Cf5INlQldwN89wnF.png"/></div></div></figure><p id="cda9" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">变量对中的某些变量可能高度相关，因此，在构建模型时，每对变量中的一个变量对于模型来说可能是多余的。</p><figure class="jz ka kb kc fd ij er es paragraph-image"><div role="button" tabindex="0" class="kf kg di kh bf ki"><div class="er es kj"><img src="../Images/bc05719e687efe83916cf2c6ae24a7b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BUU5g-LJkgVf5MlEB_q85w.png"/></div></div></figure><p id="eb1d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">2.<strong class="io hj"> <em class="kd">检查方差膨胀因子(VIF) </em> : </strong></p><p id="7d81" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">有时两两相关是不够的，也就是说，一个变量可能不能完全解释另一个变量，但是一些变量组合起来就可以解释。基本上，VIF计算一个独立变量被所有其他独立变量组合起来解释的程度。</p><p id="8970" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">VIF通常遵循的启发是:</p><p id="76aa" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">a)VIF值为10的变量被认为是高值，应予以消除。</p><p id="4873" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">b)VIF值为5的变量被认为是可以的，但值得检查。</p><p id="92b0" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">c)不需要消除VIF值小于5变量。</p><p id="7a73" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj"> <em class="kd">如何处理多重共线性</em> : </strong></p><p id="e5d7" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">以下方法可用于处理多重共线性:</p><p id="01da" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">a)删除变量</p><p id="cb12" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">I)丢弃与其他变量高度相关的变量</p><p id="328f" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">ii)选择业务可解释变量</p><p id="d841" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">b)使用旧变量的交互作用创建新变量</p><p id="6d77" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">I)添加交互特征，即使用一些原始的</p><p id="2ffa" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">ii)变量转换</p><p id="c681" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj"> 3) </strong> <strong class="io hj">功能选择:</strong></p><p id="980e" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">以下是最佳特征选择的方法:</p><p id="dfb0" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">一.<strong class="io hj"> <em class="kd">手动特征选择</em> </strong>:</p><p id="a975" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">a)建立具有所有特征的模型</p><p id="8610" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">b)丢弃对预测帮助最小的特征(高p值)</p><p id="8843" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">c)丢弃冗余的特征(使用相关性和VIF)</p><p id="1204" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">d)重建模型并重复</p><p id="2a68" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">二。<strong class="io hj"> <em class="kd">自动特征选择</em> </strong>:</p><p id="652a" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">a)递归特征消除(RFE)</p><p id="4835" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">b)基于AIC的向前/向后/逐步选择</p><p id="4e1b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">通常建议使用自动(粗调)+手动(微调)选择的组合，以获得最佳模型。</p></div></div>    
</body>
</html>