<html>
<head>
<title>Introduction to Apple’s Core ML 3 — Build Deep Learning Models for the iPhone (with code)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">苹果核心ML 3介绍——为iPhone构建深度学习模型(附代码)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/introduction-to-apples-core-ml-3-build-deep-learning-models-for-the-iphone-with-code-509b951674c1?source=collection_archive---------9-----------------------#2019-11-14">https://medium.com/analytics-vidhya/introduction-to-apples-core-ml-3-build-deep-learning-models-for-the-iphone-with-code-509b951674c1?source=collection_archive---------9-----------------------#2019-11-14</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><h1 id="1fb0" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">介绍</h1><blockquote class="jd"><p id="8fc9" class="je jf hi bd jg jh ji jj jk jl jm jn dx translated">想象一下使用最先进的机器学习模型构建惊人应用的能力，而无需了解深入的机器学习。欢迎来到苹果酷睿ML 3！</p></blockquote><p id="98fd" class="pw-post-body-paragraph jp jq hi jr b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl jn hb bi translated">你是一个狂热的苹果粉丝吗？你用iPhone吗？想知道苹果如何使用机器学习和深度学习来驱动其应用程序和软件吗？</p><p id="f209" class="pw-post-body-paragraph jp jq hi jr b js km ju jv jw kn jy jz ka ko kc kd ke kp kg kh ki kq kk kl jn hb bi translated">如果你对这些问题中的任何一个回答“是”——你就有得吃了！因为在本文中，我们将使用深度学习和苹果的Core ML 3为iPhone构建一个应用程序。下面是对该应用程序的快速浏览:</p><figure class="ks kt ku kv fd kw er es paragraph-image"><div class="er es kr"><img src="../Images/bddb4073085292644b671ce9b855d1e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/0*nQPBE8Ox6E0Wclqy.gif"/></div></figure><p id="a947" class="pw-post-body-paragraph jp jq hi jr b js km ju jv jw kn jy jz ka ko kc kd ke kp kg kh ki kq kk kl jn hb bi translated">软件开发人员、程序员，甚至数据科学家都喜欢苹果的人工智能生态系统。近年来，他们已经取得了一些惊人的进展，包括<a class="ae kz" href="https://www.analyticsvidhya.com/blog/2017/09/build-machine-learning-iphone-apple-coreml/" rel="noopener ugc nofollow" target="_blank"> Core ML </a>和我个人最喜欢的——<a class="ae kz" href="https://www.analyticsvidhya.com/blog/2019/10/comprehensive-guide-learn-swift-from-scratch-data-science/?utm_source=blog&amp;utm_medium=introduction-apple-core-ml-3-deep-learning-models-iphone" rel="noopener ugc nofollow" target="_blank">Swift编程语言</a>。</p><p id="edbc" class="pw-post-body-paragraph jp jq hi jr b js km ju jv jw kn jy jz ka ko kc kd ke kp kg kh ki kq kk kl jn hb bi translated">Core ML 3是一个框架，支持iPhone的酷功能，如FaceID、Animoji和增强现实。</p><p id="dc9b" class="pw-post-body-paragraph jp jq hi jr b js km ju jv jw kn jy jz ka ko kc kd ke kp kg kh ki kq kk kl jn hb bi translated"><strong class="jr hj">在本文中，我们将探索推动苹果应用的整个人工智能生态系统，以及如何使用Core ML 3的丰富生态系统，即尖端的预训练、深度学习模型。</strong> <strong class="jr hj"> <em class="la">注:</em> </strong> <em class="la">要理解我们要讲的概念，需要有核心ML的基础知识。我建议</em> <a class="ae kz" href="https://www.analyticsvidhya.com/blog/2017/09/build-machine-learning-iphone-apple-coreml/?utm_source=blog&amp;utm_medium=introduction-apple-core-ml-3-deep-learning-models-iphone" rel="noopener ugc nofollow" target="_blank"> <em class="la">阅读这篇文章</em> </a> <em class="la">可以快速上手。</em></p><h1 id="99e1" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">苹果的人工智能生态系统</h1><p id="aa8a" class="pw-post-body-paragraph jp jq hi jr b js lb ju jv jw lc jy jz ka ld kc kd ke le kg kh ki lf kk kl jn hb bi translated">苹果在构建利用机器学习的工具和框架方面做得很好。构建人工智能应用程序有许多选择，每一种都有自己的优缺点。以下是苹果人工智能生态系统的高级概述:</p><figure class="ks kt ku kv fd kw er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es lg"><img src="../Images/98d7c4e66b313a2ff3136d62aaa1088e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*2Jch5xbv2vPO1dGf.png"/></div></div></figure><p id="3e44" class="pw-post-body-paragraph jp jq hi jr b js km ju jv jw kn jy jz ka ko kc kd ke kp kg kh ki kq kk kl jn hb bi translated">让我们了解一下每个工具或框架。</p><h2 id="5049" class="ll ig hi bd ih lm ln lo il lp lq lr ip ka ls lt it ke lu lv ix ki lw lx jb ly bi translated">1) Turi创建</h2><p id="3ee5" class="pw-post-body-paragraph jp jq hi jr b js lb ju jv jw lc jy jz ka ld kc kd ke le kg kh ki lf kk kl jn hb bi translated">如果您想在应用中添加推荐、物体检测、图像分类、图像相似性或活动分类，这应该是您的首选框架。</p><p id="f4c3" class="pw-post-body-paragraph jp jq hi jr b js km ju jv jw kn jy jz ka ko kc kd ke kp kg kh ki kq kk kl jn hb bi translated">你不需要成为机器学习专家来使用这个工具。为什么？因为它已经为每个任务定义了模型。</p><p id="41ca" class="pw-post-body-paragraph jp jq hi jr b js km ju jv jw kn jy jz ka ko kc kd ke kp kg kh ki kq kk kl jn hb bi translated">我喜欢Turi Create的一点是，我们可以用Python来处理它，就像我们常规的工作流程一样。当我们对我们的模型感到满意时，只需将其导入到Core ML中，以便在iOS、macOS、watchOS和tvOS应用程序中使用！</p><p id="b69b" class="pw-post-body-paragraph jp jq hi jr b js km ju jv jw kn jy jz ka ko kc kd ke kp kg kh ki kq kk kl jn hb bi translated">以下是Turi创建的现成支持的一些任务:</p><figure class="ks kt ku kv fd kw er es paragraph-image"><div class="er es lz"><img src="../Images/8cad96849c19988b6655437490203f39.png" data-original-src="https://miro.medium.com/v2/resize:fit:1342/format:webp/0*45TB_sjDtXv294LX.png"/></div></figure><h2 id="fbeb" class="ll ig hi bd ih lm ln lo il lp lq lr ip ka ls lt it ke lu lv ix ki lw lx jb ly bi translated">2)创建一个</h2><p id="9a92" class="pw-post-body-paragraph jp jq hi jr b js lb ju jv jw lc jy jz ka ld kc kd ke le kg kh ki lf kk kl jn hb bi translated">Create ML让我们不用写太多代码就能建立机器学习模型。</p><p id="276f" class="pw-post-body-paragraph jp jq hi jr b js km ju jv jw kn jy jz ka ko kc kd ke kp kg kh ki kq kk kl jn hb bi translated">我喜欢这个工具的一点是，你可以拖放你的训练数据，然后选择你想要的模型(语音识别、物体检测等)。)而且它会自动开始训练模型！</p><p id="c94a" class="pw-post-body-paragraph jp jq hi jr b js km ju jv jw kn jy jz ka ko kc kd ke kp kg kh ki kq kk kl jn hb bi translated">下面是一个训练猫和狗图像分类器的例子:</p><figure class="ks kt ku kv fd kw er es paragraph-image"><div class="er es kr"><img src="../Images/700d74f02c2f8a85f97442d867d86aa4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/0*0397qHjiFzK6PHYv.gif"/></div></figure><p id="9d6e" class="pw-post-body-paragraph jp jq hi jr b js km ju jv jw kn jy jz ka ko kc kd ke kp kg kh ki kq kk kl jn hb bi translated">请注意，我只编写了两行代码，并拖放了training data文件夹——其余的由CreateML处理！</p><p id="5715" class="pw-post-body-paragraph jp jq hi jr b js km ju jv jw kn jy jz ka ko kc kd ke kp kg kh ki kq kk kl jn hb bi translated">虽然Turi Create在Python中工作，但我们可以使用CreateML在Mac上构建。是的，它支持在GPU上训练(耶！).</p><h2 id="f8b1" class="ll ig hi bd ih lm ln lo il lp lq lr ip ka ls lt it ke lu lv ix ki lw lx jb ly bi translated">3)用于TensorFlow的Swift</h2><p id="57d7" class="pw-post-body-paragraph jp jq hi jr b js lb ju jv jw lc jy jz ka ld kc kd ke le kg kh ki lf kk kl jn hb bi translated">Swift for TensorFlow拥有灵活、高性能的TensorFlow/PyTorch类API，可用于构建复杂的神经网络架构。</p><p id="8897" class="pw-post-body-paragraph jp jq hi jr b js km ju jv jw kn jy jz ka ko kc kd ke kp kg kh ki kq kk kl jn hb bi translated">这个框架最吸引人的地方是它的代码和Python的一样易读。以下是Swift和Python中相同的模型代码(注意相似之处):</p><figure class="ks kt ku kv fd kw er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es ma"><img src="../Images/3c169ab1fc0f5f64624aee02e0962979.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*sRpfd6_g8w8ujFCl.png"/></div></div></figure><p id="dc86" class="pw-post-body-paragraph jp jq hi jr b js km ju jv jw kn jy jz ka ko kc kd ke kp kg kh ki kq kk kl jn hb bi translated">当您需要模型的高性能并希望有效部署时，请使用Swift for TensorFlow。你可以在本文中了解如何使用Swift for TensorFlow构建<a class="ae kz" href="https://www.analyticsvidhya.com/blog/2019/10/comprehensive-guide-learn-swift-from-scratch-data-science/?utm_source=blog&amp;utm_medium=introduction-apple-core-ml-3-deep-learning-models-iphone" rel="noopener ugc nofollow" target="_blank">深度学习模型。</a></p><h2 id="cad3" class="ll ig hi bd ih lm ln lo il lp lq lr ip ka ls lt it ke lu lv ix ki lw lx jb ly bi translated">4)语言和愿景框架</h2><p id="9cc9" class="pw-post-body-paragraph jp jq hi jr b js lb ju jv jw lc jy jz ka ld kc kd ke le kg kh ki lf kk kl jn hb bi translated">这些是苹果公司的Python的spaCy和OpenCV框架，但增加了功能。这些框架让我们能够创建端到端的管道，用于执行图像处理和文本处理等。</p><p id="f9d5" class="pw-post-body-paragraph jp jq hi jr b js km ju jv jw kn jy jz ka ko kc kd ke kp kg kh ki kq kk kl jn hb bi translated">如果您想执行图像分析任务，如人脸或地标检测、文本检测、条形码识别、图像配准和一般特征跟踪，那么<strong class="jr hj">视觉适合您</strong>。</p><figure class="ks kt ku kv fd kw er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es mb"><img src="../Images/8fd79a3855df0fb48763d18af99aa79a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*zmxDsAEPgxfAo3nP.png"/></div></div></figure><p id="42e2" class="pw-post-body-paragraph jp jq hi jr b js km ju jv jw kn jy jz ka ko kc kd ke kp kg kh ki kq kk kl jn hb bi translated">类似地，如果你想执行诸如语言和文字识别、标记化、词汇化、词性标注和命名实体识别之类的任务，那么<strong class="jr hj">语言</strong>将会派上用场。</p><figure class="ks kt ku kv fd kw er es paragraph-image"><div class="er es mc"><img src="../Images/5223694e58ad7b76e09f4231971bc1ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:692/format:webp/0*EdGSR2H9u4Ka8hZE.png"/></div></figure><p id="9e70" class="pw-post-body-paragraph jp jq hi jr b js km ju jv jw kn jy jz ka ko kc kd ke kp kg kh ki kq kk kl jn hb bi translated">除了这两个，苹果还支持处理语音数据的框架(它们很容易与CoreML一起工作)。我将在接下来的文章中介绍这些工具。现在，让我们来看看这个节目的亮点——Core ML 3！</p><h1 id="f5ea" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">进入核心ML 3</h1><p id="fb30" class="pw-post-body-paragraph jp jq hi jr b js lb ju jv jw lc jy jz ka ld kc kd ke le kg kh ki lf kk kl jn hb bi translated">我爱苹果的核心ML 3框架。它不仅支持我们上面看到的工具，还支持它自己的一些特性。</p><p id="ea41" class="pw-post-body-paragraph jp jq hi jr b js km ju jv jw kn jy jz ka ko kc kd ke kp kg kh ki kq kk kl jn hb bi translated">首先，CoreML3允许我们从所有主要的Python框架中导入经过训练的机器学习或深度学习模型:</p><figure class="ks kt ku kv fd kw er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es md"><img src="../Images/858619b0c7155d6e8330f2a9fd18beb8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*WI1AUEeheSNHd5q0.png"/></div></div></figure><p id="4256" class="pw-post-body-paragraph jp jq hi jr b js km ju jv jw kn jy jz ka ko kc kd ke kp kg kh ki kq kk kl jn hb bi translated">在我上面链接的一篇文章中，我们已经介绍了Core ML 3的这个特性。在这里，我们将看到CoreML3的另一个有趣的特性——我们如何利用Core ML 3现在支持的大量前沿预训练模型！</p><p id="8643" class="pw-post-body-paragraph jp jq hi jr b js km ju jv jw kn jy jz ka ko kc kd ke kp kg kh ki kq kk kl jn hb bi translated">以下是Core ML 3支持的型号列表。请注意，其中一些(如Squeezenet、DeeplabV3、YOLOv3)太新了，几个月前才刚刚推出:</p><figure class="ks kt ku kv fd kw er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es me"><img src="../Images/310492b4c40e6cfeba896ad498d9badf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Frtn891EMMrVX1Gy.png"/></div></div></figure><p id="2af9" class="pw-post-body-paragraph jp jq hi jr b js km ju jv jw kn jy jz ka ko kc kd ke kp kg kh ki kq kk kl jn hb bi translated">所有这些型号实际上都经过优化，可以在移动设备、平板电脑和电脑上提供最佳性能。这就是苹果的伟大之处。</p><p id="5cc3" class="pw-post-body-paragraph jp jq hi jr b js km ju jv jw kn jy jz ka ko kc kd ke kp kg kh ki kq kk kl jn hb bi translated">这意味着即使其中许多是复杂的基于深度学习的模型，我们也不必太担心在我们的应用程序中部署和使用它们时的性能——这多酷啊？</p><h1 id="3e63" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">Core ML 3 —有什么变化？</h1><p id="4497" class="pw-post-body-paragraph jp jq hi jr b js lb ju jv jw lc jy jz ka ld kc kd ke le kg kh ki lf kk kl jn hb bi translated">你看了今年的WWDC会议吗？关于Core ML 3和苹果设备对该框架的支持，有一些有趣的公告。如果你错过了，这里有一个快速总结。</p><h1 id="18c0" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">1)设备上的培训</h1><p id="8b39" class="pw-post-body-paragraph jp jq hi jr b js lb ju jv jw lc jy jz ka ld kc kd ke le kg kh ki lf kk kl jn hb bi translated">这是Core ML 3目前为止最大的亮点。到目前为止，我们只有“在设备上推断”的支持。这基本上意味着我们在其他机器上训练我们的模型，然后利用训练好的模型在设备本身上进行实时预测。这带来了更好的用户体验，因为我们不依赖互联网来获得预测。</p><blockquote class="jd"><p id="4ae6" class="je jf hi bd jg jh ji jj jk jl jm jn dx translated">Core ML 3现在也支持设备上的训练！你可以使用iPhone的CPU、GPU和神经引擎来训练你的机器学习和深度学习模型。</p></blockquote><p id="6bac" class="pw-post-body-paragraph jp jq hi jr b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl jn hb bi translated">你可以将核心ML 3培训视为一种形式的<strong class="jr hj">转移学习</strong>或<strong class="jr hj">在线</strong>学习，在这种情况下，你只需调整现有的模式。</p><p id="9fa3" class="pw-post-body-paragraph jp jq hi jr b js km ju jv jw kn jy jz ka ko kc kd ke kp kg kh ki kq kk kl jn hb bi translated">以Face ID为例。当用户的脸随着时间的推移发生变化时(长胡子、化不同的妆、变老等)，它需要保持其模型的更新。).基本的想法是最初有一个通用的模型，给出每个人的平均性能，然后为每个用户定制一个副本。</p><p id="621e" class="pw-post-body-paragraph jp jq hi jr b js km ju jv jw kn jy jz ka ko kc kd ke kp kg kh ki kq kk kl jn hb bi translated">随着时间的推移，这种模式将变得非常适合特定用户:</p><figure class="ks kt ku kv fd kw er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es mf"><img src="../Images/98bcbf16a420f70e4f5d7b8cda618ff7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*pyxzgKaNlG3NTFqq.png"/></div></div></figure><p id="9c35" class="pw-post-body-paragraph jp jq hi jr b js km ju jv jw kn jy jz ka ko kc kd ke kp kg kh ki kq kk kl jn hb bi translated">这有多种好处:</p><ol class=""><li id="73fa" class="mg mh hi jr b js km jw kn ka mi ke mj ki mk jn ml mm mn mo bi translated">培训将在用户的个人设备上进行，这意味着用户的<strong class="jr hj">高数据隐私</strong></li><li id="21da" class="mg mh hi jr b js mp jw mq ka mr ke ms ki mt jn ml mm mn mo bi translated">我们<strong class="jr hj">不需要建立庞大的服务器</strong>来方便数百万应用用户的模型训练</li><li id="b28d" class="mg mh hi jr b js mp jw mq ka mr ke ms ki mt jn ml mm mn mo bi translated">因为不涉及互联网，所以<strong class="jr hj">模型将总是可用于</strong>预测！</li></ol><h1 id="9670" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">2)在核心ML 3中增加了新类型的神经网络层</h1><figure class="ks kt ku kv fd kw er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es ca"><img src="../Images/87e5d485988818e391d64697847a7cde.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*3QehNbQyE0UCGlx5.png"/></div></div></figure><p id="68aa" class="pw-post-body-paragraph jp jq hi jr b js km ju jv jw kn jy jz ka ko kc kd ke kp kg kh ki kq kk kl jn hb bi translated">除了拥有不同模型类型的层，Core ML 3还拥有100+层用于中间操作，如掩蔽、张量操作、布尔逻辑、控制流等。</p><blockquote class="jd"><p id="ca31" class="je jf hi bd jg jh ji jj jk jl jm jn dx translated">这些层类型中的一些被用在最先进的神经网络架构中，Core ML 3已经为我们提供了支持。</p></blockquote><p id="baab" class="pw-post-body-paragraph jp jq hi jr b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl jn hb bi translated">这仅仅意味着我们可以轻松地为我们的应用程序立即构建这样的模型。</p><p id="d705" class="pw-post-body-paragraph jp jq hi jr b js km ju jv jw kn jy jz ka ko kc kd ke kp kg kh ki kq kk kl jn hb bi translated">如果你对整个套餐感兴趣，请随意<a class="ae kz" href="https://developer.apple.com/videos/play/wwdc2019/704/" rel="noopener ugc nofollow" target="_blank">观看整个WWDC视频</a>。出于本文的目的，我们已经介绍了核心ML 3的核心基础知识。现在是时候构建一个iPhone应用程序了！</p><h1 id="9675" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">为iPhone构建一个图像分类应用程序</h1><p id="c641" class="pw-post-body-paragraph jp jq hi jr b js lb ju jv jw lc jy jz ka ld kc kd ke le kg kh ki lf kk kl jn hb bi translated">在我们开始构建我们的应用程序之前，我们需要安装一些东西。</p><h2 id="be65" class="ll ig hi bd ih lm ln lo il lp lq lr ip ka ls lt it ke lu lv ix ki lw lx jb ly bi translated">系统设置</h2><ol class=""><li id="3b2d" class="mg mh hi jr b js lb jw lc ka mu ke mv ki mw jn ml mm mn mo bi translated"><strong class="jr hj"> macOS: </strong>我用的是macOS Catalina (10.15.1)</li><li id="fc2a" class="mg mh hi jr b js mp jw mq ka mr ke ms ki mt jn ml mm mn mo bi translated">Xcode: 这是用于为苹果设备构建应用的默认软件。您可以从Mac上的App Store下载它。我用的是11.2版本</li><li id="fc6e" class="mg mh hi jr b js mp jw mq ka mr ke ms ki mt jn ml mm mn mo bi translated"><strong class="jr hj">项目:</strong>您可以在终端中使用以下命令从GitHub下载项目的基础代码:</li></ol><pre class="ks kt ku kv fd mx my mz na aw nb bi"><span id="40b2" class="ll ig hi my b fi nc nd l ne nf">git clone <a class="ae kz" href="https://github.com/mohdsanadzakirizvi/CoreML3-Resnet50.git" rel="noopener ugc nofollow" target="_blank">https://github.com/mohdsanadzakirizvi/CoreML3-Resnet50.git</a></span></pre><ol class=""><li id="f293" class="mg mh hi jr b js km jw kn ka mi ke mj ki mk jn ml mm mn mo bi translated"><em class="la">对于本文，您需要一台macOS机器，否则您将无法实现项目</em></li><li id="4f0f" class="mg mh hi jr b js mp jw mq ka mr ke ms ki mt jn ml mm mn mo bi translated"><em class="la">任何为苹果设备开发的应用程序都是用</em> <a class="ae kz" href="https://developer.apple.com/swift/" rel="noopener ugc nofollow" target="_blank"> <em class="la"> Swift </em> </a>编写的</li><li id="2e74" class="mg mh hi jr b js mp jw mq ka mr ke ms ki mt jn ml mm mn mo bi translated"><em class="la">本教程不需要学习Swift。但是如果它引起了你的兴趣，你可以在这里</em> <a class="ae kz" href="https://www.analyticsvidhya.com/blog/2019/10/comprehensive-guide-learn-swift-from-scratch-data-science/" rel="noopener ugc nofollow" target="_blank"> <em class="la">学习它</em> </a></li></ol><h2 id="c45b" class="ll ig hi bd ih lm ln lo il lp lq lr ip ka ls lt it ke lu lv ix ki lw lx jb ly bi translated">构建我们的深度学习模型</h2><p id="1a09" class="pw-post-body-paragraph jp jq hi jr b js lb ju jv jw lc jy jz ka ld kc kd ke le kg kh ki lf kk kl jn hb bi translated">下载项目后，您会看到有两个文件夹:</p><figure class="ks kt ku kv fd kw er es paragraph-image"><div class="er es ng"><img src="../Images/617200e7b5870d9fb851aaef158f56d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:736/format:webp/0*oN_FKmPrhU0OMTmG.png"/></div></figure><p id="fd02" class="pw-post-body-paragraph jp jq hi jr b js km ju jv jw kn jy jz ka ko kc kd ke kp kg kh ki kq kk kl jn hb bi translated">完整版是该应用程序的全功能版本，只需导入ResNet50模型即可运行。练习版缺少一些代码，您可以使用它们来阅读本文。</p><p id="0064" class="pw-post-body-paragraph jp jq hi jr b js km ju jv jw kn jy jz ka ko kc kd ke kp kg kh ki kq kk kl jn hb bi translated">运行以下命令在Xcode中打开项目:</p><pre class="ks kt ku kv fd mx my mz na aw nb bi"><span id="2d22" class="ll ig hi my b fi nc nd l ne nf">open ImageClassifier.xcodeproj</span></pre><figure class="ks kt ku kv fd kw er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es nh"><img src="../Images/fa10f8328b72209cebe0d5e1db0c74ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*mpS8JxXW-StDw3VU.png"/></div></div></figure><p id="9df6" class="pw-post-body-paragraph jp jq hi jr b js km ju jv jw kn jy jz ka ko kc kd ke kp kg kh ki kq kk kl jn hb bi translated">我在Xcode窗口中突出显示了三个主要区域:</p><ol class=""><li id="00e6" class="mg mh hi jr b js km jw kn ka mi ke mj ki mk jn ml mm mn mo bi translated">左上角可见的播放按钮用于<strong class="jr hj">启动模拟器上的应用程序</strong></li><li id="c63d" class="mg mh hi jr b js mp jw mq ka mr ke ms ki mt jn ml mm mn mo bi translated">如果你看播放按钮下面，有我们项目的文件和文件夹。这被称为<strong class="jr hj">项目导航器。它帮助我们在项目的文件和文件夹之间导航</strong></li><li id="50bb" class="mg mh hi jr b js mp jw mq ka mr ke ms ki mt jn ml mm mn mo bi translated">播放键旁边写着iPhone 11 Pro Max。这表示您想要测试模拟器的目标设备</li></ol><p id="26ac" class="pw-post-body-paragraph jp jq hi jr b js km ju jv jw kn jy jz ka ko kc kd ke kp kg kh ki kq kk kl jn hb bi translated">让我们首先运行我们的应用程序，看看会发生什么。点击左上角的播放按钮，将运行模拟器。</p><p id="c1b1" class="pw-post-body-paragraph jp jq hi jr b js km ju jv jw kn jy jz ka ko kc kd ke kp kg kh ki kq kk kl jn hb bi translated">你看到了什么？</p><figure class="ks kt ku kv fd kw er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es ni"><img src="../Images/cfba504b9da27be98c4b0a96e3724e23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*bU_yEjNW9--aEJsj.png"/></div></div></figure><p id="986c" class="pw-post-body-paragraph jp jq hi jr b js km ju jv jw kn jy jz ka ko kc kd ke kp kg kh ki kq kk kl jn hb bi translated">就目前而言，我们的应用程序做得不多。它只显示一个图像和一个选择其他图像的按钮——让我们做得更好！</p><p id="0b28" class="pw-post-body-paragraph jp jq hi jr b js km ju jv jw kn jy jz ka ko kc kd ke kp kg kh ki kq kk kl jn hb bi translated">如果打开练习版，您会发现以下文件夹结构:</p><figure class="ks kt ku kv fd kw er es paragraph-image"><div class="er es nj"><img src="../Images/978cc7904f71b42e16fc1d010922b556.png" data-original-src="https://miro.medium.com/v2/resize:fit:534/format:webp/0*W0z3LiOW_XUYxZOa.png"/></div></figure><p id="8307" class="pw-post-body-paragraph jp jq hi jr b js km ju jv jw kn jy jz ka ko kc kd ke kp kg kh ki kq kk kl jn hb bi translated">在项目导航器窗格中，选择<strong class="jr hj"> ViewController.swift </strong>。这个文件包含了控制我们应用程序功能的大部分代码。以下是您将看到的内容:</p><figure class="ks kt ku kv fd kw"><div class="bz dy l di"><div class="nk nl l"/></div></figure><p id="226b" class="pw-post-body-paragraph jp jq hi jr b js km ju jv jw kn jy jz ka ko kc kd ke kp kg kh ki kq kk kl jn hb bi translated">现在你已经熟悉了Xcode和项目代码文件，让我们进入下一个阶段。</p><h2 id="19d3" class="ll ig hi bd ih lm ln lo il lp lq lr ip ka ls lt it ke lu lv ix ki lw lx jb ly bi translated">将预训练模型添加到我们的应用中</h2><p id="5384" class="pw-post-body-paragraph jp jq hi jr b js lb ju jv jw lc jy jz ka ld kc kd ke le kg kh ki lf kk kl jn hb bi translated">前往官方Core ML 3网站直接下载预先训练的模型:</p><pre class="ks kt ku kv fd mx my mz na aw nb bi"><span id="8820" class="ll ig hi my b fi nc nd l ne nf"><a class="ae kz" href="https://developer.apple.com/machine-learning/models/" rel="noopener ugc nofollow" target="_blank">https://developer.apple.com/machine-learning/models/</a></span></pre><p id="690a" class="pw-post-body-paragraph jp jq hi jr b js km ju jv jw kn jy jz ka ko kc kd ke kp kg kh ki kq kk kl jn hb bi translated">在图像部分，您会发现ResNet50型号:</p><figure class="ks kt ku kv fd kw er es paragraph-image"><div class="er es nm"><img src="../Images/c231849fec641775dd336f016607d9ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1388/format:webp/0*Mt596XuB-Y2jyPlS.png"/></div></figure><p id="1ed9" class="pw-post-body-paragraph jp jq hi jr b js km ju jv jw kn jy jz ka ko kc kd ke kp kg kh ki kq kk kl jn hb bi translated">你可以下载任何你想要的版本。尺寸越大，模型就越精确。同样，尺寸越小，模型的速度越快。</p><ul class=""><li id="9447" class="mg mh hi jr b js km jw kn ka mi ke mj ki mk jn nn mm mn mo bi translated">将您的<strong class="jr hj"> Resnet50.mlmodel </strong>文件拖到项目导航器窗格的Xcode窗口中</li><li id="adbc" class="mg mh hi jr b js mp jw mq ka mr ke ms ki mt jn nn mm mn mo bi translated">将弹出一个带有一些选项的窗口。保留默认选项，点击<strong class="jr hj">【完成】</strong></li><li id="0d8d" class="mg mh hi jr b js mp jw mq ka mr ke ms ki mt jn nn mm mn mo bi translated">当我们将这样的文件拖到Xcode中时，它会自动在项目中创建对该文件的引用。这样，我们可以在代码中轻松访问该文件</li></ul><p id="0b90" class="pw-post-body-paragraph jp jq hi jr b js km ju jv jw kn jy jz ka ko kc kd ke kp kg kh ki kq kk kl jn hb bi translated">以下是整个过程供参考:</p><figure class="ks kt ku kv fd kw er es paragraph-image"><div class="er es kr"><img src="../Images/aaae79d51719ed56e51a47a0e1890cab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/0*bY6dYxyHolFmgQ4i.gif"/></div></figure><h2 id="ef23" class="ll ig hi bd ih lm ln lo il lp lq lr ip ka ls lt it ke lu lv ix ki lw lx jb ly bi translated">做出第一个预测</h2><p id="91b1" class="pw-post-body-paragraph jp jq hi jr b js lb ju jv jw lc jy jz ka ld kc kd ke le kg kh ki lf kk kl jn hb bi translated">为了进行我们的第一个预测，我们需要加载我们刚刚下载的ResNet50模型。然后，拍摄一张图像，将其转换为模型期望的格式，并进行预测。</p><p id="efad" class="pw-post-body-paragraph jp jq hi jr b js km ju jv jw kn jy jz ka ko kc kd ke kp kg kh ki kq kk kl jn hb bi translated">在<em class="la"> ViewController.swift </em>文件中的IBActions(第33行)下编写以下代码:</p><figure class="ks kt ku kv fd kw"><div class="bz dy l di"><div class="nk nl l"/></div></figure><p id="7068" class="pw-post-body-paragraph jp jq hi jr b js km ju jv jw kn jy jz ka ko kc kd ke kp kg kh ki kq kk kl jn hb bi translated">上面的代码基本上接受一个新的图像，根据ResNet50期望的格式对其进行预处理，并将其传递到网络中进行预测。</p><p id="2906" class="pw-post-body-paragraph jp jq hi jr b js km ju jv jw kn jy jz ka ko kc kd ke kp kg kh ki kq kk kl jn hb bi translated">最重要的代码行是:</p><pre class="ks kt ku kv fd mx my mz na aw nb bi"><span id="f222" class="ll ig hi my b fi nc nd l ne nf">// Load the ML model through its generated class </span><span id="bf34" class="ll ig hi my b fi no nd l ne nf">guard let model = try? VNCoreMLModel(for:<strong class="my hj">Resnet50().model</strong>) else { fatalError("can't load Places ML model") }</span></pre><p id="9a8c" class="pw-post-body-paragraph jp jq hi jr b js km ju jv jw kn jy jz ka ko kc kd ke kp kg kh ki kq kk kl jn hb bi translated">我们在这里设置模型名称。<strong class="jr hj">如果你想使用像伯特或YOLO这样的框架，你只需要修改模型名称，你的应用程序的其余部分就会顺利工作。</strong></p><p id="2060" class="pw-post-body-paragraph jp jq hi jr b js km ju jv jw kn jy jz ka ko kc kd ke kp kg kh ki kq kk kl jn hb bi translated">现在，我们需要调用这个函数<strong class="jr hj"> imageClassify() </strong>来获得对图像的预测。将下面这段代码添加到<strong class="jr hj"> viewDidLoad()(第19行)</strong>的末尾:</p><figure class="ks kt ku kv fd kw"><div class="bz dy l di"><div class="nk nl l"/></div></figure><p id="06c1" class="pw-post-body-paragraph jp jq hi jr b js km ju jv jw kn jy jz ka ko kc kd ke kp kg kh ki kq kk kl jn hb bi translated">现在，如果你运行应用程序，你会看到它已经开始对应用程序启动时显示的风景图片进行预测:</p><figure class="ks kt ku kv fd kw er es paragraph-image"><div class="er es np"><img src="../Images/7bfcb77c5211a003a054e80e23b31921.png" data-original-src="https://miro.medium.com/v2/resize:fit:426/format:webp/0*qHK6P9pOtTtZ6UnL.png"/></div></figure><p id="f773" class="pw-post-body-paragraph jp jq hi jr b js km ju jv jw kn jy jz ka ko kc kd ke kp kg kh ki kq kk kl jn hb bi translated">在<strong class="jr hj"> imagePickerController()(第87行)</strong>中复制相同的代码，然后应用程序将能够对您选择的任何图像做出相同的预测。</p><p id="2b5a" class="pw-post-body-paragraph jp jq hi jr b js km ju jv jw kn jy jz ka ko kc kd ke kp kg kh ki kq kk kl jn hb bi translated">这是该应用程序的最终版本:</p><figure class="ks kt ku kv fd kw er es paragraph-image"><div class="er es kr"><img src="../Images/becd69fb5a9980c8bb376cb4e0629f9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/0*x6JFoqmcbJPJH-yo.gif"/></div></figure><p id="bf9d" class="pw-post-body-paragraph jp jq hi jr b js km ju jv jw kn jy jz ka ko kc kd ke kp kg kh ki kq kk kl jn hb bi translated">恭喜——你刚刚为iPhone构建了你的第一个人工智能应用程序！</p><h1 id="ad3f" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">分析Vidhya对核心ML 3的看法</h1><p id="46f5" class="pw-post-body-paragraph jp jq hi jr b js lb ju jv jw lc jy jz ka ld kc kd ke le kg kh ki lf kk kl jn hb bi translated">苹果无疑已经利用所有最新的图像、语音和文本人工智能研究，轻松创建令人印象深刻的应用程序。您可以在没有太多这些模型知识的情况下立即开始，并在途中学习和探索。</p><p id="12cb" class="pw-post-body-paragraph jp jq hi jr b js km ju jv jw kn jy jz ka ko kc kd ke kp kg kh ki kq kk kl jn hb bi translated">我喜欢这个事实，即行业正在认真对待人工智能，他们希望让它非常容易被更广泛的受众所接受。</p><p id="8812" class="pw-post-body-paragraph jp jq hi jr b js km ju jv jw kn jy jz ka ko kc kd ke kp kg kh ki kq kk kl jn hb bi translated">我鼓励你进一步探索和尝试像BERT这样的最新模型，并创建更多有趣的应用程序。如果有的话，你可以在我们这里制作的同一个应用程序上尝试SqueezeNet和MobileNet，看看不同的模型在相同的图像上表现如何。</p><p id="02fe" class="pw-post-body-paragraph jp jq hi jr b js km ju jv jw kn jy jz ka ko kc kd ke kp kg kh ki kq kk kl jn hb bi translated">本文使用的所有代码<a class="ae kz" href="https://github.com/mohdsanadzakirizvi/CoreML3-Resnet50" rel="noopener ugc nofollow" target="_blank">都可以在Github </a>上获得。您可以在下面的评论区留下您的问题、建议和反馈。</p></div><div class="ab cl nq nr gp ns" role="separator"><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv"/></div><div class="hb hc hd he hf"><p id="8fa6" class="pw-post-body-paragraph jp jq hi jr b js km ju jv jw kn jy jz ka ko kc kd ke kp kg kh ki kq kk kl jn hb bi translated"><em class="la">原载于2019年11月14日</em><a class="ae kz" href="https://www.analyticsvidhya.com/blog/2019/11/introduction-apple-core-ml-3-deep-learning-models-iphone/" rel="noopener ugc nofollow" target="_blank"><em class="la">【https://www.analyticsvidhya.com】</em></a><em class="la">。</em></p></div></div>    
</body>
</html>