<html>
<head>
<title>Face Key Point Detection Using Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于深度学习的人脸关键点检测</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/face-key-point-detection-using-deep-learning-f965ab673b93?source=collection_archive---------13-----------------------#2020-07-16">https://medium.com/analytics-vidhya/face-key-point-detection-using-deep-learning-f965ab673b93?source=collection_archive---------13-----------------------#2020-07-16</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/9c7a1b2e58e36fa063ab9091e7d5a73b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ff2mTNqtwjimizZhJn15Ig.png"/></div></div></figure><h1 id="6d7b" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated"><strong class="ak"> 1。简介</strong></h1><p id="9281" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">这篇文章主要讲的是深度学习方法寻找面部关键点。在这项工作中，我们基本上找到了15个要点。这包括..</p><p id="f0a3" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated"><strong class="jq hj">眼睛</strong>:左眼中心，右眼中心，左眼内眼角，左眼外眼角，右眼内眼角，右眼外眼角。</p><p id="dc66" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated"><strong class="jq hj">眉毛</strong>:左眉内、左眉外、右眉内、右眉外。</p><p id="f200" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated"><strong class="jq hj">鼻尖</strong>:鼻尖。</p><p id="721c" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated"><strong class="jq hj">嘴</strong>:嘴左角，嘴右角，嘴中上，嘴中下。</p><p id="07a9" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">这可以用于许多应用，例如生物计量/面部识别、分析面部表情、跟踪图像和视频中的面部以及检测用于医疗诊断的面部体征。</p><h1 id="d462" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated"><strong class="ak"> 2。数据集</strong></h1><p id="f012" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">我们使用来自kaggle的<a class="ae kr" href="https://www.kaggle.com/c/facial-keypoints-detection/overview" rel="noopener ugc nofollow" target="_blank">面部关键点检测</a>数据集。训练数据中有7094幅图像。该数据集包含关键点的x和y坐标(30个字段)，最后一个字段(图像)由空格分隔的整数像素(0–255)组成。这些图像是96 x 96像素。</p><p id="2d52" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">让我们加载数据集..</p><p id="c181" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">首先pip安装kaggle直接加载数据。(这个项目我用的是google colab)</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="618e" class="lb ir hi kx b fi lc ld l le lf"># Install Kaggle API<br/>!pip install -q kaggle</span></pre><p id="ac6a" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">现在登录你的kaggel帐户并下载。包含kaggle用户名和密钥的json文件(只有当您想要将数据集直接下载到您的colab文件中或者只是直接下载和使用数据时，才使用这一步)</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="bbe4" class="lb ir hi kx b fi lc ld l le lf"># fill in xxxxx, see your kaggle.json</span><span id="e8e6" class="lb ir hi kx b fi lg ld l le lf">import os<br/>os.environ['KAGGLE_USERNAME'] = "xxxxx"<br/>os.environ['KAGGLE_KEY'] = "xxxxx"</span><span id="4083" class="lb ir hi kx b fi lg ld l le lf"># download data from Kaggle<br/>!kaggle competitions download -c facial-keypoints-detection -p data</span></pre><p id="cf3e" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">在这一步之后，我们将得到所有的数据集。他们中的两个进来了。zip格式，我们需要首先解压缩数据。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="6af8" class="lb ir hi kx b fi lc ld l le lf"># Unzip training and test datasets to data directory</span><span id="b3ff" class="lb ir hi kx b fi lg ld l le lf">!unzip data/training.zip -d data<br/>!unzip data/test.zip -d data</span></pre><p id="33bd" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">导入必要的包，然后查看训练数据集。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="9764" class="lb ir hi kx b fi lc ld l le lf">import keras<br/>import tensorflow as tf<br/>import numpy as np<br/>import pandas as pd<br/>import matplotlib.pyplot as plt<br/>import matplotlib.image as mpimg<br/>from tqdm import tqdm<br/>%matplotlib inline</span><span id="01a4" class="lb ir hi kx b fi lg ld l le lf">data_dir = Path('./data')<br/>train_data = pd.read_csv(data_dir / 'training.csv')<br/>test_csv = pd.read_csv(data_dir / 'test.csv')<br/>Id_table_path_csv = pd.read_csv(data_dir / 'IdLookupTable.csv')</span><span id="89b0" class="lb ir hi kx b fi lg ld l le lf"># View train data<br/>train_data.T</span></pre><figure class="ks kt ku kv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lh"><img src="../Images/7aa99cb220dd262e4eb5bcba03e6c487.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p7JISYvW11V4AYfrO_Ac3Q.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated">训练数据集</figcaption></figure><p id="e8d7" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">这个数据集基本上是两个独立数据集的组合。第一个包含7000+样本，具有8个特征，即4个关键点，第二个包含2000+图像，实际上属于第一数据集，但具有30个特征和15个关键点。因此，数据集中存在许多NaN值。有许多方法可以处理这个问题。我们使用的方法是通过这两个数据集分别建立两个模型，并尝试在预测关键点时使用它们。</p><figure class="ks kt ku kv fd ij er es paragraph-image"><div class="er es lm"><img src="../Images/529804eb314e50c0d9e605117282d8bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:970/format:webp/1*YnqfEMOJDLZOMxb7ahPxVA.png"/></div><figcaption class="li lj et er es lk ll bd b be z dx translated">所有列名</figcaption></figure><h1 id="b486" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated"><strong class="ak"> 3。数据预处理</strong></h1><p id="4a6b" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">现在将数据集一分为二，一个有4个点(8个值)，另一个有15个点(30个值)。左眼、右眼、鼻尖和鼠标中心底部嘴唇功能几乎适用于所有图像，其余功能仅适用于2140张以上的图像。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="4c92" class="lb ir hi kx b fi lc ld l le lf">feature_8 =['left_eye_center_x','left_eye_center_y','right_eye_center_x','right_eye_center_y','nose_tip_x','nose_tip_y','mouth_center_bottom_lip_x','mouth_center_bottom_lip_y', 'Image']</span><span id="2202" class="lb ir hi kx b fi lg ld l le lf">#Create 2 different datasets.</span><span id="6461" class="lb ir hi kx b fi lg ld l le lf">train_8_csv = train_csv[feature_8].dropna().reset_index()</span><span id="12dd" class="lb ir hi kx b fi lg ld l le lf">train_30_csv = train_csv.dropna().reset_index()</span></pre><p id="3d27" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">现在检查两个数据集的内容。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="3d39" class="lb ir hi kx b fi lc ld l le lf">#7000 samples, 8 features.</span><span id="f4a1" class="lb ir hi kx b fi lg ld l le lf">train_8_csv.info()</span></pre><figure class="ks kt ku kv fd ij er es paragraph-image"><div class="er es ln"><img src="../Images/850947a4f7e7639bcfdebaa3ffb4ab18.png" data-original-src="https://miro.medium.com/v2/resize:fit:1138/format:webp/1*aGwXg5PvL-wNO-_xEXKVXA.png"/></div></figure><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="ce8d" class="lb ir hi kx b fi lc ld l le lf">#2410 samples, 30 features.</span><span id="a8a7" class="lb ir hi kx b fi lg ld l le lf">train_30_csv.info()</span></pre><figure class="ks kt ku kv fd ij er es paragraph-image"><div class="er es lo"><img src="../Images/128b7de642baebe5425c4b99010bac43.png" data-original-src="https://miro.medium.com/v2/resize:fit:1206/format:webp/1*ubavvRWKgH5oRj0R0--leQ.png"/></div></figure><p id="3fd1" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">数据包含字符串形式的图像像素，每个元素都是一个长字符串(长度= 96*96 = 9216)。首先，我们必须将字符串像素值转换为2D数组。然后将所有数组堆叠成一个3D数组。下面的函数返回shape (96，96，1)的3D numpy数组</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="6fb7" class="lb ir hi kx b fi lc ld l le lf">def str_to_array(pd_series):<br/>    data_size = len(pd_series)<br/>    X = np.zeros(shape=(data_size,96,96,1), dtype=np.float32)<br/>    for i in tqdm(range(data_size)):<br/>       img_str = pd_series[i]<br/>       img_list = img_str.split(' ')<br/>       img_array = np.array(img_list, dtype=np.float32)<br/>       img_array = img_array.reshape(96,96,1)<br/>       X[i] = img_array</span><span id="1dc2" class="lb ir hi kx b fi lg ld l le lf">    return X</span></pre><p id="034c" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">现在用上面的函数运行所有的图像数据(两个模型)。以便我们能进一步处理。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="fe7b" class="lb ir hi kx b fi lc ld l le lf">X_train_30 = str_to_array(train_30_csv['Image'])<br/>labels_30 =  train_30_csv.drop(['index','Image'], axis=1)<br/>y_train_30 = labels_30.to_numpy(dtype=np.float32)</span><span id="1f90" class="lb ir hi kx b fi lg ld l le lf">X_train_8 = str_to_array(train_8_csv['Image'])<br/>labels_8 =  train_8_csv.drop(['index','Image'], axis=1)<br/>y_train_8 = labels_8.to_numpy(dtype=np.float32)</span></pre><h1 id="ce34" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated"><strong class="ak"> 4。显示训练图像及其关键点</strong></h1><p id="12c0" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">现在让我们看看训练图像中有什么。这里我们写了一个函数来显示24张带有关键点的图片。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="9416" class="lb ir hi kx b fi lc ld l le lf">def plot_face_pts(img, pts):<br/>    plt.imshow(img[:,:,0], cmap='gray')<br/>    for i in range(1,31,2):<br/>       plt.plot(pts[i-1], pts[i], 'b.')</span><span id="cd36" class="lb ir hi kx b fi lg ld l le lf">fig = plt.figure(figsize=(10, 7))<br/>fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)</span><span id="4ac0" class="lb ir hi kx b fi lg ld l le lf">for i in range(24):<br/>   ax = fig.add_subplot(6, 4, i + 1, xticks=[], yticks=[])<br/>   plot_face_pts(X_train_30[i], y_train_30[i])<br/>plt.show()</span></pre><figure class="ks kt ku kv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lp"><img src="../Images/30c8694e99a16258ffdb8ef60ea3ab60.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*chDiiOlm0IbFBipZS2PlBw.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated">图片及其要点</figcaption></figure><h1 id="0e4f" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated"><strong class="ak"> 5。创建神经网络(深度学习部分)</strong></h1><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="56c6" class="lb ir hi kx b fi lc ld l le lf">def create_model(output_n = 30):</span><span id="f4b0" class="lb ir hi kx b fi lg ld l le lf"> model = keras.models.Sequential([</span><span id="564d" class="lb ir hi kx b fi lg ld l le lf"> keras.layers.InputLayer(input_shape=[96,96,1]),<br/> keras.layers.Conv2D(filters=32, kernel_size=[5,5],padding='same', use_bias=False),<br/> keras.layers.LeakyReLU(alpha = .1),<br/> keras.layers.BatchNormalization(),<br/> keras.layers.Conv2D(filters=32, kernel_size=[5,5], padding='same', use_bias=False),<br/> keras.layers.LeakyReLU(alpha = .1),<br/> keras.layers.BatchNormalization(),<br/> keras.layers.MaxPool2D(pool_size=[2,2]),</span><span id="c090" class="lb ir hi kx b fi lg ld l le lf"> keras.layers.Conv2D(filters=64, kernel_size=[3,3], padding='same', use_bias=False),<br/> keras.layers.LeakyReLU(alpha = .1),<br/> keras.layers.BatchNormalization(),<br/> keras.layers.Conv2D(filters=64, kernel_size=[3,3], padding='same', use_bias=False),<br/> keras.layers.LeakyReLU(alpha = .1),<br/> keras.layers.BatchNormalization(),<br/> keras.layers.MaxPool2D(pool_size=[2,2]),</span><span id="6640" class="lb ir hi kx b fi lg ld l le lf"> keras.layers.Conv2D(filters=128, kernel_size=[3,3], padding='same', use_bias=False),<br/> keras.layers.LeakyReLU(alpha = .1),<br/> keras.layers.BatchNormalization(),<br/> keras.layers.Conv2D(filters=128, kernel_size=[3,3], padding='same', use_bias=False),<br/> keras.layers.LeakyReLU(alpha = .1),<br/> keras.layers.BatchNormalization(),<br/> keras.layers.MaxPool2D(pool_size=[2,2]),</span><span id="9a70" class="lb ir hi kx b fi lg ld l le lf"> keras.layers.Conv2D(filters=256, kernel_size=[3,3], padding='same', use_bias=False),<br/> keras.layers.LeakyReLU(alpha = .1),<br/> keras.layers.BatchNormalization(),<br/> keras.layers.Conv2D(filters=256, kernel_size=[3,3], padding='same', use_bias=False),<br/> keras.layers.LeakyReLU(alpha = .1),<br/> keras.layers.BatchNormalization(),<br/> keras.layers.MaxPool2D(pool_size=[2,2]),</span><span id="ca9e" class="lb ir hi kx b fi lg ld l le lf"> keras.layers.Conv2D(filters=512, kernel_size=[3,3], padding='same', use_bias=False),<br/> keras.layers.LeakyReLU(alpha = .1),<br/> keras.layers.BatchNormalization(),<br/> keras.layers.Conv2D(filters=512, kernel_size=[3,3], padding='same', use_bias=False),<br/> keras.layers.LeakyReLU(alpha = .1),<br/> keras.layers.BatchNormalization(),<br/> keras.layers.Flatten(),<br/> keras.layers.Dense(units=512, activation='relu'),<br/> keras.layers.Dropout(.1),<br/> keras.layers.Dense(units=output_n),</span><span id="fcf0" class="lb ir hi kx b fi lg ld l le lf">])</span><span id="248f" class="lb ir hi kx b fi lg ld l le lf"> model.compile(optimizer = 'adam' , loss = "mean_squared_error",    metrics=["mae"])</span><span id="0d50" class="lb ir hi kx b fi lg ld l le lf"> return model</span></pre><p id="7811" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">为我们创建的两个数据集创建两个模型，然后训练这两个模型。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="d07e" class="lb ir hi kx b fi lc ld l le lf">model_30 = create_model(output_n=30)<br/>model_8 = create_model(output_n=8)</span><span id="6866" class="lb ir hi kx b fi lg ld l le lf">#Prepare callbacks</span><span id="ca47" class="lb ir hi kx b fi lg ld l le lf">LR_callback = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=4, verbose=10, factor=.4, min_lr=.00001)<br/>EarlyStop_callback = keras.callbacks.EarlyStopping(patience=15, restore_best_weights=True)</span><span id="a582" class="lb ir hi kx b fi lg ld l le lf">#Train the model with 30 features.</span><span id="5823" class="lb ir hi kx b fi lg ld l le lf">history = model_30.fit(X_train_30, y_train_30, validation_split=.1, batch_size=64, epochs=100, callbacks [LR_callback,EarlyStop_callback])</span><span id="2cc7" class="lb ir hi kx b fi lg ld l le lf">#Train the model with 8 features.</span><span id="2f0d" class="lb ir hi kx b fi lg ld l le lf">history = model_8.fit(X_train_8, y_train_8, validation_split=.1, batch_size=64, epochs=100, callbacks=[LR_callback,EarlyStop_callback])</span></pre><p id="62c1" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">现在检查两个模型的训练损失和验证损失。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="f3a2" class="lb ir hi kx b fi lc ld l le lf">fig, ax = plt.subplots(2,1)<br/>ax[0].plot(history.history['loss'], color='b', label="Training loss")<br/>ax[0].plot(history.history['val_loss'], color='r', label="validation loss",axes =ax[0])<br/>legend = ax[0].legend(loc='best', shadow=True)</span><span id="6faf" class="lb ir hi kx b fi lg ld l le lf">ax[1].plot(history.history['mae'], color='b', label="Training mae")<br/>ax[1].plot(history.history['val_mae'],color='r',label="Validation mae")<br/>legend = ax[1].legend(loc='best', shadow=True)</span></pre><figure class="ks kt ku kv fd ij er es paragraph-image"><div class="er es lq"><img src="../Images/1e66252c6255f696fca6a7a481e51613.png" data-original-src="https://miro.medium.com/v2/resize:fit:894/format:webp/1*b2NTVozHumFGYd8hu2qRMg.png"/></div></figure><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="0257" class="lb ir hi kx b fi lc ld l le lf">fig, ax = plt.subplots(2,1)<br/>ax[0].plot(history.history['loss'], color='b', label="Training loss")<br/>ax[0].plot(history.history['val_loss'], color='r', label="validation loss",axes =ax[0])<br/>legend = ax[0].legend(loc='best', shadow=True)</span><span id="278d" class="lb ir hi kx b fi lg ld l le lf">ax[1].plot(history.history['mae'], color='b', label="Training mae")<br/>ax[1].plot(history.history['val_mae'], color='r',label="Validation mae")<br/>legend = ax[1].legend(loc='best', shadow=True)</span></pre><figure class="ks kt ku kv fd ij er es paragraph-image"><div class="er es lr"><img src="../Images/74892de3b1017350b52e029b8e66b885.png" data-original-src="https://miro.medium.com/v2/resize:fit:952/format:webp/1*sbYoVvkJa95UX9InnzA1hA.png"/></div></figure><h1 id="d9b4" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated"><strong class="ak"> 6。测试我们的模型</strong></h1><p id="3947" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">在测试数据集中，正如我们在训练数据集中看到的，图像数据是字符串格式的，我们需要进行与训练数据集相同的预处理。在测试数据集中，必须预测关键点，并检查我们的模型有多准确。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="f914" class="lb ir hi kx b fi lc ld l le lf">#Wrap test images into 3d array.<br/>X_test = str_to_array(test_csv['Image'])</span><span id="7457" class="lb ir hi kx b fi lg ld l le lf">#Pridect points for each image using 2 different model.<br/>y_hat_30 = model_30.predict(X_test)<br/>y_hat_8 = model_8.predict(X_test)</span></pre><p id="3c08" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">因为具有4个关键点的模型(即y_hat_8)比另一个具有更多的待训练数据。y_hat_8的模型会比y_hat_30的模型更精确。因此，在y_hat_30模型中，替换来自y_hat_8模型的8个值，这将增加准确性。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="7ad9" class="lb ir hi kx b fi lc ld l le lf">feature_8_ind = [0, 1, 2, 3, 20, 21, 28, 29]<br/>#Merge 2 prediction from y_hat_30 and y_hat_8.<br/>for i in range(8):<br/>   print('Copy "{}" feature column from y_hat_8 y_hat_30'.format(feature_8[i]))<br/>y_hat_30[:,feature_8_ind[i]] = y_hat_8[:,i]</span></pre><p id="db58" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">合并两个模型后，现在我们有了最终的值。让我们用测试图像进行测试，看看它的工作有多准确。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="70fe" class="lb ir hi kx b fi lc ld l le lf">fig = plt.figure(figsize=(10, 7))<br/>fig.subplots_adjust(<br/>left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)<br/>for i, f in enumerate(range(10,16)):<br/>  ax = fig.add_subplot(2, 3, i + 1, xticks=[], yticks=[])<br/>  plot_face_pts(X_test[f], y_hat_30[f])<br/>plt.show()</span></pre><figure class="ks kt ku kv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ls"><img src="../Images/4bac1ba2434f88297dcf157cc7e1e0af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uwsTKntMDERMw1GON1Cm6A.png"/></div></div><figcaption class="li lj et er es lk ll bd b be z dx translated">模型结果</figcaption></figure><h1 id="de39" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated"><strong class="ak"> 7。结论</strong></h1><p id="9b7a" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">作为一个较小的版本，我们的模型已经做了一个体面的工作。将来，我们可以通过以下方式使版本变得更好</p><p id="0345" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">a.增加更多的关键点。</p><p id="995d" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">b.识别实时数据的关键点。</p><p id="22e9" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">没有人是完美的，如果任何人发现任何错误或建议，请在下面不吝赐教。</p><p id="94ba" class="pw-post-body-paragraph jo jp hi jq b jr km jt ju jv kn jx jy jz ko kb kc kd kp kf kg kh kq kj kk kl hb bi translated">电子邮件Id:jerryjohn1995@gmail.com</p></div></div>    
</body>
</html>