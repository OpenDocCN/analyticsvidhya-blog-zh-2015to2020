<html>
<head>
<title>How to use ‘Tensorflow Serving’ docker container for model testing and deployment</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用tensor flow Serving docker容器进行模型测试和部署</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/how-to-use-tensorflow-serving-docker-container-for-model-testing-and-deployment-80a5e66322a5?source=collection_archive---------0-----------------------#2018-08-29">https://medium.com/analytics-vidhya/how-to-use-tensorflow-serving-docker-container-for-model-testing-and-deployment-80a5e66322a5?source=collection_archive---------0-----------------------#2018-08-29</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="4325" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">机器学习是一个涉及大量实验和研究的迭代过程。最终投产的车型只带来价值。将模型部署到产品中，同时确保它的可伸缩性并不是一件容易的事情。微服务是实现可伸缩性和健壮性的技术。数据科学家可以利用这种技术来实现为服务而部署的模型的可伸缩性、健壮性和可维护性。</p><p id="6a4e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">除此之外，对要部署的模型进行A/B测试可能是重要的或者是一个好主意。有时，数据科学家希望部署使用不同超参数训练的同一模型的多个版本，以获得关于最终用户体验的一些反馈。</p><p id="1815" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">大多数时候，研究模型的数据科学家不能立即访问部署环境，或者发现编写定制的REST API来测试新训练的模型非常耗时。</p><p id="7273" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果以上任何一个任务让你担心，那么谷歌有一个现成的解决方案叫做<em class="jd"> Tensorflow Serving </em>。</p></div><div class="ab cl je jf gp jg" role="separator"><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj"/></div><div class="hb hc hd he hf"><figure class="jm jn jo jp fd jq er es paragraph-image"><div role="button" tabindex="0" class="jr js di jt bf ju"><div class="er es jl"><img src="../Images/0b27cba32e2f29c92eed412f317bd9ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pJm1NTQ-DCJvsLvo03idZQ.png"/></div></div></figure><h1 id="d116" class="jx jy hi bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku bi translated">什么是<em class="kv"> Tensorflow服务</em>？</h1><p id="dbe7" class="pw-post-body-paragraph if ig hi ih b ii kw ik il im kx io ip iq ky is it iu kz iw ix iy la ja jb jc hb bi translated">根据谷歌的说法，<em class="jd"> Tensorflow Serving </em>是一个灵活、高性能的机器学习模型服务系统。它用于部署和服务机器学习模型。它可以同时为同一型号的多个版本提供服务。它对Tensorflow模型有现成的支持。</p><p id="0916" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是一个非常基础的教程，使用<em class="jd"> Tensorflow Serving </em>在本地快速测试你新训练的Tensorflow模型。此外，您可以使用相同的技术轻松地在生产中部署模型。如果用在类似于<em class="jd"> Kubernetes </em>的容器编排系统中，它可以开箱即用。</p></div><div class="ab cl je jf gp jg" role="separator"><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj"/></div><div class="hb hc hd he hf"><h1 id="657f" class="jx jy hi bd jz ka lb kc kd ke lc kg kh ki ld kk kl km le ko kp kq lf ks kt ku bi translated">码头工人！这是什么？</h1><p id="bb7f" class="pw-post-body-paragraph if ig hi ih b ii kw ik il im kx io ip iq ky is it iu kz iw ix iy la ja jb jc hb bi translated">在继续下一步之前，您应该熟悉Docker。<em class="jd"> Docker </em>是一个开放平台，开发人员和系统管理员可以在笔记本电脑、数据中心虚拟机或云上构建、发布和运行分布式应用。这里有一个非常好的教程，介绍了Docker的基础知识。</p><div class="lg lh ez fb li lj"><a href="https://docker-curriculum.com/" rel="noopener  ugc nofollow" target="_blank"><div class="lk ab dw"><div class="ll ab lm cl cj ln"><h2 class="bd hj fi z dy lo ea eb lp ed ef hh bi translated">面向初学者的Docker教程</h2><div class="lq l"><h3 class="bd b fi z dy lo ea eb lp ed ef dx translated">学习使用Docker轻松构建和部署您的分布式应用程序到云中，Docker由…</h3></div><div class="lr l"><p class="bd b fp z dy lo ea eb lp ed ef dx translated">docker-curriculum.com</p></div></div><div class="ls l"><div class="lt l lu lv lw ls lx jv lj"/></div></div></a></div><p id="a59a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">通常，为了开发一个RESTful webservice，并为使用Tensorflow训练的模型提供一个预测端点，需要使用您选择的框架(如Flask)用Python编写一个webservice。下一步是使用Alpine Linux或Ubuntu基础映像编写Dockerfile，安装必要的库等，并构建要部署的映像。</p><p id="9952" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所有这些步骤都已经在一个<em class="jd"> Tensorflow服务</em> Docker映像中完成。最终用户只需使用新训练的模型部署容器，他/她就可以开箱即用地获得用于预测的REST端点。在以下步骤中，我将简要说明如何使用<em class="jd"> Tensorflow服务</em> Docker图像。</p></div><div class="ab cl je jf gp jg" role="separator"><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj"/></div><div class="hb hc hd he hf"><h1 id="1909" class="jx jy hi bd jz ka lb kc kd ke lc kg kh ki ld kk kl km le ko kp kq lf ks kt ku bi translated">在Tensorflow服务容器中构建和部署模型的步骤</h1><p id="084a" class="pw-post-body-paragraph if ig hi ih b ii kw ik il im kx io ip iq ky is it iu kz iw ix iy la ja jb jc hb bi translated">我已经使用Keras和Tensorflow训练并保存了一个模型。以下步骤可用于保存使用Keras训练的模型，以部署到Tensorflow服务容器中。</p><pre class="jm jn jo jp fd ly lz ma mb aw mc bi"><span id="16f4" class="md jy hi lz b fi me mf l mg mh">from keras.layers.core import K<br/>from tensorflow.python.saved_model import builder as saved_model_builder<br/> <br/> model = Sequential()<br/> …..<br/> …<br/> model.compile(…)<br/> <br/> K.set_learning_phase(0)<br/> config = model.get_config()<br/> weights = model.get_weights()<br/> new_model = Sequential.from_config(config)<br/> new_model.set_weights(weights)<br/> <br/> builder = saved_model_builder.SavedModelBuilder(export_path)<br/> signature = predict_signature_def(<br/> inputs={'input': new_model.inputs[0]},<br/> outputs={'output': new_model.outputs[0]})<br/> <br/> <br/> with K.get_session() as sess:<br/> <br/> builder.add_meta_graph_and_variables(<br/> sess=sess,<br/> tags=[tag_constants.SERVING],<br/> clear_devices = True,<br/> signature_def_map={<br/> signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY: signature}<br/> )<br/> builder.save()</span></pre><p id="b2b3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">训练过程完成后，会在导出路径中创建一个名为“saved_model.pb”的文件和一个“variables”目录。变量目录中的文件是“variables.data-00000-of-00001”和“variables.index”。</p><p id="7127" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在进行下一步之前，Docker应该安装在您的系统上。</p><p id="4daf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">拉最新的<em class="jd"> Tensorflow发球</em>的docker图片。这将提取安装了<em class="jd"> Tensorflow Serving </em>的最小docker映像。</p><pre class="jm jn jo jp fd ly lz ma mb aw mc bi"><span id="7a8a" class="md jy hi lz b fi me mf l mg mh">docker pull tensorflow/serving</span></pre><p id="79de" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果您想了解docker容器中发生的事情，docker文件在这里:</p><div class="lg lh ez fb li lj"><a href="https://github.com/tensorflow/serving/blob/master/tensorflow_serving/tools/docker/Dockerfile" rel="noopener  ugc nofollow" target="_blank"><div class="lk ab dw"><div class="ll ab lm cl cj ln"><h2 class="bd hj fi z dy lo ea eb lp ed ef hh bi translated">张量流/服务</h2><div class="lq l"><h3 class="bd b fi z dy lo ea eb lp ed ef dx translated">面向机器学习模型的灵活、高性能服务系统——tensor flow/serving</h3></div><div class="lr l"><p class="bd b fp z dy lo ea eb lp ed ef dx translated">github.com</p></div></div><div class="ls l"><div class="mi l lu lv lw ls lx jv lj"/></div></div></a></div><p id="3810" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">它公开端口8501用于REST。现在，只需启动docker容器，使用保存模型的路径挂载卷。这里很重要的一点是，训练后保存的模型应该放在一个有编号的目录中，例如00000123。这允许Tensorflow在部署时创建模型的一个版本，以便新模型可以有不同的版本。</p><pre class="jm jn jo jp fd ly lz ma mb aw mc bi"><span id="b73c" class="md jy hi lz b fi me mf l mg mh">docker run -p 8501:8501 -v &lt;path to model parent directory&gt;:/models/&lt;model_name&gt; -e MODEL_NAME=&lt;model_name&gt; -t tensorflow/serving &amp;</span></pre><p id="0d0e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">该命令将启动一个docker容器，部署模型，并使REST端点可用于获取预测。</p><p id="707c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用curl测试模型是否正确部署:</p><pre class="jm jn jo jp fd ly lz ma mb aw mc bi"><span id="d458" class="md jy hi lz b fi me mf l mg mh">curl -d '{"instances": [1.0, 2.0, 5.0]}' \<br/>  -X POST http://localhost:8501/v1/models/&lt;model_name&gt;:predict</span></pre><p id="813f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这就是在您的本地系统中快速测试新训练的模型所需的全部内容。为了有一个合适的测试环境，使用将输入数据转换为模型输入向量所需的预处理步骤，并在python脚本中轻松测试多个值。</p><p id="1480" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">希望这将帮助人们快速测试他们的模型的健全性等。在继续云部署之前。</p></div></div>    
</body>
</html>