<html>
<head>
<title>Deep Neural Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度神经网络</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/deep-neural-networks-d14051d7c4f3?source=collection_archive---------1-----------------------#2019-05-26">https://medium.com/analytics-vidhya/deep-neural-networks-d14051d7c4f3?source=collection_archive---------1-----------------------#2019-05-26</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><figure class="hh hi ez fb hj hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es hg"><img src="../Images/b76d4631b0e836c4b295976899952dd0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hkobvL4Vu0tUlDK6kMbj-w.png"/></div></div></figure><div class=""/><p id="56d5" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">深度神经网络是具有许多隐藏层的神经网络。这种网络中隐藏层的数量可以从3层到几百层不等。我们脑海中出现的第一个问题是，<strong class="is hu"> <em class="jo">为什么我们需要这么多隐藏层？</em> </strong>这个问题的答案是，我们希望神经网络学习复杂的功能。深度网络的前几层学习简单的特征，随着我们深入，网络学习各种复杂的特征，这些特征通常是人类无法理解的。在这篇文章中，让我们来理解深度神经网络在数学环境中的工作。下面给出的是一个四层深度神经网络，我会考虑进一步的解释。</p><figure class="jq jr js jt fd hk er es paragraph-image"><div class="er es jp"><img src="../Images/0b2396faa46640e28b696806a53ed4af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1374/format:webp/1*8SDD-ysdAvAdC7PYMgQDAQ.png"/></div></figure><h1 id="b5a3" class="ju jv ht bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">表现</h1><p id="b1ab" class="pw-post-body-paragraph iq ir ht is b it ks iv iw ix kt iz ja jb ku jd je jf kv jh ji jj kw jl jm jn hb bi translated">层数<strong class="is hu"> L = 4 </strong>。它是隐藏层和输出层的总和。这里我们有三个隐藏层和一个输出层。</p><p id="2b76" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">一层<strong class="is hu"> <em class="jo"> l </em> </strong>中神经元的数量用<strong class="is hu">n[<em class="jo">l</em></strong><em class="jo">表示。</em>我们这里有，</p><ul class=""><li id="f44d" class="kx ky ht is b it iu ix iy jb kz jf la jj lb jn lc ld le lf bi translated"><strong class="is hu"> n[0] = 3 </strong>即训练数据集中的特征数量</li><li id="b3aa" class="kx ky ht is b it lg ix lh jb li jf lj jj lk jn lc ld le lf bi translated"><strong class="is hu"> n[1] = 4 </strong></li><li id="05c1" class="kx ky ht is b it lg ix lh jb li jf lj jj lk jn lc ld le lf bi translated"><strong class="is hu"> n[2] = 4 </strong></li><li id="5839" class="kx ky ht is b it lg ix lh jb li jf lj jj lk jn lc ld le lf bi translated"><strong class="is hu"> n[3] = 3 </strong></li><li id="6b90" class="kx ky ht is b it lg ix lh jb li jf lj jj lk jn lc ld le lf bi translated"><strong class="is hu"> n[4] = 1 </strong>即输出类的数量。</li></ul><p id="4d89" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在一个特定的网络中，没有选择层数和神经元数的通用规则。这是经验性的。如果你是自己建立一个网络，那么你应该从选择一个单独的层开始，然后不断增加。您可以评估测试数据集的结果，并根据您的用例选择最佳配置。</p><p id="4a10" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">与层<strong class="is hu"> <em class="jo"> l </em> </strong>相关联的权重和偏差可以分别由矩阵<strong class="is hu"> W[ <em class="jo"> l </em> ] </strong>和<strong class="is hu"> b[ <em class="jo"> l </em> ] </strong>来表示。矩阵尺寸<strong class="is hu">W[<em class="jo">l</em>]=</strong><strong class="is hu">(n[<em class="jo">l</em>)，n[<em class="jo">l</em>-1】)</strong>。这是因为特定神经元的所有传入权重都排列在一行中，并且该层中存在的每个神经元都有一行。由于每个神经元都有与之相关联的偏差，矩阵<strong class="is hu">b[<em class="jo">l</em>]=(n[<em class="jo">l</em>]，1) </strong>的维数。因此我们有，</p><ul class=""><li id="eb30" class="kx ky ht is b it iu ix iy jb kz jf la jj lb jn lc ld le lf bi translated"><strong class="is hu"> W[1] = (4，3) </strong>矩阵和<strong class="is hu"> b[1] = (4，1) </strong>矩阵</li><li id="eeef" class="kx ky ht is b it lg ix lh jb li jf lj jj lk jn lc ld le lf bi translated"><strong class="is hu"> W[2] = (4，4) </strong>矩阵和<strong class="is hu"> b[2] = (4，1) </strong>矩阵</li><li id="c6fd" class="kx ky ht is b it lg ix lh jb li jf lj jj lk jn lc ld le lf bi translated"><strong class="is hu"> W[3] = (3，4) </strong>矩阵和<strong class="is hu"> b[3] = (3，1) </strong>矩阵</li><li id="014f" class="kx ky ht is b it lg ix lh jb li jf lj jj lk jn lc ld le lf bi translated"><strong class="is hu"> W[4] = (1，3) </strong>矩阵和<strong class="is hu"> b[4] = (1，1) </strong>矩阵</li></ul><p id="93ad" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">层<strong class="is hu"><em class="jo"/></strong>的激活由矩阵<strong class="is hu"> A[ <em class="jo"> l </em> ] </strong>表示。神经元的激活可以被认为是该神经元的输出。因此，形状取决于我们提供给神经元的数据。一般来说，矩阵<strong class="is hu">A[<em class="jo">l</em>]=(n[<em class="jo">l</em>]，m) </strong>的维数，其中m是训练样本的个数。</p><p id="16fc" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">有人可能会问，<strong class="is hu"> <em class="jo">为什么不用几层，放很多神经元进去呢？</em> </strong>这个问题的答案在于电路理论。电路理论指出，我们需要在浅网络中有指数数量的神经元，以达到与深网络相似的精度。因此，为了避免指数因素并允许网络学习复杂的函数，我们更喜欢由许多隐藏层组成的深层网络。</p><h1 id="3fb6" class="ju jv ht bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">方法学</h1><p id="7265" class="pw-post-body-paragraph iq ir ht is b it ks iv iw ix kt iz ja jb ku jd je jf kv jh ji jj kw jl jm jn hb bi translated">神经网络的权重和偏差是随机初始化的，它们输出随机噪声。为了使网络能够输出正确的值，我们<em class="jo">训练</em>网络。训练网络无非是使<strong class="is hu"> <em class="jo">损失</em> </strong> <em class="jo">(预测值之间的差异，即网络的输出和原始输出)</em>最小化，使得预测值与原始值相似。整个训练过程有三个步骤，我在下面讨论过。</p><h1 id="5f28" class="ju jv ht bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">正向传播</h1><p id="1698" class="pw-post-body-paragraph iq ir ht is b it ks iv iw ix kt iz ja jb ku jd je jf kv jh ji jj kw jl jm jn hb bi translated">我们根据输入计算输出的步骤称为前向传播。它使用输入矩阵<strong class="is hu"> X </strong>，权重矩阵<strong class="is hu"> W[1] </strong>，<strong class="is hu"> W[2] </strong>，<strong class="is hu"> … </strong>，<strong class="is hu"> W[L] </strong>，<strong class="is hu"> </strong>偏差矩阵<strong class="is hu"> b[1] </strong>，<strong class="is hu"> b[2] </strong>，<strong class="is hu"> … </strong>，<strong class="is hu">b[L】</strong>。数学上，我们使用以下公式计算输出:</p><figure class="jq jr js jt fd hk er es paragraph-image"><div class="er es ll"><img src="../Images/adb91f28fb6a2d373d34c5778dcb283a.png" data-original-src="https://miro.medium.com/v2/resize:fit:636/format:webp/1*IqXH6eojtnN0ziwIMfrs4g.png"/></div></figure><p id="41a6" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在上面的等式中，函数<strong class="is hu"><em class="jo">【g(x)】</em></strong>代表激活函数。每一层可以使用不同的激活函数，因此，它们由<strong class="is hu"> <em class="jo"> g[i](x) </em> </strong>表示。如果你观察，上面的等式遵循一个趋势，可以用下面的等式来概括:</p><figure class="jq jr js jt fd hk er es paragraph-image"><div class="er es lm"><img src="../Images/3731153fa0bf45ee5c6ccf06bc2dd05c.png" data-original-src="https://miro.medium.com/v2/resize:fit:664/format:webp/1*exyYZuSYkBDwNSi6MMXbfg.png"/></div></figure><h1 id="884b" class="ju jv ht bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">反向传播</h1><p id="12bd" class="pw-post-body-paragraph iq ir ht is b it ks iv iw ix kt iz ja jb ku jd je jf kv jh ji jj kw jl jm jn hb bi translated">我们更新网络的权重和偏差的方式被称为反向传播。在这个阶段，神经网络“<strong class="is hu">借助梯度下降学习“</strong>”。梯度下降在前向传播中利用计算的导数来最小化损失，然后更新网络的权重和偏差。反向传播的每一步都可以用下面的等式来概括:</p><figure class="jq jr js jt fd hk er es paragraph-image"><div class="er es ln"><img src="../Images/8590774dbced39343d1cb84932a40bf9.png" data-original-src="https://miro.medium.com/v2/resize:fit:704/format:webp/1*T2cNFYJwCFB-ZX_ME_2LEg.png"/></div></figure><p id="d0ea" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在上面的等式中，<strong class="is hu"> "*" </strong>表示逐元素乘法，而"."表示矩阵乘法。上述方程的推导需要对微积分有详细的理解，不在本帖讨论范围之内。你可以参考我以前的帖子来清楚地了解它们是如何得出的。此外，我建议懂微积分的读者自己推导方程，以便更好地理解这个主题。</p><div class="hh hi ez fb hj lo"><a href="https://towardsdatascience.com/shallow-neural-networks-23594aa97a5" rel="noopener follow" target="_blank"><div class="lp ab dw"><div class="lq ab lr cl cj ls"><h2 class="bd hu fi z dy lt ea eb lu ed ef hs bi translated">浅层神经网络</h2><div class="lv l"><h3 class="bd b fi z dy lt ea eb lu ed ef dx translated">在这篇文章中，我解释了什么是数学背景下的浅层神经网络。</h3></div><div class="lw l"><p class="bd b fp z dy lt ea eb lu ed ef dx translated">towardsdatascience.com</p></div></div><div class="lx l"><div class="ly l lz ma mb lx mc hp lo"/></div></div></a></div><h1 id="1c39" class="ju jv ht bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">权重和偏差的更新</h1><p id="2e97" class="pw-post-body-paragraph iq ir ht is b it ks iv iw ix kt iz ja jb ku jd je jf kv jh ji jj kw jl jm jn hb bi translated">现在我们有了权重和偏差的导数，我们使用以下等式更新它们:</p><figure class="jq jr js jt fd hk er es paragraph-image"><div class="er es md"><img src="../Images/8d08cd7323cfec90b17263fb4b8a251e.png" data-original-src="https://miro.medium.com/v2/resize:fit:540/format:webp/1*ejUJwSm3Pzy039psQzKG2Q.png"/></div></figure><p id="aa6c" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在上面的等式中，<strong class="is hu"><em class="jo">α</em></strong>被称为学习率。这是决定权重更新多少的因素。高学习率表示在单个训练步骤中权重和偏差值的变化太大，反之亦然。找到理想的学习速率是至关重要的，以便有效地训练网络。</p><blockquote class="me mf mg"><p id="4634" class="iq ir jo is b it iu iv iw ix iy iz ja mh jc jd je mi jg jh ji mj jk jl jm jn hb bi translated">我敦促读者自己一次算出矩阵的维数。它将发展对各种矩阵如何用数学表示以及数据如何从输入流向输出的具体理解。</p></blockquote><h1 id="ca65" class="ju jv ht bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">总结一下</h1><p id="da94" class="pw-post-body-paragraph iq ir ht is b it ks iv iw ix kt iz ja jb ku jd je jf kv jh ji jj kw jl jm jn hb bi translated">你可能听说过训练一个神经网络需要大量的时间和资源。我上面解释的部分都是在一个步骤中完成的。此外，我只考虑了三个输入特性。在现实生活中，会有数百个功能和许多隐藏层，并且需要成百上千个步骤才能实现出色的性能。所有这些都在很大程度上增加了所需的计算资源和时间。整个过程可以用下面的内容来描述:</p><figure class="jq jr js jt fd hk er es paragraph-image"><div class="er es mk"><img src="../Images/3b59938649990d75826c1f7bc98bb76c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1048/format:webp/1*JLYNR2INWLLzvKqeUpLEAg.png"/></div></figure></div><div class="ab cl ml mm gp mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="hb hc hd he hf"><h1 id="af3c" class="ju jv ht bd jw jx ms jz ka kb mt kd ke kf mu kh ki kj mv kl km kn mw kp kq kr bi translated">参考</h1><ol class=""><li id="16bb" class="kx ky ht is b it ks ix kt jb mx jf my jj mz jn na ld le lf bi translated"><a class="ae nb" href="https://en.wikipedia.org/wiki/Learning_rate" rel="noopener ugc nofollow" target="_blank">维基百科—学习率</a></li><li id="ec97" class="kx ky ht is b it lg ix lh jb li jf lj jj lk jn na ld le lf bi translated"><a class="ae nb" href="https://www.coursera.org/learn/neural-networks-deep-learning?specialization=deep-learning" rel="noopener ugc nofollow" target="_blank"> Coursera —深度学习课程1 </a></li></ol></div><div class="ab cl ml mm gp mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="hb hc hd he hf"><p id="08e8" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="jo">我要感谢阅读这个故事的读者。如果你有任何问题或疑问，请在下面的评论区提问。我将非常乐意回答这些问题并帮助你。如果你喜欢这个故事，请关注我，以便在我发布新故事时获得定期更新。我欢迎任何能改进我的故事的建议。</em></p></div></div>    
</body>
</html>