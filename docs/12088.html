<html>
<head>
<title>A Review of Generative Adversarial Networks — part 1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">生成性对抗网络综述(一)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/a-review-of-generative-adversarial-networks-part-1-a3e5757a3dc2?source=collection_archive---------23-----------------------#2020-12-30">https://medium.com/analytics-vidhya/a-review-of-generative-adversarial-networks-part-1-a3e5757a3dc2?source=collection_archive---------23-----------------------#2020-12-30</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/199c9b0b2b233c087fdf7834c159aa3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*_PEWcPKaXEBla9pP.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">通用GAN架构</figcaption></figure><p id="ec1f" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">近年来，围绕生成性对抗网络(GANs)的炒作越来越多。自从Ian Goodfellow等人介绍了第一个GAN以来，已经有500多个(！！！)GAN架构被建议和实现。这一领域的进展非常快，新的架构定期设计出来。</p><p id="b29d" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">在这篇文章中，我将介绍最重要的基本GANs架构及其主要贡献。我将介绍并研究DCGAN、CGAN和ACGAN。</p></div><div class="ab cl jr js go jt" role="separator"><span class="ju bw bk jv jw jx"/><span class="ju bw bk jv jw jx"/><span class="ju bw bk jv jw"/></div><div class="ha hb hc hd he"><h1 id="436c" class="jy jz hh bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated"><strong class="ak"> DCGAN — </strong></h1><p id="c0a7" class="pw-post-body-paragraph it iu hh iv b iw kw iy iz ja kx jc jd je ky jg jh ji kz jk jl jm la jo jp jq ha bi translated">论文:<a class="ae lb" href="https://arxiv.org/pdf/1511.06434.pdf" rel="noopener ugc nofollow" target="_blank">深度卷积生成对抗网络的无监督表示学习</a></p><p id="bb70" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">深度卷积生成对抗网络GAN是一种架构，其中生成器和鉴别器都基于深度卷积神经网络。生成器基于转置卷积，鉴别器基于规则卷积。</p><figure class="ld le lf lg fd ii er es paragraph-image"><div class="er es lc"><img src="../Images/fa39b18e03ba9e911da7fdcca226faf6.png" data-original-src="https://miro.medium.com/v2/resize:fit:774/format:webp/1*S2M_1VtHJDeLO7cGVVIY8w.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx translated">DCGAN发电机</figcaption></figure><p id="db05" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi">主要贡献:<br/> </strong>在这篇论文中，作者提出了几条设计稳定DCGANs的准则:</p><ul class=""><li id="546f" class="lh li hh iv b iw ix ja jb je lj ji lk jm ll jq lm ln lo lp bi translated">避免合并层，用交错层代替它们。鉴别器中的步进卷积为发生器提供了更好的梯度。</li><li id="bfb4" class="lh li hh iv b iw lq ja lr je ls ji lt jm lu jq lm ln lo lp bi translated">在生成器中使用转置卷积(分数步长卷积)。</li><li id="0dff" class="lh li hh iv b iw lq ja lr je ls ji lt jm lu jq lm ln lo lp bi translated">在生成器和鉴别器中使用批处理规范化。</li><li id="5d08" class="lh li hh iv b iw lq ja lr je ls ji lt jm lu jq lm ln lo lp bi translated">为更深层次的架构移除完全连接的隐藏层。</li><li id="b0a1" class="lh li hh iv b iw lq ja lr je ls ji lt jm lu jq lm ln lo lp bi translated">在生成器中，在隐藏层中使用ReLU激活，在输出中使用Tanh。</li><li id="3192" class="lh li hh iv b iw lq ja lr je ls ji lt jm lu jq lm ln lo lp bi translated">在鉴别器中，对所有层使用LeakyReLU。</li></ul><p id="8338" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">除了指导方针之外，他们还在论文中展示了潜在空间插值的概念:</p><figure class="ld le lf lg fd ii er es paragraph-image"><div class="er es lv"><img src="../Images/9026e1ced9f8501b370a7f74f867ec43.png" data-original-src="https://miro.medium.com/v2/resize:fit:538/format:webp/1*layS2JGvEexhmgi0tEF4sA.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx translated">潜在空间插值</figcaption></figure><p id="0689" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">也就是说，如果两个不同的潜在向量被生成器映射到两个不同的图像，生成器如何映射这些向量的线性组合？下图摘自最初的DCGAN论文，很好地展示了这一概念:</p><figure class="ld le lf lg fd ii er es paragraph-image"><div class="er es lw"><img src="../Images/64262785a7c1b006e62ac99cef9b8c20.png" data-original-src="https://miro.medium.com/v2/resize:fit:872/format:webp/1*O076bfLL79Wz1xVMZLAOoQ.png"/></div></figure><p id="d10d" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">我们可以从上面的图像中看到，两个潜在向量之间的“中间点”被映射到相应生成图像之间的感知“中间点”。</p></div><div class="ab cl jr js go jt" role="separator"><span class="ju bw bk jv jw jx"/><span class="ju bw bk jv jw jx"/><span class="ju bw bk jv jw"/></div><div class="ha hb hc hd he"><h1 id="2334" class="jy jz hh bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">cGAN —</h1><p id="6924" class="pw-post-body-paragraph it iu hh iv b iw kw iy iz ja kx jc jd je ky jg jh ji kz jk jl jm la jo jp jq ha bi translated">论文:<a class="ae lb" href="https://arxiv.org/pdf/1411.1784.pdf" rel="noopener ugc nofollow" target="_blank">条件生成对抗网</a></p><p id="c2e7" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">条件生成对抗网络是一种结构，其中生成器和鉴别器使用附加信息。例如，他们可以使用标签。</p><p id="0a8d" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">该架构的概述如下:</p><figure class="ld le lf lg fd ii er es paragraph-image"><div class="er es lx"><img src="../Images/d28548300eb6bfe4240a1ad1d72f6d59.png" data-original-src="https://miro.medium.com/v2/resize:fit:736/format:webp/1*hbilFejTy1saU2whIi28tA.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx translated">cGAN</figcaption></figure><p id="1f7c" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">实施细节:</p><ul class=""><li id="1bfa" class="lh li hh iv b iw ix ja jb je lj ji lk jm ll jq lm ln lo lp bi translated">生成器接收潜在向量和附加信息向量。它将最后一个嵌入到潜在向量的形状中，并执行逐元素乘法。产品被输送到发电机。</li><li id="1b3c" class="lh li hh iv b iw lq ja lr je ls ji lt jm lu jq lm ln lo lp bi translated">鉴别器接收图像和附加信息向量。它将最后一个嵌入到图像的形状中，并执行逐元素乘法，然后将乘积提供给鉴别器。</li></ul><p id="a5a8" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi">主要贡献:</strong>本文介绍了一个框架，使GAN架构能够受益于额外的信息。</p></div><div class="ab cl jr js go jt" role="separator"><span class="ju bw bk jv jw jx"/><span class="ju bw bk jv jw jx"/><span class="ju bw bk jv jw"/></div><div class="ha hb hc hd he"><h1 id="b4fc" class="jy jz hh bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">ACGAN —</h1><p id="1542" class="pw-post-body-paragraph it iu hh iv b iw kw iy iz ja kx jc jd je ky jg jh ji kz jk jl jm la jo jp jq ha bi translated">论文:<a class="ae lb" href="https://arxiv.org/pdf/1610.09585.pdf" rel="noopener ugc nofollow" target="_blank">用辅助分类器GANs进行条件图像合成</a></p><p id="02f1" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">辅助分类器生成对抗网络是用于条件图像合成的架构，其中鉴别器具有两个目标:</p><ol class=""><li id="6250" class="lh li hh iv b iw ix ja jb je lj ji lk jm ll jq ly ln lo lp bi translated">辨别真假图像</li><li id="a635" class="lh li hh iv b iw lq ja lr je ls ji lt jm lu jq ly ln lo lp bi translated">对输入图像进行分类</li></ol><p id="0838" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">鉴别器的架构:</p><figure class="ld le lf lg fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lz"><img src="../Images/59d22fa0fd9e95005221e968a34ac88a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lI-sUuhNzt4ruPO_x_7p4w.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">阿甘鉴别器</figcaption></figure><p id="afef" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">鉴别器执行多任务学习——网络有一个共享的卷积基础模型和两个不同的模型来生成不同任务的输出:分类和鉴别。</p><p id="0bf5" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">实施细节:</p><ul class=""><li id="4d37" class="lh li hh iv b iw ix ja jb je lj ji lk jm ll jq lm ln lo lp bi translated">鉴别器接收一个图像(生成的/真实的)作为输入，并对其进行如下训练:如果图像是真实的，则对其进行训练以预测它是真实的，并对其进行正确分类。如果输入图像是假的，鉴别器被训练来预测它是假的。</li><li id="2fb8" class="lh li hh iv b iw lq ja lr je ls ji lt jm lu jq lm ln lo lp bi translated">生成器接收潜在向量和目标标签向量作为输入。它的任务是从目标标签分布中生成看起来真实的样本。例如，如果目标标签是“狗”，输入潜在向量是z，那么对于鉴别器来说，G(z)应该看起来像一只狗。生成器被训练来“愚弄”鉴别器——使它“认为”它的样本是真实的并且来自目标类。</li></ul><p id="d348" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi">主要贡献:</strong>本文展示了如何利用辅助分类形式的多任务学习来改进条件图像合成。</p></div><div class="ab cl jr js go jt" role="separator"><span class="ju bw bk jv jw jx"/><span class="ju bw bk jv jw jx"/><span class="ju bw bk jv jw"/></div><div class="ha hb hc hd he"><p id="b09a" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">在本系列的下一篇文章中，我将介绍一些先进的GAN架构和技术。</p></div></div>    
</body>
</html>