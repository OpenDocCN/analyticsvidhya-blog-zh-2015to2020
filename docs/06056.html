<html>
<head>
<title>Understanding a Single Neuron’s role in Neural Network.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">理解单个神经元在神经网络中的作用。</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/understanding-a-single-neurons-role-in-neural-network-77bb3251e9db?source=collection_archive---------13-----------------------#2020-05-10">https://medium.com/analytics-vidhya/understanding-a-single-neurons-role-in-neural-network-77bb3251e9db?source=collection_archive---------13-----------------------#2020-05-10</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="dc2e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">你们中的大多数人可能听说过神经网络这个术语(如果没有，也没关系),并试图将其应用于一些标准问题，但你们可能已经注意到，当涉及到实现它们时，你们需要获得许多库的支持，这一方面使其实现容易，但同时也带走了我们需要的神经元的实际直觉“感觉”,以便在应用于任何新问题时感到舒适。因此，在本文中，我们将通过一个简单的直觉来了解python中神经元是如何工作的(不需要使用很多库)。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/d34e9901d743c17faec080b692238a78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r1cJ5EWOejoS-gInig2_gw.jpeg"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">Src: Sikich</figcaption></figure><p id="0f7d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以，在我们继续之前，让我们看看神经网络的抽象定义，它是用于实际目的的-</p><p id="e2cf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">神经网络是神经元(类似于人脑)的集合，这些神经元连接到下一层(输出)和上一层(输入)的所有其他神经元。这些连接有一个与之相关的值，称为'<em class="jt">权重</em>，每个神经元都有一个<em class="jt">偏差</em>，这有助于给出正确的方向。现在，在对它们进行处理之后，我们应用一个激活函数，该函数产生一个预测最想要的(根据输入)结果的输出。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ju"><img src="../Images/07dd295d7f75c17fdbe81e793f8c948a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oQd98NncOH5Kko-uJTsHcA.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">资料来源:Otexts</figcaption></figure><p id="5534" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，让我们从一个单个神经元开始，考虑它的输入场景，即单个神经元的输入处理代码可能是什么样子……我们知道单个神经元将从上一层的所有神经元中获取输入，将它们乘以它们的权重并添加一个偏差，所以让我们拿起一个'<em class="jt">蓝色神经元</em>'并写下来。</p><blockquote class="jv jw jx"><p id="7335" class="if ig jt ih b ii ij ik il im in io ip jy ir is it jz iv iw ix ka iz ja jb jc hb bi translated">注意:这里我们不考虑整个网络或整个层。我们只是在观察单个神经元在做什么。</p></blockquote><pre class="je jf jg jh fd kb kc kd ke aw kf bi"><span id="3b6f" class="kg kh hi kc b fi ki kj l kk kl">inputs=[1,2,3,4]          #from the green neurons<br/>bias=2<br/>weights=[0.2,0.5,0.9,0.1] #Corresponding to the four arrows(edges)</span><span id="de45" class="kg kh hi kc b fi km kj l kk kl">output=inputs[0]*weights[0]+inputs[1]*weights[1]+ inputs[2]*weights[2]+ inputs[3]*weights[3]+ bias</span><span id="15ad" class="kg kh hi kc b fi km kj l kk kl">print(output)</span></pre><p id="a18e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这与图中的点积相同(如果你不知道点积是什么，你可以在这里找到直观的解释):</p><div class="kn ko ez fb kp kq"><a href="https://www.mathsisfun.com/algebra/vectors-dot-product.html" rel="noopener  ugc nofollow" target="_blank"><div class="kr ab dw"><div class="ks ab kt cl cj ku"><h2 class="bd hj fi z dy kv ea eb kw ed ef hh bi translated">点积</h2><div class="kx l"><h3 class="bd b fi z dy kv ea eb kw ed ef dx translated">一个向量有大小(它有多长)和方向:这里有两个向量:它们可以用“点…</h3></div><div class="ky l"><p class="bd b fp z dy kv ea eb kw ed ef dx translated">www.mathsisfun.com</p></div></div><div class="kz l"><div class="la l lb lc ld kz le jn kq"/></div></div></a></div><pre class="je jf jg jh fd kb kc kd ke aw kf bi"><span id="0e5e" class="kg kh hi kc b fi ki kj l kk kl">import numpy as np</span><span id="aa42" class="kg kh hi kc b fi km kj l kk kl">inputs=[1,2,3,4]  #from the green neurons<br/>bias=2<br/>weights=[0.2,0.5,0.9,0.1] #Corresponding to the four arrows(edges)</span><span id="9223" class="kg kh hi kc b fi km kj l kk kl">output=np.dot(inputs,weights)+bias<br/>print( output)</span></pre><p id="772a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">输出是:6.30000000000001</p><p id="6a05" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是一个关于单个神经元如何处理其输入的非常简单的代码。现在，在它处理其输入值后，我们必须对获得的值应用“激活函数”，以获得神经元的最终输出。</p><h1 id="c59e" class="lf kh hi bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">什么是激活功能&amp;我们为什么要使用它？？</h1><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="mc md l"/></div></figure><p id="197f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在讨论各种激活函数之前，让我们看看为什么我们需要一个激活函数</p><p id="67ed" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，简单地说，激活函数的基本任务是提供一种方法，根据神经元的权重和偏差来决定激活(产生一个有意义的值作为输出)神经元。</p><p id="a75b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">此外，它有助于将非线性引入神经网络的输出，如果没有它，将只能在x(输入)和y(输出)之间执行线性映射。</p><p id="4f10" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果没有激活函数，输出将只是输入向量和权重矩阵的点积，加上偏差，因为计算中的所有项都是线性的，所以输出也将是线性线。</p><p id="efd2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">通常，我们试图从中学习(进行预测)的数据越复杂，从要素到地面真实标签的映射就越非线性。</p><h1 id="e9a2" class="lf kh hi bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">激活功能的类型</h1><p id="b10d" class="pw-post-body-paragraph if ig hi ih b ii me ik il im mf io ip iq mg is it iu mh iw ix iy mi ja jb jc hb bi translated">现在我们知道了为什么我们需要一个激活函数，这是寻找一些激活函数的正确步骤。有各种各样的激活功能，让我们看看流行的-</p><p id="c6a6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"><em class="jt"/></strong>-这是一个数学函数，映射0到1范围内的任何值，正如你可以在图像中注意到的，该值从来不会精确地达到1或0，它只会趋向于1或0。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mj"><img src="../Images/7656998f11bde4e8e8832696cd769193.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YuabQiGBA-W-5PWsojwN5A.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">来源:<a class="ae mk" href="https://www.researchgate.net/figure/An-illustration-of-the-signal-processing-in-a-sigmoid-function_fig2_239269767" rel="noopener ugc nofollow" target="_blank">https://www . researchgate . net/figure/An-illustration-of-the-sigmoid-function _ fig 2 _ 239269767</a></figcaption></figure><p id="f737" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jt"> TanH Activation </em> </strong> -是一个数学函数，也叫双曲正切函数，映射-1和+1之间的值。与sigmoid相同，它也不会达到1或-1的精确值。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ml"><img src="../Images/746104d95eab108717ca377e3741d5ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:856/format:webp/1*IcQ-P-cKAyt6N4vkwgCrdg.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">来源:<a class="ae mk" href="https://www.experfy.com/blog/activation-functions-within-neural-networks" rel="noopener ugc nofollow" target="_blank">https://www . exper fy . com/blog/activation-functions-within-neural-networks</a></figcaption></figure><p id="8893" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"><em class="jt">ReLU Activation</em></strong>-代表整流线性单元，是最常见、最流行的激活函数，将负值映射为0，将正值映射为自身，图像会更清晰。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mm"><img src="../Images/c346a38499b0785354b152e6d6339505.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UWlySS1IjVLAzcvcS__s7g.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">来源:<a class="ae mk" href="https://kraj3.com.np/blog/2019/11/non-linear-activation-functions/" rel="noopener ugc nofollow" target="_blank">https://kraj 3 . com . NP/blog/2019/11/non-linear-activation-functions/</a></figcaption></figure><p id="77f5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jt"> SoftMax激活</em></strong>——这个激活函数只在神经网络的输出层使用，只在分类问题时我们需要概率得分的时候使用。在该函数中，输出值不仅取决于其输入，还取决于同一层的其他神经元的输入，因为该函数给出了特定(特定于神经元)输出的概率。<strong class="ih hj"> <em class="jt">所有神经元的输出之和总是1，因为它给出了概率。</em>T25】</strong></p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mn"><img src="../Images/c0fcc0b5f7027d1bd5b6b653661f2a19.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iRlP3JC2XChNOwrFPngACw.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">来源:<a class="ae mk" href="https://stackoverflow.com/questions/58999818/constrain-activation-on-keras-neural-net-output-layer" rel="noopener ugc nofollow" target="_blank">https://stack overflow . com/questions/58999818/constraint-activation-on-keras-neural-net-output-layer</a></figcaption></figure><p id="65a0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在我们知道了各种激活函数，让我们使用python将激活函数应用于上面使用的样本数据。因为sigmoid函数是常见的函数，所以让我们在这里应用它。</p><pre class="je jf jg jh fd kb kc kd ke aw kf bi"><span id="2fe3" class="kg kh hi kc b fi ki kj l kk kl">import numpy as np <br/>import math</span><span id="adeb" class="kg kh hi kc b fi km kj l kk kl">inputs=[1,2,3,4]  #from the green neurons<br/>bias=2<br/>weights=[0.2,0.5,0.9,0.1] #Corresponding to the four arrows(edges)</span><span id="c0bc" class="kg kh hi kc b fi km kj l kk kl">output=np.dot(inputs,weights)+bias</span><span id="0d99" class="kg kh hi kc b fi km kj l kk kl">result= 1/(1 + np.exp(-output))</span><span id="18b7" class="kg kh hi kc b fi km kj l kk kl">print( result)</span></pre><p id="dcd7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">输出结果是:0.9981677575765</p><p id="1d06" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">同样，您也可以应用其他激活功能。</p><h1 id="7cec" class="lf kh hi bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">错误</h1><p id="6ba6" class="pw-post-body-paragraph if ig hi ih b ii me ik il im mf io ip iq mg is it iu mh iw ix iy mi ja jb jc hb bi translated">现在让我们谈谈输出中的误差，它告诉我们当前输出与真实输出的偏差有多大。</p><p id="45bb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在我们的示例中，假设我们的真实输出为1(在我们的示例中，我们只考虑1个神经元，它产生了上述输出。).为了计算误差，我们对获得的值和真实值的平方差求和。这也被称为损失函数。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mo"><img src="../Images/0efbf9bdb6e6f0370199534394044f12.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*j0jcfZkZBjdzG2o9Ot9-OQ.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">误差用j表示。y和y^分别是获得值和真值。</figcaption></figure><p id="f0b5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用这个公式，我们的误差计算如下</p><pre class="je jf jg jh fd kb kc kd ke aw kf bi"><span id="82c1" class="kg kh hi kc b fi ki kj l kk kl">import numpy as np <br/>import math</span><span id="177f" class="kg kh hi kc b fi km kj l kk kl">inputs=[1,2,3,4]  #from the green neurons<br/>bias=2<br/>weights=[0.2,0.5,0.9,0.1] #Corresponding to the four arrows(edges)</span><span id="56be" class="kg kh hi kc b fi km kj l kk kl">output=np.dot(inputs,weights)+bias<br/>print(output)</span><span id="e4be" class="kg kh hi kc b fi km kj l kk kl">result= 1/(1 + np.exp(-output))</span><span id="de6e" class="kg kh hi kc b fi km kj l kk kl">print( result)</span><span id="6a2c" class="kg kh hi kc b fi km kj l kk kl">error=1/2*((result-1)**2)</span><span id="8437" class="kg kh hi kc b fi km kj l kk kl">print(error)</span></pre><p id="d84c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">出现的错误是:1.65333343 e-06</p><p id="6939" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">众所周知，没有人能够预测获得无误差输出所需的正确权重。我们通常使用随机值初始化权重，然后查看输出层的误差值，该误差值最初通常较大，但我们需要一种方法来收敛到最佳权重值，以使模型为预测做好准备。</p><p id="1d96" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在我们应该做些什么来减少这个误差，为了做到这一点，我们应用了一种叫做反向传播的算法。</p><h1 id="a77a" class="lf kh hi bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">反向传播</h1><p id="ef69" class="pw-post-body-paragraph if ig hi ih b ii me ik il im mf io ip iq mg is it iu mh iw ix iy mi ja jb jc hb bi translated">这是一种算法，在权重空间中使用一种称为梯度下降的技术来寻找最小化误差。如果你不知道什么是梯度下降，这里有一个信息丰富的解释，你可以参考</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="mp md l"/></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mq"><img src="../Images/01b5ffb883d1672cec39d952689b19a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1168/format:webp/1*dEQwi19I68NS_OGnBRl1XA.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">反向传播-基于误差的变化率更新权重。</figcaption></figure><p id="7c65" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">通过加上/减去导数(误差w.r.t .权重)乘以(乘以)称为“<em class="jt"> ETA </em>的学习率来更新权重。因此，利用这一点，我们总是朝着更优化的权重向量前进，当误差低于某个值(非常小)时，我们停止。</p><p id="9273" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你想知道反向传播中涉及的微积分，那么从下面的网站查看它的解释。</p><div class="kn ko ez fb kp kq"><a href="https://www.edureka.co/blog/backpropagation/" rel="noopener  ugc nofollow" target="_blank"><div class="kr ab dw"><div class="ks ab kt cl cj ku"><h2 class="bd hj fi z dy kv ea eb kw ed ef hh bi translated">什么是反向传播？训练神经网络</h2><div class="kx l"><h3 class="bd b fi z dy kv ea eb kw ed ef dx translated">反向传播是一种监督学习算法，用于训练多层感知器(人工神经网络)…</h3></div><div class="ky l"><p class="bd b fp z dy kv ea eb kw ed ef dx translated">www.edureka</p></div></div><div class="kz l"><div class="mr l lb lc ld kz le jn kq"/></div></div></a></div><p id="e32e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我希望这篇文章对你有所帮助，现在你对神经元的功能有了更清晰的认识。如果您有任何建议或问题，请随时留言联系我。</p></div></div>    
</body>
</html>