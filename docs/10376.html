<html>
<head>
<title>Real Image Denoising with Feature Attention (RIDNet)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于特征关注的真实图像去噪</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/real-image-denoising-with-feature-attention-ridnet-b452c5e8f8ca?source=collection_archive---------11-----------------------#2020-10-16">https://medium.com/analytics-vidhya/real-image-denoising-with-feature-attention-ridnet-b452c5e8f8ca?source=collection_archive---------11-----------------------#2020-10-16</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/02805b8caba5ac6c358cb95a3fd5c380.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*MrvhsawgEKrNyHPH"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">乔恩·泰森在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><p id="1720" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">图像处理和计算机视觉领域中的基本挑战之一是图像去噪，其中潜在的目标是通过抑制来自图像的噪声污染版本的噪声来估计原始图像。</p></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><h1 id="7d1a" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">内容:</h1><ol class=""><li id="86a0" class="ky kz hi ix b iy la jc lb jg lc jk ld jo le js lf lg lh li bi translated">商业问题</li><li id="59ce" class="ky kz hi ix b iy lj jc lk jg ll jk lm jo ln js lf lg lh li bi translated">深度学习的使用</li><li id="cfc1" class="ky kz hi ix b iy lj jc lk jg ll jk lm jo ln js lf lg lh li bi translated">数据来源</li><li id="ed74" class="ky kz hi ix b iy lj jc lk jg ll jk lm jo ln js lf lg lh li bi translated">现有方法</li><li id="a0b6" class="ky kz hi ix b iy lj jc lk jg ll jk lm jo ln js lf lg lh li bi translated">Ridnet</li><li id="c4da" class="ky kz hi ix b iy lj jc lk jg ll jk lm jo ln js lf lg lh li bi translated">第一次切割溶液</li><li id="df61" class="ky kz hi ix b iy lj jc lk jg ll jk lm jo ln js lf lg lh li bi translated">履行</li><li id="83cc" class="ky kz hi ix b iy lj jc lk jg ll jk lm jo ln js lf lg lh li bi translated">参考</li><li id="6045" class="ky kz hi ix b iy lj jc lk jg ll jk lm jo ln js lf lg lh li bi translated">Github回购</li><li id="6c7c" class="ky kz hi ix b iy lj jc lk jg ll jk lm jo ln js lf lg lh li bi translated">Linkedin个人资料</li></ol></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><h1 id="51b3" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">1.商业问题</h1><p id="d219" class="pw-post-body-paragraph iv iw hi ix b iy la ja jb jc lb je jf jg lo ji jj jk lp jm jn jo lq jq jr js hb bi translated">图像噪声可能由不同的内在(即传感器)和外在(即环境)条件引起，这些条件在实际情况下往往无法避免。</p><p id="9e8c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">因此，图像去噪在诸如图像恢复、视觉跟踪、图像配准、图像分割和图像分类等广泛的应用中起着重要的作用，其中获得原始图像内容对于强大的性能是至关重要的。</p></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><h1 id="a186" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">2.深度学习的使用</h1><p id="887c" class="pw-post-body-paragraph iv iw hi ix b iy la ja jb jc lb je jf jg lo ji jj jk lp jm jn jo lq jq jr js hb bi translated">虽然已经提出了许多用于图像去噪的算法，但是深度学习技术在图像去噪领域受到了极大的关注。</p><p id="1a01" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">深度卷积神经网络在包含空间不变噪声(合成噪声)的图像上表现更好；然而，它们的性能受限于真实噪声照片，并且需要多阶段网络建模。为了提高去噪算法的实用性，提出了一种基于模块化结构的单级真实图像盲去噪网络。</p><p id="8492" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">作者使用了残差结构上的残差来缓解低频信息的流动，并应用特征注意力来利用通道依赖性。</p><p id="c0f1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">尽管作者使用pytorch创建了模型，但我尝试使用tensorflow和keras重新创建它。</p></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><h1 id="30f2" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">3.数据来源</h1><p id="5e6e" class="pw-post-body-paragraph iv iw hi ix b iy la ja jb jc lb je jf jg lo ji jj jk lp jm jn jo lq jq jr js hb bi translated">数据集取自— RENOIR —一个用于真实微光图像降噪的数据集—【http://ani.stat.fsu.edu/~abarbu/Renoir.html】T4。</p><p id="73c1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">该数据集由小米Mi3手机摄像头点击的嘈杂和干净的地面真实图像对组成。</p></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><h1 id="dc3f" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">4.现有方法</h1><ul class=""><li id="f730" class="ky kz hi ix b iy la jc lb jg lc jk ld jo le js lr lg lh li bi translated">目前，由于卷积神经网络(CNN)的流行，图像去噪算法已经实现了性能的提升。值得注意的去噪神经网络、DnCNN和IrCNN预测图像中存在的残差，而不是去噪图像，因为与原始干净图像相比，损失函数的输入是地面真实噪声。这两个网络都取得了更好的结果，尽管具有简单的架构，其中使用了重复的卷积块、批量归一化和ReLU激活。此外，IrCNN和DnCNN依赖于盲目预测的噪声，即不考虑噪声图像的潜在结构和纹理。</li><li id="429e" class="ky kz hi ix b iy lj jc lk jg ll jk lm jo ln js lr lg lh li bi translated">最近，CBDNet为真实照片训练了一个盲去噪模型。CBDNet由两个子网络组成:噪声估计和非盲去噪。CBDNet还结合了多种损失，旨在训练真实合成噪声和真实图像噪声，并对低噪声图像执行更高的噪声标准偏差。此外，可能需要人工干预来改善结果。</li></ul></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><h1 id="c558" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">5.Ridnet</h1><figure class="lt lu lv lw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ls"><img src="../Images/530b392c961e90851592cae2015e3533.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GDQs-5LjrXkEJ-bHvy4f9A.png"/></div></div></figure><p id="3c12" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> 5.1。网络架构</strong></p><p id="d43d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">该模型由三个主要模块组成，即特征提取、残差模块上的特征学习残差和重构，如图2所示。让我们假设x是有噪声的输入图像，y’是去噪的输出图像。我们的特征提取模块仅由一个卷积层组成，用于从噪声输入中提取初始特征f0:</p><p id="98c4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">f0 = Me(x)，</p><p id="4b56" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">其中Me()对噪声输入图像执行卷积。接下来，f0被传递到残差模块上的特征学习残差，称为Mf l:</p><p id="780c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">fr = Mf l(f0)，</p><p id="6c7f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">其中fr是学习的特征，Mf l()是残差分量上的主要特征学习残差，由级联在一起的增强注意模块(EAM)组成，如图2所示。</p><p id="7e33" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">该网络具有小的深度，但是通过在每个EAM初始的两个分支卷积中的核膨胀提供了宽的感受野。最终层的输出特征被馈送到重构模块，该重构模块也由一个卷积层组成:</p><p id="4bd6" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">yˇ= Mr(fr)，</p><p id="3bd9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">其中Mr()表示重建层。</p><p id="3345" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">一些网络使用多个损失来优化模型，与早期的网络相反，我们只使用一个损失，即l1或平均绝对误差(MAE)。</p><p id="bf5a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，给定一批N个训练对，{xi，易} N i=1，其中x是噪声输入，y是地面实况，目标是使l1损失函数最小化为</p><p id="2792" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">l(W)= 1/N I = 1-N | | rid net()yi | |，</p><p id="bae2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">其中RIDNet()是网络，W表示所有学习的网络参数的集合。</p><p id="3001" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> 5.2。特征学习残差上的残差</strong></p><p id="7230" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">增强注意模块(EAM)使用具有局部跳跃和短跳跃连接的残差结构上的残差。每个EAM进一步由D块组成，其后是特征关注。</p><p id="3847" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">EAM的第一部分涵盖了输入特征的全部感受野，随后是对特征的学习；然后压缩特征以提高速度，最后特征关注模块增强地图中重要特征的权重。</p><p id="8430" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如图2第二行所示，EAM的第一部分是使用新颖的合并运行单元实现的。输入要素分支并通过两个扩张卷积，然后连接并通过另一个卷积。接下来，使用两个卷积的残差块来学习特征，同时通过三个卷积层的增强残差块(ERB)来实现压缩。ERB的最后一层通过应用1×1内核来展平特征。</p><p id="0679" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">最后，特征注意单元的输出被加到EAM的输入上。</p><p id="818d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">5.3。特色关注</p><figure class="lt lu lv lw fd ij er es paragraph-image"><div class="er es lx"><img src="../Images/3d0bdaa0b5311da8df579b7a260c0545.png" data-original-src="https://miro.medium.com/v2/resize:fit:1234/format:webp/1*Gh9z2BJGGdLtxeIVcy2QwA.png"/></div></figure><p id="b5df" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">注意力已经存在一段时间了；然而，它还没有被用于图像去噪。图像去噪方法中对通道特征一视同仁，这在很多情况下是不合适的。为了利用和学习图像的关键内容，我们将注意力集中在通道特征之间的关系上；因此得名:特色关注。</p><p id="3ef3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">由于卷积层仅利用局部信息而不能利用全局上下文信息，我们首先采用全局平均池来表示表示整个图像的统计，也可以探索用于聚集特征的其他选项来表示图像描述符。设fc是具有大小为h × w的c个特征映射的最后一个卷积层的输出特征；全局平均池会将大小从h × w × c减少到1 × 1 × c，如下所示:</p><p id="a64d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">gp = 1 / h x w i=1- h i=1- w fc(i，j)，</p><p id="e8ad" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">其中fc(i，j)是特征图中位置(I，j)处的特征值。</p><p id="74f5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">此外，自门控机制用于从由全局平均池检索的描述符中捕获通道依赖性。门控机制是=</p><p id="5d90" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">rc = α(HU (δ(HD(gp))))，</p><p id="b48f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">其中HD和HU分别是通道缩减和通道上采样运算符。全局池层gp的输出与下采样Conv层卷积，随后是relu激活。为了区分通道特征，然后将输出馈送到上采样Conv层，随后是sigmoid激活。</p></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><h1 id="47b5" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">6.第一次切割溶液</h1><p id="952a" class="pw-post-body-paragraph iv iw hi ix b iy la ja jb jc lb je jf jg lo ji jj jk lp jm jn jo lq jq jr js hb bi translated">为了测试模型的性能，我首先用默认参数在mnist数据集上训练了10个时期。</p><figure class="lt lu lv lw fd ij"><div class="bz dy l di"><div class="ly lz l"/></div></figure><figure class="lt lu lv lw fd ij"><div class="bz dy l di"><div class="ly lz l"/></div></figure><figure class="lt lu lv lw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ma"><img src="../Images/dfe0968655e555d0a6284a73c64643ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oGOxcR_D7mN5ef8iZ5Xskw.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">原始mnist图像</figcaption></figure><figure class="lt lu lv lw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mb"><img src="../Images/dbfabe44ea970161484d9096a328cc16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Nc3bSuPjzt43msMmVfZRYA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">添加了高斯白噪声的图像列表(AWGN)</figcaption></figure><figure class="lt lu lv lw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mc"><img src="../Images/f06e233255166483a94848a3ed2e6b74.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-7I8yyIKmD3flGzm8elelQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">预测去噪图像</figcaption></figure></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><h1 id="a1f1" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">7.履行</h1><p id="330a" class="pw-post-body-paragraph iv iw hi ix b iy la ja jb jc lb je jf jg lo ji jj jk lp jm jn jo lq jq jr js hb bi translated">接下来，我在雷诺阿数据集上训练模型。在每个训练批次中，每个图像被分成大小为80 × 80的小块。Adam被用作具有默认参数的优化器。学习率最初设置为0.0001，然后在处理每批后除以50。训练进行50个时期，批次大小为32。该网络在tensorflow和keras中使用google colaboratory实现。此外，峰值信噪比(PSNR)被用作评估指标，最佳模型给出的验证mae损失为0.02968。</p><figure class="lt lu lv lw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es md"><img src="../Images/7450360abf202a78f6ef178e9d393471.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TCDuF2q-iAQxWFYybRwPtg.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">嘈杂的rgb图像</figcaption></figure><figure class="lt lu lv lw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es me"><img src="../Images/91b31248d8f098134f706d4273677878.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KdyHKXcH6EFY8LzMyRtVSQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">预测去噪rgb图像</figcaption></figure><figure class="lt lu lv lw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mf"><img src="../Images/15641b5fd390026d7e57247d712d1ae1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HzTqunuVXos4_FcaqPu5WA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">原始地面真实rgb图像</figcaption></figure><figure class="lt lu lv lw fd ij er es paragraph-image"><div class="er es mg"><img src="../Images/68f5d2a07c0f4dc96bf4c9c0302c3db9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1054/format:webp/1*64AK54RnygAxiqPyoX8Q8w.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">有噪声的rgb单幅图像</figcaption></figure><figure class="lt lu lv lw fd ij er es paragraph-image"><div class="er es mh"><img src="../Images/a5c679a1e2f54c5d8a9549892cbfe8ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:868/format:webp/1*ZpOpEudP1furF9CmX2L76A.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">预测去噪rgb单幅图像</figcaption></figure><figure class="lt lu lv lw fd ij er es paragraph-image"><div class="er es mi"><img src="../Images/3292e9e537605ad5b9a642fd97b03f63.png" data-original-src="https://miro.medium.com/v2/resize:fit:950/format:webp/1*aNast4aHm4IBVwgUNL7gjA.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">原始地面真实rgb单一图像</figcaption></figure></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><h1 id="13d4" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">8.参考</h1><ol class=""><li id="1264" class="ky kz hi ix b iy la jc lb jg lc jk ld jo le js lf lg lh li bi translated"><a class="ae iu" href="https://arxiv.org/pdf/1904.07396.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1904.07396.pdf</a></li><li id="cf18" class="ky kz hi ix b iy lj jc lk jg ll jk lm jo ln js lf lg lh li bi translated">http://ani.stat.fsu.edu/~abarbu/Renoir.html<a class="ae iu" href="http://ani.stat.fsu.edu/~abarbu/Renoir.html" rel="noopener ugc nofollow" target="_blank"/></li></ol><p id="ea81" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">3.【https://blog.keras.io/building-autoencoders-in-keras.html T4】</p><p id="2b02" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">4.<a class="ae iu" href="https://www.appliedaicourse.com/" rel="noopener ugc nofollow" target="_blank">https://www.appliedaicourse.com/</a></p></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><h1 id="0d3b" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">9.Github回购</h1><p id="f883" class="pw-post-body-paragraph iv iw hi ix b iy la ja jb jc lb je jf jg lo ji jj jk lp jm jn jo lq jq jr js hb bi translated">链接到我的github回购—<a class="ae iu" href="https://github.com/pc90/Airbnb-New-User-Bookings---Kaggle-Competition" rel="noopener ugc nofollow" target="_blank"/><a class="ae iu" href="https://github.com/pc90/Ridnet-keras" rel="noopener ugc nofollow" target="_blank">https://github.com/pc90/Ridnet-keras</a>。</p></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><h1 id="f2c4" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">10.Linkedin个人资料</h1><p id="45ac" class="pw-post-body-paragraph iv iw hi ix b iy la ja jb jc lb je jf jg lo ji jj jk lp jm jn jo lq jq jr js hb bi translated">链接到我的Linkedin个人资料—<a class="ae iu" href="https://www.linkedin.com/in/puneet-chandna-050486131/" rel="noopener ugc nofollow" target="_blank">https://www.linkedin.com/in/puneet-chandna-050486131/</a>。</p></div></div>    
</body>
</html>