<html>
<head>
<title>How to use Bagging Technique for Ensemble Algorithms — A code exercise on Decision Trees</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何将Bagging技术用于集成算法——决策树上的代码练习</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/how-to-use-bagging-technique-for-ensemble-algorithms-a-code-exercise-on-decision-trees-6f944cacf085?source=collection_archive---------13-----------------------#2019-11-19">https://medium.com/analytics-vidhya/how-to-use-bagging-technique-for-ensemble-algorithms-a-code-exercise-on-decision-trees-6f944cacf085?source=collection_archive---------13-----------------------#2019-11-19</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="713d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你没有通过看标题来收集这篇文章的全部内容，请原谅我，因为我可能需要一组更简洁的句子和一个新的词汇。</p><p id="4bbf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这篇文章将涵盖集成学习中最重要的技术之一，即引导聚合技术。</p><p id="9219" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">请注意，这不是佛罗多·巴金斯的故事。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jd"><img src="../Images/10d20a4ef55e47a8365db469062f9e3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:440/1*4BdtEHfqWKL1H-8vpFu2Ag.gif"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">巴金斯一家</figcaption></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jp"><img src="../Images/eb1e07529165acb9f5b5b7a181f445bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1006/format:webp/1*z4GrjL9vVGv0PU9Fk1W8zw.png"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">套袋技术(资料来源——Aurelion Geron)</figcaption></figure><p id="79fb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这有很大的不同，但我会作为你的山姆来解释给你听。</p><p id="42f1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">集成学习主要有两个技术，一个是装袋，一个是粘贴。</p><div class="jq jr ez fb js jt"><a rel="noopener follow" target="_blank" href="/@madanflies/ensemble-learning-voting-classifier-or-how-to-aggregate-results-from-different-classifiers-a0ca27322bc7"><div class="ju ab dw"><div class="jv ab jw cl cj jx"><h2 class="bd hj fi z dy jy ea eb jz ed ef hh bi translated">集成学习/投票分类器或如何聚集来自不同分类器的结果</h2><div class="ka l"><h3 class="bd b fi z dy jy ea eb jz ed ef dx translated">今天我将讲述机器学习中一个非常非常重要和酷的技术，它涉及到使用一组…</h3></div><div class="kb l"><p class="bd b fp z dy jy ea eb jz ed ef dx translated">medium.com</p></div></div></div></a></div><p id="9fe0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">装袋更常用，因为它能产生更好的模型，我们将只在本文中讨论装袋。</p><p id="35ea" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">什么是套袋技术？</strong></p><p id="8414" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">合奏技巧是</p><ol class=""><li id="d362" class="kc kd hi ih b ii ij im in iq ke iu kf iy kg jc kh ki kj kk bi translated">一种使用不同算法对同一训练数据集使用不同分类器或回归器的方法。</li><li id="c2a7" class="kc kd hi ih b ii kl im km iq kn iu ko iy kp jc kh ki kj kk bi translated">或者使用训练算法子集(训练数据的随机实例)在不同预测器上使用相同训练算法的方法。</li></ol><p id="fd5c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当我们对数据集进行采样时，如果我们提供训练数据的替换，我们称之为装袋，而不提供替换则称为粘贴。</p><p id="6530" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这意味着，当我们对训练数据进行采样，以生成数据集子集，并使用这些子集训练预测器时，我们会对相同的预测器反复进行采样练习。</p><p id="36c0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">例句</strong></p><p id="6151" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">想象一下拥有moons数据集，现在我们将采用3个预测器，比如逻辑回归、SVM和决策树，并在moons数据集的10，000个样本上运行。然后，当我们使用所有训练数据来获得一个聚合结果时，它被称为集成学习(1)。</p><p id="519b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当我们从10，000个样本中产生500个子集，并随机选取子集来反复训练预测器时，然后聚合结果就被称为bagging。</p><p id="2fe9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">到目前为止，很好，现在和我呆在一起。</p><p id="1e4d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">有两种方法可以得到聚合的结果</p><ol class=""><li id="4cbb" class="kc kd hi ih b ii ij im in iq ke iu kf iy kg jc kh ki kj kk bi translated">软投票</li><li id="55e8" class="kc kd hi ih b ii kl im km iq kn iu ko iy kp jc kh ki kj kk bi translated">硬投票</li></ol><p id="1fba" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">原理差异btw them </strong> —如果使用的预测器具有predict_proba()类，或者如果要聚合以获得结果的预测器使用每个类的概率来聚合结果，则这是软投票，否则是硬投票。</p><p id="87f8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在我看来，软投票更好，即使用predict_proba()比硬投票更好。</p><p id="2771" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在我们知道了两种投票类别的装袋，让我们用一个代码来演示装袋技术。</p><pre class="je jf jg jh fd kq kr ks kt aw ku bi"><span id="7c08" class="kv kw hi kr b fi kx ky l kz la">bag_clf = BaggingClassifier(<br/>    DecisionTreeClassifier(random_state=42), n_estimators=500,<br/>    max_samples=100, bootstrap=True, random_state=42)</span><span id="15c7" class="kv kw hi kr b fi lb ky l kz la">bag_clf.fit(X_train, y_train)</span><span id="140f" class="kv kw hi kr b fi lb ky l kz la">y_pred = bag_clf.predict(X_test)</span></pre><p id="2118" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们在这里使用500个决策树，每个子集中有100个样本。</p><p id="ed76" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Bootstrap = True表示打包，= False表示粘贴。</p><p id="c98c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">准确度分数</p><pre class="je jf jg jh fd kq kr ks kt aw ku bi"><span id="e9b3" class="kv kw hi kr b fi kx ky l kz la">0.904</span></pre><p id="d8a5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这不是很好，但是如果我们没有使用这种打包技术，只使用决策树来进行预测，我们的准确率会是多少</p><pre class="je jf jg jh fd kq kr ks kt aw ku bi"><span id="8bb6" class="kv kw hi kr b fi kx ky l kz la">0.856</span></pre><p id="8c06" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以装袋肯定有帮助。</p><p id="e393" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">注意(额外信息)-使用bagging在决策树上使用集成技术被称为随机森林，但还要注意，最大样本被设置为整个训练集，即与整个数据集一样大的树。</p><p id="a381" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在Aurelion Geron的书中有一个很好的图表，解释了使用bagging和不使用它clear之间的区别。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jp"><img src="../Images/9732b5930fc3e7ad3f9c65e545963903.png" data-original-src="https://miro.medium.com/v2/resize:fit:1006/format:webp/1*dCU5rsihNgN6rZrR3jpPwA.png"/></div></figure><p id="6580" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">左图显示了决策树预测与Bagging预测，看看右边的曲线有多平滑？以及左边的数字是如何过度拟合的。</p><p id="1649" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你想在源代码上有一个峰值-</p><div class="jq jr ez fb js jt"><a href="https://github.com/Madmanius/Bagging_DecisionTree" rel="noopener  ugc nofollow" target="_blank"><div class="ju ab dw"><div class="jv ab jw cl cj jx"><h2 class="bd hj fi z dy jy ea eb jz ed ef hh bi translated">madmanius/Bagging _决策树</h2><div class="ka l"><h3 class="bd b fi z dy jy ea eb jz ed ef dx translated">此时您不能执行该操作。您已使用另一个标签页或窗口登录。您已在另一个选项卡中注销，或者…</h3></div><div class="kb l"><p class="bd b fp z dy jy ea eb jz ed ef dx translated">github.com</p></div></div><div class="lc l"><div class="ld l le lf lg lc lh jj jt"/></div></div></a></div><p id="832d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你有反馈或者想合作，给我写信@ rohitmadan16@gmail.com</p></div></div>    
</body>
</html>