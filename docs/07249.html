<html>
<head>
<title>Universal Dependencies: a Hidden (Markov) Quest- Drem yol lok!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">普遍依赖:一个隐藏的(马尔可夫)探索！</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/universal-dependencies-a-hidden-markov-quest-drem-yol-lok-2ca930ffc94f?source=collection_archive---------17-----------------------#2020-06-18">https://medium.com/analytics-vidhya/universal-dependencies-a-hidden-markov-quest-drem-yol-lok-2ca930ffc94f?source=collection_archive---------17-----------------------#2020-06-18</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="841e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对瘾君子来说:这个标题是让你读这篇文章的诱饵。但是在你说<em class="jd"> Gjok Hi </em>走之前，请给我一个掌声！:(</p><p id="1b7e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">甚至一个蹒跚学步的孩子也会高兴地说NLP(自然语言处理)今天是个大日子。拥有大量数据的语言正在取得惊人的进步。但与此同时，有许多低资源语言尽管拥有大量的使用者，却没有得到足够的重视。</p><p id="9ff1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">迁移学习和其他结合SMT(统计机器翻译)和NMT(神经机器翻译)的酷想法试图弥合数据鸿沟。例如，看看<a class="ae je" href="https://github.com/facebookresearch/XLM" rel="noopener ugc nofollow" target="_blank"> XMLR </a>。仍然没有一个蹒跚学步的孩子可以否认我们需要所有语言的更多数据，就像我们的大脑学习语言时一样。UD ( <a class="ae je" href="https://universaldependencies.org/" rel="noopener ugc nofollow" target="_blank">通用依赖</a>)是朝着这个方向迈出的一步:他们的目标是在所有语言中拥有一致的语法注释。UD真正酷的地方在于他们关注各种语言:你可能会在他们的列表中找到一种你从未听说过的语言。简而言之，对于对跨语言NLP感兴趣的人来说，UD是一个很好的起点。(就我个人而言，我抵挡不住玩弄白俄罗斯数据的令人垂涎的诱惑。)</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="jl jm di jn bf jo"><div class="er es jf"><img src="../Images/abf8f88d70d1e5adee2951eac8f6f8ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q50rMFOfNJaAb0nrEUzfkg.png"/></div></div><figcaption class="jr js et er es jt ju bd b be z dx translated">通用依赖项(来自universaldependencies.org)</figcaption></figure><p id="2d3a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这篇文章的目的有两个:</p><ol class=""><li id="a54a" class="jv jw hi ih b ii ij im in iq jx iu jy iy jz jc ka kb kc kd bi translated">熟悉UD数据(此处使用2.6版)及其多样性</li><li id="3d44" class="jv jw hi ih b ii ke im kf iq kg iu kh iy ki jc ka kb kc kd bi translated">快速介绍HMM及其在词性标注任务中的效率</li></ol><p id="a75d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是UD数据的样子。您可以看到，某些语言有多个数据集，而某些语言有不完整/最少的数据。在本文中，我没有考虑这种语言。</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="jl jm di jn bf jo"><div class="er es kj"><img src="../Images/159af463783be1489bac503e781b3de1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OQnkHchhjUuVAUB2kQ0bQg.png"/></div></div><figcaption class="jr js et er es jt ju bd b be z dx translated">UD子目录</figcaption></figure><p id="cd32" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这篇文章中，我将重点讨论通过HMM(隐马尔可夫模型)的词性标注。为简单起见，所有单词在进一步处理之前都进行了词汇化。使用<a class="ae je" href="https://pyconll.readthedocs.io/en/stable/" rel="noopener ugc nofollow" target="_blank"> <em class="jd"> pyconll </em> </a>包解析*train.conllu、*dev.conllu和*test.conllu文件。每个。conllu文件由每个标记旁边的词汇化形式组成，因此您不必绞尽脑汁去解释如何将“ترفض".此外，每个令牌附近还有一个相应的POS标签。所有这些属性都很容易读入pyconll对象。在开发数据可用的情况下，它被合并到训练数据中，因为我们没有迭代地训练我们的hmm。</p><p id="a17b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">为什么使用HMM进行词性标注？</strong></p><p id="e12c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为什么要研究隐马尔可夫模型？</p><p id="db83" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">隐马尔可夫模型在语音处理、手势识别等领域普遍存在。所有隐马尔可夫模型的一个共同特征是，它们都试图捕捉作为时间函数的模式。</p><p id="e240" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">例如，你下一个发音的音节是你刚才发音的函数。如果我给你每个音节的原始音频，你会想出最适合那个元音的音素。我们都知道未来和过去的单词往往会改变我们对当前音素的发音。隐马尔可夫模型是这类任务的捷径。</p><p id="80ad" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然而，隐马尔可夫模型的一个相对不那么“花哨”的应用是词性标注。可以说，严格理解世界上任何一种语言的句子结构的第一步是了解句子中每个单词/标记的作用。</p><p id="058a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们举个例子。如果“玛丽去了公园”，那么计算机会想了解“玛丽”的角色是什么，“去了”的角色是什么，等等。小时候，我们都知道“玛丽”是名词，“去”是动词，以此类推，直到“公园”是名词。愚蠢的中学语法，你抱怨。</p><p id="8827" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">那么，如果我现在说“让玛丽停车”呢？“公园”在这里还是名词吗？不，它是一个“动词”。也许你的学校老师努力让你记住这一点，但是电脑呢？我们如何教计算机学习<em class="jd">上下文</em>？也就是说，第二句中“park”后面的短语是“她的车”，所以“park”在这里很可能是一个“动词”，而在第一句中，动词“got”已经出现在“park”之前，所以“park”应该是一个名词，表示玛丽去了哪里。</p><p id="beef" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这就是隐马尔可夫模型的用武之地。要决定给定单词的功能，你需要看看前一个单词有什么功能，下一个单词有什么功能。但是同时，在当前单词和10个地点之前出现的单词之间没有直接的相关性。这是所有马尔可夫模型的一个至关重要的特征:过去的历史并不太重要。具体到我们在这里考虑的词性(POS)标记任务，我们假设POS标记直接依赖于当前单词(如“park”)和前一个POS标记。这并不排除可能存在<em class="jd">间接</em>依赖的事实，也就是说，两个字之前的词性标签会影响你现在的词性标签。</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="jl jm di jn bf jo"><div class="er es kk"><img src="../Images/eda2cb507d2f694adfa2ba9ae7c837dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zAQyNkLws8kKKgZ3-0f8vA.png"/></div></div><figcaption class="jr js et er es jt ju bd b be z dx translated">HMM示意图</figcaption></figure><p id="b891" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于HMM的数学描述，我建议您使用Ch。8在茹拉夫斯基-马丁，免费提供<a class="ae je" href="https://web.stanford.edu/~jurafsky/slp3/8.pdf" rel="noopener ugc nofollow" target="_blank">在线</a>。</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div class="er es kl"><img src="../Images/7ce04d53113a8cf2cc9d38505a739a6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:716/format:webp/1*VjSILcnG-V2x7jixxCGtYw.png"/></div><figcaption class="jr js et er es jt ju bd b be z dx translated">另一个HMM示意图，这次是条件概率</figcaption></figure><p id="e2a4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">图中的箭头非常重要:这些箭头表示HMM中推理如何发生的图形表示。这种词性标注器的训练过程包括计算对应于图中每个箭头的条件概率。从“NNP”到“Janet”的箭头链接到单词是“Janet”的概率，假定该位置的POS标签是“NNP”。从“NNP”到“MD”的箭头链接到当前标签是“MD”的概率，假定先前标签是“NNP”。</p><p id="3012" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">实际上还有两个箭头:你需要知道你在哪里开始和结束句子，也就是说，假设第一个POS标签是“NNP”的概率是从<em class="jd">开始的</em>单词，假设当前标签是一个标点符号，例如一个句点符号，那么这个句子以<em class="jd">结束的概率是多少。请注意，我认为标点符号是句子的一部分，符合词性标签集的精神。</em></p><p id="7b3c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用<a class="ae je" href="http://pomegranate.readthedocs.io/en/latest/index.html" rel="noopener ugc nofollow" target="_blank">石榴</a>库可以顺利完成HMM模型的训练和测试。我在这篇文章中使用了石榴。</p><p id="df20" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">训练HMM模型并预测标注准确率:</strong></p><p id="9667" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">回到UD的数据。这里的目标是广度而不是深度:我想覆盖尽可能多的语言，并测试标记的准确性，因此我没有实现额外的功能，如:</p><ul class=""><li id="5bb9" class="jv jw hi ih b ii ij im in iq jx iu jy iy jz jc km kb kc kd bi translated"><a class="ae je" href="https://web.stanford.edu/~jurafsky/slp3/" rel="noopener ugc nofollow" target="_blank">后退平滑</a></li><li id="be69" class="jv jw hi ih b ii ke im kf iq kg iu kh iy ki jc km kb kc kd bi translated"><a class="ae je" href="https://en.wikipedia.org/wiki/Additive_smoothing" rel="noopener ugc nofollow" target="_blank">拉普拉斯平滑</a></li><li id="f88e" class="jv jw hi ih b ii ke im kf iq kg iu kh iy ki jc km kb kc kd bi translated"><a class="ae je" href="http://www.coli.uni-saarland.de/~thorsten/publications/Brants-ANLP00.pdf" rel="noopener ugc nofollow" target="_blank">延伸到三元模型</a></li></ul><p id="918c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">测试期间的未知令牌被替换为' nan '，石榴在评估POS标签时忽略它们。</p><p id="d868" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">通过简单地将正确预测的标签数除以标签总数来计算标签准确度。</p><p id="f328" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">UD数据的另一个重要方面是它是不干净的。例如，某些语言如<em class="jd"> Bhojpuri </em>缺少训练数据，某些数据集如<em class="jd">UD _印地语_英语-HIENCS/ </em>在它们的。所有文件。</p><p id="df94" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">结果:</strong></p><p id="ce99" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">可视化这些数据是一项平凡而重要的任务。我在这里绘制了“plot_datasets”列表中各种语言的训练和测试准确度的条形图。如你所见，在这些数据中有许多欧洲语言。为了让柱状图不那么混乱，我把语言分成了两组:欧洲语言和非欧洲语言。</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="jl jm di jn bf jo"><div class="er es kn"><img src="../Images/fb40c31358b0ddd81fd7dfad377bc74f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AjQ-ZQPx08Zfo9SW0AiBBQ.jpeg"/></div></div><figcaption class="jr js et er es jt ju bd b be z dx translated">欧洲语言测试+训练准确性</figcaption></figure><figure class="jg jh ji jj fd jk er es paragraph-image"><div class="er es ko"><img src="../Images/1626a4654dc05c25eb70d4016f6882f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O8J6MhAVGEfZXjw3DaxYQg.png"/></div><figcaption class="jr js et er es jt ju bd b be z dx translated">非欧洲语言培训+测试准确性</figcaption></figure><p id="d0b8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">结论:</strong></p><p id="13c5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最重要的一点是，即使我们没有海量数据，hmm也能很好地完成词性标注任务。几千个训练句子已经产生了超过85%的准确率。尽管如此，当您更改数据源、以不同方式管理数据等时，这种情况可能会发生变化。此外，我们看到各种语言都有良好的性能(&gt; 85%)。这显示了HMM在捕获词性依赖方面的通用性。</p><p id="a00c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">该项目的代码可在<a class="ae je" href="https://github.com/prannerta100/ud-pos-tagger/" rel="noopener ugc nofollow" target="_blank">https://github.com/prannerta100/ud-pos-tagger/</a>获得。Fus Ro Dah！</p><p id="b86a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">欢迎随时留下评论和建议！</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div class="er es kp"><img src="../Images/95462f8c6996deb5d71bfe14d4c53238.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*ZKHXr3h2dEFN_e1H3nAjAg.png"/></div><figcaption class="jr js et er es jt ju bd b be z dx translated">用力，平衡，用力！</figcaption></figure></div></div>    
</body>
</html>