# 使用网络爬虫自动化任务

> 原文：<https://medium.com/analytics-vidhya/automating-tasks-using-a-web-crawler-17fc26a48fe4?source=collection_archive---------6----------------------->

![](img/75870545604b14aca4b915fb51833ab7.png)

我最近对网络爬虫/抓取器产生了浓厚的兴趣。尽管我知道它们已经有一段时间了，但直到最近我才真正需要或渴望开发一个。这种变化是由我最近从事的紧张的求职过程带来的。

当我决定注册多个在线求职平台时，我已经熟悉了每个网站的一些缺点。然而，我没有给开发人员发电子邮件并抱以最好的希望，而是决定尽我所能，用我所拥有的工具来解决这些问题。

我注册的其中一个网站是[WOB](https://my.wobbjobs.com)，这是一个连接专业人士和雇主的马来西亚平台。这绝对是迄今为止我最喜欢的平台之一。注册过程简单而流畅，一旦你上传了你的简历并输入了你的详细信息，工作申请就像点击一个按钮一样简单。

然而，这个平台有一个小问题——当我的应用程序状态改变时，我没有得到通知。这意味着我必须不断加载工作申请页面，以便获得更新。这对我来说不是最理想的，因为我必须在其他网站上发出申请，并建立一个体面的投资组合。解决办法？建立一个网络爬虫，将为我生成通知！这是一个相当简单的解决方案，节省了我大量的时间。

因为我对低于标准的双关语情有独钟，所以我决定把它命名为“沃博特”。反正我跑题了。本文的其余部分将深入探讨机器人的技术细节。

本文中的代码是在一个“main”函数中编写的，调用如下面的代码所示:

```
if __name__ == "__main__":
    main()
```

首先，让我们回顾一下我在这个项目中使用的包。第一个是 [selenium](https://www.seleniumhq.org) ，一个 web 自动化工具，它是这个项目的核心。这是我们用来浏览网站并从中提取有价值信息的工具。接下来是 [tinydb](https://tinydb.readthedocs.io/en/latest/) ，一个轻量级的无服务器 NoSQL 数据库库，使用 JSON 文件存储信息。Yagmail 是我用来给自己发送电子邮件通知的 Gmail/SMTP 客户端。如果你打算开发类似的功能，我建议创建一个指定的开发电子邮件，以防止授权库访问你的私人电子邮件。最后，我们包含了 time 和 JSON 库，以便分别处理脚本中的休眠和数据格式化。

下一步是初始化一切。我更喜欢在文件/方法/函数的顶部声明/初始化所有的东西，因为我喜欢把所有的变量初始化放在一个容易找到的地方。TinyDB 接受将用于存储我们将要抓取的数据的文件名，“Job”是查询对象。“user_credentials”是一个字典，我们将使用它来存储相关的特定于用户的变量，这些变量将在整个脚本中使用。用户数据将从与脚本文件相同目录下的 JSON 文件中读取(“credentials.json”)。然后，我初始化了驱动程序对象，传递了一个“headless”选项，以便在不打开浏览器窗口的情况下运行脚本。

WOB 会话似乎很快就会超时。我不确定这是一个普遍问题，还是只发生在我的帐户上。尽管如此，我注意到我几乎每次访问网站都必须登录。考虑到无论我是否登录，初始选项卡标题都是相同的，我决定检查登录按钮，以便检查我是否登录。如果我没有登录，凭据文件将被读取并解析到“user_credentials”字典中。

登录后，我们导航到工作卡部分，打开页面上的“我已经申请”选项卡。这里是所有已发出的申请的现场。一到这里，我偶然发现了一个小挑战。WOB 一次只显示 5 个工作，在我写这篇文章的时候，我在这个部分有 27 个工作。然而，硒不允许与隐藏的元素相互作用。我能与所有卡片互动的唯一方法是首先让它们都可见。

为此，我将工作卡长度设置为 0，然后创建一个 job_cards 列表并获取前 5 个工作卡。然后，只要可见的 job_cards 的长度大于 job_card_len，我就单击“查看更多”按钮，确保每次迭代都获得所有卡片并更新 job_card_len。为了留出加载时间，我在点击按钮和获取工卡之间添加了睡眠功能。5 秒钟可能有点过了，但安全总比冒撞车的风险好。捕捉 NoSuchElementException 是必要的，因为一旦到达列表的末尾,“查看更多”按钮就会消失。一旦 job_card_len 和检索到的卡的长度相等(即所有的卡都被检索到)，while 循环就结束。

现在更有趣的部分来了——对于我检索的每一张卡片，我将提取职位名称、发布公司、申请状态和申请日期。没有明显的方法来获得唯一的作业 id，所以数据库查询必须使用“and”操作符以及除状态之外的所有细节来唯一地标识不同的作业。我这样做是因为我相信第二个帖子会有相同的标题、公司和日期。有点冒险，但我愿意做这个假设。

第一项任务是检查当前作业是否存在于 jobs JSON 文件中。如果没有，作业将被插入到文件中并添加到 inserted_jobs 中。如果它确实存在，我们检索它并将状态与保存的状态进行比较，如果它们不相等，则状态被更新、保存并且作业被添加到 updated_jobs。

最后，我们检查是否有任何更新或插入的作业。如果有，我们将它们附加到一个字符串中，这个字符串将成为我们使用 yagmail 发出的电子邮件的正文。你可以去[这里](https://pypi.org/project/yagmail/)学习如何设置 yagmail。我使用一个开发 Gmail 帐户来发送这些电子邮件。

以上要点只突出了脚本的重要部分(这是脚本的大部分)，因为我想删除不必要的语句。如果你有兴趣看完整的项目，代码可以在我的 [Github](https://github.com/Kelvin-V-Mwinuka/wobbot) 上找到。

如果你对我的更多内容感兴趣，请访问我的个人[博客](http://kelvinmwinuka.com/blog/)。如果您有兴趣获得我的服务，请访问我的个人[网站](http://kelvinmwinuka.com)并随时联系我。