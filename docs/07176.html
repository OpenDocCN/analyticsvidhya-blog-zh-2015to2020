<html>
<head>
<title>Logical Gates: OR, AND, NOR, XOR, XNOR using TensorFlow 2.0 API, GradientTape.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">逻辑门:或，与，或非，异或，XNOR使用TensorFlow 2.0 API，GradientTape。</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/logical-gates-or-and-nor-xor-xnor-using-tensorflow-2-0-api-gradienttape-fce55a318d35?source=collection_archive---------6-----------------------#2020-06-16">https://medium.com/analytics-vidhya/logical-gates-or-and-nor-xor-xnor-using-tensorflow-2-0-api-gradienttape-fce55a318d35?source=collection_archive---------6-----------------------#2020-06-16</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="6d4c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">今天我们将讨论使用tensorflow2 API的逻辑门。</p><p id="a1a1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">“与”、“或非”和“或”门可以由单个感知器来计算。</p><p id="e152" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">首先，我们将建立“与”、“或非”和“或”门。我们将保持输入不变，并将输出改为计算“与”、“或”和“或非”门。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jd"><img src="../Images/3d96576b6f9220e0bf60f0ea86bff1f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1218/format:webp/1*f4J2Wnvt0ZjZcfYleIgE8Q.png"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">与门、或门和或非门的真值表</figcaption></figure><p id="0ad9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本教程中，我们将使用tensorflow2 API。只需在Jupyter笔记本中运行以下命令，就可以知道TensorFlow的版本。</p><pre class="je jf jg jh fd jp jq jr js aw jt bi"><span id="f745" class="ju jv hi jq b fi jw jx l jy jz">import tensorflow as tf<br/>print(tf.__version__)</span><span id="772c" class="ju jv hi jq b fi ka jx l jy jz">#!pip install --upgrade tensorflow</span></pre><p id="270b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们将初始化所有的训练示例，在我们的例子中只有四个。</p><pre class="je jf jg jh fd jp jq jr js aw jt bi"><span id="c366" class="ju jv hi jq b fi jw jx l jy jz"># Let us initialize our training examples first. <br/>import tensorflow as tf<br/>X1=tf.Variable(initial_value=[0.,1.,0.,1.])<br/>X2=tf.Variable(initial_value=[0.,0.,1.,1.])<br/>Y_AND=tf.Variable(initial_value=[0.,0.,0.,1.])<br/>Y_NOR=tf.Variable(initial_value=[1.,0.,0.,0.])<br/>Y_OR=tf.Variable(initial_value=[0.,1.,1.,1.])<br/>Y_XOR=tf.Variable(initial_value=[0.,1.,1.,0.])<br/>Y_XNOR=tf.Variable(initial_value=[1.,0.,0.,1.])</span></pre><p id="12e8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将创建一个模型类，在这里我们将做下面的<br/> 1)初始化权重，<br/> 2)创建一个感知机。<br/> 3)由于输出总是0或1，我们将使用激活作为<a class="ae kb" href="https://en.wikipedia.org/wiki/Sigmoid_function" rel="noopener ugc nofollow" target="_blank"> Sigmoid </a>。</p><pre class="je jf jg jh fd jp jq jr js aw jt bi"><span id="3955" class="ju jv hi jq b fi jw jx l jy jz">class Model(object):<br/> <br/>   def __init__(self):<br/>     # Initialize the weights to `2.0` and the bias to `2.0`<br/>     # In practice, these should be initialized to random values<br/>     # self.W1=tf.random.normal([1])<br/>     self.W1 = tf.Variable(2.)<br/>     self.W2= tf.Variable(2.)<br/>     self.b=tf.Variable(2.)<br/>   <br/>   def __call__(self, x1,x2):<br/>     self.K1=self.W1 * x1 + self.W2 * x2 + self.b<br/>     self.Output = tf.keras.activations.sigmoid(self.K1)<br/>     return(self.Output)</span><span id="4419" class="ju jv hi jq b fi ka jx l jy jz">model=Model()</span></pre><p id="d517" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">注意:在TF 2.0中，让模型类的对象可调用是一个很好的做法。<br/>tensor flow中的激活函数，可以参考这里的<a class="ae kb" href="https://www.tensorflow.org/api_docs/python/tf/keras/activations/sigmoid" rel="noopener ugc nofollow" target="_blank"/>。</p><p id="972c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在我们的模型类已经准备好了，我们需要写一个成本函数。由于我们有一个二进制分类问题，我们将使用二进制交叉熵损失函数。</p><pre class="je jf jg jh fd jp jq jr js aw jt bi"><span id="aa8d" class="ju jv hi jq b fi jw jx l jy jz">def compute_cost(target_y, predicted_y):<br/>    c=tf.keras.losses.BinaryCrossentropy()<br/>    return(c(target_y,predicted_y))</span></pre><p id="7cac" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">你可以从这个<a class="ae kb" href="https://www.tensorflow.org/api_docs/python/tf/keras/losses/BinaryCrossentropy" rel="noopener ugc nofollow" target="_blank">链接</a>学习更多关于tf.keras损失函数的知识。至于现在，我们已经在模型类中创建了一个感知器，我们还创建了一个损失函数，所以现在将准备好计算梯度和训练我们的模型。</p><p id="cbe1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将使用GradientTape来寻找梯度，并将我们的模型收敛到最佳最小值。在进入GradientTape之前，我们将编写一个小函数，将空梯度转换为0，因为，如果我们不进行转换，我们将在向变量分配空值时出错。</p><pre class="je jf jg jh fd jp jq jr js aw jt bi"><span id="0439" class="ju jv hi jq b fi jw jx l jy jz">def None_to_Zero(v):<br/>   if v==None:<br/>      v=0<br/>   return v</span></pre><p id="fcbd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">用于计算梯度和训练我们的模型的函数将被写成:</p><pre class="je jf jg jh fd jp jq jr js aw jt bi"><span id="5bfc" class="ju jv hi jq b fi jw jx l jy jz">def train(model, X1, X2, Y2, learning_rate):<br/>     with tf.GradientTape() as t:<br/>          current_loss = compute_cost(Y2,model(X1,X2))</span><span id="309d" class="ju jv hi jq b fi ka jx l jy jz">     dW1,dW2,db=t.gradient(current_loss,[model.W1,model.W2,model.b])          <br/>     dW1=None_to_Zero(dW1)<br/>     db=None_to_Zero(db)<br/>     dW2=None_to_Zero(dW2)<br/>     model.W1.assign_sub(learning_rate * dW1)<br/>     model.b.assign_sub(learning_rate * db)<br/>     model.W2.assign_sub(learning_rate * dW2)</span></pre><p id="c9a2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在我们已经编写了所有需要的函数，现在我们将调用我们的train函数，在这里我们可以初始化所有的输入和输出值。</p><pre class="je jf jg jh fd jp jq jr js aw jt bi"><span id="bae4" class="ju jv hi jq b fi jw jx l jy jz"># As we have very less Input data we need to increase the number of # epochs.<br/>epochs=range(1000)<br/>learning_rate=0.1<br/>for epoch in epochs:<br/>   train(model, X1, X2,Y_AND, learning_rate)<br/>   # train(model, X1, X2,Y_NOR, learning_rate)<br/>   # train(model, X1, X2,Y_OR, learning_rate)</span><span id="1fc2" class="ju jv hi jq b fi ka jx l jy jz">#Once the training is done we can find results by calling the Model  #Class object as <br/>print(np.round(model(X1, X2).numpy()))</span></pre><p id="37aa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于Y_AND、Y_NOR、Y_OR，我们会得到W1、W2和b的不同值。我们会将这些值存储在字典中，因为我们将来会需要这些权重。</p><pre class="je jf jg jh fd jp jq jr js aw jt bi"><span id="2285" class="ju jv hi jq b fi jw jx l jy jz">W_AND={‘W1’:model.W1.numpy(),<br/>       ’W2':model.W2.numpy(),<br/>       ’b’:model.b.numpy()}<br/>#W_NOR(calculated by keeping Y_NOR)={‘W1’:-8.65,’W2':-8.65,’b’:3.86}<br/>#W_OR(calculated by keeping Y_OR)={‘W1’:8.69,’W2': 8.69,’b’: -3.88}</span></pre><p id="6928" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在我们将计算异或门。为此，我们需要将两个门“与”和“或非”组合在一起。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es kc"><img src="../Images/997f9923c76c0e892079cc509d7e14f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1294/format:webp/1*MNI5Al0FhM9c-ZH5PCNcyA.png"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">XOR真值表</figcaption></figure><p id="435e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这个真值表可以借助下面的流程图来实现。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="er es kd"><img src="../Images/a75e65a17a690150a1e6081d6df5626a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kFOc1PzVHWEu78MBvFBt9g.png"/></div></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">异或门-使用与门和或非门</figcaption></figure><p id="a3ea" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们现在将使用字典中存储的权重W_AND和W_NOR重写模型类</p><pre class="je jf jg jh fd jp jq jr js aw jt bi"><span id="5070" class="ju jv hi jq b fi jw jx l jy jz">class Model_XOR(object):<br/> <br/>     def __init__(self):<br/>          self.W11 = tf.Variable(W_AND[‘W1’])<br/>          self.W12= tf.Variable(W_AND[‘W2’])<br/>          self.b13=tf.Variable(W_AND[‘b’])<br/>          self.W14 = tf.Variable(W_NOR[‘W1’])<br/>          self.W15= tf.Variable(W_NOR[‘W2’])<br/>          self.b16=tf.Variable(W_NOR[‘b’])<br/>          self.W21 = tf.Variable(W_NOR[‘W1’])<br/>          self.W22= tf.Variable(W_NOR[‘W2’])<br/>          self.b23=tf.Variable(W_NOR[‘b’])<br/><br/>     def __call__(self, x1,x2):<br/>          self.W1=self.W11 * x1 + self.W12*x2 + self.b13<br/>          self.W2=self.W14 * x1 + self.W15*x2 + self.b16<br/>          self.A1 = tf.keras.activations.sigmoid(self.W1)<br/>          self.A2 = tf.keras.activations.sigmoid(self.W2)<br/>          self.W3=self.W21 * self.A1 + self.W22*self.A2 + self.b23<br/>          self.A3 = tf.keras.activations.sigmoid(self.W3)<br/>          return(self.A3)<br/>model_xor=Model_XOR()</span></pre><p id="9fcc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">训练我们的Model_XOR将会像</p><pre class="je jf jg jh fd jp jq jr js aw jt bi"><span id="b576" class="ju jv hi jq b fi jw jx l jy jz">def train_xor(model_xor, X1, X2, Y2, learning_rate):<br/>      with tf.GradientTape() as t:<br/>           current_loss = compute_cost(Y2,model_xor(X1,X2))<br/> <br/>      dW11,dW12,db13,dW14,dW15,db16,dW21,dW22,db23=t.gradient<br/>      (current_loss,[model_xor.W11,model_xor.W12,model_xor.b13,<br/>      model_xor.W14,model_xor.W15,model_xor.b16,<br/>      model_xor.W21,model_xor.W22,model_xor.b23,])<br/> <br/>      model_xor.W11.assign_sub(learning_rate * None_to_Zero(dW11))<br/>      model_xor.b13.assign_sub(learning_rate * None_to_Zero(db13))<br/>      model_xor.W12.assign_sub(learning_rate * None_to_Zero(dW12))<br/>      model_xor.W14.assign_sub(learning_rate * None_to_Zero(dW14))<br/>      model_xor.b16.assign_sub(learning_rate * None_to_Zero(db16))<br/>      model_xor.W15.assign_sub(learning_rate * None_to_Zero(dW15))<br/>      model_xor.W21.assign_sub(learning_rate * None_to_Zero(dW21))<br/>      model_xor.b23.assign_sub(learning_rate * None_to_Zero(db23))<br/>      model_xor.W22.assign_sub(learning_rate * None_to_Zero(dW22))</span></pre><p id="a19a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后，我们将设置我们的纪元和学习率，并调用我们的训练函数，以分别用X1、X2和Y_XOR作为输入和输出来训练我们的模型。</p><pre class="je jf jg jh fd jp jq jr js aw jt bi"><span id="a3cf" class="ju jv hi jq b fi jw jx l jy jz">epochs=range(100)<br/>learning_rate=0.1<br/>for epoch in epochs:<br/>   train_xor(model_xor, X1, X2,Y_XOR, learning_rate)<br/>   #Once the training is done we can find results by calling the Model_XOR  #Class object as <br/>print(np.round(model_xor(X1, X2).numpy()))</span></pre><p id="b33b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们现在已经完成了异或门和同或门，唯一的区别是在最终输出端的或门。您可以使用下图和我们之前存储的字典来完成XNOR门。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="er es ki"><img src="../Images/6eaed86dddc0b084d017699ace6a66bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9RKKiI9vu7qrUSNFyZAjDw.png"/></div></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">XNOR门-使用AND、NOR和OR门</figcaption></figure><p id="9fc9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">你可以在这里找到XNOR和异或门的完整代码。</p></div></div>    
</body>
</html>