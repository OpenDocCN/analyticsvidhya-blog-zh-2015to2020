<html>
<head>
<title>Teaching Machines to Detect Skin Cancer</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">教机器检测皮肤癌</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/teaching-machines-to-detect-skin-cancer-bd165566f0fe?source=collection_archive---------6-----------------------#2019-10-10">https://medium.com/analytics-vidhya/teaching-machines-to-detect-skin-cancer-bd165566f0fe?source=collection_archive---------6-----------------------#2019-10-10</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="8a25" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">利用人工智能对医学图像进行分类，如痣的图像、CT扫描、MRI扫描等。作为诊断工具。</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/b8581276984bf312f824f364aa5515b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*JINTz275tj9g7jyo.jpg"/></div></div></figure><p id="a65f" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">癌症患者的诊断过程大概是这样的:</p><ol class=""><li id="7f12" class="kf kg hi jl b jm jn jp jq js kh jw ki ka kj ke kk kl km kn bi translated">拜访您的家庭医生，以确定是否需要进一步检查(约3天时间安排预约)</li><li id="4746" class="kf kg hi jl b jm ko jp kp js kq jw kr ka ks ke kk kl km kn bi translated">如果需要进一步测试，通常会进行皮肤活检(约3周预约)</li><li id="26de" class="kf kg hi jl b jm ko jp kp js kq jw kr ka ks ke kk kl km kn bi translated">如果被诊断患有皮肤癌，可能会建议进行进一步的检测，以提供更多的细节，如癌症的分期(大约额外2周)</li></ol><p id="0a18" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">如果幸运的话，整个诊断过程大约需要1.5个月。我听说过一些恐怖的故事，人们在急诊室等上几个小时去看医生，等上几个月去看专家，这样的例子不胜枚举。</p><p id="d7f7" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">我意识到的一件有趣的事情是，我们并没有真正完全认识到误诊是一个关键问题。这是一个隐藏的问题，也是一个不经常讨论的问题。<strong class="jl hj">癌症误诊率徘徊在20%左右。</strong>也就是说<em class="kt">每5个病人中就有1个</em>也就是说每年有<strong class="jl hj">340万例</strong>！根据一项研究，28%的误诊病例会危及生命。</p><p id="832e" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">如果我告诉你<strong class="jl hj">人工智能可以检测皮肤癌和潜在的任何类型的疾病，准确率远高于人类，时间也远少于人类，会怎么样？在皮肤癌的情况下，你需要做的就是给机器输入一张痣的图片，然后机器就会立刻给你一个诊断。事实上，我编写了一个算法来实现这一点！</strong></p><h1 id="e043" class="ku kv hi bd kw kx ky kz la lb lc ld le io lf ip lg ir lh is li iu lj iv lk ll bi translated">了解数据集:MNIST火腿10000</h1><p id="f3e4" class="pw-post-body-paragraph jj jk hi jl b jm lm ij jo jp ln im jr js lo ju jv jw lp jy jz ka lq kc kd ke hb bi translated">为了训练机器学习模型，我使用了数据集<em class="kt"> </em> <a class="ae lr" href="https://www.kaggle.com/kmader/skin-cancer-mnist-ham10000" rel="noopener ugc nofollow" target="_blank"> <em class="kt"> MNIST火腿10000 </em> </a>。总共有<strong class="jl hj"> 10 015张皮肤病变的皮镜图像</strong>标有各自的皮肤癌类型。</p><p id="5cf4" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">数据集中的图像分为以下七种皮肤癌:</p><ul class=""><li id="8dcb" class="kf kg hi jl b jm jn jp jq js kh jw ki ka kj ke ls kl km kn bi translated">光化性角化病被认为是一种非癌性(良性)皮肤癌。然而，如果不治疗，它通常会发展成鳞状细胞癌(这是一种癌症)。</li><li id="b4d8" class="kf kg hi jl b jm ko jp kp js kq jw kr ka ks ke ls kl km kn bi translated">与光化性角化病不同，<strong class="jl hj">基底细胞癌</strong>是一种发生在位于表皮下部的基底细胞层的癌性皮肤病损。这是最常见的皮肤癌类型，占所有病例的80%。</li><li id="a19b" class="kf kg hi jl b jm ko jp kp js kq jw kr ka ks ke ls kl km kn bi translated"><strong class="jl hj">良性角化病</strong>是一种非癌性且生长缓慢的皮肤癌。因为它们通常是无害的，所以可以不进行处理。</li><li id="8879" class="kf kg hi jl b jm ko jp kp js kq jw kr ka ks ke ls kl km kn bi translated"><strong class="jl hj">皮肤纤维瘤</strong>也是非癌性的，通常无害，因此不需要治疗。它通常是粉红色的，看起来像一个圆形肿块。</li><li id="87d5" class="kf kg hi jl b jm ko jp kp js kq jw kr ka ks ke ls kl km kn bi translated"><strong class="jl hj">黑色素瘤</strong>是一种恶性皮肤癌，起源于黑色素细胞，这种细胞负责皮肤的色素。</li><li id="2ae5" class="kf kg hi jl b jm ko jp kp js kq jw kr ka ks ke ls kl km kn bi translated"><strong class="jl hj">黑色素细胞痣</strong>是一种良性黑色素细胞肿瘤。患有黑色素细胞痣的患者被认为患黑色素瘤的风险较高。</li><li id="ecf6" class="kf kg hi jl b jm ko jp kp js kq jw kr ka ks ke ls kl km kn bi translated"><strong class="jl hj">血管病变</strong>由多种皮肤病变组成，包括樱桃血管瘤、血管角化瘤和化脓性肉芽肿。它们同样具有红色或紫色的特征，并且通常表现为凸起的肿块。</li></ul><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es lt"><img src="../Images/90f0b8cec14a37280cdc91411f0f85f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/0*2Rzxt4rGw5YpUKlS.jpg"/></div><figcaption class="lu lv et er es lw lx bd b be z dx translated">基底细胞位于皮肤表皮层的下部。黑素细胞位于基底细胞之下。</figcaption></figure><p id="c52f" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">对于我的模型，我应用了卷积神经网络(CNN)，这是一种深度学习算法来训练我的数据。<strong class="jl hj">CNN特别建立在图像分类领域。</strong></p><h2 id="ff0f" class="ly kv hi bd kw lz ma mb la mc md me le js mf mg lg jw mh mi li ka mj mk lk ml bi translated">但是等等，什么是深度学习？</h2><p id="0594" class="pw-post-body-paragraph jj jk hi jl b jm lm ij jo jp ln im jr js lo ju jv jw lp jy jz ka lq kc kd ke hb bi translated"><strong class="jl hj">深度学习是机器学习的一个子类，受大脑神经连接的启发。</strong></p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mm"><img src="../Images/7c3d1187bc29080b4adb4f6ad1309763.png" data-original-src="https://miro.medium.com/v2/resize:fit:1392/0*JLPIitF1b6B1jGY5"/></div></figure><p id="cb44" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">与大脑的架构类似，深度学习使得每一层中不同的节点/神经元(图中的圆圈)可以<strong class="jl hj"> <em class="kt">连接</em> </strong>到连续的层。</p><p id="8693" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">深度学习中有3种主要类型的层:</p><ol class=""><li id="4222" class="kf kg hi jl b jm jn jp jq js kh jw ki ka kj ke kk kl km kn bi translated"><strong class="jl hj">输入层</strong>:输入数据馈入模型的地方</li><li id="98d0" class="kf kg hi jl b jm ko jp kp js kq jw kr ka ks ke kk kl km kn bi translated"><strong class="jl hj">隐藏层</strong>:负责发现数据的含义</li><li id="71e5" class="kf kg hi jl b jm ko jp kp js kq jw kr ka ks ke kk kl km kn bi translated"><strong class="jl hj">输出层</strong>:返回预测答案/标签</li></ol><p id="cb30" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">解释数据涉及两个变量，<strong class="jl hj">权重，</strong>和<strong class="jl hj">偏差。</strong></p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/4b493de92ff44bfa494f3025193cc482.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*wEZ91dlILMsfV7N5.png"/></div></div><figcaption class="lu lv et er es lw lx bd b be z dx translated">权重用符号w表示，偏差用符号b表示。</figcaption></figure><p id="da02" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">在上面的场景中，体重和身高是模型的两个输入。深度神经网络然后将输入乘以权重，并添加偏差。为了产生输出，答案通过激活函数传递。简单来说，<strong class="jl hj">激活函数负责在给定输入的情况下计算节点的输出。</strong></p><p id="b1bd" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">训练数据不仅需要算法，在深度神经网络的情况下，还需要定义一个<strong class="jl hj">损失函数。</strong>损失函数允许模型了解其<strong class="jl hj"> <em class="kt">预测误差</em>。</strong></p><p id="cf09" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">损失函数表示为:<strong class="jl hj">(实际输出-预测输出)** 2 </strong></p><blockquote class="mn mo mp"><p id="7ee6" class="jj jk kt jl b jm jn ij jo jp jq im jr mq jt ju jv mr jx jy jz ms kb kc kd ke hb bi translated">我们通过模型<strong class="jl hj"> <em class="hi">将每次迭代后最小化错误率</em></strong>的<strong class="jl hj">过程称为“学习”。 </strong></p></blockquote><p id="64f8" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">在每次迭代之后，<strong class="jl hj">以最小化模型错误率的方式更新权重和偏差。</strong>训练模型时，目标是最大限度地减少损失，从而随着模型出错越来越少而提高准确性。等等，但是权重和偏差到底是怎么提炼出来的？</p><p id="c86b" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">对于由损失函数计算的每个损失数据点，<strong class="jl hj">通过利用反向传播算法计算平均梯度(代表函数导数的向量)。</strong>梯度告诉我们每个<em class="kt">参数对输出的影响程度。</em></p><p id="ae9f" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">梯度下降算法使用反向传播算法来改进权重。基本上，<strong class="jl hj">梯度下降的目标是找到损失函数的最小值，即模型损失最接近0的点。</strong></p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mt"><img src="../Images/debfadba5942b1981e2ab557d0446227.png" data-original-src="https://miro.medium.com/v2/resize:fit:590/format:webp/0*cILl9-o8vgvUMe4V.png"/></div><figcaption class="lu lv et er es lw lx bd b be z dx translated">成本函数也称为损失函数。用梯度下降法求最小值(图中标为赢家)。</figcaption></figure><p id="25d6" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">当模型到达<em class="kt">输出层时，</em>一个激活函数被用于标准化这些值，使它们对应于一个百分比。<strong class="jl hj"> sigmoid函数</strong>是常用的激活函数，用于<strong class="jl hj">将所有值转换为0到1之间的数字，代表每个输出的概率。</strong>概率最高的输出值是模型的预测值。</p><p id="3ee5" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">综上所述，<strong class="jl hj">深度学习是机器学习的一个子集，属于一类叫做神经网络的算法。</strong>神经网络的架构<strong class="jl hj">模仿了我们大脑中神经元之间的连接方式。</strong></p><h1 id="f743" class="ku kv hi bd kw kx ky kz la lb lc ld le io lf ip lg ir lh is li iu lj iv lk ll bi translated">模型:利用卷积神经网络</h1><p id="b1ba" class="pw-post-body-paragraph jj jk hi jl b jm lm ij jo jp ln im jr js lo ju jv jw lp jy jz ka lq kc kd ke hb bi translated">类似于神经网络，CNN有输入层、输出层，由节点组成。但是等等，卷积神经网络有什么不同？</p><p id="8053" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">普通神经网络(又名多层感知器)将一个向量作为输入。对于形状为100像素乘100像素的图像，常规的多层感知器必须为第二层中的每个节点计算10，000个权重。如果你有一个10节点层，这个数字会很快增加到100，000个权重！</p><p id="cffe" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">利用CNN的架构，所需的参数数量可以大大减少。这是因为CNN使用由权重向量组成的<strong class="jl hj">滤波器作为其可学习参数。</strong>这意味着图像的大小不一定影响<em class="kt">“可学习的”</em>参数的数量。*</p><p id="d388" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">CNN可以将图像的多个通道作为输入。图像通常由三层组成，因为它们由三原色组成:红色、蓝色和绿色。三层中的每一层中的每个像素构成一个从0到255的数字，该数字代表颜色的强度。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/351d9f8b354d6e7f3f2caff2e61ec040.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Iel868xzSQlZuo9d.jpeg"/></div></div></figure><p id="8f9a" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">除了输入和输出层，就像其他神经网络一样，卷积神经网络包括多个隐藏层。在卷积神经网络中发现有三种主要类型的隐藏层:</p><ol class=""><li id="7ff6" class="kf kg hi jl b jm jn jp jq js kh jw ki ka kj ke kk kl km kn bi translated">卷积层</li><li id="0880" class="kf kg hi jl b jm ko jp kp js kq jw kr ka ks ke kk kl km kn bi translated">池层</li><li id="fe37" class="kf kg hi jl b jm ko jp kp js kq jw kr ka ks ke kk kl km kn bi translated">完全连接的层</li></ol><p id="0490" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">(与完全连接的神经网络不同，如香草神经网络(也称为多层感知器)，CNN不是按结构连接的。)</p><p id="e6df" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jl hj">卷积层</strong>负责执行输入和滤波器之间的点积。<strong class="jl hj"> <em class="kt">所有的计算工作</em> </strong>都发生在这些层。过滤器是模型的“可学习”参数，因为它们用于检测特定特征，如图像中对象的<strong class="jl hj">边缘；</strong>这个过程也被称为<strong class="jl hj"> <em class="kt">特征提取。</em> </strong>类似于在多层感知器中，权重在每次迭代后被细化，<strong class="jl hj"> <em class="kt">包含权重的过滤器</em> </strong>(在CNN的上下文中)是在每次训练迭代后被细化的<strong class="jl hj"> <em class="kt">参数。</em> </strong>对于CNN，最常用的激活函数称为ReLU(校正线性单位)函数，表示为max(0，x)。这意味着对于任何小于0的值，输出将是0，对于所有大于0的值，输出将是x(输入)。ReLU函数只输出正值，因此限制了范围。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mu"><img src="../Images/9c53a94b12eccd101a025cbaf22b9238.png" data-original-src="https://miro.medium.com/v2/resize:fit:974/0*-jQQP4_H07UrQWwa.gif"/></div><figcaption class="lu lv et er es lw lx bd b be z dx translated">卷积层发挥作用的一个例子。在权重的矩阵和与权重形状相同的输入图像的矩阵之间执行点乘。生成的产品显示在最左侧的矩阵中。</figcaption></figure><p id="a0a8" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jl hj">池层</strong>通过减少数据的维度来缩小数据的大小。对于我的模型，我使用了一个名为max pooling的特定池层。Max pooling通过比较不同层的神经元来工作，然后只提取最高值作为输出，因此降低了数据的维度。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mv"><img src="../Images/55a9472194610661bd52fd756f713778.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*GaGCcHx1fSfvE9-y.jpeg"/></div></div><figcaption class="lu lv et er es lw lx bd b be z dx translated">最大池功能</figcaption></figure><p id="ca48" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jl hj">全连接层</strong>类似于多层感知器中看到的隐藏层，其中一层的节点与相应层中的节点全连接。这一层负责传达最终输出。</p><h1 id="f272" class="ku kv hi bd kw kx ky kz la lb lc ld le io lf ip lg ir lh is li iu lj iv lk ll bi translated">本质(也就是源代码)</h1><p id="180f" class="pw-post-body-paragraph jj jk hi jl b jm lm ij jo jp ln im jr js lo ju jv jw lp jy jz ka lq kc kd ke hb bi translated">继续有趣的东西，当然还有所有的代码！</p><p id="82c1" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">我没有下载3GB的图像，然后上传到google collaboratory上，这可能很繁琐，而是使用了Kaggle API。</p><pre class="iy iz ja jb fd mw mx my mz aw na bi"><span id="edab" class="ly kv hi mx b fi nb nc l nd ne">#-------------------------Kaggle API Setup---------------------</span><span id="01c4" class="ly kv hi mx b fi nf nc l nd ne">#Install kaggle library<br/>!pip install kaggle</span><span id="1558" class="ly kv hi mx b fi nf nc l nd ne">#Make a directory called .kaggle which makes it invisible<br/>!mkdir .kaggle </span><span id="f1f4" class="ly kv hi mx b fi nf nc l nd ne">import json<br/>token = {"username":"ENTER YOUR USENAME","key":"ENTER YOUR KEY"}<br/>with open('/content/.kaggle/kaggle.json', 'w') as file:<br/>    json.dump(token, file)<br/>   <br/>!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json<br/>!kaggle config set -n path -v{/content}<br/>!chmod 600 /root/.kaggle/kaggle.json</span></pre><p id="8258" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">设置好Kaggle API之后，下载MNIST HAM 10000数据集并解压文件。</p><pre class="iy iz ja jb fd mw mx my mz aw na bi"><span id="2afe" class="ly kv hi mx b fi nb nc l nd ne">#---------------Downloading and unzipping the files--------------</span><span id="08ee" class="ly kv hi mx b fi nf nc l nd ne">#Data directory: where the files will unzip to(destination folder) <br/>!mkdir data<br/>!kaggle datasets download kmader/skin-cancer-mnist-ham10000 -p data</span><span id="344a" class="ly kv hi mx b fi nf nc l nd ne">!apt install unzip</span><span id="f0ea" class="ly kv hi mx b fi nf nc l nd ne">!mkdir HAM10000_images_part_1 <br/>!mkdir HAM10000_images_part_2</span><span id="cb74" class="ly kv hi mx b fi nf nc l nd ne">!unzip /content/data/skin-cancer-mnist-ham10000.zip -d /content</span><span id="2664" class="ly kv hi mx b fi nf nc l nd ne"># Unzip the whole zipfile into /content/data<br/>!unzip /content/data/HAM10000_images_part_1.zip -d HAM10000_images_part_1 <br/>!unzip /content/data/HAM10000_images_part_2.zip -d HAM10000_images_part_2<br/>#Ouputs me how many files I unzipped<br/>!echo files in /content/data: `ls data | wc -l`</span></pre><p id="160f" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">为训练数据集和验证数据集创建不同的目录。在培训和验证目录中为七个不同的标签创建了七个子文件夹。</p><pre class="iy iz ja jb fd mw mx my mz aw na bi"><span id="b044" class="ly kv hi mx b fi nb nc l nd ne">#-------------------Make directories for the data-------------------</span><span id="5156" class="ly kv hi mx b fi nf nc l nd ne">import os <br/>import errno</span><span id="8108" class="ly kv hi mx b fi nf nc l nd ne">base_dir = 'base_dir'</span><span id="9bbe" class="ly kv hi mx b fi nf nc l nd ne">image_class = ['nv','mel','bkl','bcc','akiec','vasc','df']</span><span id="624b" class="ly kv hi mx b fi nf nc l nd ne">#3 folders are made: base_dir, train_dir and val_dir</span><span id="1f6d" class="ly kv hi mx b fi nf nc l nd ne">try:<br/>    os.mkdir(base_dir)<br/>    <br/>except OSError as exc:<br/>    if exc.errno != errno.EEXIST:<br/>        raise<br/>    pass</span><span id="6b2b" class="ly kv hi mx b fi nf nc l nd ne">train_dir = os.path.join(base_dir, 'train_dir')<br/>try:<br/>  os.mkdir(train_dir)<br/>except OSError as exc:<br/>    if exc.errno != errno.EEXIST:<br/>        raise<br/>    pass<br/>val_dir = os.path.join(base_dir, 'val_dir')<br/>try: <br/>  os.mkdir(val_dir)<br/>  <br/>except OSError as exc:<br/>    if exc.errno != errno.EEXIST:<br/>        raise<br/>    pass</span><span id="53be" class="ly kv hi mx b fi nf nc l nd ne">#make sub directories for the labels<br/>for x in image_class:<br/>      os.mkdir(train_dir+'/'+x)<br/>for x in image_class:<br/>      os.mkdir(val_dir+'/'+x)</span></pre><p id="f2fc" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">为了对数据进行预处理，将数据以9:1的比例分为训练数据和测试数据。然后，数据会相应地移动到与其标签对应的文件夹中。</p><pre class="iy iz ja jb fd mw mx my mz aw na bi"><span id="8bba" class="ly kv hi mx b fi nb nc l nd ne">#-----------------splitting data/transfering data-------------------</span><span id="758b" class="ly kv hi mx b fi nf nc l nd ne">#import libraries <br/>import pandas as pd<br/>import shutil</span><span id="3479" class="ly kv hi mx b fi nf nc l nd ne">df = pd.read_csv('/content/data/HAM10000_metadata.csv')</span><span id="fc44" class="ly kv hi mx b fi nf nc l nd ne"># Set y as the labels<br/>y = df['dx']</span><span id="d5a6" class="ly kv hi mx b fi nf nc l nd ne">#split data<br/>from sklearn.model_selection import train_test_split<br/>df_train, df_val = train_test_split(df, test_size=0.1, random_state=101, stratify=y)</span><span id="4f2f" class="ly kv hi mx b fi nf nc l nd ne"># Transfer the images into folders, Set the image id as the index<br/>image_index = df.set_index('image_id', inplace=True)</span><span id="af28" class="ly kv hi mx b fi nf nc l nd ne"># Get a list of images in each of the two folders<br/>folder_1 = os.listdir('HAM10000_images_part_1')<br/>folder_2 = os.listdir('HAM10000_images_part_2')</span><span id="3a38" class="ly kv hi mx b fi nf nc l nd ne"># Get a list of train and val images<br/>train_list = list(df_train['image_id'])<br/>val_list = list(df_val['image_id'])</span><span id="dee7" class="ly kv hi mx b fi nf nc l nd ne"># Transfer the training images<br/>for image in train_list:</span><span id="a8eb" class="ly kv hi mx b fi nf nc l nd ne">fname = image + '.jpg'</span><span id="8a1b" class="ly kv hi mx b fi nf nc l nd ne">if fname in folder_1:<br/>        #the source path<br/>        src = os.path.join('HAM10000_images_part_1', fname)<br/>        <br/>        #the destination path<br/>        dst = os.path.join(train_dir+'/'+df['dx'][image], fname)<br/>        print(dst)<br/>        <br/>        shutil.copyfile(src, dst)</span><span id="7bff" class="ly kv hi mx b fi nf nc l nd ne">if fname in folder_2:<br/>        #the source path<br/>        src = os.path.join('HAM10000_images_part_2', fname)</span><span id="c17f" class="ly kv hi mx b fi nf nc l nd ne">        #the destination path<br/>        dst = os.path.join(train_dir, fname)<br/>        <br/>        shutil.copyfile(src, dst)</span><span id="1278" class="ly kv hi mx b fi nf nc l nd ne"># Transfer the validation images<br/>for image in val_list:</span><span id="96a2" class="ly kv hi mx b fi nf nc l nd ne">fname = image + '.jpg'</span><span id="8fed" class="ly kv hi mx b fi nf nc l nd ne">if fname in folder_1:<br/>        #the source path<br/>        src = os.path.join('HAM10000_images_part_1', fname)</span><span id="8d76" class="ly kv hi mx b fi nf nc l nd ne">        #the destination path<br/>        dst = os.path.join(val_dir+'/'+df['dx'][image], fname)<br/>       <br/>        shutil.copyfile(src, dst)<br/>       <br/>    if fname in folder_2:<br/>        #the source path<br/>        src = os.path.join('HAM10000_images_part_2', fname)</span><span id="39f3" class="ly kv hi mx b fi nf nc l nd ne">        # destination path to image<br/>        dst = os.path.join(val_dir, fname)<br/>        # copy the image from the source to the destination<br/>        shutil.copyfile(src, dst)<br/>        y_valid.append(df['dx'][image])</span><span id="9dd2" class="ly kv hi mx b fi nf nc l nd ne"># Check how many training images are in train_dir<br/>print(len(os.listdir('base_dir/train_dir')))<br/>print(len(os.listdir('base_dir/val_dir')))</span><span id="c003" class="ly kv hi mx b fi nf nc l nd ne"># Check how many validation images are in val_dir<br/>print(len(os.listdir('data/HAM10000_images_part_1')))<br/>print(len(os.listdir('data/HAM10000_images_part_2')))</span></pre><p id="8a74" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">我使用图像生成器对我的图像进行随机变换。此外，使用图像生成器的一个很好的特性是，它会自动将数据调整到参数target_size中给定的尺寸。</p><pre class="iy iz ja jb fd mw mx my mz aw na bi"><span id="cadf" class="ly kv hi mx b fi nb nc l nd ne">#--------------image generator---------------<br/>from keras.preprocessing.image import ImageDataGenerator<br/>import keras <br/>print(df.head())<br/>image_class = ['nv','mel','bkl','bcc','akiec','vasc','df']</span><span id="0670" class="ly kv hi mx b fi nf nc l nd ne">train_path = 'base_dir/train_dir/'<br/>valid_path = 'base_dir/val_dir/'<br/>print(os.listdir('base_dir/train_dir'))<br/>print(len(os.listdir('base_dir/val_dir')))</span><span id="3da1" class="ly kv hi mx b fi nf nc l nd ne">image_shape = 224</span><span id="971f" class="ly kv hi mx b fi nf nc l nd ne">train_datagen  = ImageDataGenerator(rescale=1./255)<br/>val_datagen  = ImageDataGenerator(rescale=1./255)</span><span id="0b3a" class="ly kv hi mx b fi nf nc l nd ne">#declares data generator for train and val batches<br/>train_batches = train_datagen.flow_from_directory(train_path, <br/>                                                        target_size = (image_shape,image_shape),<br/>                                                        classes = image_class,<br/>                                                        batch_size = 64<br/>                                                        )</span><span id="956f" class="ly kv hi mx b fi nf nc l nd ne">valid_batches = val_datagen.flow_from_directory(valid_path, <br/>                                                        target_size = (image_shape,image_shape),<br/>                                                        classes = image_class,<br/>                                                        batch_size = 64                                                      )</span></pre><p id="7e8e" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">我们都认为最难的部分是对模型进行编码，但实际上是上面的所有事情(也就是预处理数据)。</p><p id="5d57" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">我没有使用卷积神经网络，而是利用了一种叫做<strong class="jl hj">移动网络的架构。</strong>它是一个<strong class="jl hj"> <em class="kt">预训练模型</em> </strong>，在数据集<strong class="jl hj"> ImageNet </strong>上进行训练，该数据集拥有超过1400万张图片。为了检测皮肤癌，我在移动网络上构建了几个层，然后在MNIST: HAM 10000数据集上对其进行训练。</p><p id="4ce0" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">我使用移动网络而不是常规卷积神经网络的主要原因是由于所需的<em class="kt">最小计算能力</em>，因为它减少了可学习参数的数量，并且被设计为“移动”友好的。</p><pre class="iy iz ja jb fd mw mx my mz aw na bi"><span id="34f5" class="ly kv hi mx b fi nb nc l nd ne">#-------------------------------model------------------------------<br/>from keras.models import Sequential<br/>from keras.layers import Dense, Activation<br/>from keras.layers import Conv2D, MaxPool2D, Dropout, Flatten <br/>from keras.callbacks import ReduceLROnPlateau<br/>from keras.models import Model</span><span id="472e" class="ly kv hi mx b fi nf nc l nd ne">mobile = keras.applications.mobilenet.MobileNet()<br/>x = mobile.layers[-6].output</span><span id="d3ed" class="ly kv hi mx b fi nf nc l nd ne"># Add a dropout and dense layer for predictions<br/>x = Dropout(0.25)(x)<br/>predictions = Dense(7, activation='softmax')(x)<br/>print(mobile.input)<br/>net = Model(inputs=mobile.input, outputs=predictions)</span><span id="a7cf" class="ly kv hi mx b fi nf nc l nd ne">mobile.summary()<br/>for layer in net.layers[:-23]:<br/>  layer.trainable = False</span><span id="330a" class="ly kv hi mx b fi nf nc l nd ne">net.compile(optimizer='adam',<br/>  loss='categorical_crossentropy',<br/>  metrics=['accuracy'])</span><span id="c276" class="ly kv hi mx b fi nf nc l nd ne">learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1, factor=0.5, min_lr=0.00001)</span><span id="2838" class="ly kv hi mx b fi nf nc l nd ne">history = net.fit_generator(train_batches, epochs=10)</span></pre></div><div class="ab cl ng nh gp ni" role="separator"><span class="nj bw bk nk nl nm"/><span class="nj bw bk nk nl nm"/><span class="nj bw bk nk nl"/></div><div class="hb hc hd he hf"><p id="bb4e" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">在训练模型之后，当在测试批次上执行时，获得了70%的准确度<strong class="jl hj">。对于更大的数据集，可以很容易地提高精确度。人工智能有如此大的潜力来颠覆医疗保健行业。想象一下，让人工智能诊断几乎任何疾病都比人类更好更快，<strong class="jl hj">这太疯狂了！</strong></strong></p><p id="273f" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">这不是科幻小说，人工智能的可能性是无限的！人工智能已经彻底改变了中国的医疗保健。中国一家医院推出了一项名为AI-Force的计划，该计划利用人工智能机器，能够以97%的准确率检测30种慢性疾病！</p><h1 id="8961" class="ku kv hi bd kw kx ky kz la lb lc ld le io lf ip lg ir lh is li iu lj iv lk ll bi translated">关键要点</h1><ul class=""><li id="20b5" class="kf kg hi jl b jm lm jp ln js nn jw no ka np ke ls kl km kn bi translated">深度学习的灵感来自大脑的神经连接，因为每一层中的每个节点都与下一层相连</li><li id="ddae" class="kf kg hi jl b jm ko jp kp js kq jw kr ka ks ke ls kl km kn bi translated">卷积神经网络有3种主要类型的隐藏层:卷积层、池层和全连接层</li><li id="fb10" class="kf kg hi jl b jm ko jp kp js kq jw kr ka ks ke ls kl km kn bi translated">过滤器(用于CNN)用于从数据中提取特征</li></ul><h2 id="16a1" class="ly kv hi bd kw lz ma mb la mc md me le js mf mg lg jw mh mi li ka mj mk lk ml bi translated">不要忘记:</h2><ul class=""><li id="282d" class="kf kg hi jl b jm lm jp ln js nn jw no ka np ke ls kl km kn bi translated">如果你喜欢这篇文章，请鼓掌</li><li id="f760" class="kf kg hi jl b jm ko jp kp js kq jw kr ka ks ke ls kl km kn bi translated">在<a class="ae lr" href="https://ca.linkedin.com/in/joey-mach-6293b1175" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上与我联系</li></ul></div></div>    
</body>
</html>