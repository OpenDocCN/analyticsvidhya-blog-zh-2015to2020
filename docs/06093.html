<html>
<head>
<title>Sentimental Analysis Using SVM(Support Vector Machine)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用SVM(支持向量机)的情感分析</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/sentimental-analysis-using-svm-support-vector-machine-812f2454fbc5?source=collection_archive---------19-----------------------#2020-05-11">https://medium.com/analytics-vidhya/sentimental-analysis-using-svm-support-vector-machine-812f2454fbc5?source=collection_archive---------19-----------------------#2020-05-11</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/6db6367b2c71f62ad9ac3784f3b28b89.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*bO06WNti2Tt6uAPn"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">马库斯·斯皮斯克在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><p id="e017" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">情感分析是将任何社交媒体的各种帖子和评论分为负面或正面的过程。使用NLP(自然语言编程)或ML(机器学习)是使这个过程更容易的最好方法。</p><p id="abdc" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我做的情感分析项目有以下程序流程。</p><p id="60bf" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">任何情感分析的步骤是:-</p><ol class=""><li id="d754" class="jt ju hi ix b iy iz jc jd jg jv jk jw jo jx js jy jz ka kb bi translated"><strong class="ix hj">准备数据集</strong> -用户可以获取任何类型的数据，也可以从网上下载。数据越多，预测就越准确。</li><li id="2030" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated"><strong class="ix hj">数据预处理</strong> -在这一步中，我们将单词变得更简单，这样预测就变得容易了。一些常见的数据预处理方法有:标记化(分割成每个单词)、词条化、词干化和去除停用词(不想要的单词)和字符。词条化意味着得到输入单词的原始单词“漂亮”将变成“漂亮”</li><li id="2c4a" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated"><strong class="ix hj">特征提取</strong>-对于所有的分类算法，特征对于绘制或制作精确的细节是必要的，以便预测基于该特征。这里我们将使用TFIDF算法</li><li id="429f" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated"><strong class="ix hj">分类器算法</strong> -这里我们使用svm(支持向量机)，但也使用各种其他算法，如朴素贝叶斯、回归等。可以使用。</li><li id="c20e" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated"><strong class="ix hj">预测- </strong>完成上述所有步骤后，模型就可以进行预测了。我们将在测试数据集上进行预测。</li></ol><p id="de26" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">必需品进口:-</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div class="er es kh"><img src="../Images/4dcbd83508b4da92688319fed3a58d84.png" data-original-src="https://miro.medium.com/v2/resize:fit:914/0*-7wFKaijVHMLN5zP"/></div></figure><p id="a427" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">所用的数据集非常简单，是手工输入的。数据集是一个csv文件。你可以在谷歌上得到一个直接的评论数据集。数据集的长度接近308。</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div class="er es km"><img src="../Images/f32064e283e7bbdd5e6ae22a8006c510.png" data-original-src="https://miro.medium.com/v2/resize:fit:1282/format:webp/1*b7rATreMhTEZaFueQngsuw.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">资料组</figcaption></figure><p id="99e1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">//使用下面一行，以便我们反复运行程序，并保持原始输入值。</p><p id="a951" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">随机种子(500)</p><p id="4824" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">#现在让我们使用panda(pd)读取数据集</p><p id="e810" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">data = pd.read_csv('training.csv '，encoding = ' latin1 ')<br/>#因为数据集很长所以使用latin来解码和正确的起始字节</p><p id="653d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">data . dropna(in place = True)#删除所有空格<br/> #将所有文本改为小写。</p><p id="6e78" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">#Python对‘car’和‘CARS’的解释不同。我没有在这个程序中使用词干，但这个过程很简单，可以通过使用像“ntlk”这样的内置函数来完成。<br/> data['句子']=[entry . lower()for entry in data['句子']]</p><p id="3a54" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">data['情绪'] = np.where(data['情绪'].str.contains('正')，1，0)</p><p id="076c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">#上述步骤将正数划分为1，负数划分为0这本来可以由标签编码器完成，但是我的train_y数组是1 d <br/> Train_X，Test_X，Train_Y，Test _ Y = Train _ Test _ split(data[' Sentence ']，data[' perspective ']，Test _ size = 0.3)<br/>#将数据集以70:30的比例拆分为训练集和测试集</p><p id="87b2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">print(Train_X.shape，Train _ y . shape)#这有助于查看数据集中的行数</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div class="er es kn"><img src="../Images/c1495cdf88bfb021ea2760fc1cbd2045.png" data-original-src="https://miro.medium.com/v2/resize:fit:276/format:webp/1*vN4RVyvgb5RlyoCLJokBNA.png"/></div></figure><p id="53e8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">encoder = label encoder()#这样使用是为了将Y的所有条目适当地划分为1和0<br/>Train _ Y = encoder . fit _ transform(Train _ Y)<br/>Test _ Y = encoder . fit _ transform(Test _ Y)</p><p id="6369" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">d = PD . read _ CSV(" stop words . CSV ")<br/>my _ stop word = d . values . to list()#将数据类型转换为列表</p><p id="3899" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">#删除不需要的单词，如“是、是你、将等……”(stop words . CSV有单词列表)</p><p id="5313" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">#使用函数提取tfidf特征</p><p id="fa0f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">vectorizer = TfidfVectorizer(my _ stop word)<br/>vectorizer . fit _ transform(data[' Sentence '])<br/># feature _ names = vectorizer . get _ feature _ names()by this u可以查看是否删除了停用词和唯一重要的特征词</p><p id="8733" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">#训练数据和测试数据的tfidf值<br/>Train _ X _ tfi df = vectorizer . transform(Train _ X)<br/>Test _ X _ tfi df = vectorizer . transform(Test _ X)<br/>print(Train _ X _ tfi df)</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div class="er es ko"><img src="../Images/846158e1970afdd10e2dca6e65a86234.png" data-original-src="https://miro.medium.com/v2/resize:fit:586/format:webp/1*JgYMqofcC8rDsky_HY9y3g.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">(a，b) c :csr矩阵:a-内存索引b-每个数字的唯一二进制值c- tfidf值。</figcaption></figure><p id="d09f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">#SVM函数内置在库中<br/> SVM = svm。SVC(C=1.0，kernel='linear '，degree=3，gamma = ' auto ')<br/>SVM . fit(Train _ X _ tfi df，Train_Y)</p><p id="c23f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">#预测验证数据集上的标签<br/>预测_SVM = SVM.predict(Test_X_Tfidf)</p><p id="aedd" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">#使用accuracy_score函数获得准确度<br/> print("SVM准确度得分- &gt;"，accuracy_score(预测_SVM，测试_ Y)* 100)<br/>#如果您要输入一个输入句子并检查分类是正还是负<br/> lst = [ ] <br/> print("输入句子:")<br/><br/>)for I in range(0，2):<br/>ele = input()<br/>lst . append(ele)<br/><br/># print</p><figure class="ki kj kk kl fd ij er es paragraph-image"><div class="er es kp"><img src="../Images/40358313393703ee0a2eeed55eff7fb0.png" data-original-src="https://miro.medium.com/v2/resize:fit:622/format:webp/1*YDnrRGc_RM4fOIeJMN4N3w.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">输出</figcaption></figure><p id="c603" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">希望你能理解！检查下面的代码。</p><p id="59f8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">也发表在freshly build-</p><p id="2f9a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><a class="ae iu" href="https://freshlybuilt.com/sentimental-analysis-using-svm/" rel="noopener ugc nofollow" target="_blank">https://freshlybuilt.com/sentimental-analysis-using-svm/</a></p><div class="kq kr ez fb ks kt"><a href="https://github.com/rak02/sentimental-analysis" rel="noopener  ugc nofollow" target="_blank"><div class="ku ab dw"><div class="kv ab kw cl cj kx"><h2 class="bd hj fi z dy ky ea eb kz ed ef hh bi translated">rak 02/感性分析</h2><div class="la l"><h3 class="bd b fi z dy ky ea eb kz ed ef dx translated">基于支持向量机的情感分析。在GitHub上创建一个帐户，为rak 02/情感分析开发做贡献。</h3></div><div class="lb l"><p class="bd b fp z dy ky ea eb kz ed ef dx translated">github.com</p></div></div><div class="lc l"><div class="ld l le lf lg lc lh io kt"/></div></div></a></div></div></div>    
</body>
</html>