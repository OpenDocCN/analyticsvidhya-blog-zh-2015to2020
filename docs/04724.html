<html>
<head>
<title>SHAP Part 3: Tree SHAP</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">SHAP第三部分:树SHAP</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/shap-part-3-tree-shap-3af9bcd7cd9b?source=collection_archive---------0-----------------------#2020-03-30">https://medium.com/analytics-vidhya/shap-part-3-tree-shap-3af9bcd7cd9b?source=collection_archive---------0-----------------------#2020-03-30</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="d49e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">树SHAP是一种为基于决策树的模型计算精确SHAP值的算法。SHAP(SHapley Additive exPlanation)是一种解释任何机器学习模型输出的博弈论方法。SHAP的目标是将任何xᵢ实例的预测解释为其单个特征值贡献的总和。参见本系列<a class="ae jd" rel="noopener" href="/@rakesh.melezhath/shap-part-1-an-introduction-to-shap-58aa087a460c">的第一部分这里</a>对SHAP的简要理论介绍。</p><p id="d71c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">正如在第一篇文章中所解释的，SHAP值通过以下等式获得:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/0abd1a40335a6484c4ecfd436c99f3ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0gMGleWFLgVAD-5OMDllYg.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">符号:|M|是特征的总数。S表示不包括第I个特征的任何特征子集，而|S|是该子集的大小。fₛ()代表子集s的模型的预测函数</figcaption></figure><p id="ee3e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们计算一下简单回归树的SHAP值，以便更好地理解算法。考虑一个由10个样本组成的假设数据集，其中有三个数字自变量(即:x、y、z)和一个目标变量t。在将回归树拟合到该数据集时，我们得到了下面的树结构。看这里的代码文件:<a class="ae jd" href="https://github.com/Rakeshsuku/Medium-Blog" rel="noopener ugc nofollow" target="_blank"><em class="ju">Tree _ SHAP _ hypothetic _ example . ipynb</em></a>。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es jv"><img src="../Images/d9e3954bae260915a14bc0161b06a372.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TEopgun4fxAR-i7WyOJDoQ.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">n1，n2，n3，…，n7代表树的节点。s值表示落入每个节点的训练集中的样本数。</figcaption></figure><p id="a51a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们计算一个由[x=150，y=75，z=200]给出的<strong class="ih hj">实例I的SHAP值。</strong>这个实例的预测是<strong class="ih hj"> t=20 </strong>。请记住，SHAP是一种局部特征归因技术，它将模型中的每个预测解释为单个特征贡献的总和。</p><p id="dd05" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从本系列第一部分<a class="ae jd" rel="noopener" href="/@rakesh.melezhath/shap-part-1-an-introduction-to-shap-58aa087a460c">SHAP的理论解释中，我们了解到，我们可以从没有任何独立变量的零模型开始计算SHAP值，然后计算每个变量按顺序添加到该模型时的平均边际贡献；对所有可能的序列进行平均。因为我们这里有3个独立变量，所以我们必须考虑3个！=6个序列。让我们计算每个序列的边际贡献。注意，SHAP假设具有独立变量的任何子集s的模型的模型预测是给定子集xₛ.的预测的期望值</a></p><p id="503c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">空模型ϕ⁰的预测值(也称为基值)=训练集的平均预测值= (50*2 + 30*2 + 20*1 + 10*5)/10 = 23</p><p id="2db8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="ju">考虑顺序:x &gt; y &gt; z: </em> </strong></p><p id="0dcf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">1)首先，将特征x添加到空模型中。注意，对于<strong class="ih hj">选择的实例i </strong>，我们可以仅利用该信息来计算精确的预测，因为在通向叶节点n6的节点(n1 &amp; n3)中仅使用了变量x。因此，仅具有特征x的模型的预测是20。因此x在这个序列中的边际贡献，ϕˣ= 20–23 =-3。</p><p id="19ad" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2)现在，让我们将特征y添加到上述模型中(在步骤1中)。由于添加y不会改变所选实例I的预测，因此y在此序列中的边际贡献，ϕʸ= 20–20 = 0。</p><p id="a886" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">3)同样，在这个序列中z的边际贡献，ϕᶻ = 0。</p><p id="0fc7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="ju">接下来我们来考虑序列y &gt; z &gt; x: </em> </strong></p><p id="6af2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">1)首先，特征y被添加到空模型。第一节点n1使用x作为分离变量，因为x还不可用，所以我们将预测计算为(4/10)*(来自左侧子节点n2的预测)+ (6/10)*(来自右侧子节点n3的预测)；100、60和40分别是落入节点n1、n2和n3的训练样本的数量。</p><p id="46b3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">I)来自节点n2的预测:n2使用y作为分割变量，因为y是可用的(对于实例I，yᵢ = 75)，来自节点n2的预测= 50。</p><p id="256f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">ii)来自节点n3的预测:n3再次使用x作为分割变量。因此，通过类似的逻辑，预测从n3 = (1/6)*20 + (5/6)*10= 70/6。</p><p id="f0eb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">iii)因此，仅具有特征y的模型的预测是(4/10)*50 + (6/10)*(70/6) = 27。因此，y在这个序列中的边际贡献，ϕʸ= 27–23 = 4。</p><p id="b69f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2)接下来，我们将特征z添加到上述模型中。由于z在树的任何内部节点中不被用作分割变量，所以添加该特征不会以任何方式改变预测。因此在这个序列中z的边际贡献，ϕᶻ = 0。您可以通过遵循与步骤1相同的方法来验证这一点。</p><p id="d966" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">3)最后，我们将特征x添加到给出预测为20的模型中。因此，x在这个序列中的边际贡献是ϕˣ= 20–27 =-7。</p><p id="5fba" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">类似地，我们计算剩余序列的每个特征值的边际贡献:</p><p id="5888" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="ju">序列x &gt; z &gt; y: </em> ϕˣ = -3，ϕʸ = 0，ϕᶻ = 0</p><p id="140c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="ju">序列z &gt; x &gt; y: </em> ϕˣ⁴ = -3，ϕʸ⁴ = 0，ϕᶻ⁴ = 0</p><p id="4753" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="ju">序列z &gt; y &gt; x: </em> ϕˣ⁵ = -7，ϕʸ⁵ = 4，ϕᶻ⁵ = 0</p><p id="7354" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="ju">序列y &gt; x &gt; z: </em> ϕˣ⁶ = -7，ϕʸ⁶ = 4，ϕᶻ⁶ = 0</p><p id="fde0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，实例I的SHAP值由下式给出:</p><p id="d5c0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi">ϕˣ = (ϕˣ¹ + ϕˣ² + ϕˣ³ + ϕˣ⁴ + ϕˣ⁵ + ϕˣ⁶)/6 = (-3–7–3–3–7–7)/6 = -5</p><p id="536e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi">ϕʸ = (ϕʸ¹ + ϕʸ² + ϕʸ³ + ϕʸ⁴ + ϕʸ⁵ + ϕʸ⁶)/6 = (0+4+0+0+4+4)/6 = 2</p><p id="69cd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi">ϕᶻ = (ϕᶻ¹ + ϕᶻ² + ϕᶻ³ + ϕᶻ⁴ + ϕᶻ⁵ + ϕᶻ⁶)/6 = (0+0+0+0+0+0)/6 = 0</p><p id="81fa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">以及对实例I(20)=ϕ⁰+ϕˣ+ϕʸ+ϕᶻ= 23+(-5)+2+0 = 20的预测的解释；这可以解释如下:</p><p id="ecf3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="ju">在没有任何自变量信息的情况下，预测的基值为23；知道x=150会使预测值减少5，知道y = 75会使预测值增加2，最终预测值为20。知道z = 300对模型预测没有影响。</em></p><p id="1e2a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">SHAP为这种解释提供了一个很好的图示，如下。蓝色表示x值(=150)减少了预测，红色表示y值(=75)增加了预测。这个例子的代码文件可以在这里找到:<a class="ae jd" href="https://github.com/Rakeshsuku/Medium-Blog" rel="noopener ugc nofollow" target="_blank"><em class="ju">Tree _ SHAP _假想_示例. ipynb </em> </a>。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es jw"><img src="../Images/37f5d53dc4d490f7fa9b6eb66d2202b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dR-opE7tvbdg0ZE8h-_kKw.png"/></div></div></figure><h2 id="78d2" class="jx jy hi bd jz ka kb kc kd ke kf kg kh iq ki kj kk iu kl km kn iy ko kp kq kr bi translated">实际树SHAP算法</h2><p id="b44c" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">上述算法的计算复杂度是O(LT2ᴹ量级，其中t是树集合模型中树的数量，l是任何树中叶子的最大数量，m是特征的数量。在树SHAP的论文中，作者提出了这种算法的修改版本，它跟踪流入树的每个节点的子集的数量。改进的算法具有O(LTD)的计算复杂度，其中D是树的最大深度。</p><h2 id="fcbe" class="jx jy hi bd jz ka kb kc kd ke kf kg kh iq ki kj kk iu kl km kn iy ko kp kq kr bi translated"><strong class="ak"> SHAP互动值</strong></h2><p id="0c85" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">SHAP允许我们通过考虑成对的特征属性来计算相互作用的影响。这将产生一个属性值矩阵，表示所有特征对给定模型预测的影响。SHAP相互作用效应基于博弈论的沙普利相互作用指数，由下式给出</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es kx"><img src="../Images/432fc31ffe8d2994b95ae6f2cae3f638.png" data-original-src="https://miro.medium.com/v2/resize:fit:1270/format:webp/1*POFeBIuBT3JnvqxzPv_KqA.png"/></div></figure><p id="e896" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在哪里，</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es ky"><img src="../Images/c2ffa23f551453607f9a601947b9a169.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6ml-b7cDDtFgJAyyk83TmA.png"/></div></div></figure><p id="2a13" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上述等式表明，第I个特征相对于第j个特征的SHAP相互作用值可以解释为具有和不具有第j个特征的第I个特征的SHAP值之间的差。这允许我们使用计算SHAP值的算法来计算SHAP相互作用值。</p><p id="d99d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第I个和第j个之间的SHAP相互作用效应被平均分割(即ϕᵢⱼ=ϕⱼᵢ),并且总的相互作用效应是ϕᵢⱼ + ϕⱼᵢ.然后，预测的主要影响可通过某个特征的SHAP值和SHAP相互作用值之和的差值获得:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es kz"><img src="../Images/6cefb64722ad74f4707011a907c10855.png" data-original-src="https://miro.medium.com/v2/resize:fit:582/format:webp/1*syk-MsFJBhoEtKDvgGQ0yg.png"/></div></figure><h2 id="ca19" class="jx jy hi bd jz ka kb kc kd ke kf kg kh iq ki kj kk iu kl km kn iy ko kp kq kr bi translated"><strong class="ak">真实数据集上的SHAP树</strong></h2><p id="7f76" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">现在让我们使用<a class="ae jd" href="https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients" rel="noopener ugc nofollow" target="_blank"> UCI信用卡默认数据集</a>进一步探索树SHAP算法。值为{0:否，1:是}的二进制变量“<em class="ju">下个月的违约付款</em>”指示客户是否已经拖欠他/她的信用卡付款，该变量是目标变量(因变量)，与客户相关的23个变量，如年龄、教育等以及他/她以前的账单和付款历史可用作解释变量(自变量)。从UCI网站了解有关数据集的更多信息。我们将使用google colab来运行我们的代码。找到这里上传的代码文件:<a class="ae jd" href="https://github.com/Rakeshsuku/Medium-Blog" rel="noopener ugc nofollow" target="_blank">Tree _ SHAP _ UCI _信用卡_默认. ipynb </a>。</p><p id="df18" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们从安装shap库并加载所有需要的库开始。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es la"><img src="../Images/15e279a9c85a5526b8cf9a7a2a58df04.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*brLgH2PsAlHV2724yC2Ibw.png"/></div></div></figure><p id="324a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">接下来，从UCI网站下载数据集，并将数据读入熊猫数据框。请注意，我们已经删除了数据集中的ID列。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lb"><img src="../Images/b68f7d709b0e0df073ffefc235a4e8f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HlOYJjE8Tk_HXP6z8YQ-EA.png"/></div></div></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lc"><img src="../Images/4860f3bfb0b443a60282c2a9dd19d386.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tJ0T_8Wd2g2Kr4d_y8k3HQ.png"/></div></div></figure><p id="ba9c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们将数据集中的解释变量可视化。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es ld"><img src="../Images/4fa78e2c0aec0e83f045a20d261d1fbb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oE0ug3RseTlJVAH5D_i4mA.png"/></div></div></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es le"><img src="../Images/0e3667bee5fc1abd573c7cc701a1f38e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g22CF4HqaCP-2cdHS3Ksmg.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">x轴标签0-无默认值；1-默认</figcaption></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lf"><img src="../Images/94d2a6e397f0a2328d19eaa95d7c9764.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*s5RsEOCfyAOwT9mFDkPxkQ.png"/></div></div></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lg"><img src="../Images/fd90255a75984bb09a941c41e82f2027.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ljmpak6u0mfevOCno3LyEQ.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">图例:0-无默认值；1-默认</figcaption></figure><p id="0e97" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们看看目标变量的分布。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lf"><img src="../Images/56c9f9a9d31d29b479a87405247f212c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8-juA9UmVf5taTRgZHKo5Q.png"/></div></div></figure><p id="2f31" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将在这个数据集上训练一个lightgbm模型。我们看到PAY_*列的值范围从-2到8。因为lightgbm认为所有负值都是缺失值，所以我们在这些值上加3，使范围从1到11。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lh"><img src="../Images/801a2bd579659a4dff5aa8d5f0a69012.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ta9RMLularnHH3HGohyZfQ.png"/></div></div></figure><p id="638e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们将目标复制到一个新的变量y中，并将数据分成按目标变量分层的训练集和测试集。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es li"><img src="../Images/4642339d6565cb23913bbaa5fa7a4993.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y4omomFOBJ3nnz2TJpKYhQ.png"/></div></div></figure><p id="a7da" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们现在将构建一个基线lightgbm模型。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lj"><img src="../Images/e858bee7a489de63a4365bcc34ffd101.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lQ3LE-5EQ_4AE9jRKd_GyQ.png"/></div></div></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lf"><img src="../Images/c19e1cd12025507bf2b70cb3724acf7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dFssnAo9LpHoWD097CkJtw.png"/></div></div></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lk"><img src="../Images/b8a6cf6f5585b5126b34ad858c02f4fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5enE_9ydgklEZWEWEE-uBg.png"/></div></div></figure><p id="ede6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在让我们使用hyperopt来调整这个模型的超参数。如果你需要更多关于使用hyperopt的信息，请参考我的博文<a class="ae jd" rel="noopener" href="/analytics-vidhya/introduction-to-automatic-hyperparameter-optimization-with-hyperopt-e0b9c84d1059">这里</a>。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es ll"><img src="../Images/f513203f6eb03405897c6ffe91900a58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*J854xshwGyLVR_2gfgOfng.png"/></div></div></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lm"><img src="../Images/411c984fe01a71d87421a14e056be7a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*42cLfNuh3wdaiBRE-V04VQ.png"/></div></div></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es ln"><img src="../Images/a8179fa7baea2d3925330fab464b5fe9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HTLJZ1yoKSmhHO5QuMHf9A.png"/></div></div></figure><p id="ac8b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">调整后的模型给出了78.4%的ROC AUC。产生最佳结果的超参数值为:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lf"><img src="../Images/0b82a6db65093876a9678b3fbdfbbcf9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aBJFZChmwQX5H2Vc5D7aXg.png"/></div></div></figure><p id="8896" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们为找到的最佳超参数改装模型。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lc"><img src="../Images/4ba06ac5d64c4456c10847860e33d172.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L5LKf1sq7rDTt4AfJ-F9qA.png"/></div></div></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lf"><img src="../Images/a7f39d638bb64f690946d0f7d555c7d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UQ4npDWRB3BJGwGx2YZ3Zw.png"/></div></div></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lo"><img src="../Images/d330836d31c2bd8b969471e1d7d395e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g-yeUJhIPxMatDAa9NeOrg.png"/></div></div></figure><p id="f7a0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将创建测试数据集的新副本(X_test_disp ),用相应的类别值替换整数编码的类别变量，以便SHAP图更加直观。我们从<a class="ae jd" href="https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients" rel="noopener ugc nofollow" target="_blank"> UCI网站</a>获得分类级别的详细信息。记得我们给所有的PAY_*变量加了3。此外，我们使用“Unk_*”表示UCI站点中未定义的级别。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lf"><img src="../Images/31af636c6b5f00bf3ee9bc37a17b6c8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hOj3z_y2c3xKDjEDqVh_wA.png"/></div></div></figure><h2 id="55e3" class="jx jy hi bd jz ka kb kc kd ke kf kg kh iq ki kj kk iu kl km kn iy ko kp kq kr bi translated">计算SHAP值</h2><p id="8a3c" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">让我们计算shap值。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lp"><img src="../Images/0e7532076f1928cd455aefcd5cee644a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*erPSsnl-2-okO6o4LZ3xog.png"/></div></div></figure><p id="3f58" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我来简单解释一下对shap的论证。TreeExplainer()函数。</p><ul class=""><li id="3bff" class="lq lr hi ih b ii ij im in iq ls iu lt iy lu jc lv lw lx ly bi translated">模型:基于树的模型。目前树SHAP支持以下模型:XGBoost，LightGBM，CatBoost，py spark &amp; scikit-learn中大多数基于树的模型。</li><li id="fffa" class="lq lr hi ih b ii lz im ma iq mb iu mc iy md jc lv lw lx ly bi translated">数据:用于计算树SHAP算法中特征变量的边际贡献的数据集。这是一个可选参数，默认值为None。除非提供，否则将按照上面算法部分的说明使用训练数据集。</li><li id="f284" class="lq lr hi ih b ii lz im ma iq mb iu mc iy md jc lv lw lx ly bi translated">feature_perturbation:可以取两个值。“tree_path_dependent”是数据参数为None时的默认值。如果提供了数据参数，则“interventional”是默认值。干预方法使用共享数据集来计算存在相关输入要素时的条件期望。另一方面,“tree_path_dependent”方法使用训练数据集和落入每个节点的样本数，如算法部分所述。</li><li id="13fb" class="lq lr hi ih b ii lz im ma iq mb iu mc iy md jc lv lw lx ly bi translated">model_output:使用model_output='raw '(默认值)，SHAP值解释来自树的叶节点的原始预测。<strong class="ih hj">由于大多数梯度增强分类模型预测其叶节点中的logit (log-odds)，</strong> <strong class="ih hj"> SHAP值默认解释GBM模型的logit预测</strong>。这里见解释<a class="ae jd" href="https://github.com/slundberg/shap/issues/367#issuecomment-508575308" rel="noopener ugc nofollow" target="_blank">。其他可能的值有“概率”、“log_loss”或任何模型方法名称。用“log _ loss”SHAP值解释模型损失函数的对数。看到了吗？shap。TreeExplainer了解更多细节。</a></li></ul><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lm"><img src="../Images/c9fe3e1b142f2ab9763c018e49bcec3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fH62cOgELb2jr-lsOkFSRA.png"/></div></div></figure><p id="9f29" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于分类问题，explainer.shap_values()返回大小为n_classes的列表。因为这是一个二元分类模型，n_classes=2。该列表中的每个对象都是一个大小为[n_samples，n_features]的数组，并且对应于各个类的SHAP值。在本例中，shap_values[1]是正分类的shap值(<em class="ju">默认下月付款=是</em> ) &amp; shap_values[0]是负分类的SHAP值。对于回归模型，我们得到大小为[n_samples，n_features]的单组shap值。</p><p id="9cc1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">解释单个预测</strong></p><p id="4064" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们解释一下测试集中第一项的预测。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lj"><img src="../Images/63c5551bf424279460dd4bc7ef7aa1cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Bc2OkmUcRyq6r7UKw82Uew.png"/></div></div></figure><p id="1531" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">训练数据集上正类的基本logit值为-1.538。该样本的logit预测值为-0.27。<em class="ju"> PAY_2 </em>其次是<em class="ju"> LIMIT_BAL = 5e+4。</em></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lc"><img src="../Images/99f943d972acf75d4ea85e9861f8c1f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*H0KLOsHqm__NNQblMohpjQ.png"/></div></div></figure><p id="36ae" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">解释一个以上样本的预测</strong></p><p id="918d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果我们对每个样本取上面的图，将它们旋转90度并并排堆叠，我们可以在一个图中解释多个样本的预测:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lp"><img src="../Images/5dacd4bf9028e9f6f5aa833ef1d6c2c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_Bblvnxp9ss3DVFJvZD4AQ.png"/></div></div></figure><p id="4ee2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">默认情况下，样本按相似度排序。但是，我们可以将这种排序更改为按输出值排序，或按原始样本顺序排序，或按数据集中的任何数字自变量排序。颜色代码的含义与上图相同，红色特征增加了每个数据点的对数，蓝色特征减少了每个数据点的对数。</p><p id="3379" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> SHAP汇总图</strong> <br/> SHAP.summary_plot()可以绘制每个类的平均shap值，前提是提供一个shap值列表(分类问题的explainer.shap_values()的输出)，如下所示:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es me"><img src="../Images/31990604b874a3c063fcdb9fa949ab94.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2W2PAed0qDltlCqvn21j9w.png"/></div></div></figure><p id="6c4d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">注意，两个类的shap_values是二进制分类问题的加法逆。对于一个多类分类问题，上面的图会直观得多。我们也可以为我们感兴趣的类生成上面的图，如下所示。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es mf"><img src="../Images/a431f840ea752900c9ac0302a44eec4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XbhZUWO8ufm4bde94HRl8Q.png"/></div></div></figure><p id="7ca3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果提供了一组shap值(分类问题中单个类的shap值或回归问题的shap值)，shap.summary_plot()将为每个要素创建SHAP值的密度散点图，以确定每个要素对模型输出的影响程度。要素按所有样本的SHAP量值总和排序。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es mf"><img src="../Images/ecfb0fdf8ecb0651af1134d29393fbde.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cTSvl63BLdgTSqRWOOGe-w.png"/></div></div></figure><p id="f301" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">注意，对于分类数据，我们得到灰色点，因为整数编码值(对于分类变量)不能总是用于从低到高排列。但是，对于这个数据集，PAY_*变量大致对应于延迟支付的月数，因此可以用来对值进行排序。让我们绘制与上面相同的图形，将PAY_*变量视为数字变量(我们所要做的就是用上面的X_test替换X_test_disp)。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es mg"><img src="../Images/8884943d2a4660a8ba56dc6c30d36245.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-Y6odbK1V7dYYkv_M4osPw.png"/></div></div></figure><p id="0d39" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这个剧情就直观多了。我们观察到，对于所有PAY_*变量，随着支付延迟的增加，违约的对数优势增加。还要注意，随着支付金额(PAY_AMT*)的增加，违约概率的对数下降。从上面的图中可以观察到一个令人惊讶的现象:违约概率的对数随着给定信用额度(LIMIT_BAL)的增加而降低。这可能是因为信用卡公司必须向违约概率较低的客户提供更高的信用额度。因此，具有高LIMIT_BAL的客户也必须具有高PAY_AMT*值。让我们用SHAP依赖图进一步研究这个问题。</p><p id="85db" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> SHAP依赖图</strong></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es me"><img src="../Images/744e64eab617d2abb81cffdc6d495b5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y5cApteU0VQf1XpIBfLgHQ.png"/></div></div></figure><p id="1133" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们看到具有高LIMIT_BAL的客户也具有高PAY_AMT1值。对于高LIMIT_BAL样本，带底部的红色点簇显示了LIMIT_BAL与PAY_AMT1的相互作用效果。</p><p id="4088" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们也可以创建一个SHAP依赖图，分类变量如下。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es la"><img src="../Images/0b34a682ae046c26fc5a0d8020a4a8d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vt299gnjUsWCXtSOs3nkgA.png"/></div></div></figure><p id="f35e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">SHAP还可以选择似乎与主变量有最强相互作用的交互作用变量。让我们为对模型影响最大的前3个特征(平均形状值)创建一个形状依赖图。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es mh"><img src="../Images/3bc89b0cff2e30f0c60757b83baaff9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2-WyTlmUTnRjHu5R07LakA.png"/></div></div></figure><p id="5d5b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> SHAP互动值和互动汇总图</strong></p><p id="5259" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">LightGBM &amp; CatBoost模型目前不支持SHAP交互值，因为这些库对分类变量进行了特殊处理。关于github问题的评论<a class="ae jd" href="https://github.com/slundberg/shap/issues/292#issuecomment-432835057" rel="noopener ugc nofollow" target="_blank">见此</a>和<a class="ae jd" href="https://github.com/slundberg/shap/issues/662#issuecomment-508577551" rel="noopener ugc nofollow" target="_blank">见此</a>。请参见SHAP GitHub页面中的<a class="ae jd" href="https://slundberg.github.io/shap/notebooks/NHANES%20I%20Survival%20Model.html" rel="noopener ugc nofollow" target="_blank"> <em class="ju"> NHANES生存模型与XGBoost和SHAP交互值</em> </a>笔记本中的用例示例。</p><p id="920b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">本文的代码文件上传到这里:<a class="ae jd" href="https://github.com/Rakeshsuku/Medium-Blog" rel="noopener ugc nofollow" target="_blank">Tree _ SHAP _ UCI _信用卡_默认. ipynb </a>。</p><p id="cad7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">链接到本系列的其他文章:</strong></p><p id="fe46" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae jd" rel="noopener" href="/@rakesh.melezhath/shap-part-1-an-introduction-to-shap-58aa087a460c"> SHAP第一部:SHAP简介</a></p><p id="0859" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae jd" rel="noopener" href="/@rakesh.melezhath/shap-part-2-kernel-shap-3c11e7a971b1"> SHAP第二部分:内核SHAP </a></p><p id="a06a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">参考文献</strong></p><ol class=""><li id="5c7e" class="lq lr hi ih b ii ij im in iq ls iu lt iy lu jc mi lw lx ly bi translated">SHAP:解释模式预测的统一方法。arXiv:1705.07874</li><li id="15bb" class="lq lr hi ih b ii lz im ma iq mb iu mc iy md jc mi lw lx ly bi translated">树集成的一致个性化特征属性。arXiv:1802.03888 [cs。LG]</li><li id="2a50" class="lq lr hi ih b ii lz im ma iq mb iu mc iy md jc mi lw lx ly bi translated"><a class="ae jd" href="https://christophm.github.io/interpretable-ml-book/" rel="noopener ugc nofollow" target="_blank">可解释的机器学习——让黑盒模型变得可解释的指南。</a></li><li id="0870" class="lq lr hi ih b ii lz im ma iq mb iu mc iy md jc mi lw lx ly bi translated"><a class="ae jd" href="https://github.com/slundberg/shap" rel="noopener ugc nofollow" target="_blank">https://github.com/slundberg/shap</a></li></ol></div></div>    
</body>
</html>