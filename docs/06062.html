<html>
<head>
<title>Facial Expression Recognition using Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用深度学习的面部表情识别</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/facial-expression-recognition-using-deep-learning-3ec1d7426604?source=collection_archive---------19-----------------------#2020-05-10">https://medium.com/analytics-vidhya/facial-expression-recognition-using-deep-learning-3ec1d7426604?source=collection_archive---------19-----------------------#2020-05-10</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="c987" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">基于深度学习的面部表情识别研究综述</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/2d9054a8f0ebb2ce2c90df74bce404de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*D3JjWCjBf1OOfIAH"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">她是开心还是兴奋？|照片由<a class="ae jn" href="https://unsplash.com/@seteales?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">阿莱夫·维尼修斯</a>在<a class="ae jn" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><blockquote class="jo jp jq"><p id="29f6" class="jr js jt ju b jv jw ij jx jy jz im ka kb kc kd ke kf kg kh ki kj kk kl km kn hb bi translated">人脸识别是计算机视觉和人工智能领域中的一个重要且有前途的领域。信息可以从一个人的非语言意图中挖掘出来。目前，对面部表情识别(FER)进行分类的方法可以分为两大类:传统的FER方法和基于深度学习的方法。这项调查将简要涵盖传统的FER方法，并主要侧重于讨论FER的深度学习方法。</p></blockquote><h1 id="d71a" class="ko kp hi bd kq kr ks kt ku kv kw kx ky io kz ip la ir lb is lc iu ld iv le lf bi translated"><strong class="ak">传统FER方法概述</strong></h1><p id="ffca" class="pw-post-body-paragraph jr js hi ju b jv lg ij jx jy lh im ka li lj kd ke lk ll kh ki lm ln kl km kn hb bi translated">传统的FER方法通常依赖于大量的手工特征工程。图像需要进行预处理，研究人员需要为目标数据集选择合适的特征提取和分类方法。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lo"><img src="../Images/0f298cb9eb1c2c08256e8fa76ffafd99.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*AUbneunujOP2Jn38"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">传统的FER方法工作流程</figcaption></figure><p id="e4de" class="pw-post-body-paragraph jr js hi ju b jv jw ij jx jy jz im ka li kc kd ke lk kg kh ki lm kk kl km kn hb bi translated">与传统的FER方法相比，基于深度学习的方法将更加依赖于数据和硬件。然而，在传统的FER方法中，特征提取和分类都被分成两个部分。因此，不允许同时优化这两个阶段。传统FER方法的有效性将受到这两个部件中的每一个的性能的限制。</p></div><div class="ab cl lp lq gp lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="hb hc hd he hf"><h1 id="4924" class="ko kp hi bd kq kr lw kt ku kv lx kx ky io ly ip la ir lz is lc iu ma iv le lf bi translated"><strong class="ak">深度学习方法</strong></h1><p id="ea7f" class="pw-post-body-paragraph jr js hi ju b jv lg ij jx jy lh im ka li lj kd ke lk ll kh ki lm ln kl km kn hb bi translated">基于深度学习的方法通常会限制对图像处理和特征提取的依赖，并且对其环境更加鲁棒。深度学习在包括识别、分类和目标识别在内的机器学习任务中表现非常出色。有几种方法可以使用深度学习方法来识别FER。为FER提出的三种方法包括使用卷积神经网络(CNN)、长短期记忆(LSTM)模型和生成对抗网络(GAN)。</p><p id="dfb0" class="pw-post-body-paragraph jr js hi ju b jv jw ij jx jy jz im ka li kc kd ke lk kg kh ki lm kk kl km kn hb bi translated"><strong class="ju hj">卷积神经网络</strong></p><p id="ae2c" class="pw-post-body-paragraph jr js hi ju b jv jw ij jx jy jz im ka li kc kd ke lk kg kh ki lm kk kl km kn hb bi translated">CNN是用于图像识别和处理的人工神经网络的子集，专门用于识别图像中的某些特征。它由一个或多个卷积层组成，主要用于图像处理、分类和分割。以下架构显示了基于CNN的FER程序的流程示例。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mb"><img src="../Images/d5c20ce5b812744c9dcf2e59d60c0f6b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*VZiVBKXkbATvBZiP"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">CNN架构</figcaption></figure><p id="aa5b" class="pw-post-body-paragraph jr js hi ju b jv jw ij jx jy jz im ka li kc kd ke lk kg kh ki lm kk kl km kn hb bi translated"><strong class="ju hj">长短期记忆(LSTM) </strong></p><p id="7a06" class="pw-post-body-paragraph jr js hi ju b jv jw ij jx jy jz im ka li kc kd ke lk kg kh ki lm kk kl km kn hb bi translated">LSTM模型是一种人工递归神经网络，可用于提取连续帧内的时间特征。总部位于LSTM的FER过去曾被推荐用于视频序列，因为长距离上下文建模有助于提高情感分析的准确性。已经有研究，其中代表性状态帧的空间特征通过使用CNN来学习，并且LSTM模型用于学习空间表示的时间特征。这种提出的研究方法利用了从使用LSTM的面部序列中确定的代表性表情状态，而不是评估表情的强度或表情保持了多长时间。</p><p id="959b" class="pw-post-body-paragraph jr js hi ju b jv jw ij jx jy jz im ka li kc kd ke lk kg kh ki lm kk kl km kn hb bi translated"><strong class="ju hj">生成对抗网络</strong></p><p id="5bc5" class="pw-post-body-paragraph jr js hi ju b jv jw ij jx jy jz im ka li kc kd ke lk kg kh ki lm kk kl km kn hb bi translated">GAN是一个无监督的学习模型，由一个生成网络和一个判别网络组成。GANs已被广泛用于生成图像和合成看起来非常类似于真实图像的面部图像。已经有研究提出了端到端的基于GAN的模型，其中生成器的编码器-解码器结构学习面部图像的身份表示，然后基于表情和头部姿态来指定。所提出的模型还能够通过使用GAN模型自动生成图像的图像来增加FER训练数据集。</p></div><div class="ab cl lp lq gp lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="hb hc hd he hf"><h1 id="8ee9" class="ko kp hi bd kq kr lw kt ku kv lx kx ky io ly ip la ir lz is lc iu ma iv le lf bi translated">韵律学</h1><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mc"><img src="../Images/c8a5831309097a3238059e3394812ebb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*zz-9r8rBJjh9dlXz"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">FER相关数据集|来源:<a class="ae jn" href="https://www.mdpi.com/2073-8994/11/10/1189" rel="noopener ugc nofollow" target="_blank">面部表情识别:一项调查</a></figcaption></figure><p id="c9da" class="pw-post-body-paragraph jr js hi ju b jv jw ij jx jy jz im ka li kc kd ke lk kg kh ki lm kk kl km kn hb bi translated">训练和测试数据集用于评估不同的基于深度学习的FER模型的性能。有许多训练和测试数据集可用于面部情感识别。<a class="ae jn" href="https://www.mdpi.com/2073-8994/11/10/1189" rel="noopener ugc nofollow" target="_blank">FER的一项调查</a>展示了几个不同的FER相关数据集的概况。上面的图表显示了最能代表使用基于深度学习的FER模型(如CNN、LSTM模型和甘模型)的优势的数据集。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es md"><img src="../Images/3ae5a47acbac3fd738275946e83433fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:682/0*AnAzE5bLxj9W7w1q"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">FER使用CNN和LSTM在MMI和CK+数据集上的表现|来源:<a class="ae jn" href="https://www.mdpi.com/2073-8994/11/10/1189" rel="noopener ugc nofollow" target="_blank">面部表情识别:一项调查</a></figcaption></figure><p id="bbfa" class="pw-post-body-paragraph jr js hi ju b jv jw ij jx jy jz im ka li kc kd ke lk kg kh ki lm kk kl km kn hb bi translated">通过使用不同的FER数据集的性能显示，CNN框架可以应用于几乎所有的FER数据集，并达到稳定的精度。使用CK+和MMI数据集的性能表明，基于LSTM的FER方法在视频序列上表现良好。这证实了LSTM网络对于连续帧的时间特征提取表现良好。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es me"><img src="../Images/bc7a471af303d6fae4935865842ebb65.png" data-original-src="https://miro.medium.com/v2/resize:fit:996/0*5vtxukAStLE9OuZ5"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">使用CNN &amp; GANs在Oulu-CASIA、BU-3DFE和Multi-PIE数据集上对FER的性能|来源:<a class="ae jn" href="https://www.mdpi.com/2073-8994/11/10/1189" rel="noopener ugc nofollow" target="_blank">面部表情识别:调查</a></figcaption></figure><p id="6818" class="pw-post-body-paragraph jr js hi ju b jv jw ij jx jy jz im ka li kc kd ke lk kg kh ki lm kk kl km kn hb bi translated">类似地，使用BU-3DFE、Multi-PIE和Oulu-CASIA数据集的性能显示了使用基于GAN的FER方法对这些图像的显著准确性。GAN模型最适合用于生成逼真的面部图像。因此，基于GAN的模型适用于对没有变化的面部图像(静止图像)执行表情识别。</p></div><div class="ab cl lp lq gp lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="hb hc hd he hf"><h1 id="960d" class="ko kp hi bd kq kr lw kt ku kv lx kx ky io ly ip la ir lz is lc iu ma iv le lf bi translated">期末思想</h1><p id="eeaf" class="pw-post-body-paragraph jr js hi ju b jv lg ij jx jy lh im ka li lj kd ke lk ll kh ki lm ln kl km kn hb bi translated">随着机器学习领域的最新技术和领域的发展，面部表情识别(FER)最近吸引了很多关注。本文简要介绍了FER的一些传统方法和FER使用深度学习模型的几个模型。FER内部仍然存在挑战，也有很多机会来评估不同的FER算法。这项调查的目的是提供一个简单的了解，目前有什么，提供一些见解，并促进在这一领域的进一步研究。</p><p id="c378" class="pw-post-body-paragraph jr js hi ju b jv jw ij jx jy jz im ka li kc kd ke lk kg kh ki lm kk kl km kn hb bi translated"><em class="jt">关于本文内容的简明参考，请参考我的</em><a class="ae jn" href="https://www.slideshare.net/EmmelineTsen/facial-expression-recognition-fer-using-deep-learning" rel="noopener ugc nofollow" target="_blank"><em class="jt">slide share</em></a><em class="jt">。</em></p></div><div class="ab cl lp lq gp lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="hb hc hd he hf"><p id="0c2f" class="pw-post-body-paragraph jr js hi ju b jv jw ij jx jy jz im ka li kc kd ke lk kg kh ki lm kk kl km kn hb bi translated"><strong class="ju hj">参考文献</strong></p><ol class=""><li id="e454" class="mf mg hi ju b jv jw jy jz li mh lk mi lm mj kn mk ml mm mn bi translated">黄，杨，陈，冯，吕，王，谢(2019 . 9 . 20)。面部表情识别:综述。于2020年5月8日从<a class="ae jn" href="https://www.mdpi.com/2073-8994/11/10/1189" rel="noopener ugc nofollow" target="_blank">https://www.mdpi.com/2073-8994/11/10/1189</a>检索</li><li id="9031" class="mf mg hi ju b jv mo jy mp li mq lk mr lm ms kn mk ml mm mn bi translated">Divya，m .，Reddy，R. O .，&amp; Raghavendra，C. (2019)。基于卷积神经网络算法的有效人脸情感识别。<em class="jt">国际近期技术与工程期刊定期刊，</em> <em class="jt"> 8 </em> (4)，4351–4354。doi:</li><li id="2f27" class="mf mg hi ju b jv mo jy mp li mq lk mr lm ms kn mk ml mm mn bi translated">阿米迪公司和阿米迪公司(未标明)。卷积神经网络cheatsheet Star。2020年5月8日检索，来自<a class="ae jn" href="https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks" rel="noopener ugc nofollow" target="_blank">https://Stanford . edu/~ shervine/teaching/cs-230/cheat sheet-convolutionary-neural-networks</a></li></ol></div></div>    
</body>
</html>