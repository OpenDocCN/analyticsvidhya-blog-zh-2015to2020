<html>
<head>
<title>KNN vs Decision Tree vs Random Forest for handwritten digit recognition</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">手写数字识别的KNN vs决策树vs随机森林</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/knn-vs-decision-tree-vs-random-forest-for-handwritten-digit-recognition-470e864c75bc?source=collection_archive---------4-----------------------#2020-04-16">https://medium.com/analytics-vidhya/knn-vs-decision-tree-vs-random-forest-for-handwritten-digit-recognition-470e864c75bc?source=collection_archive---------4-----------------------#2020-04-16</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><figure class="hh hi ez fb hj hk er es paragraph-image"><div class="er es hg"><img src="../Images/0c545bab35de956732d6d6a6d6012d49.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*oUhWO5T1HtPwj5F8sy6tww.png"/></div><figcaption class="hn ho et er es hp hq bd b be z dx translated">取自MNIST数据集的手写数字</figcaption></figure><div class=""/><p id="6fed" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这篇文章中，我试图比较三种机器学习算法的性能，即决策树，随机森林和k最近邻算法，用于从著名的MNIST数据集中识别手写数字。</p><p id="424f" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">开始编码…</p><p id="a9e9" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">导入模块，加载我们的数据集</p><pre class="jo jp jq jr fd js jt ju jv aw jw bi"><span id="6a77" class="jx jy ht jt b fi jz ka l kb kc">import numpy as np<br/>import pandas as pd<br/>import matplotlib.pyplot as plt<br/>df = pd.read_csv(r"D:\ML data\digit prediction\train.csv")<br/>df.head()</span></pre><figure class="jo jp jq jr fd hk er es paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="er es kd"><img src="../Images/2587ff52a2d23a55c545e09d03432be2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HtNQ0fPk8eXLqNQFLsbqoQ.png"/></div></div><figcaption class="hn ho et er es hp hq bd b be z dx translated">这里，每个像素属性指定图像像素的像素强度</figcaption></figure><pre class="jo jp jq jr fd js jt ju jv aw jw bi"><span id="0f88" class="jx jy ht jt b fi jz ka l kb kc"><strong class="jt hu">#visualising our dataset using matplotlib</strong><br/>image0 = df.iloc[3,1:]<br/>image0                                                <br/>plt.imshow(np.array(image0).reshape(28,28))</span></pre><figure class="jo jp jq jr fd hk er es paragraph-image"><div class="er es ki"><img src="../Images/c6fe556e1ff59a25d9391a23c16f2b40.png" data-original-src="https://miro.medium.com/v2/resize:fit:660/format:webp/1*ycLSZPfO5_ZVLj9i99AV1g.png"/></div></figure><p id="b15a" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">创建我们的培训和测试数据</p><pre class="jo jp jq jr fd js jt ju jv aw jw bi"><span id="171f" class="jx jy ht jt b fi jz ka l kb kc">x = df.iloc[:,1:]<br/>y = df.iloc[:,0]<br/>from sklearn.model_selection import train_test_split<br/>xtrain , xtest ,ytrain, ytest = train_test_split(x,y,test_size =0.2,shuffle = False,random_state =7)</span></pre><p id="599f" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu">决策树</strong>🌲</p><pre class="jo jp jq jr fd js jt ju jv aw jw bi"><span id="7aea" class="jx jy ht jt b fi jz ka l kb kc">from sklearn.tree import DecisionTreeClassifier <br/>dtree = DecisionTreeClassifier()<br/>dtree.fit(xtrain , ytrain)</span><span id="6b6d" class="jx jy ht jt b fi kj ka l kb kc">from sklearn.metrics import confusion_matrix<br/>cmdtree = confusion_matrix(ytest,ypred)<br/>cmdtree ,dtree.score(xtest , ytest)</span></pre><figure class="jo jp jq jr fd hk er es paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="er es kk"><img src="../Images/195407ad54b6c9d6f074b1032fb60bd0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6QY18TSigNpV1j98cnan7g.png"/></div></div><figcaption class="hn ho et er es hp hq bd b be z dx translated">带有准确度分数的混淆矩阵</figcaption></figure><p id="0d69" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">85 %的准确率！咩！，肯定能做得更好</p><p id="3751" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu">随机森林</strong>🌴🌳🌳🌳</p><p id="72d7" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">使用随机森林算法，我们可以肯定地期望精确度的增加，因为它可以被认为是决策树算法的优化版本。</p><p id="8b99" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">用通俗的语言来说，随机森林算法考虑了我们训练数据的几个具体实例，将它们分成不同的组(在我的例子中是10个)，然后对这些组做出决定。</p><p id="2f20" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这些投票中，多数人投票决定最终结果。</p><pre class="jo jp jq jr fd js jt ju jv aw jw bi"><span id="8f7d" class="jx jy ht jt b fi jz ka l kb kc">from sklearn.ensemble import RandomForestClassifier<br/>rforest = RandomForestClassifier()<br/>rforest.fit(xtrain , ytrain)</span></pre><p id="502c" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">使用seaborn库更好地可视化混淆矩阵</p><pre class="jo jp jq jr fd js jt ju jv aw jw bi"><span id="d8d3" class="jx jy ht jt b fi jz ka l kb kc">cmrforest = confusion_matrix(ytest , ypred)<br/>import seaborn as sn<br/>plt.figure(figsize=(10,7))<br/>sn.heatmap(cmrforest ,annot=True , fmt = 'd')<br/>plt.xlabel('Predicted')<br/>plt.ylabel('Truth')<br/>rforest.score(xtest,ytest)</span></pre><figure class="jo jp jq jr fd hk er es paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="er es kl"><img src="../Images/c5fa631b051a7b51f69934396936f9e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K1kFqxapY_6VirYTlrZIVw.png"/></div></div><figcaption class="hn ho et er es hp hq bd b be z dx translated">更好看的混淆矩阵</figcaption></figure><p id="9e83" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">是的，准确度如预期的那样显著提高，准确度很高</p><figure class="jo jp jq jr fd hk er es paragraph-image"><div class="er es km"><img src="../Images/153a22e321fc73cc50b02f030b9ad5ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*qTgUFWYlYHKrDEuCbA2bLQ.jpeg"/></div></figure><p id="dccb" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu"> KNN ( K个最近邻居)</strong></p><pre class="jo jp jq jr fd js jt ju jv aw jw bi"><span id="f0bd" class="jx jy ht jt b fi jz ka l kb kc">from sklearn.neighbors import KNeighborsClassifier<br/>knn = KNeighborsClassifier()<br/>knn.fit(xtrain ,ytrain)<br/>ypred = knn.predict(xtest)<br/>from sklearn.metrics import accuracy_score<br/>accuracy_score(ypred,ytest)</span></pre><figure class="jo jp jq jr fd hk er es paragraph-image"><div role="button" tabindex="0" class="ke kf di kg bf kh"><div class="er es kn"><img src="../Images/178f74cdb5e47648bef844415a01849e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fYbZN5ztI-NDV2XWU3O6kw.png"/></div></div></figure><p id="b569" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">因此，准确率再次提高到96 %，但代价是什么呢？</p><p id="37a5" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">众所周知，KNN是一个懒惰的学习者，它会记住数据，因此训练时间为0。因为它不针对参数或权重进行训练。</p><p id="7869" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">它实际上在预测的时候做了所有的工作。其复杂度为n * m *d，其中n是训练数据的大小，m是测试数据的大小，d是每次测试要执行的操作的数量。</p><p id="51be" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">大约10多分钟后，它完成了预测。</p><p id="3fc2" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu">结论</strong></p><p id="22a3" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如上所述，决策树以85 %的准确率瞬间完成，随机森林以94 %的准确率用很少的运行时间完成，KNN以96 %的准确率用相当多的运行时间完成，并且一直占用资源。</p><p id="876b" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">完整的代码请参考我的github库<a class="ae ko" href="https://github.com/kashish07/" rel="noopener ugc nofollow" target="_blank">https://github.com/kashish07/</a></p><p id="b582" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">注意:没有使用神经网络，因为那样会破坏竞争。</p></div></div>    
</body>
</html>