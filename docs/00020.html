<html>
<head>
<title>CNN Architectures: LeNet, AlexNet, VGG, GoogLeNet, ResNet and more…</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">CNN架构:LeNet，AlexNet，VGG，GoogLeNet，ResNet等等…</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/cnns-architectures-lenet-alexnet-vgg-googlenet-resnet-and-more-666091488df5?source=collection_archive---------0-----------------------#2017-11-16">https://medium.com/analytics-vidhya/cnns-architectures-lenet-alexnet-vgg-googlenet-resnet-and-more-666091488df5?source=collection_archive---------0-----------------------#2017-11-16</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="da29" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">卷积神经网络</strong> ( <strong class="ih hj"> CNN </strong>，或<strong class="ih hj"> ConvNet </strong>)是一种特殊的多层神经网络，旨在通过最少的预处理直接从像素图像中识别视觉模式..ImageNet项目是一个大型视觉数据库，设计用于视觉对象识别软件研究。ImageNet项目举办了一年一度的软件竞赛，即<strong class="ih hj"> ImageNet大规模视觉识别挑战赛(</strong><a class="ae jd" href="https://en.wikipedia.org/wiki/ImageNet#ImageNet_Challenge" rel="noopener ugc nofollow" target="_blank"><strong class="ih hj">ils vrc</strong></a><strong class="ih hj">)</strong>，软件程序在比赛中竞争正确分类和检测对象和场景。这里我将谈谈ILSVRC主要竞争对手的CNN架构。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/b27d6c3ccb6bbbc8234acc08980510bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DBXf6dzNB78QPHGDofHA4Q.png"/></div></div></figure><h1 id="f611" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">LeNet-5 (1998年)</h1><p id="2ae5" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">LeNet-5是LeCun等人在1998年开发的一种7级卷积网络，用于对数字进行分类，被几家银行用于识别以32×32像素灰度输入图像数字化的支票上的手写数字。处理更高分辨率图像的能力需要更大和更多的卷积层，因此该技术受到计算资源可用性的限制。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es kt"><img src="../Images/f259fc23002070786a6c3a4e1f5cc4c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*MU7G1aH1jw-6eFiD.png"/></div></div></figure><h1 id="64ed" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">AlexNet (2012年)</h1><p id="835e" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">在2012年，<a class="ae jd" href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" rel="noopener ugc nofollow" target="_blank"> AlexNet </a>显著超越了所有之前的竞争对手，通过将前5名的误差从26%降至15.3%赢得了挑战。排在第二位的前5名错误率，不是CNN的变化，大约是26.2%。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es ku"><img src="../Images/3a253b072b3c2a8d03ff36ec570a6027.png" data-original-src="https://miro.medium.com/v2/resize:fit:1372/format:webp/0*xPOQ3btZ9rQO23LK.png"/></div></figure><p id="7bae" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">该网络的架构与Yann LeCun等人的LeNet非常相似，但更深入，每层有更多的滤波器，并有堆叠的卷积层。它包括11x11、5x5、3x3、卷积、最大池化、丢弃、数据扩充、ReLU激活、带动量的SGD。它在每个卷积和全连接层之后附加ReLU激活。AlexNet在两个Nvidia Geforce GTX 580 GPU上同时接受了6天的训练，这就是为什么他们的网络分成两个管道的原因。AlexNet由监督小组设计，该小组由Alex Krizhevsky、Geoffrey Hinton和Ilya Sutskever组成。</p><h1 id="bd10" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">ZFNet(2013年)</h1><p id="32bd" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">毫不奇怪，ILSVRC 2013年的获奖者也是CNN，后来被称为ZFNet。它实现了14.8%的前5名错误率，现在已经是前面提到的非神经错误率的一半。这主要是通过调整AlexNet的超级参数，同时保持与本文前面讨论的额外深度学习元素相同的结构来实现的。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es kv"><img src="../Images/c618d86e42d6c509654875d94bbc6939.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g-Iwui1uFUPPHxuq8GfL6Q.png"/></div></div></figure><h1 id="543d" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">GoogLeNet/Inception(2014年)</h1><p id="f32e" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">ILSVRC 2014竞赛的获胜者是来自谷歌的GoogLeNet(又名Inception V1)。取得了6.67%的前5名错误率！这非常接近人类水平的表现，挑战的组织者现在被迫评估。事实证明，这实际上很难做到，需要一些人工训练才能击败谷歌的准确性。经过几天的训练，人类专家(Andrej Karpathy)能够实现5.1%(单个模型)和3.6%(整体)的前5名错误率。该网络使用了受LeNet启发的CNN，但实现了一个被称为inception模块的新颖元素。它使用批量标准化，图像失真和RMSprop。该模块基于几个非常小的卷积，以便大大减少参数的数量。他们的架构由22层深度CNN组成，但将参数数量从6000万(AlexNet)减少到400万。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es kw"><img src="../Images/369bc1c997a4bef2712f8369f33e7b58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*rbWRzjKvoGt9W3Mf.png"/></div></div></figure><h1 id="722a" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">VGGNet (2014年)</h1><p id="f117" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">ILSVRC 2014竞赛的亚军被社区称为VGGNet，由Simonyan和Zisserman开发。VGGNet由16个卷积层组成，由于其非常统一的架构而非常吸引人。类似AlexNet，只有3x3的卷积，但是很多滤镜。在4个GPU上训练2-3周。它是当前社区中从图像中提取特征的最优选选择。VGGNet的权重配置是公开可用的，并且已经在许多其他应用和挑战中用作基线特征提取器。然而，VGGNet包含1.38亿个参数，处理起来可能有点困难。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es kw"><img src="../Images/b124202fead2c757aba935728a2aea93.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*V1muWIDnPVwZUuEv.png"/></div></div></figure><h1 id="b138" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">ResNet(2015年)</h1><p id="7908" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">最后，在ILSVRC 2015上，由何等人提出的所谓残差神经网络(ResNet)介绍了一种具有“跳过连接”的新架构，其特点是大量的批处理规范化。这种跳跃连接也被称为门控单元或门控循环单元，并且与最近在RNNs中应用的成功元素非常相似。由于这种技术，他们能够训练152层的神经网络，同时仍然具有比VGGNet更低的复杂性。它实现了3.57%的前5名错误率，在这个数据集上击败了人类水平的性能。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es kw"><img src="../Images/f1ffe0a2f3711cccaf6ec02f0cb9acc4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*pkrso8DZa0m6IAcJ.png"/></div></div></figure><p id="c995" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">AlexNet具有在具有交叉连接的两个GPU上训练的并行的两条CNN线路，GoogleNet具有初始模块，ResNet具有剩余连接。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es kx"><img src="../Images/e1a86276e4890e450c0a9af8c9f04b40.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZqkLRkMU2ObOQWIHLBg8sw.png"/></div></div></figure><p id="f738" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">汇总表</strong></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es ky"><img src="../Images/c9884e58ac1a0ad39c54fb79c77f97bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1078/format:webp/1*q1QRxnGxg8COheh8tWXAiw.png"/></div></figure></div><div class="ab cl kz la gp lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="hb hc hd he hf"><p id="4e54" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="lg">如果我说错了，如果你想让我补充什么，请评论指正:)</em></p></div></div>    
</body>
</html>