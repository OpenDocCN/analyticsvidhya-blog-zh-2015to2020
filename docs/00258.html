<html>
<head>
<title>A Must-Read NLP Tutorial on Neural Machine Translation — The Technique Powering Google Translate</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">关于神经机器翻译的必读NLP教程——支持谷歌翻译的技术</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/a-must-read-nlp-tutorial-on-neural-machine-translation-the-technique-powering-google-translate-c5c8d97d7587?source=collection_archive---------0-----------------------#2019-01-31">https://medium.com/analytics-vidhya/a-must-read-nlp-tutorial-on-neural-machine-translation-the-technique-powering-google-translate-c5c8d97d7587?source=collection_archive---------0-----------------------#2019-01-31</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/c1d90cb1052995a7968d0684f3b03350.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*7UBS4otQ9lhGSh2J.jpeg"/></div></div></figure><blockquote class="iq ir is"><p id="77fe" class="it iu iv iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">“如果你用一个人能理解的语言和他交谈，那会让他头脑发热。如果你用他自己的语言和他交谈，那会触及他的内心。”纳尔逊·曼德拉</p></blockquote><p id="6cb6" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">语言之美超越国界和文化。学习母语以外的语言是一个巨大的优势。但是通往双语或多语的道路往往是漫长的，永无止境的。</p><p id="6136" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">有如此多的细微差别，以至于我们迷失在文字的海洋中。然而，有了在线翻译服务，事情变得简单多了(我正看着你谷歌翻译！).</p><p id="7979" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">我一直想学一门英语以外的语言。早在2014年，我就尝试过学习德语。这既有趣又有挑战性。我最终不得不退出，但我怀有重新开始的愿望。</p><figure class="jw jx jy jz fd ij er es paragraph-image"><div class="er es jv"><img src="../Images/af0accc61b8d9446ad52d6001fed1837.png" data-original-src="https://miro.medium.com/v2/resize:fit:870/format:webp/0*tHrSJrAoOoYeYmpt.png"/></div></figure><p id="4c37" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">快进到2019年，我很幸运能够为任何可能的语言对构建一个语言翻译器。自然语言处理是多么大的一件好事啊！</p><p id="2af0" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">在本文中，我们将介绍使用Keras构建德语到英语语言翻译模型的步骤。我们还将借助后见之明，快速浏览一下机器翻译系统的历史。</p><p id="9743" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">本文假设读者熟悉RNN、LSTM和喀拉斯。下面是几篇关于它们的文章:</p><ul class=""><li id="fc36" class="ka kb hi iw b ix iy jb jc js kc jt kd ju ke jr kf kg kh ki bi translated"><a class="ae kj" href="https://www.analyticsvidhya.com/blog/2017/12/introduction-to-recurrent-neural-networks/" rel="noopener ugc nofollow" target="_blank"> <em class="iv">递归神经网络简介</em> </a></li><li id="9aa2" class="ka kb hi iw b ix kk jb kl js km jt kn ju ko jr kf kg kh ki bi translated"><a class="ae kj" href="https://www.analyticsvidhya.com/blog/2017/12/fundamentals-of-deep-learning-introduction-to-lstm/" rel="noopener ugc nofollow" target="_blank"> <em class="iv">长短期记忆简介</em> </a></li></ul><h1 id="dc84" class="kp kq hi bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">目录</h1><ol class=""><li id="3f9b" class="ka kb hi iw b ix ln jb lo js lp jt lq ju lr jr ls kg kh ki bi translated">理解问题陈述</li><li id="5ef6" class="ka kb hi iw b ix kk jb kl js km jt kn ju ko jr ls kg kh ki bi translated">序列间预测简介</li><li id="3e09" class="ka kb hi iw b ix kk jb kl js km jt kn ju ko jr ls kg kh ki bi translated">使用Keras在Python中实现</li></ol><h1 id="fc75" class="kp kq hi bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">理解问题陈述</h1><p id="00f1" class="pw-post-body-paragraph it iu hi iw b ix ln iz ja jb lo jd je js lt jh ji jt lu jl jm ju lv jp jq jr hb bi translated">让我们回到我们在引言部分停止的地方，即学习德语。然而，这一次我将让我的机器来完成这项任务。<strong class="iw hj">目标是使用神经机器翻译(NMT)系统将德语句子转换成英语句子。</strong></p><figure class="jw jx jy jz fd ij er es paragraph-image"><div class="er es lw"><img src="../Images/b491170bc2169348f622741731503b5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1308/format:webp/0*yIvn4UtvE0-487dO.png"/></div></figure><p id="d808" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">我们将使用来自http://www.manythings.org/anki/的德语-英语句子对数据。你可以从<a class="ae kj" href="http://www.manythings.org/anki/deu-eng.zip" rel="noopener ugc nofollow" target="_blank">这里</a>下载。</p><h1 id="e7f8" class="kp kq hi bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">序列间(Seq2Seq)建模简介</h1><p id="bb0c" class="pw-post-body-paragraph it iu hi iw b ix ln iz ja jb lo jd je js lt jh ji jt lu jl jm ju lv jp jq jr hb bi translated">序列到序列(seq2seq)模型用于各种NLP任务，例如文本摘要、语音识别、DNA序列建模等。我们的目标是把给定的句子从一种语言翻译成另一种语言。</p><p id="0b18" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">在这里，输入和输出都是句子。换句话说，这些句子是一系列进出模型的单词。这是序列到序列建模的基本思想。下图试图解释这种方法。</p><figure class="jw jx jy jz fd ij er es paragraph-image"><div class="er es lx"><img src="../Images/a23d90dd89832624394555f6514edc2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1218/format:webp/0*g5K_EtU602q25P9p.png"/></div></figure><p id="0a38" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated"><strong class="iw hj">典型的seq2seq模型有两个主要组成部分— </strong></p><p id="9c39" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">a)编码器<br/> b)解码器</p><p id="2172" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">这两个部分本质上是两个不同的递归神经网络(RNN)模型组合成一个巨大的网络:</p><figure class="jw jx jy jz fd ij er es paragraph-image"><div class="er es ly"><img src="../Images/e17ccd76c077ea2ba3a9edd2a6cfd745.png" data-original-src="https://miro.medium.com/v2/resize:fit:1028/format:webp/0*9heSYJud0AQ-0upK.png"/></div></figure><p id="ed96" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">我在下面列出了序列到序列建模的几个重要用例(当然除了机器翻译):</p><ul class=""><li id="c513" class="ka kb hi iw b ix iy jb jc js kc jt kd ju ke jr kf kg kh ki bi translated">语音识别</li><li id="c5ba" class="ka kb hi iw b ix kk jb kl js km jt kn ju ko jr kf kg kh ki bi translated">命名实体/主题提取从文本主体中识别主要主题</li><li id="80ac" class="ka kb hi iw b ix kk jb kl js km jt kn ju ko jr kf kg kh ki bi translated">关系分类用于标记在上述步骤中标记的各种实体之间的关系</li><li id="e647" class="ka kb hi iw b ix kk jb kl js km jt kn ju ko jr kf kg kh ki bi translated">聊天机器人技能，具备对话能力并与客户互动</li><li id="380e" class="ka kb hi iw b ix kk jb kl js km jt kn ju ko jr kf kg kh ki bi translated">文本摘要生成大量文本的简明摘要</li><li id="2a85" class="ka kb hi iw b ix kk jb kl js km jt kn ju ko jr kf kg kh ki bi translated">问答系统</li></ul><h1 id="1ad9" class="kp kq hi bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">使用Keras在Python中实现</h1><p id="83b6" class="pw-post-body-paragraph it iu hi iw b ix ln iz ja jb lo jd je js lt jh ji jt lu jl jm ju lv jp jq jr hb bi translated">是时候把手弄脏了！没有比通过亲眼看到结果来学习一个话题更好的感觉了。我们将启动我们最喜欢的Python环境(对我来说是Jupyter笔记本),然后直接进入正题。</p><h1 id="276f" class="kp kq hi bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">导入所需的库</h1><figure class="jw jx jy jz fd ij"><div class="bz dy l di"><div class="lz ma l"/></div></figure><h1 id="52af" class="kp kq hi bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">将数据读入我们的IDE</h1><p id="98be" class="pw-post-body-paragraph it iu hi iw b ix ln iz ja jb lo jd je js lt jh ji jt lu jl jm ju lv jp jq jr hb bi translated">我们的数据是一个文本文件。txt)的英德句子对。首先，我们将使用下面定义的函数读取文件。</p><figure class="jw jx jy jz fd ij"><div class="bz dy l di"><div class="lz ma l"/></div></figure><p id="39af" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">让我们定义另一个函数，将文本分割成由' \n '分隔的英语-德语对。然后我们将这些句子分别分成英语句子和德语句子。</p><figure class="jw jx jy jz fd ij"><div class="bz dy l di"><div class="lz ma l"/></div></figure><p id="6496" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">我们现在可以使用这些函数将文本以我们想要的格式读入一个数组。</p><pre class="jw jx jy jz fd mb mc md me aw mf bi"><span id="0511" class="mg kq hi mc b fi mh mi l mj mk">data = read_text("deu.txt") <br/>deu_eng = to_lines(data) <br/>deu_eng = array(deu_eng)</span></pre><p id="e4db" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated"><strong class="iw hj">实际数据包含超过150，000个句子对。但是，我们将只使用前50，000个句子对来减少模型的训练时间。</strong>你可以根据你系统的计算能力改变这个数字(或者如果你觉得幸运的话！).</p><pre class="jw jx jy jz fd mb mc md me aw mf bi"><span id="43af" class="mg kq hi mc b fi mh mi l mj mk">deu_eng = deu_eng[:50000,:]</span></pre><h1 id="0dd3" class="kp kq hi bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">文本预处理</h1><p id="f2a0" class="pw-post-body-paragraph it iu hi iw b ix ln iz ja jb lo jd je js lt jh ji jt lu jl jm ju lv jp jq jr hb bi translated">这在任何项目中都是非常重要的一步，尤其是在NLP中。我们处理的数据通常是非结构化的，因此在进入模型构建部分之前，我们需要注意一些事情。</p><p id="ffd4" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated"><strong class="iw hj">(一)文字清理</strong></p><p id="f645" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">先来看看我们的数据。这将帮助我们决定采用哪些预处理步骤。</p><pre class="jw jx jy jz fd mb mc md me aw mf bi"><span id="ba8a" class="mg kq hi mc b fi mh mi l mj mk">deu_eng</span></pre><figure class="jw jx jy jz fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ml"><img src="../Images/8a00afc1514a3dbb930ebabe95cd8f88.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x9Z5TUmwhjH8O1cjULVy8g.png"/></div></div></figure><p id="1e21" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">我们将去掉标点符号，然后将所有文本转换成小写。</p><figure class="jw jx jy jz fd ij"><div class="bz dy l di"><div class="lz ma l"/></div></figure><p id="c339" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated"><strong class="iw hj"> (b)文本到序列的转换</strong></p><p id="9f68" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">Seq2Seq模型要求我们将输入和输出句子都转换成固定长度的整数序列。</p><p id="1fa0" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">但在此之前，让我们想象一下句子的长度。我们将分别在英语和德语的两个单独的列表中捕获所有句子的长度。</p><figure class="jw jx jy jz fd ij"><div class="bz dy l di"><div class="lz ma l"/></div></figure><figure class="jw jx jy jz fd ij er es paragraph-image"><div class="er es mm"><img src="../Images/e156a3f62777226020b1634816b34d1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:766/format:webp/0*E36b7xkYRopFWzLz.png"/></div></figure><p id="6216" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">非常直观——德语句子的最大长度是11个，英语短语的最大长度是8个。</p><p id="ce87" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">接下来，通过使用Keras的<em class="iv"> Tokenizer() </em>类对我们的文本数据进行矢量化。它会把我们的句子变成整数序列。然后，我们可以用零填充这些序列，使所有的序列长度相同。</p><p id="33bb" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">请注意，我们将为德语和英语句子准备标记符:</p><figure class="jw jx jy jz fd ij"><div class="bz dy l di"><div class="lz ma l"/></div></figure><p id="55d8" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">下面的代码块包含一个准备序列的函数。如上所述，它还将执行序列填充到最大句子长度。</p><figure class="jw jx jy jz fd ij"><div class="bz dy l di"><div class="lz ma l"/></div></figure><h1 id="a16d" class="kp kq hi bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">模型结构</h1><p id="0c58" class="pw-post-body-paragraph it iu hi iw b ix ln iz ja jb lo jd je js lt jh ji jt lu jl jm ju lv jp jq jr hb bi translated">我们现在将数据分为训练集和测试集，分别用于模型训练和评估。</p><figure class="jw jx jy jz fd ij"><div class="bz dy l di"><div class="lz ma l"/></div></figure><p id="2fb2" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">该给句子编码了。我们将编码<strong class="iw hj">德语句子作为输入序列</strong>，编码<strong class="iw hj">英语句子作为目标序列</strong>。对于训练和测试数据集都必须这样做。</p><figure class="jw jx jy jz fd ij"><div class="bz dy l di"><div class="lz ma l"/></div></figure><p id="4269" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">激动人心的部分来了！</p><p id="dd37" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">我们将从定义Seq2Seq模型架构开始:</p><ul class=""><li id="ba70" class="ka kb hi iw b ix iy jb jc js kc jt kd ju ke jr kf kg kh ki bi translated">对于编码器，我们将使用嵌入层和LSTM层</li><li id="6eb0" class="ka kb hi iw b ix kk jb kl js km jt kn ju ko jr kf kg kh ki bi translated">对于解码器，我们将使用另一个LSTM层，然后是一个密集层</li></ul><figure class="jw jx jy jz fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mn"><img src="../Images/025aabba8d6f90a789385d4680585681.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*UKxORA7IlU29eEXg.png"/></div></div></figure><figure class="jw jx jy jz fd ij"><div class="bz dy l di"><div class="lz ma l"/></div></figure><p id="02ff" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">我们在这个模型中使用RMSprop优化器，因为当使用递归神经网络时，它通常是一个很好的选择。</p><figure class="jw jx jy jz fd ij"><div class="bz dy l di"><div class="lz ma l"/></div></figure><p id="6b9e" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">请注意，我们使用了'<em class="iv">sparse _ categorial _ cross entropy</em>'作为损失函数。这是因为该函数允许我们按原样使用目标序列，而不是一键编码格式。使用如此庞大的词汇对目标序列进行一次性编码可能会消耗我们系统的全部内存。</p><p id="961d" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">我们都准备好开始训练我们的模型了！</p><p id="bb4c" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated"><strong class="iw hj">我们将对其进行30个时期的训练，批次大小为512，验证分割为20%。</strong> 80%的数据将用于训练模型，其余用于评估模型。你可以改变和摆弄这些超参数。</p><p id="4819" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">我们还将使用<strong class="iw hj"> ModelCheckpoint() </strong>函数来保存验证损失最低的模型。我个人更喜欢这种方法，而不是提前停止。</p><figure class="jw jx jy jz fd ij"><div class="bz dy l di"><div class="lz ma l"/></div></figure><p id="91c8" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">让我们比较一下训练损失和验证损失。</p><pre class="jw jx jy jz fd mb mc md me aw mf bi"><span id="5d52" class="mg kq hi mc b fi mh mi l mj mk">plt.plot(history.history['loss']) plt.plot(history.history['val_loss']) plt.legend(['train','validation']) <br/>plt.show()</span></pre><figure class="jw jx jy jz fd ij er es paragraph-image"><div class="er es mo"><img src="../Images/65daa1731c018778348b13d753a52418.png" data-original-src="https://miro.medium.com/v2/resize:fit:934/format:webp/0*lUF_a2s_nXwPth8c.png"/></div></figure><p id="feba" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">从上面的图中可以看出，20个时期后，验证损失停止下降。</p><p id="585e" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">最后，我们可以加载保存的模型，并对看不见的数据——testX进行预测。</p><figure class="jw jx jy jz fd ij"><div class="bz dy l di"><div class="lz ma l"/></div></figure><p id="00d4" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">这些预测是整数序列。我们需要将这些整数转换成相应的单词。让我们定义一个函数来做这件事:</p><figure class="jw jx jy jz fd ij"><div class="bz dy l di"><div class="lz ma l"/></div></figure><p id="374b" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">将预测转换成文本(英语):</p><figure class="jw jx jy jz fd ij"><div class="bz dy l di"><div class="lz ma l"/></div></figure><p id="7ece" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">让我们将原始英语句子放入测试数据集中，将预测的句子放入数据帧中:</p><pre class="jw jx jy jz fd mb mc md me aw mf bi"><span id="2369" class="mg kq hi mc b fi mh mi l mj mk">pred_df = pd.DataFrame({'actual' : test[:,0], 'predicted' : <br/>                        preds_text})</span></pre><p id="a84c" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">我们可以随机打印一些实际和预测的实例，看看我们的模型表现如何:</p><pre class="jw jx jy jz fd mb mc md me aw mf bi"><span id="0ab2" class="mg kq hi mc b fi mh mi l mj mk"># print 15 rows randomly <br/>pred_df.sample(15)</span></pre><figure class="jw jx jy jz fd ij er es paragraph-image"><div class="er es mp"><img src="../Images/7d866e4fbf70693a871137a050fa824e.png" data-original-src="https://miro.medium.com/v2/resize:fit:656/format:webp/0*_f27VH06COAoihng.png"/></div></figure><p id="41ba" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">我们的Seq2Seq模型做得不错。但是有几个例子，它错过了理解关键词。例如，它将“我厌倦了波士顿”翻译成“我是波士顿”。</p><p id="4fab" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">这些是你在NLP中经常会遇到的挑战。但是这些并不是不可逾越的障碍。我们可以通过使用更多的训练数据和建立更好(或更复杂)的模型来缓解这些挑战。</p><p id="8c79" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated"><strong class="iw hj">访问完整代码</strong> <a class="ae kj" href="https://github.com/prateekjoshi565/machine_translation/blob/master/german_to_english.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="iw hj">此处</strong> </a> <strong class="iw hj">。</strong></p><h1 id="acb0" class="kp kq hi bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">结束注释</h1><p id="31b3" class="pw-post-body-paragraph it iu hi iw b ix ln iz ja jb lo jd je js lt jh ji jt lu jl jm ju lv jp jq jr hb bi translated">即使使用非常简单的Seq2Seq模型，结果也相当令人鼓舞。通过在更大的数据集上使用更复杂的编码器-解码器模型，我们可以很容易地提高这种性能。</p><p id="fa10" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">我能想到的另一个实验是在包含较长句子的数据集上尝试seq2seq方法。你尝试的越多，你对这个广阔而复杂的空间了解的就越多。</p><p id="e5be" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated"><em class="iv">欢迎致电</em><strong class="iw hj"><em class="iv">prateekjoshi565@gmail.com</em></strong><em class="iv">联系我，进行一对一讨论。</em></p></div><div class="ab cl mq mr gp ms" role="separator"><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv mw"/><span class="mt bw bk mu mv"/></div><div class="hb hc hd he hf"><p id="d90d" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated"><em class="iv">原载于2019年1月31日</em><a class="ae kj" href="https://www.analyticsvidhya.com/blog/2019/01/neural-machine-translation-keras/" rel="noopener ugc nofollow" target="_blank"><em class="iv">www.analyticsvidhya.com</em></a>T22。</p></div></div>    
</body>
</html>