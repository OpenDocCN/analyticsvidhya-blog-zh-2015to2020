<html>
<head>
<title>Neural Style Transfer Simplified</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">简化的神经类型转移</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/neural-style-transfer-simplified-b91b990028d?source=collection_archive---------1-----------------------#2019-06-05">https://medium.com/analytics-vidhya/neural-style-transfer-simplified-b91b990028d?source=collection_archive---------1-----------------------#2019-06-05</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="8758" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用Tensorflow和GoogleCollab中的这一步一步实现来生成精美的艺术品</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/f96620a24232456afa1074eb60263ea2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GiF72odQz_8HFFq4vYY66g.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">用神经风格转移算法生成的艺术品示例。(来源:<a class="ae jt" href="https://towardsdatascience.com/light-on-math-machine-learning-intuitive-guide-to-neural-style-transfer-ef88e46697ee" rel="noopener" target="_blank">https://towards data science . com/light-on-math-machine-learning-intuitive-guide-to-neural-style-transfer-ef88e 46697 ee</a>)</figcaption></figure><h1 id="9b80" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">介绍</h1><p id="1943" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">在过去的几年里，神经网络已经被广泛应用于图像识别。最酷的应用之一是由Leon A. Gatys最初提出的<a class="ae jt" href="https://arxiv.org/abs/1508.06576" rel="noopener ugc nofollow" target="_blank">神经类型转移</a>算法。</p><p id="8986" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用预先训练的模型和简单的优化过程，该算法将两幅独立图像的风格和内容结合成一幅杰作。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es kx"><img src="../Images/d4696ae485dc268fc98e47f39c0bfdba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g_zpp_Ea0Dk8cOsEWmByqw.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">使用神经样式转移将内容和样式图像组合成单个图像</figcaption></figure><p id="f34e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">已经有几篇文章解释了算法理论和许多开源实现。然而，我面临着从零开始实现算法并让它工作的困难。</p><p id="6b48" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，本文与Google Collab  分享了一个在Tensorflow中逐步简化的<a class="ae jt" href="https://github.com/tusharsircar95/Iterative-Neural-Style-Transfer" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">实现，这样即使是初学者也可以使用它并获得惊人的效果。我假设对张量流会话和图形有基本的理解。</strong></a></p><p id="43a4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">但在此之前，这里有一个神经风格转移算法的快速解释。如果你熟悉这个，你<a class="ae jt" href="#1075" rel="noopener ugc nofollow">直接跳到</a>实现细节。</p><h1 id="a122" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">直觉</h1><p id="f8ed" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">任何图像都可以认为有两个组成部分:<br/> <strong class="ih hj">内容:</strong>对象及其在图像中的空间排列<strong class="ih hj"> <br/>风格:</strong>纹理、视觉模式和配色方案</p><p id="3799" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们将内容要复制的图像定义为I_CONTENT，样式要复制的图像定义为I_STYLE。然后，目标是生成一个图像(I_TARGET ),其内容为I_CONTENT，样式为I_STYLE。</p><p id="c6dd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了实现这一点，最初用随机像素填充的图像被反复修改，直到获得期望的内容和风格。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ky"><img src="../Images/920b8e93516f85d98edc6d4f0d046b34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o2ymvTt0Cq-6FA9TmuJtBw.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">将有噪声的图像转换成具有预定义图像的内容和风格特征的图像的迭代步骤(来源:<a class="ae jt" href="https://arxiv.org/pdf/1508.06576.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1508.06576.pdf</a></figcaption></figure><h2 id="b0ac" class="kz jv hi bd jw la lb lc ka ld le lf ke iq lg lh ki iu li lj km iy lk ll kq lm bi translated">它是如何工作的？</h2><p id="21a1" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">我们在上面看到，最初有噪声的图像被反复修改以匹配所选图像的内容和风格。</p><p id="d264" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">但是我们如何度量两幅图像之间的内容相似性或者风格相似性呢？这就是预训练卷积神经网络(CNN)发挥作用的地方。</p><p id="55ec" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当内容、风格和目标图像通过预先训练的网络时，让Cᵢⱼˡ、Sᵢⱼˡ和Tᵢⱼˡ作为层<em class="ln"> l </em>的<em class="ln"> i </em> ᵗʰ特征地图的<em class="ln"> j </em> ᵗʰ激活。<br/>(假设特征图展平)。此外，H、W和C是指高度、宽度和层<em class="ln"> l. </em>的通道数</p><h2 id="0abe" class="kz jv hi bd jw la lb lc ka ld le lf ke iq lg lh ki iu li lj km iy lk ll kq lm bi translated">内容损失</h2><p id="ac91" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">在用于对象检测的巨大图像数据集上训练的CNN的较高层学习明确地识别和学习图像内对象(内容)的表示，而不是学习精确的像素值。</p><p id="a5df" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，在较高层生成相似特征地图激活的图像将具有相似的内容。形式上，我们可以将在层<em class="ln"> l </em>测量的内容损失定义如下:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lo"><img src="../Images/17dcda5250cac43e6a7dc1e99c69b795.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2ZXj9REVtvyVde4pb-igrw.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">层l处图像X和Y之间的内容损失度量</figcaption></figure><p id="af33" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这基本上是通过CNN时图像X和图像Y的单独激活之间的归一化平方误差。</p><h2 id="d8fe" class="kz jv hi bd jw la lb lc ka ld le lf ke iq lg lh ki iu li lj km iy lk ll kq lm bi translated">风格丧失</h2><p id="e3c7" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">风格是以特定图层上不同特征地图激活之间的相关性来衡量的。这在Gram矩阵(G)中正式表示如下:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lp"><img src="../Images/193b333465a665f78df5c090a2ff69c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cHwP81HaM6LBVrV1aJu74Q.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">Gram矩阵:当图像X通过神经网络时，在神经网络的层l捕获不同特征图之间的相关性</figcaption></figure><p id="10fd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Gᵢⱼˡ在层<em class="ln"> l <br/> </em>捕捉到<em class="ln"> i </em> ᵗʰ和<em class="ln"> j </em> ᵗʰ特征图之间的相关性，因此，在层<em class="ln"> l </em>测量的风格损失定义如下:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lq"><img src="../Images/4be6ba57cf160106979f8d82573adb3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GDBI7ZX5nrLF6tP1r0Nr6g.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">在层l的图像X和Y之间测量的风格损失</figcaption></figure><p id="44a5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">注意，可以在网络的不同层测量内容损失和风格损失，以形成最终的损失函数。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lr"><img src="../Images/c39b492e5aff9e70c7c17e1deaae48dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Wj2suerqXZagfIO2TMADRQ.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">总损失，每一层和每一类损失都有特定的权重</figcaption></figure><p id="e66a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">cᵢ和sᵢ是分别给予在层<em class="ln"> l计算的内容和风格损失的权重。<br/> </em> α和β分别是给予整体内容和风格损失的权重。</p><p id="b6c2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在最初的实现中，VGG-19被用作预训练的CNN，并且使用了内容和风格层的不同组合。</p><p id="2ede" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">理论说够了，让我们开始实施吧。</p><h1 id="1075" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">履行</h1><p id="e639" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">为此我们将使用谷歌Colab。它本质上是一个免费的GPU，你可以利用它来运行你的项目。</p><p id="7f43" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">设置:</strong> <br/>打开<a class="ae jt" href="https://colab.research.google.com/notebooks/welcome.ipynb" rel="noopener ugc nofollow" target="_blank"> Google Colab </a>。<br/>转到文件- &gt;新建Python 3笔记本- &gt;笔记本将打开<br/>转到编辑- &gt;笔记本设置<br/>将运行时类型设置为‘Python 3’-&gt;将硬件加速器设置为GPU</p><p id="3a5e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，您可以在一个免费的GPU上运行您的python代码了！</p><p id="fdd4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">步骤1: </strong>我们需要预先训练的VGG19模型权重来计算每次迭代的损失。我们将构建一个字典，将图层名称映射到包含VGG19每一层的图层权重的张量。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="ls lt l"/></div></figure><p id="194a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="ln"> model.layers </em>包含每层的权重张量。<br/>对于每个卷积层<em class="ln"> i，model . layers【I】。weights[0] </em>有滤镜权重和<em class="ln"> model.layers[i]。【权重1】</em>具有偏置权重。我们将提取这些值，并将它们添加到字典<em class="ln"> weights_dict </em>中。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="ls lt l"/></div></figure><p id="d495" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">步骤2: </strong>我们将构建一个Tensorflow图，复制VGG19网络连接和权重。然而，我们将输入张量设置为一个<em class="ln"> tf。Variable() </em>并用我们在步骤1中存储的权重来定义图。<br/>这是因为我们不会训练网络的权重，我们只会修改输入张量以最小化定义的损失。</p><p id="74bb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">像以前一样，我们将把每一层对应的张量存储在一个字典中。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="ls lt l"/></div></figure><p id="37cb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">好了，我们已经完成了主要的设置。</p><p id="6e4f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">步骤3: </strong>让我们加载I_CONTENT和I_STYLE图像。我们将通过减去像素方式的平均值来预处理这些。</p><p id="0fbc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">此外，我们定义了<em class="ln"> save_image() </em>函数，该函数获取模型输出图像，添加回<em class="ln">均值，将值剪辑到范围【0，255】</em>并保存图像。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="ls lt l"/></div></figure><p id="a26d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">步骤4: </strong>让我们定义层(和相应的权重)来计算内容和风格损失。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="ls lt l"/></div></figure><p id="c10e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们定义损失项和一个优化器来最小化损失:</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="ls lt l"/></div></figure><p id="22f6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">第五步:</strong>我们需要做的就是用<em class="ln"> </em>一个白噪音图像初始化<em class="ln">层【输入】</em>并运行优化器。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="ls lt l"/></div></figure><p id="7e38" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">大约每100次迭代，我们将使用可定义的路径前缀保存图像。将<em class="ln">手段</em>添加回生成的图像是很重要的。这是在前面定义的<em class="ln"> save_image() </em>函数中完成的。</p><p id="c2a0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我已经将所有这些打包在一个函数<em class="ln"> run_style_transfer() </em>中，您可以将内容和样式图像的文件路径、内容和样式权重(α和β)、学习率和时期数传递给该函数。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="ls lt l"/></div></figure><p id="8f74" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我已经设置了α在范围[10，20]内，β为~1e-1，学习率为~5.0。我能够在大约1000次迭代中产生好的结果。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lu"><img src="../Images/8da2cf5900e1aea7102b07bf0bfaccb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cYZmpC_K9H0dtkurzPXp3g.png"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lv"><img src="../Images/ee464f0531cd470f75c99d15130721b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YKqVD92qaT_SqN9LylWsCA.png"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lw"><img src="../Images/eae61ce0dd9b743054dd47723337b456.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HU57JNdRAnzYFine2LmMZQ.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">使用立体主义绘画、梵高的星夜绘画和图案树叶纹理的图像通过迭代风格转移算法生成的图像。使用了用于内容重构的conv4_2层和用于样式重构的conv1_1、conv1_2、conv1_3、conv1_4、conv1_5层</figcaption></figure><p id="01e9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我希望这篇文章能帮助你自己实现神经风格转移。这里可以参考整个源代码<a class="ae jt" href="https://github.com/tusharsircar95/Iterative-Neural-Style-Transfer" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="0f43" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我正在研究快速神经风格转移实现，它训练网络直接生成其输入的风格化版本，而不是遵循迭代优化过程。我很快会分享。</p></div></div>    
</body>
</html>