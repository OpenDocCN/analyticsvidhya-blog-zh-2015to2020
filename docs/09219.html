<html>
<head>
<title>Bank Term Deposit Marketing Strategy</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">银行定期存款营销策略</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/bank-term-deposit-marketing-strategy-b9684e46c7cc?source=collection_archive---------13-----------------------#2020-08-29">https://medium.com/analytics-vidhya/bank-term-deposit-marketing-strategy-b9684e46c7cc?source=collection_archive---------13-----------------------#2020-08-29</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="df14" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">预测谁是营销活动的最佳目标客户的数据科学方法</strong>。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/c4806a06806a19e5f0fa38bfa951c1bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x7AIuWo0FQMPa2vRK1hxOg.jpeg"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">增加银行收入。</figcaption></figure><h1 id="59bd" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">项目介绍</h1><p id="df6b" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi kw translated"><span class="l kx ky kz bm la lb lc ld le di"> F </span>银行等金融机构通过借贷产生收入。贷款从客户的利息中产生利润，但也涉及一定程度的风险，这就是为什么机器学习算法在预测有资格获得贷款的客户时会很方便。金融机构产生收入的另一种形式是向银行借款或吸引公众储蓄，这比贷款风险要小一些。借贷的工作原理是这样的:银行将客户的长期存款投资于其他带来更好回报的领域，其中一部分支付给客户。然而，当客户进行定期存款时，公司比储蓄账户获得更好的回报，因为客户或客户被剥夺了在到期前存取资金的权利，除非客户准备补偿银行。</p><p id="9a84" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">由于这个原因，银行之间存在着说服客户在他们的银行进行定期存款的激烈竞争，并且由于这种营销活动，银行花费了大量的金钱来接触客户、预期的订户和非预期的订户，因为银行不知道谁是谁不是。随着数据科学和机器学习的进步以及数据的可用性，银行正在适应数据驱动的决策，这将有助于降低营销成本，从而增加银行的收入。</p><p id="753b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这个项目中，我们应用机器学习算法来建立数据集的预测模型，以便为营销活动团队提供必要的建议。<strong class="ih hj">目标是预测客户是否会认购定期存款。</strong></p><h1 id="da7c" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">数据集描述</h1><p id="3047" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">项目的数据集从“<a class="ae lf" href="http://archive.ics.uci.edu/ml/datasets/Bank+Marketing" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj"> UCI ML </strong> </a> <strong class="ih hj">”网站下载。</strong>该数据与一家葡萄牙银行机构的直接营销活动相关。营销活动以电话为基础。通常，如果产品(银行定期存款)被认购(“是”)或不被认购(“否”)，需要与同一客户进行多次联系。关于数据集和属性信息的更多描述可以在  <strong class="ih hj">这里找到<a class="ae lf" href="http://archive.ics.uci.edu/ml/datasets/Bank+Marketing" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">。</strong></a></strong></p><h1 id="770d" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">目标</h1><p id="9fa6" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated"><strong class="ih hj"> <em class="lg">业务目标:</em> </strong>通过识别将订阅定期存款的客户，从而将营销工作引向他们，从而减少营销资源。</p><p id="a583" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="lg">分析目标:</em> </strong>拟合可能的模型集，预测哪一组客户最适合指导他们的营销活动。我们通过训练和测试数据集分析了五种不同的机器学习算法的性能。这将有助于葡萄牙银行的营销活动团队制定其电话营销定期存款计划的策略。</p><p id="ec0e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">项目这一阶段的目标是:</p><p id="1728" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">1.数据预处理</p><p id="909c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.模型建立和预测</p><p id="7e99" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">3.性能比较和选择最佳模型</p><p id="742a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">4.算法的局限性</p><p id="f892" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">5.总结和结论</p><h1 id="bb1d" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">1.数据预处理</h1><p id="d7fe" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi kw translated">收益算法对某些数据类型有亲和力，它们在这些数据类型上表现得非常好。众所周知，它们会给出带有未缩放或未标准化特征的鲁莽预测。</p><p id="e6cc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">简而言之，预处理是指在将数据输入算法之前对其进行转换。在python中，scikit-learn库在sklearn.preprocessing下具有预构建的功能，我们将在建模之前使用这些功能来转换数据。</p><p id="895f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">首先，加载我们将使用的库。</p><p id="b680" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面的代码解释了应用于我们的数据的预处理，每个代码的简短描述与代码一起编写。</p><pre class="je jf jg jh fd lh li lj lk aw ll bi"><span id="fdb5" class="lm ju hi li b fi ln lo l lp lq">#importing data<br/>data=pd.read_csv('bank-additional-full.csv',sep=";")</span><span id="4819" class="lm ju hi li b fi lr lo l lp lq">#Viewing the shape our dataset<br/>print("The data has {} rows with {} features/columns".format(data.shape[0], data.shape[1])) </span><span id="dc8c" class="lm ju hi li b fi lr lo l lp lq">#ENCODING CATEGORICAL VARIABLES using OneHotEncoder</span><span id="8aee" class="lm ju hi li b fi lr lo l lp lq"># create an object of the OneHotEncoder</span><span id="1eec" class="lm ju hi li b fi lr lo l lp lq">OHE = ce.OneHotEncoder(cols=['job', 'marital', 'education', 'default',</span><span id="7cdc" class="lm ju hi li b fi lr lo l lp lq">'housing', 'loan','contact','month','day_of_week','poutcome'],use_cat_names=True)</span><span id="7adc" class="lm ju hi li b fi lr lo l lp lq"># encode the categorical variables</span><span id="721b" class="lm ju hi li b fi lr lo l lp lq">pred1_data = OHE.fit_transform(data)</span><span id="99d6" class="lm ju hi li b fi lr lo l lp lq">#SCALING NUMERICAL DATA using robust scaler<br/># retrieve just the numeric input values</span><span id="d977" class="lm ju hi li b fi lr lo l lp lq">num_cols = ['emp.var.rate',"pdays","age", 'cons.price.idx','cons.conf.idx', 'euribor3m', 'nr.employed']</span><span id="0a2f" class="lm ju hi li b fi lr lo l lp lq"># perform a robust scaler transform of the dataset</span><span id="bb57" class="lm ju hi li b fi lr lo l lp lq">trans = RobustScaler()</span><span id="41d4" class="lm ju hi li b fi lr lo l lp lq">pred1_data[num_cols] = trans.fit_transform(pred1_data[num_cols])</span><span id="eb5f" class="lm ju hi li b fi lr lo l lp lq">#DIMENSIONALITY REDUCTION using PCA</span><span id="6dc3" class="lm ju hi li b fi lr lo l lp lq">pca = PCA(n_components=5) #We will choose five components</span><span id="4223" class="lm ju hi li b fi lr lo l lp lq">pca_result = pca.fit_transform(X)</span><span id="b53b" class="lm ju hi li b fi lr lo l lp lq">plt.plot(range(5), pca.explained_variance_ratio_)</span><span id="201e" class="lm ju hi li b fi lr lo l lp lq">plt.plot(range(5), np.cumsum(pca.explained_variance_ratio_))</span><span id="6d57" class="lm ju hi li b fi lr lo l lp lq">plt.title("Component-wise and Cumulative Explained Variance")</span><span id="2ff4" class="lm ju hi li b fi lr lo l lp lq">#CLASS BALANCING by oversampling<br/>ran=RandomOverSampler()<br/>X_ran,y_ran= ran.fit_resample(train_X,train_Y)<br/>print('The new data contains {} rows '.format(X_ran.shape[0]))<br/>#plot_2d_space(X_ran,y_ran,X,y,'over-sampled')</span></pre><h1 id="e6d2" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">2.模型建立和预测</h1><p id="b82f" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">在将数据输入模型之前，我们需要将数据集分为训练数据集和测试数据集。我们将使用sklearn火车测试拆分。</p><pre class="je jf jg jh fd lh li lj lk aw ll bi"><span id="8201" class="lm ju hi li b fi ln lo l lp lq">from sklearn.model_selection import train_test_split,cross_val_score</span><span id="3a7a" class="lm ju hi li b fi lr lo l lp lq">#Splitting the data<br/>X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2,random_state=1)</span><span id="41a3" class="lm ju hi li b fi lr lo l lp lq"># returning the shape of our split data<br/>print(X_train.shape)<br/>print(y_train.shape)<br/>print(X_test.shape)<br/>print(y_test.shape)</span></pre><p id="c21f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 2.1逻辑回归</strong></p><p id="9038" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">逻辑回归是一种统计模型，其基本形式是使用逻辑函数来模拟二元相关变量(客户是否会认购定期存款{ '是'或'否' })。</p><p id="6645" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面是训练模型的代码，也是使用不同的度量评估模型的代码。</p><pre class="je jf jg jh fd lh li lj lk aw ll bi"><span id="a8ae" class="lm ju hi li b fi ln lo l lp lq"># create an object of the LinearRegression Model</span><span id="1cd4" class="lm ju hi li b fi lr lo l lp lq">  model_LR = LogisticRegression()</span><span id="1f6f" class="lm ju hi li b fi lr lo l lp lq"># fit the model with the training data</span><span id="e807" class="lm ju hi li b fi lr lo l lp lq">  model_LR.fit(X_train, y_train)<br/># making the predictions</span><span id="f31e" class="lm ju hi li b fi lr lo l lp lq">  predict_test  = model_LR.predict(X_test)<br/># Getting the <strong class="li hj">confusion matrix</strong></span><span id="66f8" class="lm ju hi li b fi lr lo l lp lq">  confusion_matrix = confusion_matrix(y_test, predict_test)<br/># getting the <strong class="li hj">classification report</strong><br/> <br/>  report = classification_report(y_test, predict_test)</span><span id="b7ce" class="lm ju hi li b fi lr lo l lp lq">#<strong class="li hj">ROC Curve</strong> for the model</span><span id="b418" class="lm ju hi li b fi lr lo l lp lq">ns_probs = [0 for _ in range(len(y_test))]</span><span id="d904" class="lm ju hi li b fi lr lo l lp lq"># predict probabilities</span><span id="49d1" class="lm ju hi li b fi lr lo l lp lq">lr_probs = model_LR.predict_proba(X_test)</span><span id="7ad8" class="lm ju hi li b fi lr lo l lp lq"># keep probabilities for the positive outcome only</span><span id="9a09" class="lm ju hi li b fi lr lo l lp lq">lr_probs = lr_probs[:, 1]</span><span id="bc82" class="lm ju hi li b fi lr lo l lp lq"># calculate scores</span><span id="9fee" class="lm ju hi li b fi lr lo l lp lq">ns_auc = roc_auc_score(y_test, ns_probs)</span><span id="adc1" class="lm ju hi li b fi lr lo l lp lq">lr_auc = roc_auc_score(y_test, lr_probs)</span><span id="4e0a" class="lm ju hi li b fi lr lo l lp lq"># summarize scores</span><span id="a0db" class="lm ju hi li b fi lr lo l lp lq">print('No Skill: ROC AUC=%.3f' % (ns_auc))</span><span id="5721" class="lm ju hi li b fi lr lo l lp lq">print('Logistic: ROC AUC=%.3f' % (lr_auc))</span><span id="0db2" class="lm ju hi li b fi lr lo l lp lq"># calculate roc curves</span><span id="995c" class="lm ju hi li b fi lr lo l lp lq">ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)</span><span id="17a2" class="lm ju hi li b fi lr lo l lp lq">lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)</span><span id="271e" class="lm ju hi li b fi lr lo l lp lq"># plot the roc curve for the model</span><span id="d42e" class="lm ju hi li b fi lr lo l lp lq">pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')</span><span id="9822" class="lm ju hi li b fi lr lo l lp lq">pyplot.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')</span><span id="2b19" class="lm ju hi li b fi lr lo l lp lq"># axis labels</span><span id="bbae" class="lm ju hi li b fi lr lo l lp lq">pyplot.xlabel('False Positive Rate')</span><span id="f1bb" class="lm ju hi li b fi lr lo l lp lq">pyplot.ylabel('True Positive Rate')</span><span id="ca1f" class="lm ju hi li b fi lr lo l lp lq"># show the legend</span><span id="a906" class="lm ju hi li b fi lr lo l lp lq">pyplot.legend()</span><span id="4427" class="lm ju hi li b fi lr lo l lp lq"># show the plot</span><span id="1245" class="lm ju hi li b fi lr lo l lp lq">pyplot.show()</span></pre><p id="d327" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 2.2 XGBoost分类器</strong></p><p id="10d3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">XGBoost是梯度增强决策树的一种实现，旨在提高速度和性能，是占主导地位的竞争机器学习。</p><p id="761e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面是XGBoost的实现代码和模型评估。</p><pre class="je jf jg jh fd lh li lj lk aw ll bi"><span id="4b46" class="lm ju hi li b fi ln lo l lp lq"># create an object of the XGBoost Model<br/>model = XGBClassifier()</span><span id="5272" class="lm ju hi li b fi lr lo l lp lq"># fit model with training data<br/>model.fit(X_train, y_train)</span><span id="c854" class="lm ju hi li b fi lr lo l lp lq"># make predictions for test data<br/>y_pred = model.predict(X_test)</span><span id="9475" class="lm ju hi li b fi lr lo l lp lq"># evaluate predictions<br/>accuracy = accuracy_score(y_test, y_pred)<br/>print("<strong class="li hj">Accuracy</strong>: %.2f%%" % (accuracy * 100.0))</span><span id="8afc" class="lm ju hi li b fi lr lo l lp lq">#getting the <strong class="li hj">XGBoost classification report</strong><br/>xgb_report = classification_report(y_test, y_pred)<br/>print(xgb_report)</span><span id="e684" class="lm ju hi li b fi lr lo l lp lq">#<strong class="li hj">ROC Curve for XGBoost model</strong></span><span id="684d" class="lm ju hi li b fi lr lo l lp lq">ns_probs = [0 for _ in range(len(y_test))]</span><span id="cf63" class="lm ju hi li b fi lr lo l lp lq"># predict probabilities<br/>lr_probs = model.predict_proba(X_test)</span><span id="ecba" class="lm ju hi li b fi lr lo l lp lq"># keep probabilities for the positive outcome only<br/>lr_probs = lr_probs[:, 1]</span><span id="24c6" class="lm ju hi li b fi lr lo l lp lq"># calculate scores<br/>ns_auc = roc_auc_score(y_test, ns_probs)<br/>lr_auc = roc_auc_score(y_test, lr_probs)</span><span id="0907" class="lm ju hi li b fi lr lo l lp lq"># summarize scores<br/>print('No Skill: ROC AUC=%.3f' % (ns_auc))<br/>print('Logistic: ROC AUC=%.3f' % (lr_auc))</span><span id="fc78" class="lm ju hi li b fi lr lo l lp lq"># calculate roc curves<br/>ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)<br/>lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)</span><span id="68bf" class="lm ju hi li b fi lr lo l lp lq"># plot the roc curve for the model<br/>pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')<br/>pyplot.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')</span><span id="4a85" class="lm ju hi li b fi lr lo l lp lq"># axis labels<br/>pyplot.xlabel('False Positive Rate')<br/>pyplot.ylabel('True Positive Rate')</span><span id="e108" class="lm ju hi li b fi lr lo l lp lq"># show the legend<br/>pyplot.legend()</span><span id="fae0" class="lm ju hi li b fi lr lo l lp lq"># show the plot<br/>pyplot.show()</span></pre><p id="fb86" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 2.3多层感知器</strong></p><p id="2e07" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">多层感知器</strong>是一个逻辑回归器，它不是将输入输入逻辑回归，而是插入一个中间层，称为隐藏层，它具有非线性激活函数(通常是tanh或sigmoid)</p><p id="3c43" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面是实现模型和评估的代码。</p><pre class="je jf jg jh fd lh li lj lk aw ll bi"><span id="a49c" class="lm ju hi li b fi ln lo l lp lq">from sklearn.neural_network import MLPClassifier</span><span id="b373" class="lm ju hi li b fi lr lo l lp lq">#<!-- -->create an object of the Multilayer Perceptron Classifier Model<br/> mlp = MLPClassifier(hidden_layer_sizes=(8,8,8), activation='relu',    solver='adam', max_iter=500)</span><span id="878c" class="lm ju hi li b fi lr lo l lp lq">#<!-- --> fit neural network  model with training data<br/>mlp.fit(X_train,y_train)</span><span id="6e9a" class="lm ju hi li b fi lr lo l lp lq"># Predicting<br/>predict_test = mlp.predict(X_test)</span><span id="8ed8" class="lm ju hi li b fi lr lo l lp lq">#Evaluating the Neural Network model<br/> <!-- -->print(confusion_matrix(y_train,predict_train))<br/> print(classification_report(y_train,predict_train))</span><span id="1150" class="lm ju hi li b fi lr lo l lp lq"># ROC Curve of the Neural Network model<br/>ns_probs = [0 for _ in range(len(y_test))]</span><span id="6f0e" class="lm ju hi li b fi lr lo l lp lq"># predict probabilities<br/>lr_probs = mlp.predict_proba(X_test)</span><span id="c453" class="lm ju hi li b fi lr lo l lp lq"># keep probabilities for the positive outcome only<br/>lr_probs = lr_probs[:, 1]</span><span id="b09e" class="lm ju hi li b fi lr lo l lp lq"># calculate scores<br/>ns_auc = roc_auc_score(y_test, ns_probs)<br/>lr_auc = roc_auc_score(y_test, lr_probs)</span><span id="4dd3" class="lm ju hi li b fi lr lo l lp lq"># summarize scores<br/>print('No Skill: ROC AUC=%.3f' % (ns_auc))<br/>print('Logistic: ROC AUC=%.3f' % (lr_auc))</span><span id="df59" class="lm ju hi li b fi lr lo l lp lq"># calculate roc curves<br/>ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)<br/>lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)</span><span id="b07c" class="lm ju hi li b fi lr lo l lp lq"># plot the roc curve for the model<br/>pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')<br/>pyplot.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')</span><span id="f5ba" class="lm ju hi li b fi lr lo l lp lq"># axis labels<br/>pyplot.xlabel('False Positive Rate')<br/>pyplot.ylabel('True Positive Rate')</span><span id="5da2" class="lm ju hi li b fi lr lo l lp lq"># show the legend<br/>pyplot.legend()</span><span id="d5ac" class="lm ju hi li b fi lr lo l lp lq"># show the plot<br/>pyplot.show()</span></pre><p id="6b7c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 2.4随机森林</strong></p><p id="5939" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">随机森林或随机决策森林是一种用于分类、回归和其他任务的集成学习方法，它通过在训练时构建大量决策树并输出作为各个树的类(分类)或均值预测(回归)的模式的类来操作。</p><p id="4eb4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面是实现该模型的代码。</p><pre class="je jf jg jh fd lh li lj lk aw ll bi"><span id="de40" class="lm ju hi li b fi ln lo l lp lq">#Create a Gaussian Classifier<br/>clf=RandomForestClassifier(n_estimators=100)</span><span id="6a6f" class="lm ju hi li b fi lr lo l lp lq">#Train the model using the training sets<br/>clf.fit(X_train,y_train)<br/>RF_pred=clf.predict(X_test)</span><span id="a62f" class="lm ju hi li b fi lr lo l lp lq"># Model Accuracy, how often is the classifier correct?print("Accuracy:",metrics.accuracy_score(y_test, RF_pred))</span><span id="2d7a" class="lm ju hi li b fi lr lo l lp lq">#ROC Curve <br/>ns_probs = [0 for _ in range(len(y_test))]</span><span id="34c5" class="lm ju hi li b fi lr lo l lp lq"># predict probabilities<br/>lr_probs = clf.predict_proba(X_test)</span><span id="6faa" class="lm ju hi li b fi lr lo l lp lq"># keep probabilities for the positive outcome only<br/>lr_probs = lr_probs[:, 1]</span><span id="3a57" class="lm ju hi li b fi lr lo l lp lq"># calculate scores<br/>ns_auc = roc_auc_score(y_test, ns_probs)<br/>lr_auc = roc_auc_score(y_test, lr_probs)</span><span id="21a4" class="lm ju hi li b fi lr lo l lp lq"># summarize scores<br/>print('No Skill: ROC AUC=%.3f' % (ns_auc))<br/>print('Logistic: ROC AUC=%.3f' % (lr_auc))</span><span id="cece" class="lm ju hi li b fi lr lo l lp lq"># calculate roc curves<br/>ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)<br/>lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)</span><span id="73f1" class="lm ju hi li b fi lr lo l lp lq"># plot the roc curve for the model<br/>pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')<br/>pyplot.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')</span><span id="15ff" class="lm ju hi li b fi lr lo l lp lq"># axis labels<br/>pyplot.xlabel('False Positive Rate')<br/>pyplot.ylabel('True Positive Rate')</span><span id="8c4d" class="lm ju hi li b fi lr lo l lp lq"># show the legend<br/>pyplot.legend()</span><span id="da53" class="lm ju hi li b fi lr lo l lp lq"># show the plot<br/>pyplot.show()</span></pre><p id="f33e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 2.5决策树</strong></p><p id="f080" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">决策树分类器通过构建决策树来创建分类模型。树中的每个节点指定一个属性测试，从该节点开始的每个分支对应于该属性的一个可能值。</p><p id="a225" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面是代码实现部分。</p><pre class="je jf jg jh fd lh li lj lk aw ll bi"><span id="6f5c" class="lm ju hi li b fi ln lo l lp lq">from scipy.stats import randint</span><span id="359f" class="lm ju hi li b fi lr lo l lp lq">max_depth_value = [3, None]<br/>max_features_value =  randint(1, 4)<br/>min_samples_leaf_value = randint(1, 4)<br/>criterion_value = ["gini", "entropy"]</span><span id="c2a6" class="lm ju hi li b fi lr lo l lp lq">param_grid = dict(max_depth = max_depth_value,<br/>max_features = max_features_value,<br/>min_samples_leaf = min_samples_leaf_value,criterion =criterion_value)</span><span id="7b29" class="lm ju hi li b fi lr lo l lp lq">#Create a decision tree Classifier and make predictions</span><span id="1027" class="lm ju hi li b fi lr lo l lp lq">model_CART = DecisionTreeClassifier()<br/>CART_RandSearch =RandomSearch(X_train,y_train,model_CART,param_grid)<br/>Prediction_CART = CART_RandSearch.BestModelPridict(X_test)<br/>print("Accuracy:",metrics.accuracy_score(y_test, Prediction_CART))</span><span id="1128" class="lm ju hi li b fi lr lo l lp lq">#Getting a report of the model</span><span id="b9f7" class="lm ju hi li b fi lr lo l lp lq">DC_report = classification_report(y_test, Prediction_CART)<br/>print(DC_report)</span></pre><h1 id="9c6b" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">3.性能比较和选择最佳模型</h1><p id="0ee0" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">正如我们已经看到的，我们建立的五个模型在预测客户是否会同意银行的定期存款方面有自己的准确性。正如预期的那样，在三种分类算法之间，在准确度和F1_score方面存在一些变化。</p><p id="9fad" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">算法准确率百分比</strong></p><ol class=""><li id="4226" class="ls lt hi ih b ii ij im in iq lu iu lv iy lw jc lx ly lz ma bi translated">逻辑回归模型:71%</li><li id="c68d" class="ls lt hi ih b ii mb im mc iq md iu me iy mf jc lx ly lz ma bi translated">XGBoost分类器:73.79%</li><li id="fb0f" class="ls lt hi ih b ii mb im mc iq md iu me iy mf jc lx ly lz ma bi translated">多层感知器:71.45%</li><li id="69b5" class="ls lt hi ih b ii mb im mc iq md iu me iy mf jc lx ly lz ma bi translated">随机森林:96.79%</li><li id="35e4" class="ls lt hi ih b ii mb im mc iq md iu me iy mf jc lx ly lz ma bi translated">决策树分类器:94.3%</li></ol><p id="0450" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">根据准确率，数据集最可靠的模型似乎是<strong class="ih hj">随机森林模型</strong>，只有96.79%。</p><p id="5eb3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面是我们的获奖模型，随机森林分类器的ROC曲线。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mg"><img src="../Images/747282708c7cb7487ca4fedc2c0f1f7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:834/format:webp/1*MuRjL-QanexwBvhNju6VwQ.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">随机分类器模型的ROC曲线</figcaption></figure><h1 id="ac77" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">4.算法的优点和局限性</h1><p id="ac2c" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">逻辑回归的优点是易于解释，它指导模型逻辑概率，并为结果提供一个置信区间。然而，逻辑算法的主要缺点是它存在多重共线性，因此，解释变量必须是线性无关的。</p><p id="7428" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">逻辑回归方法在上述模型中的一些局限性如下</p><ol class=""><li id="8c00" class="ls lt hi ih b ii ij im in iq lu iu lv iy lw jc lx ly lz ma bi translated">该模型有一些在模型中有意义的未知预测值。这些变量实际上并不携带任何有用的信息，但它们的重要性可能会影响模型的可预测性。</li></ol><h1 id="9aa7" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">5.总结和结论</h1><p id="6736" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">从进行的研究来看，在使用机器学习算法来决定银行的营销活动方面，结果令人印象深刻，令人信服。几乎所有的属性都对预测模型的构建有很大的贡献。在用于对数据建模的五种分类方法中，<strong class="ih hj">随机森林模型</strong>产生了最好的准确度，只有96.79%。该模型简单且易于实现。</p><p id="77f4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果客户的信息(如教育、住房贷款、个人贷款、通话持续时间、在此活动中执行的联系次数、以前的结果等)可用，银行营销经理可以通过使用该模型来识别潜在客户。这将有助于减少银行的成本，避免致电不太可能认购定期存款的客户。他们可以使用这种模式开展更成功的电话营销活动。</p><blockquote class="mh mi mj"><p id="8db9" class="if ig lg ih b ii ij ik il im in io ip mk ir is it ml iv iw ix mm iz ja jb jc hb bi translated"><a class="ae lf" href="https://github.com/Davidelvis/BankClientTermDeposit_Prediction" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj"> <em class="hi">找到整个项目的链接，了解更多信息。</em> </strong> </a></p></blockquote><h1 id="81a2" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">6.参考</h1><p id="cfb6" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">UCI机器学习知识库，<em class="lg">银行营销数据集</em>在线查看于</p><p id="5675" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae lf" href="https://archive.ics.uci.edu/ml/datasets/Bank+Marketing" rel="noopener ugc nofollow" target="_blank"><em class="lg">https://archive.ics.uci.edu/ml/datasets/Bank+Marketing</em></a></p><p id="f92b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae lf" href="https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html" rel="noopener ugc nofollow" target="_blank">多层感知器</a></p><p id="1f4d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae lf" href="https://xgboost.readthedocs.io/en/latest/python/python_api.html" rel="noopener ugc nofollow" target="_blank"> Xgboost </a></p></div></div>    
</body>
</html>