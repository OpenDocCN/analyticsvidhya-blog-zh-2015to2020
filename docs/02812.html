<html>
<head>
<title>Neuromancer Blues: Threading vs Processing — Part 2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">神经癌蓝调:线程与处理——第二部分</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/neuromancer-blues-threading-vs-processing-part-2-e67f86074721?source=collection_archive---------31-----------------------#2020-01-02">https://medium.com/analytics-vidhya/neuromancer-blues-threading-vs-processing-part-2-e67f86074721?source=collection_archive---------31-----------------------#2020-01-02</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/b99300750f0aaa4c5093ab276a0a581c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FSEGozbKSrPGlBDf4Dl0Zg.jpeg"/></div></div></figure><p id="f1ae" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">“Neuromancer Blues”是一系列帖子，我希望读者在其中找到关于整体数据科学主题的指导，如数据争论、数据库连接、应用数学和编程技巧，以提高代码效率、可读性和速度。我的例子和代码片段将会尽可能的简洁明了，以传达关键思想，而不是提供可读性差的冗长代码，这会损害帖子的目的。</p><p id="7eb9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><a class="ae jp" href="https://www.lightbringercap.com/blog/neuromancer-blues-threading-vs-multiprocessing-part-1" rel="noopener ugc nofollow" target="_blank">本主题的第一部分</a>致力于简要解释线程化和多处理之间的主要区别，同时重点关注线程化应用，以提高我们执行I/O相关任务的效率。因为一张图片胜过千言万语，下面的图片清晰地阐释了由<a class="ae jp" href="https://www.youtube.com/channel/UCCezIgC97PvUuR4_gbFUs5g" rel="noopener ugc nofollow" target="_blank">科里·斯查费</a>提供的理解这些概念的要点</p><figure class="jr js jt ju fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es jq"><img src="../Images/c32c6ee4604f4755e9631b73451a7649.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5FMfYPwxMzClDJzlque1uw.jpeg"/></div></div></figure><p id="f2d0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">正如本系列的第一部分所强调的，建议将多处理用于CPU受限的任务，因为它允许程序员在给定的CPU上打开多个处理器，每个处理器都有自己的内存，并且没有GIL限制。</p><p id="6e53" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">经典方法:使用多处理模块</strong><br/>Python中内置的<a class="ae jp" href="https://docs.python.org/3/library/threading.html" rel="noopener ugc nofollow" target="_blank"> </a> <a class="ae jp" href="https://docs.python.org/3/library/multiprocessing.html" rel="noopener ugc nofollow" target="_blank">多处理模块</a>是产生多个彼此并行运行的进程的最简单方法，而不是像我们实现线程时那样并发运行。该模块允许用户非常容易和直观地实现多处理，与使用编辑模块时非常相似。请记住，尽管使用这两个模块的编码体验是相似的，但是如前所述，在后台会发生非常不同的事情；一个很大的区别是，线程共享全局变量，而多处理同时运行独立的进程和它们自己的变量。</p><p id="0584" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">边做边学是传达上述概念的最佳方式，所以让我们言归正传。请记住，多处理意味着更好地处理CPU受限的任务，因此我们将定义一个CPU受限的函数，该函数将根据基于<a class="ae jp" href="https://en.wikipedia.org/wiki/Support-vector_machine" rel="noopener ugc nofollow" target="_blank"> SVM </a>的简单机器学习模型训练来训练和交付结果。请注意，我们使用“幼稚”这个词是出于显而易见的原因，因为我们不进行数据预处理、特征选择、交叉验证或任何类型的超参数优化，因为这篇文章的目的是专注于使用多处理提高我们的代码效率。其他系列的后续文章将重点关注增强应用于投资的机器学习模型。</p><p id="4873" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">首先，我们继续在一个对象中存储一些数据，这些数据是我们的CPU受限任务执行SVM模型训练所需要的。</p><pre class="jr js jt ju fd jv jw jx jy aw jz bi"><span id="b9b6" class="ka kb hi jw b fi kc kd l ke kf"># Modules<br/>import time<br/>import pandas_datareader.data as web<br/>import numpy as np<br/>import pandas as pd<br/>import multiprocessing<br/>import concurrent.futures<br/>from sklearn.svm import SVC</span><span id="1dce" class="ka kb hi jw b fi kg kd l ke kf"># Data download and storage in “df” object<br/>t_list = [‘KO’,’XOM’,’AAPL’,’IBM’,’MCD’]<br/>s= ‘1999–12–31’<br/>e= ‘2019–12–31’ # Last 20 years<br/>df = web.get_data_yahoo(t_list, s,e) # multiindex level dataframe<br/>df = df[‘Adj Close’].copy() # create a copy only with “Adjusted Closed Price” per ticker</span></pre><h1 id="df54" class="kh kb hi bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated"><a class="ae jp" href="https://www.lightbringercap.com/blog/neuromancer-blues-threading-vs-multiprocessing-part-2" rel="noopener ugc nofollow" target="_blank">神经癌蓝调:线程VS多重处理——第二部分</a></h1><p id="181f" class="pw-post-body-paragraph iq ir hi is b it le iv iw ix lf iz ja jb lg jd je jf lh jh ji jj li jl jm jn hb bi">12/30/2019</p><p id="cb1d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><a class="ae jp" href="https://www.lightbringercap.com/blog/neuromancer-blues-threading-vs-multiprocessing-part-2#comments" rel="noopener ugc nofollow" target="_blank"> 0条评论</a></p><figure class="jr js jt ju fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lj"><img src="../Images/a5421468c445e02fe7ffb2eb7a2d871c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*hkLf5IvuO3JZohhi"/></div></div></figure><p id="f3d4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="jo"> Neuromancer Blues”是一系列帖子，我希望读者在其中找到关于整体数据科学主题的指导，如数据争论、数据库连接、应用数学和编程技巧，以提高代码效率、可读性和速度。我的例子和代码片段将会尽可能的简洁明了，以传达关键思想，而不是提供可读性差的冗长代码，这会损害帖子的目的。</em></p><p id="9051" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><a class="ae jp" href="https://www.lightbringercap.com/blog/neuromancer-blues-threading-vs-multiprocessing-part-1" rel="noopener ugc nofollow" target="_blank">本主题的第一部分</a>除了重点介绍线程化应用在执行I/O相关任务时如何提高我们的工作效率之外，还简要解释了线程化和多处理之间的主要区别。因为一张图片胜过千言万语，下面的图片清晰地阐释了由科里·斯查费提供的理解这些概念的要点</p><figure class="jr js jt ju fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es jq"><img src="../Images/49beaab96d7e37c337a5996dec7dd7ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*EQJ5faysYHhbKQw3.jpg"/></div></div></figure><p id="11e2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">正如本系列的第一部分所强调的，建议将多处理用于CPU受限的任务，因为它允许程序员在给定的CPU上打开多个处理器，每个处理器都有自己的内存，并且没有GIL限制。</p><p id="6f31" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">经典方法:使用多处理模块</strong><br/>Python中内置的<a class="ae jp" href="https://docs.python.org/3/library/threading.html" rel="noopener ugc nofollow" target="_blank"> </a> <a class="ae jp" href="https://docs.python.org/3/library/multiprocessing.html" rel="noopener ugc nofollow" target="_blank">多处理模块</a>是产生多个彼此并行运行的进程的最简单方法，而不是像我们实现线程时那样并发运行。该模块允许用户非常容易和直观地实现多处理，与使用编辑模块时非常相似。请记住，尽管使用这两个模块的编码体验是相似的，但是如前所述，在后台会发生非常不同的事情；一个很大的区别是，线程共享全局变量，而多处理同时运行独立的进程和它们自己的变量。</p><p id="f93c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">边做边学是传达上述概念的最佳方式，所以让我们言归正传。请记住，多处理意味着更好地处理受CPU限制的任务，因此我们将定义一个受CPU限制的函数，该函数将根据基于<a class="ae jp" href="https://en.wikipedia.org/wiki/Support-vector_machine" rel="noopener ugc nofollow" target="_blank"> SVM </a>的简单机器学习模型训练来训练和交付结果。请注意，我们使用“幼稚”这个词是出于显而易见的原因，因为我们不进行数据预处理、特征选择、交叉验证或任何类型的超参数优化，因为这篇文章的目的是专注于使用多处理提高我们的代码效率。其他系列的后续文章将重点关注增强应用于投资的机器学习模型。</p><p id="6bbb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">首先，我们继续在一个对象中存储一些数据，这些数据是我们的CPU受限任务执行SVM模型训练所需要的。</p><pre class="jr js jt ju fd jv jw jx jy aw jz bi"><span id="f801" class="ka kb hi jw b fi kc kd l ke kf"># Modules</span><span id="0468" class="ka kb hi jw b fi kg kd l ke kf">import time</span><span id="1079" class="ka kb hi jw b fi kg kd l ke kf">import pandas_datareader.data as web</span><span id="4c29" class="ka kb hi jw b fi kg kd l ke kf">import numpy as np</span><span id="9a27" class="ka kb hi jw b fi kg kd l ke kf">import pandas as pd</span><span id="2961" class="ka kb hi jw b fi kg kd l ke kf">import multiprocessing</span><span id="db64" class="ka kb hi jw b fi kg kd l ke kf">import concurrent.futures</span><span id="8d9f" class="ka kb hi jw b fi kg kd l ke kf">from sklearn.svm import SVC</span><span id="e3ef" class="ka kb hi jw b fi kg kd l ke kf"># Data download and storage in "df" object</span><span id="6a38" class="ka kb hi jw b fi kg kd l ke kf">t_list = ['KO','XOM','AAPL','IBM','MCD']</span><span id="e9c2" class="ka kb hi jw b fi kg kd l ke kf">s= '1999-12-31'</span><span id="4f0c" class="ka kb hi jw b fi kg kd l ke kf">e= '2019-12-31' # Last 20 years</span><span id="517d" class="ka kb hi jw b fi kg kd l ke kf">df = web.get_data_yahoo(t_list, s,e) # multiindex level dataframe</span><span id="4e6b" class="ka kb hi jw b fi kg kd l ke kf">df = df['Adj Close'].copy() # create a copy only with "Adjusted Closed Price" per ticker</span></pre><p id="5390" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">第二，任务被封装在函数<strong class="is hj"> cpu_task() </strong>中，其中包含我们简单的SMV模型训练和模型准确性的交付，以及作为参数传递的每个ticker的累积回报。注意，包含time.sleep(3)行是为了模拟更真实的CPU密集型任务时间完成情况。</p><pre class="jr js jt ju fd jv jw jx jy aw jz bi"><span id="2ef9" class="ka kb hi jw b fi kc kd l ke kf">def cpu_task(t):<br/> ‘’’<br/> Run SVM model using 6 daily return lags as predictors <br/> Params<br/> — — — <br/> t= ticker<br/> ‘’’<br/> time.sleep(3)<br/> lags=6 # number of predictors<br/> temp=data.filter(regex=t).copy()<br/> temp[t+’_1d_r’]= np.log(temp[t] / temp[t].shift(1))<br/> for lag in range(1, lags + 1):<br/> temp[t+’_’+str(lag)+’d_r’] = np.sign(temp[t+’_1d_r’].shift(lag))<br/> temp[t+’_y’] = np.sign(np.log(temp[t].shift(-1)/temp[t])) # our dependent variable<br/> temp.dropna(inplace=True)<br/> X=temp.filter(regex=’_r’)<br/> y=temp[t+’_y’]<br/> model = SVC(gamma=’auto’)<br/> model.fit(X,y)<br/> score= model.score(X,y)<br/> temp[t+’_Pos’] = model.predict(X) # long (1) or Short(-1)<br/> temp[t+’_strat’] = temp[t+’_Pos’].shift(1) * temp[t+’_1d_r’]<br/> temp[t+’_strat_cum’] = temp[t+’_strat’].cumsum().apply(np.exp)<br/> stats[t]=[score,temp[t+’_strat_cum’][-1]] # store training score, cum return</span></pre><h1 id="58d6" class="kh kb hi bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated"><a class="ae jp" href="https://www.lightbringercap.com/blog/neuromancer-blues-threading-vs-multiprocessing-part-2" rel="noopener ugc nofollow" target="_blank">神经癌蓝调:线程VS多重处理——第二部分</a></h1><p id="5ad8" class="pw-post-body-paragraph iq ir hi is b it le iv iw ix lf iz ja jb lg jd je jf lh jh ji jj li jl jm jn hb bi">12/30/2019</p><p id="edb2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><a class="ae jp" href="https://www.lightbringercap.com/blog/neuromancer-blues-threading-vs-multiprocessing-part-2#comments" rel="noopener ugc nofollow" target="_blank"> 0条评论</a></p><figure class="jr js jt ju fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lj"><img src="../Images/2f3589a0aa5c2ba51d865b5410340b3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*_01Ty8dmbqHD1jgl"/></div></div></figure><p id="fa46" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">“Neuromancer Blues”是一系列帖子，我希望读者在其中找到关于整体数据科学主题的指导，如数据争论、数据库连接、应用数学和编程技巧，以提高代码效率、可读性和速度。我的例子和代码片段将会尽可能的简洁明了，以传达关键思想，而不是提供可读性差的冗长代码，这会损害帖子的目的。</p><p id="9399" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><a class="ae jp" href="https://www.lightbringercap.com/blog/neuromancer-blues-threading-vs-multiprocessing-part-1" rel="noopener ugc nofollow" target="_blank">本主题的第一部分</a>致力于简要解释线程化和多处理之间的主要区别，同时重点关注线程化应用，以提高我们执行I/O相关任务的效率。因为一张图片胜过千言万语，下面的图片清晰地阐释了由<a class="ae jp" href="https://www.youtube.com/channel/UCCezIgC97PvUuR4_gbFUs5g" rel="noopener ugc nofollow" target="_blank">科里·斯查费</a>提供的理解这些概念的要点</p><figure class="jr js jt ju fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es jq"><img src="../Images/6307b93030ef3ad4ace295fc0a1da389.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*nNBdATuDihaSWk6n.jpg"/></div></div></figure><p id="ac89" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">正如本系列的第一部分所强调的，建议将多处理用于CPU受限的任务，因为它允许程序员在给定的CPU上打开多个处理器，每个处理器都有自己的内存，并且没有GIL限制。</p><p id="7eb4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">经典方法:使用多处理模块</strong><br/>Python中内置的<a class="ae jp" href="https://docs.python.org/3/library/threading.html" rel="noopener ugc nofollow" target="_blank"> </a> <a class="ae jp" href="https://docs.python.org/3/library/multiprocessing.html" rel="noopener ugc nofollow" target="_blank">多处理模块</a>是产生多个彼此并行运行的进程的最简单方法，而不是像我们实现线程时那样并发运行。该模块允许用户非常容易和直观地实现多处理，与使用编辑模块时非常相似。请记住，尽管使用这两个模块的编码体验是相似的，但是如前所述，在后台会发生非常不同的事情；一个很大的区别是，线程共享全局变量，而多处理同时运行独立的进程和它们自己的变量。</p><p id="50b1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">边做边学是传达上述概念的最佳方式，所以让我们言归正传。请记住，多处理意味着更好地处理CPU受限的任务，因此我们将定义一个CPU受限的函数，该函数将根据基于<a class="ae jp" href="https://en.wikipedia.org/wiki/Support-vector_machine" rel="noopener ugc nofollow" target="_blank"> SVM </a>的简单机器学习模型训练来训练和交付结果。请注意，我们使用“幼稚”这个词是出于显而易见的原因，因为我们不进行数据预处理、特征选择、交叉验证或任何类型的超参数优化，因为这篇文章的目的是专注于使用多处理提高我们的代码效率。其他系列的后续文章将重点关注增强应用于投资的机器学习模型。</p><p id="cee7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">首先，我们继续在一个对象中存储一些数据，这些数据是我们的CPU受限任务执行SVM模型训练所需要的。</p><pre class="jr js jt ju fd jv jw jx jy aw jz bi"><span id="3101" class="ka kb hi jw b fi kc kd l ke kf"># Modules</span><span id="732f" class="ka kb hi jw b fi kg kd l ke kf">import time</span><span id="1ff4" class="ka kb hi jw b fi kg kd l ke kf">import pandas_datareader.data as web</span><span id="43f4" class="ka kb hi jw b fi kg kd l ke kf">import numpy as np</span><span id="a57c" class="ka kb hi jw b fi kg kd l ke kf">import pandas as pd</span><span id="09d3" class="ka kb hi jw b fi kg kd l ke kf">import multiprocessing</span><span id="35e3" class="ka kb hi jw b fi kg kd l ke kf">import concurrent.futures</span><span id="1c2b" class="ka kb hi jw b fi kg kd l ke kf">from sklearn.svm import SVC</span><span id="14d1" class="ka kb hi jw b fi kg kd l ke kf"># Data download and storage in "df" object</span><span id="fea3" class="ka kb hi jw b fi kg kd l ke kf">t_list = ['KO','XOM','AAPL','IBM','MCD']</span><span id="26a3" class="ka kb hi jw b fi kg kd l ke kf">s= '1999-12-31'</span><span id="e2f7" class="ka kb hi jw b fi kg kd l ke kf">e= '2019-12-31' # Last 20 years</span><span id="21bf" class="ka kb hi jw b fi kg kd l ke kf">df = web.get_data_yahoo(t_list, s,e) # multiindex level dataframe</span><span id="5105" class="ka kb hi jw b fi kg kd l ke kf">df = df['Adj Close'].copy() # create a copy only with "Adjusted Closed Price" per ticker</span></pre><p id="6bf9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">第二，任务被包装在函数<strong class="is hj"> cpu_task() </strong>中，其中包含我们简单的SMV模型训练和模型精度的交付，以及作为参数传递的每个ticker的累积回报。注意，包含time.sleep(3)行是为了模拟更真实的CPU密集型任务时间完成情况。</p><pre class="jr js jt ju fd jv jw jx jy aw jz bi"><span id="7d45" class="ka kb hi jw b fi kc kd l ke kf">def cpu_task(t):</span><span id="a9f0" class="ka kb hi jw b fi kg kd l ke kf">'''</span><span id="3cf0" class="ka kb hi jw b fi kg kd l ke kf">Run SVM model using 6 daily return lags as predictors</span><span id="10c2" class="ka kb hi jw b fi kg kd l ke kf">Params</span><span id="3d62" class="ka kb hi jw b fi kg kd l ke kf">------</span><span id="65a6" class="ka kb hi jw b fi kg kd l ke kf">t= ticker</span><span id="cc86" class="ka kb hi jw b fi kg kd l ke kf">'''</span><span id="c855" class="ka kb hi jw b fi kg kd l ke kf">time.sleep(3)</span><span id="7015" class="ka kb hi jw b fi kg kd l ke kf">lags=6 # number of predictors</span><span id="3cef" class="ka kb hi jw b fi kg kd l ke kf">temp=data.filter(regex=t).copy()</span><span id="b419" class="ka kb hi jw b fi kg kd l ke kf">temp[t+'_1d_r']= np.log(temp[t] / temp[t].shift(1))</span><span id="1a58" class="ka kb hi jw b fi kg kd l ke kf">for lag in range(1, lags + 1):</span><span id="8d0c" class="ka kb hi jw b fi kg kd l ke kf">temp[t+'_'+str(lag)+'d_r'] = np.sign(temp[t+'_1d_r'].shift(lag))</span><span id="400c" class="ka kb hi jw b fi kg kd l ke kf">temp[t+'_y'] = np.sign(np.log(temp[t].shift(-1)/temp[t])) # our dependent variable</span><span id="5205" class="ka kb hi jw b fi kg kd l ke kf">temp.dropna(inplace=True)</span><span id="5d0d" class="ka kb hi jw b fi kg kd l ke kf">X=temp.filter(regex='_r')</span><span id="f46c" class="ka kb hi jw b fi kg kd l ke kf">y=temp[t+'_y']</span><span id="8332" class="ka kb hi jw b fi kg kd l ke kf">model = SVC(gamma='auto')</span><span id="8a65" class="ka kb hi jw b fi kg kd l ke kf">model.fit(X,y)</span><span id="1560" class="ka kb hi jw b fi kg kd l ke kf">score= model.score(X,y)</span><span id="37ad" class="ka kb hi jw b fi kg kd l ke kf">temp[t+'_Pos'] = model.predict(X) # long (1) or Short(-1)</span><span id="3ae8" class="ka kb hi jw b fi kg kd l ke kf">temp[t+'_strat'] = temp[t+'_Pos'].shift(1) * temp[t+'_1d_r']</span><span id="e01a" class="ka kb hi jw b fi kg kd l ke kf">temp[t+'_strat_cum'] = temp[t+'_strat'].cumsum().apply(np.exp)</span><span id="0a26" class="ka kb hi jw b fi kg kd l ke kf">stats[t]=[score,temp[t+'_strat_cum'][-1]] # store training score, cum return</span></pre><p id="7bb3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在我们已经有了要为每个公司运行的数据和任务/工人函数，让我们回顾一下进行这种分析的不同的多处理方法。如本系列的第1部分所示，下一个代码片段提供了顺序执行效率的概念，即一次运行一个任务，只有当最后一个任务完成时，下一个任务才开始。</p><pre class="jr js jt ju fd jv jw jx jy aw jz bi"><span id="b7a5" class="ka kb hi jw b fi kc kd l ke kf">start = time.perf_counter()<br/>data=df.copy()<br/>stats={} # store every ticker results.<br/>for t in data.columns:<br/> cpu_task(t)<br/>finish = time.perf_counter()<br/>print(stats)<br/>print(f’running time: {finish-start} second(s)’)</span><span id="528a" class="ka kb hi jw b fi kg kd l ke kf">running time: 26.083961900000077 second(s)</span></pre><p id="35d0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们的CPU任务大约需要5秒钟才能完成。起初，这看起来确实很快，但请记住，我们的目标是使我们的程序尽可能具有可伸缩性。目前，我们的程序需要40多分钟来对整个标准普尔500宇宙进行同样的分析，因此这里需要改进:<strong class="is hj">进入多处理模块:</strong></p><pre class="jr js jt ju fd jv jw jx jy aw jz bi"><span id="9450" class="ka kb hi jw b fi kc kd l ke kf">start = time.perf_counter()<br/>data=df.copy()<br/>stats={} # store every ticker results.<br/>processes=[]<br/>if __name__==’__main__’: # 1<br/> for t in df.columns: # 2 <br/> p = multiprocessing.Process(target=cpu_task, args=[t]) # 3<br/> p.start() # 3<br/> processes.append(p) <br/> for p in processes:<br/> p.join() # 4 <br/>finish = time.perf_counter()<br/>print(f’running time: {finish-start} second(s)’)</span><span id="dacb" class="ka kb hi jw b fi kg kd l ke kf">running time: 15.9997299 second(s)</span></pre><p id="b2a5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">使用顺序方法时，多处理实现几乎将运行CPU任务的初始时间减少了一半。多处理模块的新用户可能需要对用数字注释突出显示的行进行进一步描述:</p><ol class=""><li id="8569" class="lk ll hi is b it iu ix iy jb lm jf ln jj lo jn lp lq lr ls bi translated"><strong class="is hj">如果__name__=='__main__' </strong>对于windows用户是强制的。这行代码允许测试脚本是直接运行还是导入。没有这条线的<strong class="is hj">多重处理。Process() </strong>模块将启动一个新的Python进程，并将导入调用模块，从而触发新进程的无限延续(或者直到您的机器耗尽资源)。请注意，Mac用户可以忽略这一行，将缩进的内容放到主脚本中。</li><li id="9d2a" class="lk ll hi is b it lt ix lu jb lv jf lw jj lx jn lp lq lr ls bi translated">为每个ticker打开一个进程所必需的循环。</li><li id="2370" class="lk ll hi is b it lt ix lu jb lv jf lw jj lx jn lp lq lr ls bi translated"><strong class="is hj">多重处理。Process() </strong>使用我们的任务工人函数和每个ticker创建一个流程对象p。下一行启动每个流程，以便他们可以开始并行工作。</li><li id="dda7" class="lk ll hi is b it lt ix lu jb lv jf lw jj lx jn lp lq lr ls bi translated"><strong class="is hj"> join() </strong>对于避免我们的脚本在我们的多个进程完成之前跳到“完成”是必不可少的。如果没有这条线，所获得的时间将是一个接近于零的误导数字。因此，join()相当于告诉我们的脚本等待一个进程完成。</li></ol><p id="32cf" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">关于<strong class="is hj">多处理模块最好的一点是，它允许使用“池”模式工作，并在我们的脚本中获得显著的可读性增益</strong>，避免不必要的循环，并在时间执行上获得一些增益:</p><pre class="jr js jt ju fd jv jw jx jy aw jz bi"><span id="1d9f" class="ka kb hi jw b fi kc kd l ke kf">start = time.perf_counter()<br/>data=df.copy()<br/>stats={} <br/>if __name__ == ‘__main__’: # 1<br/> proc_=len(data.columns) # 2<br/> with multiprocessing.Pool(processes=proc_) as pool: # 3<br/> pool.map(cpu_task, df.columns) # 4<br/>finish = time.perf_counter()<br/>print(f’running time: {finish-start} second(s)’)</span><span id="04bc" class="ka kb hi jw b fi kg kd l ke kf">running time: 15.6402651 second(s)</span></pre><p id="c45a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">同样，对于不熟悉这个模块的人来说，上面的语法可能需要进一步的澄清:<br/></p><ol class=""><li id="ced1" class="lk ll hi is b it iu ix iy jb lm jf ln jj lo jn lp lq lr ls bi translated"><strong class="is hj">如果__name__=='__main__' </strong>对于windows用户是强制的。请阅读上面的段落，同样的解释也适用于这里。</li><li id="ba92" class="lk ll hi is b it lt ix lu jb lv jf lw jj lx jn lp lq lr ls bi translated">定义要打开的流程数量。在我们的例子中，这等于tickers的数量。</li><li id="b049" class="lk ll hi is b it lt ix lu jb lv jf lw jj lx jn lp lq lr ls bi translated"><strong class="is hj">多重处理。Pool() </strong>创建一个池进程对象“Pool”。下一行使用类“map”方法并行启动每个进程。注意可读性是如何提高的，因为不再需要使用join()。</li></ol><p id="8604" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">新方法:使用并发的进程池。期货模块</strong></p><p id="be8f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">正如在本系列的第1部分中所报道的,<a class="ae jp" href="https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.ProcessPoolExecutor" rel="noopener ugc nofollow" target="_blank"> concurrent.futures </a>模块提供了一种更简单易懂的方式来处理线程和多重处理。该模块是Python线程和多处理模块之上的抽象层，简化了它们的使用。尽管如此，应该注意的是，在更高的代码简单性和更低的代码灵活性之间有一个权衡。因此，用户可能对使用多处理或并发感兴趣。未来取决于项目的复杂性和要求。</p><p id="b28f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">下面是使用这个新库运行我们程序的代码:</p><pre class="jr js jt ju fd jv jw jx jy aw jz bi"><span id="b14e" class="ka kb hi jw b fi kc kd l ke kf">start = time.perf_counter()<br/>data=df.copy()<br/>stats={} # store every ticker results.<br/>if __name__ == ‘__main__’:<br/> with concurrent.futures.ProcessPoolExecutor() as executor:<br/> results = executor.map(cpu_task,data.columns)<br/>finish = time.perf_counter()<br/>print(f’running time: {finish-start} second(s)’)</span><span id="57d5" class="ka kb hi jw b fi kg kd l ke kf">running time: 17.3365097 second(s)</span></pre><p id="581c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这种新方法的性能比我们以前的多处理选项稍差，但它仍然比标准的循环顺序选择快得多。关于concurrent.futures或本机多处理模块的使用，需要强调几点:</p><ul class=""><li id="beef" class="lk ll hi is b it iu ix iy jb lm jf ln jj lo jn ly lq lr ls bi translated"><strong class="is hj">concurrent . futures . processpoolexecutor()</strong>是本机<strong class="is hj">多处理的包装器。池()</strong>。因此，多重处理的限制同样适用(例如，对象需要是可选择的)。</li><li id="9eb3" class="lk ll hi is b it lt ix lu jb lv jf lw jj lx jn ly lq lr ls bi translated"><strong class="is hj"> concurrent.futures </strong>提供一个API来记住你是使用线程还是多重处理，例如，对于IO绑定的任务，在语法ThreadPoolExecutor()中使用ThreadPoolExecutor()而不是ProcessPoolExecutor()，这样就完成了。</li><li id="5839" class="lk ll hi is b it lt ix lu jb lv jf lw jj lx jn ly lq lr ls bi translated"><strong class="is hj"> concurrent.futures </strong>使用简单的API使得长期维护变得更加容易。然而，<strong class="is hj">多重处理</strong>库提供了在更大的灵活性和更少的可读性和维护问题之间的权衡。</li><li id="df47" class="lk ll hi is b it lt ix lu jb lv jf lw jj lx jn ly lq lr ls bi translated">使用concurrent.futures时的时间性能比使用多处理时稍差。池。这些时间增益差异的原因是<strong class="is hj">多重处理。Pool </strong>将传递给map的iterable批处理成块，然后将块传递给worker进程，这减少了父进程和子进程之间的工作量时间。相反，<strong class="is hj">concurrent . futures . processpoolexecutor</strong>总是一次将iterable中的一个项目传递给子项目，这导致了较差的时间性能。</li></ul><p id="1a86" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">综上所述，<strong class="is hj">多重处理和Concurrent.futures模块具有相似的性能，尽管前者为自定义任务提供了更多的灵活性，同时牺牲了代码的可读性。这与我们出于线程目的比较两个模块所获得的读数相同。</strong></p><figure class="jr js jt ju fd ij er es paragraph-image"><div class="er es lz"><img src="../Images/7323c8b591e9adc2b30261ca8a5e580d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1192/format:webp/1*5ETDAKiVWSi-f9VQzSSpJw.jpeg"/></div></figure><p id="b4dd" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这是对线程和多处理的简短介绍，用非常简单和简短的代码脚本来传达关键思想。</p><p id="5307" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我在Neuromancer系列的未来帖子中的目标是深入研究编程效率主题，以及对投资有用的其他数据科学主题。</p><p id="7e54" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">推荐资源:</strong></p><ul class=""><li id="a971" class="lk ll hi is b it iu ix iy jb lm jf ln jj lo jn ly lq lr ls bi translated"><strong class="is hj">最佳多处理youtube教程:</strong> <a class="ae jp" href="https://www.youtube.com/watch?v=fKl2JW_qrso&amp;t=1852s" rel="noopener ugc nofollow" target="_blank">科里·斯查费</a></li><li id="45f2" class="lk ll hi is b it lt ix lu jb lv jf lw jj lx jn ly lq lr ls bi translated"><strong class="is hj"> Python历险记</strong>:<a class="ae jp" href="https://pythonadventures.wordpress.com/2013/08/13/concurrent-futures/" rel="noopener ugc nofollow" target="_blank">concurrent . futures</a></li><li id="2044" class="lk ll hi is b it lt ix lu jb lv jf lw jj lx jn ly lq lr ls bi translated"><strong class="is hj"> Github: </strong> <a class="ae jp" href="https://github.com/Carlossn/POSTS/blob/master/post_multip.py" rel="noopener ugc nofollow" target="_blank">多重处理脚本</a></li></ul></div></div>    
</body>
</html>