<html>
<head>
<title>TensorFlow Serving: Deploying Deep Learning Models Just Got Easier!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">TensorFlow服务:部署深度学习模型变得更加容易！</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/tensorflow-serving-deploying-deep-learning-models-just-got-easier-fcb4720f2111?source=collection_archive---------26-----------------------#2020-03-02">https://medium.com/analytics-vidhya/tensorflow-serving-deploying-deep-learning-models-just-got-easier-fcb4720f2111?source=collection_archive---------26-----------------------#2020-03-02</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="43a7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以你已经建立了你的机器学习或者深度学习模型。恭喜你。这是向你的客户或顾客展示模型的重要一步。但这还不是你项目的最后阶段。</p><p id="7244" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后一个阶段——你的<a class="ae jd" href="https://courses.analyticsvidhya.com/courses/applied-machine-learning-beginner-to-professional?utm_source=blog&amp;utm_medium=tensorflow-serving-deploy-deep-learning-models" rel="noopener ugc nofollow" target="_blank">机器学习</a>或<a class="ae jd" href="https://courses.analyticsvidhya.com/courses/computer-vision-using-deep-learning-version2?utm_source=blog&amp;utm_medium=tensorflow-serving-deploy-deep-learning-models" rel="noopener ugc nofollow" target="_blank">深度学习</a>项目中至关重要的一环——是模型部署。您需要能够将模型提供给最终用户，对吗？具有讽刺意味的是——大多数课程、有影响的人，甚至专家——没有人支持模型部署的价值。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/edc4b3c8f77dca5d25662e3b0ffb3325.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*IEZwowskSeIjuTnE.png"/></div></div></figure><p id="73e7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然而，当您参加数据科学家面试时，您将面临大量关于模型部署的问题！什么是模型部署？模型部署有哪些不同的工具？如何将一种语言编写的深度学习模型处理到需要不同语言的生产环境中？</p><p id="9ee8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后，我们将研究一个流行的深度学习数据集，并了解如何使用TensorFlow服务来部署您的深度学习模型。这里有很多东西要打开，让我们开始吧。</p><p id="168d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">什么是模型部署？</strong></p><p id="d40e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在一个典型的机器学习和深度学习项目中，我们通常首先定义问题陈述，然后是数据收集和准备，理解数据和建立模型。</p><p id="6e1f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">但最终，我们希望我们的模型对最终用户可用，以便他们可以利用它。模型部署是任何机器学习项目的最后阶段之一，可能有点棘手。</p><p id="acd5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是一个典型的机器学习和深度学习项目管道的图解版本:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es jq"><img src="../Images/0abe8983526e54cf81162b7839873bf1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/0*ghqbvK2zXfb4XLRO.gif"/></div></figure><p id="f7b6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">部署后的挑战</strong></p><p id="12b5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">您可能会遇到一些后模型部署挑战:</p><ul class=""><li id="69a2" class="jr js hi ih b ii ij im in iq jt iu ju iy jv jc jw jx jy jz bi translated">如果您发现了一个更好的特性，提高了模型的性能，该怎么办？现在，您需要在不关闭服务器和不影响现有客户端的情况下更新生产中的模型</li><li id="5716" class="jr js hi ih b ii ka im kb iq kc iu kd iy ke jc jw jx jy jz bi translated">您希望回滚到以前的稳定版本，因为更新的部署模型在现实世界的数据集上不能很好地工作</li><li id="bb97" class="jr js hi ih b ii ka im kb iq kc iu kd iy ke jc jw jx jy jz bi translated">您想要同时测试多个模型</li><li id="06d3" class="jr js hi ih b ii ka im kb iq kc iu kd iy ke jc jw jx jy jz bi translated">理想情况下，您希望为不同类型的客户提供不同的模型</li></ul><p id="0875" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">那么，如何克服这些重大挑战呢？我们将在文章的后面使用TensorFlow服务来回答这个问题。</p><ol class=""><li id="4109" class="jr js hi ih b ii ij im in iq jt iu ju iy jv jc kf jx jy jz bi translated">使用Flask:  Flask是一个基于Python的框架，用于开发小型网站。在使用它部署模型时，我们必须围绕模型创建一个包装器。这里，我们需要编写额外的代码来使用这个模型。你可以在这里阅读更多关于<a class="ae jd" href="https://www.analyticsvidhya.com/blog/2017/09/machine-learning-models-as-apis-using-flask/?utm_source=blog&amp;utm_medium=tensorflow-serving-deploy-deep-learning-models" rel="noopener ugc nofollow" target="_blank">使用Flask部署机器学习模型的信息</a></li><li id="e038" class="jr js hi ih b ii ka im kb iq kc iu kd iy ke jc kf jx jy jz bi translated"><strong class="ih hj">用Azure部署模型:</strong> Azure机器学习提供web接口软件包，这样我们就可以轻松地大规模部署我们的机器学习模型和管道</li><li id="c86a" class="jr js hi ih b ii ka im kb iq kc iu kd iy ke jc kf jx jy jz bi translated"><strong class="ih hj">使用Kubernetes进行部署:</strong> Kubernetes是一个开源系统，用于自动化容器化应用程序的部署、伸缩和管理。它可以在不增加运营团队的情况下进行扩展</li><li id="0f71" class="jr js hi ih b ii ka im kb iq kc iu kd iy ke jc kf jx jy jz bi translated"><strong class="ih hj"> TensorFlow Serving: </strong>它是一个高性能的模型部署系统，已经被大多数Google项目使用。我们将在这里详细了解如何使用Tensorflow服务部署模型</li></ol><h1 id="903e" class="kg kh hi bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">TensorFlow提供的是什么？</h1><blockquote class="le lf lg"><p id="da80" class="if ig lh ih b ii ij ik il im in io ip li ir is it lj iv iw ix lk iz ja jb jc hb bi translated"><em class="hi"> TensorFlow Serving是一个灵活的高性能模型部署系统，用于将机器学习和深度学习模型投入生产。</em></p></blockquote><p id="9ff9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用TensorFlow服务很容易部署模型。如果我们想用一个更新的版本来更新已部署的模型，那么TensorFlow Serving让我们以一种比其他现有工具更简单的方式来完成。我们还可以在不关闭服务器的情况下回滚到任何以前的版本。</p><p id="3192" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">TensorFlow服务已经经过1000多个Google项目的测试，在这些项目中每秒处理数百万个请求。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es ll"><img src="../Images/40f3f85d530ed12fc31f31a360375a8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*wnA4esj1HtuLdFUf.png"/></div></div></figure><h1 id="d669" class="kg kh hi bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">什么是可服务的？</h1><p id="2304" class="pw-post-body-paragraph if ig hi ih b ii lm ik il im ln io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated">部署模型后，客户端向服务器发送请求，一些计算在服务器上执行。现在，客户机用来执行计算的对象被部署在服务器上，称为Servable。可服务的大小和粒度是灵活的。</p><p id="4570" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> Tensorflow服务可以处理多个版本的服务，并允许在不同版本的服务之间轻松交换。</strong></p><h1 id="feb4" class="kg kh hi bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">可服务对象的生命周期</h1><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lr"><img src="../Images/9e30afb848a2db9a9343d7cca50ef4f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*z6eQo0OyHc-jkon9.png"/></div></div></figure><ul class=""><li id="f0c9" class="jr js hi ih b ii ij im in iq jt iu ju iy jv jc jw jx jy jz bi translated">首先，在本地文件系统上创建一个servable，源插件系统检测版本并为该特定版本创建一个加载器</li><li id="1dd5" class="jr js hi ih b ii ka im kb iq kc iu kd iy ke jc jw jx jy jz bi translated">加载程序将可用的更新版本通知给管理器</li><li id="c6c8" class="jr js hi ih b ii ka im kb iq kc iu kd iy ke jc jw jx jy jz bi translated">接下来，管理器根据版本策略确定下一步是什么(如卸载以前的版本),并向加载器提供所需的资源来加载新版本和卸载以前的版本</li><li id="6693" class="jr js hi ih b ii ka im kb iq kc iu kd iy ke jc jw jx jy jz bi translated">最后，客户机可能要求使用模型的特定版本，或者服务器可能为客户机的不同部分提供不同版本的servable。在分析了所有这些因素之后，处理程序将结果返回给客户机</li></ul><h1 id="2e3e" class="kg kh hi bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">TensorFlow服务的安装步骤</h1><h2 id="d1fe" class="ls kh hi bd ki lt lu lv km lw lx ly kq iq lz ma ku iu mb mc ky iy md me lc mf bi translated">安装TensorFlow</h2><p id="56cc" class="pw-post-body-paragraph if ig hi ih b ii lm ik il im ln io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated">您可以使用Python-pip包管理器安装TensorFlow:</p><pre class="jf jg jh ji fd mg mh mi mj aw mk bi"><span id="c660" class="ls kh hi mh b fi ml mm l mn mo"># download package information from all configured sources. <br/>sudo apt-get update <br/># Current stable release for CPU and GPU <br/># !pip install tensorflow</span></pre><h2 id="c1bd" class="ls kh hi bd ki lt lu lv km lw lx ly kq iq lz ma ku iu mb mc ky iy md me lc mf bi translated">安装ModelServer</h2><p id="c9f8" class="pw-post-body-paragraph if ig hi ih b ii lm ik il im ln io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated">添加TensorFlow服务分发作为包源:</p><pre class="jf jg jh ji fd mg mh mi mj aw mk bi"><span id="cd2b" class="ls kh hi mh b fi ml mm l mn mo">echo "deb [arch=amd64] <a class="ae jd" href="http://storage.googleapis.com/tensorflow-serving-apt" rel="noopener ugc nofollow" target="_blank">http://storage.googleapis.com/tensorflow-serving-apt</a> stable tensorflow-model-server tensorflow-model-server-universal" | sudo tee /etc/apt/sources.list.d/tensorflow-serving.list &amp;&amp; \ <br/>curl <a class="ae jd" href="https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg" rel="noopener ugc nofollow" target="_blank">https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg</a> | sudo apt-key add -</span></pre><h2 id="8b16" class="ls kh hi bd ki lt lu lv km lw lx ly kq iq lz ma ku iu mb mc ky iy md me lc mf bi translated">安装Tensorflow模型服务器</h2><pre class="jf jg jh ji fd mg mh mi mj aw mk bi"><span id="474c" class="ls kh hi mh b fi ml mm l mn mo">sudo apt-get install tensorflow-model-server</span></pre><h1 id="b943" class="kg kh hi bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">问题陈述—识别数字</h1><p id="132b" class="pw-post-body-paragraph if ig hi ih b ii lm ik il im ln io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated">打开你的Jupyter笔记本(或Colab ),让我们开始编码吧！</p><p id="53c4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本文中，我们将构建和部署一个深度学习模型来识别数字。你猜对了——我们将使用著名的<a class="ae jd" href="http://yann.lecun.com/exdb/mnist/" rel="noopener ugc nofollow" target="_blank"> MNIST数据集。</a>这是机器学习和深度学习社区中广泛使用的数据集。它是由Yann LeCun，Corina Cortes和Christopher Burger开发的，用于评估手写数字分类问题的深度学习模型。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es mp"><img src="../Images/4cf3ecc108621902d0c17cf6c7ab279a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1396/format:webp/0*3h3h950ZiE3q_ah6.png"/></div></figure><h2 id="3a9b" class="ls kh hi bd ki lt lu lv km lw lx ly kq iq lz ma ku iu mb mc ky iy md me lc mf bi translated">构建我们的深度学习模型</h2><p id="848a" class="pw-post-body-paragraph if ig hi ih b ii lm ik il im ln io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated">让我们定义一个简单的<a class="ae jd" href="https://www.analyticsvidhya.com/blog/2020/02/cnn-vs-rnn-vs-mlp-analyzing-3-types-of-neural-networks-in-deep-learning/?utm_source=blog&amp;utm_medium=tensorflow-serving-deploy-deep-learning-models" rel="noopener ugc nofollow" target="_blank">人工神经网络模型</a>，用于从图像中识别数字。在这里，我使用了10，000张图像来训练模型。</p><p id="ec66" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本教程中，我们的重点将是<em class="lh">而不是</em>如何建立一个健壮的分类模型，而是学习一旦模型建立后如何部署它。如果您想了解关于构建影像分类模型的更多信息，我强烈推荐您阅读以下文章:</p><pre class="jf jg jh ji fd mg mh mi mj aw mk bi"><span id="9ebd" class="ls kh hi mh b fi ml mm l mn mo"># importing the libraries<br/>from tensorflow.keras import datasets<br/>from tensorflow.keras.models import Sequential<br/>from tensorflow.keras.layers import Dense</span><span id="fef4" class="ls kh hi mh b fi mq mm l mn mo"># loading dataset<br/>(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()</span><span id="4604" class="ls kh hi mh b fi mq mm l mn mo"># For training, we will use 10000 images <br/># And we will test our model on 1000 images<br/>train_labels = train_labels[:10000]<br/>test_labels = test_labels[:1000]</span><span id="42d2" class="ls kh hi mh b fi mq mm l mn mo">train_images = train_images[:10000].reshape(-1, 28 * 28) / 255.0<br/>test_images = test_images[:1000].reshape(-1, 28 * 28) / 255.0</span><span id="517e" class="ls kh hi mh b fi mq mm l mn mo"># define the model<br/>model = Sequential()<br/>model.add(Dense(512, activation='relu', input_shape=(784,)))<br/>model.add(Dense(10,activation='softmax'))</span><span id="6263" class="ls kh hi mh b fi mq mm l mn mo"># compile the model<br/>model.compile(optimizer='adam',loss= 'sparse_categorical_crossentropy',metrics=['accuracy'])</span><span id="1ee1" class="ls kh hi mh b fi mq mm l mn mo"># model summary<br/>model.summary()</span><span id="0106" class="ls kh hi mh b fi mq mm l mn mo"># Train the model with the new callback<br/>model.fit(train_images, train_labels, epochs=10, validation_data=(test_images,test_labels))</span><span id="9003" class="ls kh hi mh b fi mq mm l mn mo"># Evaluate the model<br/>loss, acc = model.evaluate(test_images,  test_labels, verbose=2)<br/>print("model, accuracy: {:5.2f}%".format(100*acc))</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es mr"><img src="../Images/7a297529a3aa8fac4077ab61ab029f3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*2AIxqnZZEMtbHehq.png"/></div></div></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es ms"><img src="../Images/bfca62911f97dd201a05635a26ba5011.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*L6WU0tMDgnwtVJSZ.png"/></div></div></figure><h2 id="90f4" class="ls kh hi bd ki lt lu lv km lw lx ly kq iq lz ma ku iu mb mc ky iy md me lc mf bi translated">如何保存TensorFlow模型？</h2><p id="5fd0" class="pw-post-body-paragraph if ig hi ih b ii lm ik il im ln io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated">只需一行代码就可以保存训练好的模型！使用<strong class="ih hj"> model.save </strong>方法保存模型的架构、权重和训练配置。您只需要传递目录的路径来存储模型。</p><p id="5d2b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="lh">确保将模型存储在具有整数名称的目录中。这个整数作为你的模型的版本号。</em></p><p id="beb4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果您正在为同一个问题创建多个模型，那么将最新的模型存储在一个具有更高版本号的目录中。将两个模型目录放在同一个父目录中。</p><pre class="jf jg jh ji fd mg mh mi mj aw mk bi"><span id="8513" class="ls kh hi mh b fi ml mm l mn mo"># save the model<br/>model.save('my_model/1')</span></pre><p id="f9db" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">您的模型目录将如下所示:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es mt"><img src="../Images/caabe098fa2613862dcbd72ad3100f89.png" data-original-src="https://miro.medium.com/v2/resize:fit:1018/format:webp/0*Rny0HrXftk7hVs3z.png"/></div></figure><p id="e4e8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">它将包含一个<strong class="ih hj"> saved_model.pb </strong>文件，其中<em class="lh"> pb </em>代表<strong class="ih hj"> <em class="lh"> protobuf </em> </strong>。它包含图形定义以及模型的权重。这将创建一个名为<strong class="ih hj"> assets </strong>的空目录(在我们的例子中是空的)。</p><p id="fe5c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">通常，该目录包含张量流图使用的文件，例如，用于初始化词汇表的文本文件。上面的命令还将创建一个包含标准训练检查点的名为<strong class="ih hj">变量</strong>的目录。检查点是模型在模型构建过程的特定阶段使用的所有参数的精确值。</p><h2 id="a6c0" class="ls kh hi bd ki lt lu lv km lw lx ly kq iq lz ma ku iu mb mc ky iy md me lc mf bi translated">如何使用保存的模型进行预测？</h2><p id="c4e1" class="pw-post-body-paragraph if ig hi ih b ii lm ik il im ln io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated">最大的问题！我们已经保存了训练好的模型，我们将使用该模型来预测看不见的数据上的数字。</p><p id="e6f3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">首先，我们将使用<strong class="ih hj"> load_model </strong>方法加载模型。你只需要通过模型目录——它会自动找到<strong class="ih hj">。pb </strong>文件并加载模型。</p><p id="deab" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用<strong class="ih hj">预测</strong>函数将返回10个概率的数组(因为我们有10个类)。数组中的第一个元素告诉我们这个数字的概率是0，以此类推。您可以使用另一个函数<strong class="ih hj"> predict_classes </strong>，它将返回概率最高的类:</p><pre class="jf jg jh ji fd mg mh mi mj aw mk bi"><span id="9743" class="ls kh hi mh b fi ml mm l mn mo"># import load_model<br/>from tensorflow.keras.models import load_model</span><span id="7942" class="ls kh hi mh b fi mq mm l mn mo"># give the path to model directory to load the model<br/>loaded_model = load_model('my_model/1/')</span><span id="f784" class="ls kh hi mh b fi mq mm l mn mo"># predict function to predict the probabilities for each class 0-9<br/>loaded_model.predict(test_images[0:1])</span><span id="940b" class="ls kh hi mh b fi mq mm l mn mo"># predict_classes to get the class with highest probability <br/>loaded_model.predict_classes(test_images[0:1])</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es mu"><img src="../Images/1f57325c1b128f68f32d7c8a48499eb1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*nh5IZHTqtkK0-9gj.png"/></div></div></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es mv"><img src="../Images/6fcf59cc74c447831d18ae25bf176ccd.png" data-original-src="https://miro.medium.com/v2/resize:fit:334/format:webp/0*liHChNIvHbV1x7Ox.png"/></div></figure><h1 id="356e" class="kg kh hi bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">使用TensorFlow服务部署您的深度学习模型</h1><p id="0aa8" class="pw-post-body-paragraph if ig hi ih b ii lm ik il im ln io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated">这是我们开始加载模型并运行TensorFlow服务器的地方。在此之后，我们将能够向服务器发出请求，并获得预测的结果。</p><p id="2d53" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用以下命令启动服务器:</p><pre class="jf jg jh ji fd mg mh mi mj aw mk bi"><span id="56de" class="ls kh hi mh b fi ml mm l mn mo">tensorflow_model_server --rest_api_port=9000 --model_base_path="path-to-directory/tensorflow_serving/my_model" --model_name=sample</span></pre><ul class=""><li id="5ab7" class="jr js hi ih b ii ij im in iq jt iu ju iy jv jc jw jx jy jz bi translated"><strong class="ih hj"> rest_api_port: </strong>这是您将用来发送rest请求的端口</li><li id="6742" class="jr js hi ih b ii ka im kb iq kc iu kd iy ke jc jw jx jy jz bi translated"><strong class="ih hj"> model_base_path: </strong>这里需要提供保存深度学习模型的目录路径</li><li id="02ba" class="jr js hi ih b ii ka im kb iq kc iu kd iy ke jc jw jx jy jz bi translated"><strong class="ih hj">型号名称:</strong>您可以在此为您的型号命名。在发出REST请求时，您需要在URL中提供这个信息</li></ul><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es mw"><img src="../Images/ea7c5d36eee790622b1db7f4d6fb7bb6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*g5KVkP0WKuZfQMFf.png"/></div></div></figure><p id="c5c9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">恭喜你。你已经部署了你的深度学习模型。现在，让我们看看如何向已部署的模型发送请求并获得结果。</p><h1 id="a637" class="kg kh hi bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">使用部署的深度学习模型进行预测</h1><p id="9330" class="pw-post-body-paragraph if ig hi ih b ii lm ik il im ln io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated">首先，我们将定义一个显示图像并添加标签作为图像标题的函数。我们将通过生成一个随机索引来测试该函数，并显示该索引上的图像和标签:</p><pre class="jf jg jh ji fd mg mh mi mj aw mk bi"><span id="592c" class="ls kh hi mh b fi ml mm l mn mo"># import skimage and matplotlib and random<br/>from skimage import io<br/>import matplotlib.pyplot as plt<br/>%matplotlib inline<br/>import random</span><span id="2e58" class="ls kh hi mh b fi mq mm l mn mo"># function to display image<br/>def show(idx, title):<br/>    plt.figure()<br/>    plt.imshow(test_images[idx].reshape(28,28))<br/>    plt.axis('off')<br/>    plt.title('\n\n{}'.format(test_labels[idx]), fontdict={'size': 16})</span><span id="b231" class="ls kh hi mh b fi mq mm l mn mo"># generate a random index<br/>r = random.randint(0,len(test_images)-1)</span><span id="1cd7" class="ls kh hi mh b fi mq mm l mn mo">#<br/>print("Random Number Generated: ", r, "Image Label : ", test_labels[r])<br/>show(r, 'Image: {}'.format(test_images[rando]))</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es mx"><img src="../Images/971b7c2d45e6c805a01b2a0e2fb8da72.png" data-original-src="https://miro.medium.com/v2/resize:fit:930/format:webp/0*Y8SGCCbwrjmD-l0r.png"/></div></figure><p id="e9f4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">接下来，我们将创建一个<strong class="ih hj"> JSON </strong>对象，并将前3个数据点成批发送到服务器。在这之后，我们将使用<strong class="ih hj">请求</strong>库向我们之前定义的<strong class="ih hj"> REST API端口9000 </strong>发送一个<strong class="ih hj"> POST </strong>请求。</p><p id="07c6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">还记得我们在部署模型时将其命名为<strong class="ih hj">样本</strong>吗？因此，在URL中，我们需要提供该名称以及您要求的结果的模型版本:</p><pre class="jf jg jh ji fd mg mh mi mj aw mk bi"><span id="b1ca" class="ls kh hi mh b fi ml mm l mn mo">import json<br/>import requests</span><span id="75a6" class="ls kh hi mh b fi mq mm l mn mo"># create a json string to ask query to the depoyed model<br/>data = json.dumps({"signature_name": "serving_default",<br/>                   "instances": test_images[0:3].tolist()})</span><span id="9a01" class="ls kh hi mh b fi mq mm l mn mo"># headers for the post request<br/>headers = {"content-type": "application/json"}</span><span id="bc00" class="ls kh hi mh b fi mq mm l mn mo"># make the post request <br/>json_response = requests.post('<a class="ae jd" href="http://localhost:9000/v1/models/sample/versions/1:predict'" rel="noopener ugc nofollow" target="_blank">http://localhost:9000/v1/models/sample/versions/1:predict'</a>,<br/>                              data=data,<br/>                              headers=headers)</span><span id="ca99" class="ls kh hi mh b fi mq mm l mn mo"># get the predictions<br/>predictions = json.loads(json_response.text)<br/>predictions</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es my"><img src="../Images/3098caf4d3720446f77b1b84a50750dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*IfQ6C9Z9Eq3XQ2qw.png"/></div></div></figure><p id="c772" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们已经收到了每个数据点的概率数组。现在，我们可以使用<strong class="ih hj"> NumPy argmax </strong>函数轻松找到最大概率的索引。</p><p id="9d4a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们看看我们得到的预测结果是否正确:</p><pre class="jf jg jh ji fd mg mh mi mj aw mk bi"><span id="7943" class="ls kh hi mh b fi ml mm l mn mo"># get the prediction array<br/>predictions = predictions['predictions']</span><span id="afa3" class="ls kh hi mh b fi mq mm l mn mo"># print the actual image and the predicted result<br/>for i, prediction in enumerate(predictions):<br/>    print("Prediction: ",np.argmax(prediction))<br/>    show(i,test_images[i])</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es mz"><img src="../Images/4e17ebe859664b0719069a0cb5920083.png" data-original-src="https://miro.medium.com/v2/resize:fit:950/format:webp/0*dS1KarVWiVs2qALR.png"/></div></figure><h2 id="ad25" class="ls kh hi bd ki lt lu lv km lw lx ly kq iq lz ma ku iu mb mc ky iy md me lc mf bi translated">如果发现新版本，自动更新模型</h2><p id="6a0b" class="pw-post-body-paragraph if ig hi ih b ii lm ik il im ln io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated">现在，我们知道我们不能一次建成一个完美的模型。我们总是构建多个模型，并从上一个模型改进模型的性能。在这里，我为同一个问题训练了另一个模型，并将其存储在目录名<strong class="ih hj"> 2 </strong>中:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es na"><img src="../Images/f5e68d5215e9ea090b2fc377c0732920.png" data-original-src="https://miro.medium.com/v2/resize:fit:920/format:webp/0*vG26WPmBSVeoziU9.png"/></div></figure><p id="5267" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">TensorFlow服务将自动检测更高版本，并自动替换它以将其部署在服务器上:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es nb"><img src="../Images/e64650301e6e36e9098c21a2280527f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*-LXHZcv-JEfbFPki.png"/></div></div></figure><h1 id="f390" class="kg kh hi bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">配置Tensorflow服务器</h1><p id="f245" class="pw-post-body-paragraph if ig hi ih b ii lm ik il im ln io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated">如果我们只需要部署一个单一的模型，到目前为止我们所做的都是最好的方法之一。<strong class="ih hj">但是如果我们需要部署多个模型呢？</strong>这是一个巨大的挑战，也是一个与行业密切相关的挑战。</p><p id="0a71" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以为Tensorflow提供一个名为<strong class="ih hj"> models.config </strong>的配置文件，其中包含一个名为<strong class="ih hj"> model_config_list </strong>的列表，该列表又包含多个模型配置。</p><p id="28ab" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">列表中的每个模型配置指定一个要服务的模型，包括它的名称和存储模型的路径。您还可以指定要使用的模型版本。默认情况下，服务器将提供版本号最大的版本。</p><p id="247a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们来看一个部署多个深度学习模型的样本配置文件。</p><h2 id="7882" class="ls kh hi bd ki lt lu lv km lw lx ly kq iq lz ma ku iu mb mc ky iy md me lc mf bi translated">部署多个模型</h2><p id="5058" class="pw-post-body-paragraph if ig hi ih b ii lm ik il im ln io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated">如果您在目录<strong class="ih hj"> my_model_1 </strong>和<strong class="ih hj"> my_model_2 </strong>中为两个不同的问题存储了两个模型，您可以如下定义配置文件并同时部署这两个模型:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es nc"><img src="../Images/d4bd13c04abce1368dcc466a7f091ca9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*PhzTXrFshhYkZus2.png"/></div></div></figure><p id="c16b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用以下命令通过配置文件部署模型:</p><pre class="jf jg jh ji fd mg mh mi mj aw mk bi"><span id="e949" class="ls kh hi mh b fi ml mm l mn mo">tensorflow_model_server --rest_api_port=9000 --model_config_file=path-to-model-directory/tensorflow_serving/models.config</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es nd"><img src="../Images/e367f8f9b0a26c1be04611fe49b75959.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*gQIxJvhcsL5G7Hlr.png"/></div></div></figure><h2 id="2dce" class="ls kh hi bd ki lt lu lv km lw lx ly kq iq lz ma ku iu mb mc ky iy md me lc mf bi translated">在指定时间后检查更新的配置</h2><p id="f6a8" class="pw-post-body-paragraph if ig hi ih b ii lm ik il im ln io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated">现在，如果我们希望服务器检查配置文件中的更改并相应地部署它，该怎么办呢？为此，我们有另一个选项<strong class="ih hj">model _ config _ file _ poll _ wait _ seconds</strong>，它将在指定时间后检查更新的配置。</p><p id="22b6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最初，模型目录只有版本1:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es ne"><img src="../Images/87f4da4841b93e80b3449e593a05b5f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*mewChXGwbtlpyLKb.png"/></div></div></figure><p id="965b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">运行以下命令，服务器将在30秒后检查更新的配置文件:</p><pre class="jf jg jh ji fd mg mh mi mj aw mk bi"><span id="8655" class="ls kh hi mh b fi ml mm l mn mo">tensorflow_model_server --rest_api_port=9000 --model_config_file=/home/lakshay/Documents/tensorflow_serving/models.config --model_config_file_poll_wait_seconds=30</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es nf"><img src="../Images/7008ebb5cd153b5d77dc41d49f196987.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*mkfPJD_0Mxn7_6yr.png"/></div></div></figure><p id="dda0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里，我们用版本2训练了另一个模型。现在，我们不必关闭服务器并使用更新后的模型重新启动它。</p><p id="0e7e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们只需要更新配置文件中的版本，在指定的时间后，TensorFlow服务器将自动用更新的版本替换模型，而无需关闭服务器。完美！</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es ng"><img src="../Images/34d61e0d56178b8447c1d8258a165736.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*RZt2BRsnFELgWUrL.png"/></div></div></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es nh"><img src="../Images/d3ae5da4b3513172bd2363a91b952856.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*qhctlGQiS0nqm1tn.png"/></div></div></figure><h2 id="98d6" class="ls kh hi bd ki lt lu lv km lw lx ly kq iq lz ma ku iu mb mc ky iy md me lc mf bi translated">回滚到以前的稳定版本</h2><p id="e475" class="pw-post-body-paragraph if ig hi ih b ii lm ik il im ln io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated">更新的机型性能不如之前的机型性能怎么办？这里，我们只需要将配置文件中的版本更新为1，之前的稳定版本将自动部署在服务器上。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es nh"><img src="../Images/4ec6038a1f5ba191fd99df1a2b1977ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*XXt4J5saIcpGbA9m.png"/></div></div></figure><h1 id="8bdf" class="kg kh hi bd ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld bi translated">结束注释</h1><p id="11a1" class="pw-post-body-paragraph if ig hi ih b ii lm ik il im ln io ip iq lo is it iu lp iw ix iy lq ja jb jc hb bi translated">部署深度学习模型起初可能看起来很复杂。但是通过这篇教程，你知道了如何使用TensorFlow服务做到这一点的具体细节。</p><p id="0426" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="lh">原载于2020年3月2日</em><a class="ae jd" href="https://www.analyticsvidhya.com/blog/2020/03/tensorflow-serving-deploy-deep-learning-models/" rel="noopener ugc nofollow" target="_blank"><em class="lh">【https://www.analyticsvidhya.com】</em></a><em class="lh">。</em></p></div></div>    
</body>
</html>