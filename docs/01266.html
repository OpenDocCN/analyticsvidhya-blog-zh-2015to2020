<html>
<head>
<title>Restaurant Reviews Analysis</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">餐馆评论分析</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/restaurant-reviews-analysis-3feed3764592?source=collection_archive---------11-----------------------#2019-10-11">https://medium.com/analytics-vidhya/restaurant-reviews-analysis-3feed3764592?source=collection_archive---------11-----------------------#2019-10-11</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><h1 id="7f8f" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">网页抓取</h1><p id="c4b9" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">数据科学更令人沮丧的一个方面是收集大量的好数据。在我最近的项目中，我实现了一个<strong class="jf hj">网络抓取器来收集来自yelp.com的餐馆评论文本</strong>。我曾计划使用yelp API，但很快发现它仅限于为每个企业返回3条评论。这对于我的特定项目来说是不可接受的，所以我决定第一次尝试抓取…我必须说，网络抓取有一些非常令人满意的东西。每次我的循环将从另一个网页提取业务和审查数据，我都觉得自己生活在危险的T2。我应该在这里澄清一下，这些数据并不是以滥用的方式收集的——搜集发生在一天的过程中，并且只针对这个项目所需的数据集。此外，收集的数据不会用于任何商业目的。结束免责声明。</p><p id="18f2" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">我用<strong class="jf hj"> <em class="kb">请求</em> </strong>和<strong class="jf hj"> <em class="kb"> BeautifulSoup </em> </strong>来抓取网页。我使用requests.get(url)只是为了获取网页内容。在那里，我使用请求返回的内容创建了一个BeautifulSoup对象。一旦创建了BeautifulSoup对象，我就可以立即遍历页面内容或者保存该对象供以后使用。为了定位和访问我的soup对象中的条目，我需要知道一些html标签和类名。这些可以通过访问yelp评论页面的url，并在Chrome中使用<em class="kb"> inspect </em>查看页面内容来找到。我遇到的一个挑战是yelp上的一些评论页面使用不同的html结构，所以我被迫为评论页面创建两种不同风格的scraper函数。完成后，我得到了纽约州奥尔巴尼市1081家餐馆的59274条评论。</p><p id="9151" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">要查看我的web scraper代码，请访问该项目的Github资源库。我在这里提供了<a class="ae kh" href="https://github.com/DTrimarchi10/nlp_yelp_review_data/blob/master/Project_Data_Gathering.ipynb" rel="noopener ugc nofollow" target="_blank">网络抓取笔记本的直接链接。</a></p><h1 id="3fe4" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">文本分析</h1><p id="8152" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">有一个很棒的python库叫做<strong class="jf hj"> <em class="kb"> textblob </em> </strong>，内置了测量一段文字的情绪的函数。参见下面的片段。</p><pre class="ki kj kk kl fd km kn ko kp aw kq bi"><span id="65d0" class="kr ig hi kn b fi ks kt l ku kv">from textblob import TextBlob<br/>my_text_blob = TextBlob("My random block of text")<br/>my_test_blob.sentiment.polarity</span></pre><p id="d049" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">我将每条评论的极性测量值与餐馆评论者给出的星级进行了比较。谢天谢地，他们相处得很好。</p><figure class="ki kj kk kl fd kx er es paragraph-image"><div role="button" tabindex="0" class="ky kz di la bf lb"><div class="er es kw"><img src="../Images/cb7de90dfa9eeb2a489fadd4127a1fd7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XfvBKHQWGu23NiOC9WR-xg.png"/></div></div></figure><p id="321b" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">每组评论(按星级分组)遵循正态分布。此外，情绪与星级相匹配，1星评论在群体中情绪最负面时达到峰值，5星评论在更积极的方向达到峰值。这可能看起来不太有趣，但它确实意味着评论文本本身的<strong class="jf hj">情感与星级</strong>一致。如果它们不一致，我会开始质疑我的数据、评级系统或texblob的能力。</p><p id="d31a" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">由于来自texblob的<strong class="jf hj">情绪值是连续的</strong> (-1比1)，我能够使用它来获得评论数据的更细微的视图，例如在更细粒度的尺度上随时间推移的评论情绪。</p><p id="95b6" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">对评论文本数据的进一步分析包括使用<strong class="jf hj"><em class="kb">gensim . models . phrases</em></strong>库来查找在我的数据集中使用的短语。这样做了两次。首先，得到二元模型。第二，从已经有<strong class="jf hj">二元模型</strong>的文本中获取二元模型——这将产生<strong class="jf hj">三元模型</strong>和4元模型……四元模型……或者其他任何应该被称为的东西。</p><p id="8d34" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">总之，<strong class="jf hj">gensim分析会取出宝石，如</strong>:</p><blockquote class="le lf lg"><p id="9bd1" class="jd je kb jf b jg kc ji jj jk kd jm jn lh ke jq jr li kf ju jv lj kg jy jz ka hb bi translated">免费赠送_薯片_莎莎<br/>尝起来_喜欢_纸板<br/>冷_芝麻_面条<br/>脆_外_软_内<br/>爱_恨_关系<br/>服务员_似乎_恼火<br/>呆_远_远_远</p></blockquote><p id="dddd" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">老实说，语法分析可能是这个项目中最有趣的部分。<strong class="jf hj">调整gensim phraser阈值和评分功能可能会极大地影响我的短语质量。</strong>我发现“<em class="kb"> npmi </em>”评分会返回更多短语，但它们没有使用默认评分器时返回的那些敏感。我的phraser拟合函数包含在下面。它返回一个合适的短语，然后可以应用于任何文本块。</p><pre class="ki kj kk kl fd km kn ko kp aw kq bi"><span id="11a2" class="kr ig hi kn b fi ks kt l ku kv">#Function Definition<br/>def fit_phraser(sentences, <br/>                min_count=5, <br/>                threshold=8, <br/>                scoring='default'):<br/>    """<br/>    This function returns a gensim bigram phraser. The phraser is fit to the sentences passed in and passes the min_count, threshold, and scoring parameters to Phrases in gensim.models.<br/>    """</span><span id="9b6a" class="kr ig hi kn b fi lk kt l ku kv">    bigram = Phrases(sentences=sentences, <br/>                     min_count=min_count, <br/>                     threshold=threshold, <br/>                     scoring=scoring)<br/>    return Phraser(bigram)</span><span id="f56d" class="kr ig hi kn b fi lk kt l ku kv">#Fit and apply bigram Phraser to text<br/>bigram_phraser = fit_phraser(all_sentences)<br/>phrased_sentence = bigram_phraser[text_block]</span></pre><p id="7232" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">措辞之后，我使用TF/IDF分析来提取每个企业的关键词。这是通过为每个星级餐厅创建评论文档，然后对文档集执行TF/IDF分析来完成的。我用了<strong class="jf hj"><em class="kb">sk learn . feature _ extraction . text . tfidf vector er</em></strong>得到单词分数。因为我已经对我的评论文本进行了清理、标记和措辞，所以我需要为TfidfVectorizer中的预处理器和标记器使用一个哑函数。令我惊讶的是，TF/IDF分析运行得相当快。请参见下面的矢量器对象实例化:</p><pre class="ki kj kk kl fd km kn ko kp aw kq bi"><span id="012a" class="kr ig hi kn b fi ks kt l ku kv">#Instantiate TfidfVectorizer object<br/>tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,1),<br/>                                   tokenizer=dummy_function,<br/>                                   preprocessor=dummy_function,<br/>                                   token_pattern=None)</span><span id="43dc" class="kr ig hi kn b fi lk kt l ku kv">#The dummy function simply returns the document.<br/>def dummy_function(doc):<br/>    return doc</span></pre><p id="1620" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">提取关键词后。我决定生成<strong class="jf hj">单词嵌入模型，以便测量单词之间的相似度</strong>。这是使用<strong class="jf hj"><em class="kb">gensim . models . word 2 vec</em></strong>矢量器完成的。</p><pre class="ki kj kk kl fd km kn ko kp aw kq bi"><span id="6687" class="kr ig hi kn b fi ks kt l ku kv">#Words to measure similarity<br/>positive = ['beer_selection','draft','service']</span><span id="a4b3" class="kr ig hi kn b fi lk kt l ku kv">#number of words to put into word_list<br/>n_words = 10</span><span id="0eb2" class="kr ig hi kn b fi lk kt l ku kv">model = Word2Vec(doc_list, <br/>                 size=20, <br/>                 window=5, <br/>                 min_count=1,<br/>                 workers=4)</span><span id="7c98" class="kr ig hi kn b fi lk kt l ku kv">model.train(doc_list, <br/>            total_examples=model.corpus_count,<br/>            epochs=10)</span><span id="9b94" class="kr ig hi kn b fi lk kt l ku kv">word_list = [w[0] for w in model.wv.most_similar(<br/>                           positive=positive, topn=n_words)]</span></pre><p id="b7bc" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">这将返回一个单词列表，这些单词与传递到模型中的正面单词最相似。因为单词向量是20维的，所以需要降维以便图形化地查看单词距离。我用了来自<strong class="jf hj"><em class="kb">sk learn . manifold . tsne</em></strong>的t分布随机邻居嵌入(t-SNE)降维。使用5星评论来训练模型的单词相似度的结果图如下:</p><figure class="ki kj kk kl fd kx er es paragraph-image"><div class="er es ll"><img src="../Images/0680129218c9e9e1d6c4ffbd69f561f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1300/format:webp/1*Nks2ZmK9_vGKcgUTa4Cf9g.png"/></div></figure><p id="e352" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">TSNE地块的代码在我的知识库中提供，链接如下。</p><p id="d4c6" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">我真的很喜欢这个项目的网页抓取和文字分析部分。除了这篇博文中讨论的部分，我还将一系列模型与评论文本相结合，以预测星级。我可能会创建一个单独的博客帖子来讨论这些模型，但是这个项目的所有项目jupyter笔记本和python文件都可以在<a class="ae kh" href="https://github.com/DTrimarchi10/nlp_yelp_review_data" rel="noopener ugc nofollow" target="_blank"> GitHub repo这里</a>查看。</p></div></div>    
</body>
</html>