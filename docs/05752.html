<html>
<head>
<title>Difference b/w Supervised Learning and Reinforcement Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">差分b/w监督学习和强化学习</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/difference-b-w-supervised-learning-and-reinforcement-learning-ee7fd1ffb945?source=collection_archive---------15-----------------------#2020-05-01">https://medium.com/analytics-vidhya/difference-b-w-supervised-learning-and-reinforcement-learning-ee7fd1ffb945?source=collection_archive---------15-----------------------#2020-05-01</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="e0fa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">用数学来解释这两个学科之间的细微差别</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/39a73fba1bc30b2d0e7f37682698d234.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*lc-IN4Zgj00z7IQF"/></div></div></figure><p id="ba5d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">鉴于机器学习、深度学习等的丰富资源、内容和例子，在这个学科中总有一个问题会阻碍我们掌握这些技能的计划。其中一个问题是监督学习和强化学习之间的区别。这个问题的答案可以增加清晰度、直觉和加深对这些学科的理解。这篇文章的目的是在数学方程的层面上解释这种差异。</p><p id="1344" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在追求这个问题的过程中，你会偶然发现机器学习、深度学习、监督和非监督学习以及强化学习的基础知识。假设有了这些基本知识，我们将直接解决头脑中的问题。</p><p id="17c2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">首先，监督学习(SL)和强化学习(RL)之间有很多表面上的差异。然而，这些差异在更高的层次上起作用，而没有提供任何关于潜在的微妙差异的直觉。(介意修改一下吗？…点击<a class="ae jp" href="https://www.educba.com/supervised-learning-vs-reinforcement-learning/" rel="noopener ugc nofollow" target="_blank">这里</a></p></div><div class="ab cl jq jr gp js" role="separator"><span class="jt bw bk ju jv jw"/><span class="jt bw bk ju jv jw"/><span class="jt bw bk ju jv"/></div><div class="hb hc hd he hf"><h1 id="d043" class="jx jy hi bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku bi translated">监督学习</h1><p id="ff28" class="pw-post-body-paragraph if ig hi ih b ii kv ik il im kw io ip iq kx is it iu ky iw ix iy kz ja jb jc hb bi translated">现在，考虑监督学习，</p><ol class=""><li id="2b6a" class="la lb hi ih b ii ij im in iq lc iu ld iy le jc lf lg lh li bi translated">我们有一个数据集，数据集的每个成员都有标签注释。</li><li id="b649" class="la lb hi ih b ii lj im lk iq ll iu lm iy ln jc lf lg lh li bi translated">我们使用数据集来训练神经网络(NN)，以便它学习一种将相应数据映射到其标签的方法。</li><li id="f390" class="la lb hi ih b ii lj im lk iq ll iu lm iy ln jc lf lg lh li bi translated">我们使用经过训练的模型来检查其在测试(或真实生活)数据上的性能，并评估其性能。</li></ol><p id="6da7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在上面的解释中，最重要的一步(<strong class="ih hj">第二步</strong>)决定了模型的<strong class="ih hj">效率</strong>。在这个训练步骤中，我们使用<strong class="ih hj">梯度下降算法。</strong>(为什么用这个？… <a class="ae jp" href="https://towardsdatascience.com/understanding-the-mathematics-behind-gradient-descent-dde5dc9be06e" rel="noopener" target="_blank">查看此处了解详情</a>)</p><p id="aa03" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">数学上表示的算法如下所示:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lo"><img src="../Images/6a523b713698164cc254314ae178605a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eT6Sp7WRzS2e_r5CumOK8w.png"/></div></div><figcaption class="lp lq et er es lr ls bd b be z dx translated">梯度下降表示方程<strong class="bd jz">【1】</strong></figcaption></figure><p id="fadd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">其中<strong class="ih hj"><em class="lt">【wᵢ】</em></strong>表示网络的权重<br/><strong class="ih hj"><em class="lt">α</em></strong>表示学习率。</p><p id="fdfc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">关注<strong class="ih hj">误差函数</strong>，它描述了两个量之间的差异:</p><ol class=""><li id="c218" class="la lb hi ih b ii ij im in iq lc iu ld iy le jc lf lg lh li bi translated">值<strong class="ih hj"> ŷ </strong>:神经网络的输出值。</li><li id="7132" class="la lb hi ih b ii lj im lk iq ll iu lm iy ln jc lf lg lh li bi translated">值<strong class="ih hj"> y </strong>:地面真实标签值(从带标签的<strong class="ih hj">数据集</strong>中获得)</li></ol><p id="d77a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在监督学习的最简单的情况下，如果使用的误差函数是"<strong class="ih hj">平均绝对误差</strong> " ( <a class="ae jp" href="https://heartbeat.fritz.ai/5-regression-loss-functions-all-machine-learners-should-know-4fb140e9d4b0" rel="noopener ugc nofollow" target="_blank">在这里检查其他类型</a>)，那么误差看起来像:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lu"><img src="../Images/9520b06472f3c537d6da92e62006a1cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1278/format:webp/1*QQ_VBKDU0gMjDLPSNZOdjw.png"/></div><figcaption class="lp lq et er es lr ls bd b be z dx translated">监督学习的误差方程<strong class="bd jz">【2】</strong></figcaption></figure><p id="460f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">其中<strong class="ih hj"> <em class="lt"> b </em> </strong>是网络的偏置参数。<br/>有了对[2]所代表的方程的理解，我们对答案已经走了一半。</p></div><div class="ab cl jq jr gp js" role="separator"><span class="jt bw bk ju jv jw"/><span class="jt bw bk ju jv jw"/><span class="jt bw bk ju jv"/></div><div class="hb hc hd he hf"><h1 id="272d" class="jx jy hi bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku bi translated">强化学习</h1><p id="2898" class="pw-post-body-paragraph if ig hi ih b ii kv ik il im kw io ip iq kx is it iu ky iw ix iy kz ja jb jc hb bi translated">现在考虑下面的<strong class="ih hj">强化学习</strong>的情况:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lv"><img src="../Images/c1398c01e1e9002cb0366b49b49940f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Qfj34QR_VnncGi9RkFGyTQ.png"/></div></div><figcaption class="lp lq et er es lr ls bd b be z dx translated"><strong class="bd jz">RL框架</strong> ( <a class="ae jp" href="https://www.kdnuggets.com/2018/03/5-things-reinforcement-learning.html" rel="noopener ugc nofollow" target="_blank">来源</a>)<strong class="bd jz">【3】</strong></figcaption></figure><ol class=""><li id="bee8" class="la lb hi ih b ii ij im in iq lc iu ld iy le jc lf lg lh li bi translated">我们有<strong class="ih hj">智能体</strong>、<strong class="ih hj">神经网络</strong>(或<strong class="ih hj">模型</strong>)和<strong class="ih hj">环境</strong>。</li><li id="a1b6" class="la lb hi ih b ii lj im lk iq ll iu lm iy ln jc lf lg lh li bi translated">我们使用<strong class="ih hj">状态</strong>、<strong class="ih hj">动作</strong>、<strong class="ih hj">奖励</strong>、<strong class="ih hj">下一状态</strong>策略来训练由神经网络表示的模型。</li><li id="f447" class="la lb hi ih b ii lj im lk iq ll iu lm iy ln jc lf lg lh li bi translated">代理被训练并基于(接近)最优策略执行动作，该策略使来自环境的<strong class="ih hj">累积回报</strong>最大化。</li></ol><p id="d4c3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在上面对强化学习的粗略解释中，最重要的步骤(显然)是训练网络。讽刺的是，我们在这里也使用了<strong class="ih hj">梯度下降算法</strong>。但是怎么做呢？</p><p id="b698" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">梯度下降算法的数学表达式保持不变(从1导出)。但是，问题是<strong class="ih hj">错误函数</strong>。在强化学习中，我们可以根据<strong class="ih hj">动作值</strong>函数和<strong class="ih hj">状态值</strong>函数计算误差。在这两种情况下，区别应该是这样的:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lw"><img src="../Images/9d50c02035ac4925a60792e11b6dace9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*huokroCYppR5PQvFDM-Ukg.png"/></div></div><figcaption class="lp lq et er es lr ls bd b be z dx translated">基于<strong class="bd jz">状态值</strong>、<strong class="bd jz">动作值</strong>功能<strong class="bd jz">、</strong>的误差方程</figcaption></figure></div><div class="ab cl jq jr gp js" role="separator"><span class="jt bw bk ju jv jw"/><span class="jt bw bk ju jv jw"/><span class="jt bw bk ju jv"/></div><div class="hb hc hd he hf"><h1 id="81cf" class="jx jy hi bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku bi translated">差别</h1><p id="06a6" class="pw-post-body-paragraph if ig hi ih b ii kv ik il im kw io ip iq kx is it iu ky iw ix iy kz ja jb jc hb bi translated">令人惊讶的是从方程来看(<strong class="ih hj">【2】&amp;【4】)</strong>，这两类机器学习不止相似(<strong class="ih hj">不是吗？</strong> ) <br/> <strong class="ih hj">其实没有</strong>。尽管在数学上描述相同，但这两个等式在一个特定的性能点上有所不同。基于上述等式的<strong class="ih hj"> SL </strong>和<strong class="ih hj"> RL </strong>之间最细微的差别如下…</p><p id="44f1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在监督学习中，我们有一个<strong class="ih hj">地面真实标签</strong> <strong class="ih hj">值</strong> ( <strong class="ih hj"> <em class="lt"> yᵢ </em> </strong>)来比较我们网络的结果(<strong class="ih hj"> <em class="lt"> ŷ </em> </strong>)，但是在强化学习的情况下，我们实际上<strong class="ih hj">没有<strong class="ih hj">正确的状态值</strong>(<strong class="ih hj"><em class="lt">【v(π)</em></strong>)和<strong class="ih hj">动作值</strong>没有<strong class="ih hj">实体</strong>，它会通知我们关于<strong class="ih hj">最优状态值(<em class="lt"> v(π) </em> ) </strong>和<strong class="ih hj">动作值(<em class="lt"> q(π) </em> ) </strong>的函数。代理的目标是与环境交互并为方程计算正确的值函数。</strong></p><p id="0f9a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">那么，<strong class="ih hj">我们是在用价值函数计算来自网络的价值函数吗？</strong>(这是一个<strong class="ih hj">方程式——悖论</strong>？！)<br/>这就是<strong class="ih hj">ε-贪婪政策</strong>(这是什么？<a class="ae jp" href="https://prakhartechviz.blogspot.com/2019/02/epsilon-greedy-reinforcement-learning.html" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj"> … </strong> </a>)来帮助我们达到最佳值。在强化学习中大多数流行的学习算法(<strong class="ih hj"> SARSA，Q-Learning </strong>)下，网络用随机值<strong class="ih hj">w</strong>进行初始化，这里使用的<strong class="ih hj">策略</strong> (π)是基于来自神经元的<strong class="ih hj">动作值<em class="lt"> q(s，a，w) </em> </strong>的<strong class="ih hj"> ε </strong> - <strong class="ih hj">贪婪策略</strong><br/>所以，我们使用ε-贪婪策略，根据奖励(<strong class="ih hj"> <em class="lt"> R </em> </strong>)和下一个状态<strong class="ih hj"> <em class="lt"> q(s `，a，w) </em> </strong>的action-value采取行动并更新值。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lx"><img src="../Images/3def3c4083224c1b8dd08c71ae64bb78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1272/format:webp/1*rbQK9j6Yhr9GwbK7waiPmA.png"/></div><figcaption class="lp lq et er es lr ls bd b be z dx translated">深度学习的梯度下降<strong class="bd jz">【5】</strong></figcaption></figure><p id="1b94" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">其中<strong class="ih hj"> <em class="lt"> γ </em> </strong>为<strong class="ih hj">折现率</strong>，决定<strong class="ih hj">未来奖励</strong>对<strong class="ih hj">代理</strong>的重要程度。(<a class="ae jp" href="https://stats.stackexchange.com/questions/221402/understanding-the-role-of-the-discount-factor-in-reinforcement-learning" rel="noopener ugc nofollow" target="_blank">……</a>)</p><p id="f63c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">总之，运行<em class="lt">监督学习</em>和<em class="lt">强化学习</em>的需求、运行环境、变量都有很大的不同。但是，数学方程描述了这两种机器学习之间最微妙和最重要的区别。</strong>是我们吗？或者说，这种解释应该归功于数学？！</p><p id="9e81" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">嗯，有了数学，设计任何系统的直觉总是变得比以前更好更有趣！</p></div></div>    
</body>
</html>