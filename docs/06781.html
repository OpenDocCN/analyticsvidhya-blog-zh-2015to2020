<html>
<head>
<title>Low Batch Size High Accuracy — Cross-iteration Batch Normalization</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">低批量高精度—交叉迭代批量标准化</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/cross-iteration-batch-normalization-a50fdf9e085?source=collection_archive---------11-----------------------#2020-06-02">https://medium.com/analytics-vidhya/cross-iteration-batch-normalization-a50fdf9e085?source=collection_archive---------11-----------------------#2020-06-02</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="f93e" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">使用<a class="ae ix" href="https://arxiv.org/abs/2002.05712" rel="noopener ugc nofollow" target="_blank">交叉迭代批量标准化</a>将mAP提高1%-2%</h2></div><p id="836d" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated"><strong class="ja hj">批量正常化</strong></p><blockquote class="ju jv jw"><p id="2f65" class="iy iz jx ja b jb jc ij jd je jf im jg jy ji jj jk jz jm jn jo ka jq jr js jt hb bi translated">由两位研究人员Sergey Ioffe和Christian Szegedy创建的生命安全算法[1]。BN有助于用更少的历元快速训练你的网络，并使你的网络更加健壮。归一化输入影像或要素对于网络的概化非常重要。</p></blockquote><p id="4098" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated"><strong class="ja hj">L层</strong>的批次定额是多少:</p><ol class=""><li id="456e" class="kb kc hi ja b jb jc je jf jh kd jl ke jp kf jt kg kh ki kj bi translated">计算Z(L)的平均值和方差</li></ol><figure class="kl km kn ko fd kp er es paragraph-image"><div class="er es kk"><img src="../Images/64a977c40d23bd3f30dcf5279c1e9d9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:370/1*iCuDoXyYhaWnSztDB62q6g.gif"/></div></figure><figure class="kl km kn ko fd kp er es paragraph-image"><div class="er es ks"><img src="../Images/c683eab2b364fe3bcb7e8a362efa7203.png" data-original-src="https://miro.medium.com/v2/resize:fit:540/1*rsA2QtWrEfiHsczcDI4LFA.gif"/></div></figure><p id="739e" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">2.使用之前计算的批次统计数据对图层输入进行归一化。</p><figure class="kl km kn ko fd kp er es paragraph-image"><div class="er es kt"><img src="../Images/dcd1efc4c0e6e59a32b1a3ac5c5e70b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:432/1*Vd-ukyDrrYIOnBHpzA7uEQ.gif"/></div></figure><p id="2f50" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">现在Z的每个分量都有均值0和标准单位方差。</p><p id="1586" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">3.但是我们并不总是希望隐藏单元有mean 0和SD 1，但是在实践中，我们通过引入gamma和beta让单元有不同的分布。</p><figure class="kl km kn ko fd kp er es paragraph-image"><div class="er es ku"><img src="../Images/b59defa80f36980755d8e9b154eba457.png" data-original-src="https://miro.medium.com/v2/resize:fit:314/1*ALtqWlEB1gChYn01euA5ZA.gif"/></div></figure><p id="1403" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">现在网络可以改变伽马值，这反过来会使所有隐藏单元偏离平均值0。</p><p id="7d84" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated"><em class="jx">问:你可能会问我们为什么要这么做？</em></p><p id="6ec8" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">我们这样做是为了<strong class="ja hj">利用激活函数</strong>的非线性。</p><figure class="kl km kn ko fd kp er es paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="er es kv"><img src="../Images/0dd0e6f54e4c3e1690edbb7ba204ca15.png" data-original-src="https://miro.medium.com/v2/resize:fit:1384/format:webp/1*XGRO-WxVHiylubuBiGzSKA.png"/></div></div></figure><p id="ecec" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated"><strong class="ja hj">BN的问题:</strong></p><p id="82cd" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">在BN中，假设<strong class="ja hj">每个小批量内的样本的分布统计反映了整个训练集</strong>的相似统计。虽然这个假设<strong class="ja hj">对大批量一般有效，</strong>但是当我们采用<em class="jx">小批量制度</em>(彭等，2018[2]；吴&amp;何，2018[3]；Ioffe，2017[4])，这导致从小样本集计算的噪声统计。</p><p id="81f5" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated"><strong class="ja hj"> BN到物体检测等消耗内存的任务</strong>(任等，2015[5]；戴等，2017[6])，语义切分(龙等，2015[7]；Chen等人，2017[8])和动作识别(Wang等人，2018b[9])，其中批大小是有限的，由于存储器限制，这是高度资源消耗的。</p><p id="e286" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">为了解决这个问题，已经提出了许多替代的规格化器。其中包括图层归一化(LN) (Ba等，2016[10])、实例归一化(IN) (Ulyanov等，2016[11])、组归一化(GN) (Wu &amp; He，2018[3])。</p><p id="15f7" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated"><strong class="ja hj">利用以前迭代的统计数据:</strong></p><p id="389a" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">为了解决小批量的BN问题，一种容易受骗的方法是计算当前和过去迭代的平均值和方差。</p><p id="dce3" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">观察到，由于基于梯度的训练的性质，网络权重在连续迭代之间平滑地变化。这允许我们通过泰勒多项式来近似均值和方差。</p><figure class="kl km kn ko fd kp er es paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="er es la"><img src="../Images/3318cb014898eeb956e6094b11e2e165.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cgNzvHx47QRxnPaDpdB3tQ.png"/></div></div><figcaption class="lb lc et er es ld le bd b be z dx translated"><a class="ae ix" href="https://arxiv.org/pdf/2002.05712.pdf" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="cf52" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">让我们做一点数学计算，理解正在发生的事情:</p><figure class="kl km kn ko fd kp er es paragraph-image"><div class="er es lf"><img src="../Images/ce998f6dc4fd8340c3d6198000b1e491.png" data-original-src="https://miro.medium.com/v2/resize:fit:1086/format:webp/1*tTJFZ2Ai_OJiykOsuJMwtw.png"/></div><figcaption class="lb lc et er es ld le bd b be z dx translated"><a class="ae ix" href="https://arxiv.org/pdf/2002.05712.pdf" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="2931" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">其中θt和Xt，i (θt)为第t个小批量中第I个例子的网络权重和某层的特征响应。</p><figure class="kl km kn ko fd kp er es paragraph-image"><div class="er es lg"><img src="../Images/5b71057d823638d492bfc2519195b645.png" data-original-src="https://miro.medium.com/v2/resize:fit:1084/format:webp/1*CVZvf5chb4fQ5neJVXrk-A.png"/></div><figcaption class="lb lc et er es ld le bd b be z dx translated"><a class="ae ix" href="https://arxiv.org/pdf/2002.05712.pdf" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="8849" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">Xt，i (θt)是均值和单位方差为零的白化激活，ε是为数值稳定性增加的小常数，μt(θt)和σt(θt)是当前小批量所有样品的均值和方差。</p><figure class="kl km kn ko fd kp er es paragraph-image"><div class="er es lh"><img src="../Images/7c491fa5bc1c324794e75a5e4a534c38.png" data-original-src="https://miro.medium.com/v2/resize:fit:510/format:webp/1*4T_Wcdp9nD-xI6wBhSL9Xg.png"/></div><figcaption class="lb lc et er es ld le bd b be z dx translated"><a class="ae ix" href="https://arxiv.org/pdf/2002.05712.pdf" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="de45" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">m表示当前小批量中的样本数量。</p><p id="87c9" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated"><strong class="ja hj">利用先前迭代的统计数据:</strong></p><figure class="kl km kn ko fd kp er es paragraph-image"><div class="er es li"><img src="../Images/c49aafed72daa35ca54b05975d8cfcca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1090/format:webp/1*SO8CFc8Spgl0A4ezY5iSgA.png"/></div><figcaption class="lb lc et er es ld le bd b be z dx translated"><a class="ae ix" href="https://arxiv.org/pdf/2002.05712.pdf" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="8eb3" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">为了找出函数在某个数的邻域中的样子，我们使用泰勒级数。随着层指数r的减小，部分梯度迅速减小。早期层的网络权重变化对后期层的激活分布的影响减小，这或许可以用BN内部协变量位移的减小来解释。</p><p id="141f" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">让我们来看看ResNet-18上CBN的一些<strong class="ja hj">实用</strong> <strong class="ja hj">结果</strong>。</p><figure class="kl km kn ko fd kp er es paragraph-image"><div class="er es lj"><img src="../Images/b23b5f619dce908220b7aa84774a378a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1074/format:webp/1*1yI3Tp6wq3LSo2aBUq0kRg.png"/></div><figcaption class="lb lc et er es ld le bd b be z dx translated">使用ResNet-18作为ImageNet上的基础模型时，不同批量标准化方法的最高准确度。<a class="ae ix" href="https://arxiv.org/pdf/2002.05712.pdf" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="97e0" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated"><strong class="ja hj"> <em class="jx">即使批次大小为1，前1名的准确度也会提高。</em>T19】</strong></p><p id="c7fd" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">缺点:</p><p id="2ce7" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">作者仅在单一图像分类模型ResNet-18上进行实验。因此，这种方法是否适用于其他深度网络仍然是实验性的。</p><p id="22bd" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">跨层的卡尔曼归一化也显示了微批次的准确性提高。</p><p id="f369" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated"><strong class="ja hj">结论:</strong></p><p id="f242" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">发现新的CBN优于原始的批量归一化和阿迪- rect统计计算，优于以前的迭代，没有任何问题。而且在ImageNet分类和COCO对象检测上也达到了和SyncBN不相上下的性能，可以算是上界了。</p><p id="446e" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated"><strong class="ja hj">参考文献:</strong></p><p id="1ed6" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">[1] Ioffe，s .和Szegedy，c .批量标准化:通过减少内部协变量偏移加速深度网络训练。在<em class="jx">机器学习国际会议</em>中，2015年第448–456页。</p><p id="a1fd" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">[2]彭，陈，肖，李，赵，姜，杨，张，徐，贾，余，孙，梅:大型小批量目标检测器。在<em class="jx">IEEE计算机视觉和模式识别会议论文集</em>第6181–6189页，2018年。</p><p id="eae8" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">[3]吴，杨，何，等.在<em class="jx">欧洲计算机视觉会议(ECCV) </em>的会议记录中，第3–19页，2018年。</p><p id="7409" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">[4] Ioffe，s,《批量重整化:减少批量标准化模型中的小批量依赖性》。在<em class="jx">神经信息处理系统进展</em>中，第1945–1953页，2017年。</p><p id="a2f3" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">[5] Ren，s .，He，k .，Girshick，r .，和Sun，j .更快的r-cnn:用区域建议网络实现实时目标检测。在<em class="jx">神经信息处理系统进展</em>，第91–99页，2015年。</p><p id="5d53" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">[6]戴，张，胡，黄，李，杨，魏，等.可变形卷积网络.在<em class="jx">IEEE计算机视觉国际会议论文集</em>，第764–773页，2017年。</p><p id="bff2" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">[7] Long，j .，Shelhamer，e .，和Darrell，t.《用于语义分割的完全卷积网络》.在<em class="jx">IEEE计算机视觉和模式识别会议论文集</em>第3431–3440页，2015年。</p><p id="e753" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">[8] Chen，L.-C .，Papandreou，g .，Kokkinos，I .，Murphy，k .，和Yuille，A. L. Deeplab:用深度卷积网、atrous卷积和全连接CRF进行语义图像分割。<em class="jx"> IEEE模式分析与机器智能汇刊</em>，40(4):834–848，2017。</p><p id="b482" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">[9]王，x .，Girshick，r .，Gupta，a .，和何，k .非局部神经网络.在<em class="jx">IEEE计算机视觉和模式识别会议记录</em>中，第7794–7803页，2018b。</p><p id="b63c" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">[10] Ba、J. L .、Kiros、J. R .和Hinton，G. E .图层标准化。<em class="jx"> arXiv预印本arXiv:1607.06450 </em>，2016。</p><p id="cde0" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">[11] Ulyanov，d .，Vedaldi，a .，和Lempitsky，v . Instance normalization:快速风格化的缺失成分。<em class="jx"> arXiv预印本arXiv:1607.08022 </em>，2016。</p><p id="bfb1" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated">批量卡尔曼归一化:<a class="ae ix" href="https://papers.nips.cc/paper/7288-kalman-normalization-normalizing-internal-representations-across-network-layers.pdf" rel="noopener ugc nofollow" target="_blank">用微批量训练深度神经网络</a></p><p id="70f1" class="pw-post-body-paragraph iy iz hi ja b jb jc ij jd je jf im jg jh ji jj jk jl jm jn jo jp jq jr js jt hb bi translated"><a class="ae ix" href="https://arxiv.org/abs/2002.05712" rel="noopener ugc nofollow" target="_blank">交叉迭代批量归一化arxiv.org</a></p></div></div>    
</body>
</html>