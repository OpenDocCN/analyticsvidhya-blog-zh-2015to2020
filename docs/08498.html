<html>
<head>
<title>Web Scraping using BeautifulSoup</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用 BeautifulSoup 进行网页抓取</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/web-scraping-using-beautifulsoup-f0c0c46c2421?source=collection_archive---------25-----------------------#2020-07-31">https://medium.com/analytics-vidhya/web-scraping-using-beautifulsoup-f0c0c46c2421?source=collection_archive---------25-----------------------#2020-07-31</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="b8e1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在当今世界，有很多网站可用，如果没有有效的方法，分析其中的数据会变得很困难。这就是网络报废发挥作用的地方。Web 抓取是以快速有效的方式自动从网站提取数据的过程。在可用于网络抓取的各种 python 库中，BeautifulSoup 就是其中之一。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/e496d27327ce99569ac92047d5fab4ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2O6LTgKFvp4_z5fa95pr-g.jpeg"/></div></div></figure><p id="aa38" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">BeautifulSoup 是一个用于解析 HTML 和 XML 文档的库，创建了一个解析树，从而允许我们提取和分析数据。</p><p id="70e4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">安装美汤</strong></p><p id="0712" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">可以使用使用 Python 包管理器 pip 安装的 Beautifulsoup 来安装 BeautifulSoup。</p><pre class="je jf jg jh fd jp jq jr js aw jt bi"><span id="5351" class="ju jv hi jq b fi jw jx l jy jz">pip install BeautifulSoup4</span></pre><p id="d268" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">也可以使用 anaconda 包管理器来安装它。</p><pre class="je jf jg jh fd jp jq jr js aw jt bi"><span id="dd75" class="ju jv hi jq b fi jw jx l jy jz">conda install beautifulsoup4</span></pre><p id="3155" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">让我们来看一个废弃提取印度各州名称的维基百科的例子</strong></p><p id="f320" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">要访问网页的 HTML 内容，<br/> 1。导入 python 的请求和 BeautifulSoup 库<br/> 2。提供抓取<br/> 3 所需的网址。通过对指定的 URL 执行 HTTP 请求来获取 HTML 数据，并将响应存储在对象中</p><pre class="je jf jg jh fd jp jq jr js aw jt bi"><span id="f883" class="ju jv hi jq b fi jw jx l jy jz">from bs4 import BeautifulSoup<br/>import requests<br/>url='<a class="ae ka" href="https://en.wikipedia.org/wiki/States_and_union_territories_of_India'" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/States_and_union_territories_of_India'</a><br/>response = requests.get(url)</span></pre><p id="b20d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">接下来，通过传递要解析的文档并将解析器的类型指定为参数来创建一个 BeautifulSoup 对象。BeautifulSoup 支持 html.parser、lxml、html5lib 等解析器。它将使用 HTML 解析器，除非特别提到使用 XML 解析器。默认情况下，Beautiful Soup 支持包含在 Python 标准库中的 HTML 解析器。</p><pre class="je jf jg jh fd jp jq jr js aw jt bi"><span id="c473" class="ju jv hi jq b fi jw jx l jy jz">soup = BeautifulSoup(response.text,'html.parser')</span></pre><p id="fd95" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">prettify()是一个函数，使我们能够查看标签是如何嵌套在文档中的。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es kb"><img src="../Images/656f69437c1afb3b614464a81a31c9d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*SfPzjIw0Bsi9OFrh.png"/></div></div></figure><p id="0581" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在让我们检查 HTML 脚本，在这个脚本中，获取州名的数据位于带有 wiki table sortable plain row headers 类的表下。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es kc"><img src="../Images/0ddd0e11d3cc95ec8d3cca8201afb084.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*wgMOIIwZIYZDBnMl.png"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es kd"><img src="../Images/25bd0431bce016825500efa709b40f63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*4CavAB8mz1vmQRTr.png"/></div></div></figure><p id="2452" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们只想提取 State 列下的州名，该列在<th>中找到，在检索到的表下 scope 属性为“row”。最后，我们可以打印出在<a>的 title 属性中找到的所有州的名称。</a></th></p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ke"><img src="../Images/6ff0f9b33e6e8a1b23c4976a9bdc2b97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*bt6duSrY4ubdlydj.png"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es kf"><img src="../Images/211815391df887cfe91871f374b5b5e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*idzHyDp-s7VXZwTXq76FiQ.png"/></div></div></figure><p id="fadd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我希望这篇文章有助于了解如何使用 BeautifulSoup 以一种快速简单的方式进行 web 报废。感谢阅读！！！</p></div></div>    
</body>
</html>