<html>
<head>
<title>Accuracy Fallacy in Credit Card Fraud Detection</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">信用卡欺诈检测中的准确性谬误</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/accuracy-fallacy-in-credit-card-fraud-detection-146abafb54bf?source=collection_archive---------0-----------------------#2019-07-31">https://medium.com/analytics-vidhya/accuracy-fallacy-in-credit-card-fraud-detection-146abafb54bf?source=collection_archive---------0-----------------------#2019-07-31</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="095b" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">了解用于分类的指标</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/18a07730e97cc23972562f043014b725.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0y4FLueDP-YvJjNboI7ieQ.png"/></div></div></figure><p id="71c9" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">在发布我上一个项目的第二部分之前，<a class="ae kf" rel="noopener" href="/@harjotspahwa/the-classifier-part-1-2-18f3c70d01fe">分类器</a>我想我应该写一下用于分类的度量标准，以及为什么一个模型尽管有99%的准确率却可能毫无用处。现在，这个准确性谬误是什么，应该使用什么度量来评估模型？在我回答这些问题之前，让我们先来探索一下数据。这里，我使用了一个经典的例子，我们预处理了信用卡交易的数据。数据集没有空值，并且已经进行了要素缩放。所以我只是在绘制了热图之后，从数据中提取了有用的特征。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es kg"><img src="../Images/41947914afab012900385a4d56577224.png" data-original-src="https://miro.medium.com/v2/resize:fit:1382/format:webp/1*OiVdGaB7RMXpuIR6aW8x3w.png"/></div></figure><p id="5c6a" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">最初，数据集中有31列，在分析数据后，只剩下12列，其中1列是包含交易是否欺诈的类变量。</p><pre class="iy iz ja jb fd kh ki kj kk aw kl bi"><span id="c465" class="km kn hi ki b fi ko kp l kq kr">new_features =['V1' ,'V3' ,'V4' ,'V7' ,'V10' ,'V11' ,'V12' ,'V14' ,'V16','V17','V18','Class']</span></pre><p id="a30e" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">现在，我使用新功能再次绘制了热图:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ks"><img src="../Images/a09fd74fe855f8efbe5abc8eaa66a367.png" data-original-src="https://miro.medium.com/v2/resize:fit:1312/format:webp/1*1lilV1zjjiGqQLrTAHZM4g.png"/></div></figure><p id="b162" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">我们看到类的行和列更暗，更亮。这意味着我们新数据集中的所有变量都有显著的影响。现在，让我们将数据分成测试集和训练集:</p><pre class="iy iz ja jb fd kh ki kj kk aw kl bi"><span id="1def" class="km kn hi ki b fi ko kp l kq kr">from sklearn.model_selection import train_test_split<br/>x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)</span></pre><p id="e5a0" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">此外，让我们看看在我们的测试和训练集中欺诈和安全案例的数量:</p><pre class="iy iz ja jb fd kh ki kj kk aw kl bi"><span id="c1ec" class="km kn hi ki b fi ko kp l kq kr">#Let's see how many safe and fraudulent cases are there in training set <br/>safe_train=(y_train==0).sum()<br/>fraud_train=(y_train==1).sum()<br/>print("Safe: {} \nFraud: {}".format(safe_train,fraud_train))</span><span id="7cbe" class="km kn hi ki b fi kt kp l kq kr">Output:<br/>Safe: 213242 <br/>Fraud: 363</span><span id="3f4d" class="km kn hi ki b fi kt kp l kq kr">#Let's see how many safe and fraudulent cases are there in test set <br/>safe_test=(y_test==0).sum()<br/>fraud_test=(y_test==1).sum()<br/>print("Safe: {} \nFraud: {}".format(safe_test,fraud_test))</span><span id="7da6" class="km kn hi ki b fi kt kp l kq kr">Output:<br/>Safe: 71073 <br/>Fraud: 129</span></pre><p id="7aaa" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jl hj">剧透警告:</strong>你看到欺诈案件数量和安全案件数量之间的巨大差异了吗？</p><p id="a97c" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">让我们尝试使用逻辑回归:</p><pre class="iy iz ja jb fd kh ki kj kk aw kl bi"><span id="1132" class="km kn hi ki b fi ko kp l kq kr">from sklearn.linear_model import LogisticRegression<br/>from sklearn.metrics import accuracy_score,classification_report, confusion_matrix</span><span id="482b" class="km kn hi ki b fi kt kp l kq kr">#Using Logistic Regression <br/>clf = LogisticRegression(random_state = 0)<br/>clf.fit(x_train, y_train)</span></pre><p id="19cd" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">之后，让我们预测和评估我们的模型:</p><pre class="iy iz ja jb fd kh ki kj kk aw kl bi"><span id="9c0d" class="km kn hi ki b fi ko kp l kq kr">#Let's evaluate our model <br/>y_pred = clf.predict(x_test)<br/>print("Training Accuracy: ",clf.score(x_train, y_train))<br/>print("Testing Accuracy: ", clf.score(x_test, y_test))<br/>cm = confusion_matrix(y_test, y_pred)<br/>print(cm)<br/>print(classification_report(y_test,y_pred))</span><span id="3254" class="km kn hi ki b fi kt kp l kq kr">Output:<br/>Training Accuracy:  0.9991432784813089<br/>Testing Accuracy:  0.9991432824920649<br/>[[71069     4]<br/> [   57    72]]<br/>              precision    recall  f1-score   support<br/><br/>           0       1.00      1.00      1.00     71073<br/>           1       0.95      0.56      0.70       129<br/><br/>    accuracy                           1.00     71202<br/>   macro avg       0.97      0.78      0.85     71202<br/>weighted avg       1.00      1.00      1.00     71202</span></pre><p id="f8b2" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">你看到了什么？</p><p id="48cb" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">如果我们看看测试集上的准确度，它接近0.99914，即超过99.9%的准确度。这是否意味着我们的模型是非凡的？不要！在此之前，让我告诉你二元分类的混淆矩阵代表什么我们在实际值和预测值之间建立了一个矩阵，所以行代表实际值，列代表预测值。现在你知道了什么是行和列，让我们理解每个单元格代表什么，因此:</p><ol class=""><li id="4057" class="ku kv hi jl b jm jn jp jq js kw jw kx ka ky ke kz la lb lc bi translated">[0][0] -&gt;真阳性，即我们的模型正确预测了多少个安全案例。这里71069是正确预测的安全病例数。</li><li id="291c" class="ku kv hi jl b jm ld jp le js lf jw lg ka lh ke kz la lb lc bi translated">[0][1] -&gt;假阴性，即有多少安全案例是我们的模型预测错误的。这里有4个错误分类的安全案例。因此，4个保险箱被误归类为欺诈。这种做法潜在的危险较小，因为最好在欺诈可能性极小的情况下停止一些安全的交易。</li><li id="59ac" class="ku kv hi jl b jm ld jp le js lf jw lg ka lh ke kz la lb lc bi translated">[1][0] -&gt;误报，即有多少欺诈案例是我们的模型预测错误的。这里有57个错误分类的欺诈案例。这里有57个欺诈案例被误归类为安全案例。这是非常危险的，因为我们让欺诈案件通过。这会给组织带来巨大的损失。</li><li id="6b19" class="ku kv hi jl b jm ld jp le js lf jw lg ka lh ke kz la lb lc bi translated">[1][1] -&gt;真正的否定，即我们的模型正确预测了多少欺诈案例。这里有72个被正确预测的欺诈案例。</li></ol><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es li"><img src="../Images/df5700ded6600a16435f42de860d04e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GJineIY65uCquVJRiQvSzg.png"/></div></div></figure><p id="bb53" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">我们可以看到，尽管准确率超过99.9%，但我们的模型错误地预测了57起欺诈案件(近44%)。这就是我所说的准确性谬误。这通常发生在数据分布不均匀的情况下。从上面的代码中，我们意识到训练集中欺诈案例的数量仅为363，而安全案例的数量为213242。这是非常不均匀的分布，将提供很大的准确性，但错误分类的危险类别。</p><p id="067d" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">为了给你一个视角，让我把所有的欺诈案例进行错误分类。让我们预测每种情况都是安全的，因此我们测试集的混淆矩阵如下:</p><pre class="iy iz ja jb fd kh ki kj kk aw kl bi"><span id="8988" class="km kn hi ki b fi ko kp l kq kr">[[71073     0]<br/> [129       0]]<br/></span></pre><p id="5067" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">因此，新的准确度= 71073/(71073 + 129) = 0.9981，接近99.8%的准确度。<strong class="jl hj">再次伟大的准确性，可怕的表现。</strong></p><h1 id="6cc1" class="lj kn hi bd lk ll lm ln lo lp lq lr ls io lt ip lu ir lv is lw iu lx iv ly lz bi translated">那么我们如何衡量模型性能呢？</h1><p id="6d5a" class="pw-post-body-paragraph jj jk hi jl b jm ma ij jo jp mb im jr js mc ju jv jw md jy jz ka me kc kd ke hb bi translated">答案是精度、召回率、f1评分、AUC-ROC曲线。让我们一个一个来看:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mf"><img src="../Images/76aa1db5943e9bd7d4336530b85c228d.png" data-original-src="https://miro.medium.com/v2/resize:fit:700/format:webp/1*arQ59t8LDBDcxkTY0ET1wA.png"/></div><figcaption class="mg mh et er es mi mj bd b be z dx translated">图片来源:维基百科</figcaption></figure><p id="2c08" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jl hj">精度:</strong>精度是指相关结果的百分比，计算方法如下:</p><pre class="iy iz ja jb fd kh ki kj kk aw kl bi"><span id="15ba" class="km kn hi ki b fi ko kp l kq kr">True Positives/(True Positives + Flase Positives)</span></pre><p id="fd59" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jl hj">:召回:</strong>召回是指被你的算法正确分类的相关结果占总结果的百分比，计算方法如下:</p><pre class="iy iz ja jb fd kh ki kj kk aw kl bi"><span id="8bc3" class="km kn hi ki b fi ko kp l kq kr">True Positives/(True Positives + False Negatives)</span></pre><p id="2512" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jl hj"> F1得分:</strong>它是精确度和召回率的调和平均值，计算方法如下:</p><pre class="iy iz ja jb fd kh ki kj kk aw kl bi"><span id="d2a2" class="km kn hi ki b fi ko kp l kq kr">(2 x Precision x Recall)/(Precision + Recall)</span></pre><p id="64b8" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><em class="mk">因此F1分数越高，模型越好</em></p><p id="d510" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated"><strong class="jl hj"> AUC-ROC曲线(曲线下面积-受试者操作特征曲线):</strong>真阳性率(TPR)是分类器预测概率相对于假阳性率(FPR)的图。然后，计算地块下的面积。曲线下的面积越大，我们的模型就越好。</p><pre class="iy iz ja jb fd kh ki kj kk aw kl bi"><span id="f374" class="km kn hi ki b fi ko kp l kq kr">TPR is also knowns as recall and hence = True Positives/(True Positives + False Negatives)</span><span id="874d" class="km kn hi ki b fi kt kp l kq kr">FPR is negation of specificity = 1 - Specificity = 1- True Negatives/(True Negatives + False Positives)</span><span id="3b99" class="km kn hi ki b fi kt kp l kq kr">Hence FPR = False Positives/(True Negatives + False Positives)</span></pre><p id="6704" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">让我们绘制ROC曲线并找出AUC:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ml"><img src="../Images/5125a4c93b344e934aa2caa549240df3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UpojhK3uyFdSw4y1l3JIpw.png"/></div></div></figure><p id="d346" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">我们看到AUC为0.78，这还不错，不是很大，但足够公平。</p><p id="8876" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">让我们试试监督异常检测算法KNN。我用异常检测算法来寻找数据中不寻常的模式。由于数据很不平衡，数据中一定有一些不寻常的模式，让我们试试K最近邻算法</p><pre class="iy iz ja jb fd kh ki kj kk aw kl bi"><span id="b167" class="km kn hi ki b fi ko kp l kq kr">from sklearn.neighbors import KNeighborsClassifier<br/>clf = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)<br/>clf.fit(x_train, y_train)<br/>y_pred = clf.predict(x_test)<br/>print("Training Accuracy: ",clf.score(x_train, y_train))<br/>print("Testing Accuracy: ", clf.score(x_test, y_test))<br/>cm = confusion_matrix(y_test, y_pred)<br/>print(cm)<br/>print(classification_report(y_test,y_pred))</span><span id="85a5" class="km kn hi ki b fi kt kp l kq kr">Output:<br/>Training Accuracy:  0.9996161138550128<br/>Testing Accuracy:  0.9995084407741356<br/>[[71065     8]<br/> [   27   102]]<br/>              precision    recall  f1-score   support<br/><br/>           0       1.00      1.00      1.00     71073<br/>           1       0.93      0.79      0.85       129<br/><br/>    accuracy                           1.00     71202<br/>   macro avg       0.96      0.90      0.93     71202<br/>weighted avg       1.00      1.00      1.00     71202</span></pre><p id="2332" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">这款车的f1得分很高，为0.93，这意味着它是一款相当不错的车型。让我们尝试绘制ROC并找到AUC:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ml"><img src="../Images/4cf2f90331a359129caabc7bff360ac5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8LMQ8DQLYQVBL48VV6ZPRw.png"/></div></div></figure><p id="cfe3" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">我们看到AUC为0.90，这很好，不同的数据随机状态可能会得到不同的AUC。我曾经通过使用随机种子混洗数据达到0.94。虽然在混洗数据集时，我为随机状态保留了一个常量种子，但是您可以随意处理那个:D</p><p id="1b19" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">你可以在我的Kaggle和Github档案中找到完整的代码:</p><p id="e911" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">https://www.kaggle.com/retroflake</p><p id="a4ee" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">github:<a class="ae kf" href="https://github.com/retroflake" rel="noopener ugc nofollow" target="_blank">https://github.com/retroflake</a></p><p id="b827" class="pw-post-body-paragraph jj jk hi jl b jm jn ij jo jp jq im jr js jt ju jv jw jx jy jz ka kb kc kd ke hb bi translated">欢迎在LinkedIn上联系我:<a class="ae kf" href="https://www.linkedin.com/in/harjot-singh-492375154/" rel="noopener ugc nofollow" target="_blank">https://www.linkedin.com/in/harjot-singh-492375154/</a></p></div></div>    
</body>
</html>