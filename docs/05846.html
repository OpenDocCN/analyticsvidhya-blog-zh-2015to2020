<html>
<head>
<title>Working With Sklearn Pipeline-2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Sklearn Pipeline-2</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/working-with-sklearn-pipeline-2-17f4f8491e2d?source=collection_archive---------39-----------------------#2020-05-03">https://medium.com/analytics-vidhya/working-with-sklearn-pipeline-2-17f4f8491e2d?source=collection_archive---------39-----------------------#2020-05-03</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/34c2f465c43a4c19befb8268801bd6ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1224/format:webp/1*WyfPecoBEEVymRVszoDx0w.jpeg"/></div></figure><p id="968e" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">今天的帖子是我们将了解Sklearn管道的三部分中的第二部分。你可以在这里看到第一部分:</p><ol class=""><li id="f921" class="jk jl hi io b ip iq it iu ix jm jb jn jf jo jj jp jq jr js bi translated"><a class="ae jt" rel="noopener" href="/@vikashprasad_16952/working-with-sklearn-pipeline-part1-419b32fc8b1">https://medium . com/@ vikashprasad _ 16952/working-with-sk learn-pipeline-part 1-419 b 32 fc 8 b 1</a></li></ol><p id="4671" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在这一部分，我们将探索sklearn管道，观察管道的属性，并在数据集上拟合不同的模型。继续上一篇文章，这是我们最终使用ExtraTreesClassifier作为估计器并使用不同的自定义和传统功能开发的管道(我假设您已经阅读了数据，请参考上一篇博客了解数据细节和功能)。</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="176b" class="kd ke hi jz b fi kf kg l kh ki">ET_pipeline_pos_tag = Pipeline([<br/>   ('u1', FeatureUnion([<br/>      ('tfdif_features', Pipeline([('cleaner', FeatureCleaner()),<br/>                            ('tfidf', TfidfVectorizer(max_features=40000, ngram_range=(1, 3))),<br/>                            ])),<br/>      ('numerical_features', Pipeline([('numerical_feats', FeatureMultiplierCount()),<br/>                               ('scaler', StandardScaler()), ])),<br/><br/>      ('pos_features', Pipeline([<br/>         ('pos', PosTagMatrix(tokenizer=nltk.word_tokenize)),<br/>      ])),<br/>   ])),<br/>   ('clf', ExtraTreesClassifier()),<br/>])</span></pre><p id="e254" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">让我们分解上面的管道，看看管道中涉及的各个步骤，您应该看到如下内容，基本上它显示了管道中的各个步骤，您也可以单独使用这些步骤来查看转换:</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="9754" class="kd ke hi jz b fi kf kg l kh ki">ET_pipeline_pos_tag.named_steps</span><span id="6fa7" class="kd ke hi jz b fi kj kg l kh ki">{'feature_union': FeatureUnion(n_jobs=None,<br/>              transformer_list=[('tfdif_features',<br/>                                 Pipeline(memory=None,<br/>                                          steps=[('cleaner',<br/>                                                  FeatureCleaner(clean=True)),<br/>                                                 ('tfidf',<br/>                                                  TfidfVectorizer(analyzer='word',<br/>                                                                  binary=False,<br/>                                                                  decode_error='strict',<br/>                                                                  dtype=&lt;class 'numpy.float64'&gt;,<br/>                                                                  encoding='utf-8',<br/>                                                                  input='content',<br/>                                                                  lowercase=True,<br/>                                                                  max_df=1.0,<br/>                                                                  max_features=40000,<br/>                                                                  min_df=1,<br/>                                                                  ngram_range=(1,<br/>                                                                               3),<br/>                                                                  norm='l2',<br/>                                                                  pr...<br/>                                                                         word_count=True,<br/>                                                                         word_density=None,<br/>                                                                         word_unique_percent=None,<br/>                                                                         words_vs_unique=None)),<br/>                                                 ('scaler',<br/>                                                  StandardScaler(copy=True,<br/>                                                                 with_mean=True,<br/>                                                                 with_std=True))],<br/>                                          verbose=False)),<br/>                                ('pos_features',<br/>                                 Pipeline(memory=None,<br/>                                          steps=[('pos',<br/>                                                  PosTagMatrix(normalize=True,<br/>                                                               tokenizer=&lt;function word_tokenize at 0x7f92f68fc620&gt;))],<br/>                                          verbose=False))],<br/>              transformer_weights=None, verbose=False),<br/> 'clf': ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',<br/>                      max_depth=None, max_features='auto', max_leaf_nodes=None,<br/>                      min_impurity_decrease=0.0, min_impurity_split=None,<br/>                      min_samples_leaf=1, min_samples_split=2,<br/>                      min_weight_fraction_leaf=0.0, n_estimators='warn',<br/>                      n_jobs=None, oob_score=False, random_state=None, verbose=0,<br/>                      warm_start=False)}</span></pre><p id="abf8" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">或者，您也可以通过以下方式查看这些步骤，“clf”是估计值:</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="4a2f" class="kd ke hi jz b fi kf kg l kh ki">In [28]: ET_pipeline_pos_tag.named_steps.keys()<br/>Out[28]:dict_keys(['feature_union', 'clf'])</span></pre><p id="f4f2" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">让我们来看看FeatureUnion，以及我们如何访问它并分别拟合我们的数据，当您执行“ET_pipeline_pos_tag.predict”时，管道会在内部负责转换数据并进行预测。</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="edac" class="kd ke hi jz b fi kf kg l kh ki">In[54]: pipeline_fit = ET_pipeline_pos_tag.named_steps['feature_union'].fit(X_train)<br/>pipeline_fit_train = pipeline_fit.transform(X_train)<br/>pipeline_fit_train</span><span id="9328" class="kd ke hi jz b fi kj kg l kh ki">Out[54]: &lt;6090x40019 sparse matrix of type '&lt;class 'numpy.float64'&gt;'<br/>	with 204786 stored elements in Compressed Sparse Row format&gt;</span><span id="8972" class="kd ke hi jz b fi kj kg l kh ki">In[55]: trans_test= pipeline_fit.transform(X_test)</span></pre><p id="fb54" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">如您所见，管道完全适合训练数据集，并在测试数据集上进行转换。我们现在需要从pipeline访问模型，并对其进行拟合和预测。了解管道的各个步骤很重要，这样您就可以在需要时进行调试。</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="f94f" class="kd ke hi jz b fi kf kg l kh ki">In[61]: model = ET_pipeline_pos_tag['clf'].fit(pipeline_fit_train,y=y_train)<br/>model</span><span id="4f23" class="kd ke hi jz b fi kj kg l kh ki">Out[61]: ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',<br/>                     max_depth=None, max_features='auto', max_leaf_nodes=None,<br/>                     min_impurity_decrease=0.0, min_impurity_split=None,<br/>                     min_samples_leaf=1, min_samples_split=2,<br/>                     min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,<br/>                     oob_score=False, random_state=None, verbose=0,<br/>                     warm_start=False)</span><span id="a661" class="kd ke hi jz b fi kj kg l kh ki">In[49]: model.predict(trans)</span></pre><p id="ff7c" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">让我们继续下一步，我们需要在管道中安装不同的模型，以找到最佳模型。在这一部分中，我们将关注如何添加不同的模型，在最后一部分中，我们将关注使用管道在模型上应用gridsearch cv。让我们看看如何在pipeline中添加不同的模型:</p><p id="2c13" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">步骤1:用管道声明模型:</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="a604" class="kd ke hi jz b fi kf kg l kh ki">def models():<br/> SVC_pipeline_pos_tag = Pipeline([<br/>  ('feature_union', FeatureUnion([<br/>   ('tfdif_features', Pipeline([('cleaner', FeatureCleaner()),<br/>           ('tfidf', TfidfVectorizer(max_features=40000, ngram_range=(1, 3))),<br/>           ])),<br/>   ('numerical_features', Pipeline([('numerical_feats', FeatureMultiplierCount()),<br/>            ('scaler', StandardScaler()), ])),</span><span id="f80a" class="kd ke hi jz b fi kj kg l kh ki">('pos_features', Pipeline([<br/>    ('pos', PosTagMatrix(tokenizer=nltk.word_tokenize)),<br/>   ])),<br/>  ])),<br/>  ('clf', LinearSVC()),<br/> ])</span><span id="076d" class="kd ke hi jz b fi kj kg l kh ki">ET_pipeline_pos_tag = Pipeline([<br/>  ('feature_union', FeatureUnion([<br/>   ('tfdif_features', Pipeline([('cleaner', FeatureCleaner()),<br/>           ('tfidf', TfidfVectorizer(max_features=40000, ngram_range=(1, 3))),<br/>           ])),<br/>   ('numerical_features', Pipeline([('numerical_feats', FeatureMultiplierCount()),<br/>            ('scaler', StandardScaler()), ])),</span><span id="3dac" class="kd ke hi jz b fi kj kg l kh ki">('pos_features', Pipeline([<br/>    ('pos', PosTagMatrix(tokenizer=nltk.word_tokenize)),<br/>   ])),<br/>  ])),<br/>  ('clf', ExtraTreesClassifier()),<br/> ])</span><span id="7ddb" class="kd ke hi jz b fi kj kg l kh ki">AdaBoost_pipeline_pos_tag = Pipeline([<br/>  ('feature_union', FeatureUnion([<br/>   ('tfdif_features', Pipeline([('cleaner', FeatureCleaner()),<br/>           ('tfidf', TfidfVectorizer(max_features=40000, ngram_range=(1, 3))),<br/>           ])),<br/>   ('numerical_features', Pipeline([('numerical_feats', FeatureMultiplierCount()),<br/>            ('scaler', StandardScaler()), ])),</span><span id="3f74" class="kd ke hi jz b fi kj kg l kh ki">('pos_features', Pipeline([<br/>    ('pos', PosTagMatrix(tokenizer=nltk.word_tokenize)),<br/>   ])),<br/>  ])),<br/>  ('clf', AdaBoostClassifier()),<br/> ])</span><span id="8991" class="kd ke hi jz b fi kj kg l kh ki">GRD_pipeline_pos_tag = Pipeline([<br/>  ('feature_union', FeatureUnion([<br/>   ('tfdif_features', Pipeline([('cleaner', FeatureCleaner()),<br/>           ('tfidf', TfidfVectorizer(max_features=40000, ngram_range=(1, 3))),<br/>           ])),<br/>   ('numerical_features', Pipeline([('numerical_feats', FeatureMultiplierCount()),<br/>            ('scaler', StandardScaler()), ])),</span><span id="6017" class="kd ke hi jz b fi kj kg l kh ki">('pos_features', Pipeline([<br/>    ('pos', PosTagMatrix(tokenizer=nltk.word_tokenize)),<br/>   ])),<br/>  ])),<br/>  ('clf', GradientBoostingClassifier()),<br/> ])</span><span id="f4c1" class="kd ke hi jz b fi kj kg l kh ki">pipelines = [SVC_pipeline_pos_tag,ET_pipeline_pos_tag,AdaBoost_pipeline_pos_tag,GRD_pipeline_pos_tag]</span><span id="0b73" class="kd ke hi jz b fi kj kg l kh ki">return pipelines</span></pre><p id="1a8a" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">第二步:我们现在需要在一个循环中运行它来观察最佳模型，我们使用F1分数作为衡量标准来测试并找到最佳模型:</p><pre class="ju jv jw jx fd jy jz ka kb aw kc bi"><span id="75ea" class="kd ke hi jz b fi kf kg l kh ki">In[66]: grids = models()<br/>grid_dict = {0: 'svc', 1: 'extratrees',<br/>             2: 'adaboost', 3: 'gradientboost'}<br/><br/>print('Performing model optimizations...')<br/>best_acc = 0.0<br/>best_clf = 0<br/>best_gs = ''<br/>for idx, gs in enumerate(grids):<br/>    print('\nEstimator: %s' % grid_dict[idx])<br/>    gs.fit(X_train, y_train)<br/>    # Predict on test data with best params<br/>    y_pred = gs.predict(X_test)<br/>    # Test data accuracy of model with best params<br/>    print('Test set f1 score : %.3f ' % f1_score(y_test, y_pred))<br/>    # Track best (highest test accuracy) model<br/>    if f1_score(y_test, y_pred) &gt; best_acc:<br/>        best_acc = f1_score(y_test, y_pred)<br/>        best_gs = gs<br/>        best_clf = idx<br/>print('\nClassifier with best test set f1 score: %s' % grid_dict[best_clf])<br/># Save best grid search pipeline to file<br/>dump_file = 'best_gs_pipeline.joblib'<br/>joblib.dump(best_gs, dump_file, compress=1)<br/>print('\nSaved %s pipeline to file: %s' % (grid_dict[best_clf], dump_file))</span><span id="95d5" class="kd ke hi jz b fi kj kg l kh ki">Performing model optimizations...<br/><br/>Estimator: svc<br/>Test set f1 score : 0.749 <br/><br/>Estimator: extratrees<br/>Test set f1 score : 0.674 <br/><br/>Estimator: adaboost<br/>Test set f1 score : 0.698 <br/><br/>Estimator: gradientboost<br/>Test set f1 score : 0.699 <br/><br/>Classifier with best test set f1 score: svc<br/><br/>Saved svc pipeline to file: best_gs_pipeline.joblib</span></pre><p id="cc49" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">正如你所看到的，最好的模型是F1分数约为0.75的LinearSVC，在下一篇文章中，我们将尝试在GridsearchCV和pipelines的帮助下对模型进行微调。如果这篇文章有任何帮助，请鼓掌:)</p><p id="23d6" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">感谢阅读！！</p></div></div>    
</body>
</html>