<html>
<head>
<title>Car buying is fun with Snowflake Part 2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">汽车购买是有趣的雪花第 2 部分</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/car-buying-is-fun-with-snowflake-part-2-42a6b91d0870?source=collection_archive---------17-----------------------#2020-11-06">https://medium.com/analytics-vidhya/car-buying-is-fun-with-snowflake-part-2-42a6b91d0870?source=collection_archive---------17-----------------------#2020-11-06</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="5d90" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在<a class="ae jd" href="https://paragshah.medium.com/car-buying-is-fun-with-snowflake-7decb8d7e774" rel="noopener"> part 1 </a>中，在推入雪花阶段之前，车辆库存数据被下载到本地。它包括手动运行 Python 脚本来下载 JSON 数据、在 SnowSql 中运行命令来上传文件，然后复制到命令中以将数据加载到雪花表中。</p><p id="5f4a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我能够使用 Azure Logic 应用程序和 Blob 存储来自动化所有这些。这个想法是每天自动运行整个过程，从雪花的每个汽车经销商那里获得更新的库存。</p><p id="6017" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">以下是自动化工作流程的样子:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/7e30a06f2f98c118f70a2725313ce007.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3hTDaAZdZCR3rc03FQpihw.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">红色圆圈中的步骤在下面展开</figcaption></figure><ol class=""><li id="7bdb" class="ju jv hi ih b ii ij im in iq jw iu jx iy jy jc jz ka kb kc bi translated">Azure Logic App 是这个工作流程的起点。现在我用 REST API 作为触发器，接受两个整数输入，开始和结束 id</li></ol><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es kd"><img src="../Images/900a7da4543792d0edeb153788f058a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1342/format:webp/1*o8qkTrZk5jIlRpEJEaCSWg.png"/></div></figure><p id="ebb9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.一旦 API 被调用，它就用一个循环启动 Logic App，从开始到结束遍历每个 Ids 值，并调用 VMS API</p><p id="4e1b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">3.逻辑应用程序将 API 响应作为对象存储在 Blob 存储中</p><p id="1554" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">4.创建 EventGrid 主题是为了在存储中创建新的 blob 时将消息推入存储队列。每当一个新的 JSON blob 在外部阶段变得可用时，需要这个步骤来自动调用 SnowPipe</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es ke"><img src="../Images/221e76cf322eabe5d0016ef68fe005cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qXmUDAUr5xJR5GdXX7vr6g.png"/></div></div></figure><p id="3064" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">查询雪花。account Usage . Pipe _ Usage _ History 视图，提供 SnowPipe 执行的日志</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es kf"><img src="../Images/11412a4075044cb8c8adfb0ef684ebb6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p9-iPrTkLw-eXYoMg6-6QQ.png"/></div></div></figure><p id="70c5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">创建自动化 SnowPipe 需要首先在雪花中进行一些设置步骤，然后通过云提供商进行设置。</p><pre class="jf jg jh ji fd kg kh ki kj aw kk bi"><span id="ea3a" class="kl km hi kh b fi kn ko l kp kq">create notification integration VMS_AZURE_QUEUE_INTEGRATION<br/> enabled = true<br/> type = queue<br/> notification_provider = azure_storage_queue<br/> azure_storage_queue_primary_uri = ‘https://&lt;storage account&gt;.queue.core.windows.net/&lt;queue name&gt;<br/> azure_tenant_id = ‘&lt;Tenant ID&gt;’;<br/> <br/>//Run DESC command to get AZURE_CONCENT_URL to authenticate Snowflake account. While you do that, you will also need to go to Azure Portal &gt; Storage Account &gt; Queue &gt; Access Control (IAM) &gt; Add Role Assignments to allow new Snowflake account access to “Storage Queue Data Contributor” role.<br/>desc notification integration VMS_AZURE_QUEUE_INTEGRATION;<br/> <br/>CREATE STORAGE INTEGRATION VMS_AZURE_BLOB_INTEGRATION<br/> TYPE = EXTERNAL_STAGE<br/> STORAGE_PROVIDER = AZURE<br/> ENABLED = TRUE<br/> AZURE_TENANT_ID = ‘&lt;Tenant ID&gt;’<br/> STORAGE_ALLOWED_LOCATIONS = (‘azure://&lt;storage account&gt;.blob.core.windows.net/&lt;storage container name&gt;/’);<br/> <br/>//Run DESC command to get AZURE_CONCENT_URL to authenticate Snowflake account. While you do that, you will also need to go to Azure Portal &gt; Storage Account &gt; Container &gt; Access Control (IAM) &gt; Add Role Assignments to allow new Snowflake account access to “Storage Blob Data Contributor” role.<br/>desc storage integration VMS_AZURE_BLOB_INTEGRATION;<br/> <br/>Create STAGE “VMS”.”PUBLIC”.”VMS_AZURE_STAGE” <br/> STORAGE_INTEGRATION = VMS_AZURE_BLOB_INTEGRATION <br/> URL = ‘azure://&lt;storage account&gt;.blob.core.windows.net/&lt;storage container name&gt;’ <br/> COMMENT = ‘Stage location for incoming JSON files from LogicApp’;<br/> <br/> <br/>create or replace pipe VMS_AZURE_BLOB_PIPE <br/> auto_ingest=true <br/> integration=’VMS_AZURE_QUEUE_INTEGRATION’ <br/> comment=’AUTOMATED PIPE’ as COPY INTO “VMS”.”PUBLIC”.”VMS_AZURE_BLOB_LZ1" FROM @”VMS”.”PUBLIC”.”VMS_AZURE_STAGE” FILE_FORMAT = ( FORMAT_NAME = “VMS”.”PUBLIC”.”VMS_JSON_FORMAT”);</span></pre><p id="4db4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一旦配置完成，SnowPipes 就会在 Blob 存储中创建新文件时运行，不会出现任何问题。与使用 SnowSql 手动加载相比，使用 SnowPipe 的好处是在加载数据时节省大量成本。SnowPipe 使用无服务器概念，并且确实需要我们的仓库来运行。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es kr"><img src="../Images/c8256a8a6524d566b2ffdcd04d04d482.png" data-original-src="https://miro.medium.com/v2/resize:fit:832/format:webp/1*S0jXyiXknr9NoFW0gJdnzA.png"/></div></div></figure><p id="d36d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了完全自动化这个工作流，唯一需要做的就是在 Logic 应用程序中用一个递归活动触发器替换 REST API 触发器。</p></div><div class="ab cl ks kt gp ku" role="separator"><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx"/></div><div class="hb hc hd he hf"><p id="1b03" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">与上述工作流无关，我还在雪花中创建了一个外部表，以检查从外部 stage 访问非结构化数据时的性能。我经历了非常慢的查询性能。XS size compute 花费了 39 分钟来展平 2896 个 blobs 中的 JSON 数据。拼合后的总行数:233370。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es kz"><img src="../Images/22d7298dfbd766fbc71065a165ce2df6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Qm8GElbPLhgSe0LzDfidlQ.png"/></div></div></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es la"><img src="../Images/e275eb5bda65c821c8cda4bb85d5b059.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CrFlsH49vEisOg9xE0OVIQ.png"/></div></div></figure></div><div class="ab cl ks kt gp ku" role="separator"><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx ky"/><span class="kv bw bk kw kx"/></div><div class="hb hc hd he hf"><p id="0ca5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">基于外部表在用于非结构化数据时对性能造成的影响，它将通过将它们加载到雪花中来节省资源。一旦加载完毕，JSON 数据的扁平化速度会像闪电一样快。在外部表上花费 39 分钟的东西，一旦加载到带有变量列的雪花表中，只需 3.3 秒。</p><p id="d24e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae jd" href="https://paragshah.medium.com/car-buying-is-fun-with-snowflake-part-3-963e79bea82d" rel="noopener">第三部</a>出版。这完全是关于雪花流和将数据着陆到下一级着陆区的任务。</p></div></div>    
</body>
</html>