# YOLOv3 —实时物体检测

> 原文：<https://medium.com/analytics-vidhya/yolov3-real-time-object-detection-54e69037b6d0?source=collection_archive---------0----------------------->

*yolov 3-实时物体检测方法的概述，通过快速进入卷积神经网络进行解释。为了便于理解，我省略了细节和一些额外的步骤。这篇文章假设了一些关于神经网络的基本知识。*

**yolo v3——实时物体检测**

YOLOv3 是“你只看一次”( YOLO)方法的最新变体。这一系列模型在实时对象检测方面很受欢迎，这在 2015 年由 Joseph Redmon 等人在论文[“你只看一次:统一的实时对象检测”](https://arxiv.org/abs/1506.02640)中介绍。在深入研究 YOLO_v3 方法之前，让我们首先探索图像分类和对象定位的概念。

最著名的计算机视觉任务之一是图像分类，旨在将数据集中的每个图像分配到两个或更多类别中的一个。例如，可以设计图像分类算法来区分包含狗的图像和包含猫的图像。基本上，它回答了“这张图片中的主要对象是什么？”

如果你不仅想检测一个物体的存在，而且还想定位这个物体在图片中的位置，你可以使用称为物体定位的方法。这就把我们的问题变成了“这幅图中的主要物体是什么，它在哪里？”。

现在，这三个过程中最复杂、最有趣的是对象检测(不考虑对象分割)。在大多数现实生活场景中，我们希望我们的模型不仅仅是识别和定位一个对象，而是在同一幅图像中检测多个对象。对象检测就是这样做的，并在每个单独的对象周围绘制一个所谓的边界框。这个问题最终变成了“这幅图中的物体是什么，它们在哪里？”。自动驾驶汽车就是使用物体检测的一个明显例子。它可以发现其他车辆、交通灯、行人、标志和其他可能影响驾驶行为的实体。因为这个动作与现实同时发生，所以它被称为实时目标检测。

![](img/a7a72e6587fdfa2229e4f1c479dd17a5.png)

分类、目标定位和目标检测之间的区别

这是如何工作的？前面提到的所有方法都结合了卷积神经网络(CNN)，这是一种当前流行的深度学习架构。CNN 模仿了视觉皮层的一些特征，视觉皮层是大脑中接收、整合和处理视觉信息的区域。通过描述 CNN 如何工作，YOLO v3 得到了部分解释。

**卷积神经网络**

当我们看到一只猫的照片时，作为人类，我们理解它是一只猫，因为它的特征，像它的胡须和皮毛的形状。计算机只能识别像点、曲线、亮点和纹理这样的低级特征。所以 CNN 所做的是匹配图像的一部分，而不是整张图片。它将图像简化为一种更容易处理的形式，而不会丢失对获得良好的分类预测至关重要的特征。

计算机看到的不是图像，而是具有形状的张量(图像高度、图像宽度、颜色通道)。例如，它将观察一个 4x4x 4 x3 的数字阵列。然后，这些数字被赋予一个从 0 到 255 的值，该值描述了像素的亮度。这个数字数组(图像)通过特定的层，最终以一个预测的类标签结束。

![](img/b4193829adbf666a1f6a38171809efb6.png)

表示计算机如何看到图像

下图代表了一个通用的 CNN 管道。现在看起来可能有点莫名其妙，但一切都会得到解释。

![](img/bc4928c1ed78ec8d560242c6236515e8.png)

卷积神经网络体系结构

**卷积层**

第一层被称为*卷积层*。在卷积层，滤波器(也称为内核)应用于输入。一个滤镜，也是一个数字数组，投射到输入的一个区域(感受域)，并滑过输入图像的所有区域。过滤器的一个步骤或滑动被称为一个步幅，每个 CNN 都不同。具体来说，滤波器在应用于输入之前被翻转。重要的是，该滤波器的深度必须等于输入的深度。通过计算元素乘法来计算每张幻灯片的结果。这些值被累加成一个数字，该数字被放置在二维输出数组的相应单元中，即“特征图”。从技术上讲，上述卷积实际上是一种互相关。

![](img/81ec24069389e36544871c4b32f20b17.png)

卷积层过程

这个过程类似于在猫的图片中识别前面提到的曲线和颜色。使用不同的滤镜，可以执行边缘检测、模糊和锐化等操作。如果图像识别问题需要大量像素来区分对象，请使用大型滤镜。如果较小的和局部的特征对于识别物体很重要，使用较小的特征。为了最终识别更高层次的特征，比如猫的鼻子和耳朵，不仅需要一层，还需要整个网络。

(为了简单起见，我省略了*填充*的概念。有兴趣的话可以随便查。)

**非线性激活功能**

就在卷积发生之后，特征图的每个值通过一个非线性激活函数*。就像它的名字已经给出的那样，它带来了一个非线性属性，允许你对响应变量(类标签)建模，该响应变量随其解释变量的非线性而变化。也就是说，它支持网络中输入层和输出层之间的复杂映射。坡向决定了模型的最终结果、精度和计算效率。激活基本上是一个数学“门”，决定每个神经元的输入是否与模型的预测相关。如果它满足某个阈值，它就通过这个门，如果不满足，它就被忽略。该功能聚焦图像上的相关特征。目前最常用的非线性激活函数是整流线性单元(ReLU)函数。*

*![](img/35ea89df9fbbbbcc5d2a1ef4837fa444.png)*

*ReLU 的图形表示*

*它应用于每个像素，并用零替换特征图中的所有负像素值。F(x) = max(0，x)。*

***汇集层***

*在特征地图被调整后，它被传递到*池层*或缩减采样层。与卷积层类似，池层通过减少网络中处理数据的参数和计算量来缩减表示的空间大小。仅保留最主要的特征，并且可以维持有效训练模型的过程。除此之外，参数数量的减少控制了模型的过度拟合。过度拟合发生在模型的评估阶段，它在训练集上表现相对较高，在测试集上表现相对较低。*

*有几个池层选项，最流行的两个是最大池和平均池。在汇集图层中，将一个过滤器(通常大小为 2x2)和一个跨度为 2 的过滤器应用于输入要素地图，并在过滤器卷积的每个子区域中创建一个带有数字的输出。本质上，它总结了在输入中检测到的特征。对于最大汇集法，这将是每个子区域中的最大数量。*

*![](img/8882c805ebad14671470ba6c57be9b38.png)*

*最大汇集过程*

*卷积层、非线性激活函数和池层一起从图像中提取有用的特征，引入非线性并降低特征维数。这些层是 CNN 架构图中显示的隐藏层的元素，并且在网络中重复多次。隐藏层的目的是组合类似于缩放和平移的特征。*

*层的第一行获得低级特征的组合，例如多行和颜色的亮度。在随后的地层线中，越来越高等级的特征浮现出来，一直延续到网络的深处。*

***全连接层***

*在隐藏层之后，模型能够理解特征，并且我们可以开始分类过程。池层的输出被*展平*为一个长向量，并通过一个*全连接层*，这是一个前馈神经网络(反向传播应用于训练的每次迭代)。该向量中的每个值代表某个特征属于某个类别的概率。回到猫的例子，代表猫的鼻子或耳朵的特征应该具有被分类为“猫”的高概率。最后一层然后使用 *softmax 激活函数*来获得图像适合特定类别的最终概率。它将 CNN 的输出标准化为介于 0 和 1 之间，本质上代表了一种概率分布。*

***超参数***

*直到今天，还没有关于超参数优化的真正可行的理论。例如，要使用的卷积层数取决于您拥有的数据类型。过滤器的尺寸和步幅也是如此。这完全取决于处理任务和您的输入数据，这取决于图像的大小、复杂性和质量等。有一些超参数优化工具集可用，但许多还没有发展到应用于大规模深度学习场景。为您的情况选择超参数的一种方法是找到一种组合，以适当的比例创建图像的抽象。*

*最后，您希望您的模型能够准确地预测新数据进入的对象类。减少过拟合的一种方法是使用可选的丢弃层，其中在训练之后，网络的权重被过度调整到训练数据。该功能通过将添加层中的随机激活设置为零来“丢弃”这些激活的百分比。这听起来可能是一个违反直觉的过程，因为您会丢失一些数据。然而，这意味着模型应该能够正确地对特定的例子进行分类，即使丢失了一些信息。显然，这一层仅在训练阶段使用，然后从模型中移除。*

*现在对 CNN 有了一个基本的了解，我们可以继续讨论 YOLO 模型家族了。*

***YOLO***

*YOLO 模型是端到端的深度学习模型，因其检测速度和准确性而广受欢迎。此外，这些方法学习对象的可概括表示，这在模型应用于现实生活时是至关重要的。YOLO 网络的结构类似于普通的 CNN。它由几个卷积层和最大池层组成，最后是两个完全连接的层。*

*以前的方法，如基于区域的卷积神经网络(R-CNN)，需要数千次网络评估来对一幅图像进行预测，这可能是耗时且难以优化的。它专注于图像的特定区域，并分别训练每个单独的组件。另一方面，YOLO 模型只将图像通过神经网络一次(“你只看一次”)。*

*该网络将图像划分成网格状的单元，这些单元都预测五个边界框和物体分类。包含对象的概率较低的盒子，以及与其他盒子共享大面积的盒子将通过称为非最大抑制的过程被移除。*

*![](img/cfcf2368c2b5c1e34703b6c32d4ef227.png)*

*划分为一个网格，每个单元五个边界框，以及由此产生的边界框*

***约洛夫 3***

*最新的主要版本是该方法的第三次迭代，即 YOLOv3。每个版本都比前一个版本有所改进。最初的版本提出了通用架构，之后的第二个版本在速度更快的同时显著提高了精度。YOLOv3 通过使用技巧进一步完善了设计，例如通过使用逻辑回归的多尺度预测和边界框预测。虽然这一版本的准确性大幅提高，但速度却有所下降，从每秒 45 帧下降到 30 帧。*

*YOLOv3 使用了 Darknet 的一个变种，这是一个训练神经网络的框架，最初有 53 层。对于检测任务，另外 53 层堆叠在其上，累积到总共 106 层完全卷积架构。这解释了与只有 30 层的第二版本相比速度降低的原因。*

*![](img/0eaffd1b56eb10d38e3a739f57b7fc02.png)*

*YOLOv3 架构*

*在卷积层中，形状为 1x1 的核被应用于网络中三个不同位置的三个不同大小的特征图上。该算法在三个尺度上进行预测，通过分别以 32、16、8 的步长对图像的维度进行下采样来给出。下采样是在保持图像表示不变的情况下降低空间分辨率，目的是减小数据的大小。每个比例每层使用三个锚点边界框。三个最大的盒子代表第一个刻度，三个中等的盒子代表第二个刻度，三个最小的盒子代表最后一个刻度。通过这种方式，每一层都能出色地检测大、中、小物体。*

*以前在 YOLO，softmax 激活功能确定边界框中对象的类别也用于这些模型中。YOLOv3 的作者避免对类进行软式化，因为这种方法基于类是互斥的假设。例如，如果数据集中有类似“cat”和“animal”的类，并且边界框中的对象之一是猫，则此假设不成立，因为猫也是一种动物。取而代之的是，独立的逻辑分类器预测每个类的分数，并且使用阈值来对图像中检测到的对象执行多标记分类。属于某一类的元素不会受到属于另一类的元素的决策的影响(二进制交叉熵损失)。*

*![](img/ccf2dc9bc0908c773c9c65b91ab775d5.png)*

*YOLOv3 在 COCO 50 基准测试中的性能*

*如上图所示，YOLOv3 在 MS COCO 数据集(一个大规模对象检测数据集)上取得了最佳的速度-精度折衷。YOLOv3 在 51 毫秒内的平均精度(mAP)为 57.9%，在 198 毫秒内超过 retina net-101 57.5%。因此，在地图相同的情况下，YOLOv3 几乎快了四倍。*

*在下面的视频中，你可以看到 YOLOv3 的运行。很酷，对吧？*

*[https://www.youtube.com/watch?v=MPU2HistivI&list = pls 8 MDS 1 bdhgmpxgjg 7 wiehognght 8 hxmf&index = 257](https://www.youtube.com/watch?v=MPU2HistivI&list=PLS8mdS1BdhgmpXgJg7wiehognGht8hxmf&index=257)*