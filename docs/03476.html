<html>
<head>
<title>Classification : Model Showdown</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">分类:模特对决</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/classification-model-showdown-713fd9b31470?source=collection_archive---------11-----------------------#2020-02-03">https://medium.com/analytics-vidhya/classification-model-showdown-713fd9b31470?source=collection_archive---------11-----------------------#2020-02-03</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="bb65" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是“分类”文章，是监督机器学习的一部分。它指定数据元素所属的类。在这里，我们将借助Kaggle提供的巨大数据集，研究各种分类算法，即SVM、随机森林、KNN、朴素贝叶斯、梯度推进。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/d78e12d8b42c17de57eef4b8591ef0c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sT3IS56jgLZ8Wl3jDOkcZQ.png"/></div></div></figure><h1 id="88d4" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">分类:用例</h1><p id="e1a4" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">使用分类案例的一些关键领域:</p><ul class=""><li id="bcae" class="ks kt hi ih b ii ij im in iq ku iu kv iy kw jc kx ky kz la bi translated">找出收到的电子邮件是否是垃圾邮件。</li><li id="9476" class="ks kt hi ih b ii lb im lc iq ld iu le iy lf jc kx ky kz la bi translated">来发现病人是否患有癌症。</li><li id="d58a" class="ks kt hi ih b ii lb im lc iq ld iu le iy lf jc kx ky kz la bi translated">是晴天还是雨天。</li><li id="3aba" class="ks kt hi ih b ii lb im lc iq ld iu le iy lf jc kx ky kz la bi translated">情绪分析(是/否，肯定/否定)</li></ul><h1 id="fe1c" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">k-最近邻(KNN):</h1><p id="a773" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">k-最近邻算法用于根据相似性度量将数据点分配给聚类。它使用监督方法进行分类。</p><ul class=""><li id="3a56" class="ks kt hi ih b ii ij im in iq ku iu kv iy kw jc kx ky kz la bi translated">选择k的数量和距离度量。(如果有偶数个类，K的数量将是奇数)</li><li id="7155" class="ks kt hi ih b ii lb im lc iq ld iu le iy lf jc kx ky kz la bi translated">查找要分类的样本的k个最近邻</li><li id="51aa" class="ks kt hi ih b ii lb im lc iq ld iu le iy lf jc kx ky kz la bi translated">通过多数投票分配类别标签。</li></ul><p id="c30f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里我们有巨大的数据集，你必须建立一个预测模型来回答这个问题:“什么样的人更有可能生存？”使用乘客数据(如姓名、年龄、性别、社会经济阶层等)。幸存是标签(0 =否，1 =是)。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lg"><img src="../Images/3e24a51545bc09bb279c370b42682f2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nDv6m2EOhxe7QXIQP6XwMA.png"/></div></div><figcaption class="lh li et er es lj lk bd b be z dx translated">泰坦尼克号数据集的数据框架</figcaption></figure><p id="f96c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里我分析了，删除了列名称、机票、客舱、登机，因为Pclass(乘客级别)和票价特征足以给出关于乘客的客舱和机票号码的概念。虽然您可以包括这些功能，但这完全取决于您。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ll"><img src="../Images/0d1840a09b2255f206283d0f6a1965f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L7ySxfQrzJTrir6uXLv9NA.png"/></div></div><figcaption class="lh li et er es lj lk bd b be z dx translated">放下柱子</figcaption></figure><p id="9186" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，使用标签编码器将列“性别”转换成数字形式。<strong class="ih hj">标签编码</strong>是指将标签或列转换成数字形式，从而转换成分类数据。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lm"><img src="../Images/3120be5cd184f9cb09be5fa2f82fb640.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LiYWq6jGu68Tg6w86e-2-Q.png"/></div></div><figcaption class="lh li et er es lj lk bd b be z dx translated">标签编码器的使用</figcaption></figure><p id="ca61" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后检查数据帧中是否有空值，如果有，你必须删除它们。<strong class="ih hj">真实世界的数据肯定会有缺失值。这可能是由许多原因造成的，例如数据输入错误或数据收集问题。不管是什么原因，处理缺失数据是很重要的，因为任何基于具有非随机缺失值的数据集的统计结果都可能有偏差</strong>。此外，许多ML算法不支持带有缺失值的数据。</p><p id="7204" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">如何识别缺失值？</strong>我们可以使用pandas函数检查数据集中的空值，如下所示:</p><p id="3cc8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> df.isnull.any()。sum() </strong>其中df是数据帧名称。</p><p id="98f2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从sklearn.model_selection导入train_test_split并拆分训练数据:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ln"><img src="../Images/2bc628e877532c0b7012e07da646284c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gd3_UUn8p2rsr0DDAqRp4A.png"/></div></div><figcaption class="lh li et er es lj lk bd b be z dx translated">对数据集应用train_test_split</figcaption></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lo"><img src="../Images/fc9e969b4eef1a95b9be5a0bb214013b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JiJIRb7ifMzWdR8z7NsW0w.png"/></div></div><figcaption class="lh li et er es lj lk bd b be z dx translated">应用Knn分类器算法</figcaption></figure><p id="b89e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后，引入度量来计算模型的精度:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lo"><img src="../Images/582c5ef4f8c8089b65113a8af3a31175.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SJEy_C4dzwFNpR588-y1aQ.png"/></div></div><figcaption class="lh li et er es lj lk bd b be z dx translated">knn分类器模型的准确性</figcaption></figure><h1 id="b359" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">梯度提升:</h1><p id="eb19" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">梯度推进是另一种执行监督机器学习任务的技术，如分类和回归。这种技术的实现可以有不同的名称，最常见的是Gradient Boosting machines(缩写为GBM)和XGBoost。这些单个模型的预测能力很弱，容易过度拟合，但是将许多这样的弱模型组合成一个整体将导致整体结果的改善。</p><p id="6ffd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在使用GradientBoostingClassifier并应用于同一数据集:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lp"><img src="../Images/8252d9a28e85b3e4f9075eabffcc79cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zArgzb966W5Xwai2Z4V5mg.png"/></div></div></figure><p id="919d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这里，你可以看到结果比KNN的算法好得多。准确率为84%。</p><h1 id="a6bc" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">朴素贝叶斯:</h1><p id="8428" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">朴素贝叶斯方法是一组基于应用贝叶斯定理的监督学习算法，其“朴素”假设是在给定类变量的值的情况下，每对要素之间的条件独立性。</p><p id="befd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">朴素贝叶斯分类器是基于<strong class="ih hj">贝叶斯定理</strong>的分类算法集合。</p><p id="4027" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> P(B/A)=P(A/B)/P(A)*P(B) </strong></p><ul class=""><li id="7b42" class="ks kt hi ih b ii ij im in iq ku iu kv iy kw jc kx ky kz la bi translated">步骤1:计算给定类别标签的先验概率</li><li id="6fef" class="ks kt hi ih b ii lb im lc iq ld iu le iy lf jc kx ky kz la bi translated">第二步:找出每个类别的每个属性的可能性概率</li><li id="4b41" class="ks kt hi ih b ii lb im lc iq ld iu le iy lf jc kx ky kz la bi translated">第三步:将这些值放入贝叶斯公式并计算后验概率。</li><li id="46ad" class="ks kt hi ih b ii lb im lc iq ld iu le iy lf jc kx ky kz la bi translated">步骤4:考虑到输入属于概率较高的类，查看哪个类的概率较高。</li></ul><p id="02d8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">P(A)和P(B)是先验概率，其中A和B是标签。</p><p id="8a7a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> P(A/B)和P(B/A)是后验概率。</strong></p><p id="0fb0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对同一数据集使用朴素贝叶斯分类器(导入高斯b):</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lq"><img src="../Images/046fb9d9b0cd0275ae271fca3e97236d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QuZ-WnvIDIJoWk5w-5EXTg.png"/></div></div><figcaption class="lh li et er es lj lk bd b be z dx translated">朴素贝叶斯分类器。准确率为82%</figcaption></figure><h1 id="13a4" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">随机森林:</h1><p id="7145" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">随机森林对随机选择的数据样本使用决策树，从每棵树获得预测，并选择最佳解决方案。它也为<strong class="ih hj">特性的重要性</strong>提供了一个很好的指示器。它是监督机器学习中最流行的算法之一，既可以用作分类器，也可以用作回归器。</p><p id="fcac" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">它分为四个步骤:</p><ol class=""><li id="2d19" class="ks kt hi ih b ii ij im in iq ku iu kv iy kw jc lr ky kz la bi translated">从给定的数据集中选择随机样本。</li><li id="3ae7" class="ks kt hi ih b ii lb im lc iq ld iu le iy lf jc lr ky kz la bi translated">为每个样本构造一个决策树，从每个决策树中得到一个预测结果。</li><li id="319b" class="ks kt hi ih b ii lb im lc iq ld iu le iy lf jc lr ky kz la bi translated">对每个预测结果进行投票。</li><li id="ae16" class="ks kt hi ih b ii lb im lc iq ld iu le iy lf jc lr ky kz la bi translated">选择得票最多的预测结果作为最终预测。</li></ol><p id="a474" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面是随机森林分类器的实现:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ls"><img src="../Images/50fa01f110065643bb73878a82432ed8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cPhIdqdYBDtBJztOwXGqrQ.png"/></div></div><figcaption class="lh li et er es lj lk bd b be z dx translated">随机森林分类器，准确率为82%</figcaption></figure><h1 id="d758" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">SVM:</h1><p id="7377" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">支持向量机也是监督机器学习中流行的算法之一。它既可以用作分类器，也可以用作回归器，但主要用作分类器。与其他分类器(如逻辑回归和决策树)相比，它提供了更好的准确性。<strong class="ih hj"> SVM找到了一个有助于分类新数据点的最佳超平面。</strong></p><p id="f2da" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">以下是SVM模型在同一数据集上的实现:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lt"><img src="../Images/adeab40d6c5046488a4ca65d844cb561.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DJ9lxtWknRlrZy_i5UjQxA.png"/></div></div><figcaption class="lh li et er es lj lk bd b be z dx translated">SVM分类器，模型准确率为81%</figcaption></figure><h1 id="b4f9" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">结论:</h1><p id="5c7c" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">在本文中，您介绍了各种分类算法及其在titanic数据集上的实现，我们必须根据0和1来预测存活率。</p></div></div>    
</body>
</html>