<html>
<head>
<title>Customer-segmentation for differentiated targeting in marketing using clustering analysis</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于聚类分析的差异化目标客户细分</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/customer-segmentation-for-differentiated-targeting-in-marketing-using-clustering-analysis-3ed0b883c18b?source=collection_archive---------2-----------------------#2020-01-13">https://medium.com/analytics-vidhya/customer-segmentation-for-differentiated-targeting-in-marketing-using-clustering-analysis-3ed0b883c18b?source=collection_archive---------2-----------------------#2020-01-13</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="136a" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">使用SSE、dunn index和silhoutte分数的k-means、agglomerative、DBSCAN聚类算法的比较</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/35a4c0a3f87904ef65ac4c495c1fcc9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rFATWK6tWBrDJ1o1rzEZ8w.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">图片来源—<a class="ae jn" href="https://www.quora.com/What-is-clustering" rel="noopener ugc nofollow" target="_blank">https://www.quora.com/What-is-clustering</a></figcaption></figure><h1 id="d7d9" class="jo jp hi bd jq jr js jt ju jv jw jx jy io jz ip ka ir kb is kc iu kd iv ke kf bi translated">了解客户细分，在营销中实现差异化目标</h1><p id="aaee" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko kp kq kr ks kt ku kv kw kx ky kz la lb hb bi translated">让我们了解一下业务目标——您有一群客户。自然，客户在人口统计数据(年龄、性别、收入)、<strong class="ki hj">购买模式和行为</strong>(购买频率、购买的货币价值(价格范围)、购买的商品类型)等方面会非常多样化。和许多其他因素。其中一种常用的手法就是<a class="ae jn" href="https://en.wikipedia.org/wiki/RFM_(customer_value)" rel="noopener ugc nofollow" target="_blank"><strong class="ki hj">【RFM】</strong></a><strong class="ki hj">。现在，作为营销人员，你需要根据这些数据来决定应该做什么类型的广告/目标定位。这对于不同的客户来说是不同的，因为不同的<a class="ae jn" href="https://en.wikipedia.org/wiki/Cohort_analysis" rel="noopener ugc nofollow" target="_blank"> <strong class="ki hj">客户群</strong> </a>会有不同的表现。例如，您可能希望将快速移动的低价产品的广告投放给某些对价格非常敏感的顾客。你会想把更多的时尚、美容产品瞄准30岁以下的女性(只是一个例子，无意冒犯所有女性:P)。这种有针对性的营销方式需要存在，因为这将更好地适应每个客户的偏好，从而改善客户体验，并最大限度地提高他们的购买机会。客户细分的目的是创建相似的客户细分或客户群(基础数据),并尽可能确保没有两个客户群是相似的，也没有两个客户群是不同的。</strong></p></div><div class="ab cl lc ld gp le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="hb hc hd he hf"><h1 id="dbb8" class="jo jp hi bd jq jr lj jt ju jv lk jx jy io ll ip ka ir lm is kc iu ln iv ke kf bi translated">了解数据集</h1><p id="9de2" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko kp kq kr ks kt ku kv kw kx ky kz la lb hb bi translated">我们将使用著名的<strong class="ki hj">商场数据集</strong>(此处参考数据)——<a class="ae jn" href="https://www.kaggle.com/vjchoudhary7/customer-segmentation-tutorial-in-python" rel="noopener ugc nofollow" target="_blank"><strong class="ki hj">https://www . ka ggle . com/vjchoudhary 7/customer-segmentation-tutorial-in-python</strong></a><strong class="ki hj">。</strong></p><p id="967c" class="pw-post-body-paragraph kg kh hi ki b kj lo ij kl km lp im ko kp lq kr ks kt lr kv kw kx ls kz la lb hb bi translated">假设您有200名客户的数据，包括他们的性别、年龄、收入和支出分数。<strong class="ki hj">支出得分</strong>是一个代理指标，在1-100的范围内使用。更高的消费分数意味着顾客对购买物品有更高的亲和力，从而为购物中心带来更高的收入。我们的目标是尽我们所能对这些客户进行最佳分组，这样相似的客户会被分组在一起，不会有任何两个组是相似的。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lt"><img src="../Images/fb280d6d7098f8e99cb7d8af04f9b4bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lu5uPtTeP6Tc2Q5AdA6Swg.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">来源——ka ggle</figcaption></figure><p id="7d80" class="pw-post-body-paragraph kg kh hi ki b kj lo ij kl km lp im ko kp lq kr ks kt lr kv kw kx ls kz la lb hb bi translated">你会怎么做？你基本上拥有客户的4个属性，你需要决定你能实现的最佳细分。假设你只有性别属性。然后，你自然会把女性和男性分成两个不同的组。或者让我们假设你只有客户的年龄——你可能会创建年龄等级(类似于&lt;18, 18–25, 25–35,35–50,&gt; 50等。)根据你的企业向客户销售的产品类型，这在商业上是有意义的。但是，当您需要根据多个属性(本例中为4个)对客户进行分组时，会发生什么呢？让我给你解释一下为什么这个问题会变得复杂。我们先来看一下数据，了解一下这个。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lu"><img src="../Images/e48b45c30347f3e584d9ba9685990116.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Hy44Dp_MCUOGhYYT6L92eQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">年龄与收入——男性/女性</figcaption></figure><p id="1848" class="pw-post-body-paragraph kg kh hi ki b kj lo ij kl km lp im ko kp lq kr ks kt lr kv kw kx ls kz la lb hb bi translated">如果一个人看到上面的图表(<strong class="ki hj">年龄对收入图表，按“性别”</strong>)，他可能会将一些直觉建立在离职界限和一些商业背景的基础上，如下所示:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lv"><img src="../Images/2115002199b02701bb9587fcfa671b84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bfq7kHRhqfjkq2lnH58dow.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">集群1</figcaption></figure><p id="8652" class="pw-post-body-paragraph kg kh hi ki b kj lo ij kl km lp im ko kp lq kr ks kt lr kv kw kx ls kz la lb hb bi translated">“花费分数”和“年龄”的图表怎么样—</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lw"><img src="../Images/6e536918e53fd5225970761c71476f63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WUPTNPDhmSXBmsnBcS10lg.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">集群2</figcaption></figure><p id="bc8b" class="pw-post-body-paragraph kg kh hi ki b kj lo ij kl km lp im ko kp lq kr ks kt lr kv kw kx ls kz la lb hb bi translated">或者可能是收入和支出得分，如下图所示？</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lx"><img src="../Images/9cc721440377647609ca2ec2b92432bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dmQs9p539Ez6ZA73WdcESA.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">集群3</figcaption></figure><p id="0115" class="pw-post-body-paragraph kg kh hi ki b kj lo ij kl km lp im ko kp lq kr ks kt lr kv kw kx ls kz la lb hb bi translated">或者是3D空间中的某些东西，因为它需要数据集中的所有要素？</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ly"><img src="../Images/c1b1d86fd27be77e85e7f7cec76b41e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1326/format:webp/1*L3yybiwraeCWLj82OpisNg.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">3d散点图—年龄、收入、支出</figcaption></figure><p id="5d48" class="pw-post-body-paragraph kg kh hi ki b kj lo ij kl km lp im ko kp lq kr ks kt lr kv kw kx ls kz la lb hb bi translated">选择正确的分割方法的困境:</p><ol class=""><li id="4b21" class="lz ma hi ki b kj lo km lp kp mb kt mc kx md lb me mf mg mh bi translated">营销团队可能会选择集群3而不是集群1或集群2，因为它们似乎更容易分开。</li><li id="ef8b" class="lz ma hi ki b kj mi km mj kp mk kt ml kx mm lb me mf mg mh bi translated">这也取决于我们实际上想要有多少段？更多的细分市场意味着不同群体的更多内容创作。</li><li id="0ba7" class="lz ma hi ki b kj mi km mj kp mk kt ml kx mm lb me mf mg mh bi translated">片段太少会导致过度概括</li></ol><p id="c827" class="pw-post-body-paragraph kg kh hi ki b kj lo ij kl km lp im ko kp lq kr ks kt lr kv kw kx ls kz la lb hb bi translated">这只是4个客户属性。现实世界的问题会有成百上千的客户事件和购买数据。这个问题变得更加棘手。让我们了解如何使用<strong class="ki hj">机器学习算法</strong>来实现这一点。我们将研究3种常见方法(如下)并将结果与人类标记的聚类进行比较:</p><ol class=""><li id="dce3" class="lz ma hi ki b kj lo km lp kp mb kt mc kx md lb me mf mg mh bi translated"><strong class="ki hj"> K表示聚类</strong></li><li id="1a70" class="lz ma hi ki b kj mi km mj kp mk kt ml kx mm lb me mf mg mh bi translated"><strong class="ki hj">层次聚类</strong></li><li id="073f" class="lz ma hi ki b kj mi km mj kp mk kt ml kx mm lb me mf mg mh bi translated"><strong class="ki hj">数据库扫描聚类</strong></li></ol></div><div class="ab cl lc ld gp le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="hb hc hd he hf"><h1 id="2961" class="jo jp hi bd jq jr lj jt ju jv lk jx jy io ll ip ka ir lm is kc iu ln iv ke kf bi translated">1.k表示聚类</h1><blockquote class="mn mo mp"><p id="e0ff" class="kg kh mq ki b kj lo ij kl km lp im ko mr lq kr ks ms lr kv kw mt ls kz la lb hb bi translated"><em class="hi">机器如何学习最好是通过最小化一个</em> <a class="ae jn" href="https://en.wikipedia.org/wiki/Loss_function" rel="noopener ugc nofollow" target="_blank"> <strong class="ki hj"> <em class="hi">损失函数</em> </strong> </a> <strong class="ki hj"> <em class="hi">。</em> </strong> <em class="hi">在K的情况下意味着基本上是距离平方和的算法。这里有一个精彩的博客，简单地解释了k-means—</em><a class="ae jn" href="https://www.saedsayad.com/clustering_kmeans.htm" rel="noopener ugc nofollow" target="_blank"><em class="hi">https://www.saedsayad.com/clustering_kmeans.htm</em></a><em class="hi">。K均值的损失函数如下:- </em></p></blockquote><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mu"><img src="../Images/634d5b19049cd7de3d3d954f813f28f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oT0vOzNGJkD_JxDdUBJhhw.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">来源—<a class="ae jn" href="https://www.saedsayad.com/clustering_kmeans.htm" rel="noopener ugc nofollow" target="_blank">https://www.saedsayad.com/clustering_kmeans.htm</a></figcaption></figure><blockquote class="mn mo mp"><p id="fdda" class="kg kh mq ki b kj lo ij kl km lp im ko mr lq kr ks ms lr kv kw mt ls kz la lb hb bi translated"><em class="hi">上述损失函数基本上告诉“</em> <strong class="ki hj"> <em class="hi">”找出聚类质心(对于“k”个聚类)，使得在所有聚类</em> </strong> <em class="hi">”中，一个聚类中的聚类内距离最小化。这基本上是一个数学优化问题——最小化公式。簇形心基本上是簇中的一种中心点。一旦找到“k”个聚类质心，就可以将每个点分配给其最近的质心，并且具有相同质心的点将构成每个聚类。</em></p><p id="0280" class="kg kh mq ki b kj lo ij kl km lp im ko mr lq kr ks ms lr kv kw mt ls kz la lb hb bi translated"><em class="hi">解上面这个方程是一个</em> <a class="ae jn" href="https://en.wikipedia.org/wiki/NP-hardness" rel="noopener ugc nofollow" target="_blank"> <strong class="ki hj"> <em class="hi"> NP难</em> </strong> </a> <em class="hi">问题——这意味着它基本上是数学领域中一个很难解决的问题。于是，为了解决这个问题，我们将使用</em> <a class="ae jn" href="https://en.wikipedia.org/wiki/Approximation_algorithm" rel="noopener ugc nofollow" target="_blank"> <strong class="ki hj"> <em class="hi">近似算法</em> </strong> </a> <strong class="ki hj"> <em class="hi">。</em> </strong> <a class="ae jn" href="https://en.wikipedia.org/wiki/Lloyd%27s_algorithm" rel="noopener ugc nofollow" target="_blank"> <strong class="ki hj"> <em class="hi"> Lyod的算法</em> </strong> </a> <em class="hi">就是解决这个的一种方法。</em></p></blockquote><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mv"><img src="../Images/b8b768c273b62ac15c04595987ad0ee2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_rwgoIrBvzrP_0lS9PwjBg.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">来源—<a class="ae jn" href="https://www.saedsayad.com/clustering_kmeans.htm" rel="noopener ugc nofollow" target="_blank">https://www.saedsayad.com/clustering_kmeans.htm</a></figcaption></figure><blockquote class="mn mo mp"><p id="d4c3" class="kg kh mq ki b kj lo ij kl km lp im ko mr lq kr ks ms lr kv kw mt ls kz la lb hb bi translated"><strong class="ki hj"> <em class="hi">初始化敏感度</em> </strong> <em class="hi">是我们在k均值算法中面临的一个问题，这基本上意味着我们获得的最终聚类将取决于我们如何选择算法中的步骤2。(上)因此，需要我们使用不同的初始化来执行该算法的多次迭代，并检查哪种初始化最适合我们对集群的要求。处理这个问题的另一种方法是使用</em><a class="ae jn" href="https://en.wikipedia.org/wiki/K-means%2B%2B" rel="noopener ugc nofollow" target="_blank"><strong class="ki hj"><em class="hi">【k-means++</em></strong></a><strong class="ki hj"><em class="hi">。</em>为了减轻离群值的影响，这里使用了一种 <a class="ae jn" href="https://en.wikipedia.org/wiki/Randomized_algorithm" rel="noopener ugc nofollow" target="_blank"> <strong class="ki hj"> <em class="hi">概率算法</em> </strong> </a> <em class="hi">。</em></strong></p><p id="82ea" class="kg kh mq ki b kj lo ij kl km lp im ko mr lq kr ks ms lr kv kw mt ls kz la lb hb bi translated"><em class="hi">k-means的一些局限性包括:(参考—</em><a class="ae jn" href="https://www.appliedaicourse.com/" rel="noopener ugc nofollow" target="_blank"><strong class="ki hj"><em class="hi"/></strong></a><em class="hi">)</em></p><p id="b00b" class="kg kh mq ki b kj lo ij kl km lp im ko mr lq kr ks ms lr kv kw mt ls kz la lb hb bi translated"><strong class="ki hj"> <em class="hi"> 1。当它们更接近时，不同的簇大小</em> </strong> <em class="hi"/></p><p id="a673" class="kg kh mq ki b kj lo ij kl km lp im ko mr lq kr ks ms lr kv kw mt ls kz la lb hb bi translated"><strong class="ki hj">②<em class="hi">。不同的群集密度</em> </strong></p><p id="67a9" class="kg kh mq ki b kj lo ij kl km lp im ko mr lq kr ks ms lr kv kw mt ls kz la lb hb bi translated"><strong class="ki hj"> <em class="hi"> 3。</em>非凸形</strong></p><p id="b345" class="kg kh mq ki b kj lo ij kl km lp im ko mr lq kr ks ms lr kv kw mt ls kz la lb hb bi translated"><strong class="ki hj">T25】4。对异常值的非鲁棒性 </strong></p><p id="59e3" class="kg kh mq ki b kj lo ij kl km lp im ko mr lq kr ks ms lr kv kw mt ls kz la lb hb bi translated"><em class="hi">(上述问题可以通过使用更多的集群，然后对子集群进行分组的策略来解决)</em></p><p id="ba5b" class="kg kh mq ki b kj lo ij kl km lp im ko mr lq kr ks ms lr kv kw mt ls kz la lb hb bi translated"><em class="hi">k-means的另一个问题是聚类形心的可解释性。聚类的质心不一定是点中的数据，因为它是聚类数据点的平均值。在现实生活中，业务团队通常希望聚类中心是数据点之一，因此在这种情况下，我们可以使用</em><a class="ae jn" href="https://en.wikipedia.org/wiki/K-medoids" rel="noopener ugc nofollow" target="_blank"><strong class="ki hj"><em class="hi">k-medoids</em></strong></a><strong class="ki hj"><em class="hi"/></strong><em class="hi">。这里不使用质心，我们使用一种叫做medoid的东西(它是一个数据点)。在这种情况下，我们不是将平均值作为质心来计算，而是在数据点上迭代以选择最能降低损失函数(SSE)的medoid。这种方法通常用于使我们的模型更容易理解。</em></p></blockquote><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mw"><img src="../Images/5db951dd40824477d017226d9580ae18.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uzFjdsbbQSq5iW95lBkO4g.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">比较k-means (vs) k-medoids，source—<a class="ae jn" href="https://subscription.packtpub.com/book/big_data_and_business_intelligence/9781789956399/1/ch01lvl1sec08/introduction-to-k-medoids-clustering" rel="noopener ugc nofollow" target="_blank">https://subscription . packtpub . com/book/big _ data _ and _ business _ intelligence/9781789956399/1/ch 01 LV 1 sec 08/introduction-to-k-medoids-clustering</a></figcaption></figure><blockquote class="mn mo mp"><p id="f79b" class="kg kh mq ki b kj lo ij kl km lp im ko mr lq kr ks ms lr kv kw mt ls kz la lb hb bi translated"><em class="hi">如上图所示，K-medoids选择聚类质心作为数据点之一，而在k-means中，它不是数据点。最佳“k”值的选择一般使用损失函数的</em> <strong class="ki hj"> <em class="hi">肘法</em> </strong> <em class="hi">来完成。当我们应用于我们的例子时，我们将详细地看到这一点。</em></p><p id="db71" class="kg kh mq ki b kj lo ij kl km lp im ko mr lq kr ks ms lr kv kw mt ls kz la lb hb bi translated"><em class="hi">k-means的</em> <strong class="ki hj"> <em class="hi">时间复杂度</em> </strong> <em class="hi">为</em><strong class="ki hj"><em class="hi">O(nkdi)</em></strong><em class="hi">，分别为#pts、#clusters、#features、#iterations。这可以简化为</em><strong class="ki hj"><em class="hi">O(nd)</em></strong><em class="hi">在‘k’和‘I’较小的情况下。</em></p><p id="bd6d" class="kg kh mq ki b kj lo ij kl km lp im ko mr lq kr ks ms lr kv kw mt ls kz la lb hb bi translated"><em class="hi">k-means的</em> <strong class="ki hj"> <em class="hi">空间复杂度</em> </strong> <em class="hi">为</em><strong class="ki hj"><em class="hi">O(nd+KD)</em></strong><em class="hi">但可以近似为</em><strong class="ki hj"><em class="hi">O(nd)</em></strong><em class="hi">为小值。</em></p></blockquote><p id="4cac" class="pw-post-body-paragraph kg kh hi ki b kj lo ij kl km lp im ko kp lq kr ks kt lr kv kw kx ls kz la lb hb bi translated">让我们将python-sklearn中的k-means应用于我们的示例并检查结果。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mx"><img src="../Images/a75eb5442d81af563bb3955bc56207d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:906/format:webp/1*dSD0P9a3PaDOSn2FMqCZSg.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">kmeans python代码片段</figcaption></figure><p id="1b43" class="pw-post-body-paragraph kg kh hi ki b kj lo ij kl km lp im ko kp lq kr ks kt lr kv kw kx ls kz la lb hb bi translated">我们首先确保数字特征和标准化。然后，我们尝试从2到14的“k”值，并使用肘方法选择最佳“k ”(如下图所示)。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es my"><img src="../Images/74b09ed8097da30c02a5d2a2551e09dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RNI33ZRnRqW82Rkd_DZdSg.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">肘法，k = 4</figcaption></figure><p id="f391" class="pw-post-body-paragraph kg kh hi ki b kj lo ij kl km lp im ko kp lq kr ks kt lr kv kw kx ls kz la lb hb bi translated">基于肘形方法，我们观察到从k=4开始的肘形形成，我们可以选择它作为k均值中的最佳聚类数。我们也可以使用k=6，但我们会尽量避免这里的过度拟合。因为我们只有200个数据点。现在让我们想象这些集群。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mz"><img src="../Images/6012654cf1471cb31676dd7726ee437d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1310/format:webp/1*fUg4zD5ac3NhgaSGTfm5Ow.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">收入与支出— 4千均值聚类</figcaption></figure><p id="83f0" class="pw-post-body-paragraph kg kh hi ki b kj lo ij kl km lp im ko kp lq kr ks kt lr kv kw kx ls kz la lb hb bi translated">正如我们在上面看到的，除了绿色和红色集群，它们在这个空间中被很好地分开。让我们从另一个角度想象一下。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es na"><img src="../Images/3e6a48bb5857f5b5da0d023d4674036f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1340/format:webp/1*jzkbpGgSRZFuxpmCdCPJjg.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">年龄与支出— 4千均值聚类</figcaption></figure><p id="5b8a" class="pw-post-body-paragraph kg kh hi ki b kj lo ij kl km lp im ko kp lq kr ks kt lr kv kw kx ls kz la lb hb bi translated">啊，所以基本上红色集群是为高年龄组，而绿色集群是为低年龄组。让我们看看年龄、收入、支出特征的三维散点图</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nb"><img src="../Images/5c96e59a6af5db519dd2d97e4c15bd29.png" data-original-src="https://miro.medium.com/v2/resize:fit:1344/format:webp/1*gANNNaEs0ko78hzIrQgCGw.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">4个具有k均值的聚类</figcaption></figure></div><div class="ab cl lc ld gp le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="hb hc hd he hf"><h1 id="8f4c" class="jo jp hi bd jq jr lj jt ju jv lk jx jy io ll ip ka ir lm is kc iu ln iv ke kf bi translated">2.分层聚类</h1><blockquote class="mn mo mp"><p id="004f" class="kg kh mq ki b kj lo ij kl km lp im ko mr lq kr ks ms lr kv kw mt ls kz la lb hb bi translated">这种方法有两种类型——凝聚型和分裂型。然而，凝聚法是最广泛使用的方法。这基本上是以分层的方式对相似的点/簇进行分组。</p></blockquote><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nc"><img src="../Images/76cd18900cbfd9b19b7802f53390adbb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1078/format:webp/1*6Yoh_3rHb9_Q0SRXr64dbQ.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">来源——Pinterest</figcaption></figure><blockquote class="mn mo mp"><p id="b7fd" class="kg kh mq ki b kj lo ij kl km lp im ko mr lq kr ks ms lr kv kw mt ls kz la lb hb bi translated">从上图我们可以看出。它首先将所有点视为单独的聚类，然后在每次后续迭代中，将邻近点分组为聚类，并重复将点/聚类分组为聚类的过程，直到达到一个大的聚类。我们可以在下面的算法中看到这种方法— </p></blockquote><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nd"><img src="../Images/7e63ae21c52817a06b4c6e31405a6d7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1080/format:webp/1*Co7B3XIWPfgqnD0HFeIChQ.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">来源——research gate</figcaption></figure><blockquote class="mn mo mp"><p id="7b11" class="kg kh mq ki b kj lo ij kl km lp im ko mr lq kr ks ms lr kv kw mt ls kz la lb hb bi translated"><em class="hi">凝聚聚类的一个主要考虑是选择</em> <strong class="ki hj"> <em class="hi">邻近度度量</em> </strong> <em class="hi">。(即，我们如何定义聚类和/或点之间的聚类间距离)。让我们看看一些接近度指标— </em></p><p id="e594" class="kg kh mq ki b kj lo ij kl km lp im ko mr lq kr ks ms lr kv kw mt ls kz la lb hb bi translated"><strong class="ki hj"> <em class="hi"> 1。MIN — </em> </strong> <em class="hi">这基本上取2个聚类对之间最小的可能距离。这样做的主要优点是</em> <strong class="ki hj"> <em class="hi">也可以处理非凸形簇</em> </strong> <em class="hi">。然而，它对离群值</em>  <em class="hi">很敏感，因为它使用了簇之间的最小距离。</em></p><p id="0d1b" class="kg kh mq ki b kj lo ij kl km lp im ko mr lq kr ks ms lr kv kw mt ls kz la lb hb bi translated"><strong class="ki hj"> <em class="hi"> 2。最大值</em></strong><em class="hi">——类似于最小值，但取最大值而不是最小值。这种方法对聚类中的离群点</em> <strong class="ki hj"> <em class="hi">和噪声点</em> </strong> <em class="hi">更加鲁棒。然而，在集群大小不均匀的情况下，这可能会很糟糕。</em></p><p id="5842" class="kg kh mq ki b kj lo ij kl km lp im ko mr lq kr ks ms lr kv kw mt ls kz la lb hb bi translated"><strong class="ki hj"> <em class="hi"> 3。组平均值— </em> </strong> <em class="hi">取两个聚类对中所有点组合的平均值。您可以使用距离度量，如欧几里德、曼哈顿等。</em></p><p id="7ea6" class="kg kh mq ki b kj lo ij kl km lp im ko mr lq kr ks ms lr kv kw mt ls kz la lb hb bi translated"><strong class="ki hj"> <em class="hi"> 4。质心之间的距离</em> </strong></p><p id="dd00" class="kg kh mq ki b kj lo ij kl km lp im ko mr lq kr ks ms lr kv kw mt ls kz la lb hb bi translated">理想情况下，你可以重复上面的方法，看看哪种方法最适合你的需求。</p><p id="fc47" class="kg kh mq ki b kj lo ij kl km lp im ko mr lq kr ks ms lr kv kw mt ls kz la lb hb bi translated"><em class="hi">凝聚聚类的空间复杂度为</em><strong class="ki hj"><em class="hi">O(n)</em></strong><em class="hi">—“n”大时空间复杂度大。时间复杂度为</em><strong class="ki hj"><em class="hi">【O(n)</em></strong><em class="hi">。这些复杂性非常大。这是使用聚集聚类的主要缺点之一。</em></p><p id="ce94" class="kg kh mq ki b kj lo ij kl km lp im ko mr lq kr ks ms lr kv kw mt ls kz la lb hb bi translated"><em class="hi">让我们将凝聚聚类应用于我们的示例并进行检查，我们将取num clusters = 4，就像我们对kmeans所做的那样— </em></p></blockquote><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ne"><img src="../Images/3857d82c58cea821b9f7d4577b6890b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1236/format:webp/1*d2iRnhJ1nDhR6ADw5ryd1A.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">python代码片段-聚合</figcaption></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nf"><img src="../Images/48f283707916d64dfaabe9229d2d4393.png" data-original-src="https://miro.medium.com/v2/resize:fit:1162/format:webp/1*iXQ5Eh3_MIXdSRzjO9IaHA.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">聚集聚类——收入与支出</figcaption></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ng"><img src="../Images/de701322d7703d24434001e02b2f5b88.png" data-original-src="https://miro.medium.com/v2/resize:fit:1212/format:webp/1*NgcdSXy-BssssU1Q2ccFfg.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">聚集聚类，4个聚类—支出与年龄</figcaption></figure><p id="1463" class="pw-post-body-paragraph kg kh hi ki b kj lo ij kl km lp im ko kp lq kr ks kt lr kv kw kx ls kz la lb hb bi translated">正如我们所看到的，聚集聚类在这里也做得相当不错。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nh"><img src="../Images/369d467d30c03abec9c037edb4e84b03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1288/format:webp/1*jT1ijzgl8wvUH_sWq4e-Hg.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">凝聚聚类，4个聚类</figcaption></figure></div><div class="ab cl lc ld gp le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="hb hc hd he hf"><h1 id="eba1" class="jo jp hi bd jq jr lj jt ju jv lk jx jy io ll ip ka ir lm is kc iu ln iv ke kf bi translated">3.DBSCAN聚类</h1><blockquote class="mn mo mp"><p id="f1ca" class="kg kh mq ki b kj lo ij kl km lp im ko mr lq kr ks ms lr kv kw mt ls kz la lb hb bi translated"><a class="ae jn" href="https://en.wikipedia.org/wiki/DBSCAN" rel="noopener ugc nofollow" target="_blank"><strong class="ki hj">DBS can</strong></a><strong class="ki hj"/>代表<strong class="ki hj">基于密度的空间聚类的噪声应用。</strong>这基本上是如何进行聚类的:</p><p id="0a18" class="kg kh mq ki b kj lo ij kl km lp im ko mr lq kr ks ms lr kv kw mt ls kz la lb hb bi translated">将每个点分为三类——</p><p id="f0eb" class="kg kh mq ki b kj lo ij kl km lp im ko mr lq kr ks ms lr kv kw mt ls kz la lb hb bi translated"><strong class="ki hj">核心点(</strong>如果它包含围绕其外圈半径的最小点<strong class="ki hj"> ) </strong>，</p><p id="16e0" class="kg kh mq ki b kj lo ij kl km lp im ko mr lq kr ks ms lr kv kw mt ls kz la lb hb bi translated"><strong class="ki hj">边界点(</strong>不是核心点，但在epislon附近有核心点<strong class="ki hj"> ) </strong>，</p><p id="16af" class="kg kh mq ki b kj lo ij kl km lp im ko mr lq kr ks ms lr kv kw mt ls kz la lb hb bi translated"><strong class="ki hj">噪声点(</strong>所有非核心点和非边界点<strong class="ki hj"> ) </strong>。</p><p id="9083" class="kg kh mq ki b kj lo ij kl km lp im ko mr lq kr ks ms lr kv kw mt ls kz la lb hb bi translated">这个任务基于两个超参数——</p><p id="f176" class="kg kh mq ki b kj lo ij kl km lp im ko mr lq kr ks ms lr kv kw mt ls kz la lb hb bi translated"><strong class="ki hj">ε(</strong>围绕一个点的半径<strong class="ki hj"> ) — </strong>这是使用肘法通过绘制每个点到第x个最近邻点的距离来确定的，其中x =最小点。</p><p id="67d0" class="kg kh mq ki b kj lo ij kl km lp im ko mr lq kr ks ms lr kv kw mt ls kz la lb hb bi translated"><strong class="ki hj">最小点(</strong>核心点周围的最小点，以将其分类为核心点/密集区域<strong class="ki hj"> ) </strong>充当密度的代理指标——这可以使用经验法则选择为<strong class="ki hj"> 2*d </strong>，其中d =数据的维度</p></blockquote><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ni"><img src="../Images/0b4f863d81de258a452b4bdafe828c8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1214/format:webp/1*IxARBKz5Omd1kJers3gEuA.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">来源—维基百科—数据库扫描</figcaption></figure><blockquote class="mn mo mp"><p id="81e0" class="kg kh mq ki b kj lo ij kl km lp im ko mr lq kr ks ms lr kv kw mt ls kz la lb hb bi translated">然后，它移除噪声点，并迭代每个核心点，以将其分配给一个聚类，该聚类将包括与该核心点密集连接的所有点。对于边界点，该点将属于最近的核心点的聚类。算法步骤如下—</p></blockquote><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nj"><img src="../Images/a3d85733127350cff3f63c687f7852fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*khLA_B99Qm4IYLx5hcbsUA.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">来源—维基百科数据库扫描</figcaption></figure><blockquote class="mn mo mp"><p id="77f4" class="kg kh mq ki b kj lo ij kl km lp im ko mr lq kr ks ms lr kv kw mt ls kz la lb hb bi translated">DBSCAN的最大优点是其处理噪声的能力及其对异常值的鲁棒性，处理复杂形状的集群等。但是，如果数据在空间中包含可变密度，则失败。它在高维数据及其对超参数的敏感性方面也是失败的。</p><p id="081a" class="kg kh mq ki b kj lo ij kl km lp im ko mr lq kr ks ms lr kv kw mt ls kz la lb hb bi translated">DBSCAN的时间复杂度为O(nlogn)，空间复杂度为O(n)在d&lt;&lt; n. This looks a good complexity as compared to agglomerative clustering.</p></blockquote><p id="48c8" class="pw-post-body-paragraph kg kh hi ki b kj lo ij kl km lp im ko kp lq kr ks kt lr kv kw kx ls kz la lb hb bi translated">Let us apply DBSCAN to dataset and see, We will select min_points = 8 as a rule of thumb of 2*d where d = 4 (d = num of features).</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nk"><img src="../Images/b152984a9272af70419efc4024e526d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1378/format:webp/1*or9IhusPejuZrKFWXzpdVQ.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">python code — DBSCAN</figcaption></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nl"><img src="../Images/5f21efa8172a3125b89686b1dbd8e2fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1086/format:webp/1*oPsoihCupdc6p-ftomit7Q.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">selecting epislon = 0.7 using elbow method DBSCAN</figcaption></figure><p id="5c5b" class="pw-post-body-paragraph kg kh hi ki b kj lo ij kl km lp im ko kp lq kr ks kt lr kv kw kx ls kz la lb hb bi translated">DBSCAN gives 6 clusters — which is slightly overfitting for our case here. Let us see a visualization.</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nm"><img src="../Images/fd5af8399ed7b4e689eab6049f7d81e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1192/format:webp/1*izNLY_Av4u6rss0h_VwZjg.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">DBSCAN , clusters = 6</figcaption></figure></div><div class="ab cl lc ld gp le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="hb hc hd he hf"><h1 id="d93c" class="jo jp hi bd jq jr lj jt ju jv lk jx jy io ll ip ka ir lm is kc iu ln iv ke kf bi translated">Comparison of Results and Conclusions</h1><h2 id="42cc" class="nn jp hi bd jq no np nq ju nr ns nt jy kp nu nv ka kt nw nx kc kx ny nz ke oa bi translated">1 — Comparing K Means clustered Labels with Human Labels</h2><p id="55bb" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko kp kq kr ks kt ku kv kw kx ky kz la lb hb bi translated">As we can see below graphs, Algorithm chooses 4 clusters but kmeans cluster creates some overlap in income vs spend which human doesn’t. But if you look from the feature space of spend vs age — this seperation seems to be justified. This kmeans clustering has advantage that it can look at multi dimensional data and take the best call how to cluster which might be difficult for a human.</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ob"><img src="../Images/9c0d67ef28d66477b022b2f077711513.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8NRkQcqr6a3PgCZj5l9Tbg.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">Human Labelled clusters = Income vs spend</figcaption></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es oc"><img src="../Images/78199b222e72252cc3ac4ccfefa7362c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1394/format:webp/1*LvRqj0ZOzTJvSJ4sChBLvQ.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">Kmeans cluster, 4 clusters</figcaption></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es od"><img src="../Images/b07cf6a2bbf3f3aa590e80c0a95bb1ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1364/format:webp/1*PCfTSba32y8nc6BziFeX1Q.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">kmeans cluster, 4 clusters</figcaption></figure><h2 id="4fbe" class="nn jp hi bd jq no np nq ju nr ns nt jy kp nu nv ka kt nw nx kc kx ny nz ke oa bi translated">2 — Other Metrics for Selecting best number of clusters — Dunn’s Index, Shiloutte Score</h2><p id="5db7" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko kp kq kr ks kt ku kv kw kx ky kz la lb hb bi translated">You can also use <a class="ae jn" href="https://en.wikipedia.org/wiki/Dunn_index" rel="noopener ugc nofollow" target="_blank"><strong class="ki hj"><em class="mq">Dunn Index</em></strong></a>作为度量来确定你的簇的情况下。这是一个比率指标。如果邓恩指数很高，这意味着你的聚类很好，这是因为簇间距离很高，这是我们想要的，而且簇的直径很低，这意味着SSE很低。</p><p id="7e42" class="pw-post-body-paragraph kg kh hi ki b kj lo ij kl km lp im ko kp lq kr ks kt lr kv kw kx ls kz la lb hb bi translated">邓恩指数=(最小(聚类间距离))/(最大(聚类内距离))</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es oe"><img src="../Images/582afbeda6411521e5717ae931cf2068.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EeWn56jRMrlPo6MGzIq5Aw.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">来源——分析</figcaption></figure><p id="bb7e" class="pw-post-body-paragraph kg kh hi ki b kj lo ij kl km lp im ko kp lq kr ks kt lr kv kw kx ls kz la lb hb bi translated">您可以使用的另一个指标称为<a class="ae jn" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html" rel="noopener ugc nofollow" target="_blank"> <strong class="ki hj"> <em class="mq"> Shiloutte得分</em> </strong> </a>。更多详情请参考sklearn链接。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es of"><img src="../Images/645a7c930530a3a3c0f2769879c41f41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LQ1Mzi0cVxcrCfaKLQbFKQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">来源— <code class="du og oh oi oj b"><a class="ae jn" href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics" rel="noopener ugc nofollow" target="_blank">sklearn.metrics</a></code>。剪影_配乐</figcaption></figure><h2 id="0073" class="nn jp hi bd jq no np nq ju nr ns nt jy kp nu nv ka kt nw nx kc kx ny nz ke oa bi translated">3—其他结论</h2><ol class=""><li id="f00d" class="lz ma hi ki b kj kk km kn kp ok kt ol kx om lb me mf mg mh bi translated">层次聚类给出了与Kmeans非常相似的结果。这里，我们使用了<strong class="ki hj">‘ward’</strong>链接作为邻近性度量。然而，我们也可以尝试“最小”、“最大”、“组平均”等。比较你的结果。凝聚聚类的唯一缺点是，与k-means相比，运行时间会更多，而且与使用elbow方法的k-means相比，使用“num clusters”的选择会非常直观。</li><li id="8be3" class="lz ma hi ki b kj mi km mj kp mk kt ml kx mm lb me mf mg mh bi translated">在我们的例子中，通过选择最佳聚类= 6，DBSCAN稍微有些过拟合，但是正如我们在上面看到的，这对于超参数的微小变化非常敏感。您可以试验不同的epislon、min点超参数，看看在这种情况下什么效果最好。</li><li id="29c4" class="lz ma hi ki b kj mi km mj kp mk kt ml kx mm lb me mf mg mh bi translated">聚类没有对错之分。与分类/回归任务不同，在分类/回归任务中，您可以度量模型的性能。这里的挑战在于根据业务需求决定什么是最佳的集群策略。</li><li id="00d3" class="lz ma hi ki b kj mi km mj kp mk kt ml kx mm lb me mf mg mh bi translated">尝试Dunn Index、Shiloutte评分指标，并根据您的业务需求决定您的正确指标。</li></ol></div></div>    
</body>
</html>