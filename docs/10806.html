<html>
<head>
<title>DataPipeline using Apache Beam and Google Cloud DataFlow as Runner and BigQuery as DataSink</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">DataPipeline使用Apache Beam和Google Cloud DataFlow作为Runner，使用BigQuery作为DataSink</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/datapiepeline-using-apache-beam-and-google-cloud-dataflow-as-runner-and-bigquery-as-datasink-a6dcfadc8428?source=collection_archive---------8-----------------------#2020-11-03">https://medium.com/analytics-vidhya/datapiepeline-using-apache-beam-and-google-cloud-dataflow-as-runner-and-bigquery-as-datasink-a6dcfadc8428?source=collection_archive---------8-----------------------#2020-11-03</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/6f48f66bd5d4b71c0f04053af66a2334.png" data-original-src="https://miro.medium.com/v2/resize:fit:1090/format:webp/1*aDqZPVxAhpgtibU014Acbg.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated"><a class="ae iq" href="https://www.hadoopinrealworld.com/batch-processing-with-google-cloud-dataflow-and-apache-beam/" rel="noopener ugc nofollow" target="_blank">https://www . Hadoop inrealworld . com/batch-processing-with-Google-cloud-data flow-and-Apache-beam/</a></figcaption></figure><p id="952a" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">在本文中，我们将探讨使用谷歌云平台(GCP)服务创建数据管道。我一直在通过Coursera专攻<a class="ae iq" href="https://www.coursera.org/account/accomplishments/specialization/certificate/YM5K5UWD8474" rel="noopener ugc nofollow" target="_blank">数据工程、大数据和机器学习进行学习，GCP </a>想自己创造一些课程之外的东西。幸运的是，我得到了一个很好的用例，最近我正在进行AWS s3日志分析。我已经用我在GCP控制台的免费账户完成了这一切。此外，有一个演练视频添加在最后，执行所有的行动对GCP！！！</p><p id="c062" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated"><strong class="it hj">用例是这样的:</strong></p><p id="3cc5" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">下载日志→上传日志到Google存储→触发数据流</p><p id="6fe2" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated"><strong class="it hj">数据流作业的职责:</strong></p><p id="fe5e" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">读取日志文件→解析日志文件→写入BigQuery</p><p id="400f" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated"><strong class="it hj">为了什么？</strong></p><p id="14b3" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">BigQuery用于生成S3日志所需的报告。</p></div><div class="ab cl jp jq gp jr" role="separator"><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju"/></div><div class="hb hc hd he hf"><p id="d217" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">我将提供所有的链接，我已经经历了，而创建这个管道。要理解这其中的每个概念可以通过这些链接:<a class="ae iq" href="https://www.youtube.com/watch?v=KalJ0VuEM7s" rel="noopener ugc nofollow" target="_blank"> DataFlow </a>、<a class="ae iq" href="https://beam.apache.org/documentation/sdks/python/" rel="noopener ugc nofollow" target="_blank"> Apache Beam Python </a>和<a class="ae iq" href="https://cloud.google.com/bigquery/?utm_source=google&amp;utm_medium=cpc&amp;utm_campaign=japac-IN-all-en-dr-bkws-all-super-trial-e-dr-1009137&amp;utm_content=text-ad-none-none-DEV_c-CRE_315806004867-ADGP_Hybrid%20%7C%20AW%20SEM%20%7C%20BKWS%20~%20T1%20%7C%20EXA%20%7C%20Big%20Data%20%7C%201%3A1%20%7C%20IN%20%7C%20en%20%7C%20bigquery-KWID_43700028131581118-kwd-297617549231&amp;userloc_1007880-network_g&amp;utm_term=KW_bigquery&amp;ds_rl=1264446&amp;gclid=CjwKCAiA-f78BRBbEiwATKRRBDt_Kkf6JeH1BGG6KW4wSwbJ6inIYEycBQo6XTirx4DdiInlBZ6cABoCngIQAvD_BwE" rel="noopener ugc nofollow" target="_blank"> BigQuery </a>。</p></div><div class="ab cl jp jq gp jr" role="separator"><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju"/></div><div class="hb hc hd he hf"><p id="f3c8" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated"><strong class="it hj">创建完整管道的步骤:</strong></p><ol class=""><li id="8fa5" class="jw jx hi it b iu iv iy iz jc jy jg jz jk ka jo kb kc kd ke bi translated">在你喜欢的地方创建一个谷歌云存储。</li><li id="159c" class="jw jx hi it b iu kf iy kg jc kh jg ki jk kj jo kb kc kd ke bi translated">在同一项目中创建一个BigQuery数据集</li><li id="208e" class="jw jx hi it b iu kf iy kg jc kh jg ki jk kj jo kb kc kd ke bi translated">创建服务帐户并提供所有者角色</li><li id="438e" class="jw jx hi it b iu kf iy kg jc kh jg ki jk kj jo kb kc kd ke bi translated">使用Apache Beam创建管道</li><li id="1014" class="jw jx hi it b iu kf iy kg jc kh jg ki jk kj jo kb kc kd ke bi translated">使用BigQuery和DataStudio分析日志</li></ol></div><div class="ab cl jp jq gp jr" role="separator"><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju"/></div><div class="hb hc hd he hf"><p id="7ff2" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated"><strong class="it hj">谷歌云存储:</strong></p><p id="32c8" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">在所选项目的任何所需区域中创建一个存储桶，并记录该区域已被选中。</p><p id="5559" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated"><strong class="it hj">创建一个大查询数据集:</strong></p><p id="418f" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">在BigQuery UI中，在同一项目下创建一个数据集。</p><p id="49cc" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated"><strong class="it hj">创建服务帐户:</strong></p><p id="01fa" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">创建一个服务帐户，以便从本地计算机与GCP服务进行通信。</p><p id="c1f8" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated"><strong class="it hj">使用Apache Beam创建管道:</strong></p><p id="eb98" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">这在开始时可能有点耗时。这里我们需要用Java或Python语言使用ApacheBeam开源库创建一个管道。这是我用Python为上述用例设计的管道。</p><pre class="kk kl km kn fd ko kp kq kr aw ks bi"><span id="1cc0" class="kt ku hi kp b fi kv kw l kx ky">obj = AwsLogParser()<br/>quotes = ( <br/>        p           <br/>        | 'Read' &gt;&gt; ReadFromText(known_args.input)<br/>        | 'Parse Log' &gt;&gt; beam.Map(lambda line: obj.parse(line))<br/>)</span><span id="9e61" class="kt ku hi kp b fi kz kw l kx ky">quotes | beam.io.gcp.bigquery.WriteToBigQuery(<br/>    obj.table_spec,<br/>    obj.schema,<br/>    write_disposition=beam.io.BigQueryDisposition.WRITE_APPEND,<br/>    create_disposition=beam.io.BigQueryDisposition.CREATE_IF_NEEDED<br/>)</span></pre><p id="3b1d" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">该管道包含三个步骤，从日志中读取每一行，然后将其传递给解析步骤。这里的解析主要是解析s3日志行，并创建一个与BigQuery表模式的列名相匹配的字典。最后一步是将解析后的数据填充到BigQuery表中。这里需要注意的一点是:当我们在本地机器上运行任何管道时，将所有数据指定为本地路径的输入和本地路径的输出。同样，当使用数据流运行器运行管道时，需要指定Google存储文件路径。我犯了一个错误，通过指定输入的本地路径在云上运行管道。这里的问题是，管道将成功执行，但是由于没有数据，表不会在BigQuery中创建。</p><p id="4c93" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated"><strong class="it hj">和上面运行的命令:</strong></p><pre class="kk kl km kn fd ko kp kq kr aw ks bi"><span id="36f4" class="kt ku hi kp b fi kv kw l kx ky">export GOOGLE_APPLICATION_CREDENTIALS="/path/to/your/json_file.json"</span><span id="02d7" class="kt ku hi kp b fi kz kw l kx ky">export PROJECT=your_project_id<br/>export BUCKET=your_bucket_id<br/>export REGION=your_region</span><span id="e4ac" class="kt ku hi kp b fi kz kw l kx ky">python main.py  \<br/> --region $REGION   \<br/> --runner DataflowRunner  \<br/> --project $PROJECT  \<br/> --temp_location gs://$BUCKET/tmp/ \<br/> --input gs://$BUCKET/aws_logs/2020*</span></pre><p id="f191" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">运行后，我们可以在GCP的Web用户界面上看到状态。这需要时间，需要一点耐心。</p><p id="dd69" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated"><strong class="it hj">使用BigQuery和DataStudio分析日志:</strong></p><p id="45a6" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">BigQuery是Google维护的数据仓库。它提供了一个简单的丰富的MySql类型的语法方法来分析Pb级的数据。</p><p id="148c" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">在我们的例子中，我们解析s3日志并将所有信息存储在表中。这里为了简单起见，我们将只查询200个请求和以HTML结尾的关键字。</p><pre class="kk kl km kn fd ko kp kq kr aw ks bi"><span id="9c4e" class="kt ku hi kp b fi kv kw l kx ky">SELECT<br/>  key,<br/>  request_uri,<br/>  http_status,<br/>  date<br/>FROM<br/>  `justlikethat-294122.s3_logs.access_report`<br/>WHERE<br/>  http_status='200' and ends_with(key, 'html')<br/>LIMIT<br/>  1000</span></pre><p id="61d9" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">然后，我们将使用Google DataStudio通过一个饼图来实现上述查询的结果。</p><figure class="kk kl km kn fd ij er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es la"><img src="../Images/bfb1cbfee0c38e701f7686f2e97913d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*08_IQiuattZY5oJjZNxopA.png"/></div></div></figure><p id="7b40" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">同样，可以获得任何类型的图表。</p><p id="ad57" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated"><strong class="it hj">接下来呢？</strong></p><p id="7e71" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">一旦使用Google Datastudio提供的模板或您自己创建的模板创建了报告，就可以通过使用iframe将报告嵌入到相应的网站中，轻松地将其集成到您的网站中。这不包括在这里。</p></div><div class="ab cl jp jq gp jr" role="separator"><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju"/></div><div class="hb hc hd he hf"><p id="25d8" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated"><strong class="it hj">链接:</strong></p><pre class="kk kl km kn fd ko kp kq kr aw ks bi"><span id="54fe" class="kt ku hi kp b fi kv kw l kx ky"><a class="ae iq" rel="noopener" href="/swlh/apache-beam-google-cloud-dataflow-and-creating-custom-templates-using-python-c666c151b4bc">https://medium.com/swlh/apache-beam-google-cloud-dataflow-and-creating-custom-templates-using-python-c666c151b4bc</a></span><span id="ab7e" class="kt ku hi kp b fi kz kw l kx ky"><a class="ae iq" href="https://github.com/ankitakundra/GoogleCloudDataflow/blob/master/dataingestion.py" rel="noopener ugc nofollow" target="_blank">https://github.com/ankitakundra/GoogleCloudDataflow/blob/master/dataingestion.py</a></span><span id="252e" class="kt ku hi kp b fi kz kw l kx ky"><a class="ae iq" href="https://stackoverflow.com/questions/55694541/error-unable-to-parse-file-when-i-run-a-custom-template-on-dataflow" rel="noopener ugc nofollow" target="_blank">https://stackoverflow.com/questions/55694541/error-unable-to-parse-file-when-i-run-a-custom-template-on-dataflow</a></span><span id="e9a5" class="kt ku hi kp b fi kz kw l kx ky"><a class="ae iq" href="https://cloud.google.com/dataflow/docs/quickstarts/quickstart-python" rel="noopener ugc nofollow" target="_blank">https://cloud.google.com/dataflow/docs/quickstarts/quickstart-python</a></span><span id="b39f" class="kt ku hi kp b fi kz kw l kx ky"><a class="ae iq" href="https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/wordcount.py" rel="noopener ugc nofollow" target="_blank">https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/wordcount.py</a></span><span id="d45b" class="kt ku hi kp b fi kz kw l kx ky"><a class="ae iq" href="https://beam.apache.org/documentation/io/built-in/google-bigquery/" rel="noopener ugc nofollow" target="_blank">https://beam.apache.org/documentation/io/built-in/google-bigquery/</a></span></pre></div><div class="ab cl jp jq gp jr" role="separator"><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju"/></div><div class="hb hc hd he hf"><p id="3a68" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated"><strong class="it hj">演练:</strong></p><figure class="kk kl km kn fd ij"><div class="bz dy l di"><div class="lf lg l"/></div></figure><p id="b552" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated"><strong class="it hj">尾注:</strong></p><p id="2e85" class="pw-post-body-paragraph ir is hi it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hb bi translated">做这个完整的流程是一次很好的经历。感觉我做了件很酷的事。我确实有在本地处理多个服务器的经验，但这是一种完全在云中进行的不同体验，代码可在此处获得<a class="ae iq" href="https://github.com/shravanc/apache_beam_learning/blob/main/apache_beam/aws_log_analysis_through_dataflow/main.py" rel="noopener ugc nofollow" target="_blank"/>。就是这个！！！感谢阅读干杯！！！享受编码！！！</p></div></div>    
</body>
</html>