<html>
<head>
<title>Fake News Detection Using TFIDFVectorizer and PassiveAggressive Classifier</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于tfidf向量机和被动主动分类器的假新闻检测</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/fake-news-detector-cbc47b085d4?source=collection_archive---------4-----------------------#2020-07-11">https://medium.com/analytics-vidhya/fake-news-detector-cbc47b085d4?source=collection_archive---------4-----------------------#2020-07-11</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/c80a757641cd1307f36d44607055058f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FQlxTH57xWnM716UNmK6og.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">图片来自<a class="ae iu" href="https://www.vpnsrus.com/" rel="noopener ugc nofollow" target="_blank">www.vpnsrus.com</a></figcaption></figure><p id="5fb7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我认为可以肯定的是，我们所有人都遇到过在我们的社交媒体论坛上流传的新闻文章，这些文章看起来好得令人难以置信。通常情况下，我们会看到同一个话题的相互矛盾的事实，并想知道哪一个是正确的。我们让自己陷入困境，无法确定该相信哪个来源。嗯，不再是了。使用Python和机器学习可以使这项任务变得更容易。我们可以使用分类器算法来训练一个模型，该模型可以预测一篇“新闻”文章是事实还是虚假的。</p><p id="d66a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">此外，查看我的其他帖子，了解更多机器学习算法的应用。一定要检查，然后通过评论分享你的见解，并与你的朋友分享，看看他们对此有何看法。您也可以按照我的文章创建这样的模型，并根据您的兴趣进行调整。</p></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><h1 id="5932" class="ka kb hi bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">什么是假新闻？</h1><p id="94e3" class="pw-post-body-paragraph iv iw hi ix b iy ky ja jb jc kz je jf jg la ji jj jk lb jm jn jo lc jq jr js hb bi translated">作为黄色新闻的一种，假新闻包含可能是恶作剧的新闻片段，通常通过社交媒体和其他在线媒体传播。这样做通常是为了推进或强加某些想法，并经常通过政治议程来实现。此类新闻可能包含虚假和/或夸大的声明，并可能最终被算法病毒式传播，用户可能最终陷入过滤器泡沫。</p><h1 id="7b95" class="ka kb hi bd kc kd ld kf kg kh le kj kk kl lf kn ko kp lg kr ks kt lh kv kw kx bi translated">关于项目</h1><p id="9335" class="pw-post-body-paragraph iv iw hi ix b iy ky ja jb jc kz je jf jg la ji jj jk lb jm jn jo lc jq jr js hb bi translated">这是我在学习数据科学和机器学习概念的同时从事的一个项目。这里的目标是识别一篇“新闻”文章是假的还是真实的。我们将采用一个带有标签的公共信息数据集，并使用频率矢量器应用分类技术。我们可以稍后在未分类的公共消息上测试该模型的准确性和性能。类似的技术可以应用于其他NLP应用，如情感分析等。</p><h1 id="4575" class="ka kb hi bd kc kd ld kf kg kh le kj kk kl lf kn ko kp lg kr ks kt lh kv kw kx bi translated">数据</h1><p id="7d77" class="pw-post-body-paragraph iv iw hi ix b iy ky ja jb jc kz je jf jg la ji jj jk lb jm jn jo lc jq jr js hb bi translated">我正在使用来自kaggle.com<a class="ae iu" href="https://www.kaggle.com/c/fake-news/data" rel="noopener ugc nofollow" target="_blank">的数据集，它包含以下特征:</a></p><ul class=""><li id="9702" class="li lj hi ix b iy iz jc jd jg lk jk ll jo lm js ln lo lp lq bi translated">id:新闻文章的唯一id</li><li id="a9a4" class="li lj hi ix b iy lr jc ls jg lt jk lu jo lv js ln lo lp lq bi translated">标题:新闻文章的标题</li><li id="8a39" class="li lj hi ix b iy lr jc ls jg lt jk lu jo lv js ln lo lp lq bi translated">作者:新闻文章的作者</li><li id="49b0" class="li lj hi ix b iy lr jc ls jg lt jk lu jo lv js ln lo lp lq bi translated">正文:文章的正文；可能不完整</li><li id="0911" class="li lj hi ix b iy lr jc ls jg lt jk lu jo lv js ln lo lp lq bi translated">标签:将文章标记为潜在不可靠的标签<br/> 1:不可靠<br/> 0:可靠</li></ul><h1 id="bbd0" class="ka kb hi bd kc kd ld kf kg kh le kj kk kl lf kn ko kp lg kr ks kt lh kv kw kx bi translated">模型</h1><p id="6d6a" class="pw-post-body-paragraph iv iw hi ix b iy ky ja jb jc kz je jf jg la ji jj jk lb jm jn jo lc jq jr js hb bi translated">我们使用TfIdf矢量器将文本字符串转换为数字表示，并初始化一个被动渐进分类器来适应模型。最后，准确度分数和混淆矩阵告诉我们模型的效果如何。</p><figure class="lx ly lz ma fd ij er es paragraph-image"><div class="er es lw"><img src="../Images/d7ece6467ccc2f369d989ff4245ce2d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1130/format:webp/1*zw1a4xt2pXd_j_7Oc-HpjA.jpeg"/></div></figure><h2 id="dc32" class="mb kb hi bd kc mc md me kg mf mg mh kk jg mi mj ko jk mk ml ks jo mm mn kw mo bi translated">词频(Tf) —逆文档频率(Idf)矢量器</h2><p id="9c38" class="pw-post-body-paragraph iv iw hi ix b iy ky ja jb jc kz je jf jg la ji jj jk lb jm jn jo lc jq jr js hb bi translated">Tf-Idf矢量器是将文本转换成有意义的数字表示的常用算法。它用于根据出现次数从文本字符串中提取特征。</p><p id="705e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们假设一个单词重复的次数越多，在给定的文本中就意味着越重要。我们用文档的大小来标准化单词的出现，因此称之为词频。数值定义:<code class="du mp mq mr ms b">tf(w) = doc.count(w) / total words in the doc</code></p><p id="1632" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在计算术语频率时，每个术语被赋予相等的权重。可能有在文档中出现频率很高的单词，因此对推导文档含义的贡献较小。例如“a”、“the”等这样的词。可能会压制更有意义的单词的权重。为了减少这种影响，Tf用一个称为逆文档频率的因子来贴现。<code class="du mp mq mr ms b">idf(w) = log(total_number_of_documents / number_of-documents_containing_word_w)</code></p><p id="6bfc" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">然后通过Tf和Idf的乘积计算Tf-Idf。更重要的单词将获得更高的tf-idf分数。<code class="du mp mq mr ms b">tf-idf(w) = tf(w) * idf(w)</code></p><h2 id="9410" class="mb kb hi bd kc mc md me kg mf mg mh kk jg mi mj ko jk mk ml ks jo mm mn kw mo bi translated"><a class="ae iu" href="http://jmlr.csail.mit.edu/papers/volume7/crammer06a/crammer06a.pdf" rel="noopener ugc nofollow" target="_blank">被动攻击性量词</a></h2><p id="4303" class="pw-post-body-paragraph iv iw hi ix b iy ky ja jb jc kz je jf jg la ji jj jk lb jm jn jo lc jq jr js hb bi translated">被动攻击算法是一类用于大规模学习的算法。直观上，被动表示如果分类正确，我们应该保留模型，而主动表示如果分类不正确，更新模型以适应更多错误分类的示例。不像大多数其他的，它不收敛，而是更新以纠正损失。</p><h1 id="43a1" class="ka kb hi bd kc kd ld kf kg kh le kj kk kl lf kn ko kp lg kr ks kt lh kv kw kx bi translated">开发ML模型</h1><p id="20ce" class="pw-post-body-paragraph iv iw hi ix b iy ky ja jb jc kz je jf jg la ji jj jk lb jm jn jo lc jq jr js hb bi translated"><strong class="ix hj">第一步:</strong>导入必要的包:</p><pre class="lx ly lz ma fd mt ms mu mv aw mw bi"><span id="e94f" class="mb kb hi ms b fi mx my l mz na"><strong class="ms hj">import</strong> <strong class="ms hj">numpy</strong> <strong class="ms hj">as</strong> <strong class="ms hj">np</strong><br/><strong class="ms hj">import</strong> <strong class="ms hj">pandas</strong> <strong class="ms hj">as</strong> <strong class="ms hj">pd</strong><br/><strong class="ms hj">import</strong> <strong class="ms hj">itertools</strong><br/><strong class="ms hj">import</strong> <strong class="ms hj">seaborn</strong> <strong class="ms hj">as</strong> <strong class="ms hj">sn</strong><br/><strong class="ms hj">import</strong> <strong class="ms hj">pandas</strong> <strong class="ms hj">as</strong> <strong class="ms hj">pd</strong><br/><strong class="ms hj">import</strong> <strong class="ms hj">matplotlib.pyplot</strong> <strong class="ms hj">as</strong> <strong class="ms hj">plt</strong><br/><strong class="ms hj">from</strong> <strong class="ms hj">sklearn.model_selection</strong> <strong class="ms hj">import</strong> train_test_split<br/><strong class="ms hj">from</strong> <strong class="ms hj">sklearn.feature_extraction.text</strong> <strong class="ms hj">import</strong> TfidfVectorizer<br/><strong class="ms hj">from</strong> <strong class="ms hj">sklearn.linear_model</strong> <strong class="ms hj">import</strong> PassiveAggressiveClassifier<br/><strong class="ms hj">from</strong> <strong class="ms hj">sklearn.metrics</strong> <strong class="ms hj">import</strong> accuracy_score, confusion_matrix, classification_report</span></pre><p id="a25a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">步骤2: </strong>将数据集加载到pandas数据框中:</p><pre class="lx ly lz ma fd mt ms mu mv aw mw bi"><span id="1656" class="mb kb hi ms b fi mx my l mz na">train = pd.read_csv('train.csv')<br/>test = pd.read_csv('test.csv')<br/>test = test.set_index('id', drop = <strong class="ms hj">True</strong>)</span></pre><p id="de7f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">第三步:</strong>阅读理解资料。创建任何ML模型最重要的步骤之一是首先准备数据。这包括清理和过滤数据，去除异常值，创建独立和合理的特征(我将在处理另一个模型时详细讨论)。</p><p id="f8e8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们使用。shape方法来标识数据集中的列数和新闻样本总数。然后使用读取数据表。方法来查看数据的外观。接下来，确定写新闻文章的栏名和标有分类的栏名。</p><p id="f28a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">然后我们使用。isna确定我们的新闻文章所在的列中是否有空值，在这种情况下，它位于名为“text”的列中。现在我们使用。sum()来标识存在多少这样的值。一旦识别出来，我们就删除列“text”有空值的行，并用空值填充其他列中的空白。</p><pre class="lx ly lz ma fd mt ms mu mv aw mw bi"><span id="963f" class="mb kb hi ms b fi mx my l mz na"><em class="nb"># Counting number of rows and columns in the data</em><br/>print('Shape of Training Data: ', train.shape)<br/><br/><em class="nb"># Gettiing a hang of the data in each column and their names</em><br/>print('<strong class="ms hj">\n</strong> <strong class="ms hj">\n</strong> TRAIN <strong class="ms hj">\n</strong>', train.head())<br/>print('<strong class="ms hj">\n</strong> <strong class="ms hj">\n</strong> TEST <strong class="ms hj">\n</strong>', test.head())<br/><br/><em class="nb"># Looking for any places where training data has NaN values</em><br/>print('<strong class="ms hj">\n</strong> <strong class="ms hj">\n</strong>Number of Null values in Train Set: ', train['text'].isna().sum())<br/>print('Number of Null values in Test Set: ', test['text'].isna().sum())<br/><br/><em class="nb"># Dropping all rows where text column is NaN</em><br/>train.dropna(axis=0, how="any", thresh=<strong class="ms hj">None</strong>, subset=['text'], inplace=<strong class="ms hj">True</strong>)<br/>test = test.fillna(' ')</span></pre><p id="cc4f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">输出如下所示:</p><figure class="lx ly lz ma fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nc"><img src="../Images/3a0b3b58bcf5f2cbc04623f996b41ba5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4sdGiJx8XMLPSj9Ulemjnw.png"/></div></div></figure><p id="3159" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">步骤4: </strong>现在让我们看看数据中是否有异常值。我们将通过检查每篇文章中的字数并确定所有文章中字数的范围和平均值来做到这一点。我们将使用len()函数来检查长度。</p><pre class="lx ly lz ma fd mt ms mu mv aw mw bi"><span id="699a" class="mb kb hi ms b fi mx my l mz na"># Checking length of each article<br/>length = []<br/>[length.append(len(str(text))) for text in train['text']]<br/>train['length'] = length</span><span id="9973" class="mb kb hi ms b fi nd my l mz na">print('Minimum Length: ', min(train['length']), '\nMaximum Length: ', max(train['length']), '\nAverage Length: ', round(sum(train['length'])/len(train['length'])))</span></pre><p id="58e9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">输出:</p><pre class="lx ly lz ma fd mt ms mu mv aw mw bi"><span id="d4fc" class="mb kb hi ms b fi mx my l mz na">Minimum Length:  1 <br/>Maximum Length:  142961 <br/>Average Length:  4553</span></pre><p id="b48d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们注意到有些文章也只有一个单词。现在让我们设定一篇新闻文章需要的最少字数，我推断为50个。</p><p id="0092" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们现在来看看有多少文章少于50个单词，这些文章是什么样子的。</p><pre class="lx ly lz ma fd mt ms mu mv aw mw bi"><span id="6043" class="mb kb hi ms b fi mx my l mz na"># Minimum length is 1. We need to spot some outliers and get rid of them. Counting how many outliers are there<br/>print('Number of articles with less than 50 words: ', len(train[train['length'] &lt; 50]))</span><span id="317d" class="mb kb hi ms b fi nd my l mz na"># Skimming through such short texts just to be sure<br/>print(train['text'][train['length'] &lt; 50])</span></pre><p id="b840" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">输出:</p><pre class="lx ly lz ma fd mt ms mu mv aw mw bi"><span id="c1c8" class="mb kb hi ms b fi mx my l mz na">Number of articles with less than 50 words:  207<br/>82                                                   <br/>169                                                  <br/>173                                   Guest   Guest  <br/>196            They got the heater turned up on high.<br/>295                                                  <br/>                             ...                     <br/>20350                         I hope nobody got hurt!<br/>20418                                 Guest   Guest  <br/>20431    \nOctober 28, 2016 The Mothers by stclair by<br/>20513                                                <br/>20636                              Trump all the way!<br/>Name: text, Length: 207, dtype: object</span></pre><p id="1210" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们注意到一些文章只是空白，而其他许多文章是随意的陈述，总共有惊人的207篇这样的文章。想象一下，这会给我们的模型对数据的理解增加多少噪音。现在让我们从数据集中删除这些文章，并重新打印文章长度统计数据。</p><pre class="lx ly lz ma fd mt ms mu mv aw mw bi"><span id="a54b" class="mb kb hi ms b fi mx my l mz na"># Removing outliers, it will reduce overfitting<br/>train = train.drop(train['text'][train['length'] &lt; 50].index, axis = 0)</span><span id="b094" class="mb kb hi ms b fi nd my l mz na">print('Minimum Length: ', min(train['length']), '\nMaximum Length: ', max(train['length']), '\nAverage Length: ', round(sum(train['length'])/len(train['length'])))</span></pre><p id="f22e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">输出:</p><pre class="lx ly lz ma fd mt ms mu mv aw mw bi"><span id="c769" class="mb kb hi ms b fi mx my l mz na">Minimum Length:  50 <br/>Maximum Length:  142961 <br/>Average Length:  4598</span></pre><p id="f852" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">步骤5: </strong>在我们开始应用模型之前，最后一步是将分类列与其余的输入特征分离，然后将数据集划分为训练和测试子集。我们这样做是为了确保我们的模型在新的数据集上表现良好。我们将90%的数据作为训练集，10%作为测试集。这个分割百分比可以定制，以便更好地调整模型。</p><pre class="lx ly lz ma fd mt ms mu mv aw mw bi"><span id="d0af" class="mb kb hi ms b fi mx my l mz na"># Secluding labels in a new pandas dataframe for supervised learning<br/>train_labels = train['label']</span><span id="0d1c" class="mb kb hi ms b fi nd my l mz na"># Splitting data into training and testing sets<br/>x_train, x_test, y_train, y_test = train_test_split(train['text'], train_labels, test_size=0.1, random_state=0)</span></pre><p id="ec28" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">步骤6: </strong>让我们用来自英语的停用词和0.7的最大文档频率初始化一个<a class="ae iu" href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html" rel="noopener ugc nofollow" target="_blank"> TfIdfVectorizer </a>(具有更高文档频率的术语将被丢弃)。停用词是在处理自然语言数据之前要过滤掉的语言中最常见的词。tfidf矢量器将原始文档的集合转化为Tf-Idf特征的矩阵。</p><p id="4b11" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，在训练集上拟合和转换矢量器，在测试集上转换矢量器。</p><pre class="lx ly lz ma fd mt ms mu mv aw mw bi"><span id="7d7e" class="mb kb hi ms b fi mx my l mz na"># Setting up Term Frequency - Inverse Document Frequency Vectorizer<br/>tfidf = TfidfVectorizer(stop_words = 'english', max_df = 0.7)</span><span id="3b8d" class="mb kb hi ms b fi nd my l mz na"># Fit and transform training set and transform test set<br/>tfidf_train = tfidf.fit_transform(x_train) <br/>tfidf_test = tfidf.transform(x_test)<br/>tfidf_test_final = tfidf.transform(test['text'])</span></pre><p id="ef7b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">接下来，我们将初始化一个<a class="ae iu" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.PassiveAggressiveClassifier.html" rel="noopener ugc nofollow" target="_blank">PassiveAggressiveClassifier</a>。我们将在tfidf_train和y_train上安装这个。</p><p id="fc55" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">然后，我们将对来自TfidfVectorizer的测试集进行预测，并使用来自sklearn.metrics 的<a class="ae iu" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html?highlight=accuracy_score#sklearn.metrics.accuracy_score" rel="noopener ugc nofollow" target="_blank"> accuracy_score()计算准确度。</a></p><pre class="lx ly lz ma fd mt ms mu mv aw mw bi"><span id="9555" class="mb kb hi ms b fi mx my l mz na"># Setting up Passive Aggressive Classifier<br/>pac = PassiveAggressiveClassifier(max_iter = 50)</span><span id="0e2c" class="mb kb hi ms b fi nd my l mz na"># Fitting on the training set<br/>pac.fit(tfidf_train, y_train)</span><span id="c8b0" class="mb kb hi ms b fi nd my l mz na"># Predicting on the test set<br/>y_pred = pac.predict(tfidf_test)<br/>score = accuracy_score(y_test, y_pred)<br/>print(f'Accuracy: {round(score * 100, 2)}%')</span></pre><p id="5687" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">输出:</p><pre class="lx ly lz ma fd mt ms mu mv aw mw bi"><span id="2bd5" class="mb kb hi ms b fi mx my l mz na">Accuracy: 97.08%</span></pre><p id="2212" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们用这个模型得到了97%的准确率。我们现在可以使用sklearn库打印出<a class="ae iu" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html?highlight=classification_report#sklearn.metrics.classification_report" rel="noopener ugc nofollow" target="_blank">分类_报告()</a>和<a class="ae iu" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html?highlight=confusion_matrix#sklearn.metrics.confusion_matrix" rel="noopener ugc nofollow" target="_blank">混淆_矩阵()</a>。</p><pre class="lx ly lz ma fd mt ms mu mv aw mw bi"><span id="1aa6" class="mb kb hi ms b fi mx my l mz na"># Creating confusion matrix with columns as True Positive, False Negative, False Positive and True Negative <br/>cm = confusion_matrix(y_test, y_pred, labels=[0, 1])<br/>df_cm = pd.DataFrame(cm, range(2), range(2))<br/>sn.set(font_scale=1)<br/>sn.heatmap(df_cm, annot=True, annot_kws={'size':14}, fmt='d').set_title('Confusion Matrix')<br/>plt.show()</span><span id="0aa3" class="mb kb hi ms b fi nd my l mz na"># Creating classification report<br/>print('\nClassification Report: \n', classification_report(y_test, (y_pred &gt; 0.5)))</span></pre><p id="9829" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">输出:</p><figure class="lx ly lz ma fd ij er es paragraph-image"><div class="er es ne"><img src="../Images/f5b9e5dee4881a688e76eb7068fe590e.png" data-original-src="https://miro.medium.com/v2/resize:fit:826/format:webp/1*PhswKJ1ElfLOJHq3jM-PJg.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">假新闻检测结果</figcaption></figure><h1 id="c7c3" class="ka kb hi bd kc kd ld kf kg kh le kj kk kl lf kn ko kp lg kr ks kt lh kv kw kx bi translated">结果:</h1><p id="f311" class="pw-post-body-paragraph iv iw hi ix b iy ky ja jb jc kz je jf jg la ji jj jk lb jm jn jo lc jq jr js hb bi translated">我们成功实现了一个机器学习和自然语言处理模型来检测一篇文章是假的还是事实。我们有1034篇文章被正确识别为假的，962篇被正确识别为真的。当进行这样的分类时，检查我们是否限制了假阳性的数量是很重要的，因为它们会导致事实被标记为假。</p><h2 id="a75e" class="mb kb hi bd kc mc md me kg mf mg mh kk jg mi mj ko jk mk ml ks jo mm mn kw mo bi translated">未来工作:</h2><p id="6805" class="pw-post-body-paragraph iv iw hi ix b iy ky ja jb jc kz je jf jg la ji jj jk lb jm jn jo lc jq jr js hb bi translated">我打算通过添加一个图形用户界面(GUI)来扩展这个项目，用户可以粘贴任何文本片段，并在结果中获得其分类。如果你有一些建议给我，请写信给我！</p></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><h2 id="ab9b" class="mb kb hi bd kc mc md me kg mf mg mh kk jg mi mj ko jk mk ml ks jo mm mn kw mo bi translated">参考</h2><p id="0594" class="pw-post-body-paragraph iv iw hi ix b iy ky ja jb jc kz je jf jg la ji jj jk lb jm jn jo lc jq jr js hb bi translated">你可以在<a class="ae iu" href="https://github.com/rpalri/Fake_News_ML" rel="noopener ugc nofollow" target="_blank"> Github </a>上找到我的代码。</p><p id="a05b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如果你喜欢我的作品，请通过分享和关注我的故事来表达你的欣赏。当我不断学习新的东西时，这会让我有动力与你们分享！</p><p id="e72b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如果你不喜欢我的作品，请分享你的想法和建议。这将有助于我下次为您改进和开发更好的阅读材料！</p><p id="d25a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">谢谢你。</p></div></div>    
</body>
</html>