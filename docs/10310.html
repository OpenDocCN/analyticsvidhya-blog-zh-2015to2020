<html>
<head>
<title>A Friendly Introduction to Cross-Entropy for Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习交叉熵的友好介绍</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/a-friendly-introduction-to-cross-entropy-for-machine-learning-b4e9f2b1f6?source=collection_archive---------6-----------------------#2020-10-13">https://medium.com/analytics-vidhya/a-friendly-introduction-to-cross-entropy-for-machine-learning-b4e9f2b1f6?source=collection_archive---------6-----------------------#2020-10-13</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/9885dcb1c757219cb8d972006753c2d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HVIA0jhuNyFOoJmlZQUpFg.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd iu">什么是机器学习的交叉熵？</strong></figcaption></figure><p id="43ad" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> <em class="jt"> 1。机器学习:- </em> </strong></p><ul class=""><li id="2579" class="ju jv hi ix b iy iz jc jd jg jw jk jx jo jy js jz ka kb kc bi translated"><em class="jt">近年来，工业界和学术界开展了一项与机器学习相关的特殊搜索研究(acedeme ),并展示了其在大规模应用中的潜在稳定性，如数据探索、预测和模式识别与分析、模式计算以及从收集的数据中预测结果。</em></li><li id="2a62" class="ju jv hi ix b iy kd jc ke jg kf jk kg jo kh js jz ka kb kc bi translated"><em class="jt">在这一研究领域，资源在主动学习任务中非常重要，有助于加深理解并提供不同形式的数据。</em></li><li id="a9e2" class="ju jv hi ix b iy kd jc ke jg kf jk kg jo kh js jz ka kb kc bi translated"><em class="jt">在小规模数据集中，对于精确的脚注和解释，专家知识在某种程度上是可接受的。</em></li><li id="455e" class="ju jv hi ix b iy kd jc ke jg kf jk kg jo kh js jz ka kb kc bi translated"><em class="jt">在大规模数据集中，数据分析成为一项复杂的任务，准确性和精确预测对于非结构化或未标记的数据至关重要。这种技术通过利用从大数据中学到的后验知识来解决问题。</em></li><li id="1489" class="ju jv hi ix b iy kd jc ke jg kf jk kg jo kh js jz ka kb kc bi translated"><em class="jt">随着数据集数量的不断增加，他们的分析往往会更好地概括，但注释在金钱和时间方面成本更高，添加更多，不同的数学和</em> <a class="ae ki" href="https://www.nature.com/subjects/statistical-methods" rel="noopener ugc nofollow" target="_blank"> <em class="jt">统计方法</em> </a> <em class="jt">被高度部署用于成功的注释</em>。<strong class="ix hj"> <em class="jt">同样的工具是交叉熵。</em>T25】</strong></li></ul><figure class="kk kl km kn fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kj"><img src="../Images/358aa7474f57e03aa9a9910018c9c99e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ylHEFp10J8CpF3Cs0stg2g.png"/></div></div></figure><p id="72e3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，让我们学习交叉熵，它的扩展(<strong class="ix hj"> <em class="jt">损失函数和KL散度</em> </strong>)以及它们在机器学习方面的部分。</p><p id="7878" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"><em class="jt"/></strong><em class="jt">-</em><strong class="ix hj"><em class="jt">熵在机器学习中常用作损失函数</em> </strong> <em class="jt">。</em></p><p id="dd51" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">理解交叉熵的概念</strong></p><p id="5f2a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为了理解交叉熵的概念，让我们从熵的定义开始:-</p><figure class="kk kl km kn fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ko"><img src="../Images/35883535896596358b48606a98dae9a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Taz8JK4UY7PigSlyNJ1lMQ.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd iu">什么是熵？</strong></figcaption></figure><p id="c647" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">熵简介</strong></p><p id="d1e5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们生活在一个渴望提前知道结果的世界里。我们想知道明天是否会下雨，我们想知道我们最喜欢的运动队是否会赢得下一场比赛。知道我们是否需要那把伞，或者知道我们的队会赢。当然，这不太可能。有太多的数据，通常使得得出一个结论对一般人来说几乎是不可能的。但是如果我们可以的话，我们可以戏剧性地改变我们生活的进程。</p><p id="8786" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">一般定义</strong> :- <em class="jt">熵是随机性的一种度量。与无穷大的概念非常相似，熵用于帮助建模和表示随机变量的不确定程度。</em></p><p id="c72c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">数学上，</strong> <em class="jt">用概率分布来定义熵。</em></p><figure class="kk kl km kn fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ko"><img src="../Images/3570308f6aca792452a8e341a47935c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KkwxleEPm8BKOq1ajH_oNg.png"/></div></div></figure><p id="5909" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">现在，回到交叉熵</strong>，</p><p id="9db7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="jt">交叉熵是对给定随机变量或事件集的两个概率分布之间的差异的度量。在监督机器学习中，一个概率分布显示训练样本的标签“true ”,正确的回答以值百分百表示。</em></p><figure class="kk kl km kn fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ko"><img src="../Images/a76b07f152b6efdcbeabcf30c60a5cb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GQSSMjxeM9hFhRe07gnGnA.png"/></div></div></figure><p id="c6d3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="jt">交叉熵由等式</em>表示；</p><figure class="kk kl km kn fd ij er es paragraph-image"><div class="er es kp"><img src="../Images/df9c0c4f6225210c6e22e024019c74a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:954/format:webp/1*q4fijHwbwGUo77Iqx6T2mA.jpeg"/></div></figure><p id="d325" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="jt">这里，</em></p><ul class=""><li id="cb9e" class="ju jv hi ix b iy iz jc jd jg jw jk jx jo jy js jz ka kb kc bi translated"><em class="jt"> x代表机器算法</em>的(预测结果)</li><li id="ba76" class="ju jv hi ix b iy kd jc ke jg kf jk kg jo kh js jz ka kb kc bi translated"><em class="jt"> p(x)是来自训练样本的“真”标签的概率分布</em></li><li id="8915" class="ju jv hi ix b iy kd jc ke jg kf jk kg jo kh js jz ka kb kc bi translated"><em class="jt"> q(x)描绘了最大似然算法的估计。</em></li></ul><p id="0aa8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">交叉熵建立在数据熵的概念上，寻找将一个事件从一个分布转换到另一个分布所需的各种比特。</p><p id="c859" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="jt">交叉熵用真实的概率分布来检验模型的预测。当预测变得更准确时，它下降，当预测趋于完美时，它变为零。</em></p><p id="da17" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">注意:- <em class="jt">交叉熵</em> </strong> <em class="jt">对于分类问题来说绝对是一个很好的损失函数，因为它最小化了两个概率分布——预测的和实际的——之间的距离。</em></p><p id="7f3c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">相对熵简介:- </strong></p><ul class=""><li id="da66" class="ju jv hi ix b iy iz jc jd jg jw jk jx jo jy js jz ka kb kc bi translated"><em class="jt">相对熵是两个分布之间“距离”的度量。</em></li><li id="0a5a" class="ju jv hi ix b iy kd jc ke jg kf jk kg jo kh js jz ka kb kc bi translated"><em class="jt">在统计学中，相对熵</em><strong class="ix hj"><em class="jt">D(p | | q)</em></strong><em class="jt">是假设分布为q，而真实分布为p时的低效率的度量</em></li><li id="0e46" class="ju jv hi ix b iy kd jc ke jg kf jk kg jo kh js jz ka kb kc bi translated"><em class="jt">既然不是对称的，</em> <strong class="ix hj"> <em class="jt">即D(p | | q)=/= D(q | | p)</em></strong><em class="jt">，并且不满足三角形不等式。这种情况下的三角形不等式会有</em><strong class="ix hj"><em class="jt">【D(p | | q)】&lt;= D(p | | u)+D(u | | q)</em></strong><em class="jt">这在一般情况下并不成立。</em></li><li id="8f22" class="ju jv hi ix b iy kd jc ke jg kf jk kg jo kh js jz ka kb kc bi translated"><em class="jt">关于相对熵的一个重要性质是它的非负性，即</em><strong class="ix hj"><em class="jt">D(p | | q)&gt;= 0</em></strong><em class="jt">。</em></li></ul><p id="4b75" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="jt">浏览下面的解释:- </em></p><figure class="kk kl km kn fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kq"><img src="../Images/b970e96cd0d7b9f1e7204c51583a43e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AyJId3kYS3cVRe8jI7nsvQ.jpeg"/></div></div></figure><p id="b555" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在上述等式中，等式(2)至等式(3)由詹森不等式得出。</p><p id="826e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">作为损失函数的交叉函数</strong></p><ul class=""><li id="bdf6" class="ju jv hi ix b iy iz jc jd jg jw jk jx jo jy js jz ka kb kc bi translated"><em class="jt">俗称</em> <strong class="ix hj"> <em class="jt">原木损耗</em> </strong> <em class="jt">或</em> <strong class="ix hj"> <em class="jt">物流损耗</em> </strong> <em class="jt">。</em></li><li id="dd57" class="ju jv hi ix b iy kd jc ke jg kf jk kg jo kh js jz ka kb kc bi translated"><em class="jt">将每个预测类别概率与实际类别期望输出0或1进行比较，并计算得分/损失，该得分/损失基于与实际期望值的距离来惩罚该概率。</em></li><li id="88e7" class="ju jv hi ix b iy kd jc ke jg kf jk kg jo kh js jz ka kb kc bi translated"><em class="jt">在训练过程中调整模型时使用交叉熵损失。目的是减少损失，也就是说，损失越小，模型越好。</em></li><li id="08af" class="ju jv hi ix b iy kd jc ke jg kf jk kg jo kh js jz ka kb kc bi translated"><em class="jt">完美的模型交叉熵损失为0。</em></li></ul><figure class="kk kl km kn fd ij er es paragraph-image"><div class="er es kr"><img src="../Images/71c66cece7a504c15892dd8e5046460b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1112/format:webp/1*RAz6_RxY1wEZam9nB0g2NQ.png"/></div></figure><ul class=""><li id="442a" class="ju jv hi ix b iy iz jc jd jg jw jk jx jo jy js jz ka kb kc bi translated"><em class="jt">交叉熵在优化分类模型时用作损失函数，例如</em> <a class="ae ki" href="https://www.analyticssteps.com/blogs/7-types-regression-technique-you-should-know-machine-learning" rel="noopener ugc nofollow" target="_blank"> <em class="jt">物流回归</em> </a> <em class="jt">或</em> <a class="ae ki" href="https://www.analyticsvidhya.com/blog/2014/10/ann-work-simplified/" rel="noopener ugc nofollow" target="_blank"> <em class="jt"> ANN算法</em> </a> <em class="jt">用于分类目的和任务。</em></li></ul><figure class="kk kl km kn fd ij er es paragraph-image"><div class="er es ks"><img src="../Images/8fdc7ea99da0598012bbe54fd60ced64.png" data-original-src="https://miro.medium.com/v2/resize:fit:924/format:webp/1*lxV_trk6D5mLkbiq21qe9w.png"/></div></figure><p id="c2f7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">结论</strong></p><p id="784d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这个博客涵盖了所有重要的概念</p><ul class=""><li id="003a" class="ju jv hi ix b iy iz jc jd jg jw jk jx jo jy js jz ka kb kc bi translated"><strong class="ix hj">熵</strong></li><li id="f1ec" class="ju jv hi ix b iy kd jc ke jg kf jk kg jo kh js jz ka kb kc bi translated"><strong class="ix hj">交叉熵及其扩展(<em class="jt">在损失函数和KL散度方面)</em> </strong></li><li id="7c96" class="ju jv hi ix b iy kd jc ke jg kf jk kg jo kh js jz ka kb kc bi translated"><strong class="ix hj">机器学习的交叉熵</strong></li><li id="3a88" class="ju jv hi ix b iy kd jc ke jg kf jk kg jo kh js jz ka kb kc bi translated">您还学习了机器学习的交叉熵，以及如何在优化分类模型时将交叉熵用作损失函数，这与KL散度不同。</li></ul><p id="8574" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我希望它让你对这些常用术语及其在更好地理解机器学习术语和神经网络中的用途/作用有了有意义和清晰的理解。</p><p id="8744" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> <em class="jt">谢谢大家:-) </em> </strong></p></div></div>    
</body>
</html>