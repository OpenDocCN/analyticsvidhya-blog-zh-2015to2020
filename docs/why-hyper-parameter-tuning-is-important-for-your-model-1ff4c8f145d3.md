# 为什么超参数调整对您的模型很重要？

> 原文：<https://medium.com/analytics-vidhya/why-hyper-parameter-tuning-is-important-for-your-model-1ff4c8f145d3?source=collection_archive---------4----------------------->

![](img/99c65e69b99d6e66d48dbe9d38985186.png)

一个模型很少能在第一时间达到生产所需的水平。为了给你的业务问题找到正确的解决方案，通常你必须经历一个[迭代周期](/analytics-vidhya/machine-learning-why-it-is-an-iterative-process-bf709e3b69f2)。有多个部分组合在一起解决预期的机器学习难题。您可能需要训练和评估包括不同数据设置和算法的多个模型，执行几次特征工程，甚至扩充更多数据。这个循环还包括调整你的模型的**超参数**。

超参数是在运行训练作业之前可以调整的旋钮或设置，用于控制 ML 算法的行为。它们对模型训练有很大的影响，因为它涉及训练时间、基础设施资源要求(以及由此产生的成本)、模型收敛和模型准确性。

***模型参数是作为训练过程的一部分学习的，而超参数的值是在运行训练作业之前设置的，在训练过程中不会改变。***

# 不同类型的超参数

超参数可以大致分为 3 类—

*   **模型超参数—** 为 ex 定义模型本身的基本构造。神经网络架构的属性，如过滤器大小、池化、步幅、填充。
*   **优化器超参数—** 与模型如何基于数据学习模式有关。这些类型的超参数包括优化器，如梯度下降和随机梯度下降(SGD)、Adam、RMSprop、Adadelta 等。更多详情请点击 [Keras 优化页面](https://keras.io/api/optimizers/)。
*   **数据超参数—** 与数据的属性相关，通常在您没有足够的数据或数据变化量时使用。在这种情况下，数据扩充技术，如裁剪、调整大小、二值化等..都参与其中。

# 超参数是如何选取的？

> 每个学习者都是独一无二的。

这种人类的品质也体现在机器学习过程中。对于超参数选择，没有一套已定义的规则。通常，超参数选择和调整是手动完成的。其中一种方法是向有领域经验的人寻求帮助，他们可以指导选择不同的超参数和合适的值。之后，进行模型训练，并对照验证数据进行检查。

通常情况下，这两种方法通常被采用—

*   **网格搜索** —建立一个由超参数及其不同值组成的网格。对于每个可能的组合，训练一个模型，并根据验证数据产生一个分数。通过这种方法，尝试了给定的可能超参数值的每一个组合。虽然该方法对所有可能的组合进行了广泛的扫描，但是在训练时间和成本方面效率非常低。

![](img/cbdf999af39122ad63682023325b148c.png)

*   **随机搜索** —类似于网格搜索，但不是对每个可能的超参数组合进行训练和评分，而是选择随机组合。您可以根据时间和资源限制来设置搜索迭代次数。

这两种方法仍然是原始的，需要反复试验的方法，直到获得满意的结果。由于手动方法的费力性质，近来优选使用可从各种云服务提供商(例如 AWS、Google 和 Microsoft)获得的自动化超参数调整解决方案。

这些自动调整解决方案使用梯度下降、贝叶斯优化、探索-开发权衡等方法来引导搜索最佳超参数设置。为了前任。Amazon SageMaker 或 Google AutoML 自动模型调优通过使用您指定的算法和超参数范围在数据集上运行许多训练作业来查找模型的最佳版本。然后，它会选择超参数值，这些值会产生一个对所需指标表现最佳的模型。

# 公共超参数

每个算法都通过各种超参数进行学习。然而，当涉及到机器学习时，以下是最常见的。

*   **学习速率(LR)** —确定每次迭代(时期)的步长，同时向损失函数的最小值移动。由于这一过程影响着模型能够在多大程度上摆脱旧信息并获取新信息，因此它象征性地代表了机器学习模型“学习”的速度。通常，模型学习从某个随机点开始(作为初始化的结果),并在许多时期采样不同的权重。它还表示这些样本之间的距离是学习率。实现正确的学习率至关重要，因为**较大的学习率意味着模型可能超过最优解，而较小的学习率将增加寻找最优解的训练时间。Keras 等框架提供了在训练过程中自动调整学习率的方法。这是通过学习率衰减函数实现的，它允许优化器在一段时间内改变学习率。**

![](img/0d6205d549e0909dbe272be256635d05.png)

*   **批量大小** —该值表示每个时期内使用的训练样本的数量。对于较小的批量，观察到很容易摆脱“T2”局部最小值。然而，较大的批量可能会陷入错误的解决方案。

![](img/6fcef8988761baa38ad1be480d7dca74.png)

超参数调整(优化)是机器学习过程的一个重要方面。超参数的良好选择确实可以使模型成功地满足期望的度量值，或者相反，它可以导致无休止的持续训练和优化循环。

这篇文章所写的内容是个人学习和经验的集合。要分享任何反馈或意见，请使用 Medium platform 上的鼓掌/回应功能。你也可以通过 [Linkedin](http://www.linkedin.com/in/niwrattikasture) 联系我。