<html>
<head>
<title>Big data Clustering: MR-DBSCAN from scratch using Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">大数据集群:使用 Python 从头开始 MR-DBSCAN</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/big-data-clustering-mr-dbscan-from-scratch-using-python-f5a89c6d33b3?source=collection_archive---------1-----------------------#2020-10-28">https://medium.com/analytics-vidhya/big-data-clustering-mr-dbscan-from-scratch-using-python-f5a89c6d33b3?source=collection_archive---------1-----------------------#2020-10-28</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="3fee" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">基于密度、形状和大小等基本标准的聚类非常常见。类似地，DBSCAN 是基于密度的聚类算法的扩展方法。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/204c6f3b674b622d5ba9d9a2c37b1901.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*lqDkOF21LJ1D_h-c.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">参考:<a class="ae jt" href="https://www.mdpi.com/2076-3417/9/20/4398/htm" rel="noopener ugc nofollow" target="_blank">https://www.mdpi.com/2076-3417/9/20/4398/htm</a></figcaption></figure><p id="2a41" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于 MapReduce，查看这篇文章(<a class="ae jt" rel="noopener" href="/@rrfd/your-first-map-reduce-using-hadoop-with-python-and-osx-ca3b6f3dfe78">https://medium . com/@ rrfd/your-first-map-reduce-using-Hadoop-with-python-and-OSX-ca 3b 6 F3 dfe 78</a>)</p><p id="ca16" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">算法描述:</p><ol class=""><li id="8347" class="ju jv hi ih b ii ij im in iq jw iu jx iy jy jc jz ka kb kc bi translated">选择一个随机点 p。</li><li id="f51c" class="ju jv hi ih b ii kd im ke iq kf iu kg iy kh jc jz ka kb kc bi translated">获取从 p 到 eps 和 minPts 密度可达的所有点。</li><li id="4556" class="ju jv hi ih b ii kd im ke iq kf iu kg iy kh jc jz ka kb kc bi translated">如果 p 是一个核心点，则形成一个簇。</li><li id="7a75" class="ju jv hi ih b ii kd im ke iq kf iu kg iy kh jc jz ka kb kc bi translated">访问数据集的下一个点，如果 p 是边界点，并且没有一个点是从 p 密度可达的。</li><li id="8ef2" class="ju jv hi ih b ii kd im ke iq kf iu kg iy kh jc jz ka kb kc bi translated">重复上述过程，直到检查完所有的点。</li></ol><p id="2d97" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="ki">这里我没有使用现有的 DBSCAN 库，而是创建了一个函数。</em></p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es kj"><img src="../Images/b4c26c437b32a73524cb55f2d7e134db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0iq_8FsvZ-P4wCg-aF43UQ.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">参考算法:<a class="ae jt" href="https://en.wikipedia.org/wiki/DBSCAN" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/DBSCAN</a></figcaption></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es kk"><img src="../Images/062c0d39966cffa526f96614f5fcf850.png" data-original-src="https://miro.medium.com/v2/resize:fit:290/format:webp/1*C3C291Mj539RojUAzzICJQ.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">步伐</figcaption></figure><h1 id="2a2f" class="kl km hi bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">聚类中的搜索点</h1><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lj"><img src="../Images/0f81b768f9f7ab3cd18f72dbb7c23cb0.png" data-original-src="https://miro.medium.com/v2/resize:fit:576/format:webp/1*cL7YcMuwceN3vFbXh01jrQ.png"/></div></figure><h1 id="8b54" class="kl km hi bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">平均类内距离(a)</h1><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lk"><img src="../Images/d84771c726cc0d1b0d35fdd1d48a71d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cIwdekbZcsh8nvUpZxF5lQ.png"/></div></div></figure><h1 id="ae29" class="kl km hi bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">每个样本计算的平均最近聚类距离(b)</h1><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ll"><img src="../Images/7fa8c2dd4d4cb226ed264dfe029a26d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HchRm05M2r_EHH1GfJV9Wg.png"/></div></div></figure><p id="f48e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里我用的是剪影评分进行验证，更多细节可以找到(<a class="ae jt" href="https://en.wikipedia.org/wiki/Silhouette_(clustering)" rel="noopener ugc nofollow" target="_blank">https://en . Wikipedia . org/wiki/Silhouette _(clustering)</a></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lm"><img src="../Images/c45eaa1961043b55a6783d2afb8e5d6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:958/format:webp/1*wQQ8PfCQcdTVfdkuzZ9p6A.png"/></div></figure><p id="46ac" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">绘图功能:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ln"><img src="../Images/2efda14ebf9a7dbf071fdd176ea85b85.png" data-original-src="https://miro.medium.com/v2/resize:fit:1398/format:webp/1*Od6PhtqH_ZRHgwGAqiZDfA.png"/></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lo"><img src="../Images/107f06835b05fd0691d68572ffa994c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1350/format:webp/1*KpKnafoL4rc2KiqRJDjg1g.png"/></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lp"><img src="../Images/34b7a06499a309a7b2543934defb58d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hgrLrijJIVTCh6z9PYq2ww.png"/></div></div></figure><p id="fab1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">但是对于十亿行来说，同样的功能需要几个小时。由于大数据集，这是当今的主要挑战。</p><p id="fcde" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">大数据存储</strong></p><ul class=""><li id="ecdc" class="ju jv hi ih b ii ij im in iq jw iu jx iy jy jc lq ka kb kc bi translated">直接连接存储(DAS)</li><li id="e963" class="ju jv hi ih b ii kd im ke iq kf iu kg iy kh jc lq ka kb kc bi translated">网络存储</li></ul><p id="fd53" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> MapReduce </strong></p><p id="2b03" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">它是在大型数据集中实现分布式和并行算法的框架。</p><p id="2dc6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">工作:</p><ol class=""><li id="58f6" class="ju jv hi ih b ii ij im in iq jw iu jx iy jy jc jz ka kb kc bi translated">将输入数据分成块，这些块将进入并行映射阶段。</li><li id="0822" class="ju jv hi ih b ii kd im ke iq kf iu kg iy kh jc jz ka kb kc bi translated">然后排序操作</li><li id="d578" class="ju jv hi ih b ii kd im ke iq kf iu kg iy kh jc jz ka kb kc bi translated">减少是最终目标</li></ol><p id="7f30" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">数据块→排序→归约</p><p id="5b1b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">它旨在避免计算机节点故障问题(容错)</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lr"><img src="../Images/a5c2134b435873c2049ca71b59f2b1e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1156/format:webp/1*CLhPUTX1iq76LG5Fm-jT1w.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">参考:<a class="ae jt" href="https://journalofbigdata.springeropen.com/articles/10.1186/s40537-019-0236-x" rel="noopener ugc nofollow" target="_blank">https://journalofbigdata . springer open . com/articles/10.1186/s 40537-019-0236-x</a></figcaption></figure><p id="f6e0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">本文提供了一种使用 300GB 数据进行聚类的新方法。</p><p id="8580" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">他们的方法包括以下步骤:<strong class="ih hj">第一层</strong></p><ol class=""><li id="2116" class="ju jv hi ih b ii ij im in iq jw iu jx iy jy jc jz ka kb kc bi translated">Map-reduce(提高可扩展性)这里 M-R 把大数据分成小块，发送到 Hadoop 平台。</li><li id="a042" class="ju jv hi ih b ii kd im ke iq kf iu kg iy kh jc jz ka kb kc bi translated">具有减少的边界点的分区(用于分割数据的算法)这种分区算法对以均等方式分布在节点之间的数据进行分区，并且在分区中最小化边界点的数量。</li><li id="35df" class="ju jv hi ih b ii kd im ke iq kf iu kg iy kh jc jz ka kb kc bi translated">初始化每个维度的切片→计算每个连续切片的累积点→选择最佳切片进行分割</li></ol><p id="0107" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">第二层</strong></p><p id="e820" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">群集过程在每个节点上独立执行。每个映射器将数据作为(键，值)读取，其中键=空，值=分区</p><p id="f187" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里他们计算了<em class="ki">局部密度</em></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ls"><img src="../Images/ddfeac5f5d791c4121df81035aa5863f.png" data-original-src="https://miro.medium.com/v2/resize:fit:658/format:webp/1*lnjuGTTbveiyf_PsuivqSg.png"/></div></figure><p id="1745" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第三层是合并。本文给出了一个具体的方法。</p><p id="110f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在下面的文章中，我将实现这个方法。希望有用。</p><p id="9f65" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">参考资料:</p><ol class=""><li id="f766" class="ju jv hi ih b ii ij im in iq jw iu jx iy jy jc jz ka kb kc bi translated"><a class="ae jt" href="https://www.ijarcce.com/upload/2016/february-16/IJARCCE%2077.pdf" rel="noopener ugc nofollow" target="_blank">https://www . ijar CCE . com/upload/2016/2 月-16/IJARCCE%2077.pdf </a></li><li id="def6" class="ju jv hi ih b ii kd im ke iq kf iu kg iy kh jc jz ka kb kc bi translated"><a class="ae jt" href="https://journalofbigdata.springeropen.com/articles/10.1186/s40537-019-0236-x" rel="noopener ugc nofollow" target="_blank">https://journalofbigdata . springer open . com/articles/10.1186/s 40537-019-0236-x</a></li></ol></div></div>    
</body>
</html>