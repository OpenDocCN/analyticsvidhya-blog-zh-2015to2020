<html>
<head>
<title>Neural network back-propagation explained</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">神经网络反向传播解释</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/neural-network-back-propagation-explained-398f76e7b49a?source=collection_archive---------11-----------------------#2019-11-25">https://medium.com/analytics-vidhya/neural-network-back-propagation-explained-398f76e7b49a?source=collection_archive---------11-----------------------#2019-11-25</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><h1 id="055f" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">介绍</h1><p id="b426" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">反向传播是允许神经网络学习的核心机制。</p><p id="dead" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">在本文中，我将从数学和描述两个方面解释反向传播，以便更好地理解这个重要的概念。</p><p id="ae8e" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">希望你喜欢它。</p><h1 id="fa73" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">神经网络的数学观点</h1><p id="4ae8" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">我们将用于这种解释的神经网络模型是<em class="kg">多类感知器</em>(听起来很花哨，不是吗？).</p><figure class="ki kj kk kl fd km er es paragraph-image"><div class="er es kh"><img src="../Images/f45a2ae89643f50f06489382dacc5b1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:260/format:webp/1*F8Ti2VweL4CqdkX0wBfYOg.png"/></div></figure><p id="e641" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">基本上，每个感知器由<strong class="jf hj"> A </strong>矩阵中的一行表示，<strong class="jf hj"> x </strong>列向量表示输入，<strong class="jf hj"> y </strong>列向量表示输出。矩阵<strong class="jf hj"> A </strong>中的元素称为<em class="kg">权重</em>。</p><p id="8600" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">您可能以前见过这种形式:</p><figure class="ki kj kk kl fd km er es paragraph-image"><div class="er es kp"><img src="../Images/f8919973c4217873957522e42c34a07e.png" data-original-src="https://miro.medium.com/v2/resize:fit:502/format:webp/1*KtirGbLwrwaCX0yVQpslBA.png"/></div></figure><p id="9c30" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">应用于矩阵乘法结果的函数称为<em class="kg">激活函数</em>；这是一个非线性函数，必须根据应用进行选择。<strong class="jf hj"> <em class="kg"> softmax </em> </strong>和<strong class="jf hj"> <em class="kg"> ReLu </em> </strong>是热门选择。</p><p id="8618" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">向量<strong class="jf hj"> b </strong>称为<em class="kg">偏差</em>，包含一组非零值；它确保如果输入<strong class="jf hj"> x </strong>全为零，网络仍然可以输出非零值，用于训练/评估。</p><p id="ae57" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">这肯定是一个更严格的公式，但它使数学变得更难，而且对理解这里揭示的原理没有太大帮助。</p><p id="bd9f" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">此外，在本文中，我们假设偏差是矩阵<strong class="jf hj"> A </strong>的一部分，输入有一个额外的常数元素等于1，与偏差相关联。</p><p id="39d7" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">输出的意义取决于输入数据和神经网络的目的。在数据分类中，输出向量中的每个元素被映射到输入的一个<em class="kg">类</em>。</p><p id="8a2f" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">面临的挑战是找到权重，使得该类很有可能对输入是正确的。</p><p id="2976" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">输出的概率方面是由于通过神经网络建模的系统——像任何数学模型一样——是真实函数的近似。以泰勒多项式为例。这是一种用多项式逼近任何函数的方法，但它只在计算点周围的特定边界内有效；我们离边界越远，得到错误值的机会就越大。</p><p id="5845" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">我们如何确定<strong class="jf hj"> A </strong>的值？</p><p id="3ca0" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">这就是训练的目的。就像篮球运动员学习如何投球一样，训练的主要算法使用试错法的数学版本。</p><p id="a1a7" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">让我们看看这是如何工作的。</p><h1 id="ce5b" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">我们期望的和我们得到的</h1><p id="3fca" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">投篮，错过篮筐，调整力量，移动到不同的位置，再次投篮，击中篮筐，调整力量，再次移动，一遍又一遍地尝试，直到你的大脑知道，不知何故，力量，距离和轨迹角度之间的关系，让球几乎一直穿过篮筐。</p><p id="851b" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">从数学上讲，这相当于这个算法:</p><ol class=""><li id="29be" class="kq kr hi jf b jg kb jk kc jo ks js kt jw ku ka kv kw kx ky bi translated">为权重分配随机值</li><li id="dc2f" class="kq kr hi jf b jg kz jk la jo lb js lc jw ld ka kv kw kx ky bi translated">应用一个具有已知输出的输入(这个已知输出的值称为<em class="kg">标签</em>；特别是在数据分类中，它代表输入的<em class="kg">类</em></li><li id="b11b" class="kq kr hi jf b jg kz jk la jo lb js lc jw ld ka kv kw kx ky bi translated">使用某个函数将标签与神经网络计算的标签进行比较；计算出的输出称为<em class="kg">预测</em>。</li><li id="c53d" class="kq kr hi jf b jg kz jk la jo lb js lc jw ld ka kv kw kx ky bi translated">使用某种方法根据比较结果改变权重</li><li id="7e10" class="kq kr hi jf b jg kz jk la jo lb js lc jw ld ka kv kw kx ky bi translated">冲洗并从步骤2开始重复；当步骤3中的函数告诉我们标签和预测足够接近时停止</li></ol><p id="52b2" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">步骤3中使用的函数称为<em class="kg">损失函数</em>。</p><p id="a013" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">通常用于在步骤4中更新权重的机制被称为<em class="kg">梯度下降法</em>。</p><p id="40d5" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">让我们更详细地研究一下，好吗？</p><h1 id="536c" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">梯度下降</h1><p id="08c5" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">如果你还记得你在学校学的微积分，你会记得你可以通过计算函数对感兴趣的变量的导数，使其等于0并求解方程来找到函数的局部最小值或拐点。或者，换句话说，我们希望找到<em class="kg"> x </em>使得:</p><figure class="ki kj kk kl fd km er es paragraph-image"><div class="er es le"><img src="../Images/29323722746caa17447833994df68505.png" data-original-src="https://miro.medium.com/v2/resize:fit:550/format:webp/1*KtaiQtFMArlAQqpRRJ6axQ.png"/></div></figure><p id="80da" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">我们如何写一个算法来做到这一点？好吧，我们来看看函数最小值前后的导数的值(我们这里的主要假设是我们的函数确实有最小值)。</p><figure class="ki kj kk kl fd km er es paragraph-image"><div class="er es lf"><img src="../Images/b656d9a187448148f4ad5a4aaa99c2ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1230/format:webp/1*6XHIde6_xhRRIw1p_0uhFg.png"/></div></figure><p id="e7f1" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">希望从图中可以清楚地看到，如果我们为<em class="kg"> x </em>选择某个随机值，并计算该点的函数导数，那么:</p><p id="f17b" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">a.如果导数为负，我们选择一个点<strong class="jf hj"> <em class="kg">在</em> </strong>最小值之前</p><p id="90fd" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">b.如果导数为正，我们在 后选择一个值<strong class="jf hj"> <em class="kg">为最小值。</em></strong></p><p id="5585" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">哼，有意思。</p><p id="d508" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">基于此，可以使用以下算法确定逐渐接近最小值的<em class="kg"> x </em>的值:</p><ol class=""><li id="d1fd" class="kq kr hi jf b jg kb jk kc jo ks js kt jw ku ka kv kw kx ky bi translated">得到一个随机的<em class="kg"> x </em></li><li id="db3a" class="kq kr hi jf b jg kz jk la jo lb js lc jw ld ka kv kw kx ky bi translated">计算该点的导数</li><li id="53fc" class="kq kr hi jf b jg kz jk la jo lb js lc jw ld ka kv kw kx ky bi translated">使用以下公式计算下一个<em class="kg"> x </em>:</li></ol><figure class="ki kj kk kl fd km er es paragraph-image"><div class="er es lg"><img src="../Images/166bbeb2d5e20cd47984b8144cb6979d.png" data-original-src="https://miro.medium.com/v2/resize:fit:836/format:webp/1*hiiJOtFAFke1karAxoD9wQ.png"/></div></figure><p id="424c" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">4.从步骤2开始重复，直到我们达到最小值(或足够接近我们的需求)</p><p id="ebe1" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">如果导数<strong class="jf hj"> <em class="kg">为负</em> </strong>则<em class="kg"> x </em>的下一个值比当前值<strong class="jf hj"> <em class="kg">高</em> </strong>，使我们更接近最小值；有道理，毕竟当前值是<strong class="jf hj"> <em class="kg">之前</em> </strong>的最小值。</p><p id="cc0e" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">另一方面，如果导数是<strong class="jf hj"> <em class="kg">正的</em> </strong>，那么<em class="kg"> x </em>的下一个值是比当前值低的 的<strong class="jf hj">；也有道理，毕竟当前值是<strong class="jf hj"> <em class="kg">后</em> </strong>的最小值。</strong></p><p id="9ce2" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">该算法被命名为<strong class="jf hj"> <em class="kg">梯度下降</em> </strong>。</p><p id="65a8" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">在我们的例子中，变量是矩阵<strong class="jf hj"> A </strong>中的权重，我们将对它们中的每一个应用算法。</p><p id="028c" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">所以现在我们知道了计算权重<strong class="jf hj"> </strong>的算法，我们必须确定我们应该使用哪个函数来进行比较。换句话说，我们应该选择哪个损失函数。</p><h1 id="4983" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">损失函数</h1><p id="a886" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated"><em class="kg">损失函数</em>或<strong class="jf hj"> <em class="kg">代价函数</em> </strong>就是我们要最小化的函数。它是输出的预期值和计算值的函数。</p><p id="2389" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">这个函数必须有一些有用的特征:</p><ol class=""><li id="1e17" class="kq kr hi jf b jg kb jk kc jo ks js kt jw ku ka kv kw kx ky bi translated">必须是可微的，所以我们可以在梯度下降计算中使用导数</li><li id="95d8" class="kq kr hi jf b jg kz jk la jo lb js lc jw ld ka kv kw kx ky bi translated">理想情况下，只有一个全局最小值，否则我们可能会陷入局部最小值，这不是权重的最优解</li><li id="d3c3" class="kq kr hi jf b jg kz jk la jo lb js lc jw ld ka kv kw kx ky bi translated">同样理想的是，它应该迅速收敛到解</li></ol><p id="5b3f" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">根据神经网络的目的，使用不同的损失函数。比如在分类问题中<strong class="jf hj"> <em class="kg">交叉熵损失</em> </strong>就是一个比较热门的选择。公式如下:</p><figure class="ki kj kk kl fd km er es paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="er es lh"><img src="../Images/6530ef4621463de4f7977aa4bad3b961.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nKB-4m5_nKjTQhC1v8KsZA.png"/></div></div><figcaption class="lm ln et er es lo lp bd b be z dx translated">等式1:交叉熵损失函数</figcaption></figure><p id="9298" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">让我们检查这个损失函数是否满足我们上面建立的标准。</p><p id="62f7" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><em class="kg">可微吗？</em></p><p id="b5d3" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">当然是，因为它是对数的组合。这是关于预测的导数</p><figure class="ki kj kk kl fd km er es paragraph-image"><div class="er es lq"><img src="../Images/bd04abf6b8d1c1cde4850893a3077511.png" data-original-src="https://miro.medium.com/v2/resize:fit:970/format:webp/1*LlDR_E-7N3oP0Z3kxgLCqQ.png"/></div></figure><p id="47d5" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">它有一个最小值吗？</p><p id="7cd1" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">毫无疑问，正如你在图表中看到的。没有极大值，没有拐点，只有一个全局极小值。完美。</p><figure class="ki kj kk kl fd km er es paragraph-image"><div class="er es lr"><img src="../Images/2a4c48adb8454a47f04af481a0618605.png" data-original-src="https://miro.medium.com/v2/resize:fit:1212/format:webp/1*sSYzRjBdwSvqvglYZuDfoQ.png"/></div></figure><p id="0fb1" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><em class="kg">是否</em> <em class="kg">快速收敛到解？</em></p><p id="da85" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">没问题，只要看它的导数的图表(记住，损失函数的导数用于梯度下降法)</p><figure class="ki kj kk kl fd km er es paragraph-image"><div class="er es ls"><img src="../Images/d98b5220208ea9353a11897fd52ea2c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1210/format:webp/1*MaQ1JY4SBUNVtNaGQtyccQ.png"/></div></figure><p id="d6ab" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">所以这似乎是一个损失函数的明智选择。</p><p id="1986" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">我们必须引起读者注意的一件事是，这个函数从100到10用了大约20个点，但从10到大约0又用了80个点。这是训练神经网络的一个固有特性:训练时间呈指数增长，越需要精确。这就是为什么我们需要巨大的计算能力来在可行的时间内训练非常精确的神经网络。</p><p id="cdad" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">一切看起来都很好。我们只需要最后一条信息。</p><h1 id="ae75" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">损失函数对重量的导数</h1><p id="cec0" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">为了计算损失函数相对于每个重量的导数，我们将使用链式法则。</p><figure class="ki kj kk kl fd km er es paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="er es lt"><img src="../Images/6ee88da4202a1629a20b3b1cfc6f8dae.png" data-original-src="https://miro.medium.com/v2/resize:fit:904/format:webp/1*0PtC3tRslNFBnw1gnRnQKg.png"/></div></div></figure><p id="4e48" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">但是自从</p><figure class="ki kj kk kl fd km er es paragraph-image"><div class="er es lu"><img src="../Images/3eb6ffaf2400c7e089110316795406f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:462/format:webp/1*rkRCLQWtjklwb7Px-AO1eQ.png"/></div><figcaption class="lm ln et er es lo lp bd b be z dx translated">等式2:神经网络的输出<strong class="bd ih"> i </strong></figcaption></figure><p id="291d" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">然后我们可以写作</p><figure class="ki kj kk kl fd km er es paragraph-image"><div class="er es lv"><img src="../Images/1ccc6b37d3c6408c8b952fc1e338d17d.png" data-original-src="https://miro.medium.com/v2/resize:fit:344/format:webp/1*vS5Ni5zCo5Jka0nqjn9EjA.png"/></div></figure><p id="a27e" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">最后，每个重量的梯度下降公式为:</p><figure class="ki kj kk kl fd km er es paragraph-image"><div class="er es lw"><img src="../Images/8fe24ebb70978ad2ed768207e2d5add1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1048/format:webp/1*d5B7fhq8UprTtf2eVTCuIg.png"/></div><figcaption class="lm ln et er es lo lp bd b be z dx translated">等式3:应用于矩阵<strong class="bd ih"> A </strong>中每个权重的值</figcaption></figure><p id="40ae" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">这就是为什么我们选择一个非常简单的神经网络来展示数学。</p><p id="2f80" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">在具有复杂图形和不同激活函数的多层神经网络中，不仅数学变得更复杂，而且应用链规则也变得更难以数学表示。</p><p id="74eb" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">好的，让我们把它们放在一起。</p><h1 id="6531" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">计算重量</h1><p id="dae8" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">现在我们已经有了所有的片段，让我们来训练我们的网络。</p><ol class=""><li id="66d7" class="kq kr hi jf b jg kb jk kc jo ks js kt jw ku ka kv kw kx ky bi translated">用一组随机的权重创建矩阵<strong class="jf hj"> A </strong></li></ol><p id="2df3" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">2.使用等式2计算输入的预测值</p><p id="0bc1" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">3.使用等式1计算每个预测的损失函数</p><p id="83d2" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">4.使用等式3计算新的权重</p><p id="d422" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">5.用新输入重复步骤2，直到损失函数低于所需阈值</p><p id="bcf8" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">你可能注意到了<strong class="jf hj"> 𝜆 </strong>参数乘以梯度下降方程中的导数；我——故意——一直等到现在才提到它。</p><p id="b03d" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">这个常数被称为<em class="kg">学习率</em>，为其选择一个合适的值非常重要。太低，训练过程将永远持续；太高，训练算法可能永远不会收敛。</p><p id="b85c" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">描述寻找最佳学习率的技术的论文可以在这里找到:<a class="ae lx" href="https://arxiv.org/abs/1506.01186" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1506.01186</a></p><p id="b72a" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">现在你知道了。利用TensorFlow或Caffe2等机器学习框架，人们可以用Python编写一个程序来定义、训练和执行一个神经网络，其代码行数几乎与上面的项目符号列表相同。</p><p id="1195" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">下面是TensorFlow的一个例子:</p><pre class="ki kj kk kl fd ly lz ma mb aw mc bi"><span id="f258" class="md ig hi lz b fi me mf l mg mh">import tensorflow as tf<br/>mnist = tf.keras.datasets.mnist<br/><br/>(x_train, y_train),(x_test, y_test) = mnist.load_data()<br/>x_train, x_test = x_train / 255.0, x_test / 255.0<br/><br/>model = tf.keras.models.Sequential([<br/>  tf.keras.layers.Flatten(input_shape=(28, 28)),<br/>  tf.keras.layers.Dense(128, activation='relu'),<br/>  tf.keras.layers.Dropout(0.2),<br/>  tf.keras.layers.Dense(10, activation='softmax')<br/>])<br/><br/>model.compile(optimizer='adam',<br/>              loss='sparse_categorical_crossentropy',<br/>              metrics=['accuracy'])<br/><br/>model.fit(x_train, y_train, epochs=5)&lt;--training is done here<br/>model.evaluate(x_test, y_test)</span></pre><h1 id="6fd4" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">最终意见</h1><p id="82c3" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">反向传播似乎相对简单。它不是。以下是它的一些缺点:</p><h2 id="9142" class="md ig hi bd ih mi mj mk il ml mm mn ip jo mo mp it js mq mr ix jw ms mt jb mu bi translated"><em class="mv">过拟合</em></h2><p id="caae" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">为训练和测试选择错误的输入集(例如，一个类别的样本比其他类别的样本多)，计算出的权重将会有偏差，并且您的神经网络将无法为其他类别正常工作。</p><h2 id="d649" class="md ig hi bd ih mi mj mk il ml mm mn ip jo mo mp it js mq mr ix jw ms mt jb mu bi translated"><em class="mv">欠配合</em></h2><p id="1658" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">选择错误的标准来停止训练，神经网络将在测试和真实数据中表现不佳。如果没有足够大的数据集用于训练，也会发生这种情况。</p><h2 id="4dc3" class="md ig hi bd ih mi mj mk il ml mm mn ip jo mo mp it js mq mr ix jw ms mt jb mu bi translated"><em class="mv">损失函数不收敛</em></h2><p id="c5e6" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">选择错误的输入序列，损失函数可能永远不会收敛(例如，每个输入“抵消”了根据前一个输入计算的权重的变化)</p><h2 id="da27" class="md ig hi bd ih mi mj mk il ml mm mn ip jo mo mp it js mq mr ix jw ms mt jb mu bi translated">损失函数最小值过于平坦</h2><p id="7edb" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">如果损失函数具有非常平坦的最小值，则损失值可能在最小值附近振荡，但永远不会达到最小值</p><h2 id="47d1" class="md ig hi bd ih mi mj mk il ml mm mn ip jo mo mp it js mq mr ix jw ms mt jb mu bi translated">训练率太高或太低</h2><p id="de97" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">选择一个合适的训练率可能很棘手。选择一个太低的值，损失函数可能永远无法收敛；选择一个过高的值，权重可能会在最佳值附近振荡，永远不会收敛。</p><h1 id="e877" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">结论</h1><p id="80a1" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">希望这篇文章有助于揭示反向传播背后的基本原理。正如我之前提到的，这是一个数学上复杂的过程，需要大量的计算能力和聪明的算法——几乎必须使用动态规划——才是可行的。</p><p id="bc9f" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">反向传播是神经网络直到最近才被认真地认为是解决问题的可行机制的主要原因。</p><p id="f1bf" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">有许多与反向传播相关的其他细节使其具有挑战性(例如，层数；权重使用浮点值；正常化；初始权重值),因此这篇文章将为您提供一些关于该主题的更高级文本的基础。</p><p id="6cb2" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">感谢阅读。</p></div></div>    
</body>
</html>