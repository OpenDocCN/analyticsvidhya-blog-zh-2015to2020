<html>
<head>
<title>Understanding Machine Learning Algorithms — Naive Bayes</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">理解机器学习算法—朴素贝叶斯</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/understanding-machine-learning-algorithms-naive-bayes-808ed649c1ec?source=collection_archive---------13-----------------------#2020-02-21">https://medium.com/analytics-vidhya/understanding-machine-learning-algorithms-naive-bayes-808ed649c1ec?source=collection_archive---------13-----------------------#2020-02-21</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/d233a6fc44e8a634f68cbed3027cdf44.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L2mwUsWwXzT1ipt013MsmQ.png"/></div></div></figure><p id="23d3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">朴素贝叶斯可以在这个博客中用于分类，我们从基本原理中推导出朴素贝叶斯。</p><h1 id="08de" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">你会学到什么？</h1><ol class=""><li id="b8d3" class="km kn hi is b it ko ix kp jb kq jf kr jj ks jn kt ku kv kw bi translated"><strong class="is hj">条件概率</strong></li><li id="a459" class="km kn hi is b it kx ix ky jb kz jf la jj lb jn kt ku kv kw bi translated"><strong class="is hj">贝叶斯定理</strong></li><li id="0377" class="km kn hi is b it kx ix ky jb kz jf la jj lb jn kt ku kv kw bi translated"><strong class="is hj">朴素贝叶斯如何工作</strong></li><li id="1acb" class="km kn hi is b it kx ix ky jb kz jf la jj lb jn kt ku kv kw bi translated"><strong class="is hj">对数概率和数值稳定性</strong></li><li id="9684" class="km kn hi is b it kx ix ky jb kz jf la jj lb jn kt ku kv kw bi translated"><strong class="is hj">过拟合和欠拟合</strong></li><li id="debb" class="km kn hi is b it kx ix ky jb kz jf la jj lb jn kt ku kv kw bi translated"><strong class="is hj">当我们有异常值和缺失值时它是如何工作的</strong></li><li id="9190" class="km kn hi is b it kx ix ky jb kz jf la jj lb jn kt ku kv kw bi translated"><strong class="is hj">使用案例和限制</strong></li></ol></div><div class="ab cl lc ld gp le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="hb hc hd he hf"><h1 id="ff82" class="jo jp hi bd jq jr lj jt ju jv lk jx jy jz ll kb kc kd lm kf kg kh ln kj kk kl bi translated"><strong class="ak"> 1。条件概率</strong></h1><p id="4be4" class="pw-post-body-paragraph iq ir hi is b it ko iv iw ix kp iz ja jb lo jd je jf lp jh ji jj lq jl jm jn hb bi translated">朴素贝叶斯工作在概率的基础上，它工作在贝叶斯定理上，但是贝叶斯定理是从条件概率中推导出来的。</p><p id="b8c3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">直觉:- </strong>事件B发生了，或者在有或没有事件A的情况下发生了。那么我们正在寻找同样发生在B中的事件A</p><figure class="ls lt lu lv fd ij er es paragraph-image"><div class="er es lr"><img src="../Images/40f2bf70afa759d3cbeccb6c401f5e66.png" data-original-src="https://miro.medium.com/v2/resize:fit:1352/format:webp/1*h5VQ9lOEQsqwYAJNPVf_RQ.png"/></div></figure><p id="4fa2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在让我们来理解一下A出现的频率公式，假设B已经出现了。我们需要找到A的出现次数，然后除以可能性的总数。当我们知道B发生了，A发生了，确切地说是A和B都发生了，因为我们假设B发生了，所以总的可能性是有限的。</p><h1 id="e874" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated"><strong class="ak"> 2。贝叶斯定理</strong></h1><p id="9690" class="pw-post-body-paragraph iq ir hi is b it ko iv iw ix kp iz ja jb lo jd je jf lp jh ji jj lq jl jm jn hb bi translated">我们从条件概率中推导出贝叶斯定理</p><figure class="ls lt lu lv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lw"><img src="../Images/56ca4f077a422fdd76e0468435f048fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AE4P4pcSNZXbNSc7YcuASw.png"/></div></div></figure><p id="42e6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，理解这个公式，在这个公式中，每个术语都有特定的名称，让我们看看</p><blockquote class="lx ly lz"><p id="efa6" class="iq ir ma is b it iu iv iw ix iy iz ja mb jc jd je mc jg jh ji md jk jl jm jn hb bi translated"><strong class="is hj"> P(A|B)是后验</strong></p><p id="2041" class="iq ir ma is b it iu iv iw ix iy iz ja mb jc jd je mc jg jh ji md jk jl jm jn hb bi translated">P(B|A)是一个可能性</p><p id="6db2" class="iq ir ma is b it iu iv iw ix iy iz ja mb jc jd je mc jg jh ji md jk jl jm jn hb bi translated"><strong class="is hj"> P(B)是一个证据</strong></p><p id="1201" class="iq ir ma is b it iu iv iw ix iy iz ja mb jc jd je mc jg jh ji md jk jl jm jn hb bi translated"><strong class="is hj"> P(A)是先验的</strong></p></blockquote><p id="3ffc" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">请观看视频</p><figure class="ls lt lu lv fd ij"><div class="bz dy l di"><div class="me mf l"/></div></figure><h1 id="5641" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated"><strong class="ak"> 3。朴素贝叶斯如何工作</strong></h1><p id="fa1b" class="pw-post-body-paragraph iq ir hi is b it ko iv iw ix kp iz ja jb lo jd je jf lp jh ji jj lq jl jm jn hb bi translated">朴素贝叶斯用在文本数据中，就像邮件是否是垃圾邮件一样，并且评论评论是积极的还是消极的，我们将看到为什么？我们以示例数据作为文本数据来解释算法</p><p id="fe74" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这里我们以一个项目为例来解释我们认为<strong class="is hj"> y=1为正，y=0为负的产品评论。</strong>毕竟，对于每个评论的文本的预处理<strong class="is hj">我们必须计算它的先验和可能性</strong></p><p id="b90b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们计算给定任何评论y=1的概率</p><figure class="ls lt lu lv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mg"><img src="../Images/be49f93010da1bafa2d791345f0f40bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZzsyJYwPonxgwdQUCh9Pmg.png"/></div></div></figure><figure class="ls lt lu lv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mh"><img src="../Images/4b0f071e66f7c2f9c382718000a72501.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KIkW8HhDEdO-_RF6EdLSZg.png"/></div></div></figure><p id="23b4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">给定任何评论，我们计算y=0的概率</p><figure class="ls lt lu lv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mi"><img src="../Images/341aa341c4b6dccba13c3dfb891b55b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AU85RP7h7jqMoSggVDJxRQ.png"/></div></div></figure><figure class="ls lt lu lv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mh"><img src="../Images/e501bcfe95fa3acb051834130ff1d29c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*f4aOs-5ta7eeSCuVve2v2Q.png"/></div></div></figure><p id="5b25" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">先验概率完成后，我们就剩下可能性了。让我们来计算可能性概率</p><figure class="ls lt lu lv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mj"><img src="../Images/df14aa2ac664c2582a91c73e8b0821dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q5esvc-ic-4rI41dN1-WYQ.png"/></div></div></figure><figure class="ls lt lu lv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mk"><img src="../Images/4c76da23ca35e4720aec793558f6eee9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yYH-ppvIk2Y1Awxv2Y8TiA.png"/></div></div></figure><p id="8a04" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">在训练数据的最后，我们得到先验和可能性</strong></p><p id="8025" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">但是一切都很好，有一个问题是，对于训练数据，我们有每个单词的概率，比如</p><p id="946e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">p(Y = 1)；P(Y=0)</p><p id="4289" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">p(W1 | Y = 1)；P(W1|Y=0)等等</p><blockquote class="lx ly lz"><p id="56bd" class="iq ir ma is b it iu iv iw ix iy iz ja mb jc jd je mc jg jh ji md jk jl jm jn hb bi translated"><strong class="is hj">如果我们在测试的时候得到一个词，这个词在训练数据中不存在，我们在训练数据中没有这个词的概率，那么问题就来了</strong></p></blockquote><figure class="ls lt lu lv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ml"><img src="../Images/de2e65109f506c513e41eeafe022bdd9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b2k6KiHt53pi3Xe0IgTwjg.png"/></div></div></figure><p id="8a44" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这里，新单词(在我们的训练数据中不存在)的概率将为零，因此整个概率的乘积将为零，这将是一个巨大的问题。</p><p id="c62a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">拉普拉斯或加法平滑:- </strong></p><figure class="ls lt lu lv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mm"><img src="../Images/583747e550e4f55c89be70fbf96afef1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GwuZ7xWZ0cyRIjg2j7BjtA.png"/></div></div></figure><figure class="ls lt lu lv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mn"><img src="../Images/442eb998b7b1ac728db7ef0ba55565fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qpD-REfOupl4eCj9noua9A.png"/></div></div></figure><blockquote class="lx ly lz"><p id="e63e" class="iq ir ma is b it iu iv iw ix iy iz ja mb jc jd je mc jg jh ji md jk jl jm jn hb bi translated"><strong class="is hj">最初，当我们有一个在训练数据中不存在的单词时，概率将是0/n，现在我们添加一些值α和αK</strong></p></blockquote><p id="6c56" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">α可以是任何值，通常我们取α= 1</strong></p><blockquote class="lx ly lz"><p id="fd3f" class="iq ir ma is b it iu iv iw ix iy iz ja mb jc jd je mc jg jh ji md jk jl jm jn hb bi translated"><strong class="is hj">当alpha较大时，给定单词Y = 1的概率和给定单词Y=0的概率是等概率的，这意味着随着alpha的增加，我们的似然概率将向均匀分布移动。</strong></p></blockquote><figure class="ls lt lu lv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mo"><img src="../Images/25d3619f5bc538b9a22072b105783143.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6IBP034qYpA-aLXerOMKOQ.png"/></div></div></figure><blockquote class="lx ly lz"><p id="93ba" class="iq ir ma is b it iu iv iw ix iy iz ja mb jc jd je mc jg jh ji md jk jl jm jn hb bi translated"><strong class="is hj">当alpha较小时，我们将摆脱与零相乘的问题。</strong></p></blockquote><h1 id="72f8" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">4.对数概率和数值稳定性:-</h1><blockquote class="lx ly lz"><p id="7fd1" class="iq ir ma is b it iu iv iw ix iy iz ja mb jc jd je mc jg jh ji md jk jl jm jn hb bi translated"><strong class="is hj">当我们有高维数据时，所有这些概率值都位于0和1之间，我们将小数字彼此相乘，这导致了数值稳定性</strong></p></blockquote><p id="6f1a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了避免这个问题，我们使用每个概率的对数</p><figure class="ls lt lu lv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mp"><img src="../Images/2f9a08e90a35ed1aae88606185e11f24.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gddMRb_Q0UNAPI51YTQDFw.png"/></div></div></figure><h1 id="adcd" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">5.过度拟合和欠拟合</h1><p id="a281" class="pw-post-body-paragraph iq ir hi is b it ko iv iw ix kp iz ja jb lo jd je jf lp jh ji jj lq jl jm jn hb bi translated">朴素贝叶斯中有一个超参数是α</p><blockquote class="lx ly lz"><p id="271e" class="iq ir ma is b it iu iv iw ix iy iz ja mb jc jd je mc jg jh ji md jk jl jm jn hb bi translated"><strong class="is hj">当alpha过小时，会导致过度拟合。</strong></p><p id="ab5c" class="iq ir ma is b it iu iv iw ix iy iz ja mb jc jd je mc jg jh ji md jk jl jm jn hb bi translated"><strong class="is hj">当α太大时会导致欠拟合，因为可能性概率变成均匀分布，我们可以说新的数据点属于哪一类。</strong></p></blockquote><h1 id="a3c3" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated"><strong class="ak"> 6。当我们有异常值和缺失值时它是如何工作的</strong></h1><p id="7963" class="pw-post-body-paragraph iq ir hi is b it ko iv iw ix kp iz ja jb lo jd je jf lp jh ji jj lq jl jm jn hb bi translated"><strong class="is hj">异常值:- </strong></p><ol class=""><li id="8759" class="km kn hi is b it iu ix iy jb mq jf mr jj ms jn kt ku kv kw bi translated">在训练时，如果一个单词(Wj)出现的次数少于10次，那么我们就忽略它们</li><li id="a138" class="km kn hi is b it kx ix ky jb kz jf la jj lb jn kt ku kv kw bi translated">测试时间时，拉普拉斯平滑会处理异常值</li></ol><p id="bf16" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">缺失值:- </strong></p><p id="e774" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果我们有文本数据，没有丢失值的情况，如果我们有分类特征，我们假设还有一个数字特征类别，我们使用morel插补</p><p id="21e5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">7。使用案例和限制</p><ol class=""><li id="bd1a" class="km kn hi is b it iu ix iy jb mq jf mr jj ms jn kt ku kv kw bi translated">Naive Baye的基本假设是特性的条件独立性，那么它工作得很好。</li><li id="176c" class="km kn hi is b it kx ix ky jb kz jf la jj lb jn kt ku kv kw bi translated">它广泛应用于文本分类和类别特征</li><li id="f475" class="km kn hi is b it kx ix ky jb kz jf la jj lb jn kt ku kv kw bi translated">它不用于实值特征</li><li id="1d48" class="km kn hi is b it kx ix ky jb kz jf la jj lb jn kt ku kv kw bi translated">朴素贝叶斯模型是可解释的</li><li id="3260" class="km kn hi is b it kx ix ky jb kz jf la jj lb jn kt ku kv kw bi translated">运行时间复杂性和训练时间复杂性较低，我们可以使用低延迟应用程序</li><li id="1541" class="km kn hi is b it kx ix ky jb kz jf la jj lb jn kt ku kv kw bi translated">它很容易过拟合，所以我们应该用拉普拉斯平滑适当地训练</li></ol><p id="fc33" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">感谢阅读！</p></div></div>    
</body>
</html>