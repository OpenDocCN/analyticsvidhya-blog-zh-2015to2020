<html>
<head>
<title>Scrape the web — It’s fun.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">刮网——很有趣。</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/scrape-the-web-its-fun-b3ad77d07c21?source=collection_archive---------18-----------------------#2020-05-09">https://medium.com/analytics-vidhya/scrape-the-web-its-fun-b3ad77d07c21?source=collection_archive---------18-----------------------#2020-05-09</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="c234" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">然而，任何有趣的事情都有它自己的限制。网络抓取也是如此。因此，一定要事先确认特定网站是否允许网络抓取。</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/03499d5802c341311dcf03c159d0268c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*H-6OUdxOYX68a18T"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">由<a class="ae jn" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的<a class="ae jn" href="https://unsplash.com/@emilep?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">émile Perron</a>拍摄的照片</figcaption></figure><p id="2bcc" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">我们为什么需要网络抓取？</strong></p><p id="3b9c" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">在当今世界，我们生活在一个数据池中。想象一下，如果我们能够理解所有隐藏的模式，并提出有用的见解，每个企业都会在行业中蓬勃发展。</p><p id="a675" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">在我看来，这是一种有来有往的政策。顾客得到他们想要的，企业从中获利。听起来简单吗？嗯，如果我们能够方便地访问结构合理、干净的数据来分析信息，以便提出创造性的抽象概念，那就有可能了。但在真实场景中并非如此。</p><p id="28da" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">无论是机器学习还是人工智能，数据科学项目中的第一个要求是收集数据。如果我们收到结构化数据，数据科学家的生活不是更轻松吗？但是我们如何让我们的生活更轻松？</p><p id="cf8d" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">正确收集数据！但是从数据库？来自excels？从文本文件？从网站上？</strong></p><p id="52c9" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">这就是我们将要在这篇文章中讨论的收集信息的方法之一。</p><p id="8eed" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">我们再举一个例子来理解。</strong></p><p id="09ca" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">假设，我们有一个场景，我的机器学习模型在训练数据和测试数据上都表现不佳。这个概念在机器学习中被称为<a class="ae jn" rel="noopener" href="/analytics-vidhya/overfitting-and-underfitting-in-machine-learning-d829d8501335">欠拟合</a>。解决不合身的最简单有效的方法是什么？难道它没有足够的数据来训练我们的模型吗？那么，什么能把我们从这种不幸的时代中拯救出来呢？</p><p id="625b" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">嗯，网络抓取可以作为救星来帮助我们收集数据。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es kk"><img src="../Images/0a11206ff97364276ebe84b629c2dd6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*_-QPKKTTTeo8-P7n"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated"><a class="ae jn" href="https://unsplash.com/@franki?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Franki Chamaki </a>在<a class="ae jn" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="16f3" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">现在进入主题，我们大多数人都知道instagram、twitter、facebook等各种网站都有特定的API，可以帮助开发人员通过执行一些简单的初始步骤，轻松访问他们正在寻找的不同类型的数据。然而，我将把这一部分留给我的读者去探索。</p><p id="ff6c" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">那么，现在问题来了？如果网站有API，如果有很多简单的方法来收集所需的信息，我们为什么需要抓取网站呢？这是因为并不是所有的网站都为我们提供了这样的设施，从而提高了网络抓取的迫切需要。</p><p id="0950" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">维基百科对网络抓取的定义:</strong></p><p id="7a4e" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><em class="kl">网页抓取、网页采集或网页数据提取是</em> <a class="ae jn" href="https://en.wikipedia.org/wiki/Data_scraping" rel="noopener ugc nofollow" target="_blank"> <em class="kl">数据抓取</em> </a> <em class="kl">用于从</em> <a class="ae jn" href="https://en.wikipedia.org/wiki/Website" rel="noopener ugc nofollow" target="_blank"> <em class="kl">网站</em> </a> <em class="kl">中</em> <a class="ae jn" href="https://en.wikipedia.org/wiki/Data_extraction" rel="noopener ugc nofollow" target="_blank"> <em class="kl">提取数据</em> </a> <em class="kl">。网络抓取软件可以使用</em> <a class="ae jn" href="https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol" rel="noopener ugc nofollow" target="_blank"> <em class="kl">超文本传输协议</em> </a> <em class="kl">或者通过网络浏览器直接访问万维网。虽然网络抓取可以由软件用户手动完成，但该术语通常指的是使用</em> <a class="ae jn" href="https://en.wikipedia.org/wiki/Internet_bot" rel="noopener ugc nofollow" target="_blank"> <em class="kl">机器人</em> </a> <em class="kl">或</em> <a class="ae jn" href="https://en.wikipedia.org/wiki/Web_crawler" rel="noopener ugc nofollow" target="_blank"> <em class="kl">网络爬虫</em> </a> <em class="kl">实现的自动化过程。它是一种复制的形式，具体的数据是从网上收集和复制的，通常是到一个中央本地的</em> <a class="ae jn" href="https://en.wikipedia.org/wiki/Database" rel="noopener ugc nofollow" target="_blank"> <em class="kl">数据库</em> </a> <em class="kl">或电子表格，供以后</em> <a class="ae jn" href="https://en.wikipedia.org/wiki/Data_retrieval" rel="noopener ugc nofollow" target="_blank"> <em class="kl">检索</em> </a> <em class="kl">或</em> <a class="ae jn" href="https://en.wikipedia.org/wiki/Data_analysis" rel="noopener ugc nofollow" target="_blank"> <em class="kl">分析</em> </a> <em class="kl">。</em></p><p id="ea0f" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">还有，为什么我们不能直接使用网站上的数据？</p><p id="623d" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj"> <em class="kl">下面是我偶然看到的关于网页抓取的精彩讲解，回答了上面的问题:</em> </strong></p><p id="55b5" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><em class="kl"> Web scraping是一种工具，用于将Web上的非结构化数据调整为可供分析的机器可读的结构化数据。</em></p><p id="604b" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">在数据科学领域，简单的python脚本和库以及HTML的基本概念可以帮助我们实现目标。</strong></p><p id="81b4" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">有各种各样的工具和方法，如selenium、scrapy和多个python库，如用于web抓取的urlib。然而，顾名思义，我们在python中有一个惊人的解析库，叫做“BeautifulSoup ”,我将在我的任务中使用它。</p><p id="1aeb" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我们在网上有很多关于任何主题的教程来教育我们自己，然而，潜在的技能在于我们如何优化我们的知识并将其用于我们自己的需要。因此，让我们开始练习。</p><p id="569f" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">让我们列出网络抓取的各个步骤:</strong></p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es km"><img src="../Images/48ac19b0c447495f8205a9fd08a52000.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S_oTC9hVwPPRstUHl2pbpw.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">图片来源:Quora.com</figcaption></figure><p id="e593" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">1 &gt;第一步也是最重要的一步是向我们想要抓取的网站发出HTTP请求，并获得响应。</p><p id="7e82" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">2 &gt;一旦收到响应，我们就像美汤一样把下载的内容喂给html解析器，提取我们需要的信息。</p><p id="38a1" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">3 &gt;现在我们有了所需的数据，我们需要将它保存在某个地方。因此，第三步也是最简单的一步是将这些输入存储到一个csv/excel文件中，或者我们甚至可以将其加载到一个兼容的数据库中。</p><p id="5ce1" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">现在，因为我喜欢食物，我们很多人都喜欢，<em class="kl">在这篇文章中，我将与大家分享我非常喜欢的一次简单的网络抓取体验，并实现了</em>收集班加罗尔10家顶级餐厅的名称、地址、价格和报价等细节。</p><p id="c477" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">但在此之前！网络抓取合法吗？</strong>我们如何知道我们是否真的被允许从特定网站提取数据。</p><p id="36d8" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><em class="kl">嗯，我们可以通过检查网站的robots.txt文件来验证这一点。如果您看到类似“User_Agent * allow: /”的内容，那么我们就可以开始了。关于这个的更多细节可以在我在stackexchange </em> <a class="ae jn" href="https://webmasters.stackexchange.com/questions/50540/what-does-disallow-search-mean-in-robots-txt" rel="noopener ugc nofollow" target="_blank"> <em class="kl">页面</em> </a> <em class="kl">找到的这个博客中找到。</em></p><p id="f10e" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj"> <em class="kl">最后我们要一步一步的实施流程:</em> </strong></p><ul class=""><li id="d312" class="kn ko hi jq b jr js ju jv jx kp kb kq kf kr kj ks kt ku kv bi translated">首先，我们将导入所需的库，如pandas、requests和BeautifulSoup。</li></ul><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es kw"><img src="../Images/8efe6f76c14f52da5572c2c1c9cfd004.png" data-original-src="https://miro.medium.com/v2/resize:fit:1100/format:webp/1*bnNVovVUxj4xilfK_LnqJQ.png"/></div></figure><ul class=""><li id="667d" class="kn ko hi jq b jr js ju jv jx kp kb kq kf kr kj ks kt ku kv bi translated">接下来，我们将获得我们想要抓取的网站的URL，并设置标题。</li></ul><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es kx"><img src="../Images/5335792d42c2c3afd7041da41f559ce0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8B9L5YoreQBXQ8XZPaheCQ.png"/></div></div></figure><ul class=""><li id="ab92" class="kn ko hi jq b jr js ju jv jx kp kb kq kf kr kj ks kt ku kv bi translated">更多关于标题的信息可以在下面的链接中找到。</li></ul><p id="141a" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><a class="ae jn" href="https://www.whoishostingthis.com/tools/user-agent/" rel="noopener ugc nofollow" target="_blank">https://www.whoishostingthis.com/tools/user-agent/</a></p><p id="470c" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><a class="ae jn" href="http://go-colly.org/articles/scraping_related_http_headers/" rel="noopener ugc nofollow" target="_blank">http://go-colly.org/articles/scraping_related_http_headers/</a></p><ul class=""><li id="83db" class="kn ko hi jq b jr js ju jv jx kp kb kq kf kr kj ks kt ku kv bi translated">我们都知道，每当我们在任何浏览器上键入一个网站地址时，都会发送一个HTTP请求来访问该网站，如果请求成功，该网站将显示所需的网页。同样，这里我们将使用Python 的<strong class="jq hj">请求库向URL发送一个HTTP GET请求来下载HTML内容。</strong></li></ul><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ky"><img src="../Images/932da16b77d7f5773f094b471f2b4e90.png" data-original-src="https://miro.medium.com/v2/resize:fit:964/format:webp/1*9eMz3tp3wfYoJAgOOwHgiQ.png"/></div></figure><ul class=""><li id="af9c" class="kn ko hi jq b jr js ju jv jx kp kb kq kf kr kj ks kt ku kv bi translated">然后使用<strong class="jq hj">解析库‘beautiful soup’</strong>获取并解析下载的数据。<strong class="jq hj">现在，在这里我特别要提一下prettify()函数。</strong>我们也可以在不使用下载内容的情况下打印它，但是应用prettify()函数确实使数据看起来漂亮、整洁、更具可读性和可理解性。</li></ul><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es kz"><img src="../Images/673638b06f2414e905d2faf743e92044.png" data-original-src="https://miro.medium.com/v2/resize:fit:822/format:webp/1*cMh28Ohil6YAXL2sXq3PbQ.png"/></div></figure><ul class=""><li id="fc74" class="kn ko hi jq b jr js ju jv jx kp kb kq kf kr kj ks kt ku kv bi translated">现在，我们需要首先在开发人员工具的帮助下，使用任何浏览器检查我们想要抓取的页面，并根据我们正在寻找的部分，尝试理解代码的结构。然后分析我们笔记本里的HTML，提取出需要的信息，存储在CSV/Database/JSON等。</li></ul><p id="ddc5" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">因为，我想要像餐馆名称、地址、价格和可用报价这样的细节，所以我将寻找存储我需要的信息的HTML标签。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es la"><img src="../Images/8ddfbe7071f880b042340161f52fdd23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5JfhV8z3jWzHNAC--0O58w.png"/></div></div></figure><p id="9591" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">上面的代码表明，将返回所有包含class equals的HTML div标记“restnt-main-wrap clearfix ”,其中包含所有餐馆信息并保存在“rest_details”中。我还检查了“rest_details”的长度，以验证我需要的数据计数是否正确。</p><p id="7dc1" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">为了提取更多的信息，我们将使用一个循环来访问每个餐馆的内容。</strong></p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lb"><img src="../Images/db640bd7d4a722900702e2858df0e145.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Hh2Rf-V8fxsL8IDrMqvuKw.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">上面的代码只提取了我需要的HTML内容。</figcaption></figure><p id="3956" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">因此，我们将检索存储在不同HTML标签和类下的所需信息。</p><p id="1d3d" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">例如:</p><ul class=""><li id="508e" class="kn ko hi jq b jr js ju jv jx kp kb kq kf kr kj ks kt ku kv bi translated">餐馆名称存储在锚标记<a> </a>下。</li></ul><pre class="iy iz ja jb fd lc ld le lf aw lg bi"><span id="433d" class="lh li hi ld b fi lj lk l ll lm"><strong class="ld hj">&lt;a</strong> analytics-action="RestaurantCardClick" analytics-label="13437_JW Kitchen" class="restnt-name ellipsis" data-w-onclick="sendAnalyticsCommon|w1-restarant" href="/bangalore/jw-kitchen-vittal-mallya-road-central-bangalore-13437"&gt;<br/>     <strong class="ld hj">JW Kitchen</strong><br/>   <strong class="ld hj"> &lt;/a&gt;</strong></span></pre><ul class=""><li id="4503" class="kn ko hi jq b jr js ju jv jx kp kb kq kf kr kj ks kt ku kv bi translated">餐馆地址存储在HTML div标签下，包含类等于“restnt-loc省略号”。</li></ul><pre class="iy iz ja jb fd lc ld le lf aw lg bi"><span id="fa73" class="lh li hi ld b fi lj lk l ll lm"><strong class="ld hj">&lt;div class="restnt-loc ellipsis"</strong> data-w-onclick="stopClickPropagation|w1-restarant"&gt;<br/>     &lt;a href="/bangalore-restaurants/jw-marriott-hotel-landmark"&gt;<br/>      <strong class="ld hj">JW Marriott Hotel</strong>,<br/>     &lt;/a&gt;<br/>     &lt;a data-name="Vittal Mallya Road" data-type="LocalityClick" href="/bangalore-restaurants/central-bangalore/vittal-mallya-road"&gt;<br/>      <strong class="ld hj">Vittal Mallya Road</strong><br/>     &lt;/a&gt;<br/>     ,<br/>     &lt;a data-name="Central Bangalore" data-type="AreaClick" href="/bangalore-restaurants/central-bangalore"&gt;<br/>      <strong class="ld hj">Central Bangalore</strong><br/>     &lt;/a&gt;<br/>   <strong class="ld hj"> &lt;/div&gt;</strong></span></pre><p id="4847" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">同样，剩下的信息。现在分析完上面的HTML内容后，我们可以编写下面的代码:</p><p id="0247" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj"> #提取餐厅详情:</strong></p><pre class="iy iz ja jb fd lc ld le lf aw lg bi"><span id="2bb0" class="lh li hi ld b fi lj lk l ll lm">for res in rest_details:<br/> <br/> rest_name = res.find(‘a’)<br/> rest_address = res.find(‘div’, attrs={‘class’: ‘restnt-loc ellipsis’})<br/> rest_price = res.find(‘span’, attrs={‘class’: ‘double-line-ellipsis’})<br/> rest_offer = res.find(‘li’,attrs={‘class’: ‘ellipsis’})<br/> <br/> print(rest_name.text,rest_address.text,rest_price.text,rest_offer.text)</span></pre><p id="ad10" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">输出:</strong>最后我们成功地检索到了细节。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ln"><img src="../Images/a4130696869150818290febf854ba18d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*n6FqT5OA4700BgqMfs5vlg.png"/></div></div></figure><h1 id="5d84" class="lo li hi bd lp lq lr ls lt lu lv lw lx io ly ip lz ir ma is mb iu mc iv md me bi translated"><strong class="ak">现在到了最重要的部分——存储数据。</strong></h1><p id="86f4" class="pw-post-body-paragraph jo jp hi jq b jr mf ij jt ju mg im jw jx mh jz ka kb mi kd ke kf mj kh ki kj hb bi translated">首先我创建了一个列表“restaurant_details ”,然后初始化字典“dataframe”。最后将字典存储在列表中。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mk"><img src="../Images/6bae9864863aeca2aaaa3477c1e26061.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4yuUtT1f7E9e5L-WG3L9nQ.png"/></div></div></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ml"><img src="../Images/40dfd61440c77bffb378644a52371fc3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1368/format:webp/1*c6HD5gYRLXrzsWB_Gz-YWw.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">输出样本。</figcaption></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mm"><img src="../Images/dc238cf08802c285c432e226fc21bf1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:848/format:webp/1*cTS9yU9cIz4pwU8SXRcbgg.png"/></div></div></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mn"><img src="../Images/93dd5e2efbd35e605e56b8040e543976.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_bilwBfSsTL4Ru_6zPhrFQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">样本测向输出</figcaption></figure><p id="2d1a" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">最后，我们将所需信息加载到CSV文件中，该文件将保存在c盘的“用户”文件夹下。</strong></p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mo"><img src="../Images/edb1d06b2b50482ddcf10071d5c8bd5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:890/format:webp/1*9IavmOGx8E_5QsavAo7PbA.png"/></div></figure><p id="896b" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj"> <em class="kl">最终，我们将数据以结构化格式保存在CSV文件中，以备分析之用。</em> </strong></p></div><div class="ab cl mp mq gp mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="hb hc hd he hf"><p id="ec00" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">以上完整代码可在github中查阅:</strong><a class="ae jn" href="https://github.com/anjuraj-ops/Projects-in-data-science/blob/master/web%20scrape%20restaurants%20details.ipynb" rel="noopener ugc nofollow" target="_blank"><em class="kl">https://github . com/anjuraj-ops/Projects-in-data-science/blob/master/web % 20 scrape % 20 restaurants % 20 details . ipynb</em></a></p><p id="5932" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">我还做过一个项目，从另一个网站上提取销售中的“天然植物名称”和它们的“价格”等细节。github中也提供了相关代码:<a class="ae jn" href="https://github.com/anjuraj-ops/Projects-in-data-science/blob/master/web%20scrape%20plants.ipynb" rel="noopener ugc nofollow" target="_blank"><em class="kl">https://github . com/anjuraj-ops/Projects-in-data-science/blob/master/web % 20 scrape % 20 plants . ipynb</em></a></p><p id="e5d1" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">最后但同样重要的是，网络抓取很有趣。请继续关注，我将深入研究更复杂的网页清理，如图片清理、多个网页清理、多个URL清理等。</p><p id="ef9b" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">让我们一起学习。快乐学习！！</p><p id="b47a" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">一如既往，我欢迎任何反馈。</p></div></div>    
</body>
</html>