<html>
<head>
<title>Introduction to Linear Regression, it’s Pitfalls, and how to avoid them</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">线性回归介绍，它的陷阱，以及如何避免它们</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/you-are-into-data-science-5dbdf9256d6e?source=collection_archive---------1-----------------------#2018-10-31">https://medium.com/analytics-vidhya/you-are-into-data-science-5dbdf9256d6e?source=collection_archive---------1-----------------------#2018-10-31</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><blockquote class="if"><p id="1787" class="ig ih hi bd ii ij ik il im in io ip dx translated">“简单是最复杂的”——莱昂纳多·达芬奇</p></blockquote><figure class="ir is it iu iv iw er es paragraph-image"><div class="er es iq"><img src="../Images/f8c5882fedeff8a29e204b6fa90b208f.png" data-original-src="https://miro.medium.com/v2/resize:fit:940/format:webp/0*RuoS1qZUOIfjFX6t.jpg"/></div></figure><p id="c58f" class="pw-post-body-paragraph iz ja hi jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv ip hb bi translated">我们都喜欢有大牌的“酷”模特！</p><p id="bc31" class="pw-post-body-paragraph iz ja hi jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv ip hb bi translated">但事实是，像<strong class="jb hj">线性回归</strong>这样的简单模型在很多实际情况下表现非常好。如果你对处理数据感兴趣，理解以下概念总是有好处的，这些概念在不同和更复杂的机器学习模型中有重复的应用。</p><h1 id="5ad9" class="jw jx hi bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">介绍</h1><p id="faf1" class="pw-post-body-paragraph iz ja hi jb b jc ku je jf jg kv ji jj jk kw jm jn jo kx jq jr js ky ju jv ip hb bi translated"><em class="kz">线性回归</em>模拟标量响应(或因变量y)和一个或多个解释变量(或自变量X)之间的关系。这是预测因变量的一个<strong class="jb hj">非常简单而强大的方法。它在时间序列分析、金融(如<a class="ae la" href="https://en.wikipedia.org/wiki/Capital_asset_pricing_model" rel="noopener ugc nofollow" target="_blank">资本资产定价模型</a>)、流行病学和其他社会科学以及机器学习等领域有着广泛的应用。</strong></p><p id="58d1" class="pw-post-body-paragraph iz ja hi jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv ip hb bi translated">下面是来自onlinestatbook.com<a class="ae la" href="http://onlinestatbook.com/2/regression/intro.html" rel="noopener ugc nofollow" target="_blank">的<strong class="jb hj">实际例子</strong>。在这里，我们相信一个学生的大学GPA(我们的y变量)可以用他或她的高中GPA来解释。当然，这是一个很幼稚的模型，不会给出太高的准确率。但是从图中我们可以看到，我们的回归曲线(红线)给出了一个大致准确的趋势。添加更多相关的预测因素(如学习时间、大学所学课程等。)可能会给我们一个更好的模型。</a></p><figure class="lc ld le lf fd iw er es paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="er es lb"><img src="../Images/e6ebc3e87d3e384ebae5921bfcc11542.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*4XDKnsG0_0Vi2C6H"/></div></div></figure><p id="fa98" class="pw-post-body-paragraph iz ja hi jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv ip hb bi translated">同样，我们可以尝试预测作为不同广告模式(如电视、报纸和互联网)的函数的销售额(y)。将吸烟与癌症和发病率联系起来的早期证据来自于一些采用回归分析的观察性研究。</p><p id="477d" class="pw-post-body-paragraph iz ja hi jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv ip hb bi translated">这在科学家之间引起了争议，正如那句名言所说的那样— <a class="ae la" href="https://www.skepticalraptor.com/skepticalraptorblog.php/correlation-implies-causation-except-doesnt/" rel="noopener ugc nofollow" target="_blank">相关性并不总是意味着因果关系</a>。</p><figure class="lc ld le lf fd iw er es paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="er es lk"><img src="../Images/981087a92d949737beedfc46e8ccdca9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*OQXTzQlPfsSGBneA"/></div></div></figure><figure class="lc ld le lf fd iw er es paragraph-image"><div class="er es ll"><img src="../Images/8debdc9a09d8ac0d876230e47299ae72.png" data-original-src="https://miro.medium.com/v2/resize:fit:918/0*FnH-72MwBEVn10aU"/></div><figcaption class="lm ln et er es lo lp bd b be z dx translated"><em class="lq">(漫画鸣谢-</em><a class="ae la" href="https://xkcd.com/" rel="noopener ugc nofollow" target="_blank"><em class="lq">xkcd</em></a><em class="lq">)</em></figcaption></figure><p id="fe31" class="pw-post-body-paragraph iz ja hi jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv ip hb bi translated"><em class="kz">现在你明白为什么你上了</em> <strong class="jb hj"> <em class="kz">统计学-101 </em> </strong> <em class="kz">课，回到大学时代了吧！</em></p><h1 id="ff78" class="jw jx hi bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">数学公式</h1><p id="6428" class="pw-post-body-paragraph iz ja hi jb b jc ku je jf jg kv ji jj jk kw jm jn jo kx jq jr js ky ju jv ip hb bi translated">通常，我们假设y和X之间存在线性关系(参数中的<strong class="jb hj">线性)，如下所示:</strong></p><figure class="lc ld le lf fd iw er es paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="er es lr"><img src="../Images/5f978f9d05e35df8de1213fb25664cc1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bHFtmDFUaAnyZmhvkhtpsQ.png"/></div></div></figure><p id="f96a" class="pw-post-body-paragraph iz ja hi jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv ip hb bi translated">这里ε表示<strong class="jb hj">误差项。</strong></p><p id="30b3" class="pw-post-body-paragraph iz ja hi jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv ip hb bi translated">我们通过标准技术估计模型的参数，如<strong class="jb hj"> <em class="kz">最小二乘法、最大似然估计、自适应估计、最小角度回归</em> </strong>等。线性回归也扩展到了<strong class="jb hj"> <em class="kz">广义线性模型、异方差模型、分层线性模型和测量误差模型</em> </strong>。关注这篇维基百科文章，了解更多细节-<a class="ae la" href="https://en.wikipedia.org/wiki/Linear_regression" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Linear_regression</a>。</p><p id="b303" class="pw-post-body-paragraph iz ja hi jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv ip hb bi translated"><strong class="jb hj">如果您对这些技术有任何疑问，请在</strong>下方评论<strong class="jb hj"> </strong>。</p><p id="2087" class="pw-post-body-paragraph iz ja hi jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv ip hb bi translated">如果你知道R，下面是我在<a class="ae la" href="https://github.com/souravstat" rel="noopener ugc nofollow" target="_blank">my Github</a>-<a class="ae la" href="https://github.com/souravstat/Statistical-Learning-Solved-excercises-from-ISLR-book/blob/master/ch3.R" rel="noopener ugc nofollow" target="_blank">https://Github . com/souravstat/Statistical-Learning-Solved-exercises-from-ISLR-book/blob/master/CH3中对线性回归的<em class="kz">实现。R </em></a>。</p><p id="0f2d" class="pw-post-body-paragraph iz ja hi jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv ip hb bi translated">下面是来自<strong class="jb hj"> Aishwarya Ramachandran </strong>用Python-<a class="ae la" href="https://www.linkedin.com/pulse/tutorial-3-applying-linear-regression-python-aishwarya-c-ramachandran/" rel="noopener ugc nofollow" target="_blank">https://www . LinkedIn . com/pulse/tutorial-3-applying-linear-regression-Python-Aishwarya-c-Ramachandran/</a>更详细的实现。</p><h1 id="faf4" class="jw jx hi bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">常见陷阱</h1><blockquote class="if"><p id="ae6d" class="ig ih hi bd ii ij ls lt lu lv lw ip dx translated">“所有的模型都是错的，但有些是有用的”——乔治·博克斯</p></blockquote><p id="6115" class="pw-post-body-paragraph iz ja hi jb b jc lx je jf jg ly ji jj jk lz jm jn jo ma jq jr js mb ju jv ip hb bi translated">本质上，一个特定模型的“有用性”取决于它的假设如何适应现实世界的应用。线性回归的假设包括<strong class="jb hj">线性(在参数中)、恒定方差、误差独立性</strong>等。如果这些在很大程度上被违反，分析可能会出错！所以，这里有一些实现线性回归时的常见问题(它始于LinkedIn中的<a class="ae la" href="https://www.linkedin.com/feed/update/urn:li:activity:6450022585307623424" rel="noopener ugc nofollow" target="_blank">这篇文章</a>，在那里我得到了朋友们非常热烈的回应)。</p><figure class="lc ld le lf fd iw er es paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="er es mc"><img src="../Images/2cfd77487cc2c4ee738ae5e280f28097.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*XLc7jA51xzdhgHlJ"/></div></div></figure><p id="5c6c" class="pw-post-body-paragraph iz ja hi jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv ip hb bi translated"><strong class="jb hj">下面是如何在拟合回归线的同时处理这些实际问题</strong>。这同样适用于这里讨论的其他回归模型。我大致遵循了ISLR书<a class="ae la" href="https://www.amazon.in/Introduction-Statistical-Learning-Applications-Statistics/dp/1461471370" rel="noopener ugc nofollow" target="_blank">中的指导方针。</a></p><h1 id="3660" class="jw jx hi bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">如何解决这些问题</h1><p id="8bde" class="pw-post-body-paragraph iz ja hi jb b jc ku je jf jg kv ji jj jk kw jm jn jo kx jq jr js ky ju jv ip hb bi translated">在这里，我们讨论在实践中实现线性回归时如何处理核心问题。</p><ol class=""><li id="df52" class="md me hi jb b jc jd jg jh jk mf jo mg js mh ip mi mj mk ml bi translated"><strong class="jb hj">非线性</strong>:</li></ol><p id="c162" class="pw-post-body-paragraph iz ja hi jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv ip hb bi translated">我们可以绘制残差(误差)与拟合值的关系图，找出数据中的非线性。对预测值使用<a class="ae la" href="https://people.revoledu.com/kardi/tutorial/Regression/nonlinear/NonLinearTransformation.htm" rel="noopener ugc nofollow" target="_blank">非线性变换</a>(如代数、对数或幂变换-见右图)以使用线性回归方法。</p><figure class="lc ld le lf fd iw er es paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="er es mm"><img src="../Images/40e3f95517e94d8b14143c44fca4c5a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:694/0*5MiNbvHJ9ALFAlXY"/></div></div></figure><p id="050e" class="pw-post-body-paragraph iz ja hi jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv ip hb bi translated">2) <strong class="jb hj">离群值:</strong></p><p id="5a9d" class="pw-post-body-paragraph iz ja hi jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv ip hb bi translated">这些是具有不寻常的Y值的观察结果。通过将每个残差e[i]除以其估计的标准误差来计算<a class="ae la" href="https://en.wikipedia.org/wiki/Studentized_residual" rel="noopener ugc nofollow" target="_blank">学生化残差</a>。如果绝对值为&gt; 3，则可能是异常值。仔细观察变量，决定是<em class="kz">删除变量、</em>还是<em class="kz">继续插补</em>(替换为合适的值，如平均值/中值)。</p><p id="b1e5" class="pw-post-body-paragraph iz ja hi jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv ip hb bi translated">3) <strong class="jb hj">高杠杆点:</strong></p><p id="1e06" class="pw-post-body-paragraph iz ja hi jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv ip hb bi translated">具有异常X值的观察值被称为<strong class="jb hj">高杠杆点</strong>。计算<a class="ae la" href="https://en.wikipedia.org/wiki/Leverage_(statistics)" rel="noopener ugc nofollow" target="_blank">杠杆统计量h </a>的值，其有界在[0，1]内。更高的幅度意味着更高的杠杆。正如我们在下面的例子中所看到的(<a class="ae la" href="https://slideplayer.com/slide/9173878" rel="noopener ugc nofollow" target="_blank">来源</a>)，尽管两种情况下的数据云是相似的，但是包含杠杆点(红色观察)完全改变了回归曲线</p><figure class="lc ld le lf fd iw er es paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="er es mn"><img src="../Images/0eeeb90f884a92ef9c290419efc0e743.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*YIWsq2nBmM2qMyUA"/></div></div></figure><p id="eb48" class="pw-post-body-paragraph iz ja hi jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv ip hb bi translated">我们还可以使用<strong class="jb hj"> Cook的距离图</strong>(学生化残差与每个点的杠杆的图)来找到这些点(称为影响点，因为它们显著影响模型行为)。要更详细地了解杠杆和影响诊断，请参考<a class="ae la" href="http://home.iitk.ac.in/~shalab/regression/Chapter6-Regression-Diagnostic%20for%20Leverage%20and%20Influence.pdf" rel="noopener ugc nofollow" target="_blank">IIT坎普尔<strong class="jb hj">沙拉布</strong>教授</a>的讲稿。</p><p id="f270" class="pw-post-body-paragraph iz ja hi jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv ip hb bi translated">4) <strong class="jb hj">误差项的相关性</strong>:</p><p id="ad5c" class="pw-post-body-paragraph iz ja hi jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv ip hb bi translated">有时，模型中的误差项会相互关联。例如，有时在时间序列数据中，对应于相邻时间点的观察值可能会变得相关。如果人群以某种方式聚集在一起，也会发生这种情况(例如，同一个家庭的成员，接触相同饮食/相似环境因素的人等)。这就是为什么我们使用<a class="ae la" href="https://en.wikipedia.org/wiki/Scientific_control" rel="noopener ugc nofollow" target="_blank">受控实验</a>来最小化不需要的变量(不包括在自变量中)的影响。</p><p id="8c7e" class="pw-post-body-paragraph iz ja hi jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv ip hb bi translated">5) <strong class="jb hj">异方差:</strong></p><p id="bd38" class="pw-post-body-paragraph iz ja hi jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv ip hb bi translated">这指的是误差项的<strong class="jb hj">非恒定方差，这是另一个常见的陷阱。我们可以绘制残差(有时以标准化格式)与预测值的关系图来找出这一点。从下图(b)可以看出，漏斗状表示异方差。我们可以使用像Log或Root这样的凹函数对Y进行变换，从而使较大值的收缩量更大。因此，线性回归变得适用，我们得到类似(a)的曲线。</strong></p><figure class="lc ld le lf fd iw er es paragraph-image"><div role="button" tabindex="0" class="lg lh di li bf lj"><div class="er es mo"><img src="../Images/65d95105a30abec850a2ae7a70d6b978.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*WI3AeJrXdDTPUvma"/></div></div></figure><p id="3287" class="pw-post-body-paragraph iz ja hi jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv ip hb bi translated">6) <strong class="jb hj">多重共线性</strong>:</p><p id="e000" class="pw-post-body-paragraph iz ja hi jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv ip hb bi translated">它指的是两个或多个预测变量彼此密切相关的情况。这是不好的，因为这会在模型中引入冗余。最小平方优化方法受到影响(即变得不稳定)，因为在这种情况下系数矩阵X不能实现满秩。这个问题在生存分析和不同期限的利率建模(利率一起变动)中尤其普遍。</p><p id="fd07" class="pw-post-body-paragraph iz ja hi jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv ip hb bi translated">另一个流行(！)练习确保完美的多重共线性是<a class="ae la" href="https://en.wikipedia.org/wiki/Dummy_variable_(statistics)" rel="noopener ugc nofollow" target="_blank">哑变量</a>陷阱；包括每个类别的虚拟变量(例如，12个月中的每个月)以及作为预测因子的常数项。</p><p id="d4a6" class="pw-post-body-paragraph iz ja hi jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv ip hb bi translated">这可以通过<strong class="jb hj">数据的随机扰动</strong>检测到(注意在多次重新运行回归后系数的变化，向数据添加随机噪声)。另一种方法是计算<a class="ae la" href="https://en.wikipedia.org/wiki/Variance_inflation_factor" rel="noopener ugc nofollow" target="_blank">方差膨胀因子</a>。VIF &gt; 5表示多重共线性的存在。</p><h1 id="79ce" class="jw jx hi bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">就这些，朋友们！</h1><p id="2f73" class="pw-post-body-paragraph iz ja hi jb b jc ku je jf jg kv ji jj jk kw jm jn jo kx jq jr js ky ju jv ip hb bi translated">希望你喜欢这篇文章。请在下面的评论中告诉我你对线性回归的体验。</p><p id="7034" class="pw-post-body-paragraph iz ja hi jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv ip hb bi translated"><em class="kz">喜欢这篇文章？随意发个“你好”！还有</em> <a class="ae la" href="http://about.me/sourav.nandi" rel="noopener ugc nofollow" target="_blank"> <em class="kz">在不同平台跟我连接</em> </a> <em class="kz">。我活跃在</em><a class="ae la" href="https://github.com/souravstat" rel="noopener ugc nofollow" target="_blank"><em class="kz">Github</em></a><em class="kz"/><a class="ae la" href="https://www.linkedin.com/in/souravstat" rel="noopener ugc nofollow" target="_blank"><em class="kz">LinkedIn</em></a><em class="kz"/><a class="ae la" href="https://www.quora.com/profile/Sourav-Nandi-58" rel="noopener ugc nofollow" target="_blank"><em class="kz">Quora</em></a><em class="kz"/><a class="ae la" href="https://twitter.com/souravstat" rel="noopener ugc nofollow" target="_blank"><em class="kz">Twitter、</em> </a> <em class="kz">和</em><a class="ae la" rel="noopener" href="/@souravstat"><em class="kz">Medium</em></a><em class="kz">。</em></p><p id="36d7" class="pw-post-body-paragraph iz ja hi jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv ip hb bi translated">PS-不要忘记关注<a class="ae la" href="https://medium.com/analytics-vidhya" rel="noopener"> Analytics Vidhya </a>获取更多类似的精彩文章！</p></div></div>    
</body>
</html>