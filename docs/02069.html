<html>
<head>
<title>Introduction of “Adversarial Examples Improve Image Recognition” , ImageNet SOTA method using Adversarial Training</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">介绍“对抗性例子提高图像识别”，ImageNet SOTA方法使用对抗性训练</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/introduction-of-adversarial-examples-improve-image-recognition-imagenet-sota-method-using-1fe981b303e?source=collection_archive---------8-----------------------#2019-11-28">https://medium.com/analytics-vidhya/introduction-of-adversarial-examples-improve-image-recognition-imagenet-sota-method-using-1fe981b303e?source=collection_archive---------8-----------------------#2019-11-28</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><h1 id="5a00" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">关于这篇文章</h1><p id="c72a" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">本文是对2019年11月21日发布的“对立的例子改善图像识别”[1]的评论。本文摘要如下。</p><p id="5d86" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj"> <em class="kg">他们提出使用对立样本的AdvProp，显著提高ImageNet和带噪声的ImageNet的精度。这是一种对抗性的训练，他们在训练中使用2批标准化。其中一个用于正常数据，另一个用于对立样本。基于这样的想法，即不适合用混合两个数据的分布来学习，因为没有噪声的正常数据和有噪声的数据在不同的域中。在不使用外部数据的情况下，使用ImageNet Top-1 Acc达到85.5%，在不使用外部数据的情况下达到最先进水平。</em>T3】</strong></p></div><div class="ab cl kh ki gp kj" role="separator"><span class="kk bw bk kl km kn"/><span class="kk bw bk kl km kn"/><span class="kk bw bk kl km"/></div><div class="hb hc hd he hf"><h1 id="b6e2" class="if ig hi bd ih ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc bi translated">对抗范例和对抗训练</h1><p id="c5e0" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">对立的例子是数据中人为制造的少量噪声，以错误识别样本。用于该图像的示例如下所示。</p><figure class="ku kv kw kx fd ky er es paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="er es kt"><img src="../Images/40d006ead806f9a376c425045e6ac255.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ivfhSw5PmJiVUDzd99vjSA.png"/></div></div><figcaption class="lf lg et er es lh li bd b be z dx translated">对立例子的例子。模型被愚弄了，但人类从未因微小的噪音而被愚弄。</figcaption></figure><p id="e0cf" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">这里有一个小噪声，旨在错误识别熊猫的图像。</p><p id="be84" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">稍微自信点回答“熊猫”的模型(左)在变成对抗性例子(右)时，被回答为高自信的长臂猿(一种猴子)。使用这种噪声来错误识别数据被称为对抗性攻击。</p><p id="9459" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">这种噪声可以通过添加扰动来产生，当分类到正确的标签中时，扰动会增加损耗。对抗性攻击和保护模型免受攻击的方法是最热门的研究领域之一。</p><figure class="ku kv kw kx fd ky er es paragraph-image"><div class="er es lj"><img src="../Images/104669512e23218cc53f228c63c15887.png" data-original-src="https://miro.medium.com/v2/resize:fit:1370/format:webp/1*p0CybspN89jSzmM4V4Ovng.png"/></div><figcaption class="lf lg et er es lh li bd b be z dx translated">敌对攻击的噪音</figcaption></figure><p id="ea90" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">虽然创建的对抗性示例会对数据产生误判，但有一种方法可以通过将它放入训练数据来改进模型，这种方法称为对抗性训练。</p><p id="1627" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">众所周知，预先向训练数据中添加对立示例会稍微提高对对立示例的抵抗力，并且在某些情况下还会提高泛化性能。</p></div><div class="ab cl kh ki gp kj" role="separator"><span class="kk bw bk kl km kn"/><span class="kk bw bk kl km kn"/><span class="kk bw bk kl km"/></div><div class="hb hc hd he hf"><h1 id="2f86" class="if ig hi bd ih ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc bi translated">关键洞察力</h1><p id="c6b9" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">在这篇论文中，他们提出了一种通过使用称为AdaProp的对抗性训练来提高准确性的方法。</p><p id="8676" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">本文的重点是如何使用称为批量归一化的正则化方法。批次归一化是一种正则化方法，它计算每个小批次的平均值和方差，标准化输入，将其乘以可学习系数，然后输出添加了可学习偏差的输入。批处理规范化是经常使用的正则化方法之一，也是使ResNet中的层更深的因素之一，这将在后面描述。</p><figure class="ku kv kw kx fd ky er es paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="er es lk"><img src="../Images/3049a525a37317c5a2633499f3ebd274.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wRzImd17xwjgMsA3uQh8Cg.png"/></div></div><figcaption class="lf lg et er es lh li bd b be z dx translated">批量标准化算法</figcaption></figure><p id="63f2" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">尽管旨在通过使用对立示例来提高泛化性能，但对立示例和正态数据具有不同的分布，因此，如果在批处理规范化中将它们放在一起，输出数据的分布将不同于最初的分布。由于这个原因，他们通过对对立的例子和正常的数据进行单独的批量标准化来减少不适当的混合分布的影响。</p><figure class="ku kv kw kx fd ky er es paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="er es lk"><img src="../Images/2c5c0c834fa9477629688c412aaa162e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*76a4K7TlJwgXzlDUQcv6_w.png"/></div></div></figure><h1 id="4d6d" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">方法</h1><p id="20dc" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">在本文提出的AdvProp中，在每个训练步骤中都创建了对立的例子。并且使用这些对立的例子和正常的小批量数据来更新模型。算法如下。</p><figure class="ku kv kw kx fd ky er es paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="er es ll"><img src="../Images/d285af8dfdad1ed45a684b8b51ff5744.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GrGxUQcu4eXWc-4TGzC7pw.png"/></div></div></figure><p id="1e47" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">请注意，对立示例的生成和模型更新都要经过辅助批处理规范化(辅助BN ),这是针对对立示例的，而带有正常数据的模型更新要经过主BN。这可以防止当来自两个不同域的数据混合时产生不适当的混合分布。</p><p id="9d4c" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">辅助BN原则上不限于一个。您可以根据需要制作2个或更多。请注意，在推断过程中仅使用主BN。</p></div><div class="ab cl kh ki gp kj" role="separator"><span class="kk bw bk kl km kn"/><span class="kk bw bk kl km kn"/><span class="kk bw bk kl km"/></div><div class="hb hc hd he hf"><h1 id="e334" class="if ig hi bd ih ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc bi translated">网络</h1><p id="9dbe" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">在展示结果之前，我先解释一下实验中使用的ResNet和EfficientNet。</p><h2 id="e741" class="lm ig hi bd ih ln lo lp il lq lr ls ip jo lt lu it js lv lw ix jw lx ly jb lz bi translated">雷斯内特</h2><p id="0682" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">ResNet [7]是2015年底提出的一个用于图像识别的网络，它有152层，是当时最深的神经网络，在ImageNet上达到了最高的性能。</p><p id="6909" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">在深度网络中，存在梯度消失的问题，但ResNet使用批量规范化和跳过连接解决了该问题。即使是现在，四年后，它仍被频繁引用为比较目标，是图像识别中事实上的基本模型之一。</p><figure class="ku kv kw kx fd ky er es paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="er es ma"><img src="../Images/941294ac9f813f58f2c0fa0e843b3532.png" data-original-src="https://miro.medium.com/v2/resize:fit:1348/format:webp/1*QPRTrogu48iaVE97by22Tg.png"/></div></div><figcaption class="lf lg et er es lh li bd b be z dx translated">跳过连接</figcaption></figure><h2 id="bc64" class="lm ig hi bd ih ln lo lp il lq lr ls ip jo lt lu it js lv lw ix jw lx ly jb lz bi translated">效率网</h2><p id="4926" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">接下来，我解释EfficientNet [9]。EfficientNet是2019年5月提出的自动神经网络架构搜索(NAS，Neural Architecture Search)中优化的网络，最近引起了关注。</p><p id="89c0" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">通过同时搜索宽度(通道数)、深度(层数)和分辨率，获得了具有高精度和小参数的网络结构。通过固定缩放参数φ，在改变宽度、深度和分辨率的同时执行搜索。这些网络按照参数的升序(按照φ的升序)命名为EfficientNet-B0，B1 … B7。</p><figure class="ku kv kw kx fd ky er es paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="er es mb"><img src="../Images/eb35b610ecef379f5bf67f5e28bddd05.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Rmg4zHjOVtEPFGueCQeNUw.png"/></div></div><figcaption class="lf lg et er es lh li bd b be z dx translated">有效净性能(左)，搜索区域(右)</figcaption></figure></div><div class="ab cl kh ki gp kj" role="separator"><span class="kk bw bk kl km kn"/><span class="kk bw bk kl km kn"/><span class="kk bw bk kl km"/></div><div class="hb hc hd he hf"><h1 id="6917" class="if ig hi bd ih ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc bi translated">结果</h1><h2 id="bb90" class="lm ig hi bd ih ln lo lp il lq lr ls ip jo lt lu it js lv lw ix jw lx ly jb lz bi translated">关于干净数据</h2><p id="a8d4" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">首先，使用EfficientNet学习ImageNet无噪声的结果。Top-1 Acc提高了0.7%，而EfficientNet-B7达到了85.2%。虽然没有说明，但在没有外部数据(最先进)的情况下，EfficientNet-B8在ImageNet Top-1 Acc下实现了85.5%。据我所知，截至2019年11月28日，ImageNet SOTA的外部数据为87.4% [3]。</p><figure class="ku kv kw kx fd ky er es paragraph-image"><div class="er es mc"><img src="../Images/aefc8cde56a529717fd6a1c3caa0cf60.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*hkLEJK4Qhp_A34K_jo7OYg.png"/></div></figure><h2 id="f6a6" class="lm ig hi bd ih ln lo lp il lq lr ls ip jo lt lu it js lv lw ix jw lx ly jb lz bi translated">关于噪声数据</h2><p id="7b0a" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">接下来，噪声数据的结果。使用了三个基于ImageNet的数据集:ImageNet-A [4]、ImageNet-C [5]风格化的ImageNet [6]。ImageNet-A是收集困难图像的数据集，ImageNet-C是在图像中多层次加入各种噪声的数据集，styled-ImageNet是经过风格转换的数据集。</p><figure class="ku kv kw kx fd ky er es paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="er es md"><img src="../Images/88930b2404ea8c7cdb3cf065d6acdd38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BhQfBFCNnlcFXHiGIxujig.png"/></div></div><figcaption class="lf lg et er es lh li bd b be z dx translated">噪声数据集</figcaption></figure><p id="58e7" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">在ImageNet-C中，使用了称为平均损坏误差(mCE)的评估指标。简单地说，它是一个指标，表明与AlexNet相比，它对图像噪声的抵抗能力有多强。它是五个噪声级的平均值。较低的mCE意味着更强的抗噪声模型。</p><figure class="ku kv kw kx fd ky er es paragraph-image"><div class="er es me"><img src="../Images/0da82176215bc29a018ec460a980b488.png" data-original-src="https://miro.medium.com/v2/resize:fit:1364/format:webp/1*0rXJyYuDFTf4ogJ2Z1O6Kw.png"/></div><figcaption class="lf lg et er es lh li bd b be z dx translated">CE(损坏错误)定义。mCE是所有讹误的CE总和。</figcaption></figure><p id="a6b8" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">结果如下。任何数据集的准确性都有所提高。</p><figure class="ku kv kw kx fd ky er es paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="er es mf"><img src="../Images/8b3dd8a1fd73b45c1aad145dad5036b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*22SoV9CKjgPcMIqwv_2pnA.png"/></div></div></figure><h2 id="2f50" class="lm ig hi bd ih ln lo lp il lq lr ls ip jo lt lu it js lv lw ix jw lx ly jb lz bi translated">辅助BN的作用</h2><p id="2c7a" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">最后再来看“辅助BN”的效果，这也是本文的重点。下表显示了分离BN的效果与EfficientNet网络规模的关系(B0 <b1 the="" larger="" network="" smaller="" benefits="" of="" separation.="" this="" is="" thought="" to="" be="" because="" becomes="" and="" has="" better="" performance="" so="" that="" even="" mixed="" distributions="" can="" learned="" well.=""/></p><figure class="ku kv kw kx fd ky er es paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="er es mg"><img src="../Images/76550b632b44d26d3ef179d21ffc72d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4WVGDjtJRvAgaoGNgJsyZw.png"/></div></div></figure><p id="fd81" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated">The following table compares AdvProp with the original Adversarial Training. Using original Adversarial Training, the generalization performance deteriorates, but using AdvProp that separates BN , accuracies improve. It can be seen that separating BN has had a great effect. Also, as the network size increases (ResNet-50 </p><figure class="ku kv kw kx fd ky er es paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="er es mh"><img src="../Images/489c460d357c86d976a581e78b92b725.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pMn3pN9VX1t7L83wSyucnQ.png"/></div></div></figure></div><div class="ab cl kh ki gp kj" role="separator"><span class="kk bw bk kl km kn"/><span class="kk bw bk kl km kn"/><span class="kk bw bk kl km"/></div><div class="hb hc hd he hf"><h1 id="7971" class="if ig hi bd ih ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc bi translated">Conclusion</h1><p id="e8a2" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">This blog post introduced AdvProp, the kind of Adversarial Training, which provides two Batch Normalizations for hostile samples and regular data. This strategy is a very general technique that can be used regardless of the network architecture. In addition, we can create a network that is resistant to noise, so I think that this is a very practical method.</p></div><div class="ab cl kh ki gp kj" role="separator"><span class="kk bw bk kl km kn"/><span class="kk bw bk kl km kn"/><span class="kk bw bk kl km"/></div><div class="hb hc hd he hf"><h1 id="5e78" class="if ig hi bd ih ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc bi translated">Weekly Machine Learning newsletter with Revue</h1><div class="mi mj ez fb mk ml"><a href="https://www.getrevue.co/profile/akiratosei" rel="noopener  ugc nofollow" target="_blank"><div class="mm ab dw"><div class="mn ab mo cl cj mp"><h2 class="bd hj fi z dy mq ea eb mr ed ef hh bi translated">Akira's ML news - Revue</h2><div class="ms l"><h3 class="bd b fi z dy mq ea eb mr ed ef dx translated">About me : Manufacturing Engineer / Machine Learning Engineer/ Master of Science in Physics / ExaWizards Inc. _ _ _ _ _…</h3></div><div class="mt l"><p class="bd b fp z dy mq ea eb mr ed ef dx translated">www.getrevue.co</p></div></div><div class="mu l"><div class="mv l mw mx my mu mz ld ml"/></div></div></a></div></div><div class="ab cl kh ki gp kj" role="separator"><span class="kk bw bk kl km kn"/><span class="kk bw bk kl km kn"/><span class="kk bw bk kl km"/></div><div class="hb hc hd he hf"><p id="3bdb" class="pw-post-body-paragraph jd je hi jf b jg kb ji jj jk kc jm jn jo kd jq jr js ke ju jv jw kf jy jz ka hb bi translated"><strong class="jf hj"> <em class="kg">我在对Twitter上关于机器学习的论文做一个简短的归纳和解释。</em>T3】</strong></p><div class="mi mj ez fb mk ml"><a href="https://twitter.com/AkiraTOSEI" rel="noopener  ugc nofollow" target="_blank"><div class="mm ab dw"><div class="mn ab mo cl cj mp"><h2 class="bd hj fi z dy mq ea eb mr ed ef hh bi translated">阿基拉</h2><div class="ms l"><h3 class="bd b fi z dy mq ea eb mr ed ef dx translated">akira的最新推文(@AkiraTOSEI)。机器学习工程师/数据科学家/物理学硕士/…</h3></div><div class="mt l"><p class="bd b fp z dy mq ea eb mr ed ef dx translated">twitter.com</p></div></div><div class="mu l"><div class="na l mw mx my mu mz ld ml"/></div></div></a></div><h1 id="9065" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">参考</h1><ol class=""><li id="a142" class="nb nc hi jf b jg jh jk jl jo nd js ne jw nf ka ng nh ni nj bi translated">谢慈航，对抗性例子提高图像识别，arXiv:1911.09665，2019</li><li id="cf7d" class="nb nc hi jf b jg nk jk nl jo nm js nn jw no ka ng nh ni nj bi translated">Ian J Goodfellow，解释和利用对立的例子，ICLR2015</li><li id="4b58" class="nb nc hi jf b jg nk jk nl jo nm js nn jw no ka ng nh ni nj bi translated">谢启哲，对立样本-带噪声学生的训练改进图像网络分类，arXiv:1911.04252，2019</li><li id="d107" class="nb nc hi jf b jg nk jk nl jo nm js nn jw no ka ng nh ni nj bi translated">丹·亨德里克斯等《自然对立的例子》。arXiv预印本arXiv:1907.07174，2019</li><li id="8822" class="nb nc hi jf b jg nk jk nl jo nm js nn jw no ka ng nh ni nj bi translated">丹·亨德里克斯和托马斯·G·迪特里奇。测试神经网络对常见腐蚀和表面变化的鲁棒性。arXiv:1807.01697，2018</li><li id="8612" class="nb nc hi jf b jg nk jk nl jo nm js nn jw no ka ng nh ni nj bi translated">经Imagenet训练的CNN偏向于纹理；增加形状偏差可以提高精确度和鲁棒性。在2018年的ICLR。</li><li id="a897" class="nb nc hi jf b jg nk jk nl jo nm js nn jw no ka ng nh ni nj bi translated">何，<strong class="jf hj">，深度残差学习在图像识别中的应用，srXiv1512.03385，2015 </strong></li><li id="f5b0" class="nb nc hi jf b jg nk jk nl jo nm js nn jw no ka ng nh ni nj bi translated">Sergey Ioffe等人.批量标准化:通过减少内部协变量偏移加速深度网络训练，arXiv:1502.03167，2015</li><li id="f314" class="nb nc hi jf b jg nk jk nl jo nm js nn jw no ka ng nh ni nj bi translated">谭明兴和Quoc V，EfficientNet:反思卷积神经网络的模型缩放，arXiv:2019.11946，2019</li></ol></div></div>    
</body>
</html>