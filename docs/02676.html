<html>
<head>
<title>Spam Mail Filtering with DeepLearning4J</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用DeepLearning4J过滤垃圾邮件</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/spam-mail-filtering-with-deeplearning4j-445aac14a722?source=collection_archive---------10-----------------------#2019-12-28">https://medium.com/analytics-vidhya/spam-mail-filtering-with-deeplearning4j-445aac14a722?source=collection_archive---------10-----------------------#2019-12-28</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/7105b6d3f5a4a56e913c25ad1230c490.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*brCivjAnojix7NfiFIAeNg.jpeg"/></div></div></figure><p id="3e10" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">文档分类</strong>是自然语言处理(NLP)领域中的常见用例之一，在许多应用中得到了很好的应用。这个例子用垃圾邮件过滤的用例来演示文档分类。结果表明，通过使用深度学习，我们可以基于上下文有策略地过滤掉大多数垃圾邮件。</p><h1 id="05f2" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">履行</h1><figure class="kn ko kp kq fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es km"><img src="../Images/f74cd1235af962de470852d99e96fa53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FN2ywFGDbSULLk6Z9ptqRw.png"/></div></div><figcaption class="kr ks et er es kt ku bd b be z dx translated">图一。垃圾邮件过滤实施的工作流程</figcaption></figure><h2 id="038b" class="kv jp hi bd jq kw kx ky ju kz la lb jy jb lc ld kc jf le lf kg jj lg lh kk li bi translated">工作流程</h2><p id="45cd" class="pw-post-body-paragraph iq ir hi is b it lj iv iw ix lk iz ja jb ll jd je jf lm jh ji jj ln jl jm jn hb bi translated">垃圾邮件过滤的工作流程如图1所示。工作流程从数据清理和重组开始，以将数据准备成可用于培训的格式。</p><p id="87ab" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">原始数据集可以从<a class="ae lo" href="http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/" rel="noopener ugc nofollow" target="_blank">这里</a>检索。在未压缩的文件夹中，可以看到整个数据集都在SMSSpamCollection.txt中，在文件中有带“ham”和“non-spam”字样的标签，分别对应着垃圾数据和非垃圾数据。</p><figure class="kn ko kp kq fd ij er es paragraph-image"><div class="er es lp"><img src="../Images/c86695621b6851d62f65b72b5c0664a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:976/format:webp/1*wKVtO_c9KLBtBAj9lIrsNw.jpeg"/></div><figcaption class="kr ks et er es kt ku bd b be z dx translated">图二。数据集的分布</figcaption></figure><p id="2401" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">数据集的分布显示在上图中。该数据集不平衡，非垃圾邮件数据点(4827个样本)多于垃圾邮件数据点(747个样本)。在这个例子中，不平衡数据用分类模型建模。有一个警告，由于数据量大，网络可能更好地适应非垃圾邮件模式。使用平衡的数据集可以更好地提高性能。</p><p id="d7f7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">数据处理步骤从读入原始文本文件SMSSpamCollection.txt开始。该文本文件包含多行文本，其中每个文本字符串构成一个邮件内容。每一个都被分别检索并保存到一个独立的文本文件中。图3显示了分离的最终结果。然后，数据集被分成训练数据集和测试数据集(分成单独的子文件夹)。</p><figure class="kn ko kp kq fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lq"><img src="../Images/11451b4add292ce92065ab8663e9f134.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U4O6xoweA8XNNkAxP038Aw.png"/></div></div><figcaption class="kr ks et er es kt ku bd b be z dx translated">图3。在一个单独的txt文件中的电子邮件文本的插图。</figcaption></figure><h2 id="35d7" class="kv jp hi bd jq kw kx ky ju kz la lb jy jb lc ld kc jf le lf kg jj lg lh kk li bi translated">获取代码库</h2><p id="ecc4" class="pw-post-body-paragraph iq ir hi is b it lj iv iw ix lk iz ja jb ll jd je jf lm jh ji jj ln jl jm jn hb bi translated">这个例子的程序存储在下面的Github库中。</p><p id="f2bb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">【https://github.com/codenamewei/nlp-with-use-case T4】</p><p id="5584" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">参考目录<strong class="is hj">垃圾邮件过滤</strong>中的用例示例。为了更好地理解，下面将进一步解释代码库。</p><p id="7d0d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">该计划基于开源的基于Java的深度学习框架——deep learning 4j(DL4J)。如果你是DL4J新手，可以参考我的另一篇文章<a class="ae lo" rel="noopener" href="/@codenamewei/ultimate-guide-to-getting-started-with-deeplearning4j-d497603cbe0b">这里</a>对它的介绍和安装。</p><h2 id="0755" class="kv jp hi bd jq kw kx ky ju kz la lb jy jb lc ld kc jf le lf kg jj lg lh kk li bi translated">预训练Word2Vec模型的加载</h2><p id="4e2b" class="pw-post-body-paragraph iq ir hi is b it lj iv iw ix lk iz ja jb ll jd je jf lm jh ji jj ln jl jm jn hb bi translated">在通过执行文件SpamMailFiltering.java来运行主程序之前，您需要下载预先训练好的文本嵌入。为了用文本形式的输入数据训练神经网络，文本必须被转换成嵌入。在这个例子中，使用了将文本转换为嵌入的预训练模型。如果你想了解更多关于Word2Vec的内容，这里有一个很好的<a class="ae lo" href="https://jalammar.github.io/illustrated-word2vec/" rel="noopener ugc nofollow" target="_blank">链接</a>。</p><p id="14b3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这个例子从使用Google新闻语料库加载预先训练的Word2Vec模型开始。这个预训练的模型用30亿个运行单词训练，输出300维英语单词向量。从<a class="ae lo" href="https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz" rel="noopener ugc nofollow" target="_blank">这里</a>下载，在SpamMailFiltering.java把<strong class="is hj"><em class="lr">WORD _ VECTORS _ PATH</em></strong>改成保存文件的路径。</p><figure class="kn ko kp kq fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ls"><img src="../Images/dcb2a0a7e306155c188c8b6b3ddad77b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CAl6c3uwjJ64nve0KNK6qA.png"/></div></div><figcaption class="kr ks et er es kt ku bd b be z dx translated">图4。将单词向量路径分配给GoogleNews-vectors-negative300.bin.gz的本地目录路径</figcaption></figure><h2 id="443e" class="kv jp hi bd jq kw kx ky ju kz la lb jy jb lc ld kc jf le lf kg jj lg lh kk li bi translated">运行代码</h2><p id="927f" class="pw-post-body-paragraph iq ir hi is b it lj iv iw ix lk iz ja jb ll jd je jf lm jh ji jj ln jl jm jn hb bi translated">设置<strong class="is hj">字向量路径</strong>后，通过执行<strong class="is hj">SpamMailFiltering.java运行代码。</strong>在神经网络训练的同时，打开<a class="ae lo" href="http://localhost:9000" rel="noopener ugc nofollow" target="_blank"> http://localhost:9000 </a>虚拟训练进度。</p><figure class="kn ko kp kq fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lt"><img src="../Images/e6b5c587e10992f47fc8cf0514efd2e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TcQTviMU7gD2SMWvaUtUKQ.png"/></div></div><figcaption class="kr ks et er es kt ku bd b be z dx translated">图5。模型训练的可视化。</figcaption></figure><p id="f4b1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">该程序可能需要相当长的时间来运行在CPU后端。加载大型谷歌新闻语料库非常耗时。或者，切换到CUDA后端将需要更短的执行时间。这样做很简单，只需更改<a class="ae lo" href="https://github.com/codenamewei/nlp-with-use-case/blob/master/SpamMailFiltering/pom.xml#L25-L26" rel="noopener ugc nofollow" target="_blank"> pom.xml </a>中的一行即可。同时，你可以让程序运行，休息一下，去☕.喝杯咖啡</p><p id="5c72" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">下面的描述提供了该过程的更详细的演练。</p><h2 id="1943" class="kv jp hi bd jq kw kx ky ju kz la lb jy jb lc ld kc jf le lf kg jj lg lh kk li bi translated">数据矢量化</h2><p id="fe13" class="pw-post-body-paragraph iq ir hi is b it lj iv iw ix lk iz ja jb ll jd je jf lm jh ji jj ln jl jm jn hb bi translated">训练和测试数据存储在目录中，其结构如下所示。有train和test文件夹，每个文件夹中都有垃圾邮件和非垃圾邮件子目录文件夹。</p><figure class="kn ko kp kq fd ij er es paragraph-image"><div class="er es lu"><img src="../Images/e75bdafd6fbe1b9e141a94d221e53d0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:486/format:webp/1*8nhOgd6K-LkKG0OKivzWag.jpeg"/></div><figcaption class="kr ks et er es kt ku bd b be z dx translated">图6。数据目录结构</figcaption></figure><p id="b85a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这些数据通过定制的SpamMailDataSetIterator进行矢量化，如图7所示。该过程包括读入每个文本文件，对具有固定截短长度文本串执行记号化，以及将数据样本分成具有优选批量大小的批。</p><figure class="kn ko kp kq fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lv"><img src="../Images/83e1d3c12cd794e055bc7b30ca9d2fb0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Xc_Jn4yHJtSmQ4iKbM2GUQ.jpeg"/></div></div><figcaption class="kr ks et er es kt ku bd b be z dx translated">图7。垃圾邮件数据设置程序初始化</figcaption></figure><h2 id="e632" class="kv jp hi bd jq kw kx ky ju kz la lb jy jb lc ld kc jf le lf kg jj lg lh kk li bi translated">网络体系结构</h2><p id="2722" class="pw-post-body-paragraph iq ir hi is b it lj iv iw ix lk iz ja jb ll jd je jf lm jh ji jj ln jl jm jn hb bi translated">接下来，长短期记忆(LSTM)模型被配置为对数据建模。由于LSTM能够捕捉长期相关性，因此通常用于对顺序数据进行建模。点击此<a class="ae lo" href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/" rel="noopener ugc nofollow" target="_blank">链接</a>了解更多关于LSTM的信息。</p><figure class="kn ko kp kq fd ij er es paragraph-image"><div class="er es lw"><img src="../Images/dbf9bb1e2b88e3de7a955d5098103505.png" data-original-src="https://miro.medium.com/v2/resize:fit:1344/format:webp/1*oDsvgyHo1CxcVQFKKr3fxw.jpeg"/></div><figcaption class="kr ks et er es kt ku bd b be z dx translated">图8。LSTM神经网络体系结构</figcaption></figure><p id="f138" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如图8所示，网络从300个单元的LSTM层开始，这是预训练单词嵌入的维度。如果原始长度超过预定长度，每封邮件文本将被截断到预定长度。网络继续输出2个类别，即垃圾邮件和非垃圾邮件标签。</p><h2 id="bc86" class="kv jp hi bd jq kw kx ky ju kz la lb jy jb lc ld kc jf le lf kg jj lg lh kk li bi translated">评估结果</h2><p id="5999" class="pw-post-body-paragraph iq ir hi is b it lj iv iw ix lk iz ja jb ll jd je jf lm jh ji jj ln jl jm jn hb bi translated">在1个时期后对测试数据集的评估显示了如图6所示的有希望的结果。在150封垃圾邮件样本中，103封被正确识别为垃圾邮件，而47封被错误地标记为假阴性。</p><figure class="kn ko kp kq fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lx"><img src="../Images/6a369e5f89d70f371ec28e5b1d556797.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AVl8FLWQd2TCpaeCU_vbfQ.png"/></div></div><figcaption class="kr ks et er es kt ku bd b be z dx translated">图九。评估结果。</figcaption></figure><p id="bc1c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我还在一封垃圾邮件样本上测试了该模型，以评估输出。配文<strong class="is hj">“恭喜恭喜！致电FREEFONE 08006344447，申领您保证的2000英镑现金或5000英镑礼品。现在就赎回来！”</strong>，这是一个值得注意的有奖骗局，该模型导致垃圾邮件的概率为98%。这表明该模型能够区别识别垃圾邮件和非垃圾邮件的信心。</p><figure class="kn ko kp kq fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ly"><img src="../Images/99d383444c61c89f413d1f426012ef12.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r3-SZCoH4L_-j01tajBScQ.png"/></div></div><figcaption class="kr ks et er es kt ku bd b be z dx translated">图10。垃圾邮件样本的概率输出。</figcaption></figure><h2 id="a1d2" class="kv jp hi bd jq kw kx ky ju kz la lb jy jb lc ld kc jf le lf kg jj lg lh kk li bi translated">下一步是什么</h2><p id="2c8d" class="pw-post-body-paragraph iq ir hi is b it lj iv iw ix lk iz ja jb ll jd je jf lm jh ji jj ln jl jm jn hb bi translated">我将在自然语言处理类别中发布更多文章，并提供实际演练的源代码。敬请期待！</p><h2 id="0edf" class="kv jp hi bd jq kw kx ky ju kz la lb jy jb lc ld kc jf le lf kg jj lg lh kk li bi translated">参考和未来</h2><ul class=""><li id="3271" class="lz ma hi is b it lj ix lk jb mb jf mc jj md jn me mf mg mh bi translated"><a class="ae lo" rel="noopener" href="/@codenamewei/ultimate-guide-to-getting-started-with-deeplearning4j-d497603cbe0b">https://medium . com/@ codename Wei/ultimate-guide-to-getting-started-with-deep learning 4j-d 497603 CBE 0b</a></li><li id="9c37" class="lz ma hi is b it mi ix mj jb mk jf ml jj mm jn me mf mg mh bi translated"><a class="ae lo" href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/" rel="noopener ugc nofollow" target="_blank">https://colah.github.io/posts/2015-08-Understanding-LSTMs/</a></li><li id="3f30" class="lz ma hi is b it mi ix mj jb mk jf ml jj mm jn me mf mg mh bi translated"><a class="ae lo" href="https://jalammar.github.io/illustrated-word2vec/" rel="noopener ugc nofollow" target="_blank">https://jalammar.github.io/illustrated-word2vec/</a></li></ul></div></div>    
</body>
</html>