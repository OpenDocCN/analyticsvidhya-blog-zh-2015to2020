<html>
<head>
<title>How to win a Kaggle classification competition?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何赢得一场Kaggle分类赛？</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/how-to-win-a-kaggle-classification-competition-bcf87273968e?source=collection_archive---------14-----------------------#2020-07-05">https://medium.com/analytics-vidhya/how-to-win-a-kaggle-classification-competition-bcf87273968e?source=collection_archive---------14-----------------------#2020-07-05</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="919e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">声明:这篇文章是我的学习日志。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/2c239482ea66c8450b0fbbde33106372.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bmO-O_xQ4eKNk1nMXgAscQ.jpeg"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">达雷布·贝克/盖蒂在<a class="ae jt" href="https://www.billboard.com/photos/8030242/celebration-songs-about-winning-victory-success-dance-music" rel="noopener ugc nofollow" target="_blank">广告牌上的照片</a></figcaption></figure><p id="abf0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Kaggle是世界上最大的机器学习爱好者竞争和争光的平台之一。对于机器学习初学者来说，这也是一个很好的平台，可以学习和证明他们在行业中应用数据科学角色时的能力。</p><p id="bc3e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这篇文章包含6个简单的提示和技巧，帮助你在下一次Kaggle比赛(分类任务)中提高你的表现。</p></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><h1 id="bdc6" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">1.使用不同的优化器</h1><p id="24f6" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">Tensorflow和pyTorch上都有许多不同类型的优化器。在他们当中，亚当乐观主义者和它的变体，那达慕通常是开始训练的好选择。Adam optimiser一直被吹捧为一个高效快速的具有自适应特性的优化器。那达慕是简单的亚当与内斯特罗夫的势头。内斯特罗夫加速梯度(NAG)是由尤里·内斯特罗夫于1983年提出的。NAG不是在局部位置测量损失函数的梯度，而是在动量方向稍微靠前的位置测量。这通常会导致更快、更准确的收敛。关于NAG的更多信息，请查看这篇文章:【https://dominikschmidt.xyz/nesterov-momentum/T2】</p><p id="d8b8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">但是，亚当和那达慕优化器并不是能够保证最佳性能的神奇优化器。就验证准确性而言，新币+动量或新币+动量+内斯特罗夫通常比亚当和那达慕表现得更好。因此，我建议你在训练的早期阶段总是从亚当/那达慕开始，在训练的后期阶段切换到新币+动量/新币+动量+内斯特罗夫。请查看这篇文章，了解不同优化者之间更详细的比较:<a class="ae jt" href="https://shaoanlu.wordpress.com/2017/05/29/sgd-all-which-one-is-the-best-optimizer-dogs-vs-cats-toy-experiment/" rel="noopener ugc nofollow" target="_blank">https://Shao anlu . WordPress . com/2017/05/29/SGD-all-the-one-is-the-best-optimizer-dogs-vs-cats-toy-experiment/</a></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es le"><img src="../Images/7ab8b7457afc6de63babb43c2093d5bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1262/format:webp/1*qhS_Z5hrHO4SDJhTrqLJtw.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">图1:不同优化器对猫和狗分类任务的验证准确性。图片摘自:<a class="ae jt" href="https://shaoanlu.wordpress.com/2017/05/29/sgd-all-which-one-is-the-best-optimizer-dogs-vs-cats-toy-experiment/" rel="noopener ugc nofollow" target="_blank">https://Shao anlu . WordPress . com/2017/05/29/SGD-all-the-one-is-the-best-optimizer-dogs-vs-cats-toy-experiment/</a></figcaption></figure><h1 id="6913" class="kb kc hi bd kd ke lf kg kh ki lg kk kl km lh ko kp kq li ks kt ku lj kw kx ky bi translated">2.使用不同的增强技术</h1><p id="7e9f" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">在训练中采用不同的增强技术以允许模型学习输入数据的不同变化以及防止过度拟合是非常重要的。网上有太多花哨的增强技术，我将简要地提到其中的几个，它们通常对图像分类任务非常有用。警告:使用太多或错误类型的增强技术会损害你的表现。T3】</p><h2 id="664f" class="ll kc hi bd kd lm ln lo kh lp lq lr kl iq ls lt kp iu lu lv kt iy lw lx kx ly bi translated">2.1随机剪切/剪切混合</h2><p id="50a1" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">随机剪切是一种随机阻挡部分输入图像技术。这种易于实现的技术可以有效地防止您的模型过度拟合输入数据。如果你的输入数据包含很多噪音信息，如价格标签、产品名称等，这种技术非常有用。</p><p id="b207" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Cutmix是一种技术，它从你随机选取的同一类的两幅图像(A和B)中随机剪切出一个小区域，并交换它们以生成两幅混合图像。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lz"><img src="../Images/9dd4d9a8fa1f19f8db642448ce4daf08.png" data-original-src="https://miro.medium.com/v2/resize:fit:1302/format:webp/1*skwiPL9h4gPd5jnmiI2vgw.jpeg"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">图2:剪切混合技术。图片摘自:<a class="ae jt" href="https://forums.fast.ai/uploads/default/original/3X/d/0/d0c959c1d585438e9095e1ba7ee3deb608edec9a.jpeg" rel="noopener ugc nofollow" target="_blank">https://forums . fast . ai/uploads/default/original/3X/d/0/d0c 959 C1 d 585438 e 9095 E1 ba 7 ee 3 deb 608 edec 9 a . JPEG</a></figcaption></figure><h2 id="573a" class="ll kc hi bd kd lm ln lo kh lp lq lr kl iq ls lt kp iu lu lv kt iy lw lx kx ly bi translated">2.2频道转换</h2><p id="f32e" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">频道偏移是一种通过从用户指定的范围中选择的随机值来随机偏移频道值的技术。如果你的分类任务中的主题可以有不同类型的颜色，这是很有用的。例如，狗、猫、塑料杯和汽车可以有许多不同的颜色。对于具有通用颜色的对象(如乌鸦)来说，这不是很有用。</p></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><p id="b912" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了保持这篇文章的简短，我不会涉及那些基本但有用的增强技术，比如旋转、剪切、缩放等等。请随意查看这篇令人惊叹的帖子以了解更多信息:<a class="ae jt" href="https://towardsdatascience.com/exploring-image-data-augmentation-with-keras-and-tensorflow-a8162d89b844" rel="noopener" target="_blank">https://towards data science . com/exploring-image-data-augmentation-with-keras-and-tensor flow-a 8162d 89 b 844</a></p><p id="dc42" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这些是我经常使用的一些图像增强资源:</p><ol class=""><li id="70b4" class="ma mb hi ih b ii ij im in iq mc iu md iy me jc mf mg mh mi bi translated"><a class="ae jt" href="https://github.com/albumentations-team/albumentations" rel="noopener ugc nofollow" target="_blank">https://github.com/albumentations-team/albumentations</a></li><li id="f587" class="ma mb hi ih b ii mj im mk iq ml iu mm iy mn jc mf mg mh mi bi translated"><a class="ae jt" href="https://github.com/yu4u/cutout-random-erasing" rel="noopener ugc nofollow" target="_blank">https://github.com/yu4u/cutout-random-erasing</a></li></ol><h1 id="2dd3" class="kb kc hi bd kd ke lf kg kh ki lg kk kl km lh ko kp kq li ks kt ku lj kw kx ky bi translated">3.Swish激活功能</h1><p id="e0b0" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">对于不同的机器学习任务，有许多不同种类的激活函数。通常，人们会选择ReLU激活函数或者它的变体，比如leaky ReLU。然而，当涉及到非常深的网络的分类或机器翻译任务时，Swish activation可能是比ReLU更好的选择。</p><p id="5ebf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Swish激活函数:y = x * sigmoid(x)</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mo"><img src="../Images/289be109a0e99275399bd15f3e541d58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kwy6M_bq5zmCoYJkbgs_IA.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">图3: Swish激活功能</figcaption></figure><p id="5b35" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">仔细观察，Swish激活功能在0附近没有ReLU那样的突变。相反，它有一个非常平滑的曲线过渡。Swish激活函数是Ramachandran等人在这篇<a class="ae jt" href="https://arxiv.org/pdf/1710.05941v1.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>中提出的。作者声称，通过他们的大量实验，他们成功地证明了Swish在应用于各种挑战性领域(如图像分类和机器翻译)的深度网络上始终匹配或优于ReLU。因此，在你未来的Kaggle比赛中，尝试一下Swish可能是个好主意。</p><h1 id="9a5f" class="kb kc hi bd kd ke lf kg kh ki lg kk kl km lh ko kp kq li ks kt ku lj kw kx ky bi translated">4.蒙特卡洛辍学</h1><p id="03f3" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">辍学是深度学习中常用的正则化技术。它在训练阶段随机地使一部分神经元失活或“脱落”。这可以有效地减少相邻神经元之间的相互依赖性，迫使它们更有效地学习。通常，退出技术仅在培训阶段实施，在验证和测试阶段停用。</p><p id="cae0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">蒙特卡洛漏失是一种在测试阶段保持漏失层活动并集合N个预测结果的技术。这个想法听起来可能很奇怪，为什么我需要在验证和测试阶段移除部分神经元？嗯，你可以这样想。随机移除模型中的一些神经元将导致不同的网络结构。在测试阶段，将对每个样本进行N次预测。然而，由于漏失被激活的事实，N个预测不是由同一模型做出的。实际上，对一个样本的预测是N个略有差异的不同模型的聚合结果。</p><p id="4fc3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Monte Carlo dropout的美妙之处在于，它可以很容易地实现到任何具有dropout层的训练模型。这意味着不需要重新培训/修改。酷吧？</p><h1 id="b1cd" class="kb kc hi bd kd ke lf kg kh ki lg kk kl km lh ko kp kq li ks kt ku lj kw kx ky bi translated">5.测试时间增加(TTA)</h1><p id="415c" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">与上述数据扩充类似，TTA对测试图像进行随机修改。测试数据集中的每个样本将增加N倍，并馈入模型以产生每个样本的N个不同预测。这N个不同的预测(在这种情况下是softmax概率)将被平均并产生最终的猜测。这个概念非常类似于系综的思想，将几个预测组合起来产生一个强有力的预测。</p><h1 id="c42a" class="kb kc hi bd kd ke lf kg kh ki lg kk kl km lh ko kp kq li ks kt ku lj kw kx ky bi translated">6.焦点损失和标签平滑</h1><p id="c181" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">通常，当涉及多类分类问题时，使用类别交叉熵(CCE)损失函数。当数据集平衡时，CCE很有用，这意味着每个类都有几乎相同数量的样本。然而，对于真实世界场景，这通常是不正确的。在现实世界中，收集的数据集通常是不平衡的。不平衡数据集会给训练带来麻烦，因为样本较少的类会被忽略，而更多的注意力会放在样本较多的类上。</p><p id="e2c5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">焦点损失可以通过对难以分类的类别增加权重来克服这个问题，并减少对容易正确预测的影响。为了实现这一点，在CCE函数中增加了一个比例因子。该因子的值将随着预测置信度的上升(下降)而上升(下降)。这类似于人眼将注意力从背景转移到前景主体，因此称为焦点丢失。</p><p id="45ca" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当模型过度拟合和过度自信时，标注平滑很有用。标签平滑仅在实现交叉熵损失函数并且在最终层中使用softmax激活函数时适用。标签平滑将通过减少“1”的值并给其余部分一个非零值来平滑向量，而不是给每个样本仅一个“1”并给其余部分一个“0”。下面的公式说明了标注平滑:</p><blockquote class="mp"><p id="4d6d" class="mq mr hi bd ms mt mu mv mw mx my jc dx translated"><em class="mz">y _ s</em>=(1—<em class="mz">α</em>)*<em class="mz">y _ hot</em>+<em class="mz">α</em>/<em class="mz">K</em></p></blockquote><p id="2de9" class="pw-post-body-paragraph if ig hi ih b ii na ik il im nb io ip iq nc is it iu nd iw ix iy ne ja jb jc hb bi translated">α是控制平滑程度的参数，而K是类的数量。α值越高，平滑程度越大，模型越不会过度自信。</p><blockquote class="mp"><p id="49b5" class="mq mr hi bd ms mt mu mv mw mx my jc dx translated">过度自信的模型没有被校准，它的预测概率总是高于准确性。例如，对于精度仅为0.6的输入，它可能会预测0.9。请注意，测试误差较小的模型仍然可能过于自信，因此可以从标签平滑中受益。(引自<a class="ae jt" href="https://towardsdatascience.com/what-is-label-smoothing-108debd7ef06" rel="noopener" target="_blank">来源</a>)</p></blockquote></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><p id="e474" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这就是我第一篇关于深度学习的中帖的结尾。机器学习是一个非常庞大且进展迅速的课题。如果这篇文章中有任何困惑或错误，请随时告诉我。如果你喜欢我的内容，请关注我并为我鼓掌。</p></div></div>    
</body>
</html>