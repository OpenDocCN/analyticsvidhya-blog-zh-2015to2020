<html>
<head>
<title>Heuristics For HAR: A Divergent Approach (Part I)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">HAR启发法:一种不同的方法(上)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/heuristics-for-har-a-divergent-approach-part-i-36292f0bf85e?source=collection_archive---------16-----------------------#2019-09-20">https://medium.com/analytics-vidhya/heuristics-for-har-a-divergent-approach-part-i-36292f0bf85e?source=collection_archive---------16-----------------------#2019-09-20</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/28aa1da5bbd5ac2366e3a77a076fda82.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Nmj8PzBsl6nGn71toMkFEQ.png"/></div></div></figure><h1 id="4e73" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">这一切为什么开始？</h1><p id="9aab" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">去年夏天，我和我的朋友计划潜入人工智能。我们计划不惜一切手段来完成这件事。这就是我们遇到的情况:</p><figure class="kn ko kp kq fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es km"><img src="../Images/60bcca24eac1a23c5c5bd53e82b95763.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*osWATx5NjRagSW0M30GhTA.png"/></div></div><figcaption class="kr ks et er es kt ku bd b be z dx translated">人工智能应用简表(各种形式)</figcaption></figure><p id="cd2d" class="pw-post-body-paragraph jo jp hi jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl hb bi translated">我们已经在为一个更大的项目实现人类活动识别(HAR)了。正如运动分析所做的那样，我们的结论是找到了通往人工智能的楼梯。</p></div><div class="ab cl la lb gp lc" role="separator"><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf"/></div><div class="hb hc hd he hf"><h1 id="8c70" class="iq ir hi bd is it lh iv iw ix li iz ja jb lj jd je jf lk jh ji jj ll jl jm jn bi translated">目标:</h1><p id="d6e4" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">作为这个领域的新手，我们用通俗的语言定义了我们的目标。这是他们的样子</p><ul class=""><li id="6555" class="lm ln hi jq b jr kv jv kw jz lo kd lp kh lq kl lr ls lt lu bi translated">以某种方式，让计算机理解身体的不同部分，或者至少是它的基本骨架。</li><li id="d992" class="lm ln hi jq b jr lv jv lw jz lx kd ly kh lz kl lr ls lt lu bi translated">得到骨架最大部分的坐标。</li><li id="9c9f" class="lm ln hi jq b jr lv jv lw jz lx kd ly kh lz kl lr ls lt lu bi translated">启发式地推导出这些部分(由坐标表示)与人类活动之间的关系。</li><li id="4548" class="lm ln hi jq b jr lv jv lw jz lx kd ly kh lz kl lr ls lt lu bi translated">尝试用同样的方法进行轻微的优化，以评估姿势和移动性等其他事情。</li><li id="36b4" class="lm ln hi jq b jr lv jv lw jz lx kd ly kh lz kl lr ls lt lu bi translated">以结构化的形式获得结果，以便于将来应用程序的部署。</li><li id="e41b" class="lm ln hi jq b jr lv jv lw jz lx kd ly kh lz kl lr ls lt lu bi translated">使用最少的计算机资源(没有GPU)，这样即使是Raspberry Pi模型也可以处理它。</li></ul><p id="3268" class="pw-post-body-paragraph jo jp hi jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl hb bi translated">为了解决这些检查点，我们花了一些时间收集资源并研究该主题，并提出了以下要求:</p><h1 id="f18f" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">要求:</h1><ul class=""><li id="9e16" class="lm ln hi jq b jr js jv jw jz ma kd mb kh mc kl lr ls lt lu bi translated">一个预先训练好的模型，可以估计人的骨骼，并给出各部分(或关键点)的坐标。最终，我们用<a class="ae md" href="https://github.com/ildoonet/tf-pose-estimation" rel="noopener ugc nofollow" target="_blank">one by<em class="me">Ildoo Kim</em></a><em class="me">。</em>(his存储库的简化安装已在下一节中提到)</li><li id="72df" class="lm ln hi jq b jr lv jv lw jz lx kd ly kh lz kl lr ls lt lu bi translated">Python 3.7(编写任何东西的编程语言)</li><li id="d1ef" class="lm ln hi jq b jr lv jv lw jz lx kd ly kh lz kl lr ls lt lu bi translated">打开CV 4.x(计算机视觉开源库)</li><li id="2a66" class="lm ln hi jq b jr lv jv lw jz lx kd ly kh lz kl lr ls lt lu bi translated">以上所有内容的依赖关系</li><li id="b9d1" class="lm ln hi jq b jr lv jv lw jz lx kd ly kh lz kl lr ls lt lu bi translated">Windows操作系统(最好是Windows 10)</li></ul><p id="7aab" class="pw-post-body-paragraph jo jp hi jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl hb bi translated">这就是我们如何克服所有的装置:—</p><h1 id="d7c2" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">设置(几乎)一切:</h1><ul class=""><li id="3c17" class="lm ln hi jq b jr js jv jw jz ma kd mb kh mc kl lr ls lt lu bi translated">从微软官方网站安装Visual Studio(c++ 14版)。</li><li id="2fde" class="lm ln hi jq b jr lv jv lw jz lx kd ly kh lz kl lr ls lt lu bi translated">安装Python 3.7 <strong class="jq hj">(仅限64位！)</strong>并将其路径添加到环境变量中。</li><li id="c5dc" class="lm ln hi jq b jr lv jv lw jz lx kd ly kh lz kl lr ls lt lu bi translated">安装OpenCV(从<a class="ae md" href="https://cv-tricks.com/how-to/installation-of-opencv-4-1-0-in-windows-10-from-source/" rel="noopener ugc nofollow" target="_blank">源</a>或使用<a class="ae md" href="https://www.learnopencv.com/install-opencv3-on-windows/" rel="noopener ugc nofollow" target="_blank"> Anaconda </a>)。我用源代码做的。</li></ul><p id="23b7" class="pw-post-body-paragraph jo jp hi jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl hb bi translated">通过在CMD上使用以下命令，确保以上两者都已安装:</p><pre class="kn ko kp kq fd mf mg mh mi aw mj bi"><span id="dab1" class="mk ir hi mg b fi ml mm l mn mo">python<br/>&gt;&gt;&gt; import cv2<br/>&gt;&gt;&gt;</span></pre><p id="95af" class="pw-post-body-paragraph jo jp hi jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl hb bi translated">如果没有错误，恭喜你。确保环境变量是正确的。我的看起来是这样的:<em class="me">(注意第10、11和12行)</em></p><figure class="kn ko kp kq fd ij er es paragraph-image"><div class="er es mp"><img src="../Images/d3009dc252fc09c31be38c25fd461131.png" data-original-src="https://miro.medium.com/v2/resize:fit:1048/format:webp/1*x7QDvtIgIglQ4zeT9PiBrw.png"/></div><figcaption class="kr ks et er es kt ku bd b be z dx translated">Variable.png环境部</figcaption></figure><ul class=""><li id="e3a8" class="lm ln hi jq b jr kv jv kw jz lo kd lp kh lq kl lr ls lt lu bi translated">安装git (pip安装gitpython)</li></ul><pre class="kn ko kp kq fd mf mg mh mi aw mj bi"><span id="59ac" class="mk ir hi mg b fi ml mm l mn mo">pip install gitpython</span></pre><ul class=""><li id="e0b5" class="lm ln hi jq b jr kv jv kw jz lo kd lp kh lq kl lr ls lt lu bi translated">从<a class="ae md" href="https://www.tensorflow.org/install/pip" rel="noopener ugc nofollow" target="_blank">这里</a>安装张量流。<em class="me">安装TensorFlow有什么困难，参考这个</em> <a class="ae md" href="https://stackoverflow.com/questions/38896424/tensorflow-not-found-using-pip" rel="noopener ugc nofollow" target="_blank"> <em class="me">链接</em> </a> <em class="me"> : </em></li><li id="9d13" class="lm ln hi jq b jr lv jv lw jz lx kd ly kh lz kl lr ls lt lu bi translated">如果使用python3.7，protobuf，python3-tk将已经安装。要验证安装，请执行以下操作:</li></ul><pre class="kn ko kp kq fd mf mg mh mi aw mj bi"><span id="5e5e" class="mk ir hi mg b fi ml mm l mn mo">&gt;&gt;&gt; import tkinter</span></pre><ul class=""><li id="5a16" class="lm ln hi jq b jr kv jv kw jz lo kd lp kh lq kl lr ls lt lu bi translated">安装<em class="me">滑动窗</em></li></ul><pre class="kn ko kp kq fd mf mg mh mi aw mj bi"><span id="1306" class="mk ir hi mg b fi ml mm l mn mo">pip3 install slidingwindow</span></pre><ul class=""><li id="b840" class="lm ln hi jq b jr kv jv kw jz lo kd lp kh lq kl lr ls lt lu bi translated">为python安装git<em class="me">(跟随</em> <a class="ae md" href="https://hackernoon.com/install-git-on-windows-9acf2a1944f0" rel="noopener ugc nofollow" target="_blank"> <em class="me">这个</em> </a> <em class="me"> </em> <strong class="jq hj"> <em class="me">但是只有</em> </strong> <em class="me">直到“常见问题”。)添加路径“C:\ Program Files \ Git \ usr \ bin”</em></li><li id="00b7" class="lm ln hi jq b jr lv jv lw jz lx kd ly kh lz kl lr ls lt lu bi translated">从<a class="ae md" href="https://github.com/ildoonet/tf-pose-estimation" rel="noopener ugc nofollow" target="_blank"> GitHub </a>中克隆并下载储存库<strong class="jq hj"> tf-pose-estimation </strong>。把它保存在一个特定的位置(比如L)</li><li id="dfc9" class="lm ln hi jq b jr lv jv lw jz lx kd ly kh lz kl lr ls lt lu bi translated">打开CMD，将目录切换到位置l。</li></ul><pre class="kn ko kp kq fd mf mg mh mi aw mj bi"><span id="4008" class="mk ir hi mg b fi ml mm l mn mo">cd path_to_L</span></pre><p id="8bce" class="pw-post-body-paragraph jo jp hi jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl hb bi translated">这是我的位置看起来的样子:</p><pre class="kn ko kp kq fd mf mg mh mi aw mj bi"><span id="2141" class="mk ir hi mg b fi ml mm l mn mo">cd C:\Python\Python37\summer\PoseEstimation</span></pre><ul class=""><li id="1641" class="lm ln hi jq b jr kv jv kw jz lo kd lp kh lq kl lr ls lt lu bi translated">安装<em class="me"> Cython </em></li></ul><pre class="kn ko kp kq fd mf mg mh mi aw mj bi"><span id="3962" class="mk ir hi mg b fi ml mm l mn mo">pip install Cython</span></pre><ul class=""><li id="0823" class="lm ln hi jq b jr kv jv kw jz lo kd lp kh lq kl lr ls lt lu bi translated">从<strong class="jq hj"> tf-pose-estimation </strong>文件夹中打开“Requirements.txt”并删除<strong class="jq hj"> pycocotools </strong>，因为此安装不适用于windows。相反，使用以下命令安装pycocotools:</li></ul><pre class="kn ko kp kq fd mf mg mh mi aw mj bi"><span id="7c8c" class="mk ir hi mg b fi ml mm l mn mo">pip3 install “git+<a class="ae md" href="https://github.com/philferriere/cocoapi.git#egg=pycocotools&amp;subdirectory=PythonAPI" rel="noopener ugc nofollow" target="_blank">https://github.com/philferriere/cocoapi.git#egg=pycocotools&amp;subdirectory=PythonAPI</a>"</span></pre><ul class=""><li id="6143" class="lm ln hi jq b jr kv jv kw jz lo kd lp kh lq kl lr ls lt lu bi translated">安装要求</li></ul><pre class="kn ko kp kq fd mf mg mh mi aw mj bi"><span id="fc54" class="mk ir hi mg b fi ml mm l mn mo">pip3 install -r requirements.txt</span></pre><ul class=""><li id="4533" class="lm ln hi jq b jr kv jv kw jz lo kd lp kh lq kl lr ls lt lu bi translated">在c盘<em class="me">(或者你的主目录)里面下载<em class="me"> swig </em>。作为参考，浏览一下上面的环境Variable.png文件)</em>来自<a class="ae md" href="https://sourceforge.net/projects/swig/files/swigwin/swigwin-4.0.0/swigwin-4.0.0.zip/download?use_mirror=nchc" rel="noopener ugc nofollow" target="_blank"> Sourceforge </a>并遵循<a class="ae md" href="https://simpletutorials.com/c/2135/Installing+SWIG+on+Windows" rel="noopener ugc nofollow" target="_blank">这些</a>指令。<strong class="jq hj">(当心！Swig应用程序文件将在没有任何窗口弹出的情况下执行。也就是说，只要你下载swig并点击应用程序文件，屏幕就会闪烁并消失。这意味着它已经完成了它的工作。)其余的步骤应该按照链接执行。</strong></li><li id="6166" class="lm ln hi jq b jr lv jv lw jz lx kd ly kh lz kl lr ls lt lu bi translated">将目录切换到<strong class="jq hj">位置估算</strong>内的<em class="me"> pafprocess </em>文件夹</li></ul><pre class="kn ko kp kq fd mf mg mh mi aw mj bi"><span id="d5c5" class="mk ir hi mg b fi ml mm l mn mo">cd C:\Python\Python37\summer\PoseEstimation\tf_pose </span></pre><p id="1fe7" class="pw-post-body-paragraph jo jp hi jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl hb bi translated">并运行命令</p><pre class="kn ko kp kq fd mf mg mh mi aw mj bi"><span id="6d92" class="mk ir hi mg b fi ml mm l mn mo">swig -python -c++ pafprocess.i &amp;&amp; python setup.py build_ext — inplace</span></pre><ul class=""><li id="585c" class="lm ln hi jq b jr kv jv kw jz lo kd lp kh lq kl lr ls lt lu bi translated">从<a class="ae md" href="https://www.addictivetips.com/windows-tips/install-and-use-wget-in-windows-10/" rel="noopener ugc nofollow" target="_blank">处</a>安装<em class="me"> wget </em>。但是在环境变量步骤中，不要按照他的步骤在<strong class="jq hj">系统变量而不是用户变量中添加path！</strong>要显示更改，请重新打开CMD。</li></ul></div><div class="ab cl la lb gp lc" role="separator"><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf"/></div><div class="hb hc hd he hf"><p id="17fe" class="pw-post-body-paragraph jo jp hi jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl hb bi translated">基本安装已经完成，我们终于可以开始分析图像和视频帧了。上面的安装会给你提供框架的骨架。对于图像类型输入:</p><ul class=""><li id="64a8" class="lm ln hi jq b jr kv jv kw jz lo kd lp kh lq kl lr ls lt lu bi translated">我将待分析的图像移动到位置L(run . py所在的位置)。即在<strong class="jq hj">位置估计</strong>文件夹中)。然后运行:</li></ul><pre class="kn ko kp kq fd mf mg mh mi aw mj bi"><span id="43c8" class="mk ir hi mg b fi ml mm l mn mo">python run.py — model=mobilenet_thin — resize=432x368 — image=p1.jpg </span></pre><p id="6e6a" class="pw-post-body-paragraph jo jp hi jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl hb bi translated">虽然直方图最初是不可见的，但是由于<em class="me"> matplotlib </em>库的一些后端问题。这里可以解决:<a class="ae md" href="https://www.pyimagesearch.com/2015/08/24/resolved-matplotlib-figures-not-showing-up-or-displaying/" rel="noopener ugc nofollow" target="_blank">对于LINUX用户</a>和<a class="ae md" href="https://stackoverflow.com/a/56422557/9625777" rel="noopener ugc nofollow" target="_blank">对于WINDOWS用户</a>。解析之后，输出应该是:</p><figure class="kn ko kp kq fd ij er es paragraph-image"><div class="er es mq"><img src="../Images/29a0b7867845039debe9b38ff302d4e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1274/format:webp/1*gnZ3b8OtSwXYVf9jrPnZvA.png"/></div><figcaption class="kr ks et er es kt ku bd b be z dx translated">所有的情节，令人满意的结果。</figcaption></figure><p id="8b2c" class="pw-post-body-paragraph jo jp hi jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl hb bi translated">然而，对于复杂的输入，结果可能会出错:</p><figure class="kn ko kp kq fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mr"><img src="../Images/1130229ad6e133e94b3a156a35348236.png" data-original-src="https://miro.medium.com/v2/resize:fit:1256/format:webp/1*wlwFVxUQnsgz_HdVXbgGOA.png"/></div></div><figcaption class="kr ks et er es kt ku bd b be z dx translated">估计不正确，因为只检测到躯干。</figcaption></figure><ul class=""><li id="dbe4" class="lm ln hi jq b jr kv jv kw jz lo kd lp kh lq kl lr ls lt lu bi translated">要分析实时网络摄像头:</li></ul><pre class="kn ko kp kq fd mf mg mh mi aw mj bi"><span id="a4ec" class="mk ir hi mg b fi ml mm l mn mo">python run_webcam.py — model=mobilenet_thin — resize=432x368 — camera=0 </span></pre></div><div class="ab cl la lb gp lc" role="separator"><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf"/></div><div class="hb hc hd he hf"><h1 id="6370" class="iq ir hi bd is it lh iv iw ix li iz ja jb lj jd je jf lk jh ji jj ll jl jm jn bi translated">结果:</h1><ul class=""><li id="6b1d" class="lm ln hi jq b jr js jv jw jz ma kd mb kh mc kl lr ls lt lu bi translated">成功地导出了进一步使用的骨架或关键点。</li><li id="4a9b" class="lm ln hi jq b jr lv jv lw jz lx kd ly kh lz kl lr ls lt lu bi translated">解锁了获得关键点坐标的可能性。</li><li id="9244" class="lm ln hi jq b jr lv jv lw jz lx kd ly kh lz kl lr ls lt lu bi translated">获取图像输入和视频输入的骨架。</li></ul><h1 id="d733" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">结语:</h1><p id="52f1" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">以上几节已经设法帮助你完成了作者<em class="me"> Ildoo Kim </em>想要的。即简单地获得关键点和骨架。但是，这仅仅是开始。这是许多不同应用程序的通用路径。我们仍然没有估计用户在画面中的姿势或活动(我们打算试探性地这样做)。</p><p id="85ea" class="pw-post-body-paragraph jo jp hi jq b jr kv jt ju jv kw jx jy jz kx kb kc kd ky kf kg kh kz kj kk kl hb bi translated">请留意后续的帖子。</p></div></div>    
</body>
</html>