<html>
<head>
<title>Train Keras Model with Large dataset (Batch Training)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用大数据集训练Keras模型(批量训练)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/train-keras-model-with-large-dataset-batch-training-6b3099fdf366?source=collection_archive---------4-----------------------#2019-09-25">https://medium.com/analytics-vidhya/train-keras-model-with-large-dataset-batch-training-6b3099fdf366?source=collection_archive---------4-----------------------#2019-09-25</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/f60bb5233b7fde573f996edab008610f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1126/format:webp/1*g6AWy5tZbcdDuJQ7Y6L_nw.png"/></div></figure><p id="bfeb" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">嗨伙计们！！在这篇博客中，我将讨论Keras的一个非常有趣的特性。在训练任何深度学习模型时，获得好结果的前提是庞大的训练数据。数据集越大，我们就越能依赖模型。现在的问题是，大部分时间我们都是在有限的资源下工作的，比如内存和CPU。随着训练数据大小的增加，将它完全放在RAM上并进行训练变得困难。在这种情况下，解决这个问题的最佳方法是分批训练模型。训练数据将存储在磁盘中。在每一步中，将从磁盘中取出一块数据，加载到RAM中，进行模型训练。然后，同样的过程将再次重复，直到没有数据留给训练。</p><h2 id="7383" class="jk jl hi bd jm jn jo jp jq jr js jt ju ix jv jw jx jb jy jz ka jf kb kc kd ke bi translated">fit_generator()参数:</h2><p id="9e0a" class="pw-post-body-paragraph im in hi io b ip kf ir is it kg iv iw ix kh iz ja jb ki jd je jf kj jh ji jj hb bi translated">Keras模型有一个名为<strong class="io hj"> fit_generator() </strong>的方法，帮助执行上述批量训练。</p><div class="kk kl ez fb km kn"><a href="https://keras.io/models/sequential/" rel="noopener  ugc nofollow" target="_blank"><div class="ko ab dw"><div class="kp ab kq cl cj kr"><h2 class="bd hj fi z dy ks ea eb kt ed ef hh bi translated">顺序Keras文档</h2><div class="ku l"><p class="bd b fp z dy ks ea eb kt ed ef dx translated">keras.io</p></div></div><div class="kv l"><div class="kw l kx ky kz kv la ik kn"/></div></div></a></div><pre class="lb lc ld le fd lf lg lh li aw lj bi"><span id="3ebb" class="jk jl hi lg b fi lk ll l lm ln"><strong class="lg hj">fit_generator </strong>(<strong class="lg hj">generator</strong>,steps_per_epoch=<strong class="lg hj">None</strong>, epochs=1, verbose=1,            callbacks=<strong class="lg hj">None</strong>, <strong class="lg hj">validation_data=None</strong>, validation_steps=<strong class="lg hj">None</strong>,    validation_freq=1, class_weight=<strong class="lg hj">None</strong>, max_queue_size=10, workers=1, use_multiprocessing=<strong class="lg hj">False</strong>, shuffle=<strong class="lg hj">True</strong>, initial_epoch=0)</span></pre><p id="1a6a" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">它以一个生成器作为参数。该生成器获取一批训练数据，并在单个步骤中将其发送给模型训练。Validation_data也可以作为生成器传递。根据文件</p><pre class="lb lc ld le fd lf lg lh li aw lj bi"><span id="1042" class="jk jl hi lg b fi lk ll l lm ln"><strong class="lg hj">generator</strong>: A generator or an instance of <!-- -->Sequence<!-- --> (<!-- -->keras.utils.Sequence<!-- -->) object in order to avoid duplicate data when using multiprocessing. The output of the generator must be either</span><span id="f98f" class="jk jl hi lg b fi lo ll l lm ln">- tuple <!-- -->(inputs, targets)<br/>- tuple <!-- -->(inputs, targets, sample_weights)<!-- -->.</span><span id="5665" class="jk jl hi lg b fi lo ll l lm ln">  This tuple (a single output of the generator) makes a single batch. Therefore, all arrays in this tuple must have the same length (equal to the size of this batch). Different batches may have different sizes. For example, the last batch of the epoch is commonly smaller than the others, if the size of the dataset is not divisible by the batch size. The generator is expected to loop over its data indefinitely. An epoch finishes when <!-- -->steps_per_epoch<!-- --> batches have been seen by the model.</span></pre><p id="9e88" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">所以我们需要一个生成器来生成一个有两个列表结构的元组——输入和目标。让我们举一个例子来说明上面提到的。</p><ol class=""><li id="99cb" class="lp lq hi io b ip iq it iu ix lr jb ls jf lt jj lu lv lw lx bi translated"><strong class="io hj">数据集</strong></li></ol><p id="000d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">例如，我们将使用MNIST数据集作为训练数据。整个数据集分为两部分，保存为train.csv和test.csv。数据如下所示。其中第一列是目标列。其余是像素值</p><figure class="lb lc ld le fd ij er es paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="er es ly"><img src="../Images/91e4b9146f98addc875b9239d87efead.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*btCxiGNFgQZx649Q-9iDxQ.png"/></div></div></figure><p id="1820" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">训练数据的维度(42000，784)</p><p id="8bdf" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">测试数据的维度(28000，784)</p><p id="c4d5" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">让我们定义我们的生成器函数，它从上表中批量捕获数据。</p><pre class="lb lc ld le fd lf lg lh li aw lj bi"><span id="9f08" class="jk jl hi lg b fi lk ll l lm ln">def batch_generator(Train_df,batch_size,<br/>                    steps):<br/>    idx=1<br/>    while True: <br/>        yield load_data(Train_df,idx-1,batch_size)## Yields data<br/>        if idx&lt;steps:<br/>            idx+=1<br/>        else:<br/>            idx=1</span></pre><p id="b16b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在下面load_data()函数的帮助下，上面的生成器将在每一步产生批处理</p><pre class="lb lc ld le fd lf lg lh li aw lj bi"><span id="e2eb" class="jk jl hi lg b fi lk ll l lm ln">def load_data(Train_df,idx,<br/>              batch_size):<br/>    df = pd.read_csv(<br/>                  Train_df, skiprows=idx*batch_size,<br/>                  nrows=batch_size)<br/>    x = df.iloc[:,1:]<br/>         <br/>    y = df.iloc[:,0]</span><span id="7c62" class="jk jl hi lg b fi lo ll l lm ln">    return (np.array(x), np_utils.to_categorical(y))</span></pre><p id="0815" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在上面的每个调用中，生成器生成元组(输入，目标)。其中“输入”和“目标”都是长度为“batch_size”的数组</p><p id="cc76" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">2.<strong class="io hj">网络架构</strong></p><p id="76e1" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在让我们用keras设计一个简单的神经网络。</p><pre class="lb lc ld le fd lf lg lh li aw lj bi"><span id="ee05" class="jk jl hi lg b fi lk ll l lm ln">## importing libraries<br/>from keras.models import Sequential <br/>from keras.layers import Dense, Activation</span><span id="0e31" class="jk jl hi lg b fi lo ll l lm ln"># some model parameters<br/>output_dim = 10<br/>input_dim = 784</span><span id="22da" class="jk jl hi lg b fi lo ll l lm ln">batch_size = 256 <br/>nb_epoch = 10<br/>steps_per_epoch=np.ceil(42000/batch_size)<br/>validation_steps=np.ceil(28000/batch_size)</span><span id="304c" class="jk jl hi lg b fi lo ll l lm ln">### Generator objects for train and validation<br/>my_training_batch_generator = batch_generator('train.csv', 256,steps_per_epoch)<br/>my_validation_batch_generator = batch_generator('test.csv', 256,validation_steps)</span><span id="5b1f" class="jk jl hi lg b fi lo ll l lm ln">## Layer 1<br/>model = Sequential()<br/>model.add(Dense(50, input_dim=input_dim, activation='relu'))</span><span id="935a" class="jk jl hi lg b fi lo ll l lm ln">## Layer 2<br/>model.add(Dense(output_dim, input_dim=50, activation='softmax'))</span><span id="9901" class="jk jl hi lg b fi lo ll l lm ln">##Compile model<br/>model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])<br/></span></pre><p id="da6d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在，我们将使用model.fit_generator()代替model.fit()，并传递my_training_batch_generator和my_validation_batch_generator</p><pre class="lb lc ld le fd lf lg lh li aw lj bi"><span id="699d" class="jk jl hi lg b fi lk ll l lm ln">model.fit_generator(my_training_batch_generator,<br/>epochs=nb_epoch,steps_per_epoch=steps_per_epoch,<br/> verbose=1, validation_data=my_validation_batch_generator,<br/>validation_steps=validation_steps)</span></pre><p id="c86d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我们完了。现在，Keras模型将使用批量训练数据进行训练，而无需将整个数据集加载到RAM中。我们可以通过设置<strong class="io hj"> use_multiprocessing=True来获得多重处理的帮助。然后，多个线程将运行以获取不同的数据块并训练模型。最后，结果将被合并。</strong></p><p id="83b2" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">今天就到这里吧。快乐学习。</p></div></div>    
</body>
</html>