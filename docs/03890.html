<html>
<head>
<title>Artificial Intelligence plays Kariba!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">人工智能玩卡里巴！</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/artificial-intelligence-plays-kariba-c281052e8dce?source=collection_archive---------11-----------------------#2020-02-24">https://medium.com/analytics-vidhya/artificial-intelligence-plays-kariba-c281052e8dce?source=collection_archive---------11-----------------------#2020-02-24</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="fcd1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以你想用蒙特卡罗树搜索(MCTS)，但是你的博弈有<strong class="ih hj">不完全信息</strong>，还有一个<strong class="ih hj">几率</strong>的元素。那就难了！在这篇博客中，我们将把MCTS应用到这样一个游戏中；卡里巴。我们会发现我们真正需要的是多观察者信息集蒙特卡罗树搜索(MOISMCTS)。</p><p id="6a43" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">卡里巴是一个有趣的小纸牌游戏，有一些简单的规则。当轮到你时，你从你的手牌中打出一张或几张相同种类的牌到场上(在水坑周围，因为动物需要喝水)。如果在某个时候，场上有3只或更多的同种动物，它们会赶走所有最接近的弱种动物。然而，每个人都知道大象害怕老鼠，所以老鼠是唯一能赶走大象的动物。每赶走一只动物，你就得一分。就是这样！</p><p id="2138" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">例子:场上有两只老鼠、两只斑马和两只豹子。玩家A从她的手牌中打出第三张豹牌到场上。现在有三只豹子，它们赶走了两只斑马。玩家A得到2分(因为她的行动赶走了2只动物)。玩家B现在扮演另一只豹子。现在场上有4只豹子，比3只多，所以他们赶走了剩下的两只老鼠。玩家B现在也得到2分。</em></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/560af3e65b04180d0b0ca0d15ebe6cae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VTpH7OrIPS5JJt3GMuo4eQ.jpeg"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">可爱的动物卡片</figcaption></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es ju"><img src="../Images/ccb97aea0f85230a48f4993d354f47dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*_rjj3bJTIRBBQP9X7ihVag.gif"/></div><figcaption class="jq jr et er es js jt bd b be z dx translated">流言终结者证明大象害怕老鼠</figcaption></figure><p id="4682" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">卡里巴是一个有<strong class="ih hj">不完全信息</strong>的游戏，因为一个玩家无法看到另一个玩家的手牌。还有，这是一个<strong class="ih hj">机会</strong>的游戏，因为你永远不知道下一张牌是什么。MCTS并不真的处理这样的游戏。</p></div><div class="ab cl jv jw gp jx" role="separator"><span class="jy bw bk jz ka kb"/><span class="jy bw bk jz ka kb"/><span class="jy bw bk jz ka"/></div><div class="hb hc hd he hf"><p id="3027" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们来谈谈MCTS吧！</p><p id="b8bd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">每个游戏状态将被称为一个“节点”。从根节点开始，我们<strong class="ih hj">选择</strong>我们想要了解更多的子节点。我们对该节点再次这样做，并继续选择子节点，直到找到一个没有任何子节点的节点(“叶节点”)。此时我们<strong class="ih hj">展开</strong>；我们找到这个节点可以拥有的新的子节点。从新节点开始，我们执行一个<strong class="ih hj">模拟</strong>(或“首次展示”)。这意味着我们模拟一个游戏，两个玩家随机移动，并记录谁赢。然后我们<strong class="ih hj">将这个结果反向传播</strong>到所有的祖先节点。当通过树反向传播一个模拟的结果时，我们只在该节点的动作被将成为胜利者的代理采取时，才将其记录为一个胜利。如果该节点的操作是由将成为输家的代理执行的，我们将结果记录为亏损。</p><p id="5c65" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们执行循环(选择、扩展、模拟、反向传播)，直到是时候进行“真正的”移动(比如说，在500次模拟之后)。然后我们通常选择我们已经运行了大多数模拟的动作。当我们处在新的形势下，必须采取新的行动时，我们就让MCTS从头开始。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es kc"><img src="../Images/3914f25bb50b26007442d289d0aba0f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*MDtERtVnMMnGGgAphEG6xQ.gif"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">40秒后蒙特卡罗树搜索。在<a class="ae kd" href="https://github.com/KnurpsBram/AI_plays_kariba/tree/master/other" rel="noopener ugc nofollow" target="_blank"> git repo </a>中也有pdf格式</figcaption></figure><p id="1f28" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">但是什么时候一个节点是‘有趣’的呢？这个问题很有意思！在选择人工智能想要了解更多的行动时，它应该在<strong class="ih hj">探索</strong>和<strong class="ih hj">开发</strong>之间找到平衡。一个很好的方法是选择具有最高<em class="jd">置信上限(UCB)的节点:</em></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es ke"><img src="../Images/120a4c7d7c786aaadf78dfbfcd1b2390.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8sn9XClB0z0yfNu-bgn_7w@2x.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">置信上限</figcaption></figure><p id="5685" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">其中<em class="jd"> nᵢ </em>是从节点开始的模拟量，<em class="jd"> wᵢ </em>获胜量，<em class="jd"> Nᵢ </em>父节点的模拟量，<em class="jd"> c </em>是超参数。c的高值促进勘探，低值促进开采。<em class="jd"> c </em>通常设置为√2。</p></div><div class="ab cl jv jw gp jx" role="separator"><span class="jy bw bk jz ka kb"/><span class="jy bw bk jz ka kb"/><span class="jy bw bk jz ka"/></div><div class="hb hc hd he hf"><p id="0f2f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">香草MCTS的问题是，它假设双方都可以完全观察到状态，但卡里巴是一个不完全信息的游戏。此外，状态不仅会因为行动而改变，还会因为抽牌而改变，这增加了一个<strong class="ih hj">偶然性</strong>的因素，使事情变得复杂。</p><p id="0526" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">解决这两个问题的方法是使用多观察者信息集蒙特卡罗树搜索(MOISMCTS)。</p><p id="4228" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了处理<strong class="ih hj">不完美信息，</strong> MOISMCTS跟踪每个玩家的独立树。这棵树上的一个节点不是一个状态，而是一个‘信息集’；给定玩家拥有的信息，游戏可能处于的所有状态的集合。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es kf"><img src="../Images/21b06d9d68fdbc89f4f5dfeae0b66367.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ekLzXEeMus9bMqhtmI4kAA.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">状态和信息集。如果玩家0只能观察状态的A部分，而玩家1只能观察B部分，那么游戏可能处于状态(A=2，B=4)，这在玩家0的树中表示为信息集(A=2)，在玩家1的树中表示为信息集(B=4)。</figcaption></figure><p id="252d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了处理<strong class="ih hj">机会</strong>的元素，该树区分中性节点和行动后节点。从中立节点过渡到行动后节点，我们采用“常规方式”；通过选择具有最高UCB的动作(幸运的是，动作的结果不受机会的影响)。由于“外力”的作用，我们通过遍历到下一个节点来模拟任何其他状态转换。这些外力可以是对手的移动，也可以是从一副牌中抽牌。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es kc"><img src="../Images/e808c8156ef112943a1615b8b91ac21a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*VvRHSFqQTfVfyUHMtpg-TA.gif"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">纸牌游戏Kariba的多观察者信息集蒙特卡罗树搜索。在<a class="ae kd" href="https://github.com/KnurpsBram/AI_plays_kariba/tree/master/other" rel="noopener ugc nofollow" target="_blank"> git repo </a>中也有pdf格式</figcaption></figure><p id="d2a5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">gif的Pdf版本可以在<a class="ae kd" href="https://github.com/KnurpsBram/AI_plays_kariba" rel="noopener ugc nofollow" target="_blank"> github repo </a>中获得，同时还有源代码(Python)和一个让卡里巴对抗MOISMCTS-agent的小型竞技场。</p><p id="9c0b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">关于MCTS的其他有趣的东西还有:<br/> - <a class="ae kd" href="https://int8.io/monte-carlo-tree-search-beginners-guide/" rel="noopener ugc nofollow" target="_blank"> int8的《MCTS入门指南》</a> <br/> - <a class="ae kd" href="https://github.com/int8/monte-carlo-tree-search" rel="noopener ugc nofollow" target="_blank"> int8的《MCTS回购井字游戏(python)】</a><br/>-<a class="ae kd" href="https://www.researchgate.net/publication/254060888_Information_Set_Monte_Carlo_Tree_Search" rel="noopener ugc nofollow" target="_blank">Cowling等人关于信息集蒙特卡罗树搜索的论文(ISMCTS) </a>，尤其是G节(第10页)<br/>-<a class="ae kd" href="https://github.com/tetraptych/synapsen" rel="noopener ugc nofollow" target="_blank">tetratych的《回购synapsen (python) </a>、信息集蒙特卡罗树搜索(信息集蒙特卡罗树搜索</p></div></div>    
</body>
</html>