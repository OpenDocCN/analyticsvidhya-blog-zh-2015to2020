<html>
<head>
<title>Sentiment Analysis on Roman Urdu using python, sklearn and nltk</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于python、sklearn和nltk的罗马乌尔都语情感分析</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/sentiment-analysis-on-roman-urdu-using-python-sklearn-and-nltk-c3a279ef7748?source=collection_archive---------2-----------------------#2019-09-10">https://medium.com/analytics-vidhya/sentiment-analysis-on-roman-urdu-using-python-sklearn-and-nltk-c3a279ef7748?source=collection_archive---------2-----------------------#2019-09-10</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="e1de" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">大家好。在这篇博文中，我们将讨论如何使用python、nltk和sklearn对罗马乌尔都语进行情感分析。我们将使用机器学习技术来执行这项任务。我们将对在这里找到的数据集进行分类。</p><h1 id="3000" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">步骤1:导入所有必需的模块</h1><pre class="kc kd ke kf fd kg kh ki kj aw kk bi"><span id="fca2" class="kl jf hi kh b fi km kn l ko kp"><em class="kq"># Importing the libraries</em><br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>import pandas as pd<br/>from sklearn.utils import shuffle<br/>from sklearn.preprocessing import LabelEncoder,OneHotEncoder<br/><em class="kq">#making corpus or words from comments</em><br/>import re<br/>from nltk.stem.porter import PorterStemmer<br/>import nltk<br/>from sklearn.feature_extraction.text import CountVectorizer<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.linear_model import LogisticRegression<br/>from sklearn.metrics import confusion_matrix<br/>from sklearn.metrics import accuracy_score</span></pre><p id="4b8a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上面我们可以看到，我们已经进口的一切，我们将用于给定的任务是对罗马乌尔都语的情绪分析</p><h1 id="e904" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">步骤2:导入数据集</h1><pre class="kc kd ke kf fd kg kh ki kj aw kk bi"><span id="82b7" class="kl jf hi kh b fi km kn l ko kp">dataset = pd.read_csv('Roman Urdu DataSet.csv')</span></pre><p id="6e23" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们已经从数据集创建了熊猫数据框架。csv文件</p><h1 id="79fb" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">步骤3:让我们看看我们的数据集</h1><pre class="kc kd ke kf fd kg kh ki kj aw kk bi"><span id="727c" class="kl jf hi kh b fi km kn l ko kp">dataset.head()</span></pre><figure class="kc kd ke kf fd ks er es paragraph-image"><div class="er es kr"><img src="../Images/fe916ae21e3b0b9dcfda3b2e34a65dcf.png" data-original-src="https://miro.medium.com/v2/resize:fit:784/format:webp/1*pAsSNs7dUc4o7XM3_n1SqA.png"/></div><figcaption class="kv kw et er es kx ky bd b be z dx translated">数据集的前五行</figcaption></figure><p id="0c6b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这个数据集包含三列，其中两列是有用的，一列是垃圾列，不会在任何地方使用</p><p id="1f04" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在让我们可视化数据集</p><pre class="kc kd ke kf fd kg kh ki kj aw kk bi"><span id="0692" class="kl jf hi kh b fi km kn l ko kp">Pos = dataset[dataset['sentiment'] == 'Positive'].shape[0]<br/>Neg = dataset[dataset['sentiment'] == 'Negative'].shape[0]<br/>Neu = dataset[dataset['sentiment'] == 'Neutral'].shape[0]<br/><em class="kq"># bar plot of the 3 classes</em><br/>plt.bar(10,Pos,3, label="Positve")<br/>plt.bar(15,Neg,3, label="Negative")<br/>plt.bar(20,Neu,3, label="Neutral")<br/>plt.legend()<br/>plt.ylabel('Number of examples')<br/>plt.title('Proportion of examples')<br/>plt.show()</span></pre><figure class="kc kd ke kf fd ks er es paragraph-image"><div class="er es kz"><img src="../Images/c0d4e2e98be19155dcc6bfca521ac4cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:824/format:webp/1*_Y8MK-XA7nVzUnJ95-u75g.png"/></div><figcaption class="kv kw et er es kx ky bd b be z dx translated">每个情感类别的文本数量</figcaption></figure><h1 id="b171" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">第四步:我们有分类数据形式的y，我们需要把它转换成定量数据</h1><pre class="kc kd ke kf fd kg kh ki kj aw kk bi"><span id="47f6" class="kl jf hi kh b fi km kn l ko kp"><em class="kq"># label selection</em><br/>y=dataset.iloc[:,1].values<br/>labelEnocder_y=LabelEncoder()<br/>y=labelEnocder_y.fit_transform(y)<br/><em class="kq"># 2 postive 0 negative 1 nuetral</em></span></pre><h1 id="78cd" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">步骤5:清洁</h1><p id="2226" class="pw-post-body-paragraph if ig hi ih b ii la ik il im lb io ip iq lc is it iu ld iw ix iy le ja jb jc hb bi translated">让我们对文本进行一些清理，在下面的代码中，我们只允许使用英文字符，不允许使用特殊字符，所有的文本都被转换成小写，罗马乌尔都语的停用词被删除</p><pre class="kc kd ke kf fd kg kh ki kj aw kk bi"><span id="75d0" class="kl jf hi kh b fi km kn l ko kp">corpus=[]<br/>stopwords=['ai', 'ayi', 'hy', 'hai', 'main', 'ki', 'tha', 'koi', 'ko', 'sy', 'woh', 'bhi', 'aur', 'wo', 'yeh', 'rha', 'hota', 'ho', 'ga', 'ka', 'le', 'lye', 'kr', 'kar', 'lye', 'liye', 'hotay', 'waisay', 'gya', 'gaya', 'kch', 'ab', 'thy', 'thay', 'houn', 'hain', 'han', 'to', 'is', 'hi', 'jo', 'kya', 'thi', 'se', 'pe', 'phr', 'wala', 'waisay', 'us', 'na', 'ny', 'hun', 'rha', 'raha', 'ja', 'rahay', 'abi', 'uski', 'ne', 'haan', 'acha', 'nai', 'sent', 'photo', 'you', 'kafi', 'gai', 'rhy', 'kuch', 'jata', 'aye', 'ya', 'dono', 'hoa', 'aese', 'de', 'wohi', 'jati', 'jb', 'krta', 'lg', 'rahi', 'hui', 'karna', 'krna', 'gi', 'hova', 'yehi', 'jana', 'jye', 'chal', 'mil', 'tu', 'hum', 'par', 'hay', 'kis', 'sb', 'gy', 'dain', 'krny', 'tou']<br/>for i <strong class="kh hj">in</strong> range(0,14646):<br/>    review = re.sub('[^a-zA-Z]',' ',dataset.iloc[:,0].values[i])<br/>    review=review.lower()<br/>    review=review.split()<br/>    review=[word for word <strong class="kh hj">in</strong> review if <strong class="kh hj">not</strong> word <strong class="kh hj">in</strong> stopwords]<br/>    review=' '.join(review)<br/>    corpus.append(review)</span></pre><p id="04aa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在我们有了语料库或单词，我们需要创建一个词汇表，这是在文本步骤中完成的</p><h1 id="4821" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">第六步:创造词汇</h1><pre class="kc kd ke kf fd kg kh ki kj aw kk bi"><span id="b954" class="kl jf hi kh b fi km kn l ko kp">cv=CountVectorizer(max_features=2500)<br/>x=cv.fit_transform(corpus).toarray()</span></pre><h1 id="6efb" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">步骤7:将数据集分成训练集和测试集</h1><pre class="kc kd ke kf fd kg kh ki kj aw kk bi"><span id="23d4" class="kl jf hi kh b fi km kn l ko kp">x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.20)</span></pre><p id="a2da" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在上面代码的帮助下，我们将80%的数据用于训练，20%用于测试</p><h1 id="bfa3" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">步骤8:创建分类器并在分类器中拟合数据</h1><pre class="kc kd ke kf fd kg kh ki kj aw kk bi"><span id="585d" class="kl jf hi kh b fi km kn l ko kp">classifier=LogisticRegression(random_state=0,solver='liblinear',multi_class='auto')<br/>classifier.fit(x_train,y_train)</span></pre><p id="53e4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们已经创建了一个逻辑回归分类器，并在其上拟合训练数据</p><h1 id="76bb" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">步骤9:执行预测</h1><pre class="kc kd ke kf fd kg kh ki kj aw kk bi"><span id="4380" class="kl jf hi kh b fi km kn l ko kp">y_pred=classifier.predict(x_test)</span></pre><p id="ab08" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上面的代码创建了一个预测向量</p><h1 id="4df1" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">步骤10:创建混淆矩阵</h1><pre class="kc kd ke kf fd kg kh ki kj aw kk bi"><span id="73c1" class="kl jf hi kh b fi km kn l ko kp">cm=confusion_matrix(y_test,y_pred)</span></pre><p id="5498" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">该矩阵显示了对每一类标签做出了多少正确和错误的预测</p><figure class="kc kd ke kf fd ks er es paragraph-image"><div class="er es lf"><img src="../Images/693e497ab6d39a7e07e08d9d7151d117.png" data-original-src="https://miro.medium.com/v2/resize:fit:362/format:webp/1*KQN3u0vrU8B11c_pe13dMg.png"/></div><figcaption class="kv kw et er es kx ky bd b be z dx translated">混淆矩阵</figcaption></figure><h1 id="4753" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">步骤11:评估</h1><pre class="kc kd ke kf fd kg kh ki kj aw kk bi"><span id="0be6" class="kl jf hi kh b fi km kn l ko kp">print('Accuracy is <strong class="kh hj">{}</strong> '.format(accuracy_score(y_test, y_pred)))</span></pre><p id="5dd9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们对模型的准确性进行了评估，我们能够获得64.6%的准确性</p><figure class="kc kd ke kf fd ks er es paragraph-image"><div class="er es lg"><img src="../Images/f69cb2301c7f53a4098c5c7a71e51592.png" data-original-src="https://miro.medium.com/v2/resize:fit:1308/format:webp/1*DtVvy6IlJyegkWZ5XY4qWA.png"/></div><figcaption class="kv kw et er es kx ky bd b be z dx translated">模型的准确性</figcaption></figure><h1 id="29d5" class="je jf hi bd jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">免费赠送:可视化混淆矩阵</h1><pre class="kc kd ke kf fd kg kh ki kj aw kk bi"><span id="27f7" class="kl jf hi kh b fi km kn l ko kp">labels=['Positive','Neutral','Negative']<br/>fig = plt.figure()<br/>ax = fig.add_subplot(111)<br/>cax = ax.matshow(cm)<br/>plt.title('Confusion matrix of the classifier <strong class="kh hj">\n</strong>')<br/>fig.colorbar(cax)<br/>ax.set_xticklabels([''] + labels)<br/>ax.set_yticklabels([''] + labels)<br/>plt.xlabel('Predicted')<br/>plt.ylabel('True')<br/>plt.show()</span></pre><figure class="kc kd ke kf fd ks er es paragraph-image"><div class="er es lh"><img src="../Images/88bac3e75762558e7b4759ef4e01c5ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:752/format:webp/1*ZAf-EW1cXBRkCna1shtvIg.png"/></div><figcaption class="kv kw et er es kx ky bd b be z dx translated">混乱矩阵图</figcaption></figure><p id="a1ec" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这就是今天的全部内容，如果你有任何问题，欢迎评论或给我发邮件到owais.leghari@hotmail.com。我也在kaggle上运行了这个内核，你可以看看这里的<a class="ae jd" href="https://www.kaggle.com/owaisraza009/roman-urdu-sentiment-analysis/notebook" rel="noopener ugc nofollow" target="_blank"/></p><p id="7e75" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">快乐编码❤ </strong></p></div></div>    
</body>
</html>